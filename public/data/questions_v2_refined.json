[
  {
    "id": 1,
    "topic": "",
    "question_cn": "一家公司收集多个大陆城市的温度、湿度和大气压力数据。公司每天从每个站点收集的数据量平均为500GB。每个站点都有高速互联网连接。该公司希望在一个单一的亚马逊S3桶中尽可能快地汇总所有这些全球站点的数据。解决方案必须最小化操作复杂性。 哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "打开目的地S3桶上的S3传输加速度。使用多部分上传直接上传站点数据到目的地S3桶。",
      "B": "从每个站点上传数据到最近区域的S3桶。使用跨区域复制将对象复制到目标S3桶。然后从原S3桶中移除数据。",
      "C": "安排Snowball边缘存储优化设备每天工作以传输数据从每个站点到最近的区域。使用跨区域复制将对象复制到目标S3桶。",
      "D": "将数据从每个站点上传到最近区域的亚马逊EC2实例。将数据存储在亚马逊弹性块存储(EBS)卷中。在固定的间隔时，EBS间里获取一个快照并将其复制到包含目标S3桶的区域。恢复该区域的卷。"
    },
    "vote_percentage": "98%",
    "tags": [
      "S3 Transfer Acceleration",
      "S3 Multi-part Upload"
    ],
    "explanation": {
      "analysis": "考查S3传输加速和多部分上传以优化大文件上传。",
      "why_correct": "选项A直接利用S3的传输加速功能和多部分上传，能快速上传数据到S3桶，且操作简单。",
      "why_wrong": "选项B涉及跨区域复制，会增加复杂性和成本；选项C使用Snowball Edge，适用于网络条件差的场景，不适用于本题场景；选项D涉及EC2和EBS，增加了复杂性，且效率不如直接上传到S3。"
    },
    "related_terms": [
      "S3",
      "S3 Transfer Acceleration",
      "多部分上传",
      "跨区域复制",
      "Snowball",
      "EC2",
      "EBS",
      "快照",
      "跨区域复制"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 2,
    "topic": "",
    "question_cn": "一家公司需要有能力分析其专有应用程序的日志文件。日志以JSON格式存储在亚马逊S3桶中。查询将是简单的并将按需运行。解决方案架构师需要在对现有架构进行最小化更改的情况下执行分析。 解决方案架构师应该如何用最少的操作开销来满足这些需求？",
    "options_cn": {
      "A": "使用亚马逊红移将所有内容加载到一个地方并根据需要运行SQL查询。",
      "B": "使用亚马逊云表日志存储日志。根据需要从亚马逊云表控制台运行SQL查询。",
      "C": "使用亚马逊Athena直接与亚马逊S3运行查询需要。",
      "D": "使用Glue对日志进行编目。在亚马逊EMR上使用一个短暂的Spark集群来根据需要运行SQL查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Athena",
      "S3"
    ],
    "explanation": {
      "analysis": "考查使用Athena直接查询S3中的日志文件。",
      "why_correct": "选项C使用Athena可以方便地直接查询S3中的JSON格式的日志文件，无需额外的ETL流程，操作简单。",
      "why_wrong": "选项A使用Redshift，需要先将数据导入，增加开销；选项B使用云表日志，不适用于存储在S3中的日志；选项D使用EMR和Glue，增加了复杂性，适用于更复杂的分析需求。"
    },
    "related_terms": [
      "Athena",
      "S3",
      "Amazon Redshift",
      "Amazon CloudWatch Logs",
      "Glue",
      "EMR",
      "Spark"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 3,
    "topic": "",
    "question_cn": "一家公司利用美国职业介绍所的组织来管理不同部门的多个美国职业介绍所的帐户。管理帐户有一个亚马逊S3桶，其中包含项目报告。该公司希望限制对这个S3桶的访问，只限于在组织内的用户的账户在美国职业安全服务组织。 用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "向S3桶策略中添加基于组织的全局条件键并引用组织ID。",
      "B": "为每个部门创建一个组织单位。添加S3桶策略的主要全局条件键。",
      "C": "使用CloudTrail来监控创造者帐户邀请者帐户的组织离开组织以及组织事件的清除。相应更新S3桶策略。",
      "D": "标记每个需要访问S3桶的用户。添加S3桶策略的全局条件键主要标记。"
    },
    "vote_percentage": "97%",
    "tags": [
      "S3 Bucket Policy",
      "IAM Organization"
    ],
    "explanation": {
      "analysis": "考查如何使用桶策略限制对S3桶的访问，基于组织成员身份。",
      "why_correct": "选项A通过在S3桶策略中使用`aws:PrincipalOrgID`全局条件键，限制只有属于指定组织的IAM用户才能访问桶，这是最直接、最简洁的解决方案。",
      "why_wrong": "选项B没有使用正确的组织ID来限制访问；选项C使用了CloudTrail来监控，这并不是直接限制访问的方法；选项D使用了标记，这增加了复杂性，且不是最有效的方法。"
    },
    "related_terms": [
      "S3",
      "IAM",
      "CloudTrail"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 4,
    "topic": "",
    "question_cn": "一个应用程序在VPC中的亚马逊EC2实例上运行。应用程序处理存储在亚马逊S3桶中的日志。EC2实例需要在没有互联网连接的情况下访问S3桶。 哪个解决方案将提供私人网络连接亚马逊S3？",
    "options_cn": {
      "A": "创建一个到S3桶的网关VPC端点。",
      "B": "将日志流到亚马逊云表日志。把日志导出到S3桶。",
      "C": "在亚马逊EC2上创建一个实例配置文件，允许EC2访问S3。",
      "D": "创建一个具有专用链接的亚马逊API网关以访问S3端点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "考查如何在VPC内安全地访问S3，避免公网连接。",
      "why_correct": "选项A创建S3网关VPC端点，允许EC2实例通过VPC内私有网络访问S3，无需公网IP或NAT Gateway，最安全高效。",
      "why_wrong": "选项B虽然可以实现日志导出，但无法解决实例访问S3的问题；选项C只是给EC2实例配置了访问S3的权限，但仍然需要互联网连接或NAT Gateway才能访问S3；选项D使用了专用链接，增加了复杂性，且不是最直接的解决方案。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "S3",
      "VPC 端点",
      "CloudWatch Logs",
      "API Gateway"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 5,
    "topic": "",
    "question_cn": "一家公司正在使用一个亚马逊EC2实例在一个亚马逊EBS卷中存储用户上传的文档，在AWS上托管一个Web应用程序。为了更好的可伸缩性和可用性，该公司复制了架构并在另一个可用性区域创建了第二个EC2实例和EBS卷，将两者置于应用程序负载平衡器后面。在完成此更改后，用户报告说每次他们刷新网站时，他们都可以看到自己的一个或另一个文档的子集，但绝不能同时看到所有的文档。 解决方案架构师应该建议什么来确保用户同时查看所有文档？",
    "options_cn": {
      "A": "复制数据使两个EBS卷包含所有文档。",
      "B": "配置应用程序负载平衡器以引导用户使用文档到服务器。",
      "C": "将两个EBS卷的数据复制到亚马逊EFS。修改应用程序将新文档保存到亚马逊EFS。",
      "D": "配置应用程序负载平衡器将请求发送到两个服务器。从正确的服务器返回每个文档。"
    },
    "vote_percentage": "98%",
    "tags": [
      "EFS",
      "EBS",
      "Load Balancer"
    ],
    "explanation": {
      "analysis": "考查如何在多个EC2实例间共享数据以保证数据一致性。",
      "why_correct": "选项C使用EFS作为共享存储，所有EC2实例都可以访问相同的数据，从而确保用户看到所有文档。修改应用程序将新文档保存到EFS，保证了数据一致性。",
      "why_wrong": "选项A简单地复制数据到EBS卷，没有解决数据同步的问题，可能导致数据不一致；选项B负载均衡器不能保证数据同步；选项D没有解决数据共享的问题。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "应用程序负载平衡器",
      "EFS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 6,
    "topic": "",
    "question_cn": "一家公司使用 NFS 存储大型视频文件在内部网络附加存储。每个视频文件的大小从1MB到500GB不等。总储存量为70TB，并且不再增长。该公司决定将视频文件迁移到亚马逊S3。该公司必须尽快迁移视频文件，同时使用尽可能少的网络带宽。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个S3桶。创建一个具有写入桶权限的 IAM 角色。使用AWS CLI将所有文件在本地复制到S3桶。",
      "B": "创建一个AWS Snowball Edge设备。在酒店内接收Snowball Edge设备。使用Snowball Edge客户端将数据传输到设备。返回设备，这样可以将数据导入到亚马逊S3。",
      "C": "在现场部署一个NFS文件网关。创建公共服务端点连接到文件网关。创建一个S3桶。在文件网关上创建一个新的文件共享。将新文件共享指向S3桶。将数据从现有的NFS文件共享传输到文件网关。",
      "D": "在酒店内的网络和网络之间建立直接连接。在现场部署一个文件网关。创建一个公共虚拟接口(VIF)连接到文件网关。创建一个S3桶。在文件网关上创建一个新的文件共享。将新文件共享指向S3桶。将数据从现有的NFS文件共享传输到S3文件网关。"
    },
    "vote_percentage": "86%",
    "tags": [
      "S3",
      "Snowball Edge"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是使用Snowball Edge可以更快地将大量数据迁移到S3，并且可以在带宽受限的环境中进行，而无需大量网络带宽。",
      "why_correct": "Snowball Edge 专为大规模数据迁移设计，可以离线传输数据，适用于网络带宽受限或需要快速传输大量数据的场景。使用 Snowball Edge 可以在本地进行数据传输，然后将设备运回 AWS，从而最大限度地减少网络带宽的使用。",
      "why_wrong": "A选项需要通过网络上传数据，速度慢且消耗带宽。C和D选项涉及文件网关，增加了复杂性，但解决问题的核心思路与 Snowball Edge 相比，效率较低。"
    },
    "related_terms": [
      "NFS",
      "S3",
      "IAM",
      "AWS CLI",
      "Snowball Edge",
      "文件网关",
      "VIF"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 7,
    "topic": "",
    "question_cn": "一家公司有一个可以吸收传入消息的应用程序。许多其他的应用程序和微服务很快就会使用这些消息。信息数量变化很大，有时会突然增加到每秒10万条。该公司希望将解决方案脱钩并提高可伸缩性。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将信息发布到亚马逊运动数据分析。配置消费者应用程序来读取和处理消息。",
      "B": "在EC2实例上部署摄取应用程序，该实例在一个自动缩放组中，以根据CPU度量标准来扩展EC2实例的数量。",
      "C": "使用单个碎片将消息写入亚马逊运动数据流。使用一个Lambda函数预处理消息并将其存储在亚马逊 DynamoDB中。将使用者应用程序配置为读取从 DynamoDB到处理消息。",
      "D": "将消息发布到具有多个亚马逊简单队列服务(SQS)订阅的亚马逊简单通知服务(SNS)主题。配置消费者应用程序来处理来自队列的消息。"
    },
    "vote_percentage": "83%",
    "tags": [
      "SNS",
      "SQS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是使用SNS和SQS可以实现消息的解耦和异步处理，同时提高系统的可伸缩性。SNS 用于消息发布，SQS 用于消息队列，消费者从队列中获取消息。",
      "why_correct": "D选项使用了SNS和SQS，SNS用于发布消息，SQS提供消息队列，从而实现了解耦和异步处理，满足了高吞吐量和可伸缩性的要求。消费者应用程序可以独立地从队列中读取和处理消息，提高了系统的弹性。多个SQS队列也可以提高吞吐量。",
      "why_wrong": "A选项没有提到解耦。B选项虽然使用自动伸缩，但直接将消息处理与EC2实例耦合，不够灵活。C选项使用了 DynamoDB 和 Lambda，增加了复杂性，而没有充分利用 SNS 和 SQS 的解耦优势。"
    },
    "related_terms": [
      "SNS",
      "EC2",
      "自动缩放组",
      "Lambda",
      "DynamoDB",
      "SQS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 8,
    "topic": "",
    "question_cn": "一家公司正在将一个分布式应用程序迁移到AWS。应用程序服务于可变工作负载。遗留平台由一个主服务器组成，该主服务器在多个计算节点之间协调作业。该公司希望通过最大限度地提高弹性和可伸缩性的解决方案使应用程序现代化。解决方案架构师应该如何设计架构以满足这些需求？",
    "options_cn": {
      "A": "配置一个亚马逊简单队列服务(SQS)队列作为作业的目的地。使用亚马逊EC2实例实现在自动缩放组中管理的计算节点。配置EC2自动缩放以使用预定缩放。",
      "B": "配置一个亚马逊简单队列服务(SQS)队列作为作业的目的地。使用亚马逊EC2实例实现在自动缩放组中管理的计算节点。根据队列的大小配置EC2自动缩放。",
      "C": "实现在自动缩放组中管理的主要服务器和具有亚马逊EC2实例的计算节点。配置 CloudWatch作为作业的目的地。根据主服务器上EC2的负载配置自动缩放。",
      "D": "实现在自动缩放组中管理的主要服务器和具有亚马逊EC2实例的计算节点。将亚马逊 CloudWatch 事件配置为EC2工作的目的地。根据计算节点上的负载配置自动缩放。"
    },
    "vote_percentage": "93%",
    "tags": [
      "SQS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是使用SQS和EC2自动伸缩，根据队列的负载进行伸缩，能更有效地实现弹性，且架构简单。",
      "why_correct": "B选项使用了SQS作为作业队列，解耦了主服务器和计算节点。EC2实例在自动伸缩组中运行，根据SQS队列的大小自动伸缩，能够更好地适应可变的工作负载，提高弹性和可伸缩性。",
      "why_wrong": "A选项使用了预定缩放，不如根据队列负载进行伸缩灵活。C选项架构复杂，主服务器成为瓶颈，并且CloudWatch不是作业的目的地。D选项使用 CloudWatch 事件，增加了复杂性，不如使用SQS和自动伸缩更简洁有效。"
    },
    "related_terms": [
      "SQS",
      "EC2",
      "自动缩放组",
      "CloudWatch"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 9,
    "topic": "",
    "question_cn": "一家公司正在其数据中心运行一个SMB文件服务器。文件服务器存储在创建文件后的最初几天经常访问的大型文件。七天后这些文件很少被访问。数据总量正在增加，接近公司的总存储容量。解决方案架构师必须增加公司可用的存储空间，同时又不损失对最近访问的文件的低延迟访问。解决方案架构师还必须提供文件生命周期管理以避免未来的存储问题。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS DataSync来复制从SMB文件服务器到S3的超过7天的数据。",
      "B": "创建一个亚马逊文件网关来扩展公司的存储空间。创建一个生命周期策略在7天后将数据转换为S3 Glacier Deep Archive。",
      "C": "为SMB文件服务器文件系统创建一个亚马逊 FSx以扩展公司的存储空间。",
      "D": "在每个用户的计算机上安装一个工具来访问亚马逊S3。创建生命周期策略在7天后将数据转换为S3 Glacier Flexible Retrieval。"
    },
    "vote_percentage": "83%",
    "tags": [
      "S3",
      "Lifecycle Policy"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是文件网关可以提供本地缓存，保证了最近文件的低延迟访问，并结合 S3 生命周期策略可以有效进行存储分层，降低成本。",
      "why_correct": "B选项使用文件网关可以缓存最近访问的文件，提供低延迟访问。S3生命周期策略可以自动将旧文件迁移到S3 Glacier Deep Archive，实现存储分层，降低成本。",
      "why_wrong": "A选项 DataSync 只是数据同步工具，没有存储分层。C选项FSx存储成本高。D选项用户访问S3的体验不好，且 Flexible Retrieval 成本较高。"
    },
    "related_terms": [
      "SMB",
      "AWS DataSync",
      "S3",
      "文件网关",
      "S3 Glacier Deep Archive",
      "FSx",
      "S3 Glacier Flexible Retrieval"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 10,
    "topic": "",
    "question_cn": "一家公司正在建立一个电子商务的网络应用程序。应用程序将有关新订单的信息发送到Amazon API Gateway来处理。该公司希望确保订单按收到的顺序进行处理。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "当应用程序收到订单时，使用API Gateway集成将消息发布到亚马逊简单通知服务(SNS)亚马逊主题。向主题订阅Lambda函数来执行处理。",
      "B": "当应用程序收到订单时，使用API Gateway集成将消息发送到亚马逊简单队列服务(SQS)亚马逊队列。为处理调用Lambda函数，配置SQS FIFO队列。",
      "C": "当应用程序处理订单时，使用API Gateway授权程序来阻止任何请求。",
      "D": "当应用程序收到订单时，使用API Gateway集成将消息发送到亚马逊简单队列服务标准队列。配置标准队列来调用Lambda函数进行处理。"
    },
    "vote_percentage": "98%",
    "tags": [
      "API Gateway",
      "SQS FIFO"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是使用 SQS FIFO 队列可以保证消息的顺序，而 API Gateway 集成可以方便地将消息发送到队列。",
      "why_correct": "B选项使用了SQS FIFO队列，FIFO队列保证了消息的顺序。 API Gateway集成可以方便地将订单消息发送到队列，Lambda函数可以从队列中获取消息并进行处理，满足了订单按顺序处理的要求。",
      "why_wrong": "A选项使用SNS不能保证消息的顺序。C选项无法处理订单。D选项使用标准SQS队列不能保证消息顺序。"
    },
    "related_terms": [
      "Amazon API Gateway",
      "SNS",
      "Lambda",
      "SQS",
      "FIFO",
      "API Gateway 授权程序"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 11,
    "topic": "",
    "question_cn": "一家公司有一个在亚马逊EC2实例上运行的应用程序，并使用亚马逊Aurora数据库。EC2实例通过使用本地存储在文件中的用户名和密码连接到数据库。该公司希望最大限度地减少凭证管理的运营开销。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "使用AWS Secrets Manager。打开自动旋转。",
      "B": "使用系统管理器参数存储。打开自动旋转。",
      "C": "创建一个亚马逊S3桶来存储用密钥管理服务(AWS KMS)加密的对象。将凭证文件迁移到S3桶。将应用程序指向S3桶。",
      "D": "为每个EC2实例创建一个加密的亚马逊弹性块存储(EBS)亚马逊EBS卷。将新EBS卷附加到每个EC2实例。将凭证文件迁移到新的EBS卷。将应用程序指向新的EBS卷。"
    },
    "vote_percentage": "95%",
    "tags": [
      "Secrets Manager",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用AWS Secrets Manager可以集中管理凭证，并支持自动轮换凭证，降低运维开销。",
      "why_correct": "A选项使用AWS Secrets Manager可以安全地存储、检索和管理凭证，并支持自动轮换，从而减少了凭证管理的运营开销。 Secrets Manager 还支持集中管理凭证，简化了管理过程。",
      "why_wrong": "B选项使用系统管理器参数存储，不如Secrets Manager方便。C和D选项涉及将凭证存储在S3或EBS中，增加了复杂性，并且没有提供自动轮换的功能。"
    },
    "related_terms": [
      "EC2",
      "Aurora",
      "Secrets Manager",
      "AWS KMS",
      "S3",
      "EBS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 12,
    "topic": "",
    "question_cn": "一家全球性的公司在亚马逊EC2实例中提供了它的Web应用程序，支持一个应用负载均衡器(ALB)。Web应用程序具有静态数据和动态数据。该公司将其静态数据存储在亚马逊S3桶中。公司希望提高性能，降低静态数据和动态数据的延迟。该公司使用自己在亚马逊Route 53线路注册的域名。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个亚马逊 CloudFront分布，其中有S3桶和 Route 53线路作为起源。将Route 53线路配置为将流量路由到 CloudFront分布。",
      "B": "创建一个亚马逊 CloudFront分布，它有一个全球加速器标准加速器。创建一个S3桶。该加速器具有S3桶作为一个端点。配置路线将流量路由到 CloudFront分布。",
      "C": "创建一个具有S3桶起源的亚马逊 CloudFront分布。创建一个 全球加速器标准加速器，它具有ALB和 CloudFront分布作为终点。创建指向加速器名称的自定义域名。使用自定义域名作为Web应用程序的端点。",
      "D": "创建一个亚马逊 CloudFront分布，它有一个起源。创建一个美国航空航天系统 全球加速器标准加速器，有一个S3桶作为终点。创建DNS和DNS Web两个域名。指向动态内容的云前域名。将其他域名指向用于静态内容的加速器名称。使用域名作为Web应用程序的端点。"
    },
    "vote_percentage": "80%",
    "tags": [
      "CloudFront",
      "Route 53"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用CloudFront可以缓存静态内容，并利用Route 53进行域名解析，提高性能和降低延迟。",
      "why_correct": "A选项使用CloudFront可以缓存来自S3桶的静态内容，从而减少延迟并提高性能。使用Route 53可以管理域名和将流量路由到CloudFront分布，满足了全球范围内的用户访问需求。",
      "why_wrong": "B选项使用了全球加速器，增加了复杂性，且不必要。C选项使用了全球加速器和ALB，更加复杂。D选项更加复杂，且使用了多个域名，配置繁琐。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "S3",
      "Route 53",
      "CloudFront",
      "全球加速器",
      "DNS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 13,
    "topic": "",
    "question_cn": "一家公司每月对其亚马逊RDS基础设施进行维护。在这些维护活动中，公司需要将其亚马逊RDS的凭证在多个区域之间进行轮换。 用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将证书作为机密保存在AWS Secrets Manager处。在需要的区域使用多区域秘密复制。配置机密管理器以根据时间表旋转机密。",
      "B": "通过创建一个安全的字符串参数将凭证作为机密存储在系统管理器中。在需要的区域使用多区域秘密复制。配置系统管理器以便在一个时间表中轮换机密。",
      "C": "在启用服务器端加密(SSE)的亚马逊S3桶中存储凭证。使用亚马逊的亚马逊云表事件来调用一个Lambda函数来旋转凭证。",
      "D": "使用密钥管理服务(AWS KMS)多区域客户管理密钥将凭证加密为机密。将这些秘密保存在亚马逊DynamoDB全球桌上。从DynamoDB中提取秘密。使用Lambda旋转秘密。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "Multi-Region Secret Rotation"
    ],
    "explanation": {
      "analysis": "考查在多个AWS区域轮换数据库凭证，并最大限度地减少操作开销。",
      "why_correct": "选项A使用AWS Secrets Manager，支持多区域秘密复制，并可以配置时间表来自动轮换凭证，是最佳解决方案。",
      "why_wrong": "选项B使用系统管理器参数存储，功能不如Secrets Manager强大；选项C使用S3存储凭证，安全性不如Secrets Manager；选项D使用DynamoDB和KMS，增加了复杂性，不适用于简单的凭证轮换。"
    },
    "related_terms": [
      "RDS",
      "Secrets Manager",
      "AWS KMS",
      "Lambda",
      "DynamoDB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 14,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例中运行一个电子商务应用程序，支持一个应用负载平衡器。这些实例在亚马逊自动缩放组中跨多个可用性区域运行。基于CPU利用率指标的自动扩展组规模。电子商务应用程序将事务数据存储在一个位于一个大型RDSMySQL 8.0数据库中。随着应用程序负载的增加，数据库的性能迅速下降。应用程序处理的读请求多于写事务。该公司希望有一个解决方案，它将自动扩展数据库以满足不可预测的阅读工作负载的需求，同时保持高可用性。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊红移与单个节点的领导和计算功能。",
      "B": "使用带有单AZ部署的亚马逊RDS。配置亚马逊RDS在不同的可用性区域添加阅读器实例。",
      "C": "使用具有多AZ部署的亚马逊Aurora。使用Aurora复制品配置Aurora自动缩放。",
      "D": "使用亚马逊弹性计算来进行点实例的记忆存储。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora",
      "Read Replicas",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考查如何构建可扩展的、高可用的数据库架构，以处理读密集型负载。",
      "why_correct": "选项C使用Aurora，支持多可用区部署和Aurora Replicas，可以自动扩展只读副本以满足读请求的需求，同时保持高可用性。",
      "why_wrong": "选项A使用Redshift，不适用于事务型数据库；选项B使用RDS，虽然可以配置只读副本，但不支持自动缩放；选项D使用EC2，不适用于数据库存储。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "RDS",
      "MySQL",
      "Aurora",
      "自动缩放",
      "Amazon Redshift",
      "单 AZ",
      "多 AZ",
      "弹性计算"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 15,
    "topic": "",
    "question_cn": "最近一家公司迁移到了AWS，并希望实现一种解决方案来保护生产VPC中的流量。该公司在其内部数据中心有一个检查服务器。检查服务器执行特定的操作，如流量检查和流量过滤。该公司希望在AWS云中拥有相同的功能。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在生产VPC中使用亚马逊护栏进行交通检查和交通过滤。",
      "B": "使用流量镜像来镜像来自生产VPC的流量用于检查和过滤。",
      "C": "使用AWS网络防火墙为生产VPC的流量检查和流量过滤创建所需的规则。",
      "D": "使用AWS防火墙管理器为生产VPC的流量检查和流量过滤创建所需的规则。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Network Firewall",
      "VPC",
      "Security"
    ],
    "explanation": {
      "analysis": "考查如何在VPC中实现流量检查和过滤。",
      "why_correct": "选项C使用AWS网络防火墙，可以创建规则来实现流量检查和过滤，满足了安全需求。",
      "why_wrong": "选项A和D使用其他服务，不适用于流量检查和过滤；选项B使用了流量镜像，可以进行流量分析，但无法实现过滤。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "流量镜像",
      "AWS 网络防火墙",
      "AWS 防火墙管理器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 16,
    "topic": "",
    "question_cn": "一家公司在美国航空公司拥有一个数据湖。数据湖由亚马逊S3和亚马逊后格拉斯格的RDS数据组成。该公司需要一个报告解决方案，提供数据可视化并包括数据湖中的所有数据源。只有公司的管理团队才有充分的访问所有可视化的权限。公司的其他部门应该只有有限的权限。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个分析亚马逊 QuickSight。连接所有数据源并创建新数据集。发布显示数据的仪表板。与适当的IAM角色共享仪表板。",
      "B": "创建一个分析亚马逊 QuickSight。连接所有数据源并创建新数据集。发布显示数据的仪表板。与适当的用户和组共享仪表板。",
      "C": "为亚马逊S3中的数据创建一个AWS Glue表和爬虫机。创建一个AWS Glue提取、转换和负载(ETL)工作以生成报告。发布亚马逊QuickSight的报告。使用S3桶策略限制访问报表。",
      "D": "为亚马逊S3中的数据创建一个AWS Glue表和爬虫机。使用亚马逊Athena联合查询来访问亚马逊S3中的后格列尔RDS数据。使用亚马逊Athena生成报告。发布亚马逊QuickSight的报告。使用S3桶策略限制访问报表。"
    },
    "vote_percentage": "83%",
    "tags": [
      "QuickSight",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用QuickSight可以连接数据源并创建仪表板，通过用户和组进行权限管理，满足了数据可视化和权限控制的需求。",
      "why_correct": "B选项使用QuickSight可以连接S3和RDS数据源，创建仪表板，并通过用户和组进行权限管理，满足了数据可视化和权限控制的需求。 管理员可以完全访问所有仪表板，而其他部门可以根据需要被授予有限的访问权限。",
      "why_wrong": "A选项使用了IAM角色，虽然也可以实现权限控制，但不如使用用户和组方便。C选项需要使用ETL工具，增加了复杂性。D选项增加了Athena联合查询，更加复杂。"
    },
    "related_terms": [
      "S3",
      "RDS",
      "QuickSight",
      "IAM",
      "AWS Glue",
      "ETL",
      "Athena"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 17,
    "topic": "",
    "question_cn": "一家公司正在实施一项新的业务应用程序。该应用程序在两个 Amazon EC2 实例上运行并使用一个 Amazon S3 存储桶进行文档存储。解决方案架构师需要确保 EC2 实例能够访问 S3 存储桶。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "创建一个 IAM 角色，允许访问 S3 存储桶。将角色附加到 EC2 实例中。",
      "B": "创建一个 IAM 策略，允许访问 S3 存储桶。将该策略附加到 EC2 实例中。",
      "C": "创建一个 IAM 组，允许访问 S3 存储桶。将小组附加到 EC2 实例中。",
      "D": "创建一个 IAM 用户，允许访问 S3 存储桶。将用户帐户附加到 EC2 实例中。"
    },
    "vote_percentage": "99%",
    "tags": [
      "IAM Role",
      "EC2 Instance"
    ],
    "explanation": {
      "analysis": "该题考察如何配置 EC2 实例访问 S3 存储桶，重点在于使用 IAM 角色。",
      "why_correct": "选项 A 是最佳实践。IAM 角色为 EC2 实例提供安全凭证，避免在实例中硬编码访问密钥。角色允许访问 S3 存储桶，提供了安全且易于管理的方法。",
      "why_wrong": "选项 B, C 和 D 都不正确。策略需要附加到角色或用户，不能直接附加到 EC2 实例。用户需要管理密钥，而将用户凭证直接配置到实例中是不安全的。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 18,
    "topic": "",
    "question_cn": "一个应用程序开发团队正在设计一种微服务，它将把大图像转换成更小的压缩图像。当用户通过 Web 界面上传图像时，微服务应该将图像存储在一个 Amazon S3 存储桶中，使用 Lambda 函数处理和压缩图像，并将图像以其压缩形式存储在一个不同的 S3 存储桶中。解决方案架构师需要设计一个解决方案，该解决方案使用持久的无状态组件来自动处理图像。哪些行动组合将满足这些要求？（选二）",
    "options_cn": {
      "A": "创建一个 Amazon SQS 队列。在将图像上传到 S3 存储桶时，配置 S3 存储桶将通知发送到队列。",
      "B": "配置 Lambda 函数以使用 Amazon SQS 队列作为调用源。当成功地处理了消息时，删除队列中的消息。",
      "C": "配置 Lambda 函数以监视新上传的 S3 存储桶。当检测到上传的图像时，将文件名写入内存中的文本文件并使用文本文件跟踪处理的图像。",
      "D": "启动一个 Amazon EC2 实例以监视 Amazon SQS 队列。当项目添加到队列中时，在 EC2 实例上的文本文件中记录文件名并调用 Lambda 函数。",
      "E": "配置一个 Amazon EventBridge 事件来监控 S3 存储桶。在上传图像时，向 Amazon SNS 服务发送警报并附上应用程序所有者的电子邮件地址以供进一步处理。"
    },
    "vote_percentage": "99%",
    "tags": [
      "Lambda",
      "SQS",
      "S3 Event Notification"
    ],
    "explanation": {
      "analysis": "该题考察使用 SQS、Lambda 和 S3 Event Notification 构建无服务器图像处理微服务。",
      "why_correct": "选项 A 和 B 是最佳实践组合。选项 A 使用 SQS 作为消息队列，当图像上传到 S3 时触发消息。选项 B 配置 Lambda 函数来消费 SQS 消息并进行图像处理，处理完成后删除消息，实现了异步处理和弹性伸缩。",
      "why_wrong": "选项 C 使用 Lambda 轮询 S3 存储桶，效率低且可能导致不必要的费用。选项 D 在 EC2 实例上运行，增加了管理复杂性，违背了无服务器设计原则。选项 E 仅发送通知，没有处理图像。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "SQS",
      "EC2",
      "EventBridge"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 19,
    "topic": "",
    "question_cn": "一个公司有一个三层的Web应用程序部署在AWS VPC上。Web服务器部署在VPC的公共子网中。应用服务器和数据库服务器部署在同一VPC的私有子网中。该公司已经部署了一个第三方的虚拟防火墙设备从AWS 市场的一个检查IP。该设备配置了一个接口可以接受IP。解决方案架构师需要将Web应用程序与设备集成，以便在流量到达服务器之前检查应用程序的所有流量。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在应用程序的VPC的公共子网中创建一个网络负载平衡器，将流量路由到设备进行包检查。",
      "B": "在应用程序的VPC的公共子网中创建一个应用程序负载平衡器，将流量路由到设备进行包检查。",
      "C": "在检查VPC配置路由表中部署一个传输网关，将传入的数据包通过传输网关进行路由。",
      "D": "在检查VPC中部署网关负载平衡器。创建网关负载平衡器端点接收传入的数据包并将数据包转发到设备。"
    },
    "vote_percentage": "82%",
    "tags": [
      "Gateway Load Balancer",
      "VPC"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是使用网关负载均衡器(Gateway Load Balancer)可以方便地将流量转发到第三方防火墙设备进行检查，同时保持高可用性和可伸缩性。",
      "why_correct": "D选项使用了网关负载均衡器(Gateway Load Balancer)，这是专门为第三方安全设备设计的，能够方便地将流量转发到防火墙设备进行检查，同时提供高可用性和可伸缩性。Gateway Load Balancer端点接收流量，然后将其转发到防火墙设备。",
      "why_wrong": "A选项使用网络负载均衡器，不适合。B选项应用程序负载均衡器不适用。C选项使用了传输网关，增加了复杂性，不如使用网关负载均衡器简单。"
    },
    "related_terms": [
      "VPC",
      "Web服务器",
      "应用服务器",
      "数据库服务器",
      "网络负载平衡器",
      "应用程序负载平衡器",
      "传输网关",
      "网关负载平衡器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 20,
    "topic": "",
    "question_cn": "一家公司希望提高其能力，将大量的生产数据克隆到同一个区域的测试环境中。这些数据存储在 Amazon EBS 卷上的 Amazon EC2 实例中。对克隆数据的修改不得影响生产环境。访问这些数据的软件始终需要高的 I/O 性能。解决方案架构师需要最小化克隆生产数据到测试环境所需的时间。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "以生产的 EBS 卷快照为例。将快照还原到测试环境中的 EC2 实例存储卷。",
      "B": "配置生产 EBS 卷使用多连接特性。拿快照生产 EBS 卷。将生产 EBS 卷附加到测试环境中的 EC2 实例上。",
      "C": "以生产的 EBS 卷快照为例。创建和初始化新的 EBS 卷。在从生产的快照恢复卷之前将新的 EBS 卷附加到测试环境中的 EC2 实例。",
      "D": "以生产的 EBS 卷快照为例。打开快速快照恢复功能的快照。将快照还原为新的 EBS 卷。在测试环境中将新 EBS 卷附加到 EC2 实例上。"
    },
    "vote_percentage": "93%",
    "tags": [
      "EBS Snapshots",
      "Fast Snapshot Restore"
    ],
    "explanation": {
      "analysis": "该题考察如何使用 EBS 快照，并结合快速快照恢复（FSR）功能，高效地克隆生产数据到测试环境。",
      "why_correct": "选项 D 提供了最快的克隆方式。使用 EBS 快照创建数据备份，开启了快速快照恢复功能，大大缩短了快照还原时间。将还原后的 EBS 卷附加到测试环境中的 EC2 实例上，满足了对高性能的需求。",
      "why_wrong": "选项 A 将快照还原到实例存储卷，实例存储卷是临时的，数据会丢失。选项 B 尝试直接将生产 EBS 卷附加到测试环境，这可能会导致数据损坏和冲突，且多连接特性无法直接复制数据。选项 C 的过程较为繁琐，并没有利用快速快照恢复功能。"
    },
    "related_terms": [
      "EBS",
      "EC2",
      "快照",
      "EBS 卷",
      "多连接特性",
      "快速快照恢复"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 21,
    "topic": "",
    "question_cn": "一家电子商务公司想在美国在线服务网站上推出一个一天一次的网站。每天都有一款产品在 24 小时内销售。该公司希望能够在高峰期以毫秒的延迟处理数百万个请求。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 Amazon S3 存储桶来托管完整的网站。添加 Amazon CloudFront 分布。设置 S3 存储桶作为 CloudFront 分发的源。将订单数据存储在 Amazon S3 中。",
      "B": "部署 Amazon EC2 实例的完整网站，这些实例在多个可用性区域的自动扩展组中运行。添加一个应用负载均衡器 来分配网站 API 流量。为后端 RDS MySQL 数据库添加另一个 ALB。为 RDS 存储数据。",
      "C": "将整个应用程序迁移到容器中运行。在 Amazon ECS (Elastic Container Service)上提供容器。使用 Kubernetes 集群自动计算器增加和减少在交通中处理突发事件的吊舱数量。为 RDS MySQL 存储数据。",
      "D": "使用 Amazon S3 存储桶来托管网站的静态内容。部署 Amazon CloudFront 分布。将 S3 存储桶设定为原产地。为后端使用 Amazon API Gateway 和 AWS Lambda 函数。将数据存储在 Amazon DynamoDB 中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront",
      "API Gateway",
      "Lambda",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "该题考察如何设计一个高性能、低延迟且可扩展的电商网站，重点在于使用无服务器架构。",
      "why_correct": "选项 D 提供了最佳的无服务器架构。使用 S3 托管静态内容，CloudFront 提供全球 CDN 加速。API Gateway 接收请求，Lambda 函数处理后端逻辑，DynamoDB 存储数据。这种组合提供了极高的可扩展性、低延迟和最小的操作开销。",
      "why_wrong": "选项 A 虽然使用了 S3 和 CloudFront，但没有后端处理逻辑，无法处理动态内容和订单数据。选项 B 使用 EC2 和 RDS，成本较高且扩展性不如无服务器方案。选项 C 使用 ECS 和 Kubernetes，管理复杂度较高，虽然可扩展性好，但操作成本较高。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "EC2",
      "ALB",
      "RDS MySQL",
      "ECS (Elastic Container Service)",
      "Kubernetes",
      "S3 Transfer Acceleration"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 22,
    "topic": "",
    "question_cn": "一个解决方案架构师正在使用 Amazon S3 设计一个新的数字媒体应用程序的存储架构。媒体文件必须对失去可用性区域具有弹性。一些文件经常被访问，而其他文件则很少以不可预测的方式被访问。解决方案架构师必须最小化存储和检索媒体文件的成本。哪个存储选项满足这些要求？",
    "options_cn": {
      "A": "S3 标准",
      "B": "S3 智能分层",
      "C": "S3 标准-不经常访问 (S3-IA) ",
      "D": "S3 单区不经常访问 (S3-IA)"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Intelligent-Tiering",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "该题考察如何选择合适的 S3 存储类别，以优化存储成本和性能，并兼顾弹性。",
      "why_correct": "选项 B 是最佳选择。S3 智能分层 (Intelligent-Tiering) 自动将对象放置在频繁访问层或不经常访问层，从而优化存储成本，无需手动管理。它提供对可用性区域的弹性。",
      "why_wrong": "选项 A 虽然提供高可用性，但成本相对较高。选项 C 成本低于标准，但需要手动管理，不适合访问模式不可预测的情况。选项 D 成本最低，但只提供单区冗余，不满足弹性需求。"
    },
    "related_terms": [
      "S3",
      "S3 标准",
      "S3 智能分层",
      "S3-IA",
      "S3 单区不经常访问 (S3-IA)"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 23,
    "topic": "",
    "question_cn": "一家公司正在使用 Amazon S3 标准存储来存储备份文件。文件经常被访问一个月。然而在一个月后，文件无法访问。公司必须无限期地保存这些文件。哪种存储方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置 S3 智能分层以自动迁移对象。",
      "B": "创建一个生命周期配置，在一个月后将对象从 S3 标准转换为 S3 Glacier Deep Archive。",
      "C": "创建一个生命周期配置，在一个月后将对象从 S3 标准转换为 S3 标准不经常访问 (S3-IA)。",
      "D": "创建一个生命周期配置，在一个月后将对象从 S3 标准转换为 S3 单区不经常访问 (S3-IA)。"
    },
    "vote_percentage": "96%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Glacier Deep Archive"
    ],
    "explanation": {
      "analysis": "该题考察如何使用 S3 生命周期策略和不同的存储类，以优化备份文件的存储成本和访问频率。",
      "why_correct": "选项 B 是最佳选择。将文件存储在 S3 Glacier Deep Archive 中可以最大限度地降低长期存储成本，并且可以使用 S3 生命周期规则在一个月后自动迁移文件。",
      "why_wrong": "选项 A 使用 S3 智能分层，适用于访问模式不确定的情况，而不是长期归档。选项 C 和 D 虽然降低了成本，但存储成本仍高于 Glacier Deep Archive，并且不提供最经济的长期存储方案。"
    },
    "related_terms": [
      "S3",
      "S3 智能分层",
      "S3 Glacier Deep Archive",
      "S3 标准",
      "S3-IA",
      "S3 单区不经常访问 (S3-IA)"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 24,
    "topic": "",
    "question_cn": "一家公司在最近的账单中注意到亚马逊EC2成本的增加。计费团队注意到一些EC2实例中不需要的实例类型垂直缩放。解决方案架构师需要创建一个图表，比较过去两个月的EC2成本，并进行深入分析以确定垂直缩放的根本原因。解决方案架构师应该如何生成具有最少操作开销的信息？",
    "options_cn": {
      "A": "使用AWS预算创建一个预算报告，并根据实例类型比较EC2成本。",
      "B": "使用成本资源管理器的粒度过滤功能，根据实例类型对EC2成本进行深入分析。",
      "C": "使用来自账单和成本管理仪表板的图表来比较基于过去两个月的实例类型的EC2成本。",
      "D": "使用成本和使用报告创建一个报表，并将其发送到一个亚马逊S3桶。以亚马逊QuickSight为源，使用亚马逊QuickSight生成基于实例类型的交互图。"
    },
    "vote_percentage": "64%",
    "tags": [
      "Cost Explorer",
      "Billing and Cost Management"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是成本资源管理器提供了更细粒度的过滤和分析功能，可以方便地根据实例类型进行深入分析。",
      "why_correct": "B选项使用成本资源管理器(Cost Explorer)可以提供粒度更细的过滤功能，可以根据实例类型对EC2成本进行深入分析，帮助确定垂直缩放的根本原因，并减少操作开销。",
      "why_wrong": "A选项使用了预算，只能用于成本控制，无法提供深入分析。C选项使用账单和成本管理仪表板，虽然可以查看成本，但分析功能不如成本资源管理器。D选项增加了QuickSight，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "AWS 预算",
      "成本资源管理器",
      "账单和成本管理仪表板",
      "S3",
      "QuickSight"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 25,
    "topic": "",
    "question_cn": "一家公司正在设计一个应用程序。该应用程序使用一个 Lambda 函数通过 Amazon API Gateway 接收信息并将信息存储在 Amazon Aurora 后端的 SQL 数据库中。在概念验证阶段，公司不得不大幅增加 Lambda 配额以处理公司需要载入数据库的大量数据。解决方案架构师必须推荐新的设计，以提高可伸缩性并将配置工作减到最小。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将 Lambda 函数代码重构为在 Amazon EC2 实例中运行的 Apache Tomcat 代码。使用本地数据库连接 (JDBC) 驱动程序连接数据库。",
      "B": "将平台从 Aurora 改为 Amazon DynamoDB，提供 DynamoDB Accelerator (DAX) 集群。使用 DAX 客户端 API 指向 DAX 集群中的现有 DynamoDB 调用。",
      "C": "设置两个 Lambda 函数。配置一个函数接收信息。配置另一个函数将信息加载到数据库中。通过使用 Amazon SNS 来集成 Lambda 函数。",
      "D": "设置两个 Lambda 函数。配置一个函数接收信息。配置另一个函数将信息加载到数据库中。通过使用 Amazon SQS (Simple Queue Service) 队列来集成 Lambda 函数。"
    },
    "vote_percentage": "99%",
    "tags": [
      "Lambda",
      "SQS",
      "API Gateway",
      "Aurora"
    ],
    "explanation": {
      "analysis": "该题考察如何优化 Lambda 函数与数据库交互的架构，以提高可扩展性和减少配置工作。",
      "why_correct": "选项 D 提供了最佳解决方案。使用 SQS 队列，将 API Gateway 接收的消息放入队列，然后配置一个 Lambda 函数从队列中读取消息并存储到 Aurora 数据库中。第二个 Lambda 函数从队列中读取数据并写入数据库，增加了并发处理能力，提高了系统的可伸缩性。",
      "why_wrong": "选项 A 降低了可伸缩性，并引入了 EC2 管理开销。选项 B 建议更换 DynamoDB，这可能涉及到架构的重大改变，且不一定适用于所有数据库需求。选项 C 使用 SNS，不适合处理大量数据，因为 SNS 主要用于消息发布和订阅。"
    },
    "related_terms": [
      "Lambda",
      "API Gateway",
      "Aurora",
      "EC2",
      "DynamoDB",
      "DAX",
      "SNS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 26,
    "topic": "",
    "question_cn": "一家公司需要审查其 AWS 部署，以确保其 Amazon S3 存储桶没有未经授权的配置更改。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "打开 Amazon CloudTrail 并配置适当的规则。",
      "B": "打开 AWS Trusted Advisor 并配置适当的检查。",
      "C": "打开 Amazon Inspector 并配置适当的评估模板。",
      "D": "打开 Amazon S3 服务器访问日志。配置 Amazon EventBridge 事件。"
    },
    "vote_percentage": "98%",
    "tags": [
      "CloudTrail",
      "S3"
    ],
    "explanation": {
      "analysis": "该题考察如何审计 S3 存储桶的配置更改，并确保安全性。",
      "why_correct": "选项 A 是最佳实践。使用 CloudTrail 记录所有对 S3 存储桶的 API 调用，包括配置更改。配置 CloudTrail 规则可以监控特定事件，如存储桶策略更改，并触发警报。",
      "why_wrong": "选项 B 的 Trusted Advisor 只能提供总体配置建议，无法具体监控配置更改。选项 C 的 Inspector 主要用于漏洞扫描。选项 D 只记录访问日志，不能完全捕捉配置更改。"
    },
    "related_terms": [
      "S3",
      "CloudTrail",
      "AWS Trusted Advisor",
      "Amazon Inspector",
      "S3 服务器访问日志",
      "EventBridge"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 27,
    "topic": "",
    "question_cn": "一家公司正在推出一个新的应用程序，并将在亚马逊的云表仪表板上显示应用程序指标。公司的产品经理需要定期访问仪表板。产品经理没有AWS帐户。解决方案架构师必须遵循最小权限原则提供对产品管理器的访问。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "共享 CloudWatch 控制台的仪表板。输入产品经理的电子邮件地址完成共享步骤。为仪表板提供与产品经理的共享链接。",
      "B": "为产品经理创建一个IAM用户。向用户附加云监视器可访问的托管策略。与产品经理共享新的登录凭证。与产品经理共享正确仪表板的浏览器URL。",
      "C": "为公司员工创建一个IAM用户。向用户附加电视访问IAM托管策略。与产品经理共享新的登录凭证。请产品经理导航到CloudWatch控制台并在仪表板部分按名称定位仪表板。",
      "D": "在公共子网中部署堡垒服务器。当产品经理要求访问仪表板时，启动服务器并共享RDP凭证。在服务器上确保浏览器配置为打开仪表板URL，其中含有缓存的凭据，这些凭据具有查看仪表板的适当权限。"
    },
    "vote_percentage": "74%",
    "tags": [
      "CloudWatch",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用CloudWatch仪表板共享功能，可以直接与产品经理共享仪表板链接，无需创建IAM用户和管理凭据，操作简单，符合最小权限原则。",
      "why_correct": "A选项通过CloudWatch的仪表板共享功能，可以方便地将仪表板共享给产品经理，无需创建IAM用户和管理凭据。只需要输入产品经理的电子邮件地址，生成一个共享链接，符合最小权限原则，降低了操作复杂度。",
      "why_wrong": "B选项创建IAM用户并附加策略，虽然可以实现访问，但增加了复杂性。C选项同样增加了复杂性。D选项使用堡垒机，操作复杂且不安全。"
    },
    "related_terms": [
      "CloudWatch",
      "IAM",
      "RDP",
      "CloudWatch控制台",
      "浏览器URL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 28,
    "topic": "",
    "question_cn": "一家公司正在将应用程序迁移到AWS。这些应用程序部署在不同的帐户中。该公司通过使用AWS SSO集中管理帐户。公司的安全团队需要一个单一的登录(SSO)解决方案在公司的所有帐户。公司必须继续管理其内部自管理的微软活动目录中的用户和群体。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "允许从AWS SSO控制台上进行单点登录。创建一个单向森林信任或单向域信任，通过为微软活动目录使用目录服务将公司的自行管理的微软活动目录与AWS SSO连接起来。",
      "B": "允许从AWS SSO控制台上进行单点登录。创建一个双向森林信任，通过使用目录服务连接公司的自动管理的微软AWS SSO活动目录和微软活动目录。",
      "C": "使用AWS IAM目录服务。与公司自行管理的微软活动目录建立双向信任关系。",
      "D": "在现场部署身份提供者。从AWS SSO控制台上启用单点登录。"
    },
    "vote_percentage": "78%",
    "tags": [
      "AWS SSO",
      "Active Directory"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是需要与内部 AD 集成，双向森林信任是最优选择。",
      "why_correct": "B选项通过使用双向森林信任，连接公司的自动管理的微软AWS SSO活动目录和微软活动目录，允许用户使用其现有的 Active Directory 凭据登录AWS SSO，并访问所有帐户和应用程序，同时保持对用户和群体的集中管理，从而简化了管理流程。",
      "why_wrong": "A选项单向信任不如双向信任灵活。C选项使用了IAM目录服务，不如SSO方便。D选项部署现场身份提供者，增加了复杂性。"
    },
    "related_terms": [
      "AWS SSO",
      "微软活动目录",
      "目录服务",
      "AWS IAM 目录服务",
      "SSO"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 29,
    "topic": "",
    "question_cn": "一家公司提供使用UDP连接的网络协议语音服务。该服务包括在自动缩放组中运行的亚马逊EC2实例。该公司的部署跨越多个AWS区域。该公司需要为用户提供最低延迟时间的路径。该公司还需要在不同地区之间进行自动故障转移。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "部署一个网络负载均衡器(NLB)和相关目标群体。将目标组与自动缩放组联系起来。将NLB作为每个区域的全球加速器终点。",
      "B": "部署一个应用负载均衡器(ALB)和相关的目标组。将目标组与自动缩放组联系起来。在每个区域使用ALB作为全球加速器端点。",
      "C": "部署一个网络负载均衡器(NLB)和相关目标群体。将目标组与自动缩放组联系起来。创建亚马逊Route 53延迟记录，指出每个NLB的别名。创建一个使用延迟记录作为起源的亚马逊CloudFront分布。",
      "D": "部署一个应用负载均衡器(ALB)和相关的目标组。将目标组与自动缩放组联系起来。创建一个亚马逊Route 53加权记录(A)，指出每个ALB的别名。部署一个亚马逊CloudFront分布，使用加权记录作为起源。"
    },
    "vote_percentage": "78%",
    "tags": [
      "Global Accelerator",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用 Global Accelerator 和 NLB 结合，可以提供更优的性能和故障转移能力。",
      "why_correct": "A选项使用网络负载均衡器（NLB）和AWS全球加速器。NLB提供低延迟的UDP流量转发。全球加速器可以智能地将用户流量路由到最近的区域的NLB，提供最低的延迟。 结合自动缩放组，确保了可用性和弹性。当一个区域出现问题时，全球加速器可以自动将流量路由到其他区域，从而实现自动故障转移。",
      "why_wrong": "B选项应用负载均衡器(ALB) 不适用于UDP。C选项使用CloudFront和延迟记录, 相对复杂，且不如全球加速器。D选项使用CloudFront和加权记录，同样相对复杂，且不如全球加速器。"
    },
    "related_terms": [
      "UDP",
      "EC2",
      "NLB",
      "ALB",
      "Route 53",
      "CloudFront"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 30,
    "topic": "",
    "question_cn": "一个开发团队每月对其通用 RDS MySQL 数据库实例进行资源密集型测试，并提供性能洞察力。测试每月持续 48 小时，是使用数据库的唯一过程。数据库团队希望降低运行测试的成本，同时又不减少 RDS 实例的计算和内存属性。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "在测试完成后停止数据库实例。必要时重新启动 RDS 实例。",
      "B": "在测试完成时，使用具有 RDS 实例的自动缩放策略自动缩放。",
      "C": "在测试完成后创建快照。在需要时终止 RDS 实例并恢复快照。",
      "D": "在测试完成时将 RDS 实例修改为低容量实例。必要时再次修改 RDS 实例。"
    },
    "vote_percentage": "76%",
    "tags": [
      "RDS",
      "Snapshots",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "该题考察如何优化 RDS MySQL 数据库测试的成本，同时保留其性能。",
      "why_correct": "选项 C 是最佳解决方案。在测试完成后创建快照，然后终止 RDS 实例，可以停止付费。当需要测试时，可以从快照恢复实例。这样可以最大限度地降低成本，仅在测试期间才运行实例。",
      "why_wrong": "选项 A 停止实例，虽然降低了成本，但是会产生重新启动的时间开销。选项 B 自动缩放无法在 48 小时后关闭 RDS 实例，反而会带来额外成本。选项 D 改变实例类型，会降低性能，不满足题目需求。"
    },
    "related_terms": [
      "RDS MySQL",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 31,
    "topic": "",
    "question_cn": "一家拥有网络应用程序的公司希望确保所有 EC2 实例、RDS 数据库实例和 Redshift 集群都配置了标签。该公司希望尽量减少配置和操作此检查的工作量。解决方案架构师应该怎么做来实现这个目标？",
    "options_cn": {
      "A": "使用 AWS Config 配置规则来定义和检测未正确标记的资源。",
      "B": "使用成本资源管理器显示未正确标记的资源。手动标记这些资源。",
      "C": "使用 EC2 API 调用检查所有资源以进行适当的标签分配。定期在实例上运行代码。",
      "D": "使用 Lambda API 调用检查所有资源以进行适当的标签分配。通过 CloudWatch 安排一个函数来定期运行代码。"
    },
    "vote_percentage": "98%",
    "tags": [
      "AWS Tagging",
      "AWS Config"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 AWS Config 和标签来自动化资源合规性检查。",
      "why_correct": "AWS Config 规则可以自动检测未正确标记的资源，并根据定义的规则评估资源的合规性，从而减少手动检查的工作量。",
      "why_wrong": "选项 B 需要手动操作，不符合题意中减少工作量的要求。选项 C 和 D 需要编写代码并定期运行，增加了运维复杂性。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "Redshift",
      "AWS Config",
      "成本资源管理器",
      "EC2 API",
      "Lambda API",
      "CloudWatch"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 32,
    "topic": "",
    "question_cn": "一个开发团队需要托管一个网站，其他团队可以访问。网站内容包括 HTML、CSS、JavaScript 脚本和图像。哪种方法对网站的托管最具成本效益？",
    "options_cn": {
      "A": "将网站封装起来并在在线网站上进行托管。",
      "B": "创建一个 S3 存储桶并在那里托管网站。",
      "C": "在 EC2 实例上部署一个 Web 服务器来托管网站。",
      "D": "配置一个应用程序负载均衡器和一个使用表达式的 Lambda 目标。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Static Website Hosting",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "这道题考察了使用 S3 存储桶托管静态网站的成本效益。",
      "why_correct": "使用 S3 存储桶托管静态网站是最具成本效益的方案，因为 S3 提供了高可用性和可扩展性，并且按存储和数据传输付费。",
      "why_wrong": "选项 A 依赖于第三方服务，成本不可控。选项 C 涉及 EC2 实例，需要额外的维护和管理成本。选项 D 涉及 Lambda 和 ALB，增加了复杂性和成本，不适用于简单的静态网站托管。"
    },
    "related_terms": [
      "S3",
      "EC2",
      "ALB",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 33,
    "topic": "",
    "question_cn": "一家公司运行一个在线市场 Web 应用程序。该应用程序在高峰时段为数十万用户提供服务。该公司需要一个可伸缩的、接近实时的解决方案，以便与其他几个内部应用程序共享数百万笔金融交易的细节。事务还需要处理，以便在存储在文档数据库中进行低延迟检索之前删除敏感数据。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "将交易数据存储到 DynamoDB 中。设置一个规则在写入时从每个事务中删除敏感数据。使用 DynamoDB Streams 与其他应用程序共享事务数据。",
      "B": "将交易数据流到 Amazon Kinesis Data Firehose 中，以便在 DynamoDB 和 S3 中存储数据。使用 Lambda 集成 Kinesis Data Firehose 以去除敏感数据。其他应用程序可以使用 S3 存储的数据。",
      "C": "将事务数据流到 Amazon Kinesis Data Streams 中。使用 Lambda 集成从每个事务中移除敏感数据，然后在 DynamoDB 中存储事务数据。其他应用程序可以消耗运行 Kinesis Data Streams 的事务数据。",
      "D": "将批处理的事务数据作为文件存储在 S3 中。在更新 S3 中的文件之前，使用 Lambda 处理每个文件并删除敏感数据。然后在 DynamoDB 中存储数据。其他应用程序可以使用存储在 S3 中的事务文件。"
    },
    "vote_percentage": "86%",
    "tags": [
      "Real-time Data Processing",
      "DynamoDB Streams",
      "Kinesis Data Streams"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 Kinesis Data Streams、Lambda 和 DynamoDB 来构建接近实时的交易数据处理管道。",
      "why_correct": "选项 C 使用 Kinesis Data Streams 实时接收数据，Lambda 移除敏感数据，最后将处理后的数据存储到 DynamoDB 中。Kinesis Data Streams 提供了接近实时的流处理能力，可以满足需求。同时DynamoDB Streams能提供事件信息给其他的应用程序消费。",
      "why_wrong": "选项 A 使用 DynamoDB Streams，无法满足实时处理需求。选项 B 虽然使用 Kinesis，但是最终存储在S3,查询延迟高。选项 D 批处理文件到 S3, 无法满足实时性需求，而且处理延迟高。"
    },
    "related_terms": [
      "DynamoDB",
      "DynamoDB Streams",
      "Kinesis Data Firehose",
      "S3",
      "Lambda",
      "Kinesis Data Streams"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 34,
    "topic": "",
    "question_cn": "一家公司将其多层应用程序放在 AWS 上。对于合规性、治理、审计和安全性，公司必须跟踪其 AWS 资源上的配置更改，并记录对这些 API 资源的调用的历史。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用 CloudTrail 配置更改和 CloudWatch API 调用记录。",
      "B": "使用 AWS CloudTrail 跟踪配置更改并使用 CloudTrail 记录 API 调用。",
      "C": "使用 AWS Config 跟踪配置更改并使用 CloudTrail 记录 API 调用。",
      "D": "使用 AWS Config 跟踪配置更改并使用 CloudWatch 记录 API 调用。"
    },
    "vote_percentage": "99%",
    "tags": [
      "AWS CloudTrail",
      "AWS Config",
      "Compliance"
    ],
    "explanation": {
      "analysis": "这道题考察了使用 CloudTrail 和 CloudWatch 来审计 API 调用和配置更改。",
      "why_correct": "选项 B 正确使用了 CloudTrail 来跟踪配置更改和记录 API 调用。CloudTrail 记录了账户中的 API 调用，提供了审计跟踪。",
      "why_wrong": "选项 A、C 和 D 都存在问题。A 使用 CloudWatch 记录 API 调用不正确。C 和 D 中使用 AWS Config 跟踪配置更改，但 API 调用的记录应该使用 CloudTrail。"
    },
    "related_terms": [
      "CloudTrail",
      "CloudWatch",
      "AWS Config",
      "API"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 35,
    "topic": "",
    "question_cn": "一家公司正准备在 AWS 云中推出面向公众的 Web 应用程序。该架构由 EC2 实例组成，在弹性负载均衡器 (ELB) 后面。DNS 和 DDoS 攻击使用第三方服务。该公司的解决方案架构师必须推荐一种解决方案，以检测和防范大规模 DDoS 攻击。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在账户上启用 AWS WAF。",
      "B": "允许 Amazon Inspector 在 EC2 实例上运行。",
      "C": "启用 AWS Shield 并将 Amazon Route 53 分配给它。",
      "D": "启动 AWS Shield 并将其分配给它。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DDoS Protection",
      "AWS Shield",
      "AWS WAF"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 AWS Shield 和 AWS WAF 来防御 DDoS 攻击。",
      "why_correct": "D项是正确的。AWS Shield 提供了针对 DDoS 攻击的基本和高级保护。启动 AWS Shield 可以有效防御 DDoS 攻击。",
      "why_wrong": "选项 A 启用 AWS WAF，AWS WAF 更多的是针对 Web 应用程序的特定攻击。选项 B 使用 Amazon Inspector，主要用于安全评估。选项 C 启用 AWS Shield 并将 Route 53 分配给它，是不完整的描述，缺少了必要的设置。"
    },
    "related_terms": [
      "EC2",
      "ELB",
      "Route 53",
      "AWS WAF",
      "Amazon Inspector",
      "AWS Shield"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 36,
    "topic": "",
    "question_cn": "一家公司正在建立一个应用程序在AWS Cloud上。该应用程序将在亚马逊S3桶数据存储在两个区域。公司必须使用密钥管理服务(AWS KMS)客户管理的密钥来加密存储在S3桶中的所有数据。两个桶中的数据必须用相同的KMS键加密和解密。数据和密钥必须存储在两个区域中的每个区域。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在每个区域创建一个S3桶。将S3桶配置为使用亚马逊托管加密密钥(SSE-S3)的服务器端加密。在桶中配置复制。",
      "B": "创建一个客户管理的多区域KMS键。在每个区域创建一个S3桶。在桶中配置复制。将应用程序配置为使用带有客户端加密的KMS键。",
      "C": "在每个区域创建一个客户管理的KMS键和一个S3桶。将S3桶配置为使用亚马逊托管加密密钥(SSE-S3)的服务器端加密。在桶中配置复制。",
      "D": "在每个区域创建一个客户管理的KMS键和一个S3桶。将S3桶配置为使用AWS KMS密钥(SSE-KMS)的服务器端加密。在桶中配置复制。"
    },
    "vote_percentage": "56%",
    "tags": [
      "KMS",
      "S3 Replication"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是使用 KMS 的多区域密钥，可以保证数据的加密密钥跨区域一致性，同时用客户端加密，减少了服务器端的配置。",
      "why_correct": "B选项创建一个客户管理的多区域KMS键，可以确保数据的加密密钥跨区域一致性。在每个区域创建S3桶，并配置复制，确保了数据在两个区域的存储。将应用程序配置为使用带有客户端加密的KMS键，可以控制加密过程，确保数据的安全。",
      "why_wrong": "A选项使用了SSE-S3，不能满足使用KMS的要求。C选项使用了SSE-S3，并且方案比较复杂。D选项使用了SSE-KMS，增加了复杂性，但仍然不如B选项直接。"
    },
    "related_terms": [
      "S3",
      "AWS KMS",
      "SSE-S3",
      "SSE-KMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 37,
    "topic": "",
    "question_cn": "最近，一家公司在其 AWS 账户中发布了各种新工作负载的 EC2 实例。公司需要创建一种策略来远程和安全地访问和管理这些实例。该公司需要实现一个可重复的流程，与本地 IT 服务一起工作并遵循精心设计的框架。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 EC2 串行控制台直接访问每个实例的终端接口进行管理。",
      "B": "将适当的 IAM 角色附加到每个现有实例和新实例。使用系统管理器会话管理器建立远程 SSH 会话。",
      "C": "创建一个管理 SSH 密钥对。将公钥加载到每个 EC2 实例中。在公共子网中部署一个堡垒主机为每个实例的管理提供一个隧道。",
      "D": "建立一个站点到站点的 VPN 连接。指示管理员使用他们的本地机器直接连接到实例，通过 SSH 使用 VPN 密钥跨隧道。"
    },
    "vote_percentage": "95%",
    "tags": [
      "EC2 Instance Management",
      "AWS Systems Manager",
      "IAM Roles"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 AWS Systems Manager (SSM) Session Manager 来安全地管理 EC2 实例。",
      "why_correct": "选项 B 是最佳的解决方案。使用 IAM 角色提供对实例的访问权限，然后使用 Systems Manager Session Manager (SSM Session Manager) 建立远程 SSH 会话。这提供了安全、无密钥、审计和可重复的访问。",
      "why_wrong": "选项 A 使用串行控制台，无法大规模部署。选项 C 需要管理密钥对和堡垒主机，增加了管理复杂性。选项 D 需要建立 VPN 连接，也增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "IAM",
      "系统管理器会话管理器",
      "SSH",
      "VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 38,
    "topic": "",
    "question_cn": "一家公司在 Amazon S3 上开设了一个静态网站，并且正在使用 Route 53 进行 DNS 解析。世界各地对该网站的需求正在增加。公司必须减少访问网站的用户的延迟时间。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "将包含该网站的 S3 存储桶复制到所有 AWS 区域。添加 Route 53 地理位置路由条目。",
      "B": "使用 Amazon CloudFront 提供加速器在美国和全球加速器。将提供的 IP 地址与 S3 存储桶联系起来。编辑路由条目指向加速器的 IP 地址。",
      "C": "在 S3 存储桶前添加一个 Amazon CloudFront 分配。编辑 Route 53 路由条目指向 CloudFront 分配。",
      "D": "在 S3 存储桶上启动 Transfer Acceleration。编辑 Route 53 路由条目指向新的端点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "S3 Website Hosting",
      "Latency Reduction"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 CloudFront 来降低静态网站的延迟。",
      "why_correct": "选项 C 是最佳的解决方案。在 S3 存储桶前添加一个 CloudFront 分配可以利用 CloudFront 的全球边缘站点缓存内容，从而减少用户的延迟。并更新Route 53的记录。",
      "why_wrong": "选项 A 复制 S3 存储桶会增加存储成本和数据同步的复杂性。选项 B 描述不够准确，并且IP地址容易变化，不方便管理。选项 D 仅适用于大文件上传，对整体网站的加速效果有限。"
    },
    "related_terms": [
      "S3",
      "Route 53",
      "CloudFront",
      "S3 Transfer Acceleration"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 39,
    "topic": "",
    "question_cn": "一家公司在其网站上维持一个可搜索的项目存储库。数据存储在一个亚马逊RDS mysql数据库表中，其中包含超过1000万行。该数据库有2个SSD通用存储器。每天有数以百万计的数据通过公司网站更新。该公司已经注意到一些插入操作需要10秒钟或更长时间。公司已确定数据库存储性能是问题所在。哪个解决方案解决了性能问题？",
    "options_cn": {
      "A": "将存储类型更改为提供的I/O性能(ISPSSSD)。",
      "B": "将db.m5.large实例更改为内存优化实例类。",
      "C": "将db.m5.large实例更改为可增加性能的实例类。",
      "D": "使用MySQL本地异步复制启用多AZ RDS读取副本。"
    },
    "vote_percentage": "95%",
    "tags": [
      "RDS",
      "Storage"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是数据库存储性能是问题所在，将存储类型更改为IOPS，能够有效提升性能。",
      "why_correct": "A选项将存储类型更改为Provisioned IOPS SSD可以显著提高数据库的I/O性能，解决数据库存储性能问题。Provisioned IOPS SSD提供了更高的IOPS性能，能够满足插入操作的需求。",
      "why_wrong": "B选项虽然可以使用内存优化实例，但是IOPS仍然是瓶颈。C选项比较笼统，无法直接解决问题。D选项使用读取副本，不能直接改善插入操作的性能。"
    },
    "related_terms": [
      "RDS mysql",
      "SSD",
      "RDS",
      "多AZ RDS读取副本"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 40,
    "topic": "",
    "question_cn": "一家公司拥有成千上万的边缘设备，它们每天共同生成大约 1TB 的状态警报。每一个警报的大小大约为 2KB。解决方案架构师需要实现一个解决方案来吸收和存储用于未来分析的警报。该公司希望有一个非常可行的解决方案。然而，该公司需要尽量减少成本，不希望管理额外的基础设施。此外，该公司希望保留 14 天的数据以供即时分析，并归档超过 14 天的数据。符合这些要求的最有效的业务解决方案是什么？",
    "options_cn": {
      "A": "创建一个 Amazon Kinesis Data Firehose 传递流以吸收警报。配置 Kinesis Data Firehose 流将警报传递到一个 Amazon S3 存储桶。建立一个 S3 生命周期配置，在 14 天后将数据转移到 Amazon Glacier。",
      "B": "在两个可用区启动 EC2 实例，并将它们放在弹性负载均衡器后面以吸收警报。在 EC2 实例上创建一个脚本，该脚本将在 S3 存储桶中存储警报。建立一个 S3 生命周期配置，在 14 天后将数据转移到 Amazon Glacier。",
      "C": "创建一个 Amazon Kinesis Data Firehose 传递流以吸收警报。将该 Kinesis Data Firehose 流配置为向 Amazon OpenSearch Service（Amazon Elasticsearch Service）集群发送警报。建立 Amazon OpenSearch Service（Amazon Elasticsearch Service）集群，每天进行手动快照并删除超过 14 天的集群数据。",
      "D": "创建一个 Amazon SQS 标准队列以吸收警报，并将消息保留期设置为 14 天。配置消费者来轮询队列，检查消息的时间，并根据需要分析消息数据。如果消息是 14 天前的，那么消费者应该将消息复制到一个 Amazon S3 存储桶中，并从队列中删除消息。"
    },
    "vote_percentage": "85%",
    "tags": [
      "Data Ingestion",
      "S3 Lifecycle",
      "Kinesis Data Firehose"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 Kinesis Data Firehose、S3 和 Glacier 来构建一个经济高效的数据摄取、存储和归档解决方案。",
      "why_correct": "选项 A 是最有效的解决方案。Kinesis Data Firehose 可以可靠地接收数据，并将数据发送到 S3 存储桶。S3 生命周期策略可以自动将数据转移到 Glacier 进行归档，满足了成本、可管理性和数据保留的需求。",
      "why_wrong": "选项 B 需要管理 EC2 实例，增加了复杂性和成本。选项 C 使用 OpenSearch Service，增加了成本和运营复杂性。选项 D 需要管理 SQS 队列，并自行编写消息处理逻辑，增加了复杂性。"
    },
    "related_terms": [
      "Kinesis Data Firehose",
      "S3",
      "Amazon Glacier",
      "EC2",
      "ALB",
      "Kinesis Data Streams"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 41,
    "topic": "",
    "question_cn": "一个公司的应用程序集成了多个软件即服务 (SaaS) 数据收集源。该公司运行 EC2 实例来接收数据并将数据上传到 S3 存储桶进行分析。接收和上传数据的相同 EC2 实例也会在上传完成后向用户发送通知。该公司已经注意到应用程序性能缓慢，希望尽可能提高性能。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个自动缩放组，使 EC2 实例可以展开。配置一个 S3 事件通知，以便在上传到 S3 存储桶完成时，将事件发送到 Amazon SNS 主题。",
      "B": "创建一个 Amazon AppFlow 流以便在每个 SaaS 源和 S3 存储桶之间传输数据。配置一个 S3 事件通知，以便在上传到 S3 存储桶完成时，将事件发送到 Amazon SNS 主题。",
      "C": "为每个 SaaS 源创建一个 Amazon EventBridge（Amazon CloudWatch Events）规则以发送输出数据。将 S3 存储桶配置为规则的目标。创建第二个 EventBridge (CloudWatch Events) 规则，以便在上传到 S3 存储桶完成时发送事件。配置一个 Amazon SNS 主题作为第二条规则的目标。",
      "D": "创建一个码头容器来代替 EC2 实例。在 Amazon Elastic Container Service 上运行容器化应用程序。当上传到 S3 存储桶完成时，将 Amazon CloudWatch 容器的见解配置为将事件发送到 Amazon SNS 主题。"
    },
    "vote_percentage": "68%",
    "tags": [
      "SaaS Integration",
      "Amazon AppFlow",
      "S3 Event Notifications"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 Amazon AppFlow 和 S3 事件通知来优化 SaaS 数据集成流程。",
      "why_correct": "选项 B 是最佳解决方案。使用 Amazon AppFlow 可以直接将数据从 SaaS 源传输到 S3 存储桶，无需 EC2 实例，从而减少了 EC2 实例的负担，提高了性能和降低了运营开销。此外，S3 事件通知触发 SNS 通知，在上传完成后通知用户。",
      "why_wrong": "选项 A 依赖于 EC2 实例，增加了复杂性，性能和可扩展性不如 AppFlow。选项 C 使用 EventBridge 配置，增加了复杂性和管理负担。选项 D 建议使用容器，并没有解决性能问题，而且增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "S3 Transfer Acceleration",
      "Amazon SNS",
      "Amazon AppFlow",
      "Amazon EventBridge",
      "CloudWatch Events",
      "SaaS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 42,
    "topic": "",
    "question_cn": "一个公司在一个 VPC 中运行一个在 EC2 实例上高度可用的图像处理应用程序。EC2 实例在多个可用区的多个子网中运行。EC2 实例之间没有通信。但是，EC2 实例从 S3 下载图像，并通过一个 NAT 网关将图像上传到 S3。该公司担心数据传输费用。公司避免区域数据传输费用的最具成本效益的方式是什么？",
    "options_cn": {
      "A": "在每个可用区启动 NAT 网关。",
      "B": "用 NAT 实例替换 NAT 网关。",
      "C": "为 Amazon S3 部署 VPC 网关端点。",
      "D": "提供一个专用主机来运行 EC2 实例。"
    },
    "vote_percentage": "99%",
    "tags": [
      "VPC Endpoint",
      "S3 Data Transfer",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 VPC 网关端点来避免 S3 的数据传输费用。",
      "why_correct": "选项 C 是最佳的解决方案。为 S3 部署 VPC 网关端点可以使 EC2 实例通过 VPC 内部的网络访问 S3，避免了使用 NAT 网关产生的区域数据传输费用。",
      "why_wrong": "选项 A 和 B 使用 NAT 网关或 NAT 实例，都会产生数据传输费用。选项 D 提供了专用主机，和降低数据传输费用无关。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "S3",
      "NAT 网关",
      "NAT 实例",
      "VPC 网关端点",
      "可用区",
      "区域数据传输费"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 43,
    "topic": "",
    "question_cn": "一家公司有一个内部应用程序，可以生成大量的实时数据支持到 Amazon S3。该应用程序已经增长，用户对互联网带宽限制有抱怨。解决方案架构师需要设计一个长期的解决方案，既能及时备份到 Amazon S3，又能对内部用户的互联网连接产生最小的影响。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "通过 VPC 网关端点建立 AWS VPN 连接并代理所有流量。",
      "B": "通过这个新的连接建立一个新的 Direct Connect 并直接备份流量。",
      "C": "每天订购 AWS Snowball 设备。将数据加载到 Snowball 设备上，并每天将设备返回到 AWS。",
      "D": "通过 AWS 管理控制台提交支持票证。要求从账户中删除 S3 服务限额。"
    },
    "vote_percentage": "99%",
    "tags": [
      "Data Backup",
      "Direct Connect",
      "Snowball"
    ],
    "explanation": {
      "analysis": "这道题考察了如何使用 Direct Connect 和 Snowball 来解决数据备份和网络带宽限制的问题。",
      "why_correct": "选项 B 是最佳的解决方案。通过 Direct Connect 建立一个专用的网络连接，可以极大地提高数据传输速度，并且不会占用内部用户的互联网带宽。",
      "why_wrong": "选项 A 通过 VPC 网关端点建立 VPN 连接，虽然安全，但仍然会占用互联网带宽。选项 C 使用 Snowball，虽然可以解决带宽问题，但是传输数据时间比较长，不适合实时备份。选项 D 只是要求增加服务限额，没有解决根本问题。"
    },
    "related_terms": [
      "VPC",
      "S3",
      "AWS VPN",
      "Direct Connect",
      "Snowball",
      "VPC 网关端点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 44,
    "topic": "",
    "question_cn": "一家公司有一个包含关键数据的亚马逊S3桶。公司必须保护数据不被意外删除。 解决方案架构师应该采取哪些步骤来满足这些需求 选二。",
    "options_cn": {
      "A": "在S3桶上启用版本控制。",
      "B": "在S3桶上启用MFA删除。",
      "C": "在S3桶上创建桶策略。",
      "D": "在S3桶上启用默认加密。",
      "E": "为S3桶中的对象创建一个生命周期策略。"
    },
    "vote_percentage": "98%",
    "tags": [
      "S3 Versioning",
      "S3 Bucket Policy"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BD，但社区共识(投票最高)为AB。社区倾向AB的原因是，AB是防止数据意外删除的关键措施，包括版本控制和MFA删除，而官方答案强调加密和桶策略。",
      "why_correct": "启用S3版本控制允许恢复意外删除或覆盖的对象。启用MFA删除需要多因素身份验证才能删除S3桶中的对象，增加了额外的安全层。 （本题为多选题，正确项为：A、B，需全部选对才得分。）",
      "why_wrong": "启用默认加密可以保护静态数据，但并不能防止意外删除。创建桶策略用于控制对桶的访问权限，不能直接防止数据被删除。生命周期策略用于管理对象的存储类，例如将对象移动到Glacier，但这也不是直接防止删除。"
    },
    "related_terms": [
      "S3",
      "版本控制",
      "MFA 删除",
      "桶策略",
      "默认加密",
      "生命周期策略"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 45,
    "topic": "",
    "question_cn": "一家公司有一个数据摄取工作流，包括：* Amazon SNS 主题用于新数据交付的通知；* AWS Lambda 函数处理数据和记录元数据。该公司观察到，由于网络连接问题，摄取工作流偶尔会失败。当出现这样的故障时，除非公司手动重新运行作业，否则 Lambda 函数不会吸收相应的数据。解决方案架构师应该采取哪些行动组合以确保未来的 Lambda 函数吸收所有数据？（选择两个。）",
    "options_cn": {
      "A": "在多个可用区中部署 Lambda 函数。",
      "B": "创建一个 Amazon SQS 队列并将其订阅到 SNS 主题。",
      "C": "增加分配给 Lambda 函数的 CPU 和内存。",
      "D": "增加为 Lambda 函数提供的吞吐量。",
      "E": "修改 Lambda 函数，从 Amazon SQS 队列读取。"
    },
    "vote_percentage": "98%",
    "tags": [
      "Lambda",
      "SQS",
      "SNS"
    ],
    "explanation": {
      "analysis": "这道题考察了如何通过 SQS 和重试机制来保证 Lambda 函数的数据摄取。",
      "why_correct": "选项 B 和 E 是正确的选择。创建一个 SQS 队列并将 SNS 主题订阅到该队列，可以作为 Lambda 函数和 SNS 之间的缓冲，当 Lambda 函数处理失败时，消息会保留在 SQS 队列中，等待 Lambda 函数再次处理。修改 Lambda 函数，从 SQS 队列读取消息，可以实现重试机制。",
      "why_wrong": "选项 A 在多个可用区中部署 Lambda 函数可以提高可用性，但不能解决数据丢失的问题。选项 C 和 D 增加 Lambda 函数的资源或吞吐量，不能解决由于网络连接问题导致的数据丢失的问题。"
    },
    "related_terms": [
      "SNS",
      "AWS Lambda",
      "可用区",
      "SQS",
      "CPU",
      "吞吐量"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 46,
    "topic": "",
    "question_cn": "一家公司通过 SFTP 上传交易数据，并处理和分析数据以生成新的营销服务。最近，该公司发现一些商店上传了包含个人识别信息 (PII) 的文件，这些信息本不应该包括在内。该公司希望在 PII 再次被共享时提醒管理员，并希望自动化补救。解决方案架构师应该如何用最小的开发工作量来满足这些需求？",
    "options_cn": {
      "A": "使用亚马逊 S3 存储桶作为安全传输点。使用 Amazon Inspector 扫描存储桶中的对象。如果对象包含 PII，则触发生命周期策略以删除包含 PII 的对象。",
      "B": "使用亚马逊 S3 存储桶作为安全传输点。使用 Amazon Macie 扫描存储桶中的对象。如果对象包含 PII，则使用 Amazon SNS 触发向管理员发出的通知以删除包含 PII 的对象。",
      "C": "实现一个自定义扫描算法在 Lambda 函数中。当对象加载到存储桶中时触发函数。如果对象包含 PII，则使用 Amazon SNS 触发向管理员发出的通知以删除包含 PII 的对象。",
      "D": "开发自定义扫描算法在 Lambda 函数中。当对象加载到存储桶中时触发函数。如果对象包含 PII，则使用 Amazon SES 服务向管理员发送通知并触发生命周期策略以删除包含 PII 的对象。"
    },
    "vote_percentage": "60%",
    "tags": [
      "S3",
      "Amazon Macie"
    ],
    "explanation": {
      "analysis": "考察如何使用 Amazon Macie 检测 S3 存储桶中的 PII 数据并采取相应的处理措施。",
      "why_correct": "选项 B 使用 Amazon Macie 扫描 S3 存储桶中的对象，检测到 PII 后，通过 SNS 通知管理员，并采取删除措施，符合题意。",
      "why_wrong": "选项 A 使用 Amazon Inspector，主要用于安全评估，不直接用于检测 PII。选项 C/D 涉及自定义 Lambda 函数扫描，开发量较大，不如使用 Amazon Macie 方便。"
    },
    "related_terms": [
      "SFTP",
      "PII",
      "S3",
      "Amazon Inspector",
      "生命周期策略",
      "Amazon Macie",
      "Amazon SNS",
      "Lambda",
      "Amazon SES"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 47,
    "topic": "",
    "question_cn": "一家公司需要保证 Amazon EC2 的产能在一个特定的可用区，持续一周时间，用于即将举行的活动。公司应如何保证 EC2 的产能？",
    "options_cn": {
      "A": "购买指定区域所需的保留实例。",
      "B": "创建按需容量预留，预留指定区域所需的容量。",
      "C": "购买指定区域和三个可用区所需的保留实例。",
      "D": "开发创建按需容量预留，预留指定区域和三个可用区所需的容量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Capacity Reservation"
    ],
    "explanation": {
      "analysis": "考察如何预留 EC2 实例容量以保证在特定可用区的可用性。",
      "why_correct": "选项 D 使用按需容量预留可以预留指定区域和可用区的 EC2 实例容量，满足题意。",
      "why_wrong": "选项 A,C 购买保留实例，可以获得折扣，但不能保证容量。选项 B 只能预留指定区域的容量，不符合题目要求。"
    },
    "related_terms": [
      "Amazon EC2",
      "可用区",
      "保留实例",
      "按需容量预留"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 48,
    "topic": "",
    "question_cn": "一家公司的网站使用亚马逊EC2实例存储器为其商品目录。该公司希望确保目录是高度可用的并且目录存储在一个持久的位置。 解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "把目录移到亚马逊的弹性图卡西为雷迪斯。",
      "B": "部署一个更大的EC2实例和一个更大的实例存储。",
      "C": "将目录从实例商店移到亚马逊S3冰川深度档案库。",
      "D": "将目录移动到亚马逊弹性文件系统(EFS) 亚马逊文件系统。"
    },
    "vote_percentage": "92%",
    "tags": [
      "EFS",
      "EC2 Instance Store"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是EFS提供高可用性和持久的共享文件存储，更适合商品目录的需求。",
      "why_correct": "将目录移动到Amazon EFS提供了高度可用性和持久性，因为EFS是专门为持久性文件存储而设计的。 EFS允许从多个EC2实例同时访问数据，满足了高可用性的要求。",
      "why_wrong": "将目录移动到Amazon ElastiCache for Redis 用于缓存，不是一个持久存储方案，不适合存储商品目录。使用更大的EC2实例和实例存储，实例存储是非持久性的，不满足持久性需求。将目录移动到Amazon S3 Glacier Deep Archive不适合经常访问的商品目录，因为访问延迟较高。"
    },
    "related_terms": [
      "EC2",
      "EFS",
      "S3",
      "弹性图卡西",
      "实例存储",
      "Glacier",
      "EFS",
      "可用性",
      "弹性文件系统",
      "实例商店"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 49,
    "topic": "",
    "question_cn": "一家公司每月存储呼叫记录文件。用户在呼叫后一年内可以随意访问文件但一年后用户很少访问文件。该公司希望通过让用户能够尽快查询和检索不到1岁的文件来优化其解决方案。延迟检索旧文件是可以接受的。 哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "在亚马逊S3中存储带有标签的个人文件在亚马逊Glacier即时检索。查询标签从Glacier即时检索检索文件。",
      "B": "在亚马逊S3标准存储中存储单个文件。使用生命周期策略将文件转移到 Glacier一年后的灵活检索。通过使用Amazon Athena来查询和检索S3中的文件。使用 Glacier Select查询并检索Glacier中的文件。",
      "C": "在亚马逊S3标准存储中存储带有标记的单个文件。存储亚马逊标准存储中每个存档的搜索元数据。使用生命周期策略将S3文件转移到Glacier一年后的即时检索。通过搜索亚马逊的元数据来查询和检索文件。",
      "D": "在亚马逊S3标准存储中存储单个文件。使用生命周期策略将文件在一年后转移到Glacier Deep Archive。在亚马逊RDS中存储搜索元数据。查询来自亚马逊S3的文件。从Glacier Deep Archive中检索文件。"
    },
    "vote_percentage": "69%",
    "tags": [
      "S3 Lifecycle Policies",
      "Amazon Athena"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，B利用S3生命周期策略将数据分层存储到Glacier Flexible Retrieval，并使用Athena进行查询，满足了成本效益和检索延迟的要求。",
      "why_correct": "选项B在Amazon S3标准存储中存储文件，然后使用生命周期策略将文件迁移到Glacier Flexible Retrieval，这样既满足了频繁访问的需求，也满足了成本优化。使用Athena查询S3中的文件和 Glacier中的文件，提供了灵活的查询能力。Glacier Flexible Retrieval提供了较低的检索延迟。",
      "why_wrong": "选项A使用Glacier Instant Retrieval，虽然检索速度快，但成本较高，不符合优化成本的要求。选项C在Standard存储中存储搜索元数据，这种方式冗余且低效。选项D将文件迁移到Glacier Deep Archive，检索延迟过高，不满足尽快查询的需求。"
    },
    "related_terms": [
      "S3",
      "Glacier",
      "Amazon Athena",
      "生命周期策略",
      "即时检索",
      "Deep Archive",
      "RDS",
      "标准存储"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 50,
    "topic": "",
    "question_cn": "一家公司有一个生产工作负载运行在 1,000 个 Amazon EC2 Linux 实例上。工作负载由第三方软件提供。该公司需要尽快在所有实例上修补第三方软件以补救一个关键的安全漏洞。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个 Lambda 函数将补丁应用于所有 EC2 实例。",
      "B": "配置 AWS Systems Manager 补丁管理器将补丁应用于所有 EC2 实例。",
      "C": "安排一个 Systems Manager 维护窗口将补丁应用于所有 EC2 实例。",
      "D": "使用 Systems Manager 运行命令来运行将补丁应用到所有 EC2 实例的自定义命令。"
    },
    "vote_percentage": "73%",
    "tags": [
      "AWS Systems Manager",
      "EC2 Patching"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS Systems Manager 在 EC2 实例上进行快速的补丁部署。",
      "why_correct": "选项 D 使用 Systems Manager 的 Run Command，可以并行在多个 EC2 实例上执行自定义命令，从而快速部署补丁。",
      "why_wrong": "选项 A 使用 Lambda 函数，效率不如 Systems Manager。选项 B 虽然可以使用 Systems Manager Patch Manager，但配置和部署相对复杂。选项 C 维护窗口适用于计划性的维护，不适用于紧急情况。"
    },
    "related_terms": [
      "EC2",
      "Lambda",
      "AWS Systems Manager",
      "补丁管理器",
      "维护窗口"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 51,
    "topic": "",
    "question_cn": "一家公司正在开发一个应用程序提供订单运输统计数据以便通过REST API进行检索。该公司希望提取运输统计数据将数据组织成易于阅读的HTML格式并每天早上同时将报告发送到几个电子邮件地址。 解决方案架构师应该采取哪些步骤来满足这些需求 选二。",
    "options_cn": {
      "A": "配置应用程序将数据发送到亚马逊运动数据消防软管。",
      "B": "使用亚马逊简单电子邮件服务(SES) 格式化数据和发送报告电子邮件。",
      "C": "创建一个亚马逊事件列表事件，此事件调用一个胶水作业来查询应用程序的数据。",
      "D": "创建一个亚马逊云表事件，计划的事件调用一个Lambda函数来查询应用程序的数据。",
      "E": "将应用程序数据存储在亚马逊S3中。创建一个亚马逊简单通知服务(SNS)主题作为事件的目的地通过电子邮件发送报告。"
    },
    "vote_percentage": "69%",
    "tags": [
      "Amazon CloudWatch Events",
      "AWS Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为DE，但社区共识(投票最高)为BD。社区倾向BD的原因是，BD涵盖了定时任务，数据处理和发送邮件这三个核心需求。使用Lambda函数处理数据，调用SES发送邮件是更优解。",
      "why_correct": "选项B使用Amazon SES发送电子邮件，满足了发送报告的需求。选项D使用CloudWatch Events触发Lambda函数，Lambda函数可以查询数据，格式化数据并使用SES发送报告。这两个选项共同满足了数据检索、处理和发送邮件的需求。",
      "why_wrong": "选项A将数据发送到Amazon Kinesis Data Firehose，这无法处理报告格式化和邮件发送的需求。选项C使用Glue作业处理数据，过于复杂，不适用于简单的报告生成。选项E将数据存储在S3中，但没有数据处理和格式化步骤，无法完成邮件发送报告的要求。"
    },
    "related_terms": [
      "REST API",
      "Amazon Kinesis Data Firehose",
      "SES",
      "Amazon EventBridge",
      "AWS Glue",
      "Lambda",
      "CloudWatch Events",
      "S3",
      "SNS"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 52,
    "topic": "",
    "question_cn": "一家公司想将其内部应用程序迁移到 AWS。应用程序生成的输出文件的大小从 10 GB 到数百兆字节不等。应用程序数据必须存储在标准的文件系统结构中。该公司希望有一个自动伸缩的解决方案。它非常可用，需要最小的操作费用。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将应用程序迁移到 Amazon ECS (Elastic Container Service) 上，作为容器运行。使用 Amazon S3 存储。",
      "B": "迁移应用程序以容器的形式运行在 Amazon EKS (Elastic Kubernetes Service) 上。使用 Amazon EBS (Elastic Block Storage) 存储。",
      "C": "在一个多 AZ (可用区) 的 Auto Scaling 组中迁移应用程序到 Amazon EC2 实例。使用 Amazon EFS (Elastic File System) 存储。",
      "D": "在一个多 AZ 的 Auto Scaling 组中迁移应用程序到 Amazon EC2 实例。使用 Amazon EBS (Elastic Block Storage) 存储。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "Amazon EFS",
      "Containerization"
    ],
    "explanation": {
      "analysis": "考察如何将应用程序迁移到 AWS，满足自动伸缩，可用性，标准文件系统以及最小运维成本的要求。",
      "why_correct": "选项 C 在 EC2 上使用 EFS 满足需求。EC2 实例在 Auto Scaling Group 中，实现自动伸缩。EFS 提供标准文件系统，同时具备高可用性。EFS 的运维成本较低。",
      "why_wrong": "选项 A, B 使用 S3 或 EBS 不满足“必须存储在标准的文件系统结构中”的要求。EKS 的运维成本高于 ECS。选项 D EBS 的高可用性需要额外的配置。"
    },
    "related_terms": [
      "ECS",
      "S3",
      "EKS",
      "EBS",
      "Auto Scaling",
      "EC2",
      "EFS",
      "可用区"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 53,
    "topic": "",
    "question_cn": "一家公司需要将其会计记录存储在 Amazon S3 上。记录必须在一年内立即可查阅，然后归档 9 年。在整个 10 年期间，包括行政用户和根用户在内的任何人都无法删除记录。必须以最大弹性存储记录。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将记录保存在 Glacier 中整整 10 年。使用访问控制策略在 10 年内拒绝删除记录。",
      "B": "使用 S3 Intelligent-Tiering 存储记录。使用 IAM 策略拒绝删除记录。10 年后修改策略允许删除。",
      "C": "使用生命周期策略在一年后将记录从 Standard 转换为 Glacier Deep Archive。在合规模式下使用对象锁定 10 年。",
      "D": "使用生命周期策略将记录在一年后从 Standard 转换为 S3 不经常访问区域。在治理模式中使用对象锁定 10 年。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Object Lock",
      "S3 Lifecycle",
      "S3 Glacier Deep Archive"
    ],
    "explanation": {
      "analysis": "考察如何在 S3 上存储不可变的数据，并满足长时间的保留要求。",
      "why_correct": "选项 C 使用生命周期策略将记录转移到 Glacier Deep Archive，满足低成本归档需求。通过对象锁定（合规模式）实现不可删除性，符合审计要求。",
      "why_wrong": "选项 A 仅使用 Glacier，在一年内无法快速访问，不满足需求。选项 B 使用 S3 Intelligent-Tiering，虽然可以管理存储类，但不能实现数据的不可变性。选项 D 使用不经常访问区域，存储成本较高，治理模式下对象锁定的安全性不如合规模式。"
    },
    "related_terms": [
      "S3",
      "Glacier",
      "IAM",
      "Intelligent-Tiering",
      "Deep Archive",
      "对象锁定",
      "生命周期策略",
      "标准",
      "不经常访问"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 54,
    "topic": "",
    "question_cn": "一家公司运行多个 Windows 工作负载在 EC2 上。该公司的员工使用在两个 Amazon EC2 实例上的文件共享。文件共享同步它们之间的数据并维护副本。该公司希望有一个高可用性和持久的存储解决方案保存用户当前访问文件的方式。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将所有数据迁移到 Amazon S3。建立用户访问文件的 IAM 身份验证。",
      "B": "建立一个 Amazon 文件网关。在现有的 EC2 实例上安装文件网关。",
      "C": "将文件共享环境扩展到具有多 AZ 配置的 FSx for Windows File Server。将所有数据迁移到 FSx for Windows File Server。",
      "D": "将文件共享环境扩展到具有多 AZ 配置的 Amazon EFS。将所有数据迁移到 Amazon EFS。"
    },
    "vote_percentage": "98%",
    "tags": [
      "FSx for Windows File Server",
      "EFS"
    ],
    "explanation": {
      "analysis": "考察如何为 Windows 文件共享提供高可用性、持久的存储解决方案。",
      "why_correct": "选项 C 使用 FSx for Windows File Server，提供完全托管的 Windows 文件服务器，支持多 AZ 配置，可以提供高可用性和持久性，并与现有的 Windows 工作负载兼容。",
      "why_wrong": "选项 A 使用 S3，无法直接用作文件共享。选项 B 使用文件网关，可以访问 S3，但配置和运维比较复杂。选项 D 使用 EFS，虽然也是高可用，但无法直接支持 Windows 文件共享的特性，需要额外的配置工作。"
    },
    "related_terms": [
      "EC2",
      "Amazon S3",
      "IAM",
      "文件网关",
      "FSx for Windows File Server",
      "EFS",
      "多AZ",
      "FSx for Windows"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 55,
    "topic": "",
    "question_cn": "解决方案架构师正在开发一个包含多个子网的 VPC 架构。该架构将容纳使用 Amazon EC2 实例和 Amazon RDS 实例的应用程序。该体系结构由两个可用区中的六个子网组成。每个可用区包括公共子网、私有子网和专用数据库子网。只有在私有子网中运行的 EC2 实例才能访问 RDS 数据库。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个新的路由表，排除了公共子网络的 CIDR 块的路由。将路由表与数据库子网关联。",
      "B": "创建一个安全组，该安全组拒绝从分配给公共子网络中实例的安全组中输入流量。将安全组附加到 RDS 实例上。",
      "C": "创建一个安全组，该安全组允许从分配给私有子网中实例的安全组进入的流量。将安全组附加到 RDS 实例上。",
      "D": "在公共子网和私人子网之间创建一个新的窥探连接。在私有子网和数据库子网之间创建不同的窥探连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Group",
      "VPC",
      "Subnet"
    ],
    "explanation": {
      "analysis": "考察如何使用安全组控制 EC2 实例对 RDS 数据库的访问。",
      "why_correct": "选项 C 创建一个安全组，允许从私有子网中运行的 EC2 实例的安全组的入站流量，附加到 RDS 实例上。通过安全组来控制流量，满足安全访问需求。",
      "why_wrong": "选项 A 通过路由表控制流量，不如安全组灵活。选项 B 拒绝公共子网的流量，但没有明确允许私有子网的流量。选项 D 建立 VPC peering，过于复杂，不必要。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "RDS",
      "可用区",
      "公共子网",
      "私有子网",
      "数据库子网",
      "CIDR",
      "安全组"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 56,
    "topic": "",
    "question_cn": "一家公司在亚马逊Route 53中注册了域名。该公司使用亚马逊API网关在us-east-1区域作为其后端微服务的公共接口。第三方服务安全地使用HTTPS API。该公司希望设计其API网关网址与公司的域名和相应的证书以便第三方服务可以使用API。 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在API网关中创建阶段变量，名称为端点URL，值为公司域名，来覆盖默认的URL。将与公司域名相关的公共证书导入证书管理(ACM)器。",
      "B": "用公司域名创建Route 53 DNS记录。将别名记录指向区域API网关阶段端点。将与该公司域名相关的公共证书导入美国东1号地区的ACM(证书管理器)。",
      "C": "创建区域API网关端点。将API网关端点与公司域名联系起来。将与公司域名相关的公共证书导入同一区域的ACM(证书管理器)API。将证书附加到API网关端点上。将Route 53配置为将流量路由到API网关端点。",
      "D": "创建区域API网关端点。将API网关端点与公司域名联系起来。将与该公司域名相关的公共证书导入美国东1号地区的ACM(证书管理器)API。将证书附加到API网关上。用公司域名创建Route 53 DNS记录。指向公司域名的记录。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Amazon API Gateway",
      "Amazon Route 53"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，C提供了最直接、最完整的解决方案，将API网关与域名、证书关联，并配置Route 53进行流量路由。",
      "why_correct": "选项C 提供了最完整、最直接的解决方案，它将 API Gateway 域端点与公司域名关联，并将证书附加到 API Gateway 域端点上。 然后，它使用 Route 53 配置DNS 记录，以便将流量路由到API Gateway。",
      "why_wrong": "选项A没有正确配置自定义域名。选项B虽然配置了DNS记录，但是方式不正确且缺少关联证书和API Gateway。选项D的流程虽然包含了所有要素，但缺少关联性，流程略显混乱。"
    },
    "related_terms": [
      "Route 53",
      "API Gateway",
      "HTTPS",
      "ACM",
      "DNS",
      "API",
      "HTTPS API",
      "区域",
      "端点"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 57,
    "topic": "",
    "question_cn": "一家公司正在运行一个流行的社交媒体网站。该网站使用户能够上传图像与其他用户共享。公司希望确保图片不包含不适当的内容。公司需要一个最小化开发工作量的解决方案。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用 Amazon Comprehend 来检测不适当的内容。用人类评估来预测低自信。",
      "B": "使用 Amazon Rekognition 来检测不适当的内容。用人类评估来预测低自信。",
      "C": "使用 Amazon SageMaker 检测不当内容。用地面真相来标记低自信预测。",
      "D": "使用 AWS Fargate 部署自定义机器学习模型来检测不适当的内容。用地面真相来标记低自信预测。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Rekognition",
      "Content moderation"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS 服务检测图片中的不当内容，实现内容审核。",
      "why_correct": "选项 B 使用 Amazon Rekognition，它提供了图像内容审核功能，可以检测不适当的内容，减少开发工作量。",
      "why_wrong": "选项 A 使用 Amazon Comprehend，主要用于文本分析，不适用于图像。选项 C 使用 SageMaker，需要开发自定义模型，增加了工作量。选项 D 需要部署自定义模型，开发和运维成本高。"
    },
    "related_terms": [
      "Amazon Comprehend",
      "Amazon Rekognition",
      "Amazon SageMaker",
      "AWS Fargate",
      "机器学习"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 58,
    "topic": "",
    "question_cn": "公司希望在容器中运行其关键应用程序以满足可伸缩性和可用性的要求。公司更喜欢专注于关键应用的维护，该公司不希望负责提供和管理运行集装箱化工作量的基础设施。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用 Amazon EC2 实例并在实例上安装 Docker 程序。",
      "B": "在 Amazon EC2 工人节点上使用 Amazon ECS (Elastic Container Service)。",
      "C": "使用 Amazon ECS (Elastic Container Service) on AWS Fargate。",
      "D": "使用 Amazon EC2 实例从 Amazon ECS (Elastic Container Service) 优化 Amazon 机器映像。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon ECS",
      "AWS Fargate"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS 托管服务运行容器化的应用程序，避免基础设施管理。",
      "why_correct": "选项 C 使用 Fargate，完全托管容器服务，无需管理底层基础设施，符合题意。",
      "why_wrong": "选项 A 需要管理 EC2 实例。选项 B 需要管理 EC2 工人节点，不符合题意。选项 D 只是优化 AMI，不能满足避免基础设施管理的需求。"
    },
    "related_terms": [
      "Docker",
      "ECS",
      "EC2",
      "容器",
      "Fargate"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 59,
    "topic": "",
    "question_cn": "一家公司拥有多个全球网站和应用程序。该公司需要一个平台来分析每天超过 300 TB 的点击流数据。解决方案架构师应该做什么来传输和处理点击流数据？",
    "options_cn": {
      "A": "设计一个数据管道，将数据归档到一个 Amazon S3 存储桶，并运行一个 Amazon EMR (Elastic MapReduce) 集群数据生成分析。",
      "B": "创建一个 Amazon EC2 实例的自动缩放组以处理数据，并将其发送到 Amazon 数据湖，以便 Amazon Redshift 用于分析。",
      "C": "将数据缓存到 Amazon CloudFront。将数据存储在一个 Amazon S3 存储桶中。当一个对象添加到存储桶时。运行一个 Lambda 函数来处理用于分析的数据。",
      "D": "从 Amazon Kinesis Data Streams 收集数据。使用 Amazon Kinesis Data Firehose 传输数据到 Amazon 数据湖。加载 Amazon Redshift 数据进行分析。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Kinesis Data Streams",
      "Kinesis Data Firehose",
      "Redshift"
    ],
    "explanation": {
      "analysis": "考察如何处理大规模的点击流数据，并将其用于分析。",
      "why_correct": "选项 D 使用 Kinesis Data Streams 收集数据，Kinesis Data Firehose 将数据传输到数据湖，最终加载到 Redshift 进行分析，是一个完整的解决方案。",
      "why_wrong": "选项 A 使用 EMR，虽然可以处理大数据，但配置和运维比较复杂。选项 B 使用 EC2 处理数据，扩展性不如 Kinesis。选项 C 使用 CloudFront 和 Lambda，处理能力有限。"
    },
    "related_terms": [
      "点击流数据",
      "S3",
      "Amazon EMR",
      "EC2",
      "Auto Scaling",
      "Amazon Redshift",
      "Amazon CloudFront",
      "Lambda",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon 数据湖"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 60,
    "topic": "",
    "question_cn": "一家公司有一个网站在美国运行。该网站后面是一个应用程序负载均衡器 (ALB)，它被配置为单独处理 HTTP 和 HTTPS。该公司希望将所有 HTTP 请求转发到 HTTPS，以便请求将使用 HTTPS。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "更新 ALB 的网络 ACL，只接受 HTTPS 流量。",
      "B": "创建一个规则，用 HTTPS 替换 URL 中的 HTTP。",
      "C": "在 ALB 上创建一个侦听器规则，以便将 HTTP 流量重定向到 HTTPS。",
      "D": "用一个配置为使用服务器名称指示 (SNI) 的网络负载均衡器替换 ALB。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ALB",
      "HTTP to HTTPS redirect"
    ],
    "explanation": {
      "analysis": "考察如何配置 ALB，将 HTTP 流量重定向到 HTTPS。",
      "why_correct": "选项 C 在 ALB 上创建一个侦听器规则，将 HTTP 流量重定向到 HTTPS。这是 ALB 提供的标准功能。",
      "why_wrong": "选项 A 仅接受 HTTPS 流量，无法处理 HTTP 请求。选项 B 无法实现重定向。选项 D 使用 NLB，功能不如 ALB，且没有明确解决重定向问题。"
    },
    "related_terms": [
      "ALB",
      "HTTP",
      "HTTPS",
      "SNI",
      "网络负载均衡器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 61,
    "topic": "",
    "question_cn": "一家公司正在开发一个基于 Web 的两层应用程序。该公司的开发人员已经将该应用程序部署在一个直接连接到后端 Amazon RDS 数据库的 Amazon EC2 实例上。公司不得在应用程序中硬编码数据库凭证。该公司还必须实现一个解决方案以自动地定期轮换数据库凭证。使用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS Lambda 函数，在实例元数据中存储数据库凭据。使用 Amazon CloudWatch Events 规则运行一个预定的 Lambda 函数，该函数同时更新凭证和实例元数据。",
      "B": "在一个加密的 Amazon S3 存储桶中的配置文件中存储数据库凭据。使用 Amazon CloudWatch Events 规则来运行一个预定的 Lambda 函数，该函数同时更新配置文件中的凭证和凭证。使用版本控制以确保能够回到以前的值。",
      "C": "将数据库凭证作为一个秘密存储在 Amazon Secrets Manager 中。打开自动旋转的秘密。对 IAM 角色附加必要的权限以允许访问该秘密。",
      "D": "在 Amazon System Manager 参数存储中将数据库凭证作为加密参数存储。打开加密参数的自动旋转。附加对 IAM 角色的所需权限以授予对加密参数的访问权。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "RDS Credential Rotation"
    ],
    "explanation": {
      "analysis": "该题考察如何安全地存储和轮换数据库凭证，并降低操作开销。",
      "why_correct": "选项 C 使用 Secrets Manager，可以安全地存储凭据，并配置自动轮换。这符合题目的要求，而且 Secrets Manager 提供了管理秘密生命周期的功能。",
      "why_wrong": "选项 A 在实例元数据中存储凭据，这不够安全，因为实例元数据可以被访问。选项 B 将凭证存储在 S3 中，需要额外的代码来读取和使用凭证。选项 D 使用 Systems Manager 参数存储，不如 Secrets Manager 专为存储密钥设计。因此，C 是最佳选择。"
    },
    "related_terms": [
      "RDS",
      "EC2",
      "Lambda",
      "CloudWatch Events",
      "S3",
      "Secrets Manager",
      "IAM",
      "System Manager Parameter Store"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 62,
    "topic": "",
    "question_cn": "一家公司正在将一个新的公共网站应用程序部署到 Amazon。应用程序将在应用程序负载均衡器 (ALB) 后面运行。应用程序需要使用由外部证书机构 (CA) 颁发的 SSL/TLS 证书进行加密。证书必须在证书到期前每年轮换一次。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用 AWS Certificate Manager (ACM) 发布 SSL/TLS 证书。将证书应用于 ALB。使用托管更新功能自动旋转证书。",
      "B": "使用 AWS Certificate Manager (ACM) 发布 SSL/TLS 证书。从证书中导入密钥材料。将证书应用于 ALB。使用托管更新功能自动旋转证书。",
      "C": "使用 AWS Certificate Manager (ACM)  从根 CA 发出 SSL/TLS 证书。将证书应用于 ALB。使用托管更新功能自动旋转证书。",
      "D": "使用 AWS Certificate Manager (ACM)  导入 SSL/TLS 证书。将证书应用于 ALB。当证书即将到期时，请使用 Amazon Data Bridge (Amazon EventBridge)  发送通知。手动旋转证书。"
    },
    "vote_percentage": "95%",
    "tags": [
      "ACM",
      "SSL/TLS Certificate Rotation"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS 证书管理器 ACM 管理和轮换 SSL/TLS 证书。",
      "why_correct": "选项 D 描述了使用 ACM 导入由外部 CA 颁发的证书，并将证书应用于 ALB。ACM 可以自动轮换证书。当证书即将到期时，可以使用 EventBridge 发送通知，然后手动更新。",
      "why_wrong": "选项 A 只能使用 ACM 颁发的证书，而题目要求使用外部 CA 颁发的证书。选项 B 试图从证书中导入密钥材料，这通常是不必要的。选项 C 描述了使用 ACM 作为内部 CA 颁发证书，不符合题意。"
    },
    "related_terms": [
      "SSL/TLS",
      "AWS Certificate Manager (ACM)",
      "ALB",
      "Amazon Data Bridge (Amazon EventBridge)"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 63,
    "topic": "",
    "question_cn": "一家公司在其 AWS 上运行其基础设施，注册的文档管理应用程序的用户数为 70 万。该公司打算创造一种能大规模转换 PDF 文件。PDF 文件的平均大小为 5MB，图像文件平均大小为 50MB。公司需要存储原始文件和转换后的文件。解决方案架构师必须设计一个可扩展的解决方案以适应随着时间的推移快速增长的需求。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "将 PDF 文件上传到 Amazon S3 存储桶。配置一个 S3 放置事件以调用一个 Lambda 函数将文件转换为 JPG。将它们存储在 Amazon S3 上。",
      "B": "使用 Amazon S3  文件动态调用一个 Lambda 函数将 PDF 文件转换为 JPG。把它们放回 S3 中。",
      "C": "将 PDF 文件上传到一个弹性负载均衡器应用程序，包括 Amazon EC2 实例、Amazon EBS、Amazon S3 存储桶和一个自动缩放组。在 EC2 实例中使用一个程序将 PDF 文件转换为 JPG 格式。存储原始文件和 JPG 文件。",
      "D": "将 PDF 文件上传到一个弹性负载均衡器应用程序，包括 Amazon EC2 实例、Amazon EFS、Amazon S3 存储桶和一个自动缩放组。在 EC2 实例中使用一个程序将 PDF 文件转换为 JPG 格式。存储原始文件和 JPG 文件。"
    },
    "vote_percentage": "99%",
    "tags": [
      "S3",
      "Lambda",
      "File Processing"
    ],
    "explanation": {
      "analysis": "该题考察如何使用 S3、Lambda 和 S3 事件驱动的架构，对上传的文件进行处理和转换。",
      "why_correct": "选项 A 使用了 S3 存储桶，通过 S3 放置事件触发 Lambda 函数进行 PDF 转 JPG 转换，并将结果存储在 S3 中。这是一种无服务器架构，具有可扩展性和成本效益。",
      "why_wrong": "选项 B 描述了通过 S3 文件动态触发 Lambda，这种方法不够直接。选项 C 和 D 涉及 EC2 实例和 EBS/EFS，增加了运维复杂度和成本，不如无服务器的方案。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "EC2",
      "EBS",
      "Elastic Load Balancer",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 64,
    "topic": "",
    "question_cn": "一家公司有超过5TB的文件数据在Windows文件服务器运行在现场。用户和应用程序每天都与数据交互。该公司正在将其Windows系统的工作负载转移到AWS系统。随着该公司继续这一进程，该公司要求使用最小延迟和内部文件存储，该公司需要一个解决方案最大限度地减少操作开销，不需要对现有的文件访问模式进行重大更改。该公司使用一个VPN到现场的AWS连接连接到AWS。 解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "部署和配置亚马逊FSx for Windows文件服务器。将内部文件数据移动到FSx for Windows文件服务器的。将工作负载重新配置为使用FSx for Windows文件服务器。",
      "B": "在现场部署和配置一个亚马逊文件网关。将现场文件数据移动到文件网关。重新配置使用文件网关的内部工作负载和云工作负载。",
      "C": "在现场部署和配置一个亚马逊文件网关。将内部文件数据移到亚马逊S3。重新配置工作负载以直接使用亚马逊S3或文件网关。依工作量的位置而定。",
      "D": "部署和配置亚马逊FSx for Windows文件服务器。在现场部署和配置一个亚马逊文件网关。将现场文件数据移动到FSx for Windows文件网关。将云工作负载配置为使用FSx for Windows用于在AWS上的文件服务器。将现场工作负载配置为使用文件网关。"
    },
    "vote_percentage": "78%",
    "tags": [
      "FSx for Windows File Server",
      "AWS File Gateway"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，D提供了混合云解决方案，既利用了FSx for Windows满足云端存储需求，又使用文件网关为本地工作负载提供访问。",
      "why_correct": "选项D结合了FSx for Windows文件服务器和AWS 文件网关，满足了混合云环境的需求。FSx for Windows提供了云端的文件存储，而文件网关为本地工作负载提供了低延迟的访问。这种架构最大限度地减少了操作开销，并保留了现有的文件访问模式。",
      "why_wrong": "选项A仅适用于将所有数据迁移到AWS云端的情况。选项B没有将文件存储在云端，不符合迁移需求。选项C将文件存储在S3中，可能不满足低延迟的需求。"
    },
    "related_terms": [
      "Windows",
      "FSx for Windows File Server",
      "Amazon File Gateway",
      "VPN",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 65,
    "topic": "",
    "question_cn": "一家医院最近部署了一个 API，使用 Amazon API Gateway 和 Lambda。该医院使用 API Gateway 和 Lambda 来上传 PDF 格式和 JPEG 格式的报告。医院需要在报告中修改《保护健康法》以确定受保护的健康信息。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用现有的 Python 库从报表中提取文本并从提取的文本中识别 PHI。",
      "B": "使用 Amazon Textract 提取从报告中提取文本。使用 Amazon SageMaker 识别从提取的文本中的 PHI。",
      "C": "使用 Amazon Textract 提取从报告中提取文本。使用 Amazon Comprehend Medical 识别从提取的文本。",
      "D": "使用 Amazon Rekognition 从报告中提取文本。使用 Amazon Comprehend Medical 识别从提取的文本。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Textract",
      "Amazon Comprehend Medical",
      "PHI Detection"
    ],
    "explanation": {
      "analysis": "本题考察使用 AWS 服务从文档中提取文本并识别受保护的健康信息。",
      "why_correct": "选项 C 结合使用 Amazon Textract 从 PDF 和 JPEG 报告中提取文本，并使用 Amazon Comprehend Medical 识别受保护的健康信息（PHI）。这是最适合的解决方案，因为它使用了专门为医疗保健设计的服务，并减少了手动开发和维护的工作量。",
      "why_wrong": "选项 A 需要自定义 Python 库来完成识别工作，工作量大。选项 B 使用 SageMaker，需要额外的机器学习模型开发工作，不符合“最少的操作开销”的要求。选项 D 使用 Rekognition，主要用于图像识别，不适用于文本提取。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "Amazon Textract",
      "Amazon SageMaker",
      "Amazon Comprehend Medical",
      "Amazon Rekognition",
      "PHI"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 66,
    "topic": "",
    "question_cn": "一家公司有一个应用程序可以生成大量的文件，每个文件的大小大约为 5MB。这些文件存储在 Amazon S3 存储桶中。公司政策要求这些文件在 4 年后删除。由于文件包含不容易复制的关键业务数据，所以总是需要立即访问。这些文件通常在对象创建的前 30 天被访问，但很少在前 30 天之后被访问。哪种存储方案最具成本效益？",
    "options_cn": {
      "A": "创建一个 S3 存储桶生命周期策略，将文件从标准存储转移到 S3 Glacier，目标是 30 天。在对象创建 4 年后删除文件。",
      "B": "创建一个 S3 存储桶生命周期策略，将文件从标准存储转移到 S3 Standard-IA，从对象创建到 30 天的一个区域访问。在对象创建 4 年后删除文件。",
      "C": "创建一个 S3 存储桶生命周期策略，将文件从标准存储移动到 S3 Standard-IA，从对象创建起 30 天。在对象创建 4 年后删除文件。",
      "D": "创建一个 S3 存储桶生命周期策略，将文件从标准存储移动到 S3 Standard-IA，从对象创建起 30 天。在物体创造 4 年后将文件移到 S3 Glacier。"
    },
    "vote_percentage": "66%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "考察如何使用 S3 生命周期策略和不同的存储类，优化存储成本。",
      "why_correct": "选项 C 描述了最经济高效的解决方案。文件在创建后 30 天内经常被访问，适合使用 S3 Standard-IA。4 年后删除文件，符合公司政策。因此，C 提供了最佳的成本效益。",
      "why_wrong": "选项 A 立即将文件转移到 Glacier，这不符合题目中“总是需要立即访问”的要求。选项 B 虽然使用了 Standard-IA，但是 30 天后才进行转移。选项 D 描述了先转移到 Standard-IA 再转移到 Glacier，操作更加复杂。因此，C 是最佳方案。"
    },
    "related_terms": [
      "S3",
      "S3 Glacier",
      "S3 Standard-IA"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 67,
    "topic": "",
    "question_cn": "一个公司在多个 Amazon EC2 实例上拥有一个应用程序。该应用程序处理来自 Amazon SQS 队列的消息，写入到 Amazon DynamoDB 表，并从队列中删除消息。偶尔会有重复的记录出现在 DynamoDB 表中。SQS 队列不包含任何重复的消息。解决方案架构师应该做什么来确保消息只被处理一次？",
    "options_cn": {
      "A": "使用 SQS API 调用创建创建一个新队列。",
      "B": "使用 SQS API 调用添加适当的权限。",
      "C": "使用 SQS API 调用接收消息时，设置适当的等待时间。",
      "D": "使用 SQS API 调用，增加消息的可见性超时。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Visibility Timeout",
      "SQS message processing"
    ],
    "explanation": {
      "analysis": "考察如何防止 SQS 消息被重复处理。",
      "why_correct": "选项 D 描述了使用 SQS 消息的可见性超时。增加消息的可见性超时可以确保在消息处理失败时，其他消费者不会立即收到该消息。 这有助于避免消息被多次处理的情况。",
      "why_wrong": "选项 A、B、C 提供的功能与防止消息重复处理没有直接关系。"
    },
    "related_terms": [
      "EC2",
      "SQS",
      "DynamoDB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 68,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计一种新的混合架构以便将公司内部的基础设施扩展到 AWS。该公司需要一个高度可用的、连接一致的、低延迟到一个 AWS 区域。该公司需要最小化成本并愿意接受较慢的流量如果主要连接失败。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "提供一个与 AWS 区域的 Direct Connect 连接。当主 Direct Connect 连接失败时，提供一个 VPN 连接作为备份。",
      "B": "为私人连接提供到 AWS 区域的 VPN 隧道连接。为私人连接提供第二个 VPN 隧道，并在主 VPN 连接失败时作为备份。",
      "C": "提供一个与 AWS 区域的 Direct Connect 连接。如果主 Direct Connect 连接失败，提供与同一区域的第二个 Direct Connect 连接作为备份。",
      "D": "提供一个与 AWS 区域的 Direct Connect 连接。如果主 Direct Connect 连接连接失败，则使用 AWS CLI 的 Direct Connect 故障转移属性自动创建备份连接。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Direct Connect",
      "VPN",
      "Hybrid Connectivity"
    ],
    "explanation": {
      "analysis": "考察如何设计混合云架构，实现高可用性和低延迟。",
      "why_correct": "选项 A 结合了 Direct Connect 和 VPN。Direct Connect 提供了低延迟和高吞吐量的连接，而 VPN 提供了备份连接。这种组合满足了高可用性、低延迟和成本最小化的要求。",
      "why_wrong": "选项 B 仅仅使用了 VPN。VPN 的延迟通常比 Direct Connect 高。选项 C 使用了两个 Direct Connect 连接，成本较高。选项 D 描述了使用 AWS CLI 的直接连接故障转移属性，这种方法通常不适用。"
    },
    "related_terms": [
      "Direct Connect",
      "VPN"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 69,
    "topic": "",
    "question_cn": "一家公司正在 Amazon EC2 实例上运行一个对业务至关重要的 Web 应用程序，支持一个应用程序负载均衡器。EC2 实例在一个自动缩放组中。应用程序使用一个部署在单一可用性区域的 Amazon Aurora PostgreSQL 数据库。该公司希望该应用程序能够在最短的停机时间和最小的数据损失的情况下非常有效。用最少的工作来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "将 EC2 实例放置在不同的 AWS 区域。使用 Amazon Route 53 的健康检查来重新定位流量。使用 Aurora PostgreSQL 跨区域复制。",
      "B": "配置自动缩放组以使用多个可用性区域。将数据库配置为多可用性区域部署。为数据库配置一个 Amazon RDS 代理实例。",
      "C": "配置自动缩放组以使用一个可用性区域。每小时生成数据库的快照。在失败时从快照中恢复数据库。",
      "D": "配置自动缩放组以使用多个可用性区域。将应用程序的数据写入到 Amazon S3。使用 EventBridge 事件通知启动一个 Lambda 函数将数据写入数据库。"
    },
    "vote_percentage": "95%",
    "tags": [
      "Aurora Multi-AZ",
      "HA",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考察如何设计高可用、低停机的 Web 应用程序架构。",
      "why_correct": "选项 B 描述了一种高可用性的数据库配置。多可用区部署的 Aurora 数据库，可以实现故障转移，减少停机时间。RDS 代理可以提高数据库连接的可用性。 使用多 AZ 自动缩放组提供 Web 应用程序的可用性。",
      "why_wrong": "选项 A 使用了跨区域复制，增加了延迟和复杂性。选项 C 的数据库快照恢复需要较长的恢复时间。选项 D 将数据写入 S3，增加了数据一致性和复杂性。"
    },
    "related_terms": [
      "EC2",
      "Application Load Balancer",
      "Aurora PostgreSQL",
      "Route 53",
      "Multi-AZ",
      "Amazon RDS Proxy",
      "S3",
      "EventBridge",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 70,
    "topic": "",
    "question_cn": "一家公司的 HTTP 应用程序背后是一个网络负载均衡器 (NLB)。NLB 的目标组配置为使用 Amazon EC2 自动缩放组，其中有多个运行 Web 服务的 EC2 实例。该公司注意到 NLB 没有检测到该应用程序的 HTTP 错误。这些错误需要手动重新启动运行 Web 服务的 EC2 实例。公司需要在不编写定制脚本或代码的情况下改进应用程序的可用性。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "允许在 NLB 上进行 HTTP 健康检查，提供公司应用程序的 URL。",
      "B": "在 EC2 实例中添加一个 cron 作业，以便每分钟检查一次本地应用程序的日志。如果检测到 HTTP 错误，应用程序将重新启动。",
      "C": "用应用负载均衡器 (ALB) 替换 NLB。通过提供公司应用程序的 URL 来启用 HTTP 健康检查。配置自动缩放操作来替换不健康的实例。",
      "D": "创建一个 Amazon CloudWatch 报警器为 NLB 监测不健康的人数。当报警处于报警状态时，配置自动缩放操作以替换不健康的实例。"
    },
    "vote_percentage": "88%",
    "tags": [
      "ALB",
      "Health Checks",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考察如何提高 Web 应用程序的可用性，利用健康检查和自动缩放。",
      "why_correct": "选项 C 提供了最佳解决方案，用 ALB 替换 NLB，并配置 HTTP 健康检查。ALB 本身支持健康检查，可以自动检测不健康的实例。并且配置自动缩放操作来替换不健康的实例。这满足了题目中不编写自定义脚本或代码的要求。",
      "why_wrong": "选项 A 描述了配置 HTTP 健康检查，但 NLB 本身不支持这种健康检查。选项 B 需要在实例中添加自定义 cron 作业，增加了复杂性。选项 D 仅根据不健康实例的数量进行报警，并没有提供替换实例的机制。"
    },
    "related_terms": [
      "NLB",
      "EC2",
      "HTTP",
      "CloudWatch",
      "ALB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 71,
    "topic": "",
    "question_cn": "一家公司运行一个使用 Amazon DynamoDB 存储客户信息的购物应用程序。在数据损坏的情况下，解决方案架构师需要设计一个符合 15 分钟恢复点目标 (RPO) 和 1 小时恢复时间目标 (RTO) 的解决方案。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "配置 DynamoDB 全局表。对于故障恢复，将应用指向不同的 AWS 区域。",
      "B": "配置 DynamoDB 实时恢复。恢复到期望的时间点。",
      "C": "每天将 DynamoDB 数据输出到 Amazon S3 Glacier。为了回收数据，从 Glacier 将数据导入 DynamoDB。",
      "D": "安排 Amazon EBS 快照，每 15 分钟一次。对于故障恢复，使用快照恢复 DynamoDB 表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB Point-in-Time Recovery",
      "RTO",
      "RPO"
    ],
    "explanation": {
      "analysis": "考察使用 DynamoDB 的内置功能实现 RPO 和 RTO。",
      "why_correct": "选项 B 描述了使用 DynamoDB 实时恢复 (PITR) 功能。PITR 允许将表恢复到过去 35 天内的任意时间点。这满足了 15 分钟的 RPO 和 1 小时的 RTO 要求。",
      "why_wrong": "选项 A 提到了全局表，但它主要用于跨区域复制，而不是故障恢复。选项 C 使用 S3 Glacier，恢复时间太长，不符合 RTO 要求。选项 D 使用 EBS 快照，这不适用于 DynamoDB。"
    },
    "related_terms": [
      "DynamoDB",
      "RPO",
      "RTO",
      "DynamoDB Global Tables",
      "DynamoDB Point-in-time recovery",
      "Amazon S3 Glacier",
      "Amazon EBS",
      "EBS 快照"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 72,
    "topic": "",
    "question_cn": "一家公司运行了一个图片处理应用程序，需要经常上传和下载来自位于同一 AWS 区域的 Amazon S3 存储桶的图片。解决方案架构师注意到数据传输费用增加，需要实施解决方案以降低这些费用。解决方案架构师如何满足这一要求？",
    "options_cn": {
      "A": "将 Amazon API Gateway 部署到一个公共子网中，并调整路由表使其通过 VPC 接口端点调用 S3 API。",
      "B": "将 NAT 网关部署到公共子网中，并附加允许访问 S3 存储桶的端点策略。",
      "C": "将应用程序部署到公共子网络中，并允许它通过互联网网关访问 S3 存储桶。",
      "D": "将 VPC 接口端点部署到 VPC 中，并附加一个端点策略，允许访问 S3 存储桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "考察如何使用 VPC 接口端点来降低 S3 数据的传输费用。",
      "why_correct": "选项 D 描述了使用 VPC 接口端点。通过使用 VPC 接口端点，应用程序可以通过私有网络访问 S3，避免了使用 Internet 网关，从而降低了数据传输费用。",
      "why_wrong": "选项 A 描述了使用 API Gateway 和 VPC 接口端点，增加了不必要的复杂性。选项 B 使用了 NAT 网关，依然需要支付数据传输费用。选项 C 使用 Internet 网关，同样会产生数据传输费用。"
    },
    "related_terms": [
      "Amazon S3",
      "VPC",
      "Amazon API Gateway",
      "NAT Gateway",
      "VPC 接口端点",
      "S3 API"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 73,
    "topic": "",
    "question_cn": "一家公司最近在一个私有子网上推出了 Amazon EC2 实例上的基于 Web 的应用程序实例，并在一个公共子网上推出了基于线性的数据存储库主机。解决方案架构师需要连接到现场网络，通过公司的 Internet 连接到堡垒主机和应用服务器。解决方案架构师必须确保所有 EC2 实例的安全组允许这种访问。解决方案架构师应该采取哪些步骤来满足这些需求？（选择两项。）",
    "options_cn": {
      "A": "用只允许从应用程序实例进入访问的安全组替换目前的堡垒主机的安全组。",
      "B": "用只允许从公司内部 IP 范围进入访问的安全组替换目前的堡垒主机的安全组。",
      "C": "用只允许公司从外部 IP 范围进入的安全组替换目前的堡垒主机的安全组。",
      "D": "将应用程序实例中当前的安全组替换为一个允许只从堡垒主机的私有 IP 地址进入 SSH 访问的安全组。",
      "E": "将应用程序实例当前的安全组替换为一个允许只从堡垒主机的公共 IP 地址进入 SSH 访问的安全组。"
    },
    "vote_percentage": "92%",
    "tags": [
      "Security Groups",
      "Bastion Host",
      "Network Security"
    ],
    "explanation": {
      "analysis": "考察如何使用安全组配置，实现堡垒主机和应用服务器的安全访问。",
      "why_correct": "选项 C 和 D 提供了正确的安全组配置。选项 C 允许从公司外部 IP 范围通过堡垒主机访问，这通常是必要的。选项 D  配置应用服务器安全组，仅允许来自堡垒主机的私有 IP 地址的 SSH 访问。 这种配置确保了安全访问。",
      "why_wrong": "选项 A 描述了一种不安全的安全组配置。选项 B 描述了配置了错误的 IP 范围。选项 E 不应该直接允许从堡垒主机的公共 IP 地址进行 SSH 访问，更安全的方式是从私有 IP 地址访问。"
    },
    "related_terms": [
      "EC2",
      "VPN",
      "堡垒主机",
      "安全组",
      "SSH"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 74,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个两层 Web 应用程序。该应用程序包括一个面向公共的网络层，在公共子网络中的 Amazon EC2 上。数据库层由在 Amazon EC2 上运行的私有子网中的 Microsoft SQL Server 组成。安保是公司的高度优先事项。在这种情况下安全组应该如何配置？（选择两项。）",
    "options_cn": {
      "A": "配置 Web 层的安全组以允许从 0.0.0.0/0 的 443 端口上的入站流量。",
      "B": "配置 Web 层的安全组允许从 0.0.0.0/0 的 443 端口上的出站流量。",
      "C": "配置数据库层的安全组以允许从 Web 层的安全组进入 1433 端口的流量。",
      "D": "配置数据库层的安全组允许在 443 和 1433 端口上向网络层的安全组进行出站流量。",
      "E": "配置数据库层的安全组以允许来自 Web 层安全组的 443 和 1433 端口上的入站流量。"
    },
    "vote_percentage": "98%",
    "tags": [
      "Security Groups",
      "Network Security",
      "Two-Tier Application"
    ],
    "explanation": {
      "analysis": "考察如何配置安全组，以确保 Web 应用程序和数据库的安全访问。",
      "why_correct": "选项 A 和 C 提供了正确的安全组配置。选项 A 允许从 0.0.0.0/0 的 443 端口上的入站流量，保证 Web 应用程序能够接收 HTTPS 流量。选项 C 允许来自 Web 层的安全组的 1433 端口的流量，这允许 Web 应用程序访问数据库。",
      "why_wrong": "选项 B 描述了安全组出站规则，通常没有必要允许从 443 端口上的出站流量。选项 D 描述了配置错误的出站规则。选项 E 的端口配置不正确。"
    },
    "related_terms": [
      "Web 应用程序",
      "EC2",
      "Microsoft SQL Server",
      "安全组"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 75,
    "topic": "",
    "question_cn": "一家公司希望将一个多层应用程序从内部转移到 AWS 云，以提高应用程序的性能。应用程序由应用程序层组成，应用程序层通过 REST 服务相互通信。当一层过载时，事务将被删除。解决方案架构师必须设计解决这些问题并使应用程序现代化的解决方案。哪个解决方案满足这些要求是最有效的操作？",
    "options_cn": {
      "A": "使用 Amazon API Gateway 和直接事务的 Lambda 函数作为应用层。使用 Amazon SQS 作为应用程序服务之间的通信层。",
      "B": "使用 Amazon EC2 实例和 Amazon CloudWatch 度量分析应用程序性能历史以确定服务器在性能失败期间的最高利用率。增加应用服务器的 Amazon EC2 实例的大小以满足高峰需求。",
      "C": "使用 Amazon SNS 处理在 Amazon EC2 上运行的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控 SQS 队列的长度并按需要上下扩展。",
      "D": "使用 Amazon SQS 处理在 Amazon EC2 上运行的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控该队列的长度并在检测到通信故障时进行升级。"
    },
    "vote_percentage": "81%",
    "tags": [
      "API Gateway",
      "Lambda",
      "SQS",
      "Microservices"
    ],
    "explanation": {
      "analysis": "考察如何构建一个现代化的、可扩展的微服务架构，以提高应用程序性能。",
      "why_correct": "选项 A 描述了最佳的解决方案。使用 Amazon API Gateway 和 Lambda 函数作为应用层，提供高可扩展性和低延迟。使用 Amazon SQS 作为应用程序服务之间的通信层，提供异步通信和解耦。这种架构可以解决事务删除的问题，并提高了应用程序的性能。",
      "why_wrong": "选项 B 和 D  使用了 EC2 实例，这增加了维护的复杂性。选项 B 试图通过增加 EC2 实例的大小来解决性能问题，这种方法不够灵活。选项 C 描述使用 SNS 进行服务间通信，不如 SQS 适合处理消息传递和解耦。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "SQS",
      "EC2",
      "CloudWatch",
      "SNS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 76,
    "topic": "",
    "question_cn": "一家公司每天从位于一个工厂的几台机器接收10TB的JSON仪器数据。数据由存储在工厂内部数据中心的存储区域网络(SAN)上的文件组成，这些文件位于S3中。该公司希望将这些数据发送到Amazon S3，在那里它可以被其他几个提供关键的近实时分析的系统访问。安全传输是重要的，因为数据被认为是敏感的。哪个解决方案提供最可靠的数据传输？",
    "options_cn": {
      "A": "在公共互联网上的无线网络服务上传输数据。",
      "B": "使用AWS Direct Connect直接连接到无线网络数据源。",
      "C": "使用AWS Database Migration Service(AWS DMS)在公共互联网上进行数据传输。",
      "D": "使用AWS Database Migration Service (AWS DMS)通过AWS Direct Connect进行数据传输。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Direct Connect",
      "S3 Transfer"
    ],
    "explanation": {
      "analysis": "考查安全、可靠的数据传输方案。",
      "why_correct": "AWS Direct Connect提供专用网络连接，安全性更高，传输更稳定，更适合敏感数据传输。",
      "why_wrong": "选项A和C通过公共互联网传输，安全性无法保障。选项B使用无线网络，可靠性较差。"
    },
    "related_terms": [
      "S3",
      "SAN",
      "AWS Direct Connect",
      "AWS DMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 77,
    "topic": "",
    "question_cn": "公司需要为其应用程序配置实时数据摄取体系结构。该公司需要一个过程，该过程在数据流化时转换数据，以及一个数据存储解决方案。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "部署一个Amazon EC2实例来主机一个将数据发送到Amazon Kinesis Data Streams的API。创建一个Amazon Kinesis Data Firehose传递流，使用Kinesis Data Streams作为数据源。使用Lambda函数来转换数据。使用动态Kinesis Data Firehose传递流将数据发送到Amazon S3。",
      "B": "部署一个Amazon EC2实例来主机一个将数据发送到AWS Glue的API。停止EC2实例的源/目的地检查。使用Glue来转换数据并将数据发送到Amazon S3。",
      "C": "配置Amazon API Gateway，将数据发送到Amazon Kinesis Data Streams。创建一个Amazon Kinesis Data Firehose传递流，使用Kinesis Data Streams作为数据源。使用Lambda函数来转换数据。使用动态Kinesis Data Firehose传递流将数据发送到Amazon S3。",
      "D": "配置一个Amazon API Gateway，以便将数据发送到Glue。使用Lambda函数来转换数据。使用Glue将数据发送到Amazon S3。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Kinesis Data Streams",
      "Lambda",
      "API Gateway"
    ],
    "explanation": {
      "analysis": "考查实时数据摄取架构，需要考虑数据流、转换和存储。",
      "why_correct": "选项C使用API Gateway接收数据，Kinesis Data Streams实现流式处理，Lambda进行数据转换，Kinesis Data Firehose将数据发送到S3，整体架构简洁、高效。",
      "why_wrong": "选项A和B都需要维护EC2实例，增加了运维成本。选项D没有使用流式处理组件，性能较差。"
    },
    "related_terms": [
      "Kinesis Data Streams",
      "Kinesis Data Firehose",
      "Lambda",
      "S3",
      "EC2",
      "API Gateway",
      "AWS Glue"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 78,
    "topic": "",
    "question_cn": "公司需要将用户事务数据保存在Amazon DynamoDB表中。公司必须将数据保存七年。符合这些要求的最有效的业务解决方案是什么？",
    "options_cn": {
      "A": "使用DynamoDB实时恢复来连续备份表。",
      "B": "使用AWS Backup为表创建备份时间表和保留策略。",
      "C": "通过使用DynamoDB控制台创建表的按需备份。将备份存储在一个Amazon S3桶中。为S3桶设置一个生命周期配置。",
      "D": "创建一个Amazon EventBridge(Amazon CloudWatch Events)规则来调用一个Lambda函数。配置Lambda函数以备份桌子并将备份存储在Amazon S3桶中。为S3桶设置一个生命周期配置。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB Backup",
      "AWS Backup"
    ],
    "explanation": {
      "analysis": "考查DynamoDB数据的备份和保留方案。",
      "why_correct": "AWS Backup专门用于备份和恢复AWS资源，可以方便地配置备份时间表和保留策略。",
      "why_wrong": "选项A不是备份方案。选项C和D需要手动配置备份和生命周期管理，较为复杂。"
    },
    "related_terms": [
      "DynamoDB",
      "AWS Backup",
      "S3",
      "EventBridge",
      "CloudWatch Events",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 79,
    "topic": "",
    "question_cn": "一家公司计划使用Amazon DynamoDB表进行数据存储。公司关心的是成本优化，大多数早晨不使用这张表。在晚上读写流量往往是不可预测的。当交通高峰发生时，它们会发生得非常快。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "在按需容量模式下创建一个DynamoDB表。",
      "B": "用全局二级索引创建一个DynamoDB表。",
      "C": "创建一个配备容量和自动缩放的DynamoDB表。",
      "D": "在提供容量模式下创建DynamoDB表并将其配置为全局表。"
    },
    "vote_percentage": "79%",
    "tags": [
      "DynamoDB Capacity",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考查DynamoDB容量模式的选择，侧重成本优化。",
      "why_correct": "按需容量模式可以根据实际的读写请求自动调整容量，适用于流量不稳定的场景，可以最大限度地节省成本。",
      "why_wrong": "选项B和D与容量模式无关。选项C使用预置容量，成本可能较高，不符合题意。"
    },
    "related_terms": [
      "DynamoDB",
      "按需容量",
      "全局二级索引",
      "自动缩放",
      "提供容量"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 80,
    "topic": "",
    "question_cn": "最近一家公司与美国世界服务公司(MSP)的合作伙伴签订了一份合同，要求他们提供应用程序迁移方面的帮助。解决方案架构师需要使用与合作伙伴的AWS账户共享现有的AWS账户中的Amazon机器映像(AMI)。由Amazon EBS支持AMI，并使用一个AWS Key Management Service (AWS KMS)客户管理的密钥加密卷快照。对于解决方案架构师来说，什么是最安全的方式来与合作伙伴的AWS账户共享这些信息？",
    "options_cn": {
      "A": "使加密的AMI和快照公开。修改密钥策略，允许伙伴的账户使用密钥。",
      "B": "修改AMI的启动权限属性。只与MSP合作伙伴的账户分享该信息。修改密钥策略，允许伙伴的账户使用密钥。",
      "C": "修改AMI的启动权限属性。只与MSP合作伙伴的账户分享该信息。修改密钥策略以信任一个新的密钥，它是由MSP伙伴拥有的加密。",
      "D": "从源代码账户中向伙伴的账户中的一个Amazon S3桶中导出了该数据，用一个新的密钥对S3桶进行加密，这个密钥是MSP伙伴拥有的。复制并启动在合作伙伴的AWS账户中。"
    },
    "vote_percentage": "90%",
    "tags": [
      "AMI Sharing",
      "KMS",
      "EBS"
    ],
    "explanation": {
      "analysis": "考查共享AMI和快照的安全方法。",
      "why_correct": "选项B通过修改AMI的启动权限属性，只与MSP合作伙伴共享，并修改KMS密钥策略，允许合作伙伴使用密钥，确保了安全性。 并且保证了安全，不会泄露给其他人。",
      "why_wrong": "选项A将AMI公开，存在安全风险。选项C的密钥控制不清晰，可能导致密钥泄露。选项D需要导出数据，操作复杂，安全性较低。"
    },
    "related_terms": [
      "AMI",
      "EBS",
      "AWS KMS",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 81,
    "topic": "",
    "question_cn": "一个解决方案架构师正在为部署在AWS上的新应用程序设计云架构。流程应该并行运行，同时根据需要处理的作业数量添加和删除应用程序节点。处理器应用程序是无状态的。解决方案架构师必须确保应用程序是松散耦合的，作业项是持久存储的。解决方案架构师应该使用哪种设计？",
    "options_cn": {
      "A": "创建一个Amazon SNS主题发送需要处理的工作。创建一个由处理器应用程序组成的Amazon机器映像(AMI)。创建一个启动配置，该配置将使用该系统。使用启动配置创建一个自动缩放组。为自动缩放组设置缩放策略以根据CPU使用情况添加和删除节点。",
      "B": "创建一个Amazon SQS队列以保存需要处理的作业。创建一个由处理器应用程序组成的Amazon机器映像(AMI)。创建一个启动配置，该配置将使用该系统。使用启动配置创建一个自动缩放组。为自动缩放组设置缩放策略以根据网络使用情况添加和删除节点。",
      "C": "创建一个Amazon SQS队列以保存需要处理的作业。创建一个由处理器应用程序组成的Amazon机器映像(AMI)。创建一个启动模板，该模板将使用该模型。使用启动模板创建一个自动缩放组。为自动缩放组设置缩放策略以根据队列中的项目数量添加和删除节点。",
      "D": "创建一个Amazon SNS主题发送需要处理的工作。创建一个由处理器应用程序组成的Amazon机器映像(AMI)。创建一个启动模板，该模板将使用该模型。使用启动模板创建一个自动缩放组。设置自动缩放组的缩放策略以根据发布到SNS主题的消息数量来添加和删除节点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Auto Scaling",
      "Loose Coupling"
    ],
    "explanation": {
      "analysis": "考查构建松散耦合、可扩展的应用程序架构。",
      "why_correct": "选项C使用SQS存储作业，实现了松散耦合和持久存储。使用启动模板和自动缩放组，根据队列中的项目数量动态调整应用程序节点，满足并行处理和弹性伸缩的需求。",
      "why_wrong": "选项A和D使用SNS，消息传递机制与作业处理逻辑耦合。选项B使用网络使用情况进行伸缩，不直接与作业数量相关。"
    },
    "related_terms": [
      "Amazon SNS",
      "Amazon EC2",
      "AMI",
      "启动配置",
      "自动缩放组",
      "CPU",
      "Amazon SQS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 82,
    "topic": "",
    "question_cn": "一家公司将其网络应用程序放在AWS云中。该公司配置的弹性负载平衡器使用的证书是导入到AWS证书管理器(ACM)。必须在每份证书到期前30天通知公司的安全小组。 解决方案架构师应该建议什么来满足这个需求",
    "options_cn": {
      "A": "添加ACM中的一条规则即每天从证书到期前30天开始向亚马逊简单通知服务(SNS)亚马逊主题发布自定义消息。",
      "B": "创建一个AWS Config规则，用于检查30天内到期的证书。当Config报告一个不符合要求的资源时，请通过SNS来调用自定义警报。",
      "C": "使用AWS Trusted Advisor检查30天内到期的证书。创建一个亚马逊云表警报，该警报是基于Trusted Advisor度量检查状态变化。将报警器配置为通过SNS发送自定义警报。",
      "D": "创建一个亚马逊事件桥(CloudWatch Events)规则来检测任何将在30天内到期的证书。将该规则配置为调用Lambda函数。通过使用SNS(亚马逊简单通知服务)亚马逊来发送自定义警报。"
    },
    "vote_percentage": "52%",
    "tags": [
      "AWS Certificate Manager (ACM)",
      "Amazon SNS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，B使用了Config规则，可以自动检查证书到期情况，并在到期前30天触发通知。",
      "why_correct": "选项B 使用AWS Config规则，可以自动检查证书的到期情况，并在证书到期前30天触发通知。通过配置SNS，可以发送自定义的警报通知，满足了需求。",
      "why_wrong": "选项A 配置复杂，需要手动配置规则，不推荐。选项C 依赖于Trusted Advisor，但Trusted Advisor的更新频率可能不足，无法准确监控。选项D使用了Lambda，增加了复杂性，并非最佳实践。"
    },
    "related_terms": [
      "AWS",
      "ACM",
      "AWS",
      "SNS",
      "CloudWatch Events",
      "Lambda",
      "SNS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 83,
    "topic": "",
    "question_cn": "一家公司在美国的动态网站使用的是内部服务器。该公司正在欧洲推出其产品并希望为新的欧洲用户优化网站加载时间。网站后端必须留在美国。该产品将在几天后推出，需要立即解决。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "在AWS美国东部1区启动Amazon EC2实例并将站点迁移到它。",
      "B": "将网站移到Amazon S3。在区域之间使用跨区域复制。",
      "C": "使用Amazon CloudFront，其自定义来源指向内部服务器。",
      "D": "使用Amazon Route 53线路地理邻近路由策略指向内部服务器。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Latency"
    ],
    "explanation": {
      "analysis": "考查加速全球网站访问速度的方案。",
      "why_correct": "CloudFront CDN可以缓存静态内容，就近分发给用户，从而优化网站加载时间。将自定义源指向内部服务器，可以满足后端留在美国的要求。",
      "why_wrong": "选项A没有解决延迟问题。选项B需要迁移网站，耗时较长。选项D仅调整DNS解析策略，没有缓存加速功能。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon S3",
      "CloudFront",
      "Amazon Route 53"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 84,
    "topic": "",
    "question_cn": "一家公司希望降低其现有三层网络架构的成本。网站、应用程序和数据库服务器在Amazon EC2实例中运行，用于开发、测试和生产环境。EC2实例平均在高峰时段使用CPU 30%，在非高峰时段使用CPU 10%。EC2生产实例每天24小时运行。开发和测试EC2实例每天至少运行8小时。该公司计划实现自动化以停止开发和测试未使用的EC2实例。哪个EC2实例采购解决方案最符合公司的要求？",
    "options_cn": {
      "A": "使用Spot EC2实例进行生产EC2实例。为开发和测试EC2实例使用保留实例。",
      "B": "为生产EC2实例使用保留实例。为开发和测试EC2实例使用按需实例。",
      "C": "使用Spot块生产EC2实例。为开发和测试EC2实例使用保留实例。",
      "D": "为生产EC2实例使用按需实例。使用Spot块开发和测试EC2实例。"
    },
    "vote_percentage": "96%",
    "tags": [
      "EC2 Instance Purchasing Options",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考查EC2实例购买选项，重点是成本优化。",
      "why_correct": "生产环境需要稳定，保留实例可以提供折扣价格，开发和测试环境可以灵活使用按需实例，按需使用按需实例更灵活，可以满足停止实例的需求。",
      "why_wrong": "选项A使用Spot实例用于生产环境，可靠性较差。选项C使用Spot实例，可靠性较差。选项D生产环境使用按需实例，成本较高。"
    },
    "related_terms": [
      "Spot EC2",
      "保留实例",
      "按需实例",
      "Spot块"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 85,
    "topic": "",
    "question_cn": "公司有一个生产网络应用程序，用户可以通过网络接口或移动应用程序上传文档。根据新的监管要求，新文档存储后不能修改或删除。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "将上传的文档存储在一个具有版本控制和S3对象锁定功能的Amazon S3桶中。",
      "B": "将上传的文档存储在Amazon S3桶中。配置一个生命周期策略来定期归档文档。",
      "C": "将上传的文档存储在一个启用版本控制的Amazon S3桶中。配置S3 ACL以限制所有只读访问。",
      "D": "将上传的文档存储在Amazon弹性文件系统(EFS)卷中。通过安装只读模式的卷访问数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Object Lock",
      "Immutability",
      "S3 Versioning"
    ],
    "explanation": {
      "analysis": "考查满足文档不可变性要求的存储方案。",
      "why_correct": "选项A使用S3版本控制和对象锁定功能，可以防止文档被修改或删除。",
      "why_wrong": "选项B通过归档实现不可变性，无法满足立即不可变的需求。选项C仅设置ACL权限，无法防止删除。选项D使用EFS，但EFS无法直接提供不可变性。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 86,
    "topic": "",
    "question_cn": "一家公司有几个Web服务器需要经常访问一个共同的Amazon RDS MySQL数据库实例。该公司需要一种安全的方法使Web服务器能够连接到数据库，同时满足经常旋转用户凭证的安全要求。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将数据库用户的凭证存储在AWS Secrets Manager中。授予必要的IAM权限允许Web服务器访问Secrets Manager。",
      "B": "将数据库用户的凭证存储在AWS Systems Manager中。授予必要的IAM权限以允许Web服务器访问Secrets Manager。",
      "C": "将数据库用户凭证存储在一个安全的Amazon S3桶中。授予必要的IAM权限允许Web服务器检索凭证和访问数据库。",
      "D": "在Web服务器文件系统中将数据库用户的凭证存储在使用AWS KMS加密的文件中。Web服务器应该能够解密文件并访问数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "RDS MySQL",
      "Security"
    ],
    "explanation": {
      "analysis": "考查安全存储和管理数据库凭证的方案。",
      "why_correct": "选项A使用AWS Secrets Manager安全地存储数据库凭证，并通过IAM权限控制访问，满足安全要求。",
      "why_wrong": "选项B使用了Systems Manager，功能不如Secrets Manager强大。选项C将凭证存储在S3中，安全性较低。选项D在Web服务器上存储加密文件，增加了安全风险，且维护成本较高。"
    },
    "related_terms": [
      "AWS Secrets Manager",
      "IAM",
      "Amazon S3",
      "AWS KMS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 87,
    "topic": "",
    "question_cn": "一家公司拥有一个应用程序，该应用程序使用的是亚马逊API网关API。Lambda功能是将客户数据保存到亚马逊奥罗拉数据库(MySQL)中。每当公司对数据库进行升级时，在升级完成之前，Lambda功能无法建立数据库连接。结果是一些事件没有记录客户数据。 解决方案架构师需要设计存储数据库升级期间创建的客户数据的解决方案。 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "提供一个亚马逊RDS代理人以坐在Lambda功能和数据库之间。配置函数以连接到代理。",
      "B": "将Lambda函数的运行时间增加到最大。在数据库中存储客户数据的代码中创建重试机制。",
      "C": "将客户数据持久保存到Lambda本地存储中。配置新的函数扫描本地存储以将客户数据保存到数据库中。",
      "D": "将客户数据存储在亚马逊简单队列服务(SQS)队列中。创建一个新的Lambda函数可以对队列进行轮询并在数据库中存储客户数据。"
    },
    "vote_percentage": "61%",
    "tags": [
      "Amazon SQS",
      "AWS Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，SQS可以作为Lambda函数的中间件，保证数据在数据库不可用时也能安全存储，并最终写入数据库。",
      "why_correct": "选项D 使用 SQS 作为消息队列，Lambda 函数将客户数据发送到 SQS，即使数据库不可用，数据也不会丢失。 另一个 Lambda 函数轮询 SQS 队列并将数据写入数据库，确保在数据库恢复后能够处理数据。",
      "why_wrong": "选项A 使用 RDS 代理，代理可以提供连接池和故障转移， 但不能解决数据库升级期间的连接问题。 选项B 增加运行时间并重试，但如果数据库持续不可用，重试机制无法有效解决问题。 选项C 使用Lambda 本地存储，本地存储容量有限，不适合存储大量数据，且数据丢失风险较高。"
    },
    "related_terms": [
      "亚马逊API网关",
      "Lambda",
      "亚马逊奥罗拉数据库",
      "RDS",
      "RDS 代理",
      "SQS",
      "SQS",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 88,
    "topic": "",
    "question_cn": "几年来一家调查公司从美国的一些地区收集数据，这些数据保存在一个Amazon S3桶中，这个桶的尺寸和增长都是3TB。该公司已经开始与一家拥有S3系统的欧洲营销公司分享数据。该公司希望确保其数据传输成本尽可能低。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在公司的S3桶上配置请求者支付的功能。",
      "B": "配置S3跨区域复制，从公司的S3桶到营销公司的S3桶。",
      "C": "为营销公司配置跨账户访问，以便营销公司可以访问公司的S3桶。",
      "D": "配置公司的S3桶使用智能层。同步S3桶到营销公司的S3桶。"
    },
    "vote_percentage": "46%",
    "tags": [
      "S3 Cross-Region Replication",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考查降低S3数据传输成本的方案。",
      "why_correct": "选项B使用S3跨区域复制，将数据复制到欧洲，营销公司可以从欧洲的S3桶中读取数据，减少了数据传输成本。",
      "why_wrong": "选项A要求营销公司支付传输费用，不符合题意。选项C会增加跨账户访问的复杂性，并且没有优化传输成本。选项D没有说明如何降低成本。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "S3",
      "S3",
      "跨区域复制",
      "S3",
      "智能层"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 89,
    "topic": "",
    "question_cn": "一家公司使用Amazon S3存储其机密审计文件。S3桶使用桶策略根据最小权限原则限制对审计团队IAM用户凭证的访问。公司经理担心S3桶中的文档会被意外删除，他们希望有一个更安全的解决方案。解决方案架构师应该如何确保审计文件的安全？",
    "options_cn": {
      "A": "启用S3桶上的版本控制和MFA删除功能。",
      "B": "为每个审计团队IAM用户账户在IAM用户凭证上启用多因素身份验证(MFA)。",
      "C": "将生命周期策略添加到审计团队的IAM用户账户中，以拒绝在审计日期期间的删除对象操作。",
      "D": "使用AWS Key Management Service(AWS KMS)加密S3桶并限制审计团队IAM用户账户访问KMS密钥。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Versioning",
      "S3 Object Lock",
      "MFA"
    ],
    "explanation": {
      "analysis": "考查保护S3桶中文件免受意外删除的方案。",
      "why_correct": "选项A启用版本控制和MFA删除功能，可以防止文件被意外删除。",
      "why_wrong": "选项B和D与防止误删除无关。选项C使用生命周期策略限制删除操作，但不能完全防止误删除。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "IAM",
      "IAM",
      "MFA",
      "AWS Key Management Service",
      "AWS KMS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 90,
    "topic": "",
    "question_cn": "一家公司正在使用一个SQL RDS数据库来存储公开的电影数据。数据库运行在亚马逊单AZ数据库实例上。脚本每天随机地运行查询记录添加到数据库中的新电影的数量。脚本必须在工作时间报告最终总数，该公司的开发团队注意到当脚本运行时数据库性能不足以执行开发任务。解决方案架构师必须推荐解决这个问题的解决方案。 用最少的操作开销来满足这个需求的解决方案是什么",
    "options_cn": {
      "A": "将数据库实例修改为多AZ部署。",
      "B": "创建数据库的读副本。将脚本配置为只查询读取副本。",
      "C": "指示开发团队在每天结束时手动导出数据库中的条目。",
      "D": "使用亚马逊弹性缓存来缓存脚本在数据库中运行的常见查询。"
    },
    "vote_percentage": "95%",
    "tags": [
      "RDS Read Replicas",
      "Amazon ElastiCache"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，B提供了读写分离，缓解了数据库负载，同时对开发团队的影响最小。",
      "why_correct": "选项B通过创建只读副本，将脚本的查询负载转移到只读副本上，从而减轻了主数据库的负载，提高了性能。开发团队可以继续在主数据库上进行开发任务，不会受到影响。",
      "why_wrong": "选项A将数据库改为多AZ部署，提高了可用性，但没有解决数据库负载的问题。选项C手动导出数据，操作繁琐，不符合自动化要求。选项D使用了缓存，虽然可以提高查询速度，但只对经常访问的数据有效，不能完全解决问题。"
    },
    "related_terms": [
      "SQL RDS",
      "Amazon",
      "AZ",
      "多AZ",
      "读副本",
      "亚马逊弹性缓存"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 91,
    "topic": "",
    "question_cn": "一家公司在VPC中运行在亚马逊EC2实例上运行的应用程序。其中一个应用程序需要调用亚马逊S3API来存储和读取对象。根据该公司的安全规定，不允许来自申请的流量在互联网上旅行。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为S3配置一个VPC网关端点。",
      "B": "在私有子网中创建一个S3桶。",
      "C": "在与EC2实例相同的区域中创建一个S3桶。",
      "D": "在与EC2实例相同的子网中配置NAT网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3 Security"
    ],
    "explanation": {
      "analysis": "使用VPC网关端点允许EC2实例通过VPC内网络访问S3，而不经过互联网。",
      "why_correct": "VPC网关端点允许流量在VPC内部路由到S3，满足了安全规定，即流量不能通过互联网。",
      "why_wrong": "B选项创建S3桶本身并不能解决问题，仍然需要网络配置；C选项创建桶无助于实现安全访问；D选项NAT网关允许实例访问互联网，违反了安全规定。"
    },
    "related_terms": [
      "VPC",
      "亚马逊EC2",
      "亚马逊S3",
      "VPC",
      "S3",
      "VPC",
      "NAT网关"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 92,
    "topic": "",
    "question_cn": "一家公司正在亚马逊S3桶中存储敏感的用户信息。该公司希望通过在VPC中的亚马逊EC2实例上运行的应用程序层提供对这个桶的安全访问。解决方案架构师应该采取哪些步骤组合来实现这个目标？（选二）",
    "options_cn": {
      "A": "在VPC中为亚马逊S3配置一个VPC网关端点。",
      "B": "创建一个S3桶策略，使桶中的对象公开。",
      "C": "创建一个VPC桶策略，该策略只限制对在VPC中运行的应用程序层的访问。",
      "D": "创建一个具有IAM访问策略的IAM用户，并将凭证复制到EC2实例。",
      "E": "创建一个NAT实例让EC2实例使用NAT实例访问S3桶。"
    },
    "vote_percentage": "88%",
    "tags": [
      "S3 Security",
      "VPC Endpoint"
    ],
    "explanation": {
      "analysis": "结合VPC网关端点和桶策略，限制访问，实现对S3桶的安全访问。",
      "why_correct": "选项 A 和 C 结合了 VPC 端点和桶策略，提供了安全的 S3 访问。A 通过 VPC 端点使 EC2 实例能够通过私有网络访问 S3。C 限制了对 S3 桶的访问，仅允许来自 VPC 内的应用程序层的访问。",
      "why_wrong": "B 选项将对象公开，这违反了安全要求；D 选项使用 IAM 用户，将凭证暴露在 EC2 实例上，不够安全；E 选项使用 NAT 实例，虽然提供了访问互联网的能力，但并非最佳解决方案，且增加了复杂性。"
    },
    "related_terms": [
      "VPC",
      "亚马逊S3",
      "EC2",
      "VPC",
      "亚马逊S3",
      "VPC",
      "IAM",
      "NAT"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 93,
    "topic": "",
    "question_cn": "一家公司运行一个由MySQL数据库提供动力的内部应用程序。该公司正在将应用程序迁移到AWS以增加应用程序的弹性和可用性。当前的架构显示在正常运行期间数据库上的大量读取活动。每隔4小时，公司的开发团队就会将生产数据库全部导出以填充阶段环境中的数据库。在此期间，用户经历了不可接受的应用程序延迟。开发团队在程序完成之前无法使用阶段环境。解决方案架构师必须推荐可缓解应用程序延迟问题的替换架构。替换架构还必须使开发团队能够立即继续使用阶段环境。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用亚马逊 Aurora 与多 AZ 极光复制品生产。通过实现使用 mysqldump 实用程序的备份和还原过程来填充阶段数据库。",
      "B": "使用亚马逊 Aurora 与多 AZ 极光复制品生产。使用数据库克隆来创建按需的临时数据库。",
      "C": "使用亚马逊 RDS 进行MySQL的多AZ部署并读取副本用于生产。使用临时数据库的备用实例。",
      "D": "使用亚马逊 RDS 进行MySQL的多AZ部署并读取副本用于生产。通过实现使用 mysqldump 实用程序的备份和还原过程来填充阶段数据库。"
    },
    "vote_percentage": "91%",
    "tags": [
      "RDS",
      "Aurora",
      "Database Cloning"
    ],
    "explanation": {
      "analysis": "使用 Aurora 数据库克隆功能，可以快速创建数据库副本，而无需长时间的备份和恢复过程，从而减少应用程序延迟并使开发团队能够立即访问阶段环境。",
      "why_correct": "选项 B 提供了最佳的解决方案。Aurora 数据库克隆允许快速创建数据库的独立副本，减少了填充阶段环境所需的时间，从而解决了应用程序延迟问题。开发团队可以立即使用克隆的数据库。",
      "why_wrong": "选项 A 使用 mysqldump 备份和恢复过程，这仍然需要时间，并且会导致应用程序延迟；选项 C 使用备用实例，这不能解决填充阶段环境所需的时间问题；选项 D 同样使用备份和恢复，无法满足需求。"
    },
    "related_terms": [
      "MySQL",
      "AWS",
      "亚马逊 Aurora",
      "Aurora",
      "RDS",
      "MySQL",
      "多AZ"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 94,
    "topic": "",
    "question_cn": "一家公司正在设计一个应用程序，用户可以在其中向亚马逊S3上传小文件。在用户上传文件后，文件需要一次性的简单处理以转换数据为JSON数据，并将数据保存在JSON格式中供以后的分析使用。每个文件上传后必须尽快处理。需求会有所不同。有时候用户会上传大量文件。其他时候用户会上传一些文件或没有文件。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "配置亚马逊EMR来读取来自亚马逊S3的文本文件。运行处理脚本来转换数据，将结果的JSON文件存储在亚马逊极光数据库集群中。",
      "B": "配置亚马逊S3，将事件通知发送到亚马逊简单队列服务队列。使用亚马逊EC2实例读取队列并处理数据。将结果JSON文件存储在亚马逊发电机中。",
      "C": "配置亚马逊S3，将事件通知发送到亚马逊简单队列服务队列。从队列中读取Lambda函数并处理数据。将结果的JSON文件存储在亚马逊发电机中。",
      "D": "配置亚马逊云表事件，以便在新文件上传时将事件发送到亚马逊运动数据流。使用Lambda函数从流中消耗JSON事件并处理数据。将结果的JSON文件存储在亚马逊极光数据库集群中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Lambda",
      "SQS",
      "Event-Driven Architecture"
    ],
    "explanation": {
      "analysis": "使用 S3 事件触发 Lambda 函数，处理上传的文件，并将结果存储在 DynamoDB 中，是最具成本效益和可伸缩的解决方案。",
      "why_correct": "选项 C 实现了最少的操作开销。S3 触发 SQS，SQS 触发 Lambda 函数。Lambda 函数处理 S3 文件，并将结果存储在 DynamoDB 中。这种架构是事件驱动的，并且是无服务器的，因此可以自动扩展并按需付费。",
      "why_wrong": "A 选项使用 EMR，会带来额外的管理开销和成本。B 选项使用 EC2 实例，维护成本更高，需要手动管理；D 选项使用 Kinesis Data Streams，增加了复杂性，并非最佳。"
    },
    "related_terms": [
      "亚马逊S3",
      "JSON",
      "亚马逊EMR",
      "亚马逊S3",
      "亚马逊简单队列服务",
      "Lambda",
      "JSON",
      "亚马逊极光数据库",
      "亚马逊云表",
      "JSON",
      "Lambda",
      "运动数据流",
      "亚马逊极光数据库"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 95,
    "topic": "",
    "question_cn": "应用程序允许公司总部的用户访问产品数据。产品数据存储在亚马逊RDS MySQL数据库实例中。操作团队已经隔离了应用程序性能的减缓，并希望将读流量和写流量分开。解决方案架构师需要快速优化应用程序的性能。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "将现有数据库更改为多AZ部署。从主可用性区服务读取请求。",
      "B": "将现有数据库更改为多AZ部署。从二级可用性区服务读取请求。",
      "C": "为数据库创建读副本。用一半的计算和存储资源作为源数据库来配置读取副本。",
      "D": "为数据库创建读副本。使用与源数据库相同的计算和存储资源配置读取副本。"
    },
    "vote_percentage": "98%",
    "tags": [
      "RDS",
      "Read Replica",
      "Performance Optimization"
    ],
    "explanation": {
      "analysis": "创建读副本可以分担主数据库的读取负载，提高应用程序性能。",
      "why_correct": "D 选项是最佳选择。创建读副本允许将读取请求分发到多个数据库实例，从而提高读取性能，并且读副本可以使用与源数据库相同的计算和存储资源，保证性能和可用性。",
      "why_wrong": "A 和 B 选项将现有数据库更改为多AZ部署，虽然提高了可用性，但并不能直接解决读写分离的问题。C 选项使用较少的资源创建读副本，可能会影响性能，并非最佳。"
    },
    "related_terms": [
      "亚马逊RDS",
      "RDS",
      "多AZ",
      "读副本"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 96,
    "topic": "",
    "question_cn": "亚马逊IAM管理员创建了与包含多个用户的IAM组相关的下列策略：```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:TerminateInstances\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"IpAddress\": {\n          \"aws:SourceIp\": \"10.100.100.254\"\n        }\n      }\n    }\n  ]\n}```这项策略的效果如何？",
    "options_cn": {
      "A": "用户可以终止任何区域的EC2实例，但美国东部1号区域除外。",
      "B": "用户可以在美国东部1号区域使用IP地址10.100.100.1终止EC2实例。",
      "C": "当用户的源IP为10.100.100.254时，用户可以终止美国东部1号地区的EC2实例。",
      "D": "当用户的源IP为10.100.100.254时，用户不能终止美国东部1号地区的EC2实例。"
    },
    "vote_percentage": "70%",
    "tags": [
      "IAM",
      "EC2",
      "Policy"
    ],
    "explanation": {
      "analysis": "IAM 策略允许在特定源 IP 地址下终止 EC2 实例，该策略使用了 aws:SourceIp 条件。",
      "why_correct": "C 选项正确描述了策略的效果。该策略允许用户，如果他们的源 IP 地址是 10.100.100.254，则可以终止所有区域中的 EC2 实例。资源是“*”，表示所有资源。",
      "why_wrong": "A 选项错误。策略允许终止所有区域的实例。B 选项错误。IP 地址是针对策略的条件，而不是固定的。D 选项错误。策略允许终止实例，而不是禁止。"
    },
    "related_terms": [
      "IAM",
      "EC2",
      "IP"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 97,
    "topic": "",
    "question_cn": "一个公司有一个大型的微软共享点部署运行在现场，需要微软的共享文件存储。该公司希望将此工作负载迁移到AWS云，并正在考虑各种存储选项。存储解决方案必须是高度可用的并与活动目录集成以进行访问控制。哪种方法能满足这些要求？",
    "options_cn": {
      "A": "配置亚马逊EFS存储并设置活动目录域进行身份验证。",
      "B": "在两个可用性区域中的一个存储网关文件网关上创建一个SMB文件共享。",
      "C": "创建一个亚马逊S3桶并配置微软Windows服务器将其安装为卷。",
      "D": "在AWS FSx for Windows文件服务器文件系统创建一个亚马逊FSx并设置活动目录域进行身份验证。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Windows File Server",
      "Active Directory",
      "File Storage"
    ],
    "explanation": {
      "analysis": "FSx for Windows File Server 专门设计用于在 AWS 上提供高度可用的 Windows 文件共享，并与 Active Directory 集成。",
      "why_correct": "D 选项是最佳选择。FSx for Windows File Server 提供了与 Active Directory 集成、高可用性以及 Windows 文件共享的特性，完全满足了需求。",
      "why_wrong": "A 选项，EFS 本质上是 Linux 的文件系统，不支持直接与 AD 集成。B 选项, 文件网关更适合于本地数据中心和 AWS 之间的混合存储场景。C 选项, S3 本身不是一个文件系统，不能直接安装到 Windows 服务器上，需要额外的软件桥接。"
    },
    "related_terms": [
      "EFS",
      "AWS",
      "FSx for Windows",
      "FSx",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 98,
    "topic": "",
    "question_cn": "一家图像处理公司有一个网络应用程序，用户可以用来上传图像。应用程序将图像上传到一个亚马逊S3桶。该公司已经建立了S3事件通知，将对象创建事件发布到一个亚马逊简单队列服务(SQS)标准队列。该SQS队列作为Lambda函数的事件源，该函数处理图像并通过电子邮件向用户发送结果。用户报告说他们正在接收每个上传图像的多个电子邮件。解决方案架构师确定SQS消息多次调用Lambda函数，从而产生多个电子邮件消息。 解决方案架构师应该如何用最少的操作开销来解决这个问题",
    "options_cn": {
      "A": "通过将接收机等待时间增加到30秒，在SQS队列中设置长时间轮询。",
      "B": "使用消息删除复制来丢弃重复的消息。",
      "C": "将该队列中的可见性超时提高到一个比函数超时和批处理窗口超时的总和还要大的值。",
      "D": "在处理邮件之前在读取邮件后立即修改Lambda函数以删除从该邮件队列中删除的每个消息。"
    },
    "vote_percentage": "81%",
    "tags": [
      "Amazon SQS",
      "AWS Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，通过调整可见性超时可以避免Lambda函数重复处理同一条消息。",
      "why_correct": "选项C将可见性超时设置为一个足够长的时间，以确保Lambda函数有足够的时间来处理消息并删除它。如果处理时间超过了可见性超时，消息将再次变为可见，这可以解决由于处理时间过长而导致的消息重复处理问题。",
      "why_wrong": "选项A设置长轮询，长轮询有助于减少延迟，但并不能解决消息重复的问题。选项B使用消息删除复制，这不能解决问题。选项D直接在Lambda函数中删除消息，但这样没有处理函数失败的情况。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "Amazon SQS",
      "SQS",
      "Lambda",
      "SQS",
      "Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 99,
    "topic": "",
    "question_cn": "一个公司正在为一个游戏应用程序实现共享存储解决方案，该应用程序在一个内部数据中心中托管。该公司需要能够使用光纤通道客户端访问数据。解决办法必须得到充分管理。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个存储网关文件网关。创建一个使用所需客户端协议的文件共享，将应用程序服务器连接到文件共享",
      "B": "创建一个亚马逊EC2 Windows实例。在实例中安装和配置文件共享角色，将应用程序服务器连接到文件共享",
      "C": "创建一个亚马逊弹性文件系统（EFS）并配置它以支持光纤通道。将文件系统连接到应用程序服务器。",
      "D": "为光纤通道文件系统创建一个亚马逊FSx。将文件系统连接到应用程序服务器。"
    },
    "vote_percentage": "94%",
    "tags": [
      "FSx for Lustre",
      "File Storage",
      "High Performance Computing (HPC)"
    ],
    "explanation": {
      "analysis": "FSx for Lustre 是专为高性能计算场景设计的，支持光纤通道协议。",
      "why_correct": "D 选项是最佳选择。FSx for Lustre 专为高性能、计算密集型工作负载设计，并且支持光纤通道访问，满足了游戏应用程序的需求。",
      "why_wrong": "A 选项, 存储网关文件网关不支持光纤通道。B 选项, EC2 Windows 实例需要手动管理和配置，且不支持光纤通道。C 选项, EFS 本身不支持光纤通道。"
    },
    "related_terms": [
      "存储网关",
      "EFS",
      "FSx"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 100,
    "topic": "",
    "question_cn": "公司的集装箱化应用程序运行在亚马逊EC2实例上。应用程序在与其他业务应用程序通信之前需要下载安全证书。该公司希望有一个高度安全的解决方案在近实时加密和解密证书。解决方案还需要在数据加密后将数据存储在高可用性存储中。 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "为加密证书创建IAM机密管理员机密。根据需要手动更新证书。使用细粒度 IAM 访问控制对数据的访问。",
      "B": "创建一个Lambda函数，该函数使用Bcrypt密码库接收和执行加密操作。该功能存储在一个亚马逊S3桶。",
      "C": "创建一个密钥管理服务(KMS)客户管理密钥。允许IAM角色使用KMS键进行加密操作。在亚马逊S3上存储加密数据。",
      "D": "创建一个密钥管理服务(KMS)客户管理密钥。允许IAM角色使用KMS键进行加密操作。在亚马逊弹性块存储(EBS)卷上存储加密数据。"
    },
    "vote_percentage": "79%",
    "tags": [
      "AWS KMS",
      "Amazon S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，C提供了高安全性和高可用性存储的组合。",
      "why_correct": "选项C 使用 AWS KMS 客户管理密钥来加密证书，并使用 S3 存储加密后的数据，这提供了高度的安全性，并满足了高可用性的需求。 KMS 提供了密钥的集中管理和控制，并且 S3 提供了高可用性和耐用性。",
      "why_wrong": "选项A 使用 IAM 机密，管理起来复杂，并且没有高可用性。选项B 使用 Lambda 和 Bcrypt，安全性较低，并且维护成本较高。选项D使用 EBS 存储加密数据，EBS 卷的可用性低于S3，并且管理成本较高。"
    },
    "related_terms": [
      "EC2",
      "IAM",
      "KMS",
      "KMS",
      "EBS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 101,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个具有公共和私有子网络的VPC。VPC和子网使用IPv4CIDR块。对于高可用性，在三个可用性区中，每个区都有一个公共子网和一个私有子网。使用互联网网关为公共子网络提供互联网接入。私有子网络需要访问互联网以允许亚马逊EC2实例下载软件更新。解决方案架构师应该做什么来为私有子网络启用互联网接入？",
    "options_cn": {
      "A": "创建三个NAT网关，每个可用性区中每个公共子网一个。为每个NAT网关创建一个专用路由表，将非NAT流量转发到其所在的NAT网关。",
      "B": "创建三个NAT实例，每个可用性区中每个私有子网一个。为每个NAT实例创建一个专用路由表，将非NAT流量转发到其所在的NAT实例。",
      "C": "在其中一个私有子网上创建第二个互联网网关。更新将非互联网流量转发到私人互联网网关的私有子网的路由表。",
      "D": "在其中一个公共子网络上创建一个仅限电子数据的因特网网关。更新那些将非互联网流量转发到只使用电子数据的因特网网关的私有子网的路由表。"
    },
    "vote_percentage": "98%",
    "tags": [
      "VPC",
      "NAT Gateway",
      "Internet Access"
    ],
    "explanation": {
      "analysis": "使用 NAT 网关允许私有子网中的实例访问互联网，同时保留私有 IP 地址。",
      "why_correct": "A 选项是最佳解决方案。使用 NAT 网关可以在每个可用性区中提供高可用性，并且允许多个私有子网共享一个 NAT 网关，从而简化了网络配置。",
      "why_wrong": "B 选项使用 NAT 实例，需要手动管理，并增加了复杂性。 C 选项在私有子网中创建互联网网关是错误的。D 选项，互联网网关和流量的配置是错误的。"
    },
    "related_terms": [
      "VPC",
      "IPv4 CIDR",
      "Internet Gateway",
      "NAT 网关",
      "NAT 实例",
      "路由表",
      "VPC 端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 102,
    "topic": "",
    "question_cn": "一家公司想将一个内部数据中心迁移到AWS。数据中心拥有一个SFTP服务器，该服务器将其数据存储在基于NFS的文件系统上，该文件系统需要迁移200GB的数据。服务器必须在使用亚马逊弹性文件系统(EFS)的亚马逊EC2实例上托管。 解决方案架构师应该采取哪些步骤来自动化这个任务 选二。",
    "options_cn": {
      "A": "将EC2实例启动到与EFS文件系统相同的可用性区域。",
      "B": "在酒店内的数据中心安装一个AWS数据合成代理。",
      "C": "为数据在EC2实例上创建一个二级亚马逊弹性块存储(EBS)卷。",
      "D": "手动使用操作系统复制命令将数据推到EC2实例。",
      "E": "使用AWS SFTP服务为现场的SFTP服务器创建合适的位置配置。"
    },
    "vote_percentage": "55%",
    "tags": [
      "AWS DataSync",
      "Amazon EFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AB，但社区共识(投票最高)为BE。社区倾向BE的原因是，BE使用了DataSync实现数据的安全高效迁移，同时满足SFTP需求。",
      "why_correct": "选项B 在数据中心安装AWS DataSync代理，用于数据的迁移。选项E 使用AWS SFTP服务，并配置一个DataSync的位置配置，用于现场 SFTP 服务器的数据传输。 这两个选项结合起来，提供了一个自动化和安全的解决方案来将数据从SFTP服务器迁移到AWS云端。",
      "why_wrong": "选项A 在同一AZ启动EC2实例，并不能实现数据的迁移，只是满足了EC2的部署需求。选项C创建EBS卷不能迁移NFS数据。选项D使用操作系统复制命令，需要手动操作，不符合自动化要求。"
    },
    "related_terms": [
      "EC2",
      "EFS",
      "AWS DataSync",
      "EBS",
      "SFTP",
      "AWS SFTP"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 103,
    "topic": "",
    "question_cn": "一个公司有一个Glue提取、转换和负载（ETL）作业，每天在同一时间运行。作业处理位于亚马逊S3桶中的XML数据。新数据每天都被添加到S3桶中。解决方案架构师注意到 Glue 在每次运行中处理所有数据。解决方案架构师应该做些什么来防止Glue对旧数据进行再处理？",
    "options_cn": {
      "A": "编辑工作以使用工作书签。",
      "B": "在处理数据后编辑作业以删除数据。",
      "C": "编辑工作将员工的数量设置为1。",
      "D": "使用搜索匹配机器学习转换。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Glue",
      "ETL",
      "Job Bookmarks"
    ],
    "explanation": {
      "analysis": "Glue 工作书签可以跟踪已处理的数据，防止对旧数据进行重复处理。",
      "why_correct": "A 选项是正确的。使用 Glue 工作书签可以跟踪 Glue 作业已处理过的数据。当作业下次运行时，它将只处理新数据，从而避免了重复处理。",
      "why_wrong": "B 选项不推荐，因为删除数据可能会导致数据丢失。C 选项调整工作人员数量并不能解决重复处理数据的问题。D 选项，机器学习转换和本问题无关。"
    },
    "related_terms": [
      "Glue",
      "S3",
      "ETL",
      "工作书签"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 104,
    "topic": "",
    "question_cn": "解决方案架构师必须为网站设计一个非常可用的基础设施。该网站由运行在亚马逊EC2实例上的网络服务器提供动力。解决方案架构师必须实现一种解决方案，这种解决方案可以缓解源于成千上万个 IP 地址的大规模 DDoS 攻击。该网站不能接受停机时间。解决方案架构师应该采取哪些行动来保护网站免受这种攻击？（选二）",
    "options_cn": {
      "A": "使用AWS Shield Advanced来阻止DDoS攻击。",
      "B": "配置亚马逊护卫任务自动阻止攻击者。",
      "C": "为静态和动态内容配置网站以使用亚马逊云端。",
      "D": "使用Lambda函数自动向VPC网络添加攻击者的IP地址。",
      "E": "在具有目标跟踪扩展策略的自动扩展组中使用EC2点实例，该策略设置为80%CPU利用率。"
    },
    "vote_percentage": "87%",
    "tags": [
      "DDoS Protection",
      "AWS Shield",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "AWS Shield Advanced 和 CloudFront 结合使用，可以有效地缓解 DDoS 攻击，提高网站可用性。",
      "why_correct": "A 和 C 是正确的。A 选项 使用 AWS Shield Advanced 提供了针对大规模 DDoS 攻击的保护。C 选项，使用 Amazon CloudFront，可以缓存静态和动态内容，从而减少对源服务器的负载，并提供了额外的安全保护层。",
      "why_wrong": "B 选项，AWS WAF 并不直接提供针对 DDoS 攻击的保护。D 选项，使用 Lambda 函数自动阻止 IP 地址，操作复杂，容易出错，且效果有限。E 选项 使用 EC2 Spot 实例，并不能有效阻止 DDoS 攻击。"
    },
    "related_terms": [
      "EC2",
      "DDoS",
      "AWS Shield Advanced",
      "CloudFront",
      "Lambda",
      "VPC",
      "自动扩展组",
      "EC2 点实例"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 105,
    "topic": "",
    "question_cn": "一个公司正在准备部署一个新的无服务器工作量。解决方案架构师必须使用最小权限原则来配置权限，这些权限将被用于运行Lambda函数。一个亚马逊事件桥（Amazon EventBridge）规则将调用该函数。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将一个执行角色添加到使用Lambda函数的角色中，将lambda:*作为操作，作为主体。",
      "B": "将一个执行角色添加到有lambda函数的角色中，将lambda:InvokeFunction作为动作和服务，作为主体。",
      "C": "在该职能中加入一项基于资源的政策，由lambda公司负责，作为动作和服务。",
      "D": "将基于资源的政策加入到有lambda函数中，以调用函数作为动作和服务EventBridge。"
    },
    "vote_percentage": "97%",
    "tags": [
      "IAM",
      "Lambda",
      "EventBridge",
      "Least Privilege"
    ],
    "explanation": {
      "analysis": "基于资源的策略允许其他 AWS 服务调用 Lambda 函数。应该使用最少的权限原则。",
      "why_correct": "D 选项是最佳选择。使用基于资源的策略允许 EventBridge 调用 Lambda 函数。该策略应该仅允许 EventBridge 调用 Lambda 函数，从而遵循最小权限原则。",
      "why_wrong": "A 选项，使用lambda:*作为操作，权限过大，违反了最小权限原则。B 选项, 权限不足，EventBridge无法调用 Lambda。C 选项，将策略添加到函数本身，策略配置错误，无法正常工作。"
    },
    "related_terms": [
      "Lambda",
      "Amazon EventBridge",
      "IAM"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 106,
    "topic": "",
    "question_cn": "一家公司正准备在 Amazon S3 上存储机密数据。出于遵从性原因，数据必须在静态时加密。为了审计目的，必须记录加密密钥的使用情况。密钥必须每年轮换一次。哪个解决方案满足这些要求，且操作最有效？",
    "options_cn": {
      "A": "使用客户提供密钥的服务器端加密 (SSE-C)",
      "B": "使用 Amazon 托管密钥的 S3 服务器端加密 (SSE-S3)",
      "C": "手动轮换的服务器端加密",
      "D": "使用具有自动轮换密钥的 AWS KMS (SSE-KMS) 的服务器端加密"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3 Encryption",
      "AWS KMS"
    ],
    "explanation": {
      "analysis": "该题考察如何在 S3 上加密数据，满足合规性、审计和密钥轮换的要求。",
      "why_correct": "D 选项使用 AWS KMS (SSE-KMS) 进行服务器端加密，密钥由 KMS 托管，并支持自动轮换，满足了所有要求。",
      "why_wrong": "A 选项 (SSE-C) 需要用户管理密钥，不便于审计和轮换；B 选项 (SSE-S3) 使用 Amazon 托管的密钥，但不支持密钥轮换；C 选项手动轮换无法自动化，增加运维成本。"
    },
    "related_terms": [
      "S3",
      "SSE-C",
      "SSE-S3",
      "KMS",
      "SSE-KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 107,
    "topic": "",
    "question_cn": "一家自行车共享公司正在开发一种多层结构以跟踪其自行车在高峰运行时间的位置。该公司希望在现有的分析平台中使用这些数据API点。解决方案架构师必须确定支持这个架构的最可行的多层选项。数据点必须可以从其他API访问。 哪个操作满足这些存储和检索位置数据的要求",
    "options_cn": {
      "A": "使用亚马逊S3与亚马逊Athena。",
      "B": "使用亚马逊API网关与Lambda。",
      "C": "使用亚马逊快速视觉与亚马逊红移。",
      "D": "使用亚马逊API网关与亚马逊运动数据分析。"
    },
    "vote_percentage": "50%",
    "tags": [
      "Amazon API Gateway",
      "AWS Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，B提供了API端点、Lambda处理，满足数据存储和检索需求。",
      "why_correct": "选项B使用Amazon API Gateway创建API端点，方便其他API访问数据。Lambda函数可以处理数据存储和检索逻辑。这个方案满足了存储和检索位置数据的要求。",
      "why_wrong": "选项A使用S3和Athena，Athena不适合实时数据查询。选项C使用QuickSight和Redshift，QuickSight是可视化工具，Redshift是数据仓库，不适用于存储和检索。选项D使用API网关和Kinesis Data Analytics，并不完全适合存储和检索。"
    },
    "related_terms": [
      "S3",
      "Athena",
      "API Gateway",
      "Lambda",
      "快速视觉",
      "红移",
      "运动数据分析"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 108,
    "topic": "",
    "question_cn": "一家公司有一个汽车销售网站在亚马逊RDS数据库中存储其上市信息。销售汽车时需要从网站上删除清单数据，必须发送到多个目标系统。 解决方案架构师应该推荐哪种设计",
    "options_cn": {
      "A": "当RDS上的数据库被更新以将信息发送到一个亚马逊简单队列服务(SQS)亚马逊队列以供目标使用时创建一个Lambda函数。",
      "B": "当RDS上的数据库被更新后创建一个Lambda函数，将信息发送到亚马逊简单队列服务(SQS)队列中以便目标使用。",
      "C": "订阅RDS事件通知并发送一个SNS主题展开到多个SNS主题。使用Lambda函数更新目标。",
      "D": "订阅RDS事件通知并发送一个SNS主题展开到多个SQS队列。使用Lambda函数更新目标。"
    },
    "vote_percentage": "63%",
    "tags": [
      "Amazon RDS",
      "Amazon SQS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A通过SQS实现了更好的消息传递可靠性。",
      "why_correct": "选项A使用SQS来处理消息，这提供了更好的消息传递可靠性。Lambda 函数通过读取SQS 队列来处理删除事件，并将信息发送到多个目标系统， 即使目标系统暂时不可用，消息也会保留在 SQS 队列中。",
      "why_wrong": "选项C使用SNS，SNS消息传递不如SQS可靠。 选项B没有使用SNS，降低了扩展性，且可靠性较低。选项D订阅RDS事件通知并发送一个SNS主题展开到多个SQS队列。使用Lambda函数更新目标，这同样不如选项A好。"
    },
    "related_terms": [
      "RDS",
      "SQS",
      "Lambda",
      "SNS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 109,
    "topic": "",
    "question_cn": "一家公司需要在 Amazon S3 中存储数据，并且必须防止数据被更改。该公司希望上传到 Amazon S3 的新对象在非特定的时间段内保持不变，直到公司决定修改这些对象。只有在公司的账户中的特定用户才能拥有删除对象的能力。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个 S3 冰川 (Glacier) 拱顶。对对象应用写过一次、读过的 (WORM) 保险库锁策略。",
      "B": "使用对象锁为 S3 创建一个存储桶。启用版本控制。规定保留期为 100 年。使用治理模式作为新对象的存储桶默认保留模式。",
      "C": "创建一个 S3 存储桶。使用 CloudTrail 跟踪修改对象的任何事件。通知后，从公司拥有的任何备份版本中还原修改的对象。",
      "D": "使用对象锁为 S3 创建一个存储桶。启用版本控制。对物体加一个合法的持有权。添加对需要删除对象的用户的 IAM 策略授予许可。"
    },
    "vote_percentage": "76%",
    "tags": [
      "S3 Object Lock",
      "S3 Versioning",
      "IAM"
    ],
    "explanation": {
      "analysis": "本题考察如何使用 S3 对象锁实现数据的不可变性和控制删除权限。",
      "why_correct": "D 选项使用对象锁和合法持有，可以防止对象被删除，并使用 IAM 策略控制删除权限，满足了所有要求。",
      "why_wrong": "A 选项针对 Glacier 存储，不适用本题场景；B 选项使用治理模式，但没有控制删除权限；C 选项使用 CloudTrail 监控，无法阻止数据被更改。"
    },
    "related_terms": [
      "S3",
      "Glacier",
      "WORM",
      "IAM",
      "CloudTrail"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 110,
    "topic": "",
    "question_cn": "一家社交媒体公司允许用户将图片上传到其网站。网站运行在 Amazon EC2 实例上。在上传请求期间，网站将图像调整到标准大小，并在 Amazon S3 中存储调整大小的图像。用户正在经历向网站上传请求的缓慢过程。公司需要减少应用中的耦合，提高网站性能。解决方案架构师必须设计最有效的图像上传操作流程。解决方案架构师应该采取哪些行动组合来满足这些需求？（选二）",
    "options_cn": {
      "A": "配置应用程序将图像上传到 Glacier。",
      "B": "配置 Web 服务器将原始图像上传到 Amazon S3。",
      "C": "配置应用程序通过使用预先签名的 URL 直接从每个用户的浏览器将图像上传到 Amazon S3。",
      "D": "配置 S3 事件通知，以便在上传图像时调用 Lambda 函数。使用该函数调整图像的大小。",
      "E": "创建一个 Amazon EventBridge 规则，该规则调用一个 Lambda 函数的时间表，以调整上传的图像的大小。"
    },
    "vote_percentage": "52%",
    "tags": [
      "S3 Pre-signed URLs",
      "Lambda",
      "S3 Event Notifications"
    ],
    "explanation": {
      "analysis": "本题考察如何优化图像上传流程，提高性能和解耦。",
      "why_correct": "B 和 D 选项：B 选项让用户直接上传原始图像到 S3，减轻了 EC2 的负载；D 选项使用 S3 事件通知和 Lambda 函数，在上传后进行图像大小调整，实现了异步处理。这些方案减少了 EC2 的工作量，提高了效率。",
      "why_wrong": "A 选项将图像上传到 Glacier，不适用于即时处理；C 选项没有实际图片处理操作；E 选项使用 EventBridge 定时任务，无法及时处理上传。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "Glacier",
      "预先签名的 URL",
      "Lambda",
      "Amazon EventBridge"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 111,
    "topic": "",
    "question_cn": "一家公司最近将一个消息处理系统迁移到了 AWS。系统将消息接收到运行在 Amazon EC2 实例上的活动 MQ 队列中。消息由运行在 Amazon EC2 上的消费者应用程序处理。消费者应用程序处理消息并将结果写入在 Amazon RDS 上运行的 MySQL 数据库。该公司希望这个应用程序能以低的操作复杂性获得高可用性。哪个架构提供最高可用性？",
    "options_cn": {
      "A": "将第二个活动 MQ 服务器添加到另一个可用区。在另一个可用区中添加一个额外的消费者实例。将 MySQL 数据库复制到另一个可用区。",
      "B": "使用通过两个可用区配置的活动/备用经纪人的 Amazon MQ。在另一个可用区中添加一个额外的消费者实例。将 MySQL 数据库复制到另一个可用区。",
      "C": "使用通过两个可用区配置的活动/备用经纪人的 Amazon MQ。在另一个可用区中添加一个额外的消费者实例。将 Amazon RDS 用于具有多个可用区的 MySQL 数据库。",
      "D": "使用通过两个可用区配置的活动/备用经纪人的 Amazon MQ。在两个可用区域中为消费者实例添加一个自动伸缩组。将 Amazon RDS 用于具有多个可用区的 MySQL 数据库。"
    },
    "vote_percentage": "98%",
    "tags": [
      "MQ High Availability",
      "EC2 Auto Scaling",
      "RDS Multi-AZ"
    ],
    "explanation": {
      "analysis": "本题考察如何设计一个具有高可用性的消息处理系统。",
      "why_correct": "D 选项：使用 MQ 活动/备用 Broker，EC2 消费者实例使用自动伸缩组，RDS 使用多可用区部署。提供了 MQ、消费者和数据库的多可用区部署，实现了高可用性。",
      "why_wrong": "A 选项仅在单个 MQ 服务器上进行故障转移，可用性较低；B 选项和 C 选项虽然使用多可用区，但缺乏对消费者实例的弹性伸缩支持，并且消费者数量过少，无法应对峰值负载。"
    },
    "related_terms": [
      "EC2",
      "Amazon MQ",
      "RDS",
      "MySQL",
      "可用区"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 112,
    "topic": "",
    "question_cn": "一家公司在一个由内部服务器组成的团队中拥有一个容器化的 Web 应用程序，以处理传入的请求。请求的数量正在迅速增加。内部服务器无法处理越来越多的请求。该公司希望通过最小的代码更改和最小的开发工作将应用程序转移到 AWS。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在 Amazon Elastic Container Service (ECS) 上使用 Fargate 运行服务的、自动伸缩的容器化应用程序。使用 Application Load Balancer (ALB) 分配传入的请求。",
      "B": "使用两个 Amazon EC2 实例来托管容器化的应用程序。使用 ALB 分配传入的请求。",
      "C": "使用支持语言之一的新代码创建多个 Lambda 函数来支持负载。使用 Amazon API Gateway 作为一个入口点的 Lambda 功能。",
      "D": "使用高性能计算 (HPC) 解决方案（如并行集群）来建立一个 HPC 集群，可以在适当的规模上处理传入的请求。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS Fargate",
      "ALB",
      "Containerization"
    ],
    "explanation": {
      "analysis": "本题考察如何将容器化应用程序迁移到 AWS，并实现自动伸缩。",
      "why_correct": "A 选项使用 ECS Fargate，无需管理底层服务器，自动伸缩，减少了运维开销，能够满足负载增加的需求。",
      "why_wrong": "B 选项需要管理 EC2 实例，增加了运维负担，且手动配置伸缩不够灵活；C 选项需要重写代码，工作量大；D 选项是 HPC 解决方案，不适用于 Web 应用程序。"
    },
    "related_terms": [
      "ECS",
      "Fargate",
      "ALB",
      "EC2",
      "Lambda",
      "API Gateway",
      "HPC"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 113,
    "topic": "",
    "question_cn": "一家公司使用 50 TB 的数据进行报告。该公司希望将这些数据从公司内部转移到 AWS。公司数据中心的一个定制应用程序，每周运行一个数据转换作业。该公司计划暂停应用程序，直到数据传输完成，并需要尽快启动传输过程。数据中心没有任何可用的网络带宽用于额外的工作负载。解决方案架构师必须传输数据，并且必须配置转换作业以继续在云中运行。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS DataSync 来移动数据。使用 Glue 创建自定义转换作业。",
      "B": "订购一个 AWS Snowcone 设备来移动数据。将转换应用程序部署到设备上。",
      "C": "订购一个 AWS Snowball Edge 存储优化设备。将数据拷贝到设备上。使用 Glue 创建自定义转换作业。",
      "D": "订购一个 AWS Snowball Edge 存储优化设备，包括 Amazon EC2 计算。把数据拷贝到设备上。在 EC2 上创建一个新的实例来运行转换应用程序。"
    },
    "vote_percentage": "71%",
    "tags": [
      "Snowball Edge",
      "AWS Glue",
      "Data Transfer"
    ],
    "explanation": {
      "analysis": "本题考察如何将大量数据传输到 AWS，并进行数据转换。",
      "why_correct": "C 选项使用 Snowball Edge，可以进行离线数据传输，解决了网络带宽不足的问题。并使用 Glue 进行自定义转换作业，降低了运维成本。",
      "why_wrong": "A 选项使用 DataSync，需要网络带宽，不适用于当前场景；B 选项 Snowcone 存储容量较小，不适用于 50 TB 数据量；D 选项使用 Snowball Edge 和 EC2，增加了运维复杂性，且成本较高。"
    },
    "related_terms": [
      "AWS DataSync",
      "Glue",
      "AWS Snowcone",
      "AWS Snowball Edge",
      "EC2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 114,
    "topic": "",
    "question_cn": "一家公司已经创建了一个图像分析应用程序，用户可以上传照片并在图片中添加相框。用户上传图片和元数据以显示他们想在图片中EC2添加哪些照片帧。应用程序使用一个亚马逊EC2实例和亚马逊发电机来存储元数据。该应用程序越来越受欢迎，用户数量也在增加。该公司预计并发用户的数量会因日、周的时间而有很大差异。公司必须确保应用程序 能够适应不断增长的用户群的需求。 这些要求有哪些解决方法",
    "options_cn": {
      "A": "使用Lambda处理照片。将照片和元数据存储在发电机中。",
      "B": "使用亚马逊动态数据消防软管处理照片和存储照片和元数据。",
      "C": "使用Lambda处理照片。把照片放在亚马逊S3上。保留发电机来存储元数据。",
      "D": "将EC2实例增加到3个。使用提供的EBS卷存储照片和元数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Lambda",
      "Amazon S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，C使用了Lambda、S3和DynamoDB，实现了可扩展性和成本效益。",
      "why_correct": "选项C将照片存储在S3中，将元数据存储在DynamoDB中，并使用Lambda处理照片，这是一个可扩展且具有成本效益的架构。S3可以处理大量的图像存储，Lambda可以根据需求自动扩展，DynamoDB提供了灵活的元数据存储。",
      "why_wrong": "选项A将照片和元数据都存储在DynamoDB中，成本较高，不适合存储大量的照片。选项B使用Kinesis Data Firehose处理照片和存储照片和元数据，虽然可以满足需求，但不如Lambda+S3+DynamoDB的方案灵活。选项D增加EC2实例数量，不能很好地扩展，成本也高，EBS的性能会成为瓶颈。"
    },
    "related_terms": [
      "EC2",
      "Lambda",
      "S3",
      "DynamoDB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 115,
    "topic": "",
    "question_cn": "一家医疗记录公司正在使用 Amazon EC2 应用程序。应用程序处理存储在 Amazon S3 上的客户数据文件。EC2 实例在公共子网中托管。EC2 实例通过互联网访问 Amazon S3，但他们不需要任何其他网络访问。一项新的要求规定文件传输的网络流量采用私有路径，而不是通过互联网发送。解决方案架构师应该推荐哪些改变来满足这个需求？",
    "options_cn": {
      "A": "创建一个 NAT 网关。为公共子网配置路由表，以便通过 NAT 网关将流量发送到 Amazon S3。",
      "B": "配置 EC2 实例的安全组，以限制出站流量，从而只允许到 S3 前缀列表的流量。",
      "C": "将 EC2 实例移动到私有子网。为 Amazon S3 创建一个 VPC 端点，并为私有子网将端点链接到路由表。",
      "D": "从 VPC 中移除互联网网关。建立一个 Direct Connect 连接，并通过 Direct Connect 连接将流量路由到 Amazon S3。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3 Private Access",
      "Security"
    ],
    "explanation": {
      "analysis": "本题考察如何保护 EC2 实例到 S3 的数据传输，使用私有路径，避免通过互联网。",
      "why_correct": "C 选项使用 S3 VPC 端点，允许 EC2 实例在私有子网中直接访问 S3，流量不会经过互联网，提高了安全性。",
      "why_wrong": "A 选项使用 NAT 网关，流量仍然需要经过互联网网关，不符合要求；B 选项限制了安全组的出站流量，但无法阻止通过互联网访问 S3；D 选项使用 Direct Connect，增加了成本和复杂度，且不适用于此题场景。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "NAT 网关",
      "VPC 端点",
      "Direct Connect"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 116,
    "topic": "",
    "question_cn": "一家公司在其公司网站上使用流行的内容管理系统。然而，所需的修补和维护是繁重的。该公司正在重新设计其网站，并希望有新的解决方案。网站将每年更新四次，不需要提供任何动态内容。解决方案必须提供高的可伸缩性和增强的安全性。哪些变化组合将以最少的操作开销满足这些需求？（选二）",
    "options_cn": {
      "A": "在网站前配置 Amazon CloudFront，以使用 HTTPS 功能。",
      "B": "在网站前部署一个 AWS WAF，以提供 HTTPS 功能。",
      "C": "创建并部署一个 Lambda 函数来管理和服务网站内容。",
      "D": "创建新网站和一个 Amazon S3 存储桶。在存储桶上部署网站并启用静态网站托管。",
      "E": "创建新网站。通过在应用负载均衡器后面使用 Amazon EC2 实例的自动伸缩组来部署网站。"
    },
    "vote_percentage": "85%",
    "tags": [
      "S3 Static Website",
      "CloudFront",
      "WAF",
      "Security"
    ],
    "explanation": {
      "analysis": "本题考察如何设计一个静态网站，提供高可伸缩性和安全性，并减少运维开销。",
      "why_correct": "A 和 D 选项：A 选项使用 CloudFront 作为 CDN，可以提供 HTTPS 加密，提高安全性，同时加速内容分发；D 选项使用 S3 静态网站托管，易于部署，并提供高可伸缩性。这些方案实现了低运维成本、高可用性和安全性。",
      "why_wrong": "B 选项使用 AWS WAF 提供安全防护，功能重复，且不是必需；C 选项使用 Lambda 管理和维护静态内容，增加了复杂性，不符合题目要求；E 选项使用 EC2 和 ALB，增加了运维成本，不适用于静态网站。"
    },
    "related_terms": [
      "CloudFront",
      "HTTPS",
      "AWS WAF",
      "Lambda",
      "Amazon S3",
      "EC2",
      "ALB"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 117,
    "topic": "",
    "question_cn": "一家公司将其应用程序日志存储在亚马逊 CloudWatch 日志组中。一项新政策要求该公司在 Amazon OpenSearch Service（亚马逊弹性搜索服务）中几 乎实时地存储所有应用日志。用最少的操作开销来满足这个需求的解决方案是什么？",
    "options_cn": {
      "A": "配置 CloudWatch 日志订阅将日志流到 Amazon OpenSearch Service（亚马逊弹性搜索服务）。",
      "B": "创建一个Lambda函数。使用日志组调用函数将日志写入 Amazon OpenSearch Service（亚马逊弹性搜索服务）。",
      "C": "创建一个 Amazon Kinesis Data Firehose 传递流。将日志组配置为传递流源。将 Amazon OpenSearch Service（亚马逊弹性搜索服务）配置为传递流的目的地。",
      "D": "在每个应用服务器上安装和配置 Amazon CloudWatch 代理，将日志传送到 Amazon CloudWatch Logs。配置动态数据流将日志传递到 Amazon OpenSearch Service（亚马逊弹性搜索服务）。"
    },
    "vote_percentage": "69%",
    "tags": [
      "CloudWatch Logs",
      "Amazon OpenSearch Service"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用CloudWatch日志订阅直接将日志转发到OpenSearch Service，最简单，开销最小。",
      "why_correct": "选项 A 使用 CloudWatch 日志订阅直接将日志流式传输到 Amazon OpenSearch Service，这是最直接且运营开销最小的解决方案。",
      "why_wrong": "选项 B 涉及Lambda函数，增加了复杂性和运营开销。选项 C 使用 Kinesis Data Firehose，虽然可行，但比直接订阅更复杂。选项 D 需要在服务器上安装代理，增加了维护成本。"
    },
    "related_terms": [
      "CloudWatch",
      "OpenSearch Service",
      "Lambda",
      "Kinesis Data Firehose",
      "Amazon CloudWatch 代理"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 118,
    "topic": "",
    "question_cn": "一家公司正在建立一个基于 Web 的应用程序，在多个可用区中运行在 Amazon EC2 实例上。Web 应用程序将提供访问总计约 900 TB 的文本文件库的机会。该公司预计 Web 应用程序将经历高需求时期。解决方案架构师必须确保文本文档的存储组件能够随时进行规模化，以满足应用程序的需求。公司对解决方案的整体成本表示担忧？哪种存储方案最符合这些要求？",
    "options_cn": {
      "A": "Amazon EBS (Elastic Block Store) 卷",
      "B": "Amazon EFS (Elastic File System)",
      "C": "Amazon OpenSearch Service（Amazon Elasticsearch Service）",
      "D": "Amazon S3"
    },
    "vote_percentage": "96%",
    "tags": [
      "S3",
      "Scalability",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "本题考察如何选择存储方案，以存储大量静态文件，并满足可伸缩性和成本要求。",
      "why_correct": "D 选项使用 S3 存储，可以存储大量数据，提供高可用性和可伸缩性，且成本相对较低，最符合要求。",
      "why_wrong": "A 选项 EBS 主要用于 EC2 实例的存储，不适用于大量静态文件的存储；B 选项 EFS 主要用于共享文件系统，性能和成本不如 S3；C 选项 OpenSearch Service 适用于日志分析和搜索，不适用于存储文本文件。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "EFS",
      "OpenSearch Service",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 119,
    "topic": "",
    "question_cn": "一家全球性的公司正在使用 Amazon API Gateway 为其忠诚俱乐部用户设计 API，该 API 位于美国东部 1 号地区和美国东南部 2 号地区。解决方案架构师必须设计一个解决方案以保护这些 API 网关管理的 API 跨多个帐户免受注入和跨站点脚本攻击。用最少的行政努力来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "在这两个地区都建立 Amazon ACLs。将区域性网络与 API 阶段联系起来。",
      "B": "在两个区域都建立 AWS WAF 防火墙管理器。集中配置 WAF 规则。",
      "C": "在两个区域设置 API 防护罩。将区域性网络与 API 阶段联系起来。",
      "D": "在其中的一个区域设置一个 API 保护罩。将区域性网络与 API 阶段联系起来。"
    },
    "vote_percentage": "69%",
    "tags": [
      "API Gateway",
      "AWS WAF"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是使用WAF防火墙管理器进行集中配置，减少了管理工作量。",
      "why_correct": "选项 B 建议使用 AWS WAF 防火墙管理器，可以集中配置 WAF 规则，从而简化管理并保护 API 免受注入和跨站点脚本攻击。",
      "why_wrong": "选项 A 涉及 ACLs (访问控制列表)，这无法全面防御 Web 应用程序攻击。选项 C 和 D 缺乏明确的措施来保护 API 免受攻击。"
    },
    "related_terms": [
      "API Gateway",
      "WAF",
      "ACLs",
      "AWS WAF",
      "API 防护罩"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 120,
    "topic": "",
    "question_cn": "一家公司已经在美国西部 1 号地区的一个网络负载均衡器背后的三个 Amazon EC2 实例上实现了一个自我管理的 DNS 解决方案。该公司的大多数用户位于美国和欧洲。公司希望改进解决方案的性能和可用性。该公司在欧盟西部 2 号区域推出并配置了三个 EC2 实例并将 EC2 实例作为新的网络负载均衡器的目标。该公司可以使用哪种解决方案将流量路由到所有 EC2 实例？",
    "options_cn": {
      "A": "创建一个 Amazon Route 53 地理定位路由策略将请求路由到两个 NLBs 中的一个。创建 Amazon CloudFront 分布。使用 A 记录作为销售来源。",
      "B": "创建一个标准加速器在美国全球加速器。在美国西部和欧盟西部创建端点组。添加两个 NLBs 作为端点组的端点。",
      "C": "将弹性 IP 地址附加到 6 个 EC2 实例。创建 Amazon Route 53 地理定位路由策略将请求路由到 6 个 EC2 实例中的一个。创建 Amazon CloudFront 分布。使用 A 记录作为销售来源。",
      "D": "用两个应用负载均衡器替换两个 NLBs。创建一个 Amazon Route 53 延迟路由策略将请求路由到两个选项中的一个。创建 Amazon CloudFront 分布。使用 A 记录作为销售来源。"
    },
    "vote_percentage": "75%",
    "tags": [
      "Route 53",
      "Global Accelerator"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是使用Global Accelerator，能够加速流量到不同region的endpoint，优化延迟。",
      "why_correct": "选项 B 使用 AWS Global Accelerator，可以加速流量到不同区域的 EC2 实例，从而优化延迟和可用性，尤其对于全球用户来说。同时减少延迟，提高性能和可用性。",
      "why_wrong": "选项 A 仅使用 Route 53 地理定位路由，并不能实现全局加速。选项 C 增加了复杂性，并且没有提供明确的性能优势。选项 D 使用了延迟路由策略，但没有解决全球加速的问题。"
    },
    "related_terms": [
      "EC2",
      "网络负载均衡器",
      "Route 53",
      "CloudFront",
      "全球加速器",
      "NLB",
      "弹性 IP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 121,
    "topic": "",
    "question_cn": "一家公司正在运行一个在线事务处理工作负载。此工作负载在多可用区部署中使用未加密的 RDS 数据库实例。每天都会对该实例进行数据库快照。解决方案架构师应该怎么做来确保数据库和快照总是加密的？",
    "options_cn": {
      "A": "加密最新快照的副本。通过恢复加密快照替换现有的数据库实例。",
      "B": "创建一个新的加密 EBS 卷并将快照复制到它。启用数据库实例的加密。",
      "C": "复制数据库快照并使用 AWS KMS 启用加密，将加密快照还原到现有实例。",
      "D": "将快照复制到使用 KMS 管理密钥的服务器端加密的 S3 存储桶中。"
    },
    "vote_percentage": "83%",
    "tags": [
      "RDS Encryption",
      "KMS Integration"
    ],
    "explanation": {
      "analysis": "该题考察了如何确保 RDS 数据库及其快照的加密。关键在于使用 AWS KMS 和加密快照的恢复。",
      "why_correct": "选项 A 通过加密快照副本，并在替换现有数据库实例时使用加密快照，确保了数据库和快照的加密。这是最佳实践，能够保障数据的安全性和合规性。",
      "why_wrong": "选项 B 仅加密了 EBS 卷，并未涉及到快照的加密，无法满足需求。选项 C 描述的流程不完整，且容易出错。选项 D 虽然使用了 KMS 和 S3，但没有涉及到数据库的加密和恢复，不符合题意。"
    },
    "related_terms": [
      "RDS",
      "快照/Snapshot",
      "KMS",
      "EBS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 122,
    "topic": "",
    "question_cn": "一家公司希望建立一个可伸缩的密钥管理基础设施，以支持需要在其应用程序中加密数据的开发人员。解决方案架构师应该怎么做来减少运营负担？",
    "options_cn": {
      "A": "使用多因素身份验证 (MFA) 来保护加密密钥。",
      "B": "使用 AWS KMS 来保护加密密钥。",
      "C": "使用 AWS 证书管理器 (ACM) 创建、存储和分配加密密钥。",
      "D": "使用 IAM 策略限制拥有访问权限的用户的权限以保护加密密钥。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS KMS",
      "Key Management"
    ],
    "explanation": {
      "analysis": "本题考察如何通过 AWS KMS 简化密钥管理，减轻运营负担。",
      "why_correct": "选项 B 使用 AWS KMS 可以集中管理加密密钥，减少了开发人员手动管理密钥的工作，降低了运营负担。AWS KMS 提供了密钥的创建、存储、轮换等功能，简化了密钥管理流程。",
      "why_wrong": "选项 A 描述的 MFA 是一种安全措施，但不能直接降低密钥管理的运营负担。选项 C 使用 ACM 用于证书管理，与密钥管理不符。选项 D 中，IAM 策略是安全措施，但不能直接减少运营负担。"
    },
    "related_terms": [
      "KMS",
      "MFA",
      "ACM",
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 123,
    "topic": "",
    "question_cn": "一家公司在两个 EC2 实例上有一个动态的 Web 应用程序。公司有自己的 SSL 证书，并在每个实例上执行 SSL 终止。最近流量增加，运营团队确定加密和解密正在导致服务器的计算能力达到最大限度。解决方案架构师应该如何提高应用程序的性能？",
    "options_cn": {
      "A": "使用 AWS 证书管理器 (ACM) 创建一个新的 SSL 证书。在每个实例上安装证书。",
      "B": "创建一个 S3 存储桶，将 SSL 证书迁移到该存储桶。配置 EC2 实例以引用 S3 桶以进行 SSL 终止。",
      "C": "创建另一个 EC2 实例作为代理服务器。将证书迁移到新实例并将其配置为直接连接到现有的 EC2 实例。",
      "D": "将 SSL 证书导入 ACM。使用使用 ACM 证书的 HTTPS 侦听器创建应用程序负载均衡器 (ALB)。"
    },
    "vote_percentage": "96%",
    "tags": [
      "ALB",
      "ACM",
      "SSL Offload"
    ],
    "explanation": {
      "analysis": "此题考察如何通过 SSL 卸载提高应用程序性能。最佳实践是使用 ALB 和 ACM。",
      "why_correct": "选项 D 通过使用 ALB 和 ACM 进行 SSL 终止，可以卸载 EC2 实例上的 SSL 处理负载，从而提高应用程序的性能。ALB 负责处理 SSL 握手和解密，减轻了后端 EC2 实例的负担。",
      "why_wrong": "选项 A 仍然需要在每个 EC2 实例上安装证书，没有解决性能瓶颈。选项 B 中 EC2 直接引用 S3 桶进行 SSL 终止不可行，S3 不提供 SSL 终止功能。选项 C 增加了额外的中间服务器，增加了复杂性，且未解决性能问题。"
    },
    "related_terms": [
      "SSL",
      "ACM",
      "EC2",
      "S3",
      "HTTPS",
      "ALB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 124,
    "topic": "",
    "question_cn": "一家公司有一个高度动态的批处理工作，使用许多 EC2 实例来完成它。这项工作本质上是无状态的，可以在任何时间启动和停止，通常需要 60 分钟以上的时间才能完成，且没有负面影响。该公司已经请解决方案设计师设计一个可伸缩的、符合工作要求的成本效益高的解决方案。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "实施 EC2 Spot 实例。",
      "B": "购买 EC2 保留实例。",
      "C": "实施 EC2 按需实例。",
      "D": "实施对 SQS 的加工。"
    },
    "vote_percentage": null,
    "tags": [
      "EC2 Spot Instances",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "此题考察如何为无状态、可中断的批处理任务选择经济高效的 EC2 实例类型。Spot 实例是最优选择。",
      "why_correct": "选项 A 实施 EC2 Spot 实例是最佳选择。Spot 实例提供剩余的 EC2 计算能力，可以显着降低成本，尤其适用于可中断的任务。由于任务无状态，中断不会造成负面影响。",
      "why_wrong": "选项 B 保留实例用于长期稳定的工作负载，不适用于动态批处理任务。选项 C 按需实例成本较高，不符合成本效益要求。选项 D SQS 用于异步消息传递，与批处理任务的计算需求不符。"
    },
    "related_terms": [
      "EC2",
      "EC2 Spot 实例",
      "EC2 保留实例",
      "EC2 按需实例",
      "SQS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 125,
    "topic": "",
    "question_cn": "一家公司运行其两级电子商务网站的美国世界银行。Web 层由负载平衡器组成，它将流量发送到 Amazon EC2 实例。数据库层使用 Amazon RDS 数据库实例。EC2 实例和 RDS 数据库实例不应公开于公共互联网。EC2 实例要求通过互联网接入完成通过第三方服务处理订单的付款。应用程序必须是高度可用的。哪些配置选项组合将满足这些要求？（选二）",
    "options_cn": {
      "A": "使用自动缩放组在私有子网络中启动 EC2 实例。在私有子网中部署一个多 AZ RDS 数据库实例。",
      "B": "配置跨两个可用性区域的两个私有子网和两个 NAT 网关的 VPC。在私有子网中部署应用程序负载平衡器。",
      "C": "使用自动缩放组在两个可用性区的公共子网络中启动 EC2 实例。在私有子网中部署一个多 AZ RDS 数据库实例。",
      "D": "配置一个 VPC，其中包括两个公共子网络、两个私有子网络和两个跨两个可用性区域的 NAT 网关。在公共子网络中部署应用程序负载平衡器。"
    },
    "vote_percentage": "61%",
    "tags": [
      "VPC",
      "RDS",
      "EC2",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CE，但社区共识(投票最高)为AD。社区倾向AD的原因是，在私有子网部署EC2和RDS，实现安全隔离；同时使用NAT Gateway让EC2可以访问外部网络。",
      "why_correct": "选项 A 和 D 共同提供了满足要求的解决方案。A 在私有子网中使用自动缩放组启动 EC2 实例和多 AZ RDS 数据库实例，确保了高可用性和安全性。D 配置 VPC，包括公共和私有子网，并使用 NAT 网关允许 EC2 实例通过互联网访问，用于处理第三方支付，同时保证了数据库的隔离。这两个选项结合起来满足了安全性、高可用性和访问外部服务的需求。",
      "why_wrong": "选项 B 中，在私有子网中使用应用程序负载均衡器，不满足通过互联网访问的需求。选项 C 在公共子网中启动 EC2 实例，这违背了实例不公开于公共互联网的要求。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "VPC",
      "Auto Scaling",
      "NAT 网关",
      "私有子网",
      "ALB"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 126,
    "topic": "",
    "question_cn": "解决方案架构师需要实现解决方案以降低公司的 S3 存储成本。该公司的所有数据都在 S3 标准存储级别。公司必须保存所有数据至少 25 年。最近两年的数据必须是高度可用的并可立即检索。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "立即建立 S3 生命周期策略，将对象转移到 S3 Glacier Deep Archive。",
      "B": "建立 S3 生命周期策略，在两年后将对象转移到 S3 Glacier Deep Archive。",
      "C": "使用 S3 智能分层。启动归档选项以确保数据在 S3 Glacier Deep Archive 中存档。",
      "D": "建立一个 S3 生命周期策略，将对象立即过渡到 S3 标准 - IA 存储类，并在两年后过渡到 S3 Glacier Deep Archive。"
    },
    "vote_percentage": "79%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "本题考察如何使用 S3 生命周期策略和存储类来优化存储成本，同时满足数据可用性和保留期限的要求。",
      "why_correct": "选项 B 是最佳选择。它满足了数据 25 年的保留期要求，并且在两年内保持数据的高可用性和即时检索，随后转移到更低成本的 S3 Glacier Deep Archive 存储类。",
      "why_wrong": "选项 A 不符合最近两年需要高可用性的要求，直接转移到 S3 Glacier Deep Archive，检索成本高。选项 C 使用智能分层无法满足 2 年内高可用性的要求。选项 D 将数据立即转移到 S3 标准 - IA，而不是两年后，可能导致不必要的费用，且不满足两年内高可用性的要求。"
    },
    "related_terms": [
      "S3",
      "S3 Glacier Deep Archive",
      "S3 生命周期策略",
      "S3 标准 - IA",
      "S3 智能分层"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 127,
    "topic": "",
    "question_cn": "一家媒体公司正在评估是否有可能将其系统迁移到 AWS 云。该公司需要至少 10 个具有最大可能的视频处理性能的存储区，300 个非常耐用的存储区用于存储媒体内容以及 900 个存储区以满足不再使用的档案媒体的需求。解决方案架构师应该推荐哪些服务来满足这些需求？",
    "options_cn": {
      "A": "Amazon EBS（最大性能）、Amazon S3（持久数据存储）和 Amazon Glacier（档案存储）。",
      "B": "Amazon EBS（最高性能）、Amazon EFS（持久数据存储）和 Amazon Glacier（档案存储）。",
      "C": "Amazon EC2 实例存储（最大性能）、Amazon EFS（持久数据存储）和 Amazon S3（档案存储）。",
      "D": "Amazon EC2 实例存储（最大性能）、Amazon S3（持久数据存储）和 Amazon Glacier（档案存储）。"
    },
    "vote_percentage": "62%",
    "tags": [
      "Amazon EBS",
      "Amazon S3",
      "Amazon Glacier",
      "Amazon EC2 Instance Store"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是：EC2实例存储提供最高性能，S3提供持久化存储，Glacier提供归档存储，最符合题目要求。",
      "why_correct": "选项 D 提供了正确的服务组合：Amazon EC2 实例存储（用于最大性能），Amazon S3（用于持久数据存储），和 Amazon Glacier（用于档案存储），满足了对不同存储性能和成本的需求。",
      "why_wrong": "选项 A 使用 Amazon EBS 作为最大性能的存储，这不如 EC2 实例存储。选项 B 使用 Amazon EFS 作为持久数据存储，这并非最经济的选择。选项 C 虽然使用了 EC2 实例存储，但是用了EFS,也不是最优解。"
    },
    "related_terms": [
      "EBS",
      "S3",
      "Glacier",
      "EC2 实例存储",
      "EFS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 128,
    "topic": "",
    "question_cn": "一家公司希望在 AWS 云中的容器中运行应用程序。这些应用程序是无状态的，可以容忍底层基础结构内的干扰。公司需要一个能最大限度地降低成本和运营成本的解决方案。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "在 Amazon EC2 自动缩放组中使用 Spot 实例运行应用程序容器。",
      "B": "在 Amazon Elastic Kubernetes Service (EKS) 亚马逊管理的节点组中使用 Spot 实例。",
      "C": "在 Amazon EC2 自动缩放组中使用按需实例运行应用程序容器。",
      "D": "在 Amazon Elastic Kubernetes Service (EKS) 亚马逊管理的节点组中使用按需实例。"
    },
    "vote_percentage": "72%",
    "tags": [
      "Amazon EC2",
      "Amazon EKS",
      "Spot Instances"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是使用EKS和Spot实例，可以有效降低成本，同时EKS能够简化容器的编排和管理。",
      "why_correct": "选项 B 建议在 Amazon EKS 中使用 Spot 实例，这提供了成本效益，Spot 实例可以显著降低计算成本，而 EKS 则简化了容器的编排和管理。",
      "why_wrong": "选项 A 仅使用 EC2 Spot 实例，在没有 EKS 的情况下，增加了管理容器的复杂性。选项 C 使用按需实例，这增加了成本。选项 D 使用 EKS，但使用按需实例，也增加了成本。"
    },
    "related_terms": [
      "Spot 实例",
      "EC2",
      "EKS",
      "Fargate"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 129,
    "topic": "",
    "question_cn": "一家公司正在内部运行一个多层 Web 应用程序。应用程序是容器化的，运行在连接到包含用户记录的后 SQL 数据库的一些 Linux 主机上。维护基础设施和能力规划的运营成本限制了公司的发展。解决方案架构师必须改进应用程序的基础设施。解决方案架构师应该采取哪些行动组合来实现这个目标？（选择两项）",
    "options_cn": {
      "A": "将 SQL 数据库移到 Amazon Aurora 数据库。",
      "B": "将 Web 应用程序迁移到亚马逊 EC2 实例上。",
      "C": "为 Web 应用程序内容建立一个亚马逊云端分发。",
      "D": "在 Web 应用程序和后 SQL 数据库之间建立亚马逊弹性负载均衡器。",
      "E": "将托管的 Web 应用程序迁移到亚马逊弹性容器服务 (ECS)。"
    },
    "vote_percentage": "97%",
    "tags": [
      "Microservices",
      "Database Optimization",
      "ECS",
      "Aurora"
    ],
    "explanation": {
      "analysis": "此题考察如何通过现代化、云原生设计，优化现有 Web 应用程序的架构，降低运营成本。",
      "why_correct": "选项 A 和 E 是最佳选择。选项 A 将数据库迁移到 Aurora 可以提高性能、可用性和可扩展性，同时降低运营成本。选项 E 将应用程序迁移到 ECS，利用容器编排和托管服务，简化了部署和管理。两者都减轻了运营负担，降低了成本。",
      "why_wrong": "选项 B 迁移到 EC2 实例并没有解决运营成本高的问题，反而可能增加维护成本。选项 C 亚马逊云端分发 (CloudFront) 主要用于 CDN，不直接解决运营成本问题。选项 D 建立负载均衡器是很好的实践，但是对降低运营成本的贡献有限。"
    },
    "related_terms": [
      "Aurora",
      "EC2",
      "CloudFront",
      "ELB",
      "ECS"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 130,
    "topic": "",
    "question_cn": "一个应用程序在多个可用区中的 EC2 实例上运行。实例运行在应用程序负载均衡器后面的 EC2 自动伸缩组中。当 CPU 利用率达到或接近 40% 时，应用程序的性能最好。解决方案架构师应该做什么来维护团队中所有实例的预期性能？",
    "options_cn": {
      "A": "使用简单的缩放策略来动态地缩放自动缩放组。",
      "B": "使用目标跟踪策略动态扩展自动伸缩组。",
      "C": "使用 AWS Lambda 函数更新所需的自动缩放组容量。",
      "D": "使用预定的缩放操作来扩大和缩小自动伸缩组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Target Tracking",
      "Performance Optimization"
    ],
    "explanation": {
      "analysis": "本题考察如何使用自动伸缩策略来根据应用程序的 CPU 利用率进行动态扩缩容，从而维护应用程序的性能。",
      "why_correct": "选项 B 使用目标跟踪策略是最佳选择。目标跟踪策略可以根据指定的指标（如 CPU 利用率）自动调整自动伸缩组的容量，以保持指标接近目标值，从而确保应用程序的性能。",
      "why_wrong": "选项 A 简单的缩放策略可能无法根据实际负载进行精确的扩缩容。选项 C 使用 Lambda 函数来更新容量，较为复杂，且不够灵活。选项 D 预定的缩放操作无法动态响应负载变化。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 131,
    "topic": "",
    "question_cn": "一家公司正在开发一个文件共享应用程序，该应用程序将使用 S3 存储桶进行存储。该公司希望通过 Amazon CloudFront 分发服务所有文件。该公司不希望通过 S3 URL 的直接导航来访问这些文件。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "为每个 S3 存储桶编写单独的策略，以授予只对 CloudFront 访问的读取权限。",
      "B": "创建一个 IAM 用户。授予用户对 S3 桶中对象的读取权限。将用户分配到 CloudFront。",
      "C": "编写一个 S3 存储桶策略，将 CloudFront 分配 ID 指定为主体，并将目标 S3 存储桶指定为亚马逊资源名称 (ARN)。",
      "D": "创建原点访问身份 (OAI)。指定 OAI 作为 CloudFront 分配。配置 S3 存储桶权限，使只有 OAI 有读取权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "OAI",
      "S3 Security"
    ],
    "explanation": {
      "analysis": "本题考察如何通过 CloudFront 和 OAI 实现 S3 存储桶的安全访问控制，确保用户只能通过 CloudFront 访问 S3 中的对象。",
      "why_correct": "选项 D 是最佳选择。创建 OAI，并将其与 CloudFront 分配关联。然后，配置 S3 存储桶权限，仅允许 OAI 访问。这样，用户只能通过 CloudFront 访问 S3 对象，而无法直接通过 S3 URL 访问。",
      "why_wrong": "选项 A 过于复杂，需要为每个桶编写单独的策略。选项 B 没有解决禁止直接访问 S3 URL 的问题。选项 C 使用 ARN 作为主体，会使得权限过于开放，不安全。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "IAM",
      "OAI",
      "ARN"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 132,
    "topic": "",
    "question_cn": "公司网站为用户提供可下载的历史业绩报告。该网站需要一个解决方案以满足公司网站的全球需求。解决办法应具有成本效益，限制基础设施资源的提供，并提供尽可能快的响应时间。解决方案架构师应该推荐哪些组合来满足这些需求？",
    "options_cn": {
      "A": "S3 和 Amazon CloudFront",
      "B": "Lambda 和 DynamoDB",
      "C": "EC2 和 Amazon 应用程序负载均衡器",
      "D": "S3 和带有内部应用程序负载均衡器的 Amazon Route 53"
    },
    "vote_percentage": "95%",
    "tags": [
      "S3",
      "CloudFront",
      "Global Distribution",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "本题考察如何为静态内容分发选择经济高效的解决方案，以满足全球用户的需求，并提供快速的响应时间。",
      "why_correct": "选项 A 是最佳选择。S3 存储桶用于存储报告，CloudFront 用于在全球范围内缓存和分发这些报告。这种组合具有成本效益，可以最大限度地减少延迟，并满足全球用户的需求。",
      "why_wrong": "选项 B Lambda 和 DynamoDB 主要用于构建无服务器应用程序和存储动态数据，不适合静态内容的全球分发。选项 C EC2 和 ALB 涉及服务器的维护，成本相对较高，且不如 CloudFront 更适合全球分发。选项 D 使用内部 ALB 不利于全球分发，不能提供最佳的响应时间。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "Lambda",
      "DynamoDB",
      "EC2",
      "ALB",
      "Route 53"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 133,
    "topic": "",
    "question_cn": "一家公司在内部运行甲骨文数据库。作为该公司迁移到 AWS 的一部分，该公司希望将数据库升级到最新的可用版本。该公司还希望为数据库建立灾难恢复系统。公司需要最小化正常操作和安装的运营开销。该公司还需要维护对数据库基础操作系统的访问。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将甲骨文数据库迁移到 Amazon EC2 实例。建立数据库复制到不同的 AWS 区域。",
      "B": "将甲骨文数据库迁移到 Amazon RDS。激活跨区域自动备份以便将快照复制到另一个 AWS 区域。",
      "C": "将甲骨文数据库迁移到 Amazon RDS for Oracle。在另一个 AWS 区域中为数据库创建一个读副本。",
      "D": "将甲骨文数据库迁移到 Amazon RDS。在另一个可用性区域创建一个备用数据库。"
    },
    "vote_percentage": "49%",
    "tags": [
      "Amazon RDS",
      "Oracle",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是， RDS for Oracle 读副本可以减少延迟，而且运维负担也小。",
      "why_correct": "选项 C 提供了一个理想的解决方案，将数据库迁移到 Amazon RDS for Oracle，可以简化数据库的管理，并且通过创建读副本实现灾难恢复，可以减少延迟。 这也减少了运营开销。",
      "why_wrong": "选项 A 涉及 Amazon EC2 实例，增加了管理数据库的复杂性，需要手动管理数据库和操作系统。选项 B 增加了恢复时间目标，因为备份和恢复通常比较慢。选项 D 在另一个可用区域创建一个备用数据库，虽然提供了灾难恢复，但是不具备读写功能，增加了成本。"
    },
    "related_terms": [
      "EC2",
      "Aurora",
      "RDS",
      "RDS for Oracle",
      "跨区域备份"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 134,
    "topic": "",
    "question_cn": "一家公司希望将其应用转移到无服务器解决方案。无服务器解决方案需要使用 Amazon S3 分析现有数据和新数据。该公司将数据存储在一个 Amazon S3 桶中。数据需要加密，必须复制到不同的 AWS 区域。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个新的 S3 桶。将数据加载到新的 S3 桶中。使用 S3 跨区域复制（CRR）复制加密对象到另一个区域的 S3 桶。使用服务器端加 AWS KMS 的多区域 KMS（SSE-KMS）加密。使用 Amazon Athena 查询数据。",
      "B": "创建一个新的 S3 桶。将数据加载到新的 S3 桶中。使用 S3 跨区域复制（CRR）复制加密对象到另一个区域的 S3 桶。使用服务器端加密与 AWS KMS（SSE-KMS）和多区域 KMS 密钥。使用 Amazon RDS 查询数据。",
      "C": "将数据装载到现有的 S3 桶中。使用 S3 跨区域复制（CRR）复制加密对象到另一个区域的 S3 桶。使用 Amazon 托管加密密钥的服务器端加密（SSE-S3）。使用 Amazon Athena 查询数据。",
      "D": "将数据装载到现有的 S3 桶中。使用 S3 跨区域复制（CRR）复制加密对象到另一个区域的 S3 桶。使用 Amazon 托管加密密钥（SSE-S3）的服务器端加密。使用 Amazon RDS 查询数据。"
    },
    "vote_percentage": "52%",
    "tags": [
      "Amazon S3",
      "S3 Cross-Region Replication",
      "Amazon Athena",
      "SSE-S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，使用SSE-S3是S3的默认加密方式，最简单。并且使用Athena分析数据最合适。",
      "why_correct": "选项 C 提供了最直接的解决方案。使用现有的 S3 桶，通过跨区域复制 (CRR) 实现跨区域的数据复制，使用 SSE-S3 进行服务器端加密，并使用 Amazon Athena 进行数据查询。SSE-S3 是 S3 的默认加密方式，简单易用，Athena 适用于分析存储在 S3 中的数据。",
      "why_wrong": "选项 A 使用了多区域 KMS (SSE-KMS)，增加了复杂性。选项 B 使用 Amazon RDS 查询数据，这不适合直接查询 S3 中的数据。选项 D 使用 Amazon RDS 查询数据,并且没有利用 SSE-S3."
    },
    "related_terms": [
      "S3",
      "S3 桶",
      "AWS KMS",
      "S3 跨区域复制",
      "Athena",
      "SSE-KMS",
      "RDS",
      "SSE-S3"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 135,
    "topic": "",
    "question_cn": "一家公司运行的工作负载在美国世界银行的 VPC 中。公司需要从外部供应商连接到服务，该服务在供应商的 VPC 中托管。据该公司的安全团队说，VPC 连接必须是私有的，必须限于目标服务，并且连接必须仅从公司的 VPC 启动。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在公司的 VPC 和供应商的 VPC 之间创建一个 VPC 对等连接。更新路由表以连接到目标服务。",
      "B": "请提供者在其 VPC 中创建虚拟专用网关。使用 AWS PrivateLink 连接到目标服务。",
      "C": "在该公司的公共子网中创建一个 NAT 网关并将路由表与目标服务连接起来。",
      "D": "请提供者为目标服务创建一个 VPC 终端节点。使用 AWS PrivateLink 连接到目标服务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "PrivateLink",
      "VPC Endpoint",
      "Security"
    ],
    "explanation": {
      "analysis": "本题考察了如何在 VPC 中安全地连接到外部服务，满足私有连接、仅限目标服务和单向发起连接的安全要求。",
      "why_correct": "选项 D 是最佳选择。通过使用 PrivateLink 连接到由提供者提供的 VPC 终端节点，可以创建私有连接，仅限于目标服务。 终端节点是私有访问的，并且连接由公司 VPC 发起。这样可以满足安全团队的所有要求。",
      "why_wrong": "选项 A VPC 对等连接不保证连接仅限于目标服务，且双向通信。选项 B 虚拟专用网关是 VPN 的一部分，不是私有连接。选项 C NAT 网关用于连接到 Internet，不满足私有连接的要求。"
    },
    "related_terms": [
      "VPC",
      "VPC 对等连接",
      "NAT 网关",
      "AWS PrivateLink",
      "VPC 终端节点"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 136,
    "topic": "",
    "question_cn": "一家公司正在将其网站内的 PostgreSQL 数据库迁移到 Amazon Aurora PostgreSQL。房地内的数据库必须保持在线，并在迁移期间可以查阅。Aurora 数据库必须与现场数据库保持同步。解决方案架构师必须采取哪些行动组合才能满足这些需求？（选二）",
    "options_cn": {
      "A": "创建一个持续的复制任务。",
      "B": "创建一个数据库备份的内部数据库。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 创建一个数据库迁移服务复制服务器。",
      "D": "使用 AWS Schema Conversion Tool (AWS SCT) 转换数据库架构。",
      "E": "创建一个 Amazon EventBridge（亚马逊云观察事件）规则来监视数据库同步。"
    },
    "vote_percentage": "91%",
    "tags": [
      "AWS DMS",
      "AWS SCT",
      "Amazon Aurora",
      "Database Migration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CD，但社区共识(投票最高)为AC。社区倾向AC的原因是，使用DMS实现持续同步，以及持续的复制任务，能够保证数据库同步。",
      "why_correct": "选项 A 和 C 提供了满足需求的组合。使用 AWS DMS 创建一个数据库迁移服务复制服务器（选项 C），可以实现数据库的迁移，选项 A 创建持续的复制任务，可以保证Aurora数据库和本地数据库的同步。",
      "why_wrong": "选项 B 仅创建数据库备份，不能满足同步需求。选项 D 使用 AWS SCT 仅用于数据库模式转换，不能保证数据同步。选项 E 仅用于监视数据库同步，但并不能解决迁移和同步问题。"
    },
    "related_terms": [
      "PostgreSQL",
      "Aurora PostgreSQL",
      "AWS DMS",
      "AWS SCT",
      "EventBridge",
      "数据库备份",
      "复制任务"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 137,
    "topic": "",
    "question_cn": "一家公司利用美国职业介绍所的组织为每个业务单位创建专门的 AWS 账户，根据请求独立管理每个业务单位的帐户。根电子邮件接收者错过了发送给一个帐户的根用户电子邮件地址的通知。该公司希望确保所有未来的通知不会被遗漏。未来的通知必须限于帐户管理员。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置公司的电子邮件服务器将发送到 AWS 账户根用户的电子邮件地址的通知邮件转发给组织中的所有用户。",
      "B": "将所有 AWS 账户根用户的电子邮件地址配置为发送列表发送到几个能够响应警报的管理员。在 AWS 组织控制台或编程方式中配置 AWS 账户备用联系人。",
      "C": "配置所有 AWS 账户根用户电子邮件发送给一个管理员，他负责监控警报并将这些警报转发给适当的组。",
      "D": "配置所有现有的 AWS 账户和所有新创建的账户以使用相同的根用户电子邮件地址。在 AWS 组织控制台或编程方式中配置 AWS 账户备用联系人。"
    },
    "vote_percentage": "89%",
    "tags": [
      "AWS Organizations",
      "Account Recovery",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用备用联系人，配置管理员接收警报，能够满足要求。",
      "why_correct": "选项 B 提供了最全面的解决方案：将所有 AWS 账户根用户的电子邮件地址配置为发送列表，将警报发送给管理员，并在 AWS 组织中配置备用联系人，这可以确保通知不会被遗漏，并且由合适的管理员负责。",
      "why_wrong": "选项 A 会将通知转发给组织中的所有用户，这不符合“仅限于帐户管理员”的要求。选项 C 依赖于单个管理员，增加了单点故障风险。选项 D 使用相同的根用户电子邮件地址，如果该邮箱无法访问，则会失败。"
    },
    "related_terms": [
      "AWS",
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 138,
    "topic": "",
    "question_cn": "一家公司在 Amazon EC2 上运行其电子商务应用程序。每一个新订单都作为消息发布到 Amazon MQ 上的 RabbitMQ 队列中，该队列位于一个可用区中的 EC2 实例中。这些消息由运行在单独的 EC2 实例上的不同应用程序处理。这个应用程序在另一个 EC2 实例上的数据库中存储细节。所有实例都位于同一可用区。该公司需要重新设计其架构以提供最高可用性和最少的运营开销。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将 MQ 队列迁移到 Amazon MQ 上的冗余对（活动-备用）RabbitMQ 实例。为托管应用程序的 EC2 实例创建一个多可用区 Auto Scaling 组。为托管数据库的 EC2 实例创建另一个多可用区 Auto Scaling 组。",
      "B": "将 MQ 队列迁移到 Amazon MQ 上的冗余对（活动-备用）RabbitMQ 实例。为托管应用程序的 EC2 实例创建一个多可用区 Auto Scaling 组。将数据库迁移到 Amazon RDS 多可用区部署。",
      "C": "创建托管 RabbitMQ 队列的 EC2 实例的多可用区 Auto Scaling 组。为托管应用程序的 EC2 实例创建另一个多可用区 Auto Scaling 组。将数据库迁移到 Amazon RDS 多可用区部署。",
      "D": "创建托管 RabbitMQ 队列的 EC2 实例的多可用区 Auto Scaling 组。为托管应用程序的 EC2 实例创建另一个多可用区 Auto Scaling 组。为托管数据库的 EC2 实例创建第三个多可用区 Auto Scaling 组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "High Availability",
      "Amazon MQ"
    ],
    "explanation": {
      "analysis": "此题考查如何设计高可用性架构，包括 Amazon MQ 和数据库。",
      "why_correct": "B 提供最高可用性。MQ 采用活动-备用模式，RDS 使用多可用区部署，保证了可用性。使用多可用区 Auto Scaling 组可以提高应用程序的可用性。",
      "why_wrong": "A 中数据库在 EC2 上运行，没有实现高可用性。C 中 RabbitMQ 队列没有高可用性。D 中数据库在 EC2 上运行，没有实现高可用性。"
    },
    "related_terms": [
      "EC2",
      "Amazon MQ",
      "RabbitMQ",
      "Auto Scaling",
      "RDS",
      "多可用区"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 139,
    "topic": "",
    "question_cn": "一个报告团队每天在 Amazon S3 桶中接收文件。报告团队每天在同一时间手动审查和复制这些文件，从最初的 S3 桶到分析 S3 桶，以便与 Amazon QuickSight 系统一起使用。更多的团队开始向初始 S3 桶发送更多的大尺寸文件。报告团队希望在文件输入初始 S3 桶时移动文件，自动分析 S3 桶。报告团队还希望使用 Lambda 函数来运行复制数据上的模式匹配代码。此外，报告团队希望将数据文件发送到 Amazon SageMaker 管道的管道中。解决方案架构师应该如何用最少的操作开销来满足这些需求？",
    "options_cn": {
      "A": "创建一个 Lambda 函数将文件复制到分析 S3 桶。为分析 S3 桶创建一个 S3 事件通知。配置 Lambda 和 SageMaker 管道作为事件通知的 S3::ObjectCreated 目的地。配置对象创建作为事件类型放置。",
      "B": "创建一个 Lambda 函数将文件复制到分析 S3 桶。配置分析 S3 桶将事件通知发送到 Amazon EventBridge。配置一个对象创建的规则 EventBridge。将 Lambda 和 SageMaker 管道作为规则的目标。",
      "C": "配置 S3 桶之间的 S3 复制。为分析 S3 桶创建一个 S3 事件通知。配置 Lambda 和 SageMaker 管道作为事件通知的目的地。配置对象创建作为事件类型放置。",
      "D": "配置 S3 桶之间的 S3 复制。配置分析 S3 桶将事件通知发送到 Amazon EventBridge。配置一个对象创建的规则 EventBridge。将 Lambda 和 SageMaker 管道作为规则的目标。"
    },
    "vote_percentage": "78%",
    "tags": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon SageMaker"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，使用S3 复制，同时配置EventBridge，能够实现自动同步，并调用Lambda和SageMaker.",
      "why_correct": "选项 D 提供了最有效的解决方案。它使用 S3 复制来实现桶之间的数据自动复制，配置 EventBridge 来触发 Lambda 函数，用于模式匹配，并将数据发送到 SageMaker 管道。通过复制和事件驱动的 Lambda，减少了手动操作，实现了自动化。",
      "why_wrong": "选项 A 仅使用 Lambda 进行文件复制，增加了复杂性。选项 B 增加了复杂性，但没有提供明确的优势。选项 C 缺少 Lambda 函数来处理模式匹配代码。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "SageMaker",
      "S3 事件通知",
      "EventBridge"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 140,
    "topic": "",
    "question_cn": "解决方案架构师需要帮助公司优化在 EC2 上运行应用程序的成本。该应用程序将使用 Amazon EC2 实例、AWS Fargate 和 Lambda 用于架构内的计算。EC2 实例将运行应用程序的数据摄入层。EC2 实例的使用将是零星的和不可预测的。在 EC2 实例上运行的工作负载可以随时中断。应用程序的前端将运行在 Fargate，而 Lambda 将服务 API 层。前端利用率和 API 层利用率在下一年将是可预测的。哪些采购选择组合将为托管该应用程序提供最具成本效益的解决方案？（选择两个。）",
    "options_cn": {
      "A": "对数据摄入层使用 Spot 实例。",
      "B": "为数据摄入层使用按需实例。",
      "C": "为前端和 API 层购买一年的计算节省计划。",
      "D": "为数据摄入层购买一年期所有预留的实例。",
      "E": "为前端和 EC2 API 层购买一个为期一年的 EC2 实例节约计划。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cost Optimization",
      "EC2 Spot Instances"
    ],
    "explanation": {
      "analysis": "此题考察如何优化 EC2、Fargate 和 Lambda 应用程序的成本。",
      "why_correct": "A 和 C 是最佳实践。由于数据摄入层的工作负载可中断，Spot 实例是最具成本效益的选择。前端和 API 层的利用率可预测，购买计算节省计划可以节省成本。",
      "why_wrong": "B 中按需实例成本较高。D 中数据摄入层不适合预留实例。E 中前端是 Fargate，不是 EC2，所以无法购买 EC2 实例节约计划。"
    },
    "related_terms": [
      "EC2",
      "AWS Fargate",
      "Lambda",
      "Spot 实例",
      "按需实例",
      "EC2 实例节约计划",
      "预留的实例"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 141,
    "topic": "",
    "question_cn": "一家公司经营一个基于网络的门户网站，向用户提供全球突发新闻、本地警报和天气更新。门户通过混合静态和动态内容向每个用户（ALS）提供个性化视图。内容是通过在应用程序负载平衡器后面的 Amazon EC2 实例上运行的服务器在 HTTPS 上提供的。该公司希望门户网站能尽快向世界各地的用户提供这些内容。解决方案架构师应该如何设计应用程序以确保所有用户的延迟时间最少？",
    "options_cn": {
      "A": "将应用程序堆栈部署在一个 AWS 区域。使用 Amazon CloudFront 服务所有静态和动态的内容，通过指定的一个起源。",
      "B": "将应用程序堆栈部署在两个 AWS 区域。使用 Amazon Route 53 延迟路由策略在最近的区域从 AWS 提供所有内容服务。",
      "C": "将应用程序堆栈部署在一个 AWS 区域。使用 Amazon CloudFront 服务静态内容。直接提供动态内容。",
      "D": "将应用程序堆栈部署在两个 AWS 区域。使用 Amazon Route 53 地理定位路由策略在最近的区域提供所有的内容。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Amazon CloudFront",
      "Latency Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，CloudFront可以缓存内容，减少全球用户的延迟，而无需部署多区域。",
      "why_correct": "选项 A 使用 Amazon CloudFront，可以缓存静态和动态内容，从而减少全球用户的延迟。 CloudFront 是一个 CDN（内容分发网络），可以从靠近用户的位置提供内容，降低延迟。",
      "why_wrong": "选项 B 涉及了多个区域，增加了复杂性，并且没有 CloudFront 的优势。选项 C 仅使用 CloudFront 服务静态内容，忽略了动态内容，无法实现最佳延迟优化。选项 D 使用了地理定位路由，但没有利用 CDN 的优势。"
    },
    "related_terms": [
      "Amazon CloudFront",
      "Route 53",
      "AWS 区域"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 142,
    "topic": "",
    "question_cn": "一家游戏公司正在设计一个高可用的架构。该应用程序运行在一个经过修改的 Linux 内核上，只支持基于 UDP 的流量。公司需要前端 IP 层来提供最佳的用户体验。该层必须具有较低的延迟时间，将流量路由到最近的边缘位置，并为进入应用程序端点提供静态 IP 地址。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "配置 Amazon Route 53 将请求转发到应用程序负载均衡器。在自动缩放应用程序中使用 ALB。",
      "B": "配置 AWS Network Load Balancer 转发请求。在应用程序的自动缩放组中使用 ALB。",
      "C": "配置 AWS Global Accelerator 向 Network Load Balancer 转发请求。在自动缩放组中使用 Amazon EC2 实例。",
      "D": "配置 Amazon API Gateway 向应用程序负载均衡器转发请求。在自动缩放组中使用 Amazon EC2 实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "考察如何设计具有低延迟和静态 IP 的游戏应用程序架构。",
      "why_correct": "C 是最佳实践。使用 Global Accelerator 可以优化 UDP 流量的延迟，并提供静态 IP。Network Load Balancer 适用于处理 UDP 流量，并且支持自动缩放。",
      "why_wrong": "A 中 Route 53 无法直接优化 UDP 流量。B 中使用 Network Load Balancer，没有提供静态 IP。D 中 API Gateway 适用于 HTTP/HTTPS，不适用于 UDP。"
    },
    "related_terms": [
      "Amazon Route 53",
      "应用程序负载均衡器",
      "AWS Network Load Balancer",
      "AWS Global Accelerator",
      "Amazon API Gateway",
      "Amazon EC2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 143,
    "topic": "",
    "question_cn": "一家公司希望将其现有的内部整体应用程序迁移到 AWS。公司希望保留尽可能多的前端代码和后端代码。然而，该公司希望将该应用程序分解为较小的应用程序。不同的团队将管理每个应用程序。该公司需要一个高度可伸缩的解决方案，最大限度地减少运营开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在 AWS Lambda 上托管应用程序。将应用程序与 Amazon API Gateway 集成。",
      "B": "在 AWS Lambda 上托管应用程序，并与 API Gateway 集成。将应用程序连接到一个 Amazon API Gateway，该网关与 ALB 集成在一起。",
      "C": "在 Amazon EC2 实例上托管应用程序。在自动缩放组中以 EC2 实例为目标建立应用程序负载均衡器。",
      "D": "在 Amazon Elastic Container Service 上部署该应用。建立一个应用程序负载均衡器以 Amazon ECS 为目标。"
    },
    "vote_percentage": "74%",
    "tags": [
      "Microservices",
      "Amazon ECS"
    ],
    "explanation": {
      "analysis": "此题考察如何将单体应用程序分解为微服务，并提高可伸缩性和减少运维成本。",
      "why_correct": "D 是最佳实践。使用 ECS 可以将应用程序容器化，简化部署和管理。ALB 可以将流量负载均衡到 ECS 任务。ECS 易于扩展，并且可以减少运维开销。",
      "why_wrong": "A 和 B 使用 Lambda 对于现有应用程序迁移，可能代码改动量较大。C 中直接使用 EC2 需要手动管理基础设施。"
    },
    "related_terms": [
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon EC2",
      "应用程序负载均衡器",
      "Amazon Elastic Container Service",
      "Amazon ECS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 144,
    "topic": "",
    "question_cn": "一家公司最近开始使用 Amazon Aurora 作为其全球电子商务应用的数据存储。当运行大型报表时，开发人员报告电子商务应用程序的性能很差。在审查了 Amazon CloudWatch 中的度量指标之后，解决方案架构师发现当月度报告运行时，CPU 利用率和 I/O 指标正在上升。最具成本效益的解决办法是什么？",
    "options_cn": {
      "A": "迁移到 Amazon Redshift 每月报告。",
      "B": "移到 Aurora 副本的每月报告。",
      "C": "将 Aurora 数据库迁移到更大的实例类。",
      "D": "在 Aurora 实例上增加已提供的 IOPS。"
    },
    "vote_percentage": "98%",
    "tags": [
      "Aurora Read Replicas",
      "Database Performance"
    ],
    "explanation": {
      "analysis": "此题考察如何优化 Aurora 数据库的性能。",
      "why_correct": "B 是最佳实践。使用 Aurora 副本可以分担读取负载，从而提高性能，且成本较低。",
      "why_wrong": "A 迁移到 Redshift 需要进行数据迁移和修改代码。C 和 D 都是增加资源，成本较高，且不一定能解决问题。"
    },
    "related_terms": [
      "Amazon Aurora",
      "Amazon CloudWatch",
      "Amazon Redshift",
      "IOPS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 145,
    "topic": "",
    "question_cn": "一家公司在一个 Amazon EC2 按需实例上拥有一个网站分析应用程序。该分析软件是用 PHP 编写的，并使用了 MySQL 数据库。分析软件、PHP Web 服务器和数据库服务器都在 EC2 实例上。该应用程序在繁忙时期显示性能下降的迹象，并呈现 5xx 错误。该公司需要使应用程序规模无缝。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon RDS for MySQL。创建一个 Web 应用程序的 AMI。使用该系统启动第二个按需实例。使用应用程序负载均衡器将负载分配到每个 EC2 实例。",
      "B": "将数据库迁移到 Amazon RDS for MySQL。创建一个 Web 应用程序的 AMI。使用该系统启动第二个按需实例。使用 Amazon Route 53 路由，加权路由分配负载在两个 EC2 实例。",
      "C": "将数据库迁移到 Amazon Aurora 实例。创建一个 Lambda 函数以停止 EC2 实例并更改实例类型。当 CPU 利用率超过 75% 时，创建一个 Amazon CloudWatch 报警器来调用 Lambda 函数。",
      "D": "将数据库迁移到 Amazon Aurora 实例。创建一个 Web 应用程序的 AMI。在一个发布模板中应用 Auto Scaling。使用发布模板创建 SPOT 自动缩放组，将发布模板配置为使用 Auto Scaling 组。将应用程序负载均衡器附加到自动缩放组上。"
    },
    "vote_percentage": "75%",
    "tags": [
      "Auto Scaling",
      "RDS MySQL"
    ],
    "explanation": {
      "analysis": "此题考察如何对网站分析应用程序进行扩展，以满足性能需求。",
      "why_correct": "D 是最佳实践。使用 Aurora 数据库可以提高数据库性能。创建 AMI 简化了实例的创建。使用 Auto Scaling 和 Spot 实例可以自动扩展应用程序，并优化成本。ALB 负责负载均衡。",
      "why_wrong": "A 和 B 中使用按需实例，成本较高，且扩展能力有限。C 中虽然使用了 Aurora，但是使用 Lambda 停止 EC2 实例并更改实例类型，过于复杂且效率低。"
    },
    "related_terms": [
      "Amazon EC2",
      "MySQL",
      "Amazon RDS",
      "PHP",
      "AMI",
      "应用程序负载均衡器",
      "Amazon Route 53",
      "Amazon Aurora",
      "Lambda",
      "Amazon CloudWatch"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 146,
    "topic": "",
    "question_cn": "一家公司在生产过程中运行一个无状态的 Web 应用程序，该应用程序在一个应用负载均衡器后面的 Amazon 按需实例组上运行。该应用程序在每 8 小时内会经历大量使用。一夜之间应用程序的使用是适度和稳定的，周末的应用程序使用率很低。该公司希望在不影响应用程序可用性的情况下尽量减少其成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "对整个工作负载使用 Spot 实例。",
      "B": "对使用的基线级别使用预留的实例。对应用程序需要的任何额外容量使用 Spot 实例。",
      "C": "对基线使用水平的按需实例。为应用程序需要的任何额外能力使用 Spot 实例。",
      "D": "使用基准使用水平的专用实例。为应用程序需要的任何额外能力使用随需应变的实例。"
    },
    "vote_percentage": "64%",
    "tags": [
      "Spot Instances",
      "Reserved Instances"
    ],
    "explanation": {
      "analysis": "此题考察如何优化 EC2 实例的成本，平衡可用性和成本。",
      "why_correct": "B 是最佳实践。使用预留实例满足稳定的基线需求，使用 Spot 实例满足峰值需求，可以最大化节省成本。",
      "why_wrong": "A 中全部使用 Spot 实例可能会因为实例中断而影响可用性。C 中使用按需实例成本较高。D 中专用实例成本高，不适用。"
    },
    "related_terms": [
      "Spot 实例",
      "预留的实例",
      "按需实例",
      "专用实例",
      "应用负载均衡器"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 147,
    "topic": "",
    "question_cn": "一个公司需要为一个关键的应用程序保留 10 年的应用程序日志文件。应用程序团队经常访问上个月的日志以进行故障诊断，但是超过一个月日志很少被访问。应用程序每月生成超过 10 TB 的日志。哪种储存选择最符合这些要求？",
    "options_cn": {
      "A": "将日志放在 Amazon S3 上。使用 AWS Backup 将超过一个月的日志移到 Glacier Deep Archive。",
      "B": "将日志放在 Amazon S3 上。使用生命周期策略将超过一个月的日志转移到 Glacier Deep Archive。",
      "C": "将这些日志保存在 Amazon CloudWatch Logs 中。使用 AWS Backup 将超过一个月的日志移到 Glacier Deep Archive。",
      "D": "将这些日志保存在 Amazon CloudWatch Logs 中。使用 Amazon S3 生命周期策略将超过一个月的日志转移到 Glacier Deep Archive。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Glacier Deep Archive"
    ],
    "explanation": {
      "analysis": "此题考察 S3 存储桶的生命周期管理，以满足长期日志存储需求。",
      "why_correct": "B 是最佳实践。使用 S3 的生命周期策略，可以将一个月以上的日志自动转移到 Glacier Deep Archive，满足成本和访问需求。",
      "why_wrong": "A 中虽然使用了 Glacier Deep Archive，但是没有使用生命周期策略，需要手动操作，运维成本高。C 中 CloudWatch Logs 存储日志不适合长期存储。D 中 CloudWatch Logs 存储日志，并且使用 S3 生命周期策略是错误的配置。"
    },
    "related_terms": [
      "Amazon S3",
      "AWS Backup",
      "Glacier Deep Archive",
      "Amazon CloudWatch Logs",
      "生命周期策略"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 148,
    "topic": "",
    "question_cn": "一家公司有一个数据摄取工作流程，包括以下组成部分：一个 Amazon Simple Notification Service (SNS) 主题接收关于新数据交付的通知，一个 AWS Lambda 函数处理和存储数据。由于网络连接问题，摄取工作流偶尔会失败。发生故障时，除非公司手动重新运行作业，否则不会接收相应数据。解决方案架构师应该如何确保最终处理所有通知？",
    "options_cn": {
      "A": "配置用于跨多个可用区部署的 Lambda 函数。",
      "B": "修改 Lambda 函数的配置以增加该函数的 CPU 和内存分配。",
      "C": "配置 SNS 主题的重试策略以增加重试次数和重试之间的等待时间。",
      "D": "配置一个 Amazon Simple Queue Service (SQS) 队列作为死信目标。修改 Lambda 函数以处理队列中的消息。"
    },
    "vote_percentage": "88%",
    "tags": [
      "SNS Retry Policy",
      "SQS Dead Letter Queue"
    ],
    "explanation": {
      "analysis": "此题考察如何保证 SNS 消息处理的可靠性，处理消息失败的情况。",
      "why_correct": "D 是最佳实践。使用 SQS 作为死信队列可以保证消息在处理失败后被重新处理。",
      "why_wrong": "A 无法解决消息处理失败的问题。B 无法根本性解决问题。C 中 SNS 重新尝试次数有限。"
    },
    "related_terms": [
      "AWS Lambda",
      "Amazon Simple Notification Service (SNS)",
      "Amazon Simple Queue Service (SQS)"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 149,
    "topic": "",
    "question_cn": "一家公司有一个生成事件数据的服务。该公司希望使用 Lambda 处理接收到的事件数据。数据是按特定顺序编写的，必须在整个处理过程中维护。该公司希望实现一种能最大限度减少运营开销的解决方案。解决方案架构师应该如何做到这一点？",
    "options_cn": {
      "A": "创建一个 Amazon SQS FIFO 队列来保存消息。设置一个 Lambda 函数来处理队列中的消息。",
      "B": "创建一个 Amazon SNS 主题以传递包含有效负载的通知进行处理。配置一个作为订阅者的 Lambda 函数。",
      "C": "创建一个 Amazon SQS 标准队列来保存消息。建立一个 Lambda 函数独立地处理队列中的消息。",
      "D": "创建一个 Amazon SNS 主题以传递包含有效负载的通知进行处理。配置一个 Amazon SQS 队列作为订阅者。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS FIFO",
      "Lambda"
    ],
    "explanation": {
      "analysis": "此题考察使用 SQS FIFO 队列和 Lambda 函数来处理需要保证顺序的消息。",
      "why_correct": "A 是最佳实践。SQS FIFO 队列可以保证消息的顺序，Lambda 函数可以处理队列中的消息。",
      "why_wrong": "B 中 SNS 无法保证消息的顺序。C 中 SQS 标准队列不能保证消息的顺序。D 中虽然使用了 SNS 和 SQS，但是 SQS 不是 FIFO 队列，无法保证消息的顺序。"
    },
    "related_terms": [
      "Amazon SQS FIFO 队列",
      "Lambda",
      "Amazon SNS",
      "SQS",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 150,
    "topic": "",
    "question_cn": "解决方案架构师需要为 EC2 实例实现基础设施指标警报。如果 CPU 利用率在短时间内提高到 50% 以上，那么公司不需要采取行动。然而，如果 CPU 利用率提高到 50% 以上，同时在磁盘上 I/O，则该公司需要尽快采取行动。解决方案架构师还必须减少错误警报。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "尽可能创建 Amazon CloudWatch 复合报警器。",
      "B": "创建 Amazon CloudWatch 仪表板以可视化的度量和快速反应问题。",
      "C": "创建 Amazon CloudWatch 合成金丝雀应用监控和报警。",
      "D": "在可能的情况下创建具有多个米制阈值的单一 Amazon CloudWatch 米制报警器。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudWatch Composite Alarms",
      "CloudWatch Metrics"
    ],
    "explanation": {
      "analysis": "考察如何使用 CloudWatch 报警，实现复杂的报警条件。",
      "why_correct": "A 是最佳实践。CloudWatch 复合报警可以组合多个指标的报警条件，实现更复杂的报警逻辑，并减少错误警报。",
      "why_wrong": "B 仅用于可视化，不能主动报警。C 用于应用程序的可用性监控，而非基础设施指标。D 无法实现多个指标的联合报警逻辑。"
    },
    "related_terms": [
      "Amazon CloudWatch",
      "CPU",
      "IO"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 151,
    "topic": "",
    "question_cn": "一家公司希望将其内部数据中心迁移到 AWS。根据该公司的合规要求，该公司只能使用东北地区。公司管理员不得将 VPC 连接到互联网。哪些解决方案能满足这些要求（选二）？",
    "options_cn": {
      "A": "使用 AWS Control Tower 实现数据驻留护栏，拒绝互联网接入和拒绝访问所有区域，除了东北地区。",
      "B": "使用 AWS WAF 的规则防止互联网接入。在账户设置中拒绝访问所有的区域，除了东北地区。",
      "C": "使用 AWS Organizations 配置服务控制策略（SCP），防止获得互联网接入。拒绝进入除东北之外的所有 AWS 区域。",
      "D": "在每个 VPC 中为网络 ACL 创建一个出站规则以拒绝 0.0.0.0/0 的所有流量。为每个用户创建一个 IAM 策略以防止使用任何区域，而不包括东北地区。",
      "E": "使用 AWS 配置来激活托管规则以检测和警报互联网网关，并检测和警报部署在东北之外的新资源。"
    },
    "vote_percentage": "78%",
    "tags": [
      "AWS Organizations",
      "Service Control Policies (SCP)"
    ],
    "explanation": {
      "analysis": "考察使用 AWS Organizations 的 SCP 和 Control Tower 来限制 AWS 资源的使用区域和访问互联网。",
      "why_correct": "A 选项使用 Control Tower 能够集中管理 AWS 环境，设置合规性和安全控制。C 选项使用 SCP 限制用户在 AWS 账户中可以执行的操作，并限制其使用的区域，满足合规需求。",
      "why_wrong": "B 选项使用 WAF，虽然可以限制访问，但无法满足禁止访问除东北地区之外的其他区域的需求。D 选项使用 NACL 和 IAM 策略，增加了运维复杂度，难以有效管理。E 选项配置检测和警报，仅限于检测，无法阻止违规操作。"
    },
    "related_terms": [
      "AWS Control Tower",
      "AWS WAF",
      "AWS Organizations",
      "VPC",
      "IAM",
      "东北区域"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 152,
    "topic": "",
    "question_cn": "一家公司使用三层网络应用程序为新员工提供培训。每天只能在 8 小时内访问该应用程序。该公司正在使用 Amazon RDS 来存储 MySQL 数据库实例的信息，并希望最小化成本。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "为 IAM 系统管理器会话管理器配置一个 IAM 策略。为该策略创建一个 IAM 角色。更新角色的信任关系。为数据库实例设置自动启动和停止。",
      "B": "为缓存集群创建一个 Amazon ElastiCache。它使用户能够在数据库实例停止时访问缓存中的数据。在数据库实例启动后使缓存无效。",
      "C": "使用 EC2 cron 启动 Amazon RDS 实例。创建一个 IAM 角色，允许访问 Amazon RDS。将角色附加到 EC2 实例。配置一个 cron 作业来启动和停止 EC2 实例在所需时间表上。",
      "D": "创建 Lambda 函数来启动和停止 RDS 实例。创建 Amazon CloudWatch 事件预定规则来调用 Lambda 函数。为规则配置 Lambda 函数作为事件目标。"
    },
    "vote_percentage": "80%",
    "tags": [
      "RDS",
      "Lambda"
    ],
    "explanation": {
      "analysis": "考察使用 Lambda 和 CloudWatch Events 自动化 RDS 实例的启动和停止，以节省成本。",
      "why_correct": "D 选项使用 Lambda 函数来启动和停止 RDS 实例，并使用 CloudWatch Events 进行定时触发，是最有效且成本最低的方案。",
      "why_wrong": "A 选项中使用 Systems Manager 会话管理器配置 IAM 策略，与启动和停止数据库实例无关，且较为复杂。B 选项中使用 ElastiCache 虽然可以提高性能，但不能解决控制 RDS 实例启停的问题。C 选项使用 EC2 cron 启动 RDS 实例，增加了运维成本和复杂性。"
    },
    "related_terms": [
      "Amazon RDS",
      "MySQL",
      "IAM",
      "EC2",
      "Amazon ElastiCache",
      "Lambda",
      "Amazon CloudWatch",
      "Amazon RDS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 153,
    "topic": "",
    "question_cn": "一家公司出售流行歌曲片段制作的铃声。含有铃声的文件存储在 Amazon S3 标准存储中，大小至少为 128KB。该公司拥有数百万个文件，但对于超过 90 天以上的铃声下载并不常见。该公司需要在存储上省钱，同时为其用户保留最容易访问的文件。公司应采取哪些行动来满足这些要求最具成本效益？",
    "options_cn": {
      "A": "将对象初始存储层配置为 S3 标准访问标准存储。",
      "B": "将文件移动到 S3 智能分层，并将其配置为在 90 天后将对象移动到费用较低的存储层。",
      "C": "配置 S3 库存以管理对象，并在 90 天后将其转移到 S3 标准 - IA 标准。",
      "D": "实施 S3 生命周期策略，在 90 天后将对象从标准移动到标准不经常访问 (Standard-IA)。"
    },
    "vote_percentage": "64%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Standard-IA"
    ],
    "explanation": {
      "analysis": "考察 S3 生命周期策略和存储类，以优化存储成本。",
      "why_correct": "D 选项使用 S3 生命周期策略，在 90 天后将文件从 S3 标准存储类移动到 S3 标准 - IA 存储类，实现成本优化。Standard-IA 存储类的存储成本比 Standard 存储类更低，适合不经常访问的数据。",
      "why_wrong": "A 选项将所有文件存储在 S3 标准存储类，无法优化成本。B 选项移动到 S3 智能分层，虽然可以优化成本，但不如直接移动到 S3 Standard-IA。C 选项配置 S3 库存，虽然可以管理对象，但不能实现成本优化。"
    },
    "related_terms": [
      "Amazon S3",
      "S3 标准存储",
      "S3 智能分层",
      "S3 标准 - IA",
      "S3 生命周期策略",
      "标准不经常访问 (Standard-IA)"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 154,
    "topic": "",
    "question_cn": "一家公司需要将医疗试验的结果保存到 Amazon S3 存储桶。存储桶必须允许一些科学家添加新文件，并且必须限制所有其他用户的只读访问。没有任何用户能够修改或删除存储桶中的任何文件。公司必须在创建日期后至少保存一年的存储桶中的每个文件。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在治理模式中使用 S3 对象锁，合法持有时间为一年。",
      "B": "使用 S3 对象锁定合规模式，保留期为 365 天。",
      "C": "使用 IAM 角色来限制所有用户删除或更改 S3 桶中的对象。使用桶策略只允许 IAM 角色。",
      "D": "配置 S3 桶以在每次添加对象时调用 Lambda 函数。将函数配置为跟踪保存对象的散列，以便相应地标记修改对象。"
    },
    "vote_percentage": "91%",
    "tags": [
      "S3 Object Lock",
      "S3 Object Versioning"
    ],
    "explanation": {
      "analysis": "考察使用 S3 对象锁定功能来实现文件的不可变性和保留期。",
      "why_correct": "B 选项使用 S3 对象锁定合规模式，保留期为 365 天，满足了文件不可变性和保存一年的需求。",
      "why_wrong": "A 选项使用治理模式，允许有权限的用户绕过保护。C 选项使用 IAM 角色和桶策略，可以限制访问，但不能确保文件的不可变性。D 选项使用 Lambda 函数跟踪散列，无法保证文件的不可变性，且增加了复杂性。"
    },
    "related_terms": [
      "S3",
      "S3 对象锁",
      "IAM",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 155,
    "topic": "",
    "question_cn": "一家大型媒体公司在 AWS 上主持一个网络应用程序。该公司希望开始缓存机密媒体文件，以便世界各地的用户能够可靠地访问这些文件。内容存储在 Amazon S3 存储桶。公司必须迅速提供内容，无论请求从哪里来。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Web 数据化方法将 S3 桶连接到应用程序。",
      "B": "部署 AWS Global Accelerator 连接 S3 桶到应用程序。",
      "C": "部署 Amazon CloudFront 连接 S3 桶到 CloudFront 边缘服务器。",
      "D": "使用 Amazon Simple Queue Service (SQS) 连接 S3 桶到应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon CloudFront",
      "Content Delivery Network (CDN)"
    ],
    "explanation": {
      "analysis": "考察使用 CloudFront 作为 CDN 来加速内容的全球分发。",
      "why_correct": "C 选项部署 CloudFront，CloudFront 是 AWS 的 CDN 服务，可以缓存内容，并从全球边缘站点提供内容，以实现快速的内容分发。",
      "why_wrong": "A 选项使用 Web 数据化方法，无法实现全球加速。B 选项使用 Global Accelerator，主要用于加速 TCP 和 UDP 流量，不适用于静态文件分发。D 选项使用 SQS，与内容分发无关。"
    },
    "related_terms": [
      "Amazon S3",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon Simple Queue Service (SQS)"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 156,
    "topic": "",
    "question_cn": "一家公司生产来自不同数据库的批处理数据。该公司还通过网络传感器和应用生成实时流数据。公司需要将所有数据整合到一个 S3 地方进行业务分析。该公司需要处理输入的数据，然后在不同的 Amazon S3 桶数据。团队随后将运行一次性查询并将数据导入业务智能工具以显示关键性能指标。哪些步骤组合将以最少的操作开销满足这些要求？（选二）",
    "options_cn": {
      "A": "使用 Amazon Athena 进行一次性查询。使用 Amazon QuickSight 创建 KPI 仪表板。",
      "B": "使用 Amazon Kinesis Data Analytics 进行一次性查询。使用 Amazon QuickSight 创建 KPI 仪表板。",
      "C": "创建自定义的 Lambda 函数将单个记录从数据库转移到 Amazon Redshift 集群。",
      "D": "使用 AWS Glue 提取、转换和加载（ETL）作业将数据转换为 JSON 格式。将数据加载到多个 Amazon OpenSearch Service 集群中。",
      "E": "使用 AWS Lake Formation 蓝图来识别可以被数据湖吸收的数据。使用 Glue 爬网源提取数据并加载数据到 Amazon S3，采用 Apache Parquet 格式。"
    },
    "vote_percentage": "89%",
    "tags": [
      "Amazon Athena",
      "Amazon S3",
      "AWS Glue",
      "AWS Lake Formation"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AC，但社区共识(投票最高)为AE。社区倾向AE的原因是，AE使用了 Athena 和 Lake Formation，能够低成本高效的实现数据分析和管理。",
      "why_correct": "选项 A 和 E 提供了最适合的解决方案。A 使用 Athena 进行一次性查询，使用 QuickSight 创建仪表板，这对于快速的数据分析和可视化非常有效。E 使用 AWS Lake Formation 和 Glue 来构建数据湖，简化了数据处理和管理，并能够进行后续的分析。 这两个选项组合起来，覆盖了数据的整合、处理、查询和可视化，且运维成本较低。",
      "why_wrong": "选项 B 使用 Kinesis Data Analytics 进行一次性查询，这对于一次性查询来说，过于复杂。选项 C 创建自定义 Lambda 函数，会增加复杂性。选项 D 使用 Glue 将数据加载到 OpenSearch，这并不直接用于业务智能分析。"
    },
    "related_terms": [
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon Kinesis Data Analytics",
      "Lambda",
      "Amazon Redshift",
      "AWS Glue",
      "Amazon OpenSearch Service",
      "AWS Lake Formation"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 157,
    "topic": "",
    "question_cn": "一家公司将数据存储在一个 Amazon Aurora PostgreSQL 数据库集群中。公司必须存储所有数据 5 年，并在 5 年后删除所有数据。公司还必须无限期地保存数据库中执行的行为的审计日志。目前该公司已自动化备份配置为 Aurora。解决方案架构师应该采取哪些步骤来满足这些需求？（选二）",
    "options_cn": {
      "A": "为 DB 集群拍摄一个手动快照。",
      "B": "为自动备份创建一个生命周期策略。",
      "C": "配置 5 年自动备份保留。",
      "D": "为数据库集群配置 Amazon CloudWatch 日志导出。",
      "E": "使用 AWS Backup 获取备份，并将备份保存 5 年。"
    },
    "vote_percentage": "78%",
    "tags": [
      "Amazon Aurora",
      "AWS Backup",
      "CloudWatch Logs"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BE，但社区共识(投票最高)为DE。社区倾向DE的原因是，DE分别处理了日志导出，以及审计日志的存储。",
      "why_correct": "选项 D 和 E 提供了最全面的解决方案。D 配置 Amazon CloudWatch 日志导出，满足了保存审计日志的需求。E 使用 AWS Backup，提供了一整套的备份管理和生命周期管理，能够设置5年的备份保存期，满足了数据保留的要求。",
      "why_wrong": "选项 A 仅创建了手动快照，不能满足长期存储需求。选项 B 仅创建了备份的生命周期策略，没有考虑到审计日志。选项 C 配置 5 年的自动备份保留，但没有考虑到审计日志。"
    },
    "related_terms": [
      "Amazon Aurora PostgreSQL",
      "Amazon CloudWatch",
      "AWS Backup",
      "自动备份"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 158,
    "topic": "",
    "question_cn": "解决方案设计师正在优化一个网站为即将到来的音乐活动。表演录像将实时播放，然后按需提供。预计这一活动将吸引全球在线受众。哪些服务可以提高实时流和点播流的性能？",
    "options_cn": {
      "A": "Amazon CloudFront",
      "B": "Global Accelerator",
      "C": "Amazon S3",
      "D": "Amazon S3 Transfer Acceleration"
    },
    "vote_percentage": "66%",
    "tags": [
      "Amazon CloudFront",
      "Content Delivery Network (CDN)"
    ],
    "explanation": {
      "analysis": "考察使用 CloudFront 来优化视频流的性能。",
      "why_correct": "A 选项 CloudFront 是一个 CDN，可以缓存视频内容，并从全球边缘站点提供内容，以实现快速的内容分发，提高性能。",
      "why_wrong": "B 选项 Global Accelerator 适用于加速 TCP 和 UDP 流量，不适用于静态视频文件的分发。C 选项 S3 用于存储视频文件，而不是加速分发。D 选项 S3 Transfer Acceleration 用于加速上传到 S3 存储桶，不适用于视频播放。"
    },
    "related_terms": [
      "Amazon CloudFront",
      "Global Accelerator",
      "Amazon S3",
      "Amazon S3 Transfer Acceleration"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 159,
    "topic": "",
    "question_cn": "一家公司正在运行一个可以公开访问的无服务器应用程序，该应用程序使用 Amazon API Gateway 和 AWS Lambda。由于僵尸网络的欺诈性请求，该应用程序的流量最近激增。解决方案架构师应该采取哪些步骤来阻止来自未授权用户的请求？（选二）",
    "options_cn": {
      "A": "使用只与真正用户共享的 API 密钥创建使用计划。",
      "B": "将逻辑整合到 Lambda 函数中，以忽略欺诈性 IP 地址的请求。",
      "C": "实现一个 AWS WAF 规则，目标恶意请求和触发行动过滤他们。",
      "D": "将现有的公共 API 转换为私有 API。更新 DNS 记录，将用户重定向到新的 API 端点。",
      "E": "为试图访问 API 的每个用户创建一个 IAM 角色。当进行 API 调用时，用户将承担这个角色。"
    },
    "vote_percentage": "67%",
    "tags": [
      "API Gateway",
      "AWS WAF",
      "AWS Lambda",
      "Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CD，但社区共识(投票最高)为AC。社区倾向AC的原因是使用API Key和WAF，能够直接实现安全防护。",
      "why_correct": "选项 A 和 C 提供了有效的解决方案组合：选项 A 使用 API 密钥和使用计划来限制对 API 的访问，并且只允许授权用户使用。选项 C 使用 AWS WAF 来识别和阻止恶意流量，WAF 规则可以过滤掉欺诈性请求，这两个方法能有效降低僵尸网络攻击。",
      "why_wrong": "选项 B 仅依赖于 Lambda 函数中的 IP 过滤，这可能会被绕过。选项 D 增加了复杂性，但不能完全解决问题。选项 E 涉及 IAM 角色，这与解决僵尸网络攻击并不直接相关。"
    },
    "related_terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "API 密钥",
      "AWS WAF",
      "私有 API",
      "IAM"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 160,
    "topic": "",
    "question_cn": "一家电子商务公司在 AWS 云中拥有其分析应用程序。该应用程序每月生成大约 300MB 的 JSON 数据。该公司正在评估一个灾难恢复解决方案以支持数据。如果需要的话，这些数据必须在毫秒内可以访问，数据必须保存 30 天。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "Amazon OpenSearch Service",
      "B": "Amazon S3 Glacier",
      "C": "Amazon S3 标准",
      "D": "Amazon RDS for PostgreSQL"
    },
    "vote_percentage": "89%",
    "tags": [
      "S3 Standard",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "考察存储方案的选择，需要快速访问、存储时间 30 天。",
      "why_correct": "C 选项 S3 标准存储类提供了高可用性和低延迟，满足毫秒级访问的需求，且可以存储 30 天。",
      "why_wrong": "A 选项 OpenSearch Service，适用于索引和搜索数据，不是最佳存储方案。B 选项 S3 Glacier 适用于长期归档，不满足毫秒级访问的需求。D 选项 RDS for PostgreSQL 是数据库服务，不适用于存储每月生成的数据。"
    },
    "related_terms": [
      "Amazon S3",
      "Amazon OpenSearch Service",
      "Amazon S3 Glacier",
      "Amazon S3 标准",
      "Amazon RDS for PostgreSQL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 161,
    "topic": "",
    "question_cn": "一家公司有一个小型 JSON SQL 应用程序可以处理文档并将结果输出到内部的数据库。应用程序每天运行几千次。该公司希望将应用程序转移到 AWS 云。该公司需要一个高度可用的解决方案，以最大限度地提高可伸缩性和最小化运营开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将 JSON 文档放在亚马逊 S3 桶中。在多个亚马逊 EC2 实例上运行比顿代码来处理文档。将结果存储在亚马逊极光数据库集群中。",
      "B": "将 JSON 文档放在亚马逊 S3 桶中。创建一个 Lambda 函数，该函数运行当文档在 S3 桶中到达时处理这些文档的组代码。将结果存储在亚马逊极光数据库集群中。",
      "C": "将 JSON 文档放在亚马逊 EBS 卷中。使用多连接功能将卷附加到多个亚马逊 EC2 实例。在 EC2 实例上运行 RDS 比顿代码以处理文档。将结果存储在亚马逊 RDS 数据库实例上。",
      "D": "将 JSON 文档作为消息放置在亚马逊简单队列服务队列中。在与亚马逊 ECS 发射类型配置的亚马逊弹性容器服务集群上将 QSS 比顿代码部署为容器。使用容器来处理消息。将结果存储在亚马逊 RDS 数据库实例上。"
    },
    "vote_percentage": "95%",
    "tags": [
      "Lambda",
      "S3"
    ],
    "explanation": {
      "analysis": "核心考点：使用Lambda函数触发S3上的对象创建事件，实现无服务器的文档处理。 注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是B选项是基于事件驱动的无服务器架构，满足了高可用，高伸缩，低运维开销的需求。",
      "why_correct": "选项B使用Lambda函数响应S3事件，实现自动化的文档处理流程，符合题干对高可用性、可伸缩性和低运维的要求。 S3作为数据存储，Lambda作为计算引擎，Aurora作为数据库，构成了一个完整的无服务器架构。 ",
      "why_wrong": "选项A在EC2实例上运行，增加了运维负担和潜在的单点故障风险。 选项C使用EBS和多连接，增加了复杂度和维护成本，并且EBS的单实例特性限制了高可用性。 选项D使用SQS和ECS，增加了系统的复杂度。且维护成本较高。"
    },
    "related_terms": [
      "S3",
      "EC2",
      "Lambda",
      "Aurora",
      "EBS",
      "RDS",
      "ECS",
      "SQS",
      "Fargate",
      "EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 162,
    "topic": "",
    "question_cn": "一家公司希望在金融风险建模中使用高性能计算（HPC）基础设施。该公司的 HPC 工作负载运行在 Linux 上。每一个工作流运行在数百个 Amazon EC2 Spot 实例上，是短期的，并生成数以千计的输出文件，最终存储在持久存储中用于分析和长期的未来使用。该公司寻求一种云存储解决方案，允许将内部数据复制到长期的持久存储中，以使所有 EC2 实例都能处理数据。解决方案还应该是一个高性能的文件系统，它与持久存储集成以读写数据集和输出文件。什么样的服务组合符合这些要求？",
    "options_cn": {
      "A": "Amazon FSx for Lustre 与 Amazon S3 集成",
      "B": "Amazon FSx for Windows File Server 与 Amazon S3 集成",
      "C": "Amazon S3 与 Amazon Glacier 集成",
      "D": "具有 VPC 端点的 Amazon S3 存储桶与 Amazon EBS 通用卷集成"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Lustre",
      "S3"
    ],
    "explanation": {
      "analysis": "考察在 HPC 场景下，高性能文件系统和对象存储的结合。",
      "why_correct": "A 选项使用 FSx for Lustre 与 S3 集成，FSx for Lustre 是一个高性能的文件系统，能够满足高性能计算的需求，与 S3 集成可以实现持久存储。",
      "why_wrong": "B 选项 FSx for Windows File Server 适合 Windows 环境，不是最适合 Linux HPC 的方案。C 选项 S3 与 Glacier 集成，Glacier 是归档存储，不适合 HPC。D 选项 S3 与 EBS 集成，EBS 性能有限，不满足 HPC 的高性能需求。"
    },
    "related_terms": [
      "FSx for Lustre",
      "S3",
      "FSx for Windows File Server",
      "Glacier",
      "VPC",
      "S3",
      "EBS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 163,
    "topic": "",
    "question_cn": "一家公司正在开发一个集装箱化的应用程序并决定将该应用程序转移到 AWS。该应用程序部署后不久将有成千上万的用户。该公司无法确定如何管理集装箱的大规模部署。该公司需要将集装箱化的应用程序部署在一个高可用性的架构中，以最大限度地减少运营开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将容器图像存储在亚马逊弹性容器注册中心 ECR 存储库中。使用一个亚马逊弹性容器服务 ECS 集群与 AWS Fargate 发射类型运行容器。根据需求使用目标跟踪自动缩放",
      "B": "将容器图像存储在亚马逊弹性容器注册中心 ECR 存储库中。使用亚马逊弹性容器服务 ECS 集群与亚马逊 EC2 发射类型运行容器。根据需求使用目标跟踪自动缩放",
      "C": "在运行于亚马逊 EC2 实例的存储库中存储容器图像。运行分布在多个可用性区域的 EC2 实例上的容器。监控亚马逊云表中的平均 CPU EC2 利用率。根据需要启动新的 EC2 实例。",
      "D": "创建一个包含容器图像的亚马逊 AMI。在多个可用性区的自动扩展组中启动 EC2 实例。当平均 CPU EC2 利用率阈值被突破时使用亚马逊云表警报来扩展 EC2 实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS",
      "Fargate"
    ],
    "explanation": {
      "analysis": "核心考点：使用Fargate作为ECS的启动类型，实现无需管理底层服务器的容器部署，从而降低运营开销。 注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是A使用 Fargate 启动类型，是完全托管的容器服务，运维成本最低，同时具备高可用性和弹性。",
      "why_correct": "选项A使用了Fargate启动类型，这是AWS完全托管的容器服务，无需管理底层EC2实例，满足了运营开销最小化的要求。 ECS和Fargate也提供了高可用性和自动伸缩的能力，可以满足大规模用户需求。",
      "why_wrong": "选项B虽然使用了ECS，但选择了EC2启动类型，需要用户自己管理EC2实例，增加了运维负担。选项C和D都是基于EC2的方案，需要用户自己管理EC2实例，增加了运维负担和复杂性。并且选项C没有体现容器化部署的优势。"
    },
    "related_terms": [
      "ECR",
      "ECS",
      "Fargate",
      "EC2",
      "ECR",
      "ECS",
      "EC2",
      "EC2",
      "EC2",
      "AMI",
      "EC2",
      "CloudWatch"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 164,
    "topic": "",
    "question_cn": "一个公司有两个应用程序：一个发送邮件的发送者应用程序，其有效负载将被处理；以及一个处理应用程序，其目的是接收有效负载的消息。发送者应用程序每小时可以发送大约 1000 条消息。这些消息可能需要长达 2 天的处理时间。如果消息无法处理，则必须保留它们，以免它们影响任何剩余消息的处理。哪个解决方案满足这些要求是最有效的操作？",
    "options_cn": {
      "A": "建立一个运行 Redis 数据库的 Amazon EC2 实例。配置两个应用程序来使用这个实例。分别存储、处理和删除消息。",
      "B": "使用 Amazon Kinesis Data Streams 接收来自发送者应用程序的消息。将处理应用程序集成到 Kinesis Client Library (KCL) 上。",
      "C": "将发送者和处理器应用程序与 Amazon Simple Queue Service (SQS) 队列整合。配置一个死信队列来收集无法处理的消息。",
      "D": "订阅处理应用程序到一个 Amazon Simple Notification Service (SNS) 主题以接收要处理的通知。将发送方应用程序集成以写入到 SNS 主题。"
    },
    "vote_percentage": "90%",
    "tags": [
      "SQS",
      "Dead Letter Queue"
    ],
    "explanation": {
      "analysis": "考察使用 SQS 和死信队列来异步处理消息，并处理失败的消息。",
      "why_correct": "C 选项使用 SQS 队列，可以异步处理消息，并配置死信队列，用于处理失败的消息，满足保留失败消息的需求。",
      "why_wrong": "A 选项使用 Redis 数据库，需要自己管理消息的存储、处理和删除，增加了运维成本和复杂性。B 选项使用 Kinesis Data Streams，适合实时数据流，不适合消息队列。D 选项使用 SNS，消息会被立即发送，没有失败处理机制。"
    },
    "related_terms": [
      "EC2",
      "Redis",
      "Kinesis Data Streams",
      "KCL",
      "SQS",
      "SNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 165,
    "topic": "",
    "question_cn": "解决方案架构师必须设计一个解决方案，使用具有 Amazon CloudFront 起源的 Amazon S3 存储桶来存储静态网站。该公司的安全策略要求所有的网站流量都要接受 AWS WAF 的检查。解决方案架构师应该如何遵守这些要求？",
    "options_cn": {
      "A": "配置 S3 桶策略，只接受来自 AWS WAF (ARN) 的请求。",
      "B": "配置 Amazon CloudFront，在从 S3 来源请求内容之前，将所有传入的请求转发给 AWS WAF。",
      "C": "配置一个安全组，允许 Amazon CloudFront 的 IP 地址只访问 Amazon S3 存储桶。与 CloudFront 相连。",
      "D": "配置 Amazon CloudFront 和 Amazon S3，使用原产地访问身份 (OAI) 限制访问 S3 存储桶。在分发时启用 AWS WAF。"
    },
    "vote_percentage": "58%",
    "tags": [
      "CloudFront",
      "WAF",
      "OAI"
    ],
    "explanation": {
      "analysis": "考察使用 CloudFront 和 WAF 保护 S3 存储桶中的静态网站，并使用 OAI 进行安全访问。",
      "why_correct": "D 选项配置 CloudFront 和 S3，使用 OAI 限制对 S3 桶的访问。在 CloudFront 分发中启用 WAF，可以实现对所有流量的 WAF 检查。",
      "why_wrong": "A 选项配置 S3 桶策略，虽然限制了访问，但无法实现 WAF 的检查。B 选项配置 CloudFront 转发请求给 WAF，增加了请求的延迟。C 选项使用安全组，安全性有限，无法实现 WAF 检查。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "AWS WAF",
      "S3",
      "CloudFront",
      "AWS WAF",
      "S3",
      "CloudFront",
      "S3",
      "OAI",
      "CloudFront",
      "AWS WAF"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 166,
    "topic": "",
    "question_cn": "HTML 全球活动的组织者希望将每日报告作为静态页面放在网上。预计这些页面将从世界各地的用户那里生成数百万个浏览量。这些 S3 文件存储在一个亚马逊存储桶中。一个解决方案架构师被要求设计一个高效和有效的解决方案。解决方案架构师应该采取哪些行动来实现这一点？",
    "options_cn": {
      "A": "为文件生成预签名 URL。",
      "B": "对所有区域使用跨区域复制。",
      "C": "使用 Amazon CloudFront 的地理邻近特性。",
      "D": "使用以存储桶为源头的 Amazon CloudFront。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考察如何使用 CloudFront 优化 S3 静态网站的内容分发。",
      "why_correct": "CloudFront 可以缓存 S3 中的静态内容，并将其分发到全球边缘站点，从而提高性能并减少 S3 的负载。",
      "why_wrong": "A 选项预签名 URL 适用于特定用户，而不是大规模的内容分发。B 选项跨区域复制主要用于数据冗余。C 选项 CloudFront 地理邻近性本身是一个特性，但需要配合 CloudFront 使用。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "CloudFront",
      "CloudFront",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 167,
    "topic": "",
    "question_cn": "一家公司在亚马逊 EC2 实例中运行一个生产应用程序。该应用程序读取来自亚马逊 SQS 队列的数据并并行处理消息。消息量是不可预测的，经常有断断续续的流量。这个应用程序应该连续地处理消息，而不需要任何停机时间。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "只使用现场实例来处理所需的最大容量",
      "B": "只使用保留的实例来处理所需的最大容量",
      "C": "使用为基线容量保留的实例并使用 SPOT 实例处理额外容量。",
      "D": "使用为基线容量保留的实例并使用按需实例处理额外容量。"
    },
    "vote_percentage": "53%",
    "tags": [
      "EC2",
      "Spot Instances"
    ],
    "explanation": {
      "analysis": "核心考点：使用预留实例作为基础容量，结合按需实例或Spot实例处理突发流量，平衡成本与可用性。 注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，D使用按需实例，虽然成本稍高，但可用性最好。",
      "why_correct": "选项D使用预留实例提供基础容量，确保了基本的性能和可用性，使用按需实例处理额外容量，满足了流量不可预测的需求。按需实例提供最强的可用性，适合关键业务。",
      "why_wrong": "选项A只使用竞价实例，可能因为竞价中断导致停机。选项B只使用预留实例，无法应对流量峰值。选项C使用了Spot实例，但Spot实例可能会被中断，导致停机。"
    },
    "related_terms": [
      "EC2",
      "SQS",
      "EC2",
      "SPOT",
      "EC2",
      "On-Demand"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 168,
    "topic": "",
    "question_cn": "AWS 安全团队希望限制对团队所有账户中的特定服务或操作的访问。所有的账户都属于一个大组织。解决方案必须是可伸缩的，必须有一个可以维护权限的单一点。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "创建一个 ACL 来提供对服务或操作的访问。",
      "B": "创建一个安全组允许账户并将其附加到用户组。",
      "C": "在每个账户中创建跨账户角色以拒绝访问服务或操作。",
      "D": "在根组织单元中创建服务控制策略拒绝访问服务或操作。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SCP",
      "IAM",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "考察如何使用服务控制策略 (SCP) 在 AWS Organizations 中集中管理账户的访问权限。",
      "why_correct": "D 选项使用 SCP 可以在 AWS Organizations 的根组织单元中集中控制所有账户的访问权限，符合可伸缩性和单一点的要求。",
      "why_wrong": "A 选项 ACL 用于控制 S3 存储桶的访问权限。B 选项安全组用于控制 EC2 实例的访问权限。C 选项在每个账户中创建跨账户角色比较繁琐，不易于管理。"
    },
    "related_terms": [
      "ACL",
      "IAM",
      "SCP"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 169,
    "topic": "",
    "question_cn": "由于最近的网络攻击，一家公司担心其公共网络应用的安全性。应用程序使用应用程序负载均衡器。解决方案架构师必须降低 DDoS 攻击应用程序的风险。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "添加一个 Amazon Inspector 代理到 ALB。",
      "B": "配置 Amazon Macie 以防攻击。",
      "C": "启用 AWS Shield 以防止攻击。",
      "D": "配置 Amazon GuardDuty 以监控 ALB。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DDoS",
      "AWS Shield",
      "ALB"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS Shield 来防御 DDoS 攻击。",
      "why_correct": "C 选项启用 AWS Shield 可以直接防御 DDoS 攻击，保护应用程序。",
      "why_wrong": "A 选项 Amazon Inspector 主要用于安全评估。B 选项 Amazon Macie 主要用于数据安全和合规性。D 选项 Amazon GuardDuty 用于威胁检测。"
    },
    "related_terms": [
      "ALB",
      "DDoS",
      "Amazon Inspector",
      "ALB",
      "Amazon Macie",
      "AWS Shield",
      "ALB",
      "GuardDuty"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 170,
    "topic": "",
    "question_cn": "一家公司的 Web 应用程序在 Amazon EC2 实例的应用负载均衡器后面运行。该公司最近改变了政策，现在只要求从一个特定国家访问该应用程序。哪种配置能满足这一要求？",
    "options_cn": {
      "A": "配置 EC2 实例的安全组。",
      "B": "在应用程序负载均衡器上配置安全组。",
      "C": "在 VPC 中的应用负载均衡器上配置 AWS WAF。",
      "D": "为包含 EC2 实例的子网配置网络 ACL。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS WAF",
      "ALB",
      "Geographic Restrictions"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS WAF 在应用程序负载均衡器上配置地理限制。",
      "why_correct": "C 选项在 ALB 上配置 AWS WAF，并使用地理匹配规则来限制来自特定国家的访问，可以满足要求。",
      "why_wrong": "A 选项安全组主要控制 EC2 实例的访问。B 选项安全组无法实现地理限制。D 选项网络 ACL 主要用于子网级别的流量控制，无法直接实现地理限制。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "VPC",
      "AWS WAF",
      "VPC",
      "Network ACL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 171,
    "topic": "",
    "question_cn": "一家公司向其用户提供一个 API，它可以自动查询基于项目价格的税务计算。公司在假日期间会遇到更多的询问，这只会导致反应时间变慢。解决方案架构师需要设计一个可伸缩和有弹性的解决方案。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "在亚马逊 EC2 实例上提供一个 API。当提出 API 请求时，EC2 实例执行所需的计算。",
      "B": "使用亚马逊 API 网关设计 RESTAPI API，接受项目名称。API 网关将项目名称传递给美国税务局来计算税款。",
      "C": "创建一个包含两个亚马逊 EC2 实例的应用程序负载平衡器。EC2 实例将计算接收项名称的税。",
      "D": "使用亚马逊 API 网关设计 API，该网关连接到位于亚马逊 EC2 实例上的 API。API 网关接受并将项目名称传递到 EC2 实例中进行税务计算。"
    },
    "vote_percentage": "96%",
    "tags": [
      "API Gateway",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点：使用API Gateway和第三方服务集成，实现可扩展性和弹性。 注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是B， 使用 API Gateway 简化了 API 管理，将税务计算委托给外部服务，减轻了后端服务器的负载。如果能够直接调用第三方API，性能和成本更佳。",
      "why_correct": "选项B使用API Gateway，它可以处理请求，并调用外部API服务计算税款，从而实现高可扩展性和弹性，并且减轻了服务器的负载。",
      "why_wrong": "选项A在EC2实例上运行API，扩展性受限于实例的容量，负载能力有限。 选项C使用应用程序负载均衡器和EC2实例，增加了运维成本。 选项D 虽然使用了API Gateway，但最终还是依赖EC2实例，扩展能力有限。"
    },
    "related_terms": [
      "API Gateway",
      "EC2",
      "API Gateway",
      "EC2",
      "API Gateway",
      "EC2",
      "EC2",
      "API Gateway"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 172,
    "topic": "",
    "question_cn": "一个解决方案架构师正在为一个应用程序创建一个新的亚马逊 CloudFront 分布。用户提交的一些信息是敏感的。应用程序使用 HTTPS，但需要另一层安全性。敏感信息应在整个应用程序堆栈中得到保护，对信息的访问应限于某些应用程序。解决方案架构师应该采取哪些行动？",
    "options_cn": {
      "A": "配置一个云端签名网址。",
      "B": "设计一个云端符号饼干。",
      "C": "配置云前实地加密配置文件。",
      "D": "配置 CloudFront 并将源协议策略设置为只用于查看器协议策略的 HTTPS。"
    },
    "vote_percentage": "77%",
    "tags": [
      "CloudFront",
      "Field-level Encryption"
    ],
    "explanation": {
      "analysis": "核心考点：使用CloudFront的字段级加密，实现对敏感数据的保护，限制访问。 注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是C直接提供了对特定字段的加密，更符合题目需求。",
      "why_correct": "选项C配置了CloudFront的字段级加密，可以在传输过程中保护敏感数据，并限制对这些字段的访问，从而满足了题目的要求。",
      "why_wrong": "选项A仅配置了签名URL，主要用于控制用户访问权限，而不是加密数据。 选项B使用CloudFront签名cookie，主要用于控制访问权限，而不是数据加密。选项D仅配置了HTTPS，提供了传输加密，但是没有对数据字段本身进行加密。"
    },
    "related_terms": [
      "CloudFront",
      "HTTPS",
      "CloudFront",
      "HTTPS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 173,
    "topic": "",
    "question_cn": "一家游戏公司在 S3 上拥有一个基于浏览器的应用程序。应用程序的用户消费大量存储在 Amazon S3 中的视频和图像。这一内容对所有用户都是一样的。该应用程序越来越受欢迎，全世界数以百万计的用户访问这些媒体文件。该公司希望向用户提供这些文件，同时减少来源的负载。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "在网络服务器前部署一个 Amazon Global Accelerator。",
      "B": "在 S3 存储桶前部署一个 Amazon CloudFront 网站。",
      "C": "在 Web 服务器前为 Web 系统的实例部署一个 Amazon ElastiCache。",
      "D": "在 Web 服务器前部署一个 Amazon 可调整的实例。"
    },
    "vote_percentage": "95%",
    "tags": [
      "S3",
      "CloudFront",
      "Content Delivery"
    ],
    "explanation": {
      "analysis": "考察如何使用 CloudFront 优化 S3 存储的静态内容分发，以提高性能和降低源站负载。",
      "why_correct": "B 选项在 S3 存储桶前部署 CloudFront，可以利用 CloudFront 的缓存功能，将静态内容分发到全球边缘站点，减少源站负载，并提高用户访问速度。",
      "why_wrong": "A 选项 Global Accelerator 主要用于加速动态内容，而不是静态内容。C 选项 ElastiCache 主要用于缓存数据库查询等。D 选项部署可调整的实例无法有效解决源站负载问题。"
    },
    "related_terms": [
      "S3",
      "Amazon Global Accelerator",
      "S3",
      "Amazon CloudFront",
      "ElastiCache",
      "Amazon"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 174,
    "topic": "",
    "question_cn": "一个公司有一个多层应用程序在一个 Amazon EC2 自动缩放组中运行，六个前端服务器在一个应用负载均衡器后面的一个可用性区域。解决方案架构师需要在不修改应用程序的情况下修改高可用性的基础结构。解决方案架构师应该选择哪个架构来提供高可用性？",
    "options_cn": {
      "A": "创建一个自动缩放组，在两个区域中使用，每个区域使用三个实例。",
      "B": "修改自动缩放组，在两个可用性区域中的每个区域使用三个实例。",
      "C": "创建一个自动缩放模板，可以用来在另一个区域快速创建更多实例。",
      "D": "将 Amazon EC2 实例前面的 ALB 改变为循环配置，以平衡到各层的流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "ALB",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考察如何使用自动缩放组和 ALB 实现应用程序的高可用性。",
      "why_correct": "B 选项修改自动缩放组，在两个可用性区域中使用，可以保证在单个可用性区域发生故障时，应用程序仍然可用，实现了高可用性。",
      "why_wrong": "A 选项虽然也使用了多个可用区，但题干中已声明在单个可用性区域中，所以 A 选项不符合题意。C 选项自动缩放模板可以用于快速启动实例，但不能直接提高可用性。D 选项 ALB 本身已经具有高可用性，无需修改。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "ALB",
      "EC2",
      "ALB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 175,
    "topic": "",
    "question_cn": "一家电子商务公司有一个订单处理应用程序，它使用 Amazon API Gateway 和 Lambda 功能。应用程序将数据存储在 Amazon Aurora 数据库中。在最近的一次销售活动中，客户订单突然激增。一些客户经历了超时，应用程序没有处理这些客户的订单。一个解决方案架构师确定，由于大量的开放连接，数据库中的 CPU 利用率和内存利用率很高。解决方案架构师需要防止超时错误，同时尽可能减少对应用程序的更改。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置为 Lambda 函数提供的并发配置。修改数据库使之成为多个可用区区域的全局数据库。",
      "B": "使用 Amazon RDS 代理创建数据库代理。修改 RDS 代理端点函数使用代理端点代替数据库端点。",
      "C": "在不同的 AWS 区域中为数据库创建一个读副本。使用 API Gateway 中的查询字符串参数将流量路由到读取副本",
      "D": "通过使用数据库迁移服务将数据从 Aurora 迁移到 Amazon DynamoDB。修改 Lambda 函数以使用 DynamoDB 表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Proxy",
      "Aurora",
      "Lambda"
    ],
    "explanation": {
      "analysis": "考察如何使用 RDS 代理来改善数据库的连接管理和性能，并减少对应用程序的修改。",
      "why_correct": "B 选项使用 RDS 代理可以有效地管理数据库连接，减少数据库负载，并提高性能。修改 Lambda 函数使用代理端点可以最小化对应用程序代码的更改。",
      "why_wrong": "A 选项 Lambda 并发配置并不能解决数据库连接问题，全局数据库的修改也比较复杂。C 选项读副本可以提高读取性能，但不能解决数据库连接问题。D 选项将数据库迁移到 DynamoDB 会对应用程序进行较大的修改。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "Aurora",
      "Lambda",
      "RDS",
      "API Gateway",
      "RDS",
      "RDS",
      "Aurora",
      "DynamoDB",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 176,
    "topic": "",
    "question_cn": "一个应用程序在私有子网中的亚马逊 EC2 实例上运行。应用程序需要访问亚马逊 DynamoDB 表。什么是访问表的最安全的方式，同时确保流量不会离开 VPC 网络？",
    "options_cn": {
      "A": "VPC 为 DynamoDB 使用 VPC 端点。",
      "B": "在公共子网中使用 NAT 网关。",
      "C": "在私有子网中使用 NAT 实例。",
      "D": "使用连接到 VPC 的互联网网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "核心考点：使用VPC Endpoint实现私有网络访问DynamoDB，保证安全性，避免流量经过Internet。 注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是A提供了最安全的访问方式，即通过VPC Endpoint在VPC内部访问DynamoDB，流量不会经过Internet。",
      "why_correct": "选项A使用了VPC Endpoint，这是访问DynamoDB的最安全的方式。 流量在VPC内部路由，不会经过Internet，从而提高了安全性。",
      "why_wrong": "选项B和C使用了NAT网关或NAT实例，虽然可以访问Internet，但不是最安全的访问DynamoDB的方式，并且增加了复杂性。 选项D使用互联网网关，会将流量暴露在公网上，不安全。"
    },
    "related_terms": [
      "EC2",
      "DynamoDB",
      "VPC",
      "DynamoDB",
      "VPC",
      "NAT",
      "NAT",
      "VPC"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 177,
    "topic": "",
    "question_cn": "一家娱乐公司正在使用 Amazon DynamoDB 存储媒体元数据。该应用程序是读密集型的，并且经历了延迟。公司没有员工来处理额外的运营费用，需要在不重新配置应用程序的情况下提高 DynamoDB 的性能。解决方案架构师应该建议什么来满足这个需求？",
    "options_cn": {
      "A": "使用 Amazon ElastiCache。",
      "B": "使用 Amazon DynamoDB Accelerator (DAX)。",
      "C": "使用 DynamoDB 全局表复制数据。",
      "D": "使用 Amazon ElastiCompute 进行自动发现。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "DAX",
      "Performance"
    ],
    "explanation": {
      "analysis": "考察如何使用 DAX 提高 DynamoDB 的读取性能，而无需更改应用程序代码。",
      "why_correct": "B 选项使用 DynamoDB Accelerator (DAX) 可以为 DynamoDB 提供缓存，显著提高读取性能，且无需修改应用程序代码。",
      "why_wrong": "A 选项 ElastiCache 是一种缓存服务，但与 DynamoDB 集成需要进行配置。C 选项全局表用于数据复制和高可用性，不是提高读取性能的直接解决方案。D 选项 ElastiCompute 是一种计算服务，与提高 DynamoDB 性能无关。"
    },
    "related_terms": [
      "DynamoDB",
      "ElastiCache",
      "DynamoDB",
      "DAX",
      "DynamoDB",
      "ElastiCompute"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 178,
    "topic": "",
    "question_cn": "一家公司的基础设施由 Amazon EC2 实例和一个 Amazon RDS 数据库实例组成。该公司希望在一个单独的区域备份其数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS Backup 将 EC2 备份和 RDS 备份复制到单独的区域。",
      "B": "使用 Amazon Data Lifecycle Manager 和 AWS Backup 将 EC2 备份和 RDS 备份复制到单独的区域。",
      "C": "创建 EC2 实例的 Amazon Machine Image。将 AMI 复制到另一个区域。在单独区域中为 RDS 数据库实例创建一个读副本。",
      "D": "创建 Amazon EBS 弹性块存储快照。将 EBS 快照复制到单独的区域。创建 RDS 快照。导出 RDS 快照到 S3。将跨区域复制配置到单独的区域。"
    },
    "vote_percentage": "97%",
    "tags": [
      "AWS Backup",
      "EC2",
      "RDS",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "考察如何使用 AWS Backup 实现 EC2 和 RDS 的跨区域备份。",
      "why_correct": "A 选项使用 AWS Backup 可以直接管理 EC2 和 RDS 的备份和跨区域复制，操作简单，开销最小。",
      "why_wrong": "B 选项虽然也使用了 AWS Backup，但 Data Lifecycle Manager 功能相对复杂，不符合题目要求。C 选项创建 AMI 和读副本需要额外的操作。D 选项需要进行 EBS 快照和 RDS 快照的复制，以及导出到 S3 等多个步骤，操作开销较大。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "AWS Backup",
      "EC2",
      "RDS",
      "Data Lifecycle Manager",
      "AWS Backup",
      "EC2",
      "AMI",
      "RDS",
      "EBS",
      "EBS",
      "RDS",
      "S3"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 179,
    "topic": "",
    "question_cn": "解决方案架构师需要安全地存储一个数据库用户名和密码，应用程序需要使用该数据库名和密码来访问 Amazon RDS 数据库实例。访问数据库的应用程序运行在 Amazon EC2 实例上。解决方案架构师希望在 Systems Manager 参数存储中创建一个安全参数。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "创建一个具有对参数存储参数的读取访问的 IAM 角色。允许解密访问用于加密参数的 KMS 密钥。将此 IAM 角色分配给 EC2 实例。",
      "B": "创建一个允许读取参数存储参数的 IAM 策略。允许解密访问用于加密参数的 KMS 密钥。将此 IAM 策略分配给 EC2 实例。",
      "C": "在参数存储参数和 EC2 实例之间创建 IAM 信任关系。在信任策略中指定 Amazon RDS 为主体。",
      "D": "在 EC2 实例和 EC2 实例之间创建 IAM 信任关系。在信任策略中指定 Systems Manager 为主体。"
    },
    "vote_percentage": "95%",
    "tags": [
      "Systems Manager Parameter Store",
      "IAM Roles",
      "KMS"
    ],
    "explanation": {
      "analysis": "考察如何安全地使用 Systems Manager Parameter Store 存储敏感信息，并允许 EC2 实例访问。",
      "why_correct": "A 选项创建一个具有读取参数存储权限和 KMS 解密权限的 IAM 角色，并将该角色分配给 EC2 实例，这是最佳实践。这样，EC2 实例就可以通过 IAM 角色访问存储在 Parameter Store 中的数据库凭证。",
      "why_wrong": "B 选项使用 IAM 策略虽然也可以，但不如 IAM 角色安全。C 和 D 选项创建信任关系是不正确的，Parameter Store 并不需要与 RDS 或 EC2 实例之间建立信任关系。"
    },
    "related_terms": [
      "RDS",
      "EC2",
      "Systems Manager",
      "IAM",
      "KMS",
      "IAM",
      "KMS",
      "IAM",
      "EC2",
      "IAM",
      "RDS",
      "EC2",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 180,
    "topic": "",
    "question_cn": "一家公司正在设计一个由 API 驱动的云通信平台。该应用程序在 Amazon EC2 实例的网络负载均衡器后面运行。该公司使用 Amazon API Gateway 向外部用户提供通过 API 访问应用程序的机会。该公司希望保护该平台不受 SQL 注入等服务的影响，并希望检测和 DDoS 缓解大型的、复杂的攻击。哪些解决方案的组合提供了最大的保护？（选择两个）",
    "options_cn": {
      "A": "使用 AWS WAF 保护 ALB。",
      "B": "使用与 ALB 集成的 AWS Shield Advanced。",
      "C": "使用 AWS WAF 保护 Amazon API Gateway。",
      "D": "使用 Amazon Shield 标准。",
      "E": "使用与 Amazon API Gateway 集成的 AWS Shield 标准。"
    },
    "vote_percentage": "93%",
    "tags": [
      "AWS WAF",
      "AWS Shield",
      "API Gateway",
      "ALB",
      "Security"
    ],
    "explanation": {
      "analysis": "考察如何结合使用 AWS WAF 和 AWS Shield 来保护应用程序免受各种安全威胁，包括 DDoS 攻击和常见的 Web 攻击。",
      "why_correct": "B 和 C 选项结合了使用 AWS Shield Advanced 和 AWS WAF 来保护应用程序。 AWS Shield Advanced 可以防御复杂的 DDoS 攻击， AWS WAF 可以防御常见的 Web 攻击，例如 SQL 注入。 这提供了最全面的保护。",
      "why_wrong": "A 选项仅提供了 WAF 的保护，缺少 DDoS 保护。D 和 E 选项只提供了 Shield 标准的保护，对 Web 应用程序的保护不足。"
    },
    "related_terms": [
      "API",
      "EC2",
      "ALB",
      "API Gateway",
      "SQL",
      "AWS WAF",
      "ALB",
      "AWS Shield Advanced",
      "AWS WAF",
      "API Gateway",
      "Amazon Shield"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 181,
    "topic": "",
    "question_cn": "一家公司有一个传统的数据处理应用程序运行在 EC2 实例上。数据按顺序处理，但结果的顺序并不重要。应用程序使用一个整体架构。公司可以扩展应用程序以满足需求增加的唯一方法是扩大实例的规模。该公司的开发人员已决定改写应用程序以便在亚马逊弹性容器服务上使用微服务体系结构。对于微服务之间的通信解决方案，架构师应该建议什么？",
    "options_cn": {
      "A": "创建一个亚马逊简单队列服务队列。向数据生成者添加代码并将数据发送到队列中。向数据使用者添加代码以处理队列中的数据。",
      "B": "创建一个亚马逊简单通知服务主题。向数据生成者添加代码并发布该主题的通知。向数据使用者添加代码以订阅主题。",
      "C": "创建一个 Lambda 函数来传递消息。向数据生成者添加代码以调用带有数据对象的 Lambda 函数。向数据使用者添加代码以接收从 Lambda 函数传递的数据对象。",
      "D": "创建一个 DynamoDB 表。启动 DynamoDB 流。向数据生成者添加代码以便将数据插入表中。向数据使用者添加代码使用 DynamoDB 流来检测新的表项并检索数据。"
    },
    "vote_percentage": "93%",
    "tags": [
      "Microservices",
      "SQS"
    ],
    "explanation": {
      "analysis": "考察微服务架构中服务间通信的常用解决方案，侧重于 SQS 消息队列的异步通信模式。",
      "why_correct": "SQS 消息队列提供了可靠的异步通信机制，服务可以将消息放入队列，而消费者可以异步地从队列中读取和处理消息，这种方式解耦了服务，提高了系统的可伸缩性和容错性。",
      "why_wrong": "SNS 适用于发布/订阅模式，不适用于这种点对点的数据处理场景。Lambda 在微服务间通信中，增加了复杂性和延迟。DynamoDB Stream 适用于数据变更的通知，不适用于这种通用数据处理。"
    },
    "related_terms": [
      "EC2",
      "亚马逊弹性容器服务",
      "微服务",
      "简单队列服务",
      "Lambda",
      "DynamoDB",
      "DynamoDB 流"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 182,
    "topic": "",
    "question_cn": "一家公司想把自己的 MySQL 数据库从内部迁移到 AWS。该公司最近经历了数据库故障，对业务产生了重大影响。为了确保这种情况不再发生，该公司希望在 AWS 上有一个可靠的数据库解决方案，最大限度地减少数据丢失，并在至少两个节点上存储每个事务。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon RDS 数据库实例，同步复制到三个可用性区域中的三个节点。",
      "B": "创建一个具有多可用区功能的 Amazon RDS MySQL 数据库实例，可以同步复制数据。",
      "C": "创建一个 Amazon RDS MySQL 数据库实例，然后在一个单独的可用区创建一个可以同步复制数据的读取副本。",
      "D": "使用安装的 MySQL 引擎创建一个 Amazon EC2 实例，该引擎将触发一个 Lambda 函数，以同步地将数据复制到一个 Amazon RDS MySQL 数据库实例。"
    },
    "vote_percentage": "97%",
    "tags": [
      "RDS Multi-AZ",
      "MySQL"
    ],
    "explanation": {
      "analysis": "考察 RDS MySQL 数据库的高可用性和容错能力，特别是 Multi-AZ 部署。",
      "why_correct": "RDS MySQL 的 Multi-AZ 部署可以在不同可用区之间同步复制数据，当主数据库发生故障时，自动故障转移到备用数据库，确保业务连续性。",
      "why_wrong": "RDS 单可用区部署不提供高可用性。读取副本不能提供主数据库故障时的自动故障转移。使用 EC2 实例自建数据库增加了管理复杂性，也不提供 RDS 的自动备份、监控等功能。"
    },
    "related_terms": [
      "MySQL",
      "RDS",
      "多可用区",
      "读取副本",
      "EC2",
      "Lambda",
      "RDS MySQL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 183,
    "topic": "",
    "question_cn": "一家公司正在建立一个新的动态订购网站。该公司希望尽量减少服务器维护和修补。网站必须是高度可用的，必须尽快扩大读写能力以满足用户需求的变化。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 API 托管静态内容在 Amazon S3 存储桶中。通过使用 Amazon API Gateway 和 Lambda 托管动态内容。使用 Amazon DynamoDB 具有随需应变的数据库能力。配置 Amazon CloudFront 提供网站内容。",
      "B": "使用 Amazon S3 API 托管静态内容在 Amazon S3 存储桶中。通过使用 Amazon API Gateway 和 Lambda 托管动态内容。使用 Amazon Aurora 与 Aurora Auto Scaling 数据库。配置 Amazon CloudFront 提供网站内容。",
      "C": "所有网站内容都在 Amazon EC2 实例中。创建一个 Auto Scaling 组来扩展 EC2 实例。使用应用程序负载均衡器分配流量。使用具有为数据库提供的编写容量的 Amazon DynamoDB。",
      "D": "所有网站内容都在 Amazon EC2 实例中。创建一个 Auto Scaling 组来扩展 EC2 实例。使用应用程序负载均衡器分配流量。使用 Amazon Aurora 与 Aurora Auto Scaling 数据库。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Serverless",
      "DynamoDB",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考察如何构建一个高可用、可扩展且易于维护的 Web 应用程序，特别是 Serverless 架构和 DynamoDB 的使用。",
      "why_correct": "选项 A 采用了 Serverless 架构，使用 S3 存储静态内容，Lambda 处理动态内容，DynamoDB 提供灵活的数据库，CloudFront 提供内容分发，实现了高可用性和自动伸缩，并减少了运维负担。",
      "why_wrong": "选项 B 同样使用了 Serverless 架构，但是 Aurora 不如 DynamoDB 适合本题场景。选项 C 和 D 依赖 EC2 实例，运维成本较高，并且扩展性不如 Serverless 架构。"
    },
    "related_terms": [
      "S3",
      "Amazon API Gateway",
      "Lambda",
      "DynamoDB",
      "CloudFront",
      "Aurora",
      "Aurora Auto Scaling",
      "EC2",
      "Auto Scaling",
      "应用程序负载均衡器",
      "DynamoDB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 184,
    "topic": "",
    "question_cn": "公司有一个用于软件工程的 AWS 帐户。AWS 帐户可以通过两个直接连接进入公司内部的数据中心。所有非 VPN 通信都通过虚拟专用网关路由。一个开发团队最近通过控制台创建了一个 Lambda 函数。开发团队需要允许该功能访问在公司数据中心的私有子网中运行的数据库。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "用适当的安全组配置在 VPC 中运行的 Lambda 函数。",
      "B": "建立一个从 AWS 到数据中心的 VPN 连接。将流量从 Lambda 函数中通过 VPN 进行路由。",
      "C": "更新 VPC 中的路由表，使 Lambda 函数能够通过直接连接进入内部数据中心。",
      "D": "创建一个弹性 IP 地址。在没有弹性网络接口的情况下通过弹性 IP 地址来发送流量。"
    },
    "vote_percentage": "73%",
    "tags": [
      "Lambda",
      "VPC"
    ],
    "explanation": {
      "analysis": "核心考点：在VPC中配置Lambda函数，并配置合适的安全组，使其能够访问数据中心内的数据库。 注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A是最简单的解决方案，只需要配置安全组即可。",
      "why_correct": "选项A在VPC中运行Lambda函数，并配置安全组，允许访问数据中心数据库，是满足需求的简单方法。",
      "why_wrong": "选项B通过VPN路由流量，增加了复杂性。 选项C需要更新路由表，比较复杂。选项D使用弹性IP，无法直接访问数据中心数据库。"
    },
    "related_terms": [
      "VPC",
      "Lambda",
      "VPN",
      "Elastic IP"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 185,
    "topic": "",
    "question_cn": "一家公司运行一个应用程序使用 Amazon EC2 计算机。该应用程序创建了原始图像的大小化版本，然后将 Amazon S3 API 调用来存储 Amazon S3 中的大小化图像。解决方案架构师如何确保应用程序具有访问 Amazon S3 的权限？",
    "options_cn": {
      "A": "更新 IAM 中的角色，允许从 Amazon EC2 系统进行读写访问，然后重新启动容器。",
      "B": "使用具有 S3 权限的 IAM 角色创建一个角色，然后在任务定义中指定该角色为任务学习。",
      "C": "创建一个安全组，允许从 Amazon EC2 通信系统进入 Amazon S3 并更新通信系统集群使用的启动配置。",
      "D": "创建一个具有 S3 权限的 IAM 用户，然后在作为此帐户登录时重新启动 Amazon EC2 实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Role",
      "EC2 Instance Profile"
    ],
    "explanation": {
      "analysis": "考察 EC2 实例访问 S3 存储桶的权限配置，特别是使用 IAM 角色。",
      "why_correct": "通过 IAM 角色向 EC2 实例授予 S3 访问权限，是最安全、最便捷的方式，无需在实例中存储凭证。",
      "why_wrong": "直接在 EC2 实例中存储凭证不安全。安全组用于控制网络流量，而非授权。对于任务学习来说，应该使用任务角色。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "IAM",
      "S3",
      "IAM",
      "S3",
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 186,
    "topic": "",
    "question_cn": "一个公司有一个基于 Windows 的应用程序，它必须迁移到 AWS。该应用程序要求使用连接到多个 Amazon Windows 实例的共享文件系统。这些实例部署在多个可用区。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "在卷网关模式下配置 AWS 存储网关。将卷挂载到每个 Windows 实例。",
      "B": "为文件服务器配置 Amazon FSx for Windows。将 Amazon FSx 文件系统安装到每个 Windows 实例。",
      "C": "利用 Amazon Elastic File System (EFS) 配置文件系统。将 EFS 文件系统安装到每个 Windows 实例。",
      "D": "配置一个 Amazon Elastic Block Store (EBS) 卷与要求的尺寸。将每个 EC2 实例附加到卷上。将卷中的文件系统安装到每个 Windows 实例中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Windows",
      "EFS"
    ],
    "explanation": {
      "analysis": "考察在 AWS 上部署共享文件系统的方案，特别是 FSx for Windows 和 EFS 的选择。",
      "why_correct": "FSx for Windows 提供了 Windows 原生的文件共享服务，可以轻松地被 Windows 实例访问。 EFS 适用于 Linux 实例。",
      "why_wrong": "EBS 卷需要手动管理，并且不能实现多实例共享。存储网关主要用于混合云场景。"
    },
    "related_terms": [
      "Windows",
      "FSx for Windows",
      "Amazon Elastic File System (EFS)",
      "EC2",
      "Elastic Block Store (EBS)"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 187,
    "topic": "",
    "question_cn": "一家公司正在开发一个电子商务应用程序，它将由一个负载平衡的前端、一个容器应用程序和一个关系数据库组成。解决方案架构师需要创建一个非常可用的解决方案，该解决方案可以在尽可能少的手动干预下运行。哪些解决方案符合这些要求？（选二）",
    "options_cn": {
      "A": "在多可用区模式下创建一个 Amazon RDS 数据库实例。",
      "B": "在另一个可用区创建一个 Amazon RDS 数据库实例和一个或多个副本。",
      "C": "创建一个基于 Amazon EC2 实例的 Docker 集群来处理动态应用程序负载。",
      "D": "创建一个具有 Fargate 启动类型的 Amazon Elastic Container Service 集群以处理动态应用程序负载。",
      "E": "创建一个具有 EC2 启动类型的 Amazon Elastic Container Service 集群以处理动态应用程序负载。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Multi-AZ",
      "ECS Fargate"
    ],
    "explanation": {
      "analysis": "考察高可用性的数据库和容器化应用程序的部署方案。",
      "why_correct": "A: 使用 RDS 多可用区部署，数据库实现高可用性。D: 使用 ECS Fargate 运行容器，无需管理底层 EC2 实例，减少运维负担。",
      "why_wrong": "B: RDS 副本虽然提供了读扩展，但不能提供自动故障转移。C、E: 使用 EC2 启动类型需要运维 EC2 实例，增加了运维负担。"
    },
    "related_terms": [
      "RDS",
      "EC2",
      "Docker",
      "Fargate",
      "Elastic Container Service"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 188,
    "topic": "",
    "question_cn": "一家公司使用亚马逊 S3 作为其数据湖。该公司有一个新的合作伙伴必须使用 SFTP 来上传数据文件。解决方案架构师需要实现一个高度可用的 SFTP 解决方案，以最大限度地减少操作开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Transfer Family 来配置带有可公开访问端点的 S3 启用服务器。选择 S3 数据湖作为目的地。",
      "B": "使用亚马逊 文件网关作为 S3 SFTP 服务器。向新伙伴公开文件网关端点 URL。与新伙伴共享文件网关端点。",
      "C": "在 VPC 中的私人子网中启动亚马逊 EC2 实例。指示新伙伴使用 SFTP 将文件上传到 EC2 实例。运行一个作业脚本在 EC2 实例中上 S3 传文件到数据湖。",
      "D": "在 VPC 的私人子网中启动亚马逊 EC2 实例。在 EC2 实例前放置一个网络负载平衡器 NLB。为 NLB 创 SFTP 监听端口。与新伙伴分享 NLB 的主机名称。在 EC2 实例上运行作业脚本以便将文件上传到数据湖。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SFTP",
      "Transfer Family"
    ],
    "explanation": {
      "analysis": "核心考点：使用AWS Transfer Family服务，实现高可用、低运维的SFTP解决方案。 注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是A选项使用AWS Transfer Family，是AWS提供的完全托管的SFTP服务，运维成本最低，同时具备高可用性。",
      "why_correct": "选项A使用了AWS Transfer Family，是完全托管的SFTP服务，提供了高可用性和低运维成本。它直接将文件上传到S3。",
      "why_wrong": "选项B使用文件网关，不是专门为SFTP设计的服务。选项C和D基于EC2的方案，需要用户管理EC2实例，增加了运维负担。"
    },
    "related_terms": [
      "S3",
      "SFTP",
      "AWS Transfer Family",
      "文件网关",
      "VPC",
      "网络负载平衡器"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 189,
    "topic": "",
    "question_cn": "公司需要储存合同文件。合同有效期为 5 年。在 5 年期间，公司必须确保文件不被覆盖或删除。该公司需要加密文件的休息，并自动旋转加密密钥，每年。解决方案架构师应该采取哪些步骤组合以最少的操作开销来满足这些需求？ 选二。",
    "options_cn": {
      "A": "将文件存放在亚马逊 S3 上。在治理模式中使用对象锁定。",
      "B": "将文件存放在亚马逊 S3 上。在服从模式下使用对象锁定。",
      "C": "使用亚马逊 S3 (SSE-S3) 的服务器端加密。配置键旋转。",
      "D": "使用服务器端加密的 AWS KMS 密钥管理服务客户管理密钥。配置键旋转。",
      "E": "使用服务器端加密与 AWS KMS 客户提供的导入密钥。配置键旋转。"
    },
    "vote_percentage": "77%",
    "tags": [
      "S3",
      "Object Lock"
    ],
    "explanation": {
      "analysis": "核心考点：结合S3对象锁定、SSE-KMS加密，以及密钥轮换策略，实现数据的不可变性和加密。 注意: 此题官方答案为CE，但社区共识(投票最高)为BD。社区倾向BD的原因是，这两个选项结合了加密和密钥管理，并且强调了密钥轮换的重要性。",
      "why_correct": "选项B使用服从模式的对象锁定，确保文件在指定时间内不可变。选项D使用KMS客户管理密钥，结合密钥轮换，可以满足加密和密钥管理需求。",
      "why_wrong": "选项A 使用治理模式的对象锁定，这种模式下，具有特定权限的用户可以删除锁定。选项C使用了SSE-S3，由AWS托管加密，无法实现密钥轮换。选项E使用了客户提供的导入密钥，增加了复杂性，不太常见。"
    },
    "related_terms": [
      "S3",
      "对象锁定",
      "服务器端加密",
      "KMS",
      "KMS"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 190,
    "topic": "",
    "question_cn": "一家公司有一个基于 Java 和 PHP 的 Web 应用程序。该公司计划将申请从公司内部转移到 AWS。公司需要有能力经常测试新网站的功能。该公司还需要一个高可用性和管理的解决方案，要求最小的运营开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个亚马逊 S3 桶。在 S3 桶上启用静态网络主机。上传静态内容到 S3 桶。使用 Lambda 处理所有动态内容。",
      "B": "将 Web 应用程序部署到 AWS 弹性豆柄环境中。使用交换在多个弹性豆柄环境之间进行特征测试。",
      "C": "将 Web 应用程序部署到使用 Java 和 PHP 配置的亚马逊 EC2 实例中。使用自动缩放组和一个应用负载平衡器来管理网站的可用性。",
      "D": "容纳 Web 应用程序。将 Web 应用程序部署到亚马逊 EC2 实例。使用 负载平衡器控制器来动态地路由容器之间的流量，这些容器包含用于测试的新站点功能。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Elastic Beanstalk",
      "Load Balancing"
    ],
    "explanation": {
      "analysis": "核心考点：使用Elastic Beanstalk，简化Web应用程序的部署和管理，同时实现高可用性和便捷的特征测试。 注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是B， 使用Elastic Beanstalk可以简化部署，同时通过交换功能实现不同版本之间的切换，满足了测试需求。并且，Elastic Beanstalk也能够实现高可用性。",
      "why_correct": "选项B使用Elastic Beanstalk，简化了Web应用程序的部署和管理，并且支持特性测试。Elastic Beanstalk也能够实现高可用性。",
      "why_wrong": "选项A只适用于静态网站，不能处理动态内容。 选项C需要手动配置EC2实例，运维复杂。选项D使用EC2实例和负载平衡器控制器，增加了复杂性。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "弹性豆柄",
      "EC2",
      "Auto Scaling",
      "负载平衡器"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 191,
    "topic": "",
    "question_cn": "一个公司有一个订购应用程序，它在亚马逊 RDS 中存储了客户信息，用于 MySQL。在正常工作时间，雇员为报告目的进行一次性查询。在顺序处理过程中会出现超时，因为报表查询要花费很长时间才能运行。公司需要在不妨碍员工进行查询的情况下消除超时。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个阅读副本。将报告查询移动到读副本。",
      "B": "创建一个阅读副本。将订购应用程序分发到主数据库实例和读副本。",
      "C": "将订单应用程序迁移到具有随需应变能力的亚马逊 DynamoDB。",
      "D": "安排非高峰时段的报告查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "核心考点：使用RDS的只读副本，将报表查询负载分流，避免影响主数据库的性能。 注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，A选项是最直接有效的解决方案，创建只读副本，将报表查询指向只读副本，不会影响主数据库的性能。",
      "why_correct": "选项A创建只读副本，并将报表查询移动到只读副本，可以避免报表查询对主数据库性能的影响，从而消除超时问题。",
      "why_wrong": "选项B将订单应用程序分发到主数据库实例和读副本，会使读写操作都负载到只读副本上。选项C将应用程序迁移到DynamoDB，可能需要对应用程序代码进行修改，比较复杂。选项D在非高峰期运行报表查询，但并不能根本解决问题。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "读副本",
      "DynamoDB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 192,
    "topic": "",
    "question_cn": "一家医院希望为其大量的历史记录创建数字副本。医院将继续每天增加数百份新文件。该医院的数据小组将扫描这些文件并将文件上传到 AWS 云。解决方案架构师必须实现一个解决方案来分析文档，提取医疗信息，并存储文档，以便应用程序能够在数据上运行 SQL 查询。解决方案必须最大限度地提高可伸缩性和操作效率。解决方案架构师应该采取哪些步骤来满足这些需求？ 选二。",
    "options_cn": {
      "A": "将文档信息写入运行 MySQL 数据库的亚马逊 EC2 实例。",
      "B": "将文档信息写入一个亚马逊 S3 桶。使用亚马逊 Athena 查询数据。",
      "C": "创建亚马逊 EC2 实例的自动缩放组，运行处理扫描文件并提取医疗信息的定制应用程序。",
      "D": "创建一个当新文档上传时运行的 Lambda 函数。使用亚马逊 Rekognition 将文件转换为原始文本。使用亚马逊 Transcribe Medical 检测和提取相关医学信息的文本。",
      "E": "创建一个当新文档上传时运行的 Lambda 函数。使用亚马逊 Textract 将文档转换为原始文本。使用亚马逊 Comprehend Medical 检测和提取相关医学信息的文本。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Athena"
    ],
    "explanation": {
      "analysis": "核心考点：使用S3、Athena、Textract和Comprehend Medical组合，实现文档分析、信息提取和查询，并保证可伸缩性和运维效率。 注意: 此题官方答案为CD，但社区共识(投票最高)为BE。社区倾向BE的原因是，BE使用了无服务器架构，并使用了Textract和Comprehend Medical进行提取和分析，更符合题目需求，同时也具备可扩展性。",
      "why_correct": "选项B将文档存储在S3中，使用Athena进行查询，满足了可伸缩性和运维效率的要求。 选项E使用Lambda函数触发，使用Textract进行文档转换，Comprehend Medical提取相关医学信息，实现了自动化的文档处理。",
      "why_wrong": "选项A在EC2实例上运行MySQL数据库，增加了运维复杂性，扩展性较差。 选项C使用EC2实例，运维复杂且扩展性受限。 选项D 使用亚马逊Rekognition进行文本转换，不适合用于提取文本。"
    },
    "related_terms": [
      "MySQL",
      "EC2",
      "S3",
      "Athena",
      "Lambda",
      "Rekognition",
      "Transcribe Medical",
      "Textract",
      "Comprehend Medical"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 193,
    "topic": "",
    "question_cn": "一家公司正在亚马逊 EC2 实例上运行一个批处理应用程序。该应用程序由具有多个亚马逊 RDS 数据库的后端组成。应用程序正在导致数据库上的大量读取。解决方案架构师必须减少数据库读取的数量，同时确保高可用性。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "添加亚马逊 RDS 阅读副本。",
      "B": "使用亚马逊弹性 Redis。",
      "C": "使用亚马逊 CloudFront 缓存。",
      "D": "使用亚马逊弹性计算机进行记忆存储。"
    },
    "vote_percentage": "53%",
    "tags": [
      "RDS",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "核心考点：使用RDS只读副本减少数据库的读取负载，同时保证数据库高可用。 注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是B,使用Redis作为缓存，能很大程度减少数据库的读取操作。",
      "why_correct": "选项B使用了ElasticCache Redis缓存，可以缓存常用的数据，从而减少对数据库的读取操作，提高性能，同时保证高可用性。",
      "why_wrong": "选项A添加了RDS只读副本，可以分担读负载，但Redis缓存更有效。 选项C 使用CloudFront缓存，不能解决数据库读取压力。 选项D弹性计算机用于计算，不能解决数据库读取压力。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "读副本",
      "弹性 Redis",
      "CloudFront",
      "弹性计算机"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 194,
    "topic": "",
    "question_cn": "一个公司需要在 AWS 上运行一个关键的应用程序。该公司需要使用亚马逊 EC2 作为应用程序的数据库。数据库必须是高度可用的，如果发生破坏性事件，则必须自动关闭。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "启动两个 EC2 实例，每个实例在同一区域的不同可用性区域中。在两个 EC2 实例上安装数据库。将 EC2 实例配置为集群。建立数据库复制。",
      "B": "在可用性区域启动 EC2 实例。在 EC2 实例上安装数据库。使用一个亚马逊机器映像来备份数据。如果发生破坏性事件，使用云 EC2 组来自动提供 EC2 实例。",
      "C": "启动两个 EC2 实例，每个实例位于不同的区域。在两个 EC2 实例上安装数据库。建立数据库复制。数据库失败到第二个区域。",
      "D": "在可用性区域启动 EC2 实例。在 EC2 实例上安装数据库。使用一个亚马逊机器映像来备份数据。如果发生破坏性事件，使用 EC2 自动恢复恢复实例。"
    },
    "vote_percentage": "55%",
    "tags": [
      "EC2",
      "High Availability"
    ],
    "explanation": {
      "analysis": "核心考点：在多个可用区部署数据库，并配置数据库复制，实现高可用性和自动故障转移。 注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A选项提供了数据库集群和复制，确保了数据库的高可用性，并且在同一区域内的不同可用区部署，保证了低延迟。但是，C选项提供了跨区域部署，灾备等级更高。",
      "why_correct": "选项A在同一区域的不同可用性区域中启动两个EC2实例，建立数据库复制，保证了数据库的高可用性。 选项C跨区域部署，灾备级别更高，但是延迟相对会高。",
      "why_wrong": "选项B使用AMI备份数据，如果发生故障，需要手动恢复，不能自动故障转移。 选项D使用EC2自动恢复，但如果发生故障，可能导致数据丢失。"
    },
    "related_terms": [
      "EC2",
      "EC2",
      "EC2",
      "EC2 自动恢复"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 195,
    "topic": "",
    "question_cn": "公司的订单系统向亚马逊 EC2 实例发送客户的请求。EC2 实例处理订单，然后在亚马逊 RDS 上的数据库中存储订单。用户报告说，当系统失败时，他们必须重新处理订单。该公司希望有一个弹性解决方案，能够在系统发生故障时自动处理订单。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将 EC2 实例移动到一个自动缩放组中。创建一个亚马逊事件桥 AWS CloudWatch 事件规则以目标亚马逊弹性容器服务 ECS 任务。",
      "B": "将 EC2 实例移动到应用程序负载平衡器 ALB 后面的自动缩放组中。更新订单系统将消息发送到 ALB 端点。",
      "C": "将 EC2 实例移动到一个自动缩放组中。将订单系统配置为将消息发送到亚马逊简单队列服务队列 SQS。配置 EC2 实例以使用队列中的消息。",
      "D": "创建一个亚马逊简单通知服务 SNS 主题。创建一个 Lambda 函数并将该函数订阅到 SNS 主题。将订单系统配置为将消息发送到 SNS 主题。向 EC2 实例发送一个命令，通过使用系统管理器运行命令来处理消息。"
    },
    "vote_percentage": "95%",
    "tags": [
      "SQS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "核心考点：使用SQS和自动伸缩组，实现系统故障时订单的自动重试和恢复。 注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，C使用了SQS，能够实现消息的异步处理，保证了系统的弹性和可靠性，避免了因系统故障导致的数据丢失。",
      "why_correct": "选项C使用SQS队列作为消息队列，保证了订单的可靠性。当EC2实例发生故障时，SQS中的消息不会丢失，并被其他实例处理。 自动伸缩组则能够根据负载自动伸缩EC2实例数量，保证了系统的弹性。",
      "why_wrong": "选项A使用事件桥，并指向ECS，增加了系统的复杂性，不符合题目需求。 选项B使用ALB，不能保证失败订单的重试。 选项D虽然使用了SNS和Lambda，但是通过System Manager运行命令的方式，效率不高，并且增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "亚马逊事件桥",
      "ECS",
      "事件规则",
      "ALB",
      "SQS",
      "SNS",
      "Lambda",
      "系统管理器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 196,
    "topic": "",
    "question_cn": "一家公司在大量 EC2 实例上运行一个应用程序。应用程序在 DynamoDB 表中读取和写入条目。DynamoDB 表的大小持续增长，但应用程序只需要过去 30 天的数据。该公司需要一个解决方案，以最大限度地降低成本和开发工作量。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 CloudFormation 模板来部署完整的解决方案。每隔 30 天重新部署 CloudFormation 堆栈并删除原来的堆栈。",
      "B": "使用从 AWS Marketplace 运行的监控应用程序的 EC2 实例。在表中创建新项目时，将监视应用程序配置为使用 DynamoDB 流来存储时间戳。使用在 EC2 实例上运行的脚本来删除具有超过 30 天的时间戳的项目。",
      "C": "配置 DynamoDB 流以便在表中创建一个新项目时调用 Lambda 函数。配置 Lambda 函数以删除表中超过 30 天的项。",
      "D": "扩展应用程序以向表中创建的每个新项添加具有当前时间戳值的天数属性。将 DynamoDB 配置为使用该属性作为 TTL 属性。"
    },
    "vote_percentage": "92%",
    "tags": [
      "DynamoDB TTL",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考察使用 DynamoDB TTL（Time To Live）来自动删除旧数据以节省成本。",
      "why_correct": "选项 D 使用 DynamoDB 的 TTL 功能，可以根据时间戳自动删除旧数据，无需额外代码或运维成本，是最优解。",
      "why_wrong": "选项 A 涉及 CloudFormation 和堆栈的重新部署，带来了额外的运维复杂性。选项 B 引入了额外的 EC2 实例和自定义脚本，增加了成本和运维负担。选项 C 使用 Lambda 函数，增加了复杂性和潜在的延迟。"
    },
    "related_terms": [
      "EC2",
      "DynamoDB",
      "CloudFormation",
      "Lambda",
      "DynamoDB 流",
      "TTL"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 197,
    "topic": "",
    "question_cn": "一家公司有一个 Windows 微软应用程序，运行在内部服务器上。应用程序通过使用甲骨文数据库标准版服务器存储数据。该公司正在计划迁移到 AWS，并希望在移动应用程序的同时将开发变化减少到最低限度。应用环境应该是非常可用的。公司应采取哪些措施来满足这些要求？选二。",
    "options_cn": {
      "A": "AWS Lambda将应用程序还原为无服务器并运行网络核心功能。",
      "B": "将应用程序与AWS Elastic Beanstalk重新放在一起。多部署中的网络平台。",
      "C": "EC2 Linux 重新设置应用程序的平台以便在亚马逊 EC2上运行使用亚马逊机器映像。",
      "D": "使用AWS Database Migration Service (DMS)在多AZ部署中从甲骨文数据库迁移到Amazon DynamoDB。",
      "E": "使用AWS Database Migration Service (DMS)在多AZ部署中从甲骨文数据库迁移到Amazon RDS上的甲骨文数据库。"
    },
    "vote_percentage": "98%",
    "tags": [
      "Database Migration",
      "High Availability"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BD，但社区共识(投票最高)为BE。社区倾向BE的原因是，将数据库迁移到RDS比迁移到 DynamoDB更容易，更符合“减少开发更改”的要求。此外，使用 Elastic Beanstalk 可以更容易地部署和管理应用程序，同时保持高可用性。",
      "why_correct": "选项 B 使用 Elastic Beanstalk 部署应用程序，可以简化部署和管理，实现高可用性。选项 E 使用 DMS 将 Oracle 数据库迁移到 RDS，最大限度地减少了应用程序的更改。",
      "why_wrong": "选项 A 转向 Lambda 可能需要对应用程序进行较大修改，不符合“将开发变化减少到最低限度”的要求。选项 C 需要重构应用程序，工作量大，耗时。"
    },
    "related_terms": [
      "Lambda",
      "Elastic Beanstalk",
      "EC2",
      "亚马逊机器映像",
      "Database Migration Service (DMS)",
      "DynamoDB",
      "RDS"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 198,
    "topic": "",
    "question_cn": "一家公司在其内部数据中心的 Kubernetes 集群上运行一个容器化应用程序。该公司正在使用 MongoDB 进行数据存储。该公司希望将其中一些环境迁移到 AWS，但此时不可能进行代码更改或部署方法更改。公司需要一个能最大限度减少运营开销的解决方案。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Service 与 Amazon EC2 工人节点进行计算，并在 EC2 上使用 MongoDB 进行数据存储。",
      "B": "使用 Amazon Elastic Container Service，Amazon ECS 的 Fargate 计算和 Amazon DynamoDB 数据存储。",
      "C": "使用 Amazon Elastic Kubernetes Service，Amazon EKS 与 Amazon EC2 工人节点进行计算，和 Amazon DynamoDB 存储数据。",
      "D": "使用 Amazon Elastic Kubernetes Service，Amazon EKS 和 Fargate 计算和 Amazon Elastic File System 与 MongoDB 兼容性数据存储。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Containerization",
      "Kubernetes Migration"
    ],
    "explanation": {
      "analysis": "考察 Kubernetes 容器化应用迁移到 AWS 上的方案，关注最小化运维开销。",
      "why_correct": "选项 D 使用 Amazon EKS 结合 Fargate 计算，可以实现容器化应用的部署，并且 Fargate 是一种无服务器计算引擎，可以最大限度减少运营开销。使用 EFS 存储与 MongoDB 兼容的数据。",
      "why_wrong": "选项 A 和 C 使用 EC2 实例，增加了运维开销，需要管理 EC2 实例。选项 B 使用 DynamoDB 作为数据存储，与 MongoDB 不兼容，需要修改现有代码，不符合题目要求。"
    },
    "related_terms": [
      "Kubernetes",
      "Amazon Elastic Container Service",
      "EC2",
      "MongoDB",
      "Fargate",
      "DynamoDB",
      "Amazon Elastic Kubernetes Service",
      "Amazon EKS",
      "Elastic File System"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 199,
    "topic": "",
    "question_cn": "一家电话销售公司正在设计它的客户呼叫中心功能。该公司需要一个解决方案提供多个扬声器识别和生成记录文件。该公司想查询记录文件来分析业务模式。为了审计的目的，记录档案必须保存七年。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon Rekognition重新识别多个扬声器。将记录文件存储在Amazon S3上。用机器学习模型进行记录文件分析。",
      "B": "使用Amazon Transcribe进行多扬声器识别。使用Amazon Athena进行记录文件分析。",
      "C": "使用SQL进行多扬声器识别。在Amazon Redshift存储记录文件。使用查询进行记录文件分析。",
      "D": "使用Amazon Rekognition重新识别多个扬声器。将记录文件存储在Amazon S3上。使用Amazon Athena进行记录文件分析。"
    },
    "vote_percentage": "92%",
    "tags": [
      "Speech-to-Text",
      "Data Analysis"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，使用Amazon Transcribe进行语音转录，并使用Athena查询分析，是更直接和成本效益的选择，并且能够满足保存七年的要求。",
      "why_correct": "选项 B 使用 Amazon Transcribe 进行语音转录，它专为转录语音而设计。使用 Amazon Athena 可以方便地查询存储在 S3 中的转录文本。",
      "why_wrong": "选项 C 使用 SQL 在 Amazon Redshift 存储记录文件，这不适用于存储非结构化文本数据。选项 D 使用 Rekognition 进行语音识别，不适用于语音转录。选项 A 使用 Rekognition 进行语音识别和机器学习模型分析，增加了复杂性，并非最佳选择。"
    },
    "related_terms": [
      "Rekognition",
      "S3",
      "Athena",
      "Transcribe",
      "Redshift"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 200,
    "topic": "",
    "question_cn": "一家公司将其应用程序放在美国航空公司上。该公司使用Amazon Cognito管理用户。当用户登录到应用程序时，应用程序通过使用位于Amazon API Gateway中的REST API来获取所需数据。该公司希望有一个托管的解决方案将控制对其他API的访问，以减少开发工作。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在API Gateway中配置一个Lambda函数作为授权人以验证哪个用户提出了请求。",
      "B": "对于每个用户创建并分配一个API key，该key必须与每个请求一起发送。使用Lambda函数验证key。",
      "C": "将用户的电子邮件地址发送到每一个请求的标题中。调用Lambda函数来验证拥有该电子邮件地址的用户有适当的访问权限。",
      "D": "在API Gateway中配置一个Amazon Cognito用户池授权器，允许Amazon Cognito验证每个请求。"
    },
    "vote_percentage": "98%",
    "tags": [
      "API Gateway",
      "Authentication and Authorization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，使用Amazon Cognito 用户池授权器是最简单的实现方法，因为它是API Gateway提供的原生的授权方式，不需要额外的开发工作，并且可以与 Cognito 用户池无缝集成。",
      "why_correct": "选项 D 使用API Gateway的Cognito用户池授权器，简化了用户认证和授权流程。 Cognito 负责用户身份验证，并提供授权机制，减少开发工作。",
      "why_wrong": "选项 A 需要开发自定义 Lambda 授权器，增加开发和维护成本。选项 B 和 C 也需要自定义代码和复杂的密钥管理，不如 Cognito 用户池授权器方便。"
    },
    "related_terms": [
      "Amazon Cognito",
      "API Gateway",
      "Lambda",
      "API key",
      "Lambda",
      "Cognito"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 201,
    "topic": "",
    "question_cn": "一家公司正在开发针对移动应用用户的营销通信服务。公司需要通过短信服务向用户发送确认信息。用户必须能够回复短信。该公司必须将答复存储一年进行分析。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个Amazon Connect接触流发送短信。用Lambda来处理响应。",
      "B": "建立一个Amazon Pinpoint旅程。配置Amazon Pinpoint将事件发送到Amazon Kinesis Data Firehose进行分析和归档。",
      "C": "使用Amazon Simple Queue Service (SQS) Amazon SQS来分发短信。用Lambda来处理响应。",
      "D": "创建一个Amazon Simple Notification Service (SNS)主题。订阅一个Amazon Kinesis Data Firehose以进行分析和归档。"
    },
    "vote_percentage": "87%",
    "tags": [
      "SMS",
      "Marketing Automation"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，Amazon Pinpoint 是专门为营销活动设计的服务，可以发送短信，处理用户回复，并将数据发送到Kinesis Data Firehose进行分析，实现了端到端的解决方案。",
      "why_correct": "选项 B 使用 Amazon Pinpoint 发送短信并收集回复，同时可以分析这些数据。 Pinpoint 提供营销活动的管理功能，包括短信发送、用户回复处理和数据分析。",
      "why_wrong": "选项 A 使用 Amazon Connect 主要用于客户服务，不适合营销短信场景。选项 C 和 D 缺乏对短信回复的处理和分析功能，无法满足需求。"
    },
    "related_terms": [
      "Amazon Connect",
      "Lambda",
      "Amazon Pinpoint",
      "Kinesis Data Firehose",
      "SQS",
      "SNS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 202,
    "topic": "",
    "question_cn": "一家公司正计划将其数据转移到 Amazon S3 存储桶。数据存储在存储桶中时必须加密。此外，加密密钥必须每年自动轮换。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将数据移到 S3 存储桶。使用 Amazon S3 托管加密密钥的服务器端加密 (SSE-S3)。使用 S3 加密密钥的内置密钥轮换行为。",
      "B": "创建 AWS Key Management Service (KMS) 客户管理密钥。启动自动密钥轮换。设置存储桶的默认加密行为，使用客户管理的密钥。把数据移到 S3 存储桶。",
      "C": "创建 AWS KMS 客户管理密钥。设置存储桶的默认加密行为，使用客户管理的密钥。把数据移到 S3 存储桶。每年手动轮换 KMS 密钥。",
      "D": "在将数据转移到 S3 存储桶之前，用客户密钥材料对数据进行加密。创建一个不含关键材料的 KMS 密钥。将客户密钥材料导入 KMS 密钥。启动自动密钥轮换。"
    },
    "vote_percentage": "55%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "考察 S3 数据的加密，以及密钥轮换机制。",
      "why_correct": "选项 B 使用 AWS KMS 客户管理密钥，并且启用自动密钥轮换，满足数据加密和密钥自动轮换的要求。 设置 S3 桶的默认加密行为使用 KMS 密钥，可以自动加密新上传的数据，最符合题意，并且运维成本最小。",
      "why_wrong": "选项 A 使用 SSE-S3，无法实现密钥轮换。选项 C 需要手动轮换密钥，增加了运维成本。选项 D 需要手动加密数据，增加了复杂性。"
    },
    "related_terms": [
      "S3",
      "SSE-S3",
      "KMS",
      "AWS KMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 203,
    "topic": "",
    "question_cn": "一家金融公司的客户通过发送短信要求与财务顾问预约。在 Amazon EC2 实例上运行的 Web 应用程序接受指定请求。通过应用程序将文本消息发布到 Amazon Simple Queue Service 队列中。另一个运行在 EC2 实例上的应用程序然后向客户发送会议邀请和会议确认邮件。在成功的调度之后，该应用程序将会议信息存储在 Amazon DynamoDB 数据库中。随着公司的扩张，客户报告他们的会议请柬要花更长的时间才能到达。解决方案架构师应该建议什么来解决这个问题？",
    "options_cn": {
      "A": "在 DynamoDB 数据库前添加 DynamoDB Accelerator (DAX) 集群。",
      "B": "在接受预约请求的 Web 应用程序前面添加一个 Amazon API Gateway。",
      "C": "添加 Amazon CloudFront。将原应用程序设置为接受指定请求的 Web 应用程序。",
      "D": "为发送会议邀请的应用程序添加一个自动缩放组。将自动缩放组配置为基于队列深度的缩放组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Auto Scaling",
      "Performance"
    ],
    "explanation": {
      "analysis": "考察 SQS 队列、Auto Scaling，以及解决消息处理延迟的方案。",
      "why_correct": "选项 D 解决了问题，即消息处理的延迟，因为发送邀请的应用程序的负载过大，在 SQS 队列中堆积了大量消息，添加一个自动缩放组，并且基于队列的深度进行缩放，可以根据消息的积压情况进行动态扩展，从而加快会议邀请的发送速度。",
      "why_wrong": "选项 A 解决不了问题。DAX 用于加速 DynamoDB 的读取性能，跟消息处理的延迟没有关系。 选项 B 解决不了问题。Amazon API Gateway 解决了 API 访问的问题，但是跟消息处理的延迟没有关系。选项 C 解决不了问题。CloudFront 用于加速静态内容的分发，跟消息处理的延迟没有关系。"
    },
    "related_terms": [
      "DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon API Gateway",
      "Amazon CloudFront",
      "API Gateway",
      "Auto Scaling",
      "API Gateway"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 204,
    "topic": "",
    "question_cn": "一家在线零售公司有5000万活跃客户，每天收到超过25000个订单。该公司为客户收集购买数据并将这些数据存储在Amazon S3上。其他客户数据存储在Amazon RDS中。该公司希望向各个团队提供所有数据以便团队能够进行分析。解决方案必须提供管理数据的细粒度权限的能力并且必须最小化操作开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将购买数据直接写入Amazon RDS。使用IAM访问控件限制访问。",
      "B": "定期将数据从Amazon RDS复制到Amazon S3。创建一个AWS Glue爬虫。使用Amazon Athena查询数据。使用S3策略限制访问。",
      "C": "通过使用AWS Lake Formation创建一个数据湖。创建一个AWS Glue连接到Amazon RDS。在Lake Formation注册S3桶。使用Lake Formation通道控制来限制通 。",
      "D": "创建一个Amazon Redshift集群。计划一个Lambda功能定期从Amazon RDS和Amazon S3到Amazon Redshift数据。使用Amazon Redshift访问控制限制访问。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Data Lake",
      "Data Access Control"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，Lake Formation可以简化数据湖的建立，提供细粒度的权限控制，并减少操作开销。 Glue 可以自动发现数据结构， Athena 可以进行查询。",
      "why_correct": "选项 C 使用 AWS Lake Formation 构建数据湖，提供了精细的访问控制。AWS Glue 用于数据发现和ETL，Amazon Athena 用于查询。可以减少操作开销。",
      "why_wrong": "选项 D  使用 Redshift 集群，虽然可以用于数据分析，但配置和管理更复杂，操作开销较高。选项 B 将数据复制到 S3 再使用 Athena，但没有提供细粒度的权限控制。选项 A 直接写入 RDS，扩展性有限，不符合题意。"
    },
    "related_terms": [
      "RDS",
      "IAM",
      "S3",
      "AWS Glue",
      "Athena",
      "Lake Formation",
      "Redshift",
      "Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 205,
    "topic": "",
    "question_cn": "一家公司在一个内部数据中心托管一个营销网站。网站由静态文档组成，运行在单个服务器上。管理员不经常更新网站内容，并使用 SFTP 客户端上传新文档。该公司决定在 AWS 上开设网站并使用 Amazon CloudFront。该公司的解决方案设计师创建了一个 CloudFront 分布。解决方案架构师必须设计最具成本效益和弹性的网站托管架构以作为 CloudFront 的源。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Lightsail 创建一个虚拟服务器。在 Lightsail 实例中配置 SFTP 服务器。通过使用 SFTP 客户端上传网站内容。",
      "B": "为 Amazon EC2 实例创建一个 Auto Scaling 组。使用 Application Load Balancer。通过使用 SFTP 客户端上传网站内容。",
      "C": "创建一个私有 Amazon S3 存储桶。使用 S3 存储桶策略允许从 CloudFront 原产地访问身份 (OAI) 进行访问。上传网站内容使用 AWS CLI。",
      "D": "创建一个公共 Amazon S3 存储桶。为 SFTP 配置 AWS S3 Transfer Acceleration。配置网站托管的存储桶。通过使用 SFTP 客户端上传网站内容。"
    },
    "vote_percentage": "76%",
    "tags": [
      "S3 Static Website Hosting",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考察静态网站托管，S3 和 CloudFront 的结合，以及最优化成本。",
      "why_correct": "选项 C 使用 S3 存储桶作为 CloudFront 的源，可以实现静态网站的托管，S3 存储桶策略允许 OAI 访问，确保只有 CloudFront 才能访问 S3 上的内容，保证了安全性。 使用 AWS CLI 上传文件，可以实现文件上传的自动化。 这是成本最低的方案。",
      "why_wrong": "选项 A 使用 Lightsail 实例，运维成本相对较高。选项 B 使用 EC2 Auto Scaling，运维成本更高。选项 D 使用 SFTP 客户端上传文件，增加了复杂性，并且 SFTP 不适用于 S3。"
    },
    "related_terms": [
      "Lightsail",
      "SFTP",
      "CloudFront",
      "EC2",
      "Auto Scaling",
      "Application Load Balancer",
      "S3",
      "OAI",
      "AWS CLI",
      "S3 Transfer Acceleration"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 206,
    "topic": "",
    "question_cn": "一家公司希望管理亚马逊机器图像(AMI)。该公司目前将AMI复制到AMI成立的同一地区。该公司需要设计一个AWS API，EC2 API应用程序来捕捉 API 调用并在公司帐户中被调用时发出警报。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个Lambda函数用于查询CloudTrail日志并在检测到创建图像API 调用时发送警报。",
      "B": "将更新后的日志发送到Amazon S3时，使用Amazon Simple Notification Service(SNS)  Amazon SNS来配置CloudTrail。使用Amazon Athena创建一个新API的表并在检测到API 调用时查询创建映像。",
      "C": "为创建图像API 调用创建一个Amazon EventBridge Amazon EventBridge事件规则。将目标配置为Amazon Simple Notification Service(SNS) Amazon SNS主题以便在API检测到创建图像API 调用时发送警报。",
      "D": "配置一个Amazon Simple Queue Service(SQS) Amazon SQS队列作为CloudTrail日志的目标。当检测到创建图像API 调用时，创建一个Lambda函数向Amazon Simple Notification Service(SNS) Amazon SNS主题发送警报。"
    },
    "vote_percentage": "72%",
    "tags": [
      "CloudTrail",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，使用 EventBridge 可以更直接地响应CloudTrail事件，无需轮询或复杂的日志处理，减少了操作开销。 EventBridge可以监控特定API的调用，触发SNS通知。",
      "why_correct": "选项 C 使用 EventBridge 监听 CloudTrail 事件，当检测到创建 AMI 的 API 调用时，EventBridge 触发 SNS 通知。这种方法简单高效，无需编写额外的查询或轮询操作。",
      "why_wrong": "选项 A 需要使用 Lambda 轮询 CloudTrail 日志，增加了复杂性和延迟。选项 B 使用 Athena 查询 CloudTrail 日志，增加了额外的步骤和成本。选项 D  使用 SQS 和 Lambda，需要额外的基础设施和管理工作。"
    },
    "related_terms": [
      "AMI",
      "EC2",
      "CloudTrail",
      "Lambda",
      "SNS",
      "Amazon SNS",
      "Athena",
      "EventBridge",
      "EventBridge",
      "SQS",
      "Amazon SQS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 207,
    "topic": "",
    "question_cn": "一个公司拥有一个异步 API，用于吸收用户请求，并根据请求类型将请求发送到适当的微服务中进行处理。该公司正在使用 Amazon API Gateway 来部署 API 的前端，以及一个使用 Amazon DynamoDB 来存储用户请求，然后再将其分配到处理微型服务之前的 Lambda 函数。该公司在预算允许的情况下提供了尽可能多的 DynamoDB 吞吐量，但该公司仍面临可用性问题并正在失去用户请求。解决方案架构师应该如何在不影响现有用户的情况下解决这个问题？",
    "options_cn": {
      "A": "在 API Gateway 上添加带服务器端节流限制的节流。",
      "B": "使用 DynamoDB Accelerator (DAX) 和 Lambda 缓冲写入 DynamoDB。",
      "C": "为带有用户请求的表创建一个辅助索引。",
      "D": "使用 Amazon Simple Queue Service (SQS) 队列和 Lambda 来缓冲对 DynamoDB 的写入。"
    },
    "vote_percentage": "98%",
    "tags": [
      "DynamoDB",
      "SQS",
      "Throttling"
    ],
    "explanation": {
      "analysis": "考察如何解决 DynamoDB 写入吞吐量问题，同时保证用户可用性。",
      "why_correct": "选项 D 使用 SQS 队列作为 DynamoDB 写入的缓冲，Lambda 函数从队列中读取数据，异步写入 DynamoDB，可以平滑突发的流量，避免 DynamoDB 达到吞吐量限制，从而提高应用程序的可用性。这种方式也提供了更好的弹性。",
      "why_wrong": "选项 A 在 API Gateway 上进行节流，会拒绝用户的请求，影响用户体验。选项 B 使用 DAX 缓存，可以加速读取操作，但对写入操作的帮助有限。选项 C 创建辅助索引，无法提高写入吞吐量，并且会增加 DynamoDB 的写入负载。"
    },
    "related_terms": [
      "API Gateway",
      "DynamoDB",
      "DAX",
      "Lambda",
      "SQS",
      "DynamoDB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 208,
    "topic": "",
    "question_cn": "一个公司需要将数据从Amazon EC2实例转移到Amazon S3桶。公司必须确保没有 API 调用和数据通过公共互联网路由。只有 EC2实例能够S3访问将数据上传到S3桶。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "在EC2实例所在的子网中为Amazon S3创建一个接口VPC端点。在S3桶上附加一个资源策略只允许EC2实例的IAM角色进行访问。",
      "B": "在EC2实例所在的可用性区域中为Amazon S3创建网关VPC端点。在端点上附加适当的安全组。在S3桶上附加一个资源策略只允许EC2实例的IAM角色进行访问。",
      "C": "从EC2实例中运行nslookup工具以获得S3桶的服务端点的私有IP地址。在路由表中创建一个路由为EC2实例提供对S3桶的访问。在S3桶上附加一个资源策略只允许EC2实例的IAM角色进行访问。",
      "D": "使用提供的可公开获得的JSON序列。文件获取S3桶服务端点的私有IP地址。在路由表中创建一个路由为EC2实例提供对S3桶的访问。在S3桶上附加一个资源策略只允许EC2实例的IAM角色进行访问。"
    },
    "vote_percentage": "57%",
    "tags": [
      "VPC Endpoint",
      "S3 Access"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，接口端点提供私有连接，且比网关端点更灵活，可以为每个可用区单独配置，符合题目“无公网路由”的要求。并且接口端点更安全，因为它们不依赖于网关。",
      "why_correct": "选项 A 使用接口 VPC 端点，允许 EC2 实例通过私有网络访问 S3，避免了公网访问。 使用 IAM 角色进行访问控制，增强了安全性。",
      "why_wrong": "选项 B 虽然使用了网关VPC端点，但相比于接口端点，网关端点不支持细粒度的可用区选择，并且配置较复杂。 选项 C 和 D 依赖私有 IP 地址，增加了维护难度和出错的风险，不如直接使用 VPC 端点方便。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "VPC",
      "VPC端点",
      "IAM",
      "IAM 角色",
      "IAM角色",
      "IAM 角色"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 209,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计一个被部署到 AWS 云的新应用程序的架构。该应用程序将在 Amazon EC2 按需实例上运行，并将在多个可用区自动扩展。EC2 实例将在一天中频繁地增加和减少。应用程序负载均衡器将处理负载分布。架构需要支持分布式会话数据管理。如果需要的话，公司愿意修改代码。解决方案架构师应该如何确保架构支持分布式会话数据管理？",
    "options_cn": {
      "A": "使用 Amazon ElastiCache 来管理和存储会话数据。",
      "B": "使用 Application Load Balancer (ALB) 的会话亲和性 (粘性会话) 来管理会话数据。",
      "C": "使用来自 Systems Manager 的会话管理器来管理会话。",
      "D": "在 AWS Security Token Service 中使用服务令牌操作来管理会话。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Session Management",
      "ElastiCache"
    ],
    "explanation": {
      "analysis": "考察分布式会话管理，以及各种解决方案的优缺点。",
      "why_correct": "选项 A 使用 Amazon ElastiCache，是一个完全托管的内存缓存服务，可以用于存储和管理会话数据，实现分布式会话管理，并且能够支持快速读写操作，非常适合会话存储。",
      "why_wrong": "选项 B 使用 ALB 的会话亲和性 (粘性会话)，虽然可以解决一些会话管理问题，但是负载均衡器需要将请求定向到同一个 EC2 实例，无法实现真正的分布式。选项 C 使用 Systems Manager 的会话管理器，不适用于存储会话数据。选项 D 使用 STS 管理令牌，不能解决会话数据存储问题。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "ElastiCache",
      "Application Load Balancer",
      "ALB",
      "Systems Manager",
      "AWS Security Token Service"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 210,
    "topic": "",
    "question_cn": "一家公司提供快速发展的食品递送服务。由于业务的增长，该公司的订单处理系统在高峰时段遇到了缩放问题。目前的架构包括 * 在Amazon EC2自动缩放组运行的一组Amazon EC2实例以收集应用程序的订单 * 在Amazon EC2自动缩放组运行的另一组EC2实例以完成订单 订单收集过程发生得很快，但订单完成过程可能需要更长的时间。不能因为缩放事件而丢失数据。解决方案架构师必须确保订单收集过程和订单执行过程能够在高峰时段适当地扩展。解决方案必须最大限度地利用公司的资源。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用Amazon CloudWatch度量来监视自动缩放组中每个实例的CPU。根据峰值工作量值配置每个自动缩放组的最小容量。",
      "B": "使用Amazon CloudWatch度量来监视自动缩放组中每个实例的CPU。配置一个CloudWatch警报以调用Amazon Simple Notification Service (SNS) Amazon SNS主题，根据需要创建额外的自动缩放组。",
      "C": "提供两个Amazon Simple Queue Service (SQS) Amazon SQS队列：一个用于订单收集，另一个用于订单实现。配置EC2实例来检查各自的队列。根据队列发送的通知来扩展自动扩展组。",
      "D": "提供两个Amazon Simple Queue Service (SQS) Amazon SQS队列：一个用于订单收集，另一个用于订单实现。配置EC2实例来检查各自的队列。根据每个实例计算的积压创建一个度量。根据这个度量标准对自动缩放组进行缩放。"
    },
    "vote_percentage": "88%",
    "tags": [
      "Auto Scaling",
      "SQS",
      "Monitoring"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，基于 SQS 队列中消息积压的数量来动态伸缩 EC2 实例，更能动态地响应负载变化，而且最大限度地利用了资源。",
      "why_correct": "选项 D 通过监控 SQS 队列的深度，来决定是否需要扩展。当 SQS 队列中消息积压数量增加时，自动伸缩组扩展，以处理更多的订单。该方案有效地利用了资源。",
      "why_wrong": "选项 C 仅仅根据 SQS 队列是否有消息就触发缩放，没有考虑消息的实际处理量。选项 A 和 B 仅使用 CPU 指标，无法准确反映订单处理的实际负载。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "CloudWatch",
      "SNS",
      "Amazon SNS",
      "SQS",
      "Amazon SQS",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 211,
    "topic": "",
    "question_cn": "一家公司拥有多个生产应用程序。其中一个应用程序包括来自亚马逊 RDS、Lambda、亚马逊 EC2、亚马逊简单通知服务和亚马逊简单队列服务。所有的公司资源都被标记为 应用程序 的标记名称和对应于每个应用程序的值。解决方案架构师必须提供识别 所有标记组件的最快解决方案。 哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS 云路径生成一个具有应用程序标记的资源列表。",
      "B": "使用 AWS CLI，在所有区域查询每个服务以报告标记组件。",
      "C": "在亚马逊 CloudWatch 日志中运行一个查询用应用程序标记报告组件。",
      "D": "使用 AWS 资源组标记编辑器运行查询以使用应用程序标记报告全局的资源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Tagging",
      "Resource Groups"
    ],
    "explanation": {
      "analysis": "考查如何快速查询和识别带有特定标签的 AWS 资源。",
      "why_correct": "选项 D 使用资源组标记编辑器，可以跨多个 AWS 服务和区域快速查询和报告资源，是最有效的方法。",
      "why_wrong": "选项 A 使用 AWS CloudTrail，需要分析审计日志，效率较低。选项 B 使用 CLI，需要编写脚本，手动操作较多。选项 C 使用 CloudWatch 日志，需要先将日志数据记录到 CloudWatch，效率不高。"
    },
    "related_terms": [
      "CloudWatch",
      "AWS CLI",
      "CloudWatch",
      "AWS 资源组",
      "IAM"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 212,
    "topic": "",
    "question_cn": "一家公司需要每天向亚马逊 S3 输出一次数据库以便其他团队访问。导出对象的大小在 2GB 到 5GB 之间。数据的访问模式变化很快。必须 3 立即提供数据而且最多可持续 个月。该公司需要最具成本效益的解决方案不会增加检索时间。 公司应使用哪一个 S3 存储类别来满足这些要求？",
    "options_cn": {
      "A": "S3 智能分层",
      "B": "S3 冰川即时检索",
      "C": "S3 标准",
      "D": "S3 标准 (S3-IA) 标准 不经常访问"
    },
    "vote_percentage": "75%",
    "tags": [
      "S3 Storage Classes",
      "S3 Intelligent-Tiering"
    ],
    "explanation": {
      "analysis": "考察 S3 存储类别的选择，以及对访问频率和成本的考量。",
      "why_correct": "S3 智能分层可以根据对象的访问频率自动在不同的存储层之间移动，满足频繁访问、快速检索的需求，并优化成本。",
      "why_wrong": "S3 冰川即时检索成本较低，但检索时间长，不满足立即提供数据的需求。S3 标准成本最高，不符合最具成本效益的要求。S3 标准-不经常访问 (S3-IA) 适用于访问频率较低的数据，不适用于每天访问的数据。"
    },
    "related_terms": [
      "S3",
      "S3 智能分层",
      "S3 冰川",
      "S3 标准",
      "S3-IA",
      "S3 标准 (S3-IA)",
      "不经常访问"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 213,
    "topic": "",
    "question_cn": "一家公司正在开发一款新的移动应用程序。公司必须实现适当的流量过滤以保护其应用负载均衡器防止常见的应用级攻击如 SQL 跨站点脚本或 注入。该公司的基础设施和运营人员极少。该公司需要减少其在管理、更新和保护其美国信息系统环境的服务器 方面的责任份额。 解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "使用 AWS WAF 设计 ALS 的规则并将它们与 ALS 联系起来。",
      "B": "启用公共主机使用亚马逊 S3 部署应用程序。",
      "C": "部署先进的 AWS Shield 并添加作为保护资源。",
      "D": "创建新的 ALS，将流量导向运行第三方防火墙的亚马逊 EC2 实例然后将流量传递到当前的 ALS。"
    },
    "vote_percentage": "72%",
    "tags": [
      "AWS WAF",
      "Application Load Balancer (ALB)"
    ],
    "explanation": {
      "analysis": "考查如何使用 AWS WAF 保护应用程序，减少运维负担。",
      "why_correct": "选项 A 使用 AWS WAF 与 ALB 集成，可以实现流量过滤和安全保护，且运维负担最小。",
      "why_wrong": "选项 B 使用 S3 部署应用程序，无法实现流量过滤。选项 C 使用 AWS Shield，提供了基本的 DDoS 保护，但无法实现应用层面的安全防护。选项 D 增加了运维复杂性，需要管理 EC2 实例上的第三方防火墙。"
    },
    "related_terms": [
      "AWS WAF",
      "ALB",
      "S3",
      "AWS Shield",
      "ALB",
      "EC2",
      "ALB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 214,
    "topic": "",
    "question_cn": "一家公司的报告系统每天提供了数百个CSV文件到Amazon S3桶。公司必须将这些文件转换为Apache Parquet格式，并必须将文件存储在转换后的数据桶中。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个Amazon EMR集群与Apache Spark安装。编写一个Spark应用程序来转换数据，使用Amazon EMR文件系统(EMRFS)将文件写入转换后的数据桶。",
      "B": "创建一个AWS Glue爬虫发现数据。创建一个AWS Glue提取、转换和负载(ETL)工作来转换数据。在输出步骤中指定转换后的数据S3桶。",
      "C": "使用AWS Batch创建具有Bash语法的作业定义以转换数据并将数据输出到已转换的数据桶。使用工作定义提交工作，将数组作业指定为作业类型",
      "D": "创建一个Lambda函数以转换数据并将数据输出到被转换的数据桶。为S3桶配置事件通知。指定Lambda函数作为事件通知的目的地。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Data Transformation",
      "ETL"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，AWS Glue 是一项托管的 ETL 服务，可以自动发现数据模式，生成 ETL 脚本，简化了数据转换流程。 并且，Glue可以更好地支持 Parquet 格式。",
      "why_correct": "选项 B  使用 AWS Glue  进行 ETL 操作，可以自动生成转换脚本，并且支持将数据转换为 Parquet 格式，并输出到S3桶。 易于使用，减少了开发工作。",
      "why_wrong": "选项 D  虽然可以使用 Lambda 函数进行数据转换，但需要手动编写转换代码，并需要配置 S3 事件通知，比 Glue 更加复杂。 选项 A 和 C 需要管理额外的基础设施（EMR 和 Batch），增加了运维复杂度。"
    },
    "related_terms": [
      "EMR",
      "Apache Spark",
      "EMRFS",
      "AWS Glue",
      "ETL",
      "S3",
      "AWS Batch",
      "Lambda",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 215,
    "topic": "",
    "question_cn": "一个公司有 700TB 的备份数据存储在其数据中心的网络附加存储 (NAS) 中。对于不经常的监管请求这些备份数据必须是可访问的而且 7 必须保留 年。该公司已决定将这些备份数据从其数据中心迁移到美国信息系统。迁移必须在一个月内完成。该公司在其公共互联网 500Mbps 连接上有 的专用带宽可用于数据传输。 解决方案架构师应该如何以最低的成本迁移和存储数据？",
    "options_cn": {
      "A": "订购 AWS Snowball 设备来传输数据。使用生命周期策略将文件转换到亚马逊 冰川深度档案库。",
      "B": "在数据中心和亚马逊 VPC 之间部署一个 VPN 连接。使用 AWS CLI 从内部复制数据到亚马逊 冰川。",
      "C": "提供一个 500Mbps 的 Direct Connect 连接和传输数据到亚马逊 S3。使用生命周期策略将文件转换到亚马逊 冰川深度档案库。",
      "D": "使用 AWS DataSync 来传输数据并在现场部署 DataSync 代理。使用 DataSync 任务从内部 NAS 存储到亚马逊 冰川的文件。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Snowball",
      "S3 Glacier Deep Archive",
      "Data Migration"
    ],
    "explanation": {
      "analysis": "考察大规模数据迁移到 AWS 的方案，以及如何选择合适的存储级别。",
      "why_correct": "选项 A 使用 Snowball 传输大量数据，速度快，成本较低。然后使用生命周期策略将数据转换为 Glacier Deep Archive，实现长期存储。",
      "why_wrong": "选项 B 使用 VPN 连接，传输速度受限于互联网带宽，速度慢。选项 C 使用 Direct Connect，虽然带宽高，但成本较高，且无法在一个月内完成迁移。选项 D 使用 DataSync，也需要较长的传输时间，不符合一个月完成的需求。"
    },
    "related_terms": [
      "NAS",
      "Snowball",
      "深度档案库",
      "VPC",
      "CLI",
      "Direct Connect",
      "S3",
      "DataSync",
      "DataSync 代理",
      "DataSync",
      "NAS",
      "冰川"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 216,
    "topic": "",
    "question_cn": "一家公司有一个无服务网站在亚马逊 S3 的桶中有数百万个对象。该公司使用 S3 桶作为亚马逊 CloudFront 分发的来源。该公司没有设置加密 S3，S3 的桶之前对象加载。解决方案架构师需要为所有现有对象和将来添加到 S3 桶中的所有对象启用加密。 用最少的努力来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个新的 S3 桶。打开新 S3 桶的默认加密设置。将所有现有对象下载到临时本地存储器 上传对象到新的 S3 桶。",
      "B": "打开 S3 桶的默认加密设置。使用 S3 库存功能创建一个 CSV 列出未加密对象的 文件。运行一个 批处理操作作业该作业使用复制命令对这些对象进行加密。",
      "C": "使用 AWS Key Management Service (AWS KMS) 创建一个新的加密密钥。更改 S3 桶上的设置使用 托管加密密钥 使用服务器端 S3 加密。打开 S3 桶版本控制。",
      "D": "在 AWS 管理控制台上导航到亚马逊 S3。浏览 S3 桶的对象。在加密区域排序。选择每个未加密的对象。使用修改按钮将默认 S3 加密设置应用于 S3 桶中的每个未加密对象。"
    },
    "vote_percentage": "90%",
    "tags": [
      "S3 Encryption",
      "S3 Batch Operations"
    ],
    "explanation": {
      "analysis": "考察如何为现有和新上传的 S3 对象启用加密。",
      "why_correct": "选项 B 使用 S3 批量操作，可以高效地对现有对象进行加密，并开启 S3 桶的默认加密，确保后续上传的对象也被加密。",
      "why_wrong": "选项 A 需要下载和上传所有对象，操作复杂，耗时。选项 C 使用 KMS 加密，需要管理密钥，增加了复杂性。选项 D 需要手动操作每个对象，效率极低。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "S3",
      "AWS KMS",
      "KMS",
      "S3",
      "S3 桶",
      "S3",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 217,
    "topic": "",
    "question_cn": "一家公司在Amazon EC2实例中运行一个全球Web应用程序，支持一个应用负载平衡器。应用程序在Amazon Aurora中存储数据。该公司需要创建一个灾难恢复解决方案并能够容忍长达30分钟的停机时间和潜在的数据丢失。解决方案不需要在主要基础设施健康的情况下处理负载。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将应用程序与所需的基础结构元素一起部署到位。使用Amazon Route 53路由来配置主动-被动故障转移。在第二个区域创建一个Aurora副本。",
      "B": "在第二个区域主持应用程序的缩小部署。使用Amazon Route 53配置活动-主动故障转移。在第二区域创建一个Aurora复制品。",
      "C": "在第二区域复制主基础设施。使用Amazon Route 53配置活动-主动故障转移。创建一个从最新快照恢复的Aurora数据库。",
      "D": "备份数据与AWS Backup。使用备份在第二个区域创建所需的基础设施。使用Amazon Route 53路由来配置主动-被动故障转移。在第二区域创造一个Aurora第二次原始实例。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Disaster Recovery",
      "Route 53"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，通过在另一个区域创建Aurora只读副本，并结合Route 53的DNS故障转移，可以实现快速的灾难恢复，且符合30分钟的停机时间容忍度。主动-被动的故障转移不需要一直处理负载，从而节省成本。",
      "why_correct": "选项 A 在另一个区域部署基础设施，并创建 Aurora 副本，通过 Route 53 进行故障转移，从而实现灾难恢复。主动-被动配置可以在主区域故障时快速切换到备用区域。",
      "why_wrong": "选项 D 相对复杂，使用了AWS Backup，备份和恢复所需的时间可能超过 30 分钟。选项 B 和 C 在主区域正常工作时，也需要处理负载，增加了成本。"
    },
    "related_terms": [
      "EC2",
      "Aurora",
      "Route 53",
      "Aurora",
      "Route 53",
      "Aurora",
      "Route 53",
      "Aurora",
      "AWS Backup",
      "Aurora"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 218,
    "topic": "",
    "question_cn": "一个公司有一个网站服务器运行在一个具有弹性 IP 地址的公共子网亚马逊 EC2 实例。默认安全组被分配给 EC2 实例。默认网络 ACL 已被 Web 443 修改以阻止所有流量。解决方案架构师需要使 Web 服务器可以从 443 端口的任何地方访问。 哪些步骤组合将完成这项任务？(选二)",
    "options_cn": {
      "A": "创建一个安全组允许从源 0.0.0.0/0 获得 443 端口 tml 端口。",
      "B": "创建一个具有规则的安全组以允许向目标 443 端口提供 0.0.0.0/0 TP 端口。",
      "C": "更新网络 ACL 允许从源 0.0.0.0/0 获得 443 端口 tml 端口。",
      "D": "更新网络 ACL 允许从源 0.0.0/0 和目的地 0.0.0/0 输入和出站 443 端口。",
      "E": "更新网络 ACL 允许从 32768-65535 到 0.0.0/0 的入站贸易协定端口和到 443 的入站端口。"
    },
    "vote_percentage": "69%",
    "tags": [
      "Security Groups",
      "Network ACLs",
      "EC2"
    ],
    "explanation": {
      "analysis": "考察 EC2 实例的安全组和网络 ACL 配置，确保 Web 服务器可以被访问。",
      "why_correct": "选项 A 在安全组中创建允许来自所有来源的 443 端口的规则。选项 E 更新网络 ACL，允许从客户端的临时端口到 Web 服务器的 443 端口的流量通过。",
      "why_wrong": "选项 B 在安全组中定义入站规则，但对于服务器响应，需要允许相应的出站流量。选项 C 无法单独通过修改网络 ACL 来开放 443 端口，还需要修改安全组。选项 D 设置 ACL 规则，允许出站流量，但无法满足访问需求。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "安全组",
      "网络 ACL",
      "ACL",
      "443 端口",
      "443",
      "TCP",
      "443"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 219,
    "topic": "",
    "question_cn": "一家公司的申请有性能问题。该应用程序是有状态的需要在亚马逊 EC2 实例上完成内存中的任务。该公司使用 CloudFormation 组来部署基础设 , 使用 M5 EC2， 实例家族。随着流量的增加应用程序的性能降低了。当用户试图访问应用程序时用户正在报告延迟。 哪种解决办法能最有效地解决这些问题？",
    "options_cn": {
      "A": "用在自动缩放组中运行的 T3 EC2 实例替换 EC2 实例。使用 AWS 管理控制台进行更改。",
      "B": "修改 CloudFormation 模板以便在自动缩放组中运行 EC2 实例。当需要增加时手动增加自动缩放组的期望容量和最大容量。",
      "C": "修改云形成模板。用 R5 EC2 实例替换 EC2 实例。使用亚马逊 CloudWatch 内置的 内存度量来跟踪未来容量规划的应用程序性能。",
      "D": "修改云图模板。用 R5 EC2 实例替换 EC2 实例。在 EC2 实例上部署亚马逊 CloudWatch 代理为未来的容量规划生成自定义的应用程序延迟度量。"
    },
    "vote_percentage": "97%",
    "tags": [
      "EC2 Instance Types",
      "CloudWatch",
      "Performance Tuning"
    ],
    "explanation": {
      "analysis": "考察如何提升 EC2 应用程序的性能。",
      "why_correct": "选项 D 替换实例类型，升级到 R5 实例可以提供更高的性能。部署 CloudWatch 代理可以收集应用程序延迟指标，用于未来的容量规划。",
      "why_wrong": "选项 A 替换实例类型，但 T3 实例可能不如 M5 实例性能好。选项 B 手动调整自动伸缩组容量无法实现自动化弹性。选项 C 只是替换实例类型，没有进行监控。"
    },
    "related_terms": [
      "EC2",
      "CloudFormation",
      "M5 EC2",
      "Auto Scaling",
      "T3 EC2",
      "AWS 管理控制台",
      "CloudFormation",
      "EC2",
      "R5 EC2",
      "CloudWatch",
      "EC2",
      "CloudWatch",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 220,
    "topic": "",
    "question_cn": "一个解决方案架构师正在使用亚马逊 API 网关设计一个新的 API，它将接收用户的请求。请求的数量变化很大，几个小时可以不收到一个 请求。数据处理将异步进行，但应在提出请求后几秒钟内完成。 API 解决方案架构师应该让 API 调用哪种计算服务来以最低成本交付需求？",
    "options_cn": {
      "A": "一种 Glue 工作",
      "B": "一个 Lambda 函数",
      "C": "亚马逊弹性库伯内特斯服务公司的集装箱化服务",
      "D": "由亚马逊生态服务公司提供的集装箱化服务"
    },
    "vote_percentage": "96%",
    "tags": [
      "API Gateway",
      "Lambda",
      "Asynchronous Processing"
    ],
    "explanation": {
      "analysis": "考察 API Gateway 后端计算服务的选择，以及对成本和异步处理的考量。",
      "why_correct": "选项 B 使用 Lambda 函数，满足异步处理、低延迟和成本效益的需求。API Gateway 可以触发 Lambda 函数。",
      "why_wrong": "选项 A 使用 Glue 工作，主要用于数据处理，不适合快速的异步处理。选项 C 和 D 是容器化服务，启动时间和资源消耗比 Lambda 高，成本也相对较高。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "Glue",
      "EKS",
      "ECS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 221,
    "topic": "",
    "question_cn": "一个公司运行一个应用程序在一组亚马逊 EC2 实例。出于遵守的原因公司必须保存所有应用程序日志文件七年。日志文件将由一个 必须能够并发访问所有文件的报告工具进行分析。 哪种存储方案最符合这些要求？",
    "options_cn": {
      "A": "亚马逊 EBS 弹性块商店 (Amazon EBS)",
      "B": "亚马逊 EFS 弹性文件系统",
      "C": "亚马逊 EC2 实例存储",
      "D": "亚马逊 S3"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Logging",
      "Long-term Storage"
    ],
    "explanation": {
      "analysis": "考察长期存储日志文件以及并发访问的需求。",
      "why_correct": "选项 D 使用 S3，满足长期存储、高可用性和并发访问的需求，并且成本较低。",
      "why_wrong": "选项 A 使用 EBS，适合单个 EC2 实例的数据存储，无法满足并发访问需求。选项 B 使用 EFS，文件系统访问，但是不适合长期存储。选项 C 使用 EC2 实例存储，数据会随实例的生命周期而丢失，无法满足长期保存的需求。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "EFS",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 222,
    "topic": "",
    "question_cn": "一家公司已经聘请了一个外部的供应商在该公司的 AWS 帐户上工作。供应商使用一个自动化的工具该工具存储在供应商拥有的 AWS 帐户中。卖方无法进入该公司的 AWS 帐户。 解决方案架构师应该如何授予供应商此权限？",
    "options_cn": {
      "A": "在公司的 IAM 帐户中创建一个 IAM 角色以授权对供应商 IAM 角色的访问。将适当的 IAM 策略附加到供应商所需权限的角色上。",
      "B": "在公司帐户中创建一个符合密码复杂性要求的 IAM 用户。为供应商要求的权限向用户附加适当的 IAM 策略。",
      "C": "在公司帐户中创建一个 IAM 组。将该工具的 用户从供应商帐户添加到组中。将适当的 IAM 策略附加到供应商要求的权限组 中。",
      "D": "通过在 IAM 控制台中选择作为提供者类型的 AWS 帐户 来创建一个新的身份提供者。提供供应商的 AWS 帐户标识和用户名。 将适当的 IAM 策略附加到新的供应商以获得供应商所需的权限。"
    },
    "vote_percentage": "87%",
    "tags": [
      "IAM Roles",
      "Cross-Account Access"
    ],
    "explanation": {
      "analysis": "考察如何安全地授权外部供应商访问 AWS 资源。",
      "why_correct": "选项 A 使用 IAM 角色进行跨账户访问，是最佳实践。供应商的 IAM 角色可以被授予访问公司帐户中角色的权限。",
      "why_wrong": "选项 B 使用 IAM 用户，会产生长期密钥管理和权限更新问题，不安全。选项 C 使用 IAM 组，无法实现跨账户访问。选项 D 创建身份提供商，需要配置 SAML 或 OpenID Connect，操作复杂，且无法满足授权需求。"
    },
    "related_terms": [
      "IAM",
      "IAM 角色",
      "IAM 策略",
      "IAM 用户",
      "IAM 组",
      "AWS 帐户"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 223,
    "topic": "",
    "question_cn": "一个公司已经部署了一个 Java 弹簧引导应用程序作为一个 POD，运行在亚马逊弹性库伯内特斯服务 (Amazon EKS) 的私人子网。应用程序需要将数据写入亚马逊 DynamoDB 表。解决方案架构师必须确保应用程序能够与 DynamoDB 表交互而不向互联网暴露流量。 解决方案架构师应该采取哪些步骤来实现这个目标？(选二)",
    "options_cn": {
      "A": "附加一个具有足够权限的 IAM 角色。",
      "B": "附加一个具有足够权限的 IAM 用户",
      "C": "ACL 允许通过私人子网络的与 DynamoDB 表进行出站连接。",
      "D": "为 DynamoDB 创建一个 VPC 端点。",
      "E": "在 Java 弹簧引导代码中嵌入访问密钥。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EKS",
      "DynamoDB",
      "VPC Endpoints"
    ],
    "explanation": {
      "analysis": "考察如何在 EKS 中安全地访问 DynamoDB，避免流量暴露到公网。",
      "why_correct": "选项 A 为 EKS Pod 附加 IAM 角色，授权访问 DynamoDB。选项 D 为 DynamoDB 创建 VPC 端点，使流量在 VPC 内传输，避免暴露到公网。",
      "why_wrong": "选项 B 使用 IAM 用户，不推荐。选项 C 修改 ACL，无法完全解决安全问题。选项 E 在代码中嵌入访问密钥，不安全。"
    },
    "related_terms": [
      "EKS",
      "DynamoDB",
      "IAM 角色",
      "IAM 用户",
      "ACL",
      "VPC 端点",
      "Java",
      "DynamoDB"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 224,
    "topic": "",
    "question_cn": "最近一家公司将其 Web 应用程序迁移到了 在一个 AWS 区域的亚马逊 EC2 实例中重新托管应用程序。该公司希望重新设计其应用程序架构使其具有高度的可用性和容错性。流量必须随机到达所有运行的 EC2 实例。 公司应采取哪些措施来满足这些要求？(选二)",
    "options_cn": {
      "A": "创建一个亚马逊 Route 53 故障转移路由策略。",
      "B": "创建一个亚马逊 Route 53 加权路由策略。",
      "C": "创建一个亚马逊 Route 53 多值答案路由策略。",
      "D": "启动三个 EC2 实例：一个可用性区域中的两个实例和另一个可用性区域中的一个实例。",
      "E": "发射四个 EC2 实例：一个可用区域中的两个实例和另一个可用区域中的两个实例。"
    },
    "vote_percentage": "67%",
    "tags": [
      "Route 53",
      "High Availability",
      "EC2"
    ],
    "explanation": {
      "analysis": "考察如何使用 Route 53 和 EC2 实例实现高可用性。",
      "why_correct": "选项 C 使用 Route 53 多值答案路由策略，可以将流量随机分发到多个实例。选项 E 启动多个 EC2 实例，分布在不同的可用区，确保高可用性和容错性。",
      "why_wrong": "选项 A 故障转移路由策略用于主备切换，不满足随机流量分发的需求。选项 B 加权路由策略用于根据权重分发流量，不满足随机流量分发的需求。选项 D 实例数量较少，容错性较低。"
    },
    "related_terms": [
      "EC2",
      "Route 53",
      "可用性区域"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 225,
    "topic": "",
    "question_cn": "一家媒体公司收集和分析用户活动数据。该公司希望将此功能迁移到AWS服务。用户活动数据存储将继续增长并将是小字节SQL的大小。该公司需要建立一个高度可用的数据摄入解决方案以便利对现有数据和新数据的需求分析使用SQL。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将活动数据发送到Amazon Kinesis Data Firehose。将流配置为将数据传输到Amazon S3桶。",
      "B": "将活动数据发送到Amazon Kinesis Data Firehose传递流。配置流将数据传递到Amazon Redshift集群。",
      "C": "将活动数据放在Amazon S3桶中。在数据到达S3桶时，将Amazon Lambda配置为在数据上运行函数。",
      "D": "在Amazon EC2实例上创建一个摄入服务，该实例分布在多个可用性区域。配置服务将数据转发到Amazon RDS多AZ数据库。"
    },
    "vote_percentage": "95%",
    "tags": [
      "Data Ingestion",
      "Kinesis Data Firehose"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，将数据直接摄入 Redshift 集群，可以实现高效的数据分析，并且 Kinesis Data Firehose 可以自动完成数据的写入。与将数据写入S3再导入Redshift相比，更简单和高效。",
      "why_correct": "选项 B 使用 Kinesis Data Firehose 将活动数据传递到 Amazon Redshift 集群，实现了直接的数据摄取和分析流程。 Firehose 简化了数据流入流程，Redshift 是一个数据仓库，用于高效的 SQL 分析。",
      "why_wrong": "选项 A 将数据写入 S3，需要额外的步骤来将数据加载到 Redshift 中，增加了复杂性。 选项 C 和 D 需要更多的工作来实现，且成本较高。"
    },
    "related_terms": [
      "Kinesis Data Firehose",
      "S3",
      "Lambda",
      "EC2",
      "RDS",
      "多AZ",
      "SQL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 226,
    "topic": "",
    "question_cn": "一家公司通过使用在亚马逊EC2实例上运行的REST Web服务应用程序从成千上万的远程设备中收集数据。EC2实例接收原始数据转换,并将原始数据存储在亚马逊S3桶中。远程设备的数量将很快增加到数百万个。该公司需要一个高度可伸缩的解决方案最大限度地减少运营开销。解决方案架构师应该采取哪些步骤来满足这些需求？选二。",
    "options_cn": {
      "A": "在亚马逊S3中使用AWS Glue处理原始数据。",
      "B": "使用亚马逊Route 53将流量路由到不同的EC2实例。",
      "C": "增加更多的EC2实例以适应越来越多的传入数据。",
      "D": "将原始数据发送到亚马逊简单队列服务(Amazon SQS)。使用EC2实例来处理数据。",
      "E": "使用亚马逊API Gateway发送原始数据到亚马逊运动数据流。配置亚马逊Kinesis Data Firehose以使用数据流作为一个源将数据传递到亚S3。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "S3 Data Processing"
    ],
    "explanation": {
      "analysis": "考查如何设计高可伸缩、低运维成本的架构。核心是通过Kinesis和S3来实现数据收集和存储。",
      "why_correct": "选项A：使用Glue处理数据，可以简化数据处理流程。选项E：使用Kinesis Data Firehose可以实现高吞吐的数据流，并直接将数据传输到S3。",
      "why_wrong": "选项B：Route 53主要用于DNS解析和流量管理，不解决数据摄入问题。选项C：简单增加EC2实例无法解决数据量爆发的问题，且运维成本高。选项D：SQS虽然可以解耦，但不是最佳的数据摄入方案，且增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "REST Web服务",
      "S3",
      "AWS Glue",
      "Route 53",
      "SQS",
      "API Gateway",
      "Kinesis Data Firehose",
      "S3"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 227,
    "topic": "",
    "question_cn": "一家公司需要保留它的AWS CloudTrail日志三年。该公司正在通过使用来自母账户的组织对一组账户强制执行CloudTrail。CloudTrail目标S3桶配置了版本控制启用。一个生命周期策略已经到位可以在一年后删除当前对象。在使用S3桶的第四年之后，S3桶的指标显示对象的数量继续上升。然而提供给S3桶的新CloudTrail日志的数量保持一致。哪个解决方案将以最具成本效益的方式删除三年以上的对象？",
    "options_cn": {
      "A": "配置该组织的集中CloudTrail路径使其在三年后失效。",
      "B": "配置S3生命周期策略以删除先前版本和当前版本。",
      "C": "创建一个Lambda函数从亚马逊S3中枚举和删除超过三年的对象。",
      "D": "将父帐户配置为交付到S3桶的所有对象的所有者。"
    },
    "vote_percentage": "91%",
    "tags": [
      "S3 Lifecycle Policy",
      "CloudTrail Retention"
    ],
    "explanation": {
      "analysis": "考察S3生命周期策略和CloudTrail日志的保留策略。核心是利用S3的生命周期策略删除旧的CloudTrail日志。",
      "why_correct": "选项B：S3生命周期策略是删除旧版本对象的最佳方式，也是最符合成本效益的方式。",
      "why_wrong": "选项A：配置集中CloudTrail路径使其在三年后失效，无法删除已有的日志，也无法满足保留需求。选项C：使用Lambda函数删除对象会增加运维成本，不如S3生命周期策略。选项D：改变对象所有者与删除旧日志无关。"
    },
    "related_terms": [
      "CloudTrail",
      "S3",
      "生命周期策略",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 228,
    "topic": "",
    "question_cn": "一家公司有一个API，它从一组监控设备中接收实时数据。将此数据存储在亚马逊RDS数据库实例中供以后分析。监控设备发送到API的数据量波动。在流量大的时候，通常会返回超时错误。在检查了日志之后，该公司确定数据库无法处理来自API的写入流量。解决方案架构师必须最大限度地减少与数据库连接的数量并且必须确保数据不会在繁忙的流量期间丢失。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将RDS实例的大小增加到具有更多可用内存的实例类型。",
      "B": "将RDS实例修改为多AZ实例。将应用程序配置为写入所有活动的数据库实例。",
      "C": "修改API将传入的数据写入到亚马逊简单队列服务(Amazon SQS)队列中。使用亚马逊调用的Lambda函数将数据从队列写入数据库。",
      "D": "修改API将传入的数据写入亚马逊简单通知服务(Amazon SNS)主题。使用亚马逊调用的Lambda函数将数据从主题写入数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Lambda",
      "RDS"
    ],
    "explanation": {
      "analysis": "考察如何解决数据库写入压力问题，并保证数据不丢失。核心是引入消息队列解耦。",
      "why_correct": "选项C：使用SQS作为消息队列，可以缓冲写入流量，避免数据库过载，并且保证数据不丢失，Lambda函数可以异步处理数据库写入。",
      "why_wrong": "选项A：增加数据库实例的内存可能无法解决问题，也无法应对突发流量。选项B：多AZ可以提高可用性，但不能解决写入压力问题。选项D：SNS主要用于通知，不能很好地解决写入压力问题。"
    },
    "related_terms": [
      "RDS",
      "API",
      "SQS",
      "Lambda",
      "SNS",
      "多AZ"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 229,
    "topic": "",
    "question_cn": "一家公司管理自己的亚马逊EC2实例运行MySQL数据库。随着需求的增加或减少，该公司正在手动管理复制和缩放。该公司需要一个新的解决方案以简化在其数据库层中添加或删除所需计算能力的过程。解决方案还必须提供更好的性能、规模和耐久性，从操作上最小的努力。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将数据库迁移到亚马逊Aurora MySQL。",
      "B": "将数据库迁移到亚马逊Aurora Serverless。",
      "C": "将MySQL数据库组合到一个较大的EC2数据库中。在较大的EC2实例上运行较大的数据库。",
      "D": "为数据库层创建自动缩放组。将现有数据库迁移到新环境中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora",
      "MySQL",
      "RDS"
    ],
    "explanation": {
      "analysis": "考察如何实现数据库的自动伸缩和高可用，以及迁移方案。核心是选择Aurora。",
      "why_correct": "选项A：Aurora MySQL提供了自动伸缩、高可用性和更好的性能。",
      "why_wrong": "选项B：Aurora Serverless更适合流量不稳定的场景，并不一定优于Aurora MySQL。选项C：将MySQL数据库组合到一个较大的EC2实例上，无法实现自动伸缩和高可用。选项D：为EC2数据库创建自动伸缩组，无法解决数据库本身的问题，运维复杂。"
    },
    "related_terms": [
      "EC2",
      "MySQL",
      "Aurora MySQL",
      "Aurora Serverless",
      "自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 230,
    "topic": "",
    "question_cn": "一家公司担心的是正在使用的两个NAT实例将无法支持该公司申请所需的流量。解决方案架构师希望实现一个高度可用、容错和自动可伸缩的解决方案。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "删除两个NAT实例并在同一可用性区用两个NAT网关替换它们。",
      "B": "对于不同可用性区域的EC2实例使用具有网络负载平衡器的自动缩放组。",
      "C": "删除两个NAT实例并在不同的可用性区域用两个NAT网关替换它们。",
      "D": "将两个NAT实例替换为不同可用性区域中的NAT实例并部署一个网络负载平衡器。"
    },
    "vote_percentage": "96%",
    "tags": [
      "NAT Gateway",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考察如何实现NAT服务的HA和伸缩性。核心是用NAT网关替换NAT实例。",
      "why_correct": "选项C：使用多个NAT网关部署在不同可用区，可以实现高可用和容错。NAT网关是AWS托管服务，也更容易伸缩。",
      "why_wrong": "选项A：在同一可用区使用多个NAT网关无法保证可用性。选项B：使用网络负载均衡器和EC2实例搭建NAT实例，无法解决NAT实例的运维问题，也无法实现自动伸缩。选项D：部署NAT实例不能解决现有问题，而且需要额外运维。"
    },
    "related_terms": [
      "NAT实例",
      "NAT网关",
      "网络负载均衡器",
      "可用性区",
      "自动缩放组"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 231,
    "topic": "",
    "question_cn": "一个应用程序运行在一个具有EC2弹性IP地址的亚马逊VPC实例上。应用程序需要访问VPC中的数据库。两个VPC都在同一个AWS帐户中。哪个解决方案将提供所需的访问最安全？",
    "options_cn": {
      "A": "创建一个EC2实例安全组允许从VPC中的应用程序服务器的公共IP地址获得所有流量。",
      "B": "配置VPC与VPC之间的窥视连接",
      "C": "使数据库实例可以公开访问。为EC2实例分配一个公共IP地址。",
      "D": "将具有弹性IP地址的EC2实例启动到VPC-B中。通过新的EC2实例代理所有请求。"
    },
    "vote_percentage": "88%",
    "tags": [
      "VPC Peering",
      "Security"
    ],
    "explanation": {
      "analysis": "考察VPC互联的安全性和最佳实践。核心是使用VPC Peering。",
      "why_correct": "选项B：VPC Peering 提供了安全且私密的VPC间通信方式。",
      "why_wrong": "选项A：使用公共IP和安全组不安全，且会暴露实例。选项C：使数据库公开访问极不安全，不推荐。选项D：通过EC2代理增加复杂性和开销，非最佳实践。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "EC2",
      "弹性IP",
      "安全组",
      "VPC",
      "VPC 窥视",
      "公共IP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 232,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例中为其客户运行演示环境。每个环境都在自己的VPC中进行隔离。当RDP或SSH访问环境时需要通知公司的运营团队。",
    "options_cn": {
      "A": "在检测到RDP或SSH访问时配置亚马逊CloudWatch应用程序的洞察力以创建系统管理器。",
      "B": "用附有亚马逊管理实例策略的具有IAM角色的EC2实例配置EC2实例。",
      "C": "将VPC流日志发布到亚马逊CloudWatch日志。创建所需的公制滤波器。创建一个亚马逊CloudWatch公制报警与通知行动当警报处于报警状态。",
      "D": "配置一个亚马逊事件桥规则来监听EC2类型的事件的状态更改通知。将亚马逊简单通知服务(Amazon SNS)主题设置为目标。同意操作团队讨论这个主题"
    },
    "vote_percentage": "79%",
    "tags": [
      "CloudWatch",
      "EC2 monitoring"
    ],
    "explanation": {
      "analysis": "考察如何监控EC2实例的访问，并及时通知团队。核心是CloudWatch监控和告警。",
      "why_correct": "选项C：使用CloudWatch日志和告警，可以监控RDP和SSH的登录事件，并及时通知运营团队。",
      "why_wrong": "选项A：CloudWatch应用程序的洞察力不直接支持RDP/SSH的监控。选项B：IAM角色主要用于权限管理。选项D：EC2状态更改通知无法监控RDP/SSH登录事件。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "RDP",
      "SSH",
      "CloudWatch",
      "System Manager",
      "IAM 角色",
      "EC2",
      "VPC 流日志",
      "CloudWatch Logs",
      "CloudWatch",
      "SNS",
      "EventBridge",
      "SNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 233,
    "topic": "",
    "question_cn": "一个解决方案架构师已经创建了一个新的AWS帐户并且必须确保帐户根用户访问。哪些行动组合将实现这一点？选二。",
    "options_cn": {
      "A": "确保根用户使用强密码",
      "B": "对根用户启用多因素身份验证。",
      "C": "将根用户访问密钥存储在一个加密的亚马逊S3桶。",
      "D": "将根用户添加到包含管理权限的组中",
      "E": "将所需权限应用于具有内联策略文档的根用户。"
    },
    "vote_percentage": "79%",
    "tags": [
      "IAM Best Practices",
      "Security"
    ],
    "explanation": {
      "analysis": "考察AWS账户安全最佳实践。核心是保护根用户。",
      "why_correct": "选项A：强密码是保护根用户的第一步。选项B：MFA是增强根用户安全性的重要措施。",
      "why_wrong": "选项C：不应该存储根用户的访问密钥，无论是加密还是未加密。选项D：不应将根用户放入管理组。选项E：不应直接给根用户分配权限。"
    },
    "related_terms": [
      "根用户",
      "多因素身份验证",
      "S3",
      "IAM"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 234,
    "topic": "",
    "question_cn": "一家公司正在开发一种新的基于网络的客户关系管理应用程序。该应用程序将使用亚马逊EC2实例，这些实例由亚马逊弹性块存储(EBS)卷支持，后面的应用程序负载均衡器(ALB)。该应用程序还将使用亚马逊Aurora数据库。应用程序的所有数据必须在休息和传输时加密。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS Key Management Service (AWS KMS) 证书在ALB上加密传输中的数据。使用证书管理器(ACM) 加密EBS卷和在休息时的极光数据库存储。",
      "B": "使用根帐户登录到AWS管理控制台。上传公司的加密证书。在根帐户中选择打开该帐户所有在休息和传输中的数据的加密选项。",
      "C": "使用AWS Key Management Service (AWS KMS) 加密EBS卷和静止的极光数据库存储。将证书管理器(ACM)证书附加到ALB上以便在传输过程中加密数据。",
      "D": "使用BitLocker对所有数据进行加密。将该公司的TLS证书密钥导入到AWS Key Management Service (AWS KMS)，将KMS密钥附加到ALB以便在传输过程中加密数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Encryption",
      "KMS",
      "ALB"
    ],
    "explanation": {
      "analysis": "考察如何在传输中和静态数据进行加密。核心是利用KMS和ACM。",
      "why_correct": "选项C：使用KMS加密EBS和Aurora数据，使用ACM为ALB配置SSL证书，实现传输加密和静态加密。",
      "why_wrong": "选项A：ACM不能用于EBS卷的加密。选项B：使用根账户操作不安全，并且不能提供针对Aurora的加密。选项D：BitLocker主要用于Windows系统，且TLS证书密钥不是KMS密钥的导入项。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "ALB",
      "Aurora",
      "AWS KMS",
      "ACM",
      "EBS",
      "Aurora",
      "ALB",
      "KMS",
      "BitLocker",
      "TLS",
      "KMS",
      "ALB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 235,
    "topic": "",
    "question_cn": "一家公司正在将其内部甲骨文数据库迁移到亚马逊Aurora PostgreSQL。数据库有几个应用程序写入同一个表。这些应用程序需要在，每次迁移之间用一个月逐一迁移。管理层对数据库的读写数量很高表示关切。在整个迁移过程中两个数据库必须保持数据同步。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "在初始迁移中使用数据库迁移服务(AWS DMS)。使用数据库迁移服务创建更改数据捕获复制任务和表映射以选择所有表。",
      "B": "在初始迁移中使用数据库迁移服务(AWS DMS)。使用数据库迁移服务来创建一个完整的负载加更改数据捕获复制任务和一个表映射来选择所有的表。",
      "C": "使用数据库迁移服务的架构转换工具使用内存优化复制实例。创建一个完整的负载加更改数据捕获复制任务和一个表映射来选择所有的表。",
      "D": "使用数据库迁移服务(AWS DMS)的架构转换工具使用计算优化的复制实例。创建一个完整的负载加更改数据捕获(CDF)复制任务和一个表映射来选择最大的表。"
    },
    "vote_percentage": "90%",
    "tags": [
      "DMS",
      "Database Migration"
    ],
    "explanation": {
      "analysis": "考察数据库迁移方案和DMS的使用。核心是利用DMS的架构转换工具和CDC功能。",
      "why_correct": "选项C：架构转换工具结合DMS，能够实现迁移，且使用内存优化实例可以减少复制延迟。创建CDC任务确保数据同步。",
      "why_wrong": "选项A、B、D：虽然都使用DMS，但DMS的架构转换工具对数据库的兼容性有更好的支持。选择哪个取决于对数据库的兼容性，和对读写量的关注程度。"
    },
    "related_terms": [
      "Aurora PostgreSQL",
      "AWS DMS",
      "CDF"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 236,
    "topic": "",
    "question_cn": "一个公司有一个三级的应用程序来分享图像。应用程序在前端层使用Amazon EC2实例，在应用层使用另一个 EC2实例，在数据库中使用第三个EC2实例。解决方案架构师必须设计一个可伸缩的、高可用性的解决方案，该解决方案对应用程序的更改最少。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用Amazon S3主机前端层。在应用程序层中使用Lambda函数。将数据库移到Amazon DynamoDB表。使用Amazon S3存储和服务用户的图像。",
      "B": "在前端层和应用层采用负载平衡的多AZ Elastic Beanstalk环境。将数据库移到具有多个读取副本的Amazon RDS数据库实例以服务用户的图像。",
      "C": "使用Amazon S3主机前端层。在应用程序层的自动缩放组中使用一组EC2实例。将数据库移动到内存优化实例类型以存储和服务用户的图像。",
      "D": "在前端层和应用层采用负载平衡的多AZ Elastic Beanstalk环境。将数据库移到Amazon RDS多AZ数据库实例。使用Amazon S3存储和服务用户的图像。"
    },
    "vote_percentage": "69%",
    "tags": [
      "Elastic Beanstalk",
      "RDS",
      "S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，Elastic Beanstalk可以简化部署和管理，RDS 多AZ 数据库实例提供高可用性，S3用于存储图像，符合可伸缩性和高可用性的要求。",
      "why_correct": "选项 D 在前端层和应用层使用负载均衡的 Elastic Beanstalk，简化了部署和扩展。使用 RDS 多 AZ 实例提供数据库的高可用性，用 S3 存储图像，符合可伸缩性和高可用性要求。",
      "why_wrong": "选项 A 将数据库切换到 DynamoDB 可能需要对应用程序进行较大修改，不符合“对应用程序的更改最少”的要求。 选项 B 和 C 没有充分利用弹性伸缩的能力， 并且没有提供足够的数据库高可用性。 "
    },
    "related_terms": [
      "EC2",
      "S3",
      "Lambda",
      "DynamoDB",
      "Elastic Beanstalk",
      "RDS",
      "多AZ",
      "自动缩放组",
      "内存优化"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 237,
    "topic": "",
    "question_cn": "在VPC-A中的亚马逊EC2实例上运行的应用程序需要访问VPC-B中的另一个EC2实例中的文件。两个EC2实例都在单独的AWS账户VPC-A和VPC-B中。网络管理员需要设计一个解决方案来配置对VPC-B中实例的安全访问。连接不应该有单一的故障点或带宽问题。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在VPC-A和VPC-B之间建立一个VPC窥视连接。",
      "B": "为在VPC-B中运行的EC2实例设置网关端点。",
      "C": "将虚拟专用网关附加到VPC-B并从VPC-A设置路由。",
      "D": "为在VPC-B中运行的EC2实例创建一个专用虚拟接口(VIF)并从VPC-A中添加适当的路由。"
    },
    "vote_percentage": "96%",
    "tags": [
      "VPC Peering",
      "VPC Interconnection"
    ],
    "explanation": {
      "analysis": "考察跨VPC访问的最佳实践。核心是使用VPC peering。",
      "why_correct": "选项A：VPC Peering提供了安全、高性能的VPC互联方式，且没有单点故障。是最佳方案。",
      "why_wrong": "选项B：网关端点用于访问AWS服务，不适用VPC之间的实例访问。选项C：使用VPN需要额外的配置和管理，不如VPC peering。选项D：VIF与Direct Connect关联，不适用于VPC互联。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "VPC 窥视连接",
      "网关端点",
      "虚拟专用网关",
      "专用虚拟接口(VIF)"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 238,
    "topic": "",
    "question_cn": "一家公司想在其工程师团队中试验单个AWS账户。一旦一个月内亚马逊EC2实例的使用超过了每个帐户的特定阈值，该公司就会得到通知。解决方案架构师应该做什么才能最经济有效地满足这一要求？",
    "options_cn": {
      "A": "使用成本资源管理器创建按服务分列的每日成本报告。用EC2实例过滤报告。配置成本资源管理器以在超过阈值时发送Amazon Simple Email Service(SES)  Amazon SES通知。",
      "B": "使用成本资源管理器创建按服务分列的每月成本报告。用EC2实例过滤报告。配置成本资源管理器以在超过阈值时发送Amazon Simple Email Service(SES)  Amazon SES通知。",
      "C": "使用AWS预算为每个帐户创建成本预算。把期限定为每月一次，设置EC2实例的范围。为预算设定一个警戒阈值。在超过阈值时，配置Amazon Simple Notification Service(SNS) Amazon SNS主题接收通知。",
      "D": "使用成本和使用率报表创建一个小时粒度的报表。将报告数据整合到Amazon Athena。使用Amazon EventBridge来安排Athena查询。在超过阈值时配置Amazon Simple Notification Service(SNS)  Amazon SNS主题接收通知。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Cost Optimization",
      "Budget",
      "Notifications"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，AWS 预算服务提供了更直接的成本监控和通知功能。通过设置预算和阈值，当成本超过阈值时，可以自动发送SNS通知。",
      "why_correct": "选项 C 使用 AWS 预算，针对每个账户创建成本预算，设置警戒阈值，并在超过阈值时通过 SNS 发送通知。这是直接、简单、高效的解决方案。",
      "why_wrong": "选项 B 虽然使用 Cost Explorer，但不如 Budget 直接和方便。选项 A 和 D 需要更多步骤，实现起来更复杂。"
    },
    "related_terms": [
      "EC2",
      "成本资源管理器",
      "EC2",
      "SES",
      "AWS 预算",
      "EC2",
      "SNS",
      "SNS",
      "成本和使用率报表",
      "Athena",
      "EventBridge",
      "Athena",
      "SNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 239,
    "topic": "",
    "question_cn": "解决方案架构师需要为公司的应用程序设计一种新的微服务。客户端必须能够调用HTTPS端点来到达微服务。微服务还必须使用IAM标识和访问管理(IAM)来验证调用。解决方案架构师将使用一个用Go 1.x编写的Lambda函数编写此微服务的逻辑。哪个解决方案将以最有效的方式部署函数？",
    "options_cn": {
      "A": "创建一个亚马逊API Gateway休息API。将方法配置为使用Lambda函数。在API Gateway上启用IAM身份验证。",
      "B": "为该函数创建一个兰布达函数 URL。指定AWS_IAM为身份验证类型。",
      "C": "创建一个亚马逊云端分布。将函数部署到兰布达 边缘。将IAM身份验证逻辑集成到边缘函数中。",
      "D": "创建一个亚马逊云端分布。将函数部署到云前函数。指定AWS_IAM为身份验证类型。"
    },
    "vote_percentage": "65%",
    "tags": [
      "API Gateway",
      "Lambda",
      "IAM"
    ],
    "explanation": {
      "analysis": "考察如何构建一个API服务，并实现IAM认证。核心是使用API Gateway。",
      "why_correct": "选项A：API Gateway提供了简便的REST API构建方式，可以配置IAM认证，与Lambda函数集成。",
      "why_wrong": "选项B：Lambda Function URL虽然简单，但功能有限，不支持自定义身份验证方式。选项C、D：Lambda@Edge主要用于CDN边缘计算，不适合标准REST API构建。"
    },
    "related_terms": [
      "HTTPS",
      "IAM",
      "Lambda",
      "API Gateway",
      "Lambda",
      "Lambda 边缘",
      "IAM",
      "CloudFront",
      "Lambda 边缘",
      "CloudFront"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 240,
    "topic": "",
    "question_cn": "一家公司以前将其数据仓库解决方案迁移到了AWS。该公司也有一个直接连接连接。公司办公室用户使用可视化工具查询数据仓库。数据仓库返回的查询的平均大小为50MB，而可视化工具发送的每个网页大约为500GB。数据仓库返回的结果集没有缓存。哪个解决方案为公司提供最低的数据传输出口成本？",
    "options_cn": {
      "A": "在网站上主持可视化工具并直接通过互联网查询数据仓库。",
      "B": "将可视化工具放在与数据仓库相同的区域中。在互联网上访问。",
      "C": "在现场主持可视化工具并直接通过在同一区域位置上的直接连接连接查询数据仓库。",
      "D": "将可视化工具置于与数据仓库相同的区域并通过在同一区域某个位置的直接连接连接访问该工具。"
    },
    "vote_percentage": "92%",
    "tags": [
      "Data Transfer",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，将可视化工具和数据仓库放在同一区域内，并且通过直接连接进行访问，可以避免数据传输费用，降低成本，同时还能提高性能。",
      "why_correct": "选项 D 将可视化工具与数据仓库放在同一区域内，并通过 Direct Connect 进行连接。由于数据传输在同一区域内，且通过 Direct Connect，可以最大程度地降低数据传输费用，并提高访问速度。",
      "why_wrong": "选项 A 和 B 通过互联网访问，会产生高昂的数据传输费用。选项 C 也是通过 Direct Connect，但是把工具放在了现场，仍然需要访问互联网。 "
    },
    "related_terms": [
      "数据仓库",
      "直接连接",
      "数据仓库",
      "S3",
      "可视化工具",
      "数据仓库",
      "区域",
      "直接连接",
      "数据仓库",
      "区域"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 241,
    "topic": "",
    "question_cn": "aws , 一个在线学习公司正在迁移到云。该公司将其学生记录保存在后格拉格数据库中。该公司需要一个解决方案即它的数据可以随时在多个美国信息系统区域在线提供。什么解决方案用最少的操作开销来满足这些需求？",
    "options_cn": {
      "A": "将后格拉格数据库迁移到亚马逊EC2实例上的后格拉格集群。",
      "B": "通过开启多功能将后格拉格数据库迁移到亚马逊RDS实例。",
      "C": "将后格拉格数据库迁移到亚马逊RDS数据库。在另一个区域创建读副本。",
      "D": "将后格拉格数据库迁移到亚马逊RDS数据库。设置数据库快照以复制到另一个区域。"
    },
    "vote_percentage": "79%",
    "tags": [
      "RDS",
      "Multi-AZ"
    ],
    "explanation": {
      "analysis": "考查 RDS 跨区域高可用方案选择。",
      "why_correct": "选项 C 通过创建跨区域读副本实现数据的多区域可用性，同时保证了最少的管理开销。",
      "why_wrong": "选项 A 依赖于用户手动搭建和维护数据库集群，运维成本高。 选项 B 仅仅迁移数据库，没有考虑高可用性。 选项 D 仅通过快照复制无法满足实时数据访问的需求。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "Multi-AZ",
      "Read Replica",
      "快照/Snapshot"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 242,
    "topic": "",
    "question_cn": "一家公司使用七个亚马逊EC2实例在Route 53上主持其网络应用程序。该公司要求所有健康的EC2实例的IP地址响应DNS查询并返回。应采用哪种策略来满足这一要求？",
    "options_cn": {
      "A": "简单路由策略",
      "B": "延迟路由策略",
      "C": "多值路由策略",
      "D": "地理定位路由政策"
    },
    "vote_percentage": "96%",
    "tags": [
      "Route 53",
      "Health Checks"
    ],
    "explanation": {
      "analysis": "考查 Route 53 的路由策略，特别是多值路由策略的使用场景。",
      "why_correct": "多值路由策略允许您将多个资源（如 EC2 实例）与一个 DNS 名称关联。Route 53 可以配置为仅返回正常运行的资源的 IP 地址，并且可以使用健康检查来实现这一功能。",
      "why_wrong": "简单路由策略和延迟路由策略不考虑实例的健康状态。地理定位路由策略根据用户的地理位置将流量路由到不同的资源，不满足题意。"
    },
    "related_terms": [
      "Route 53",
      "EC2",
      "DNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 243,
    "topic": "",
    "question_cn": "一个医学研究实验室生成与一项新研究相关的数据。该实验室希望将数据以最小的延迟提供给全国各地的诊所供其在办公室内基于S3文件的应用。数据文件存储在一个具有每个诊所只读权限的Amazon S3桶中。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "在每个诊所内部署一个AWS Storage Gateway文件网关作为虚拟机(VM)",
      "B": "将文件迁移到每个诊所的现场应用程序中，通过使用AWS医疗服务协会的数据化处理。",
      "C": "在每个诊所的现场部署一个AWS Storage Gateway卷网关作为虚拟机(VM)。",
      "D": "将Amazon Elastic File System (EFS)  Amazon EFS连接到每个诊所的内部服务器上。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Storage Gateway",
      "S3 Access"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，文件网关可以缓存 S3 数据到本地，减少延迟，同时保持 S3 桶的单点存储。 卷网关更适用于块存储。",
      "why_correct": "选项 A 在每个诊所部署文件网关，可以缓存 S3 文件到本地，减少延迟。文件网关可以作为虚拟机部署，易于管理。",
      "why_wrong": "选项 C 使用卷网关，不适用于文件共享。 选项 D  EFS 适用于在 AWS 内部共享文件，不适用于诊所的内部服务器。选项 B 将文件迁移到现场应用程序，增加了复杂性，不便于管理。"
    },
    "related_terms": [
      "S3",
      "AWS Storage Gateway",
      "AWS Storage Gateway 文件网关",
      "AWS Storage Gateway 卷网关",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 244,
    "topic": "",
    "question_cn": "一家公司使用的内容管理系统运行在一个亚马逊EC2实例上。EC2实例包含Web服务器和数据库软件。该公司必须高度开放其网站平台并使网站能够扩大规模以满足用户需求。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "将数据库移到亚马逊RDS并启用自动备份。在同一可用性区域手动启动另一个EC2实例。在可用性区域中配置应用程序负载平衡器并将两个实例设置为目标。",
      "B": "将数据库迁移到与现有EC2实例相同的可用性区域中的读取副本的亚马逊 Aurora实例。在同一可用性区域手动启动另一个EC2实例。配置应用程序负载平衡器并将两个EC2实例设置为目标。",
      "C": "将数据库移到亚马逊Aurora，并在另一个可用性区创建读副本。从EC2实例中创建一个亚马逊机器映像(AMI)。在两个可用性区域中配置应用程序负载平衡器。附加一个自动缩放组该组在两个可用性区域中使用该AMI。",
      "D": "将数据库移动到一个单独的EC2实例并将备份安排到亚马逊S3。从最初的EC2实例中创建一个亚马逊机器映像(AMI)。在两个可用性区域中配置应用程序负载平衡器。附加一个自动缩放组该组在两个可用性区域中使用该AMI。"
    },
    "vote_percentage": "97%",
    "tags": [
      "EC2",
      "RDS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考查 Web 应用程序的可扩展性和高可用性架构设计。",
      "why_correct": "选项 C 实现了数据库的高可用性，使用 Aurora 读副本，在不同可用区创建 AMI 和 自动伸缩组，提供高可用性和可扩展性。",
      "why_wrong": "选项 A 和 B 没有考虑数据库的高可用性，只在同一可用区中部署实例。 选项 D 的方案中数据库的备份没有实现高可用。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "自动备份",
      "可用性区域",
      "应用程序负载平衡器",
      "亚马逊 Aurora",
      "读副本",
      "AMI",
      "自动缩放组",
      "S3"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 245,
    "topic": "",
    "question_cn": "一家公司正在美国航空公司推出一个应用程序。应用程序使用一个应用程序负载平衡器 来引导一个目标组中至少两个亚马逊 EC2 实例的流量。实例位于每个环境的自动缩放组中。公司需要一个开发环境和一个生产环境 生产环境会有一段时间流量大？ 哪个解决方案将配置开发环境最具成本效益",
    "options_cn": {
      "A": "在开发环境中重新配置目标群体使其仅有一个 EC2实例作为目标。",
      "B": "将应用程序负载平衡算法更改为最小未完成请求。",
      "C": "减少两个环境中 EC2 实例的大小。",
      "D": "在开发环境的自动缩放组中减少 EC2 实例的最大数量。"
    },
    "vote_percentage": "56%",
    "tags": [
      "EC2 Auto Scaling",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "核心考点: 优化开发环境的成本效益。 注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，通过降低开发环境中EC2实例的最大数量，可以减少资源消耗，从而降低成本。",
      "why_correct": "选项D通过减少开发环境中 EC2 实例的最大数量，可以减少资源消耗，从而降低开发环境的成本。这符合成本效益的要求。",
      "why_wrong": "选项A 虽然可以降低成本，但可能影响开发环境的可用性。选项B和C与降低开发环境成本关系不大。"
    },
    "related_terms": [
      "应用程序负载平衡器",
      "EC2",
      "自动缩放组"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 246,
    "topic": "",
    "question_cn": "一家公司在多个可用性区域的亚马逊 EC2实例上运行一个Web应用程序。 EC2 实例在私有子网中。解决方案架构师实现互联网面向应用程序负载平衡器 (ALS), 并指定 EC2 实例为目标组。然而互联网流量并没有到达 EC2 实例。？ 解决方案架构师应该如何重新配置架构以解决这个问题",
    "options_cn": {
      "A": "用网络负载平衡器替换 ALS。在公共子网络中配置 NAT 网关以允许互联网流量。",
      "B": "将 EC2 实例移动到公共子网络。向 EC2 实例的安全组添加一条规则允许出站流量达到 0.0.0/0。",
      "C": "更新 EC2 实例的子网路由表通过因特网网关路由发送 流量。向 EC2 实例的安全组添加一条规则允许出站流量达到 0.0.0/0。",
      "D": "在每个可用区域中创建公共子网络。将公共子网与 ALS 联系起来。更新公共子网络的路由表并提供到私有子网络的路径。"
    },
    "vote_percentage": "83%",
    "tags": [
      "VPC",
      "Load Balancing",
      "Networking"
    ],
    "explanation": {
      "analysis": "核心考点: 解决互联网流量无法到达私有子网中的EC2实例的问题。 注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，将公共子网与ALB关联，并配置路由表，使流量可以到达私有子网中的EC2实例。",
      "why_correct": "选项D 允许互联网流量通过 ALB 路由到私有子网中的 EC2 实例。在每个可用区创建公共子网，ALB 关联公共子网，并配置路由表，提供到私有子网的路由。",
      "why_wrong": "选项A 使用了 NLB，但问题描述中使用了 ALB。选项B 没有考虑到私有子网的访问问题。选项C 缺少了将流量路由到私有子网的配置。"
    },
    "related_terms": [
      "EC2",
      "可用性区域",
      "应用程序负载平衡器",
      "Internet",
      "NAT 网关",
      "子网",
      "因特网网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 247,
    "topic": "",
    "question_cn": "一家公司已经为MySQL RDS在亚马逊中部署了一个数据库。由于事务的增加数据库支持团队正在报告针对 RDS 实例的缓慢读取并建议添加一个读副本。在实现此更改之前解决方案架构师应该采取哪些行动组合？ 选二。",
    "options_cn": {
      "A": "在RDS主节点上启用绑定日志复制。",
      "B": "为源数据库实例选择故障转移优先级。",
      "C": "允许在源数据库实例上完成长期运行的事务。",
      "D": "创建一个全局表并指定将提供该表的区域。",
      "E": "通过将备份保留期设置为 0 以外的值启用源实例上的自动备份。"
    },
    "vote_percentage": "71%",
    "tags": [
      "RDS",
      "Read Replicas",
      "Database"
    ],
    "explanation": {
      "analysis": "核心考点: 准备 RDS 读副本的配置。 注意: 此题官方答案为AC，但社区共识(投票最高)为CE。社区倾向CE的原因是，在创建读副本之前，需要启用备份，并且数据库主节点必须配置日志复制。",
      "why_correct": "选项 C：在创建读副本之前，应该确保源数据库上的事务能够正常完成，避免复制过程中出现问题。选项E：在创建读副本之前，应该启用自动备份，以保证数据的可恢复性。",
      "why_wrong": "选项A: 在已经存在数据库实例的情况下，不需要在 RDS 主节点上启用绑定日志复制。选项B：设置故障转移优先级与创建读副本关系不大。选项D: 创建全局表是 Aurora 的功能，而非MySQL RDS。"
    },
    "related_terms": [
      "MySQL RDS",
      "RDS",
      "读副本"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 248,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例上运行分析软件。该软件接受用户的工作请求以处理上传到亚马逊S3的数据。用户报告说一些提交的数据没有被处理，亚马逊 CloudWatch显示EC2实例有一个一致的CPU利用率达到或接近100%。公司希望提高系统性能并根据用户负载对系统进行规模化。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个EC2实例的副本。将所有实例放在应用程序负载平衡器后面。",
      "B": "为亚马逊S3创建一个VPC端点。更新软件以引用端点。",
      "C": "停止EC2实例。将实例类型修改为具有更强大CPU和更多内存的实例类型，重新启动实例。",
      "D": "将传入请求路由到亚马逊简单队列服务(SQS)。根据队列大小配置Auto Scaling组。更新软件以读取队列。"
    },
    "vote_percentage": "95%",
    "tags": [
      "EC2",
      "S3",
      "SQS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考查利用队列和自动伸缩来解决高负载下的性能问题。",
      "why_correct": "选项 D 解决了高 CPU 利用率的问题，通过 SQS 将请求进行解耦，然后利用自动伸缩组根据队列大小自动扩展 EC2 实例的数量，以处理负载。该方案具有可扩展性。",
      "why_wrong": "选项 A 只是简单地创建了副本，无法根据负载自动扩展。 选项 B 并不能解决实例的 CPU 压力问题。 选项 C 只是增加了单台实例的性能，无法满足系统的扩展性需求。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "CloudWatch",
      "CPU",
      "VPC",
      "VPC端点",
      "SQS",
      "Auto Scaling"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 249,
    "topic": "",
    "question_cn": "一个公司正在为位于AWS云中的媒体应用程序实现共享存储解决方案。公司需要能够使用SMB客户端访问数据。解决办法必须得到充分管理。哪个AWS解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Storage Gateway 卷网关。创建一个使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享",
      "B": "创建一个AWS Storage Gateway磁带网关。配置磁带使用亚马逊S3。连接应用服务器到磁带网关",
      "C": "创建一个亚马逊EC2 Windows实例。在实例中安装和配置文件共享角色。将应用程序服务器连接到文件共享",
      "D": "为文件服务器文件系统创建一个亚马逊 FSx for Windows File Server。将文件系统连接到应用程序服务器上。将应用程序服务器连接到文件系统"
    },
    "vote_percentage": "98%",
    "tags": [
      "FSx for Windows File Server",
      "SMB"
    ],
    "explanation": {
      "analysis": "考查共享存储解决方案的选择，SMB 客户端的访问支持，以及托管服务的选择。",
      "why_correct": "FSx for Windows File Server 是一个完全托管的文件存储服务，支持 SMB 协议，可以方便地被 Windows 客户端访问。 并且 FSx for Windows File Server 是一个完全托管的服务，符合题目的“充分管理”的要求。",
      "why_wrong": "选项 A 使用 Storage Gateway 文件网关，虽然可以提供 SMB 访问，但是需要自己管理。选项 B 使用磁带网关，不适用于文件共享。 选项 C  需要在 EC2 实例中搭建和维护文件共享服务，需要自行管理，不符合题意。"
    },
    "related_terms": [
      "AWS Storage Gateway",
      "AWS Storage Gateway 卷网关",
      "S3",
      "SMB",
      "EC2",
      "FSx for Windows File Server"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 250,
    "topic": "",
    "question_cn": "一家公司的安全团队要求将网络流量记录在VPC流日志中。这些日志将经常被访问90天然后断断续续地被访问。在配置日志时解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "使用亚马逊云表作为目标。将云表日志组的有效期定为90天",
      "B": "使用亚马逊运动作为目标。配置运动流以始终保留记录90天。",
      "C": "使用S3作为目标。配置云迹以保存到一个S3桶并启用智能分层。",
      "D": "使用亚马逊S3作为目标。启用生命周期策略在90天后将日志转换为标准IA。"
    },
    "vote_percentage": "92%",
    "tags": [
      "VPC Flow Logs",
      "S3 Lifecycle Policies",
      "Storage Tiering"
    ],
    "explanation": {
      "analysis": "核心考点: 配置 VPC 流日志的存储和生命周期。 注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，使用S3作为存储目标，并通过生命周期策略实现成本优化。",
      "why_correct": "选项D 通过使用 S3 作为目标，并启用生命周期策略将日志转换为标准-IA，实现了成本和访问频率的平衡。90天后将日志转换为标准-IA，能满足不频繁访问的需求。",
      "why_wrong": "选项A 使用了 CloudWatch Logs，这通常用于实时监控和分析，不适合长期存储。选项B 使用了 CloudTrail，这用于审计，不适合 VPC 流日志。选项C 使用了 S3，但缺少生命周期策略，无法优化存储成本。"
    },
    "related_terms": [
      "VPC",
      "VPC 流日志",
      "CloudWatch",
      "S3",
      "智能分层",
      "生命周期策略",
      "标准IA"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 251,
    "topic": "",
    "question_cn": "亚马逊EC2实例位于一个新的VPC中的私有子网中。这个子网没有出站互联网接入，但是EC2实例需要从外部供应商下载每月安全更新的能力。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个互联网网关并将其连接到VPC。将专用子网络路由表配置为使用互联网网关作为默认路由。",
      "B": "创建一个NAT网关并将其放在公共子网中。将专用子网络路由表配置为使用NAT网关作为默认路由。",
      "C": "创建一个NAT实例并将其放置在EC2实例所在的同一子网中。将专用子网络路由表配置为使用NAT实例作为默认路由。",
      "D": "创建一个互联网网关并将其连接到VPC。创建一个NAT实例并将其放置在EC2实例所在的同一子网中。将专用子网络路由表配置为使用互联网网关作为默认路由。"
    },
    "vote_percentage": "90%",
    "tags": [
      "VPC",
      "NAT Gateway",
      "Internet Access"
    ],
    "explanation": {
      "analysis": "考查如何在私有子网中配置出站互联网访问，以便 EC2 实例可以下载更新。",
      "why_correct": "选项 B  通过在公共子网中部署NAT网关，并将私有子网的路由表配置到NAT网关，提供了安全的出站互联网访问，并且简化了配置，不需要自己维护 NAT 实例。",
      "why_wrong": "选项 A 将导致私有子网的 EC2 实例具有公网 IP，不符合安全最佳实践。 选项 C 使用 NAT 实例，需要用户自己维护，增加了管理负担。 选项 D  使用了互联网网关，不符合题意。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "互联网网关",
      "NAT 网关",
      "NAT 实例",
      "子网",
      "路由表"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 252,
    "topic": "",
    "question_cn": "解决方案架构师需要设计一个存储客户机案例文件的系统。这些文件是公司的核心资产，非常重要。随着时间的推移，文件的数量会增加。这些文件必须同时从运行在亚马逊EC2实例上的多个应用服务器上访问。解决方案必须有内置的冗余。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "亚马逊弹性文件系统(EFS)",
      "B": "亚马逊弹性块存储(EBS)",
      "C": "亚马逊S3 + 亚马逊 Glacier 深度档案馆",
      "D": "人工智能辅助系统"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "Shared Storage"
    ],
    "explanation": {
      "analysis": "考查适用于多台 EC2 实例共享文件存储的方案，以及数据的持久性和可用性。",
      "why_correct": "EFS 提供了一个可扩展的、共享的文件系统，可以被多个EC2实例同时访问，并且具有内置的冗余和高可用性。 满足了题目中的所有要求。",
      "why_wrong": "选项 B EBS 是块存储，不能被多台 EC2 实例共享。 选项 C S3 虽然可以存储文件，但是不是一个文件系统，并且不适合频繁访问。 选项 D 不是一个存储解决方案。"
    },
    "related_terms": [
      "EC2",
      "EFS",
      "EBS",
      "S3",
      "Glacier"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 253,
    "topic": "",
    "question_cn": "IAM：解决方案架构师已经创建了两个IAM策略: policy1 和 policy2。两个保单都附属于一个 IAM 组。将一个云工程师作为IAM用户添加到IAM组中。云工程师将能够执行哪些操作？",
    "options_cn": {
      "A": "删除IAM用户",
      "B": "删除目录",
      "C": "删除亚马逊 EC2 实例",
      "D": "删除亚马逊 CloudWatch 日志中的日志"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "Permissions"
    ],
    "explanation": {
      "analysis": "考查 IAM 策略的继承和权限管理。",
      "why_correct": "EC2 实例的删除操作需要 EC2 相关的权限，只要 policy1 和 policy2 包含了删除 EC2 实例的权限，用户就可以执行删除 EC2 实例的操作。",
      "why_wrong": "选项 A  删除 IAM 用户需要 IAM:DeleteUser 权限。 选项 B  删除目录没有指定在那个服务中，缺少了上下文。 选项 D 删除 CloudWatch 日志需要 CloudWatch 相关的权限。 需要查看 policy1 和 policy2的具体策略才能判断。"
    },
    "related_terms": [
      "IAM",
      "IAM",
      "IAM用户",
      "EC2",
      "CloudWatch"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 254,
    "topic": "",
    "question_cn": "一家公司正在审查最近一个三层申请迁移到VPC的过程。安全团队发现最小特权原则不适用于亚马逊EC2安全组在应用程序层之间的出入口规则。解决方案架构师应该如何纠正这个问题？",
    "options_cn": {
      "A": "使用实例ID作为源或目的地创建安全组规则",
      "B": "使用安全组ID作为源或目标创建安全组规则。",
      "C": "使用 VPC CIDR块作为源或目标创建安全组规则。",
      "D": "使用子网CIDR块作为源或目标创建安全组规则。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Groups",
      "Least Privilege"
    ],
    "explanation": {
      "analysis": "考查安全组之间的通信，以及最小权限原则的实践。",
      "why_correct": "选项 B  通过使用安全组ID作为源或目标，可以实现不同应用层之间的隔离，只允许特定的流量通过，遵循最小权限原则。",
      "why_wrong": "选项 A 使用实例 ID ，需要对每个实例进行单独配置，增加了维护的复杂性。 选项 C  使用 VPC CIDR 块会允许所有 VPC 内的流量，过于宽松。 选项 D 使用子网CIDR 块， 过于宽松。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "安全组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 255,
    "topic": "",
    "question_cn": "一家公司有一个电子商务结帐工作流程，它向数据库写入订单并调用服务来处理支付。在结帐过程中用户正在经历超时。当用户重新提交签出表单时，将为相同的所需事务创建多个唯一的订单。解决方案架构师应该如何重构该工作流以防止创建多个订单？",
    "options_cn": {
      "A": "配置Web应用程序将订单消息发送到亚马逊动态数据消防软管(Kinesis Data Firehose)。设置支付服务从动态数据消防软管中检索消息并处理订单。",
      "B": "在AWS CloudTrail中创建一个规则以调用基于登录的应用程序路径请求的Lambda函数。使用Amazon Athena查询数据库，调用支付服务并传递订单信息。",
      "C": "将订单保存在数据库中。向亚马逊简单通知服务(SNS)发送包含订单号的消息。将支付服务设置为对亚马逊SNS系统进行投票检索消息并处理订单。",
      "D": "将订单保存在数据库中。将包含订单号的消息发送到亚马逊简单队列服务(SQS)队列。设置支付服务来检索消息并处理订单。从队列中删除消息。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Idempotency"
    ],
    "explanation": {
      "analysis": "考查如何通过异步消息队列来解决重复提交订单的问题，以及确保幂等性。",
      "why_correct": "选项 D  通过 SQS 队列来实现异步处理。如果一个用户多次提交订单，只会将一个消息放入队列中，确保了订单的幂等性。并且支付服务从队列中获取消息进行处理，处理完毕后删除消息，确保了消息只被处理一次。",
      "why_wrong": "选项 A  Kinesis Data Firehose 不适合消息队列。 选项 B  使用 CloudTrail 和 Lambda 和 Athena，过于复杂，不适用。 选项 C  使用 SNS，如果用户多次提交表单，则会发送多个 SNS 通知，可能导致重复处理订单。"
    },
    "related_terms": [
      "数据库",
      "Kinesis Data Firehose",
      "AWS CloudTrail",
      "Lambda",
      "Athena",
      "SNS",
      "SQS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 256,
    "topic": "",
    "question_cn": "解决方案架构师正在使用一个用于存储S3桶的亚马逊S3实现文档审查应用程序。解决办法必须防止文件的意外删除并确保所有版本的S3文件均可提供。用户必须能够下载、修改和上传文件？应采取哪些行动来满足这些要求（选二）。",
    "options_cn": {
      "A": "启用一个只读水桶。",
      "B": "在桶上启用版本控制。",
      "C": "在桶上附加一个IAM策略。",
      "D": "允许删除桶上的MFA。",
      "E": "用美国桶对桶加密。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Versioning",
      "S3 Security"
    ],
    "explanation": {
      "analysis": "考查S3的文件保护和版本控制策略。题目要求防止意外删除并确保文件版本可用。",
      "why_correct": "启用版本控制（B）和IAM策略（C）可以满足要求。版本控制允许恢复之前的版本，IAM策略可以控制用户的访问权限。MFA 增加安全，防止误删除 （本题为多选题，正确项为：B、D，需全部选对才得分。）",
      "why_wrong": "只读桶（A）限制了修改和上传。桶加密（E）只涉及数据安全，不解决删除问题。MFA 允许删除，违背题意。"
    },
    "related_terms": [
      "S3",
      "版本控制",
      "IAM",
      "MFA",
      "加密"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 257,
    "topic": "",
    "question_cn": "一家公司正在开发一个AWS EC2解决方案，该方案将在AWS帐户中报告亚马逊EC2在所有应用程序中的自动缩放事件。该公司需要使用无服务器AWS S3解决方案来存储亚马逊EC2中的自动缩放状态数据。然后该公司将使用亚马逊S3的数据在仪表板上提供接近实时的更新。解决方案不得影响EC2实例的启动速度。公司应该如何将数据转移到亚马逊S3来满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊CloudWatch度量流发送EC2自动缩放状态数据到亚马逊运动数据消防软管。将数据存储在亚马逊S3中。",
      "B": "启动亚马逊EMR集群收集EC2自动缩放状态数据并将数据发送到亚马逊运动数据消防软管。将数据存储在亚马逊S3中。",
      "C": "创建一个亚马逊EventBridge规则以调用一个日程表上的Lambda函数。配置Lambda函数将自动缩放状态数据直接发送到亚马逊S3。",
      "D": "在启动EC2实例时使用引导脚本安装亚马逊运动代理。配置运动代理来收集EC2自动缩放状态数据并将数据发送到亚马逊S3运动数据消防软管。将数据存储在亚马逊S3中。"
    },
    "vote_percentage": "85%",
    "tags": [
      "EC2 Auto Scaling",
      "S3 Data Storage"
    ],
    "explanation": {
      "analysis": "考察EC2自动伸缩事件的近实时存储和分析。要求方案不影响实例启动速度，并使用无服务器方案。",
      "why_correct": "选项 A 使用 CloudWatch Metrics 流和 Kinesis Data Firehose，符合无服务器需求，且不会影响 EC2 启动速度。数据直接发送到 S3，符合要求。",
      "why_wrong": "选项 B 涉及 EMR 集群，需要额外管理，不符合无服务器原则。选项 C 使用 Lambda 函数，但可能因为调用频率或 Lambda 限制导致延迟。选项 D 涉及在 EC2 实例中安装代理，会增加启动时间。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "无服务器",
      "CloudWatch",
      "Kinesis Data Firehose",
      "EMR",
      "EventBridge",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 258,
    "topic": "",
    "question_cn": "一家公司有一个可以放置数百个CSV文件的应用程序到亚马逊S3桶每小时。文件的大小是1GB。每次上传文件时公司需要将文件转换为阿帕奇拼花格式并将输出文件放置到一个S3桶。用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "创建一个Lambda函数下载CSV文件，将文件转换为拼接格式并将输出文件放置在一个S3桶中。调用每个放置事件的Lambda函数。",
      "B": "创建一个阿帕奇火花作业读CSV文件，将文件转换为拼接格式并将输出文件放置在一个S3桶中。为每一个放置事件创建一个 AWS Lambda函数来调用火花作业。",
      "C": "为S3桶创建一个Glue表和一个Glue爬虫机应用程序将其放置CSV文件。定期使用Amazon Athena来查询 Glue 表，将查询结果转换为拼花格式，将输出文件放置到S3桶中。",
      "D": "创建一个Glue提取转换和负载(ETL)工作来转换CSV文件拼接格式和将输出文件放置到一个S3桶。为每一个放置事件AWS ETL创建一个Lambda函数来调用作业。"
    },
    "vote_percentage": "89%",
    "tags": [
      "S3",
      "Glue",
      "Apache Parquet",
      "ETL"
    ],
    "explanation": {
      "analysis": "核心考点: 将CSV文件转换为Parquet格式并存储到S3桶中。 注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，Glue ETL 提供了更强大的数据转换能力和自动化的ETL流程。",
      "why_correct": "选项D 通过使用 Glue ETL 作业来转换 CSV 文件为 Parquet 格式，并利用 Lambda 函数触发 ETL 作业，实现了自动化，且具有良好的扩展性。",
      "why_wrong": "选项A 中 Lambda 函数直接处理1GB文件，容易超时。选项B Spark 作业的启动开销较大。选项C 需要额外的 Athena 查询，增加了复杂性。"
    },
    "related_terms": [
      "S3",
      "CSV",
      "Lambda",
      "Apache Spark",
      "Glue",
      "Athena",
      "ETL"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 259,
    "topic": "",
    "question_cn": "一家公司正在对亚马逊RDS数据库实例上运行的所有数据库实施新的数据保留策略。公司必须保留每日备份至少两年。备份必须是一致的和可恢复的。解决方案架构师应该推荐哪种解决方案来满足这些需求？",
    "options_cn": {
      "A": "在AWS RDS备份中创建一个备份库以保留RDS备份。创建一个新的备份计划每天的时间表并在创建后两年内到期。将数据库实例分配到备份计划中。",
      "B": "为每日快照配置RDS数据库实例的备份窗口。为每个RDS数据库实例分配一个两年的快照保留策略。使用Amazon Data Lifecycle Manager (DLM) 来安排快照删除。",
      "C": "配置数据库事务日志以自动备份到具有2年有效期的亚马逊CloudWatch日志。",
      "D": "配置AWS DMS(数据库迁移服务)复制任务。部署一个复制实例并配置一个更改数据捕获任务将数据库更改作为目标流到S3。配置S3生命周期策略以便在2年后删除快照。"
    },
    "vote_percentage": "93%",
    "tags": [
      "RDS Backup",
      "Data Retention"
    ],
    "explanation": {
      "analysis": "考察RDS数据库备份策略。需要满足备份时间、一致性和可恢复性要求。",
      "why_correct": "选项 A 介绍了利用 RDS 备份，可以满足备份期限和可恢复性要求。创建备份计划方便管理和自动化。",
      "why_wrong": "选项 B 涉及快照，但 DLM 管理快照删除，无法完全保证两年的保留时间。选项 C 涉及 CloudWatch Logs，主要用于监控，不是备份解决方案。选项 D 涉及 DMS，主要用于数据库迁移，不是备份方案。"
    },
    "related_terms": [
      "RDS",
      "数据保留",
      "备份",
      "快照",
      "Amazon Data Lifecycle Manager (DLM)",
      "CloudWatch",
      "DMS",
      "S3"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 260,
    "topic": "",
    "question_cn": "一家公司的合规团队需要把它的文件股份转移到美国信息系统。共享运行在Windows SMB文件共享上。一个在现场自行管理的活动目录控件访问文件和文件夹。该公司希望将Amazon FSx for Windows作为解决方案的一部分用于Windows SMB文件服务器。公司必须确保在移动到FSx后，现场的活动目录组限制对Windows SMB FSx Windows文件服务器合规性共享、文件夹和文件的访问。该公司为FSx文件服务器文件系统创建了FSx。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个活动目录连接器连接到活动目录，将活动目录组映射到IAM组以限制访问。",
      "B": "为IAM标签分配一个限制标记键和一个服从标记值，将活动目录组映射到IAM组以限制访问。",
      "C": "为FSx for Windows文件服务器创建一个直接链接到IAM的服务链接角色以限制访问。",
      "D": "将文件系统连接到活动目录以限制访问。"
    },
    "vote_percentage": "89%",
    "tags": [
      "FSx for Windows",
      "Active Directory Integration"
    ],
    "explanation": {
      "analysis": "考察 FSx for Windows 文件服务器与 Active Directory 的集成。要求保留现有的访问控制策略。",
      "why_correct": "选项 D  描述了将 FSx 文件系统连接到活动目录的方法。通过这种方式，FSx 将继承现有的 Active Directory 组策略和权限，实现访问控制。",
      "why_wrong": "选项 A 和 B 涉及 IAM 组和标签，与 SMB 共享的 Active Directory 集成无关。 选项 C  涉及 IAM 服务链接角色，通常用于 AWS 服务之间的授权，无法直接控制文件访问。"
    },
    "related_terms": [
      "FSx for Windows",
      "Windows SMB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 261,
    "topic": "",
    "question_cn": "一家公司最近宣布向全球受众部署其零售网站。该网站运行在多个亚马逊EC2实例后面的弹性负载平衡器。实例在多个可用性区域的自动缩放组中运行。该公司希望为其客户提供基于用户访问网站所使用的设备的不同版本的内容。解决方案架构师应该采取哪些行动组合来满足这些需求（选二）。",
    "options_cn": {
      "A": "配置Amazon CloudFront缓存多个版本的内容。",
      "B": "在网络负载均衡器中配置主机头，将流量转发到不同的实例。",
      "C": "配置一个Lambda@Edge函数，根据用户端配置一个边缘函数向用户发送特定对象。",
      "D": "配置全球加速器。转发请求到网络负载均衡器。配置网络负载均衡器以便为不同的EC2实例设置基于主机的路由。",
      "E": "配置全球加速器。转发请求到网络负载均衡器。配置网络负载均衡器为不同的EC2实例设置基于路径的路由。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Lambda@Edge",
      "Content Delivery"
    ],
    "explanation": {
      "analysis": "考察内容分发和针对不同设备提供不同版本内容的需求。",
      "why_correct": "选项 A  使用 CloudFront 缓存，可以缓存不同设备的内容。选项 C 使用 Lambda@Edge，可以根据用户的设备类型，动态地选择合适的版本的内容。",
      "why_wrong": "选项 B  只涉及负载均衡器转发，不能提供不同版本的内容。选项 D 和 E 涉及 Global Accelerator，用于加速全球访问，与设备特定内容关系不大。"
    },
    "related_terms": [
      "CloudFront",
      "EC2",
      "弹性负载平衡器",
      "Lambda@Edge",
      "Global Accelerator",
      "网络负载均衡器",
      "EC2"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 262,
    "topic": "",
    "question_cn": "一家公司计划在其多层网络应用程序中使用Amazon Elastic Compute Cloud(EC2)。解决方案架构师创建了一个应用程序VPC，为EC2集群的缓存和应用程序EC2实例。这两个VPC都位于美国东部地区。解决方案架构师必须实现一个解决方案以便为应用程序的EC2实例提供对弹性计算集群的访问。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在VPC之间创建一个窥视连接。为两个VPC中的窥视连接添加路由表项。为集群的安全组配置一个入站规则以允许应用程序的安全组的入站连接。",
      "B": "创建一个传输VPC。更新缓存VPC和应用程序VPC中的路由表以通过传输VPC来路由流量。为集群的安全组配置一个入站规则以允许应用程序的安全组的入站连接。",
      "C": "在VPC之间创建一个窥视连接。为两个VPC中的窥视连接添加路由表项。为监视连接的安全组配置入站规则以允许从应用程序的安全组入站连接。",
      "D": "创建一个传输VPC。更新缓存VPC和应用VPC中的路由表以通过传输VPC来路由流量。为传输VPC的安全组配置入站规则以允许应用程序的安全组的入站连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Peering",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "考察VPC间网络连接方案。需要在两个VPC之间建立连接，并允许应用程序实例访问缓存集群。",
      "why_correct": "选项 A 使用 VPC Peering，是 VPC 之间建立连接的简单、直接方法。 并配置安全组，满足需求。",
      "why_wrong": "选项 B  使用 Transit VPC，对于两个 VPC 来说，过于复杂。选项 C  配置不正确。选项 D  安全组配置错误。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "窥视连接",
      "路由表",
      "安全组",
      "传输VPC"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 263,
    "topic": "",
    "question_cn": "一家公司正在开发一个由几种微服务组成的应用程序。该公司已决定使用集装箱技术将其软件部署到AWS。该公司需要一个解决方案，最大限度地减少正在进行的维护和规模化的工作量。该公司无法管理额外的基础设施。解决方案架构师应该采取哪些行动组合来满足这些需求（选二）。",
    "options_cn": {
      "A": "部署Amazon Elastic Container Service(ECS)集群。",
      "B": "在亚马逊EC2实例上部署Kubernetes控制平面，它跨越多个可用性区域。",
      "C": "部署具有Amazon EC2发射类型的Amazon Elastic Container Service(ECS)。指定一个高于或等于2的理想任务数级别。",
      "D": "部署一个Amazon Elastic Container Service(ECS)与Fargate发射类型。指定一个高于或等于2的理想任务数级别",
      "E": "在亚马逊EC2实例上部署工作节点跨多个可用性区域。创建一个为每个微服务指定两个或多个副本的部署。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS",
      "Fargate"
    ],
    "explanation": {
      "analysis": "考查容器部署方案，需要最小化维护和扩展工作量，且不管理基础设施。",
      "why_correct": "选项 A 部署 ECS 集群。选项 D 使用 Fargate 启动类型，都是无需管理底层基础设施的方案，简化运维。",
      "why_wrong": "选项 B  部署 Kubernetes，需要自行管理控制平面，不符合题意。 选项 C 使用 EC2 Launch Type, 需要管理EC2实例。选项 E  部署 EC2工作节点,需要自己管理节点。"
    },
    "related_terms": [
      "ECS",
      "ECS",
      "EC2",
      "Fargate"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 264,
    "topic": "",
    "question_cn": "一家公司拥有一个网站应用程序托管了超过10个亚马逊EC2实例，流量由亚马逊Route 53引导。在尝试浏览应用程序时，公司偶尔会出现DNS IP超时错误。网络团队发现一些DNS查询返回不健康实例的IP地址，导致超时错误。解决方案架构师应该实现什么来克服这些超时错误？",
    "options_cn": {
      "A": "为每个EC2实例创建一个Route 53简单路由策略记录。将健康检查与每个记录联系起来。",
      "B": "为每个EC2实例创建一个Route 53故障转移路由策略记录。将健康检查与每个记录联系起来。",
      "C": "创建一个亚马逊CloudFront分发以EC2实例为其起源。将健康检查与EC2实例联系起来。",
      "D": "在EC2实例前创建一个应用程序负载均衡器（ALB），并进行健康检查。从Route 53配置流量到ALB。"
    },
    "vote_percentage": "66%",
    "tags": [
      "Route 53 Health Checks",
      "ALB"
    ],
    "explanation": {
      "analysis": "考查如何解决 DNS 解析到不健康 EC2 实例导致超时的问题。",
      "why_correct": "选项 D  使用应用程序负载均衡器 (ALB) 进行健康检查，Route 53 流量到 ALB，ALB 负责将流量分配到健康的实例，可以解决问题。",
      "why_wrong": "选项 A 和 B 使用简单路由策略和故障转移路由策略，但没有负载均衡能力，不能根据实例的健康状态动态调整流量分配。选项 C  CloudFront 用于内容分发，不能解决后端实例健康问题。"
    },
    "related_terms": [
      "EC2",
      "Route 53",
      "DNS",
      "CloudFront",
      "EC2",
      "应用程序负载均衡器",
      "ALB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 265,
    "topic": "",
    "question_cn": "解决方案架构师需要设计一个非常可用的Web应用程序，包括HTTPS内容传递。内容传递应该尽可能接近边缘且传递时间最短。哪个解决方案满足这些要求最安全？",
    "options_cn": {
      "A": "在公共子网络中配置具有多个冗余亚马逊EC2实例的公共应用程序负载均衡器(ALB)。将Amazon CloudFront配置为提供HTTPS内容，使用ALB作为起源。",
      "B": "配置一个公共应用程序负载均衡器在私有子网中使用多个冗余的亚马逊EC2实例。配置Amazon CloudFront提供HTTPS内容，使用EC2实例作为起源。",
      "C": "在私有子网中配置一个具有多个冗余亚马逊EC2实例的公共应用程序负载均衡器(ALB)。将Amazon CloudFront配置为提供HTTPS内容使用ALB作为起源。",
      "D": "在公共子网络中配置具有多个冗余亚马逊EC2实例的公共应用程序负载均衡器。配置Amazon CloudFront提供HTTPS内容使用EC2实例作为起源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "ALB",
      "Security"
    ],
    "explanation": {
      "analysis": "考察 HTTPS 内容交付的可用性和安全性，以及CloudFront和ALB的结合使用。",
      "why_correct": "选项 C 在私有子网中使用 ALB，并通过 CloudFront 提供内容，安全性更好。 CloudFront 负责 HTTPS 的终止，ALB 提供负载均衡。 ALB 与EC2 实例位于私有子网，减少了攻击面。",
      "why_wrong": "选项 A ALB 在公共子网，风险较高。选项 B  EC2 实例作为 CloudFront 的 Origin,不符合高可用要求，而且 HTTPS 终止不安全。选项 D  未说明 ALB 子网。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "CloudFront",
      "HTTPS",
      "EC2",
      "ALB",
      "CloudFront",
      "HTTPS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 266,
    "topic": "",
    "question_cn": "一个公司有一个流行的游戏平台运行在AWS上。应用程序对延迟敏感，因为延迟会影响用户体验并给一些玩家带来不公平的优势。该应用程序部署在每一个AWS区域。它在亚马逊EC2实例上运行，这些实例是在应用程序负载平衡器(ALBs)后面配置的自动缩放组的一部分。解决方案架构师需要实现一种机制来监控应用程序的健康性并将流量重定向到健康的端点。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在美国世界银行的全球加速器中配置一个加速器。为应用程序监听的端口添加侦听器并将其附加到每个区域的区域端点。添加ALB作为端点。",
      "B": "创建一个Amazon CloudFront分发并指定ALB为原服务器。将缓存行为配置为使用原缓存头,使用ALB功能优化流量。",
      "C": "创建一个Amazon CloudFront分发并指定Amazon S3为原始服务器。将缓存行为配置为使用原缓存头,使用ALB功能优化流量。",
      "D": "配置一个Amazon DynamoDB作为应用程序的数据存储。创建一个发电机加速器(DAX)集群作为存储应用程序数据的发电机缓存。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "ALB Health Checks"
    ],
    "explanation": {
      "analysis": "考察游戏平台延迟敏感性，需要健康检查和流量重定向。需要实现健康监控和流量重定向。",
      "why_correct": "选项 A 使用 Global Accelerator，通过健康检查进行流量重定向。 它能够检测到后端实例的健康状况，并将流量路由到健康的端点。",
      "why_wrong": "选项 B 涉及 CloudFront 和 ALB，但 CloudFront 主要用于内容分发，不能解决健康检查和流量重定向。 选项 C 使用 S3 作为源，不适合动态内容。 选项 D  DAX 用于数据库缓存，不能解决整体的健康检查和流量重定向问题。"
    },
    "related_terms": [
      "Global Accelerator",
      "ALB",
      "EC2",
      "Amazon CloudFront",
      "S3",
      "ALB",
      "Amazon DynamoDB",
      "DAX"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 267,
    "topic": "",
    "question_cn": "一家公司有一百万用户使用其移动应用程序。公司必须在近实时分析数据使用情况。该公司还必须在近实时加密数据并必须在集中的位置以阿帕奇拼花格式存储数据以便进一步处理。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个Amazon Kinesis Data Stream来存储亚马逊S3中的数据。创建一个Amazon Kinesis Data Analytics应用分析数据。调用Lambda函数将数据发送到Kinesis Data Analytics应用程序中。",
      "B": "创建一个Amazon Kinesis Data Stream来存储亚马逊S3中的数据。创建一个Amazon EMR集群来分析数据。调用Lambda函数将数据发送到EMR集群。",
      "C": "创建一个Amazon Kinesis Data Firehose传递流以存储数据在亚马逊S3。创建一个Amazon EMR集群来分析数据。",
      "D": "创建一个Amazon Kinesis Data Firehose传递流以存储数据在亚马逊S3。创建一个Amazon Kinesis Data Analytics应用分析数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Kinesis Data Firehose",
      "Kinesis Data Analytics",
      "Data Analytics"
    ],
    "explanation": {
      "analysis": "考察近实时数据分析方案。需要数据流、数据加密、和 Parquet 格式存储，并且要最小化操作开销。",
      "why_correct": "选项 D  使用了 Kinesis Data Firehose (数据流服务) 以及 Kinesis Data Analytics（分析服务），可以满足近实时分析，并将数据存储到S3中。 Firehose 还可以处理数据加密。 Kinesis Data Firehose 可以直接将数据输出成 Parquet 格式，实现需求。",
      "why_wrong": "选项 A  Kinesis Data Analytics 还需要 Lambda 函数处理，增加了开销。选项 B  需要 EMR 集群，增加了运维开销。选项 C  Firehose 和 EMR, 需要额外管理。 "
    },
    "related_terms": [
      "Kinesis Data Stream",
      "S3",
      "Kinesis Data Analytics",
      "Lambda",
      "Kinesis Data Stream",
      "S3",
      "EMR",
      "Lambda",
      "Kinesis Data Firehose",
      "S3",
      "EMR",
      "Kinesis Data Firehose",
      "S3",
      "Kinesis Data Analytics"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 268,
    "topic": "",
    "question_cn": "一家游戏公司有一个显示得分的Web应用程序。应用程序在应用程序负载平衡器后面的亚马逊EC2实例上运行。应用程序将数据存储在一个用于MySQL数据库的亚马逊RDS中。用户开始经历数据库读取性能造成的长时间延迟和中断。该公司希望改善用户体验，同时尽量减少对应用程序架构的更改。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "在数据库前使用Amazon ElastiCache。",
      "B": "在应用程序和数据库之间使用RDS代理。",
      "C": "将应用程序从EC2实例迁移到AWSRABDA。",
      "D": "将数据库从亚马逊RDS的MySQL迁移到亚马逊DynamoDB。"
    },
    "vote_percentage": "51%",
    "tags": [
      "ElastiCache",
      "RDS Performance"
    ],
    "explanation": {
      "analysis": "考察数据库读取性能优化。 需求是减少对现有应用程序架构的更改。",
      "why_correct": "选项 A 使用 ElastiCache， 可以在数据库前面增加缓存，从而减少数据库读取压力，提升性能。 这是对现有架构影响最小的方案。",
      "why_wrong": "选项 B  RDS 代理主要用于连接管理和故障转移，对提升性能帮助不大。 选项 C  将应用程序迁移到 Lambda，涉及架构重大变化。 选项 D  将数据库迁移到 DynamoDB，也涉及架构重大变化。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "RDS",
      "MySQL",
      "ElastiCache",
      "RDS",
      "Lambda",
      "DynamoDB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 269,
    "topic": "",
    "question_cn": "一家电子商务公司已经注意到其亚马逊Web应用程序的性能下降。性能下降归因于业务分析员触发的只读SQL查询数量的增加。解决方案架构师需要用对现有Web应用程序的最小更改来解决这个问题。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "将数据输出到亚马逊DynamoDB，并让业务分析师进行查询。",
      "B": "将数据加载到亚马逊的Redshift中，并让业务分析师运行他们的查询。",
      "C": "创建主数据库的读副本，并让业务分析员运行他们的查询。",
      "D": "将数据复制到亚马逊红移集群中，并让业务分析师运行他们的查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Read Replicas",
      "Database Performance"
    ],
    "explanation": {
      "analysis": "考察提高数据库只读查询性能的方案，并且要最小化对现有应用程序的更改。",
      "why_correct": "选项 C  创建 RDS 的读副本是最简单的方案，业务分析师可以从读副本中查询，不会影响主数据库的性能。 这对现有应用程序的更改最小。",
      "why_wrong": "选项 A  需要将数据迁移到 DynamoDB，改动大。 选项 B  需要将数据迁移到 Redshift，也需要改动。 选项 D  将数据复制到 Redshift，虽然可以提高分析性能，但需要额外成本和复杂性。"
    },
    "related_terms": [
      "DynamoDB",
      "Redshift",
      "RDS",
      "Redshift"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 270,
    "topic": "",
    "question_cn": "一家公司正在使用一个集中的AWS帐户来存储各种亚马逊S3桶中的日志数据。解决方案架构师需要在数据上传到S3桶之前确保数据在休息时加密。数据也必须在传输过程中加密。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用客户端加密加密正在上传到S3桶的数据。",
      "B": "使用服务器端加密加密正在上传到S3桶的数据。",
      "C": "创建需要使用AWS托管加密密钥(SSE-S3)的服务器端加密的上传的桶策略。",
      "D": "启用安全选项通过使用默认的AWS KMS密钥加密S3桶。"
    },
    "vote_percentage": "96%",
    "tags": [
      "S3 Encryption",
      "Client-Side Encryption"
    ],
    "explanation": {
      "analysis": "考察 S3 数据加密，包括静态加密和传输中加密。",
      "why_correct": "选项 A 使用客户端加密，在上传前加密数据，满足静态加密和传输加密的要求。",
      "why_wrong": "选项 B  服务器端加密只加密静态数据，不能保证传输加密。选项 C  SSE-S3 只是服务器端加密方式，不能保证传输加密。 选项 D  使用 KMS 密钥的服务器端加密，但没有说明传输加密。 只有客户端加密，才可以保证传输前加密。"
    },
    "related_terms": [
      "S3",
      "SSE-S3",
      "KMS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 271,
    "topic": "",
    "question_cn": ", EC2 , 解决方案架构师观察到在达到所需的亚马逊 EC2 容量之前每晚的批处理作业将自动升级 1 小时。最大的产能是 每天晚上都一样而批处理总是在凌晨 1 点开始。解决方案架构师需要找到一个成本效益高的解决方案以便能够快速达到所需的 EC2 容量并允许自动缩放组在批处理工作完成后缩小规模。 解决方案架构师应该做什么来满足这些需求",
    "options_cn": {
      "A": "增加自动缩放组的最小容量。",
      "B": "增加自动缩放组的最大容量。",
      "C": "配置计划的扩展以扩展到所需的计算级别。",
      "D": "更改扩展策略以便在每次扩展操作中添加更多的 EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "考查如何通过计划扩展来实现EC2实例的自动伸缩，以满足批处理作业的资源需求。",
      "why_correct": "选项C，配置计划的扩展，可以精确控制EC2实例的伸缩时机和容量，以满足批处理作业的特定需求，是成本效益最高的方案。",
      "why_wrong": "选项A和B：增加自动缩放组的最小或最大容量，可能导致资源过度配置或无法满足峰值需求。选项D：修改扩展策略会导致每次扩展时实例数量的变化，不够灵活且难以预测。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 272,
    "topic": "",
    "question_cn": "(ALS) EC2 , 一家公司在一个应用负载平衡器背后的亚马逊EC2实例车队中为一个动态网站提供服务。网站需要支持多种语言以服务世界各地的客户。该网站的架构运行在美国西部地区的1号区域并且对位于世界其他地区的用户显示出高的请求延迟。 无论用户的位置如何，网站都需要快速有效地满足请求。然而该公司不希望在多个区域重新创建现有的架构。 解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "使用亚马逊S3桶提供的网站替换现有的架构。配置一个亚马逊云端分布以S3桶作为起源。根据接受语言请求头设置缓存行为设置。",
      "B": "配置一个亚马逊云端分布以 ALS作为起源。根据接受语言请求头设置缓存行为设置。",
      "C": "创建API网关，该网关与ALS API集成。将API网关配置为使用HTTP API集成类型。设置一个API网关阶段以启用基于接受语言请求头的缓存。",
      "D": "在每个额外区域启动一个EC2实例并配置NGINX作为该区域的缓存服务器。将所有EC2实例和ALS放在亚马逊Route 53后面并设置一个地理定位路由策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Multi-language website"
    ],
    "explanation": {
      "analysis": "考查如何使用 CloudFront 和基于语言的缓存来加速全球用户的网站访问。",
      "why_correct": "选项B：使用 CloudFront 作为 CDN，并将ALS设置为源，可以基于用户的地理位置和语言设置缓存行为，从而显著减少延迟。",
      "why_wrong": "选项A：使用S3托管网站，虽然可以加速静态内容，但对于动态网站，无法充分利用ALB的负载均衡和处理能力。选项C：API网关的缓存功能不如 CloudFront 强大。选项D：在每个区域部署缓存服务器，增加了运维复杂性，并需要额外的成本。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "CloudFront",
      "S3",
      "CloudFront",
      "ALS",
      "API Gateway",
      "ALS",
      "EC2",
      "NGINX",
      "Route 53"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 273,
    "topic": "",
    "question_cn": "一家快速发展的电子商务公司正在单个的美国世界服务组织地区开展工作。解决方案架构师必须创建一个包含不同区域的灾难恢复 (DR) 策略。该公司希望它的数据库能以尽可能少的延迟期更新。该区域剩余的基础设施需要以降低的能力运行必要时必须能够扩大规模。 (RTO)? 哪个解决方案将满足这些需求的最低恢复时间目标",
    "options_cn": {
      "A": "使用亚马逊极光全球数据库与试点轻部署。",
      "B": "使用亚马逊极光全球数据库与一个温暖的备用部署。",
      "C": "使用具有试点轻部署的亚马逊 RDS 多 AZ 数据库实例。",
      "D": "使用一个带有热备用部署的亚马逊 RDS 多 AZ 数据库实例。"
    },
    "vote_percentage": "98%",
    "tags": [
      "Aurora Global Database",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "考查如何在满足RTO要求的同时，实现数据库的灾难恢复，以及不同 Aurora 部署方式的特点。",
      "why_correct": "选项B：使用 Aurora Global Database 和 warm standby 部署，在灾难发生时，备库可以快速切换，满足低 RTO 的要求。",
      "why_wrong": "选项A：使用 Aurora Global Database 和 pilot light，RTO 会比 warm standby 更高。选项C：RDS 多 AZ 实例与 pilot light 部署，RTO会比 warm standby 更高。选项D：RDS 多 AZ 实例和 hot standby 部署，虽然 RTO 较低，但成本较高。"
    },
    "related_terms": [
      "DR",
      "Aurora Global Database",
      "RDS",
      "Multi-AZ"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 274,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例上运行一个应用程序。该公司需要为应用程序实现灾难恢复解决方案。解决方案需要有一个不到4小时的恢复时间目标 (RTO)。在正常的操作中 解决方案还需要使用尽可能少的资源。哪个解决方案将以最有效的方式满足这些要求",
    "options_cn": {
      "A": "创建亚马逊机器镜像(AMI) 以备份 EC2 实例。把AMI复制到第二地区。通过使用Lambda和定制脚本在二级区域 自动化基础设施部署。",
      "B": "创建亚马逊机器镜像(AMI) 以备份 EC2 实例。把AMI复制到第二地区。在二级区域的基础设施部署自动化使用的是 aws 云组。",
      "C": "在第二可用区启动 EC2 实例。在第二区域始终保持 EC2 实例的活动。",
      "D": "在二级可用性区内启动 EC2 实例。在第二可用性区中始终保持 EC2 实例的活动。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "Disaster Recovery",
      "RTO",
      "AMI"
    ],
    "explanation": {
      "analysis": "核心考点: 灾难恢复方案选择，满足低 RTO 和资源使用率。 注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，使用AMI备份，并在另一个区域通过 CloudFormation 自动化部署，满足了 RTO 和资源使用率的要求。",
      "why_correct": "选项B通过 AMI 备份 EC2 实例，复制到另一个区域，使用 CloudFormation 实现基础设施的自动化部署，能够在满足 RTO 的同时，减少资源消耗。",
      "why_wrong": "选项C 和 D 保持 EC2 实例始终活动，会消耗更多资源。选项 A 需要使用 Lambda 和定制脚本，增加了复杂性和维护成本。"
    },
    "related_terms": [
      "EC2",
      "RTO",
      "AMI",
      "Lambda",
      "AMI",
      "AWS CloudFormation",
      "EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 275,
    "topic": "",
    "question_cn": "一家公司运行一个基于浏览器的内部应用程序。应用程序在应用程序负载平衡器后面的亚马逊 EC2 实例上运行。这些实例在亚马逊 EC2 自动缩放组中跨多个可用性区域运行。自动扩展组在工作时间内可扩展到 20 个实例但在一夜之间可缩小到 2 个实例。工作人员抱怨说应用程序在一天开始的时候速度很慢虽然它在上午的时候运行得很好。应如何改变规模以解决工作人员的抱怨并将费用保持在最低水平",
    "options_cn": {
      "A": "实施预定的行动在办公室启用前不久将所需能力提高到20个。",
      "B": "实现在较低 CPU 阈值下触发的一步缩放动作并减少冷却时间。",
      "C": "实现在较低 CPU 阈值下触发的目标跟踪操作并减少冷却时间。",
      "D": "实施一项预定的行动在办公室开业前不久将最低和最高容量定为20。"
    },
    "vote_percentage": "66%",
    "tags": [
      "EC2 Auto Scaling",
      "Scaling Policies",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "核心考点: 优化自动伸缩组的伸缩策略，解决应用程序启动时的性能问题。 注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，目标跟踪策略能够根据 CPU 使用率自动调整实例数量，同时减少冷却时间，响应速度更快。",
      "why_correct": "选项C 使用目标跟踪策略，能够根据 CPU 使用率自动调整实例数量，并且减少冷却时间，可以更快地响应负载增加，从而解决应用启动时的性能问题。",
      "why_wrong": "选项 A，使用预定的伸缩策略，无法动态应对负载变化，且不够灵活。选项 B 依赖于单步缩放动作，不够灵活，无法根据CPU使用率进行自动调整。选项D，设置固定容量，无法根据实际负载进行弹性伸缩。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "EC2",
      "自动缩放组",
      "预定的行动"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 276,
    "topic": "",
    "question_cn": "一个公司有一个多层应用程序部署在几个亚马逊 EC2 实例中的一个自动缩放组。用于甲骨文实例的亚马逊 RDS 是应用程序的数据层。该数据层使用特定的 SQL 函数。应用程序的流量一直在稳步增加。这导致 RDS 实例被重载而 RDS 实例将耗尽存储。自动缩放组没有任何缩放度量，只定义了最小健康实例计数。该公司预测交通流量将继续以稳定但不可预测的速度增长然后才会趋于平稳。解决方案架构师应该做什么来确保系统能够自动为增加的流量进行规模化？ 选二。",
    "options_cn": {
      "A": "为甲骨文 RDS 实例在RDS 上配置存储自动缩放。",
      "B": "将数据库迁移到亚马逊 Aurora使用自动缩放存储。",
      "C": "为甲骨文 RDS 实例的低自由存储空间配置RDS 上的报警器。",
      "D": "配置自动缩放组以使用平均 CPU 作为缩放度量。",
      "E": "配置自动缩放组以使用平均空闲内存作为缩放度量。"
    },
    "vote_percentage": "88%",
    "tags": [
      "RDS",
      "Auto Scaling",
      "Database",
      "Storage"
    ],
    "explanation": {
      "analysis": "核心考点: 数据库和应用程序的自动伸缩，解决性能和存储问题。 注意: 此题官方答案为AC，但社区共识(投票最高)为AD。社区倾向AD的原因是，存储自动伸缩和基于CPU的伸缩策略，可以解决数据库和应用程序的扩展问题。",
      "why_correct": "选项A:  配置 RDS 存储自动伸缩可以自动增加存储容量。选项D:  配置自动伸缩组以使用平均 CPU 作为伸缩度量，可以根据 CPU 负载自动调整 EC2 实例的数量。",
      "why_wrong": "选项B: 将数据库迁移到 Aurora 涉及数据库迁移。 选项 C: 仅仅设置报警无法解决问题，需要采取伸缩措施。选项 E:  使用空闲内存作为度量标准可能无法准确反映数据库的负载。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "Oracle",
      "自动缩放组",
      "RDS",
      "存储自动缩放",
      "Aurora",
      "RDS",
      "自动缩放组"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 277,
    "topic": "",
    "question_cn": "一家公司提供在线视频内容发布服务并将其转码供任何移动平台使用。应用程序体系结构使用亚马逊弹性文件系统 (EFS) 来收集和存储视频，以便多个亚马逊 EC2 Linux 实例能够访问视频内容进行处理。随着服务的普及程度随着时间的推移而增长，存储成本变得过于昂贵。哪种存储方案最具成本效益",
    "options_cn": {
      "A": "使用存储网关存储文件来存储和处理视频内容。",
      "B": "使用存储网关为卷存储和处理视频内容。",
      "C": "使用亚马逊EFS存储视频内容。一旦处理完成将文件转移到亚马逊弹性块存储(EBS) 卷。",
      "D": "使用亚马逊S3存储视频内容。将文件临时移到亚马逊弹性块存储(EBS)卷上以供处理。"
    },
    "vote_percentage": "78%",
    "tags": [
      "EFS",
      "S3",
      "Storage Cost Optimization",
      "EBS"
    ],
    "explanation": {
      "analysis": "核心考点: 优化视频存储成本。 注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，将视频存储在 S3 中，能够实现低成本存储，而将视频临时移到 EBS 上进行处理，可以保证高性能。",
      "why_correct": "选项D 通过使用 S3 来存储视频，可以利用 S3 的低成本存储。将文件临时移到 EBS 卷上进行处理，可以满足处理需求。",
      "why_wrong": "选项 A 和 B 使用存储网关，成本较高，不适合大规模视频存储。选项 C 使用 EFS 存储视频，成本较高。"
    },
    "related_terms": [
      "EFS",
      "EC2",
      "EFS",
      "存储网关",
      "EBS",
      "S3",
      "EBS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 278,
    "topic": "",
    "question_cn": "公司希望创建一个应用程序以便在分层结构化的关系中存储员工数据。公司需要对员工数据的高流量查询做出最小的响应并且必须保护任何敏感数据。如果员工数据中有任何财务信息公司还需要每月收到电子邮件。解决方案架构师应该采取哪些步骤来满足这些需求？ 选二。",
    "options_cn": {
      "A": "使用亚马逊红移存储层次结构中的员工数据。每月将数据卸载到亚马逊S3。",
      "B": "使用亚马逊 DynamoDB 在层次结构中存储员工数据。每月将数据输出到亚马逊S3。",
      "C": "为 AWS 帐户配置亚马逊 Macie。整合 Macie 与亚马逊 EventBridge 每月事件发送给AWS Lambda。",
      "D": "利用亚马逊 Athena 分析亚马逊S3 的员工数据。将 Athena 与亚马逊 QuickSight 集成发布分析仪表板并与用户共享仪表板。",
      "E": "为 AWS 帐户配置亚马逊 Macie。通过亚马逊的简单通知服务 (SNS) 订阅将 Macie 整合到亚马逊 EventBridge 上每月发送通知。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "S3",
      "Macie",
      "Data Security",
      "Notifications"
    ],
    "explanation": {
      "analysis": "核心考点: 设计存储和处理员工数据的方案，满足性能、安全性和通知需求。 注意: 此题官方答案为CD，但社区共识(投票最高)为BE。社区倾向BE的原因是，使用DynamoDB存储，使用Macie进行敏感数据检测并发送通知。",
      "why_correct": "选项B: 使用 DynamoDB 存储员工数据，满足高流量查询的性能要求。选项E: 使用 Macie 检测敏感数据，并通过 SNS 发送通知，满足安全和通知的需求。",
      "why_wrong": "选项 A:  Amazon Redshift 不适合高频查询。 选项 C: Macie 与 Lambda 的集成方式不能直接发送邮件，通常是用于触发其他操作。选项 D: Athena 用于分析，不适合存储和高频查询。"
    },
    "related_terms": [
      "DynamoDB",
      "Redshift",
      "S3",
      "Macie",
      "EventBridge",
      "Lambda",
      "Athena",
      "S3",
      "QuickSight",
      "Macie",
      "SNS",
      "EventBridge"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 279,
    "topic": "",
    "question_cn": "一个公司有一个由亚马逊 DynamoDB 支持的应用程序。该公司的合规要求规定数据库备份必须每月进行，必须有 6 个月的可用性，必须保留 7 年。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在每个月的第一天创建一个 DynamoDB 备份计划来备份 DynamoDB 表。指定一个生命周期策略在 6 个月后将备份转换为冷存储。将每个备份的保留期设置为 7 年。",
      "B": "在每个月的第一天根据需要创建一个 DynamoDB 表的备份。6 个月后将备份转换为亚马逊冰川的灵活检索。创建一个生命周期策略，删除超过 7 年的备份。",
      "C": "使用AWSSDK 开发一个脚本该脚本可以根据需要创建 DynamoDB 表的备份。建立了一个亚马逊 EventBridge 规则在每个月的第一天运行 脚本。创建第二个脚本在每个月的第二天运行将超过 6 个月的 DynamoDB 备份转换为冷存储并删除超过 7 年的备份。",
      "D": "使用 AWS CLI 创建一个按需备份的 DynamoDB 表。建立了一个亚马逊 EventBridge 规则该规则在每个月的第一天运行命令并使用 CRON 表达式。在命令中指定在 6 个月后将备份转换为冷存储并在 7 年后删除备份。"
    },
    "vote_percentage": "86%",
    "tags": [
      "DynamoDB Backup",
      "Lifecycle Policy",
      "Data Retention",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "核心考点:  实现 DynamoDB 备份，满足合规性要求。 注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，使用备份计划，设置生命周期策略来管理备份的存储和删除，最简洁高效。",
      "why_correct": "选项 A 通过使用 DynamoDB 备份计划，结合生命周期策略，能够满足备份、可用性、和保留期的所有要求，并且易于管理。",
      "why_wrong": "选项 B 缺少了冷存储的明确指定。 选项 C 使用了自定义脚本，增加了复杂性。选项 D 需要手动编写CLI命令，管理复杂。"
    },
    "related_terms": [
      "DynamoDB",
      "冷存储",
      "Amazon Glacier",
      "AWS SDK",
      "EventBridge",
      "AWS CLI",
      "CRON"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 280,
    "topic": "",
    "question_cn": "一家公司正在使用亚马逊S3的网站。该公司已经能够记录云前线分布日志保存在亚马逊S3的一个桶。该公司需要对日志进行高级分析并 构建可视化。解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "使用亚马逊 Athena 的标准 SQL 查询来分析S3桶中的云前线日志。用 胶水 将结果可视化。",
      "B": "使用亚马逊 Athena 的标准 SQL 查询来分析S3桶中的云前线日志。用亚马逊 QuickSight 来想象结果。",
      "C": "使用亚马逊 DynamoDB 中的标准 SQL 查询来分析S3桶中的云前线日志。用 胶水 将结果可视化。",
      "D": "使用亚马逊 DynamoDB 中的标准 SQL 查询来分析S3桶中的云前线日志。用亚马逊 QuickSight 来想象结果。"
    },
    "vote_percentage": "93%",
    "tags": [
      "CloudFront Logs",
      "Athena",
      "QuickSight",
      "Data Analysis",
      "S3"
    ],
    "explanation": {
      "analysis": "核心考点:  分析 S3 中的 CloudFront 日志并进行可视化。 注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，使用 Athena 查询 S3 日志，并使用 QuickSight 进行可视化，是最常用的组合。",
      "why_correct": "选项B 使用 Athena 查询 S3 中的日志，QuickSight 用于可视化，是常用的解决方案，操作简单。 ",
      "why_wrong": "选项A, 选项C, 选项D 均使用错误的服务进行日志分析。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "Athena",
      "S3",
      "Glue",
      "Athena",
      "S3",
      "QuickSight",
      "DynamoDB",
      "S3",
      "Glue",
      "DynamoDB",
      "QuickSight"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 281,
    "topic": "",
    "question_cn": "一家公司使用亚马逊 RDS 运行了一组网络服务器用于后端的数据库实例。在例行的合规性检查之后该公司设定了一个标准要求其(RPO)1所有生产数据库的恢复点目标 小于 秒。 哪种解决方案符合这些要求",
    "options_cn": {
      "A": "为 RDS 实例启用多AZ 部署。",
      "B": "在一个可用性区域中启用数据库实例的自动缩放。",
      "C": "在一个可用性区域中配置 RDS 实例并在一个单独的可用性区域中创建多个读副本。",
      "D": "在一个可用性区域中配置数据库实例并配置 AWS 数据库迁移服务(DMS) 更改数据捕获任务。"
    },
    "vote_percentage": "91%",
    "tags": [
      "RDS",
      "RPO",
      "Multi-AZ",
      "High Availability"
    ],
    "explanation": {
      "analysis": "核心考点: 实现数据库的高可用性和低 RPO。 注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，启用多 AZ 部署可以提供数据库的故障转移能力，满足低 RPO 的要求。",
      "why_correct": "选项 A: 启用 Multi-AZ 部署，RDS 会在不同的可用区创建一个备用数据库实例。当主数据库出现故障时，可以自动切换到备用实例，从而满足低 RPO 的要求。",
      "why_wrong": "选项 B 和 C 都无法提供自动故障转移能力。 选项D: 数据库迁移服务与RPO关系不大。"
    },
    "related_terms": [
      "RDS",
      "RPO",
      "Multi-AZ",
      "Read Replica",
      "DMS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 282,
    "topic": "",
    "question_cn": "一个公司运行一个Web应用程序，该应用程序部署在一个VPC的私有子网中的亚马逊EC2实例中。应用程序负载平衡器(ALS)通过公共子网扩展将Web流量引导到 EC2 实例。该公司希望实施新的安全措施限制从 Web 到 EC2 的入站流量，同时防止从 EC2 实例的私有子网内外的任何其他来源访问。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在路由表中配置一个路由以将从因特网到 EC2实例的私有 IP 地址的通信导向。",
      "B": "配置EC2实例的安全组只允许来自ALS安全组的流量。",
      "C": "将EC2实例移动到公共子网中。给EC2实例一个弹性IP地址集。",
      "D": "配置ALS的安全组以允许任何端口上的任何流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Groups",
      "VPC",
      "Networking"
    ],
    "explanation": {
      "analysis": "核心考点:  限制对 EC2 实例的访问，仅允许来自 ALB 的流量。 注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，配置 EC2 实例的安全组，只允许来自 ALB 安全组的流量，可以实现最小特权访问控制，满足安全需求。",
      "why_correct": "选项 B:  配置 EC2 实例的安全组，只允许来自 ALB 安全组的流量，实现了最小特权访问控制，限制了对 EC2 实例的访问，仅允许来自 ALB 的流量。",
      "why_wrong": "选项 A: 错误的路由配置。选项 C: 将 EC2 实例移到公共子网，这会暴露 EC2 实例。选项 D:  允许任何端口上的任何流量，违背了安全原则。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "ALS",
      "安全组",
      "弹性IP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 283,
    "topic": "",
    "question_cn": "一家研究公司运行的实验由模拟应用和可视化应用提供动力。模拟应用程序运行在 Linux 上，每 5 分钟将中间数据输出到 NFS 共享中。可视化应用程序是一个 Windows 桌面应用程序，需要一个 SMB 文件系统。该公司维护两个同步文件系统。这一战略正在造成数据重复和资源使用效率低下。公司需要将应用程序迁移到AWS，而不需要对任何一个应用程序进行代码更改。 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将这两个应用程序迁移到 AWS Lambda S3。创建一个亚马逊 S3 桶以便在应用程序之间交换数据。",
      "B": "将这两个应用程序迁移到亚马逊弹性容器服务 (ECS)。为存储配置亚马逊 FSx 文件网关。",
      "C": "将模拟应用程序迁移到 亚马逊EC2 Linux 实例中。将可视化应用程序迁移到 亚马逊 EC2 Windows 实例。配置亚马逊简单队列服务(SQS)以便在应用程序之间交换数据。",
      "D": "将模拟应用程序迁移到 亚马逊EC2 Linux 实例中。将可视化应用程序迁移到 亚马逊EC2 Windows 实例。将亚马逊 FSx 配置为用于存储 . 的网络应用程序"
    },
    "vote_percentage": "98%",
    "tags": [
      "FSx",
      "Cross-Platform File System"
    ],
    "explanation": {
      "analysis": "考察如何在 AWS 上实现跨平台的共享文件系统，同时最大程度地减少代码更改。",
      "why_correct": "选项D：使用 FSx for Windows File Server，可以同时支持 Linux 和 Windows 应用程序，并且不需要修改代码。FSx 可以提供 NFS 和 SMB 协议，满足不同操作系统访问共享文件的需求。",
      "why_wrong": "选项A：S3 不支持 NFS 或 SMB 协议，不适用。选项B：ECS 与文件共享无关。选项C：使用 SQS 来传递数据，需要修改应用程序代码，且效率较低。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "ECS",
      "FSx 文件网关",
      "EC2",
      "SQS",
      "FSx"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 284,
    "topic": "",
    "question_cn": "作为预算规划的一部分，管理层希望有一份由用户列出的美国世界银行账单项目的报告。这些数据将用于编制部门预算。解决方案架构师需要确定获取此报表信息的最有效方式。 哪种解决方案符合这些要求",
    "options_cn": {
      "A": "运行与亚马逊 Athena 查询生成报告。",
      "B": "在成本资源管理器中创建一个报表并下载报表。",
      "C": "从账单仪表板上访问账单细节并下载账单。",
      "D": "修改 AWS 预算中的成本预算以提醒亚马逊简单电子邮件服务 (SES)。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Cost Explorer",
      "Billing Report"
    ],
    "explanation": {
      "analysis": "考查如何获取 AWS 账单报告。",
      "why_correct": "选项B：在成本资源管理器中创建报告并下载，是最直接和最有效的方式。",
      "why_wrong": "选项A：Athena 用于查询数据，不是直接生成报告的工具。选项C：账单仪表板上只能查看细节，不能直接生成所需的报告。选项D：SES 用于发送通知，不能生成报告。"
    },
    "related_terms": [
      "Athena",
      "成本资源管理器",
      "SES"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 285,
    "topic": "",
    "question_cn": "一家公司通过使用亚马逊 S3 来主持其静态网站。该公司想在其网页上添加一个联系表格。该联系人表单将有动态服务器端组件供用户输入其姓名、电子邮件地址、电话号码和用户信息。该公司预计每月的实地访问将少于 100 次。 哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "在亚马逊弹性容器服务中设有动态接触表格页面。建立亚马逊简单电子邮件服务 (SES) 连接任何第三方电子邮件提供商。",
      "B": "创建一个 API API网关端点使用一个AWS Lambda 后端，它向亚马逊简单的电子邮件服务 (SES) 呼叫。",
      "C": "通过部署亚马逊光帆将静态网页转换为动态网页。使用客户端脚本来构建联系表单。将表单与亚马逊工作邮件集成。",
      "D": "创建一个 T2 微亚马逊 EC2 实例。部署一个灯(Linux, Apache, MySQL, PHP/Perl/Python)堆栈来主机网页。使用客户端脚本来构建联系表单。将表单与亚马逊工作邮件集成。"
    },
    "vote_percentage": "93%",
    "tags": [
      "Lambda",
      "API Gateway",
      "SES"
    ],
    "explanation": {
      "analysis": "考查如何添加动态表单到静态网站，并处理少量邮件发送。",
      "why_correct": "选项B：使用 API Gateway、AWS Lambda 和 SES 是一个轻量级、低成本的解决方案，适用于少量邮件发送需求。Lambda 处理表单提交，SES 发送邮件。",
      "why_wrong": "选项A：ECS 成本较高。选项C：LightSail 虽然简单，但对于动态网页，不如Lambda灵活。选项D：使用EC2 实例，资源消耗和运维成本较高。"
    },
    "related_terms": [
      "S3",
      "ECS",
      "SES",
      "API Gateway",
      "Lambda",
      "光帆",
      "EC2",
      "LAMP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 286,
    "topic": "",
    "question_cn": "一家公司有一个静态网站该网站在亚马逊 CloudFront 前的 CloudFront。静态网站使用数据库后端。该公司注意到该网站并不反映网站存储库中所做的更新。该公司检查存储库和亚马逊 S3 之间的连续集成和连续交付(CI/CD) 管道。该公司验证网络挂钩的配置是否正确以 CI/CD 及 管道正在发送信息表明部署是否成功。解决方案架构师需要实现在网站上显示更新的解决方案。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "添加一个应用程序负载平衡器。",
      "B": "在应用程序的数据库层中添加用于Web的亚马逊弹性计算机 (REDIS)。",
      "C": "无效云前缓存。",
      "D": "使用 AWS 证书管理器 (ACM) 来验证网站的 SSL 证书。"
    },
    "vote_percentage": "96%",
    "tags": [
      "CloudFront",
      "Caching",
      "CI/CD"
    ],
    "explanation": {
      "analysis": "核心考点: 解决静态网站无法及时更新的问题，确保内容变更能够被用户看到。 注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，通过无效化 CloudFront 缓存来更新网站内容，可以立即反映代码更改。",
      "why_correct": "选项 C 通过无效化 CloudFront 缓存，强制 CloudFront 重新从 S3 获取最新的内容，确保网站能够及时显示更新。",
      "why_wrong": "选项 A 和 B 与解决网站缓存问题无关。 选项 D 用于 SSL 证书管理，与内容更新无关。"
    },
    "related_terms": [
      "CloudFront",
      "S3",
      "应用程序负载平衡器",
      "REDIS",
      "ACM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 287,
    "topic": "",
    "question_cn": "一家公司希望将基于Windows SQL的应用程序从内部迁移到云。应用程序有三层：应用程序层、业务层和带有微软 SQL Server的数据库层。该公司希望使用 SQL Server 的特定功能，如本地备份和数据质量服务。该公司还需要共享文件以便在各个层次之间进行处理。 解决方案架构师应该如何设计架构以满足这些需求？",
    "options_cn": {
      "A": "在亚马逊 EC2网站上提供所有三级服务。使用亚马逊文件网关进行层与层之间的文件共享。",
      "B": "在亚马逊 EC2网站上提供所有三级服务。使用亚马逊 FSX for Windows 文件服务器之间的文件共享层。",
      "C": "在亚马逊 EC2 实例上托管应用程序层和业务层。在亚马逊 RDS 上主机数据库层。使用亚马逊弹性文件系统 EFS 进行层与层之间的文件共享。",
      "D": "发展在亚马逊 EC2 实例上托管应用程序层和业务层。在亚马逊 RDS 上主机数据库层。使用一个提供的亚马逊 EBS 卷进行层之间的文件共享。"
    },
    "vote_percentage": "89%",
    "tags": [
      "EC2",
      "FSx for Windows File Server"
    ],
    "explanation": {
      "analysis": "考点是 Windows 环境下的文件共享和数据库迁移。FSx for Windows File Server 提供了 Windows 文件共享功能，RDS 提供了数据库服务",
      "why_correct": "B 方案使用 FSx for Windows File Server 满足文件共享需求, 并且可以在 EC2 和 RDS 上托管应用程序",
      "why_wrong": "A 使用文件网关，增加了复杂性，且不是最佳实践；C 使用 EFS 进行 Windows 文件共享不合适； D 使用 EBS 进行文件共享不合适。"
    },
    "related_terms": [
      "EC2",
      "文件网关",
      "FSx for Windows",
      "RDS",
      "EFS",
      "EBS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 288,
    "topic": "",
    "question_cn": "一家公司正在将一个基于 Web 的网上服务服务器组迁移到 AWS。服务器必须为某些内容访问共享文件存储库中的文件。公司不得 对申请作出任何更改。 解决方案架构师应该如何满足这些需求?",
    "options_cn": {
      "A": "创建一个亚马逊 S3 桶访问 Web 服务器。",
      "B": "配置亚马逊 S3，以亚马逊 S3 桶作为起源配置亚马逊云端分布。",
      "C": "创建一个亚马逊 EFS 弹性文件系统。在所有网络服务器上安装 EFS 文件系统。",
      "D": "配置通用 亚马逊 EBS 弹性块存储卷。将 EBS 卷挂载到所有服务器上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察共享文件存储解决方案。 社区共识认为 EFS 是最佳答案。EFS 适合多个 EC2 实例共享文件存储，而 S3 适合静态网站或对象存储。",
      "why_correct": "EFS 提供一个共享文件系统，可以被多个 EC2 实例访问，满足题目需求，无需对应用程序进行更改。",
      "why_wrong": "A 选项 S3 桶不能直接作为文件系统挂载给 EC2 实例， 需要通过其他方式如 FUSE 来实现文件访问，且 S3 适合存储对象，不是共享文件系统。B 选项，配置 CloudFront 无法解决共享文件系统的问题。D 选项, EBS 是块存储，需要每个 EC2 实例单独挂载，不适合多实例共享文件存储。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "EFS",
      "EBS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 289,
    "topic": "",
    "question_cn": "一个公司有一个 Lambda 函数，需要阅读访问位于相同 AWS 帐户的亚马逊 S3 桶。 哪个解决方案将以最安全的方式满足这些要求?",
    "options_cn": {
      "A": "对 S3 桶应用一个桶策略，该策略允许 Lambda 函数阅读访问 S3 桶。",
      "B": "在 Lambda 函数中应用 IAM 角色。对角色应用策略授予对 S3 桶的读访问权。",
      "C": "在 Lambda 函数的代码中嵌入一个访问密钥和一个秘密密钥以授予对 S3 桶的读取访问所需的权限。",
      "D": "在 Lambda 函数中应用 IAM 角色。对该角色应用策略授予对帐户中所有 S3 桶的读访问权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "IAM"
    ],
    "explanation": {
      "analysis": "此题考察 Lambda 函数访问 S3 桶的安全性。 社区共识认为，使用 IAM 角色是最安全的方案。",
      "why_correct": "使用 IAM 角色，通过角色策略控制 Lambda 函数对 S3 桶的访问权限，遵循最小权限原则，提高了安全性，并且方便管理。",
      "why_wrong": "A 选项，桶策略可以授权访问，但不如 IAM 角色安全和灵活。C 选项，在代码中硬编码访问密钥和秘密密钥不安全，容易泄露。D 选项，授予对所有 S3 桶的读访问权限，违反了最小权限原则，存在安全风险。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "IAM",
      "IAM 角色"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 290,
    "topic": "",
    "question_cn": "一个公司在多个亚马逊 EC2 实例上拥有一个应用程序。 实例位于一个自动缩放组中，根据用户需求进行缩放。该公司希望在不 做出长期承诺的情况下优化成本节约。 解决方案架构师应该推荐哪个 EC2 实例采购选项来满足这些需求?",
    "options_cn": {
      "A": "专用实例",
      "B": "只按需提供实例",
      "C": "按需实例和竞价实例的混合",
      "D": "按需实例和保留实例的混合"
    },
    "vote_percentage": "90%",
    "tags": [
      "EC2",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "此题考察 EC2 实例的购买选项。 社区共识认为，按需实例和竞价实例的混合是最佳方案，可以在不承诺长期使用的情况下优化成本。",
      "why_correct": "竞价实例提供了大幅折扣，可以有效降低成本。结合按需实例，可以满足应用程序的弹性需求，并在竞价实例不可用时提供备用资源。",
      "why_wrong": "A 选项，专用实例没有成本优势。B 选项，按需实例成本最高。D 选项，保留实例需要长期承诺，不符合题目中“不做出长期承诺”的要求。"
    },
    "related_terms": [
      "EC2",
      "专用实例",
      "按需实例",
      "竞价实例",
      "保留实例"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 291,
    "topic": "",
    "question_cn": "一家媒体公司利用亚马逊 CloudFront 为其公开提供的流媒体视频内容。该公司希望通过控制谁可以访问来确保亚马逊 S3 上的视频内容的 HTTP 安全。该公司的一些用户正在使用一个不支持饼干的定制 客户机。该公司的一些用户无法更改他们用于访问的硬编码网址。 哪些服务或方法将满足这些要求对用户的影响最小？ 选二。",
    "options_cn": {
      "A": "签名饼干",
      "B": "签名网址",
      "C": "AWS WAF 应用程序",
      "D": "JSON Web (JWT) 令牌",
      "E": "AWS 密钥管理服务（KMS）"
    },
    "vote_percentage": "85%",
    "tags": [
      "CloudFront",
      "Security"
    ],
    "explanation": {
      "analysis": "此题考察 CloudFront 的安全访问控制。社区共识认为签名 URL 和签名 Cookie 可以满足需求。",
      "why_correct": "签名 URL 和签名 Cookie 允许您控制对 CloudFront 内容的访问。签名 URL 适用于无法使用 Cookie 的客户端。 签名 Cookie 提供了更灵活的控制，但需要客户端支持 Cookie。 （本题为多选题，正确项为：A、B，需全部选对才得分。）",
      "why_wrong": "C 选项，AWS WAF 应用程序可以保护 Web 应用程序免受常见攻击，但不能直接控制视频内容的访问。D 选项，JWT 令牌是一种身份验证和授权机制，需要客户端实现。E 选项，KMS 用于加密，与控制访问无关。"
    },
    "related_terms": [
      "CloudFront",
      "S3",
      "HTTP",
      "饼干",
      "签名网址",
      "AWS WAF",
      "JSON Web (JWT)",
      "KMS"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 292,
    "topic": "",
    "question_cn": "一家公司正在准备一个新的数据平台，它将吸收来自多个来源的实时流数据。在将数据写入亚马逊 S3 之前，该公司需要对数据进行转换。公司需要能够使用 Amazon Athena 来查询被转换的数据。 哪些解决方案能满足这些要求？ 选二。",
    "options_cn": {
      "A": "使用亚马逊 Kinesis Data Streams来流数据。使用亚马逊 Kinesis Data Analytics 来转换数据。使用亚马逊 Kinesis Data Firehose 将数据写入亚马逊 S3。使用 Amazon Athena 查询从亚马逊 S3 转换数据。",
      "B": "使用亚马逊 Managed Apache Kafka (MSK)流来流数据。使用 Glue 来转换数据并将数据写入到亚马逊 S3。使用 Amazon Athena 查询从亚马逊 S3 转换数据。",
      "C": "使用 AWS Database Migration Service 来吸收数据。使用亚马逊 EMR 来转换数据并将数据写入亚马逊 S3。使用 Amazon Athena 查询从亚马逊 S3 转换数据。",
      "D": "发展使用亚马逊 Managed Apache Kafka (MSK)流来流数据。使用亚马逊 Kinesis Data Analytics来转换数据并将数据写入亚马逊 S3。使用 Amazon Athena 查询编辑器来查询来自亚马逊 S3 的转换数据。",
      "E": "使用亚马逊 Kinesis Data Streams来流数据。使用 Glue 来转换数据 使用亚马逊 Kinesis Data Firehose 将数据写入亚马逊 S3。使用 Amazon Athena 查询编辑器来查询来自亚马逊 S3 的转换数据。"
    },
    "vote_percentage": "91%",
    "tags": [
      "Kinesis",
      "Glue",
      "Athena"
    ],
    "explanation": {
      "analysis": "考点是数据流、数据转换和数据查询。Kinesis、Glue 和 Athena 提供了完整的解决方案。",
      "why_correct": "A 和 B 方案分别使用 Kinesis Data Streams/Kinesis Data Analytics/Kinesis Data Firehose 和 MSK/Glue 满足数据流、转换和写入 S3 的需求，Athena 用于查询。",
      "why_wrong": "C 使用 DMS 进行数据流处理不合适。D 和 E  均使用 Amazon Athena 查询编辑器，不符合最佳实践。"
    },
    "related_terms": [
      "S3",
      "Athena",
      "Kinesis Data Streams",
      "Kinesis Data Analytics",
      "Kinesis Data Firehose",
      "Managed Apache Kafka (MSK)",
      "Glue",
      "AWS Database Migration Service",
      "EMR"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 293,
    "topic": "",
    "question_cn": "一个公司有一个在现场的卷备份解决方案已经到了生命的尽头。该公司希望使用 AWS 作为新的备份解决方案的一部分，并希望在备份时维护对所有数据的本地访问。该公司希望确保自动和安全地传输 AWS 上备份的数据。 哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS Snowball 将数据从内部解决方案迁移到亚马逊 S3。配置内部系统以安装 Snowball 端点提供对数据的本地访问。",
      "B": "使用 AWS Snowball Edge 将数据从内部解决方案迁移到亚马逊 S3。使用 Snowball Edge 文件接口提供本地访问数据的内部系统。",
      "C": "使用 AWS Storage Gateway 并配置缓存的卷网关。在现场运行 Storage Gateway 软件设备并配置一定比例的数据进行本地缓存。安装网关存储卷，以提供对数据的本地访问",
      "D": "发展使用 Storage Gateway 并配置存储卷网关。在酒店内运行 Storage Gateway 软件设备并将网关存储量映射到酒店内存储。安装网关存储卷以提供对数据的本地访问"
    },
    "vote_percentage": "100%",
    "tags": [
      "Storage Gateway",
      "Backup"
    ],
    "explanation": {
      "analysis": "考点是本地备份和 AWS 备份解决方案。Storage Gateway 提供了本地访问和云端备份的结合。",
      "why_correct": "D  Storage Gateway (存储卷网关) 提供了本地存储，并通过异步方式备份到 AWS。这满足了本地访问和备份的需求。",
      "why_wrong": "A 和 B  Snowball 用于大规模数据迁移，不适合作为日常备份方案; C 配置缓存的卷网关，缓存的比例可能无法满足需求。"
    },
    "related_terms": [
      "AWS Snowball",
      "S3",
      "Snowball Edge",
      "Storage Gateway",
      "Storage Gateway 缓存的卷网关",
      "Storage Gateway 存储卷网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 294,
    "topic": "",
    "question_cn": "在亚马逊 EC2 实例中托管的应用程序需要访问一个亚马逊 S3 桶。流量不得穿过互联网。 解决方案架构师应该如何配置访问以满足这些需求？",
    "options_cn": {
      "A": "使用亚马逊 Route 53 创建一个私人托管区域。",
      "B": "在 VPC 中为亚马逊 S3 设置 VPC 网关 Endpoint。",
      "C": "配置使用 NAT 网关访问 S3 桶的 EC2 实例。",
      "D": "发展在 VPC 和 S3 吊桶之间建立一个站点到站点的 VPN 连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "考点是 EC2 实例访问 S3 的私有连接方式，VPC Endpoint 提供此功能。",
      "why_correct": "B 使用 VPC 网关 Endpoint，使 EC2 实例通过私有网络访问 S3，避免了流量通过互联网，且无需 NAT 或 VPN。",
      "why_wrong": "A  Route 53 用于 DNS 解析，与 S3 的私有访问无关；C NAT 网关用于使实例可以访问互联网，但增加了成本和复杂度；D VPN 连接增加了复杂性，不高效。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "Route 53",
      "VPC",
      "VPC 网关 Endpoint",
      "NAT 网关",
      "VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 295,
    "topic": "",
    "question_cn": "一家电子商务公司在 AWS 云中存储数兆字节的客户数据。数据包含个人识别信息 PII。该公司希望在三个应用程序中使用这些数据。只有一个应用程序需要处理 PII。在其他两个应用程序处理数据之前必须删除 PII。 用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将数据存储在亚马逊 DynamoDB 表中。创建代理应用程序层以拦截和处理每个应用程序请求的数据。",
      "B": "将数据存储在亚马逊 S3 桶中。在将数据返回请求的应用程序之前，使用 Lambda 对象处理和转换数据。",
      "C": "将 S3，处理数据并将转换后的数据存储在三个独立的亚马逊 S3 桶中，这样每个应用程序都有自己的自定义数据集。将每个应用程序指 S3 向各自的桶。",
      "D": "发展处理数据并将转换后的数据存储在三个独立的亚马逊 DynamoDB 表中，这样每个应用程序都有自己的自定义数据集。将每个应 用程序指向各自的 DynamoDB 表。"
    },
    "vote_percentage": "86%",
    "tags": [
      "S3",
      "Lambda",
      "Data Processing"
    ],
    "explanation": {
      "analysis": "考点是数据存储、PII 处理和数据分发。 Lambda 函数可以处理数据转换。",
      "why_correct": "B 将数据存储在 S3 中， 使用 Lambda 函数在返回应用程序前处理数据，可以删除 PII，满足需求且开销最小。",
      "why_wrong": "A 使用代理，增加了复杂性，且效率不高；C 拷贝数据到不同的桶增加了存储和管理开销；D 将数据复制到不同的 DynamoDB 表增加了成本。"
    },
    "related_terms": [
      "EC2",
      "DynamoDB",
      "PII",
      "S3",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 296,
    "topic": "",
    "question_cn": "一个开发团队已经启动了一个新的应用程序，它在一个开发 VPC 中的亚马逊 EC2 实例中托管。解决方案架构师需要在同一帐户中创建一个新的 VPC。新的 VPC 将与开发 VPC 一起观察。开发 VPC CIDR 块是 192.168.0.0/24。解决方案架构师需要为新的 VPC 创建一个 CIDR 块。 VPC 块必须对开发 VPC 的窥视连接有效。 满足这些要求的最小的 CIDR 块是什么?",
    "options_cn": {
      "A": "10.0.1.0/32",
      "B": "192.168.0.0/24",
      "C": "192.168.1.0/32",
      "D": "10.0.1.0/24"
    },
    "vote_percentage": "98%",
    "tags": [
      "VPC",
      "CIDR"
    ],
    "explanation": {
      "analysis": "此题考察 VPC 和 CIDR 块的知识。 社区共识认为 D 选项 10.0.1.0/24 是最佳答案，能满足建立 VPC peering 的要求，且CIDR 块不能重叠。",
      "why_correct": "D 选项，10.0.1.0/24 能够创建一个新的 VPC，并且 CIDR 与 192.168.0.0/24 互不冲突，可以建立 VPC peering 连接。",
      "why_wrong": "A 选项，/32 只能容纳一个 IP 地址，无法满足 VPC 的需求。B 选项，192.168.0.0/24 与开发 VPC CIDR 重叠，无法建立 VPC peering。C 选项，192.168.1.0/32 只能容纳一个 IP 地址，且与开发 VPC 的 CIDR 在同一个网段，无法满足 VPC 的需求。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "CIDR"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 297,
    "topic": "",
    "question_cn": "一个公司在 5 个 EC2 实例上部署一个应用程序。应用程序负载平衡器通过使用目标组向实例分配流量。在大多数情况下，每个 CPU 实例的平均使用率都低于 10%，偶尔会激增到 65%。 解决方案架构师需要实现解决方案来自动化应用程序的可伸缩性。解决方案必须优化体系结构的成本，并且必须确保在出现激增时应 CPU 用程序有足够的资源。 哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "创建一个亚马逊 CloudWatch 报警，当使用率低于 20% 时进入报警状态。创建 CloudWatch 警报调用的 Lambda 函数以终止目标组中的一个实例。",
      "B": "创建一个 EC2 自动缩放组。选择现有的应用程序负载平衡器作为负载平衡器，现有的目标组作为目标组。设定基于垃圾利用率度量的目标跟踪缩放策略。将最小实例设置为 2，所需容量设置为 3，最大实例设置为 6，目标值设置为 50%。将 EC2 实例添加到自动缩放组中。",
      "C": "创建一个 EC2 自动缩放组。选择现有的应用程序负载平衡器作为负载平衡器，现有的目标组作为目标组。将最小实例设置为 2 个，将所需容量设置为 3 个，将最大实例设置为 6 个。将 EC2 实例添加到自动缩放组中。",
      "D": "创建一个亚马逊 CloudWatch 警报器。当平均使用率指标低于 20% 时，将第一个 CloudWatch 报警设置为进入报警状态。配置第二个 CloudWatch 报警器，当平均利用率大于 50% 时进入报警状态。将警报器配置为发布到亚马逊简单通知服务（SNS）主题以发送电子邮件。在 EC2 收到消息后登录以减少或增加正在运行的实例的数量。"
    },
    "vote_percentage": "96%",
    "tags": [
      "EC2 Auto Scaling",
      "Load Balancing"
    ],
    "explanation": {
      "analysis": "此题考察 EC2 自动伸缩组（Auto Scaling Group, ASG）的配置。 社区共识认为 B 选项是最佳答案，利用目标跟踪缩放策略，可以自动调整实例数量以适应负载变化，实现弹性伸缩。",
      "why_correct": "B 选项使用目标跟踪缩放策略，它可以根据目标组的平均 CPU 利用率自动调整实例数量，实现自动化伸缩。 配置最小实例数和最大实例数，控制成本和资源可用性。 设定目标值为 50%，可以根据实际情况调整。",
      "why_wrong": "A 选项，使用 Lambda 函数终止实例，不够自动化，且不能实现扩容。D 选项，通过 SNS 发送邮件通知人工干预，无法实现自动化伸缩。C 选项，手动设置实例数量，无法自动伸缩。"
    },
    "related_terms": [
      "EC2",
      "CloudWatch",
      "Lambda",
      "EC2 自动缩放组",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 298,
    "topic": "",
    "question_cn": "一家公司正在 EC2 实例中运行一个关键的业务应用程序，支持一个应用程序负载平衡器。 EC2 实例在一个自动缩放组中运行并访问亚马逊 RDS 数据库实例。 设计没有通过操作性审查，因为 EC2 实例和 RDS 数据库实例都位于一个可用性区中。解决方案架构师必须更新设计以使用第二个可用性区域。 哪个解决方案将使应用程序非常可用?",
    "options_cn": {
      "A": "在每个可用区域提供一个子网。配置自动缩放组将 EC2 实例分布到两个可用性区域。配置带有连接到每个网络的 RDS 实例。",
      "B": "提供两个子网络覆盖两个可用区域。配置自动缩放组将 EC2 实例分布到两个可用性区域。配置带有连接到每个网络的 RDS 实例。",
      "C": "在每个可用区域提供一个子网。配置自动缩放组将 EC2 实例分布到两个可用性区域。为多 AZ 部署配置 RDS 实例。",
      "D": "提供跨两个可用性区域的子网。配置自动缩放组将 EC2 实例分布到两个可用性区域。为多 AZ 部署配置 RDS 实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "High Availability",
      "Multi-AZ"
    ],
    "explanation": {
      "analysis": "此题考察应用程序的高可用性设计，尤其是 RDS 多可用区部署。 社区共识认为 C 选项是最佳答案，RDS 多可用区部署是高可用性的关键。",
      "why_correct": "C 选项，通过在两个可用区中配置子网，并使用自动缩放组将 EC2 实例分布到两个可用区，可以实现高可用性。 此外，为多 AZ 部署配置 RDS 实例是高可用性的关键。RDS 会自动在多个可用区创建数据库实例的备用副本，保证数据库的可用性。",
      "why_wrong": "A 选项，虽然实现了 EC2 的高可用性，但没有解决 RDS 的单点故障问题。B 选项，RDS 部署没有使用多可用区，不满足高可用性。D 选项，子网跨越可用区不合规范。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "RDS",
      "自动缩放组",
      "可用性区",
      "Multi-AZ"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 299,
    "topic": "",
    "question_cn": "一个研究实验室需要处理大约 8 TB 的数据。该实验室需要的是亚毫秒的延迟和存储子系统的最小吞吐量为 6Gbps。运行亚马逊 EC2 的数百个亚马逊 EC2 实例将分发和处理数据。 哪种解决方案能满足性能要求?",
    "options_cn": {
      "A": "创建一个亚马逊 FSx for Lustre 网络文件系统。每个卷都有所有的分类政策。将原始数据导入文件系统。在 EC2 实例上安装 FSx 系统。",
      "B": "创建一个亚马逊 S3 桶来存储原始数据。为使用持久性 SSD 存储的光文件系统创建一个亚马逊 FSx。选择向亚马逊 S3 导入数据和 EC2 导出数据的选项。在 EC2 实例上安装 FSx 文件系统。",
      "C": "创建一个亚马逊 S3 桶来存储原始数据。为光泽文件系统创建一个亚马逊 FSx，该系统使用持久的 HDD 存储。选择向亚马逊 S3 导入数据和 EC2 导出数据的选项。在 EC2 实例上安装 FSx 文件系统。",
      "D": "创建一个亚马逊 FSx for Lustre 网络文件系统。将每卷的分页策略设置为零。将原始数据导入文件系统。在 EC2 实例上安装 FSx 文件系统。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Lustre",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察高性能存储解决方案。社区共识认为 B 选项是最佳答案，它结合了 S3 的存储和 FSx for Lustre 的高性能。 ",
      "why_correct": "B 选项使用 FSx for Lustre，满足亚毫秒延迟和 6Gbps 吞吐量的要求。通过 S3 作为数据源，可以方便地导入数据。FSx for Lustre 专为高性能计算（HPC）工作负载设计，提供了高性能的存储解决方案。",
      "why_wrong": "A 选项，FSx for Lustre 的性能不错，但没有说明数据如何导入。C 选项，HDD 的性能无法满足亚毫秒的延迟要求。D 选项，FSx for Lustre 的性能不错，但没有说明数据如何导入，且 paging 策略不明确。"
    },
    "related_terms": [
      "EC2",
      "FSx for Lustre",
      "S3",
      "SSD",
      "HDD"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 300,
    "topic": "",
    "question_cn": "由于硬件容量的限制，公司需要将遗留应用程序从内部数据中心迁移到 AWS 云。该应用程序每天 24 小时运行，每周 7 天。随着时间的推移，迁移应用程序的数据库存储继续增长。 解决方案架构师应该做什么才能最经济有效地满足这些需求？",
    "options_cn": {
      "A": "将应用层迁移到亚马逊 EC2 点实例。将数据存储层迁移到亚马逊 S3。",
      "B": "将应用程序层迁移到亚马逊 EC2 保留实例。将数据存储层迁移到亚马逊 RDS 按需实例。",
      "C": "将应用程序层迁移到亚马逊 EC2 保留实例。将数据存储层迁移到亚马逊 Aurora 保留实例。",
      "D": "发展将应用层迁移到亚马逊 EC2 按需实例。将数据存储层迁移到亚马逊 RDS 保留实例。"
    },
    "vote_percentage": "86%",
    "tags": [
      "Cost Optimization",
      "Reserved Instances"
    ],
    "explanation": {
      "analysis": "考点是成本优化。保留实例提供最大的成本节省，适用于持续运行的应用程序。",
      "why_correct": "C 使用保留实例对应用程序层和 Aurora 数据库存储进行优化，因为它们是持续运行的。Aurora 保留实例提供了额外的成本节省。",
      "why_wrong": "A 点实例是临时的，不适用于关键业务；B 将数据库层使用按需实例，会增加成本；D 将应用层使用按需实例，会增加成本。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "RDS",
      "Aurora"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 301,
    "topic": "",
    "question_cn": "一家大学研究实验室需要将30TB的数据从所在地的Windows文件服务器迁移到亚马逊S3文件服务器。该实验室有一个1Gbps的网络链接，这是大学许多其他部门共享的，该实验室希望实现数据迁移服务以最大限度地提高数据传输的性能。然而实验室需要能够控制服务使用的带宽量以尽量减少对其他部门的影响。数据迁移必须在未来30天内进行。哪一种AWS解决方案能够满足这些要求？",
    "options_cn": {
      "A": "Snowball",
      "B": "FSx亚马逊文件网关",
      "C": "数据采集系统",
      "D": "家庭服务转学"
    },
    "vote_percentage": "96%",
    "tags": [
      "Data Migration",
      "AWS Snowball"
    ],
    "explanation": {
      "analysis": "考查数据迁移服务，需要考虑带宽控制和传输效率。",
      "why_correct": "数据采集系统可以控制带宽使用，适用于大规模数据迁移。",
      "why_wrong": "雪锥用于物理传输，FSx文件网关用于混合云存储，不适合直接数据传输。"
    },
    "related_terms": [
      "S3",
      "Windows",
      "FSx",
      "Snowball"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 302,
    "topic": "",
    "question_cn": "一家公司希望创建一个手机应用程序，允许用户在他们的移动设备上传输慢动作视频片段。目前该应用程序捕捉视频片段并将原始格式的视频片段上传到亚马逊S3桶。应用程序直接从S3桶中检索这些视频片段。然而这些视频的原始格式很大，用户正在经历在移动设备上缓冲和播放的问题。该公司希望实现解决方案以最大限度地提高应用程序的性能和可伸缩性，同时最大限度地减少操作开销。哪些解决方案能够满足这些要求？（选二）",
    "options_cn": {
      "A": "部署亚马逊云端用于内容传递和缓存。",
      "B": "使用S3数据监视器来复制这些视频文件。",
      "C": "使用亚马逊弹性转换器将视频文件转换成更合适的格式。",
      "D": "在本地区域部署亚马逊EC2实例的自动密封组用于内容传递和缓存。",
      "E": "部署亚马逊EC2实例的自动缩放组将视频文件转换为更合适的格式。"
    },
    "vote_percentage": "57%",
    "tags": [
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考查视频流媒体优化，包括内容分发和转码。",
      "why_correct": "云端用于内容分发和缓存，弹性转换器用于视频转码，都可提升性能和用户体验。",
      "why_wrong": "数据监视器仅复制文件，不能解决性能问题；EC2方案增加了运维复杂度。"
    },
    "related_terms": [
      "CloudFront",
      "S3",
      "EC2",
      "弹性转换器",
      "自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 303,
    "topic": "",
    "question_cn": "一家公司正在推出一种新的应用程序，部署在亚马逊弹性集装箱服务集群上，并正在使用法尔盖特发射类型的任务。该公司正在监控CPU和内存的使用情况，因为它在启动时期待着高流量的应用程序。然而公司希望在利用率下降时降低成本。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "根据以前的流量模式使用亚马逊EC2自动缩放在某些时间段。",
      "B": "使用一个基于公制破口的Lambda功能以触发亚马逊云表警报。",
      "C": "使用亚马逊ECS自动缩放与简单的缩放策略来缩放时，公制破坏触发亚马逊云表警报。",
      "D": "使用ECS应用程序与目标跟踪策略自动缩放，当公制破坏触发亚马逊云表警报。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考查ECS的自动伸缩策略，目标是优化成本和性能。",
      "why_correct": "使用ECS应用程序目标跟踪策略自动缩放可以根据资源利用率自动调整任务数量，实现成本优化。",
      "why_wrong": "其他选项无法充分利用ECS自动伸缩功能，或增加了不必要的复杂性。"
    },
    "related_terms": [
      "ECS",
      "法尔盖特",
      "EC2",
      "Lambda",
      "CloudWatch",
      "自动缩放"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 304,
    "topic": "",
    "question_cn": "一家公司最近在一个不同的区域创建了一个灾难恢复站点。该公司需要在两个地区的NFS文件系统之间进行大量数据的周期性交换。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用NFS数据库。",
      "B": "使用Snowball装置。",
      "C": "在亚马逊EC2上设置一个SFTP服务器。",
      "D": "使用数据库迁移服务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "NFS",
      "Data Replication"
    ],
    "explanation": {
      "analysis": "考查不同区域间的数据同步和灾备方案。",
      "why_correct": "NFS数据库可以实现不同区域的文件系统间的数据同步。",
      "why_wrong": "Snowball用于离线数据传输，SFTP服务器需要手动管理，数据库迁移服务用于数据库迁移，不适用于文件系统同步。"
    },
    "related_terms": [
      "EC2",
      "NFS",
      "Snowball",
      "SFTP",
      "数据库迁移服务"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 305,
    "topic": "",
    "question_cn": "一家公司正在设计一个共享存储解决方案，用于在云中托管的游戏应用程序。公司需要能够使用SMB客户端访问数据。解决办法必须得到充分管理。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个作为可挂载文件系统共享数据的Amazon EFS数据合成任务。将文件系统安装到应用服务器上。",
      "B": "创建一个亚马逊Windows EC2实例。在实例中安装和配置文件共享角色。将应用程序服务器连接到文件共享。",
      "C": "为文件服务器文件系统创建一个亚马逊FSX。将文件系统连接到原服务器上。将应用程序服务器连接到文件系统。",
      "D": "创建一个亚马逊S3桶。为授予对S3桶访问权的应用程序分配一个IAM角色。将桶安装到应用服务器上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Windows File Server",
      "SMB"
    ],
    "explanation": {
      "analysis": "考查在AWS上提供SMB文件共享的解决方案。",
      "why_correct": "FSx for Windows File Server提供了完全托管的SMB文件共享服务，满足需求。",
      "why_wrong": "其他方案或者不提供SMB支持，或者需要手动配置和管理。"
    },
    "related_terms": [
      "SMB",
      "EFS",
      "EC2",
      "FSx",
      "S3",
      "IAM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 306,
    "topic": "",
    "question_cn": "一个公司想为一个在亚马逊EC2实例上运行的对延迟敏感的应用程序运行一个内存数据库。该应用程序每分钟处理10万多个事务，需要高网络吞吐量。解决方案架构师需要提供成本效益高的网络设计，最大限度地减少数据传输费用。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在同一区域内的同一可用性区域内启动所有EC2实例。在启动EC2实例时用集群策略指定一个放置组。",
      "B": "在同一区域内的不同可用性区域启动所有EC2实例。在启动EC2实例时用分区策略指定一个放置组。",
      "C": "部署一个自动缩放组，根据网络利用率目标在不同可用性区域启动EC2实例。",
      "D": "部署一个带有步骤扩展策略的自动扩展组以在不同可用性区域启动EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "Placement Group"
    ],
    "explanation": {
      "analysis": "考查EC2实例的网络性能优化，尤其是内存数据库。",
      "why_correct": "将EC2实例部署在同一可用区内的放置组中，可以最大限度减少延迟并提高网络吞吐量。",
      "why_wrong": "其他选项会导致更高的延迟和数据传输费用，或者不适用于对延迟敏感的应用程序。"
    },
    "related_terms": [
      "EC2",
      "可用性区域",
      "放置组",
      "自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 307,
    "topic": "",
    "question_cn": "一家主要在公司内部运行应用服务器的公司已经决定迁移到 AWS。该公司希望最大限度地减少扩大其互联网小型计算 (ISCSI) 机系统接口 存储的需求。该公司只希望其最近访问的数据保持在本地存储。 该公司应该使用哪种 解决方案来满足这些要求?",
    "options_cn": {
      "A": "亚马逊 S3 文件网关",
      "B": "存储网关磁带网关",
      "C": "存储网关卷网关存储卷",
      "D": "存储网关卷网关缓存卷"
    },
    "vote_percentage": "100%",
    "tags": [
      "Storage Gateway",
      "Caching"
    ],
    "explanation": {
      "analysis": "此题考察 AWS Storage Gateway 的应用场景。 社区共识认为 D 选项是最佳答案，可以使用缓存卷，只将最近访问的数据缓存在本地。",
      "why_correct": "D 选项，存储网关卷网关的缓存卷模式允许将数据缓存在本地，从而减少对存储的需求。只有最近访问的数据才会缓存在本地，其他数据存储在 S3 中，满足了“只希望其最近访问的数据保持在本地存储”的需求。",
      "why_wrong": "A 选项，文件网关主要用于访问 S3 桶。B 选项，磁带网关主要用于备份和存档。C 选项，存储卷网关的存储卷模式，所有数据存储在 AWS 上。"
    },
    "related_terms": [
      "S3",
      "存储网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 308,
    "topic": "",
    "question_cn": "一家公司有多个使用合并账单的 AWS 账户。该公司运行几个主动高性能亚马逊 RDS for Oracle 点播数据库实例。公司的财务团队可以在合并账单账户和所有其他 AWS 账户中访问 AWS Trusted Advisor。 财务团队需要使用适当的 RDS 账户访问 Trusted Advisor 检查建议的 RDS 成本。 财务团队必须审查适当的 Trusted Advisor 检查以减少 RDS 成本。 财务小组应采取哪些措施来满足这些要求？ 选二。",
    "options_cn": {
      "A": "使用运行 RDS 实例的账户中的 Trusted Advisor 建议。",
      "B": "使用来自合并账单账户的 Trusted Advisor 建议，可以同时查看所有 RDS 实例检查。",
      "C": "回顾亚马逊 RDS 保留实例优化的 Trusted Advisor 检查。",
      "D": "审查亚马逊 RDS 闲置 DB 实例的可信顾问检查。",
      "E": "回顾 Trusted Advisor 检查亚马逊 Redshift 保留节点优化。"
    },
    "vote_percentage": "61%",
    "tags": [
      "RDS",
      "Trusted Advisor"
    ],
    "explanation": {
      "analysis": "此题考察使用 Trusted Advisor 优化 RDS 成本。 社区共识认为 B 和 D 选项是最佳答案，一个是从合并账单账户统一查看，一个是检查闲置 DB 实例。",
      "why_correct": "B 选项，使用合并账单账户，可以集中管理所有 RDS 实例的成本。D 选项，检查闲置数据库实例，可以识别并关闭未使用的资源，节省成本。",
      "why_wrong": "A 选项，在单个账户中查看，无法全面了解所有 RDS 实例的成本情况。C 选项，Review RDS Reserved Instance 的检查，可以优化成本，但不是主要的检查目标。E 选项，审查 Redshift 保留节点优化，与 RDS 无关。"
    },
    "related_terms": [
      "RDS",
      "Trusted Advisor",
      "RDS 保留实例",
      "Amazon Redshift",
      "RDS 闲置 DB 实例"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 309,
    "topic": "",
    "question_cn": "解决方案架构师需要优化存储成本。解决方案架构师必须识别不再被访问或很少被访问的任何亚马逊 S3 桶。 哪个解决方案可以用最少的操作开销来实现这个目标?",
    "options_cn": {
      "A": "使用 S3 存储镜头仪表板分析桶访问模式，用于高级活动度量。",
      "B": "使用 AWS 管理控制台中的 S3 仪表板分析桶访问模式。",
      "C": "打开亚马逊 CloudWatch 的桶数为单位。使用亚马逊 Athena 的度量数据分析桶访问模式。",
      "D": "打开 CloudTrail 进行对象监测。通过使用与亚马逊 CloudWatch 日志集成的 CloudTrail 日志分析桶访问模式。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3",
      "S3 Storage Lens"
    ],
    "explanation": {
      "analysis": "此题考察 S3 存储成本优化。 社区共识认为 A 选项是最佳答案，利用 S3 存储镜头可以方便地分析 S3 桶的访问模式。",
      "why_correct": "A 选项，S3 存储镜头是专门为 S3 存储桶分析而设计的，可以提供访问模式的详细信息，方便识别不再被访问或很少被访问的桶，并采取相应的存储优化措施。这是最简便有效的方案。",
      "why_wrong": "B 选项，S3 管理控制台中的仪表板提供的分析功能有限，无法提供详细的访问模式分析。C 选项，CloudWatch + Athena 的方式虽然可行，但操作复杂度高。D 选项，使用 CloudTrail 分析访问模式，需要手动配置日志聚合和分析，不如 S3 存储镜头方便。"
    },
    "related_terms": [
      "S3",
      "S3 存储镜头",
      "CloudWatch",
      "Athena",
      "CloudTrail"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 310,
    "topic": "",
    "question_cn": "一家公司向从事人工智能和机器学习研究的客户销售数据集。这些数据集是大型的格式化文件，存储在美国东部1号区域的亚马逊S3桶中。该公司拥有一个Web应用程序，客户使用该应用程序购买访问给定数据集的权限。Web应用程序部署在应用程序负载均衡器后面的多个亚马逊EC2实例上。在购买之后，客户收到一个签名的URL，允许访问文件。客户分布在北美和欧洲各地。该公司希望降低与数据传输相关的成本，并希望保持或提高性能。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "在现有的S3桶上配置S3传输加速度。直接客户请求到传输加速端点。继续使用签名的URL进行访问控制。",
      "B": "以现有的S3桶作为起源部署亚马逊云端分布。直接客户请求到云前网址。切换到云前线签署的网址访问控制。",
      "C": "在欧盟-1区域设置第二个S3桶，在桶之间进行跨区域复制。直接客户请求到最近的区域。继续使用签名的URL进行访问控制。",
      "D": "修改Web应用程序使数据集能够流到终端用户。配置应用程序来读取现有S3桶中的数据。在应用程序中直接实现访问控制。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考查如何优化全球范围内的S3数据访问成本和性能。",
      "why_correct": "使用CloudFront分发S3内容可以降低数据传输成本，并提高全球范围内的访问速度。",
      "why_wrong": "其他方案或者不能有效降低成本，或者影响安全性。"
    },
    "related_terms": [
      "S3",
      "S3 Transfer Acceleration",
      "CloudFront",
      "签名URL",
      "EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 311,
    "topic": "",
    "question_cn": "一家公司正在使用 AWS 设计一个处理保险报价的 Web 应用程序。用户将从应用程序中请求报价。报价必须按报价类型分开，必须在 24 小时内回复，并且不得丢失。解决方案必须最大限度地提高操作效率，并必须最大限度地减少维护。 哪种解决方案符合这些要求?",
    "options_cn": {
      "A": "根据报价类型创建多个亚马逊 Kinesis 数据流。配置应用程序将消息发送到适当的数据流。配置每个应用程序服务器后端组（KCL）以使用查找客户机库 从自己的数据流中共享消息。",
      "B": "为每一个报价类型创建一个 Lambda 函数和一个亚马逊简单通知服务（SNS）主题。订阅 Lambda 函数与其相关的 SNS 主题。将应用程序配置为将引号请求发布到适当的 SNS 主题。",
      "C": "创建一个单一的亚马逊简单通知服务主题。订阅亚马逊简单队列服务（SQS）队列的信噪比主题。根据报价类型将 SQS 消息过滤器配置为将消息发布到适当的 SQS 队列。将每个后端应用程序服务器配置为使用自己的 SQS 队列。",
      "D": "根据报价类型创建多个亚马逊 DynamoDB 传递流。将数据流传递到亚马逊开放搜索服务集群。配置应用程序将消息发送到适当的传递流。配置每个应用服务器后端组来搜索来自开放搜索服务的消息并相应地处理它们。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "SNS"
    ],
    "explanation": {
      "analysis": "此题考察异步消息处理架构的设计。 社区共识认为 C 选项是最佳答案，利用 SQS 和 SNS 组合，可以实现异步消息处理，满足高可用和高效率需求。",
      "why_correct": "C 选项，通过 SNS 创建一个主题，应用程序将报价请求发布到 SNS 主题。SNS 将消息发布到根据报价类型配置的 SQS 队列。每个后端应用程序服务器从其自己的 SQS 队列中获取消息，并处理报价请求。这种架构满足了高可用性，异步处理，以及消息不丢失的要求，并且易于维护。Sqs 消息过滤能够支持按类型进行消息路由。",
      "why_wrong": "A 选项，Kinesis 数据流适合处理实时数据流，但对于报价请求这种场景，SQS 更合适。B 选项，每个报价类型对应一个 Lambda 函数和一个 SNS 主题，配置管理复杂，效率较低。D 选项， DynamoDB 传递流和开放搜索服务集群，开放搜索服务集群主要用于搜索和分析，不适合处理报价请求。"
    },
    "related_terms": [
      "Kinesis Data Streams",
      "Lambda",
      "SNS",
      "SQS",
      "DynamoDB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 312,
    "topic": "",
    "question_cn": "一个公司有一个应用程序运行在几个亚马逊 EC2 实例上。每个 EC2 实例都有多个亚马逊 EBS 数据卷连接到它。应用程序的 EC2 实例配置和数据需要每晚备份。应用程序还需要在不同的区域中恢复。 哪个解决方案将以最有效的方式满足这些要求?",
    "options_cn": {
      "A": "编写一个 Lambda 函数，该函数每天晚上安排应用程序 EBS 卷的快照，并将快照复制到不同的区域。",
      "B": "通过使用 AWS Backup 来执行夜间备份来创建备份计划。将备份复制到另一个区域。添加应用程序的 EC2 实例作为资源。",
      "C": "通过使用 AWS Backup 来执行夜间备份来创建备份计划。将备份复制到另一个区域。添加应用程序的 EBS 卷作为资源。",
      "D": "编写一个 Lambda 函数，该函数每天晚上安排应用程序 EBS 卷的快照，并将快照复制到不同的可用性区域。"
    },
    "vote_percentage": "92%",
    "tags": [
      "EBS Backup",
      "AWS Backup"
    ],
    "explanation": {
      "analysis": "此题考察 EBS 的备份和恢复方案。 社区共识认为 B 选项是最佳答案， 使用 AWS Backup 可以简化备份和恢复流程，更高效。",
      "why_correct": "B 选项，AWS Backup 提供了集中式的备份管理服务，可以简化备份的创建，调度，存储和恢复过程。通过 AWS Backup，可以轻松地创建 EBS 卷的备份计划，并将备份复制到另一个区域，满足了备份和跨区域恢复的需求，减少了手动操作的复杂性。",
      "why_wrong": "A 选项，手动编写 Lambda 函数管理 EBS 快照和复制，工作量大，维护复杂。D 选项，快照复制到不同的可用区，只能实现高可用，不能解决跨区域恢复的问题。C 选项，AWS Backup 备份 EBS 卷，缺少 EC2 实例的备份。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "Lambda",
      "AWS Backup"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 313,
    "topic": "",
    "question_cn": "一家公司正在建立一个基于AWS的移动应用程序。该公司希望将业务范围扩大到数百万人。公司需要建立一个平台，这样授权用户就可以在他们的移动设备上观看公司的内容。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "发布内容的公共亚马逊S3桶。使用AWS KMS键管理服务键来流内容。",
      "B": "在移动应用程序和AWS环境之间建立IPSEC VPN来流内容。",
      "C": "使用亚马逊云端。提供签名的URL来流内容。",
      "D": "在移动应用程序和AWS环境之间建立VPN客户端来流内容。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Signed URL"
    ],
    "explanation": {
      "analysis": "考查移动视频流媒体的解决方案，需要考虑可扩展性和安全性。",
      "why_correct": "使用CloudFront并提供签名的URL可以实现安全可靠的内容分发，并支持大规模用户访问。",
      "why_wrong": "其他方案不提供足够的可扩展性或安全性。"
    },
    "related_terms": [
      "S3",
      "AWS KMS",
      "云端",
      "签名的URL",
      "IPSEC VPN"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 314,
    "topic": "",
    "question_cn": "一家公司有一个内部的MySQL数据库，由全球销售团队使用，访问模式不常见。销售团队要求数据库有最少的停机时间。数据库管理员希望将此数据库迁移到AWS，而不选择特定的实例类型，因为预计将来会有更多的用户。解决方案架构师应该推荐哪种服务？",
    "options_cn": {
      "A": "亚马逊Aurora",
      "B": "亚马逊Aurora MySQL为MySQL提供无服务",
      "C": "亚马逊Redshift Spectrum",
      "D": "最新数据集"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora",
      "Serverless"
    ],
    "explanation": {
      "analysis": "考查数据库迁移和弹性扩展。",
      "why_correct": "亚马逊Aurora MySQL为MySQL提供无服务，可以自动扩展，并提供高可用性。",
      "why_wrong": "其他选项不提供这种灵活性或者不适用于此场景。"
    },
    "related_terms": [
      "MySQL",
      "Aurora",
      "MySQL",
      "Redshift",
      "无服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 315,
    "topic": "",
    "question_cn": "一家公司经历了一次破坏，影响了其内部数据中心的几个应用程序。攻击者利用服务器上运行的自定义应用程序中的漏洞。该公司目前正在将其应用程序迁移到亚马逊 EC2 实例上运行。该公司希望实现一种解决方案，即积极扫描 EC2 实例上的漏洞，并发送一份详细说明结果的报告。 哪个解决方案能满足这些要求?",
    "options_cn": {
      "A": "部署 AWS Inspector 扫描 EC2 实例的漏洞。创建一个 AWS CloudWatch Lambda 功能记录任何发现到的 AWS CloudTrail。",
      "B": "部署亚马逊 Macie 和 Lambda 功能扫描 EC2 实例的漏洞。把任何发现记录到 AWS CloudTrail 上。",
      "C": "打开亚马逊 GuardDuty。将 GuardDuty 部署到 EC2 实例中。配置一个 Lambda 功能以自动生成和分发详细说明调查结果的报告。",
      "D": "打开亚马逊 Inspector。部署亚马逊 Inspector 代理到 EC2 实例。配置一个 Lambda 功能以自动生成和分发详细说明调查结果的报告。"
    },
    "vote_percentage": "97%",
    "tags": [
      "EC2 Security",
      "Amazon Inspector"
    ],
    "explanation": {
      "analysis": "此题考察 EC2 实例的漏洞扫描。 社区共识认为 D 选项是最佳答案，使用 Inspector 和 Lambda 可以实现自动扫描和生成报告。",
      "why_correct": "D 选项，Amazon Inspector 是专门为 EC2 实例提供漏洞扫描的服务。部署 Inspector 代理，可以自动扫描 EC2 实例中的漏洞。然后，使用 Lambda 函数自动生成报告并分发调查结果，满足了扫描，报告，自动化的需求。",
      "why_wrong": "A 选项，AWS Inspector 扫描漏洞，但是 CloudTrail 的作用是记录 AWS API 调用，无法记录扫描结果。B 选项，Amazon Macie 主要用于数据安全，检测敏感数据，无法检测漏洞。C 选项， GuardDuty 主要用于威胁检测，而不是漏洞扫描。"
    },
    "related_terms": [
      "EC2",
      "AWS Inspector",
      "CloudWatch",
      "Lambda",
      "Amazon Macie",
      "GuardDuty"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 316,
    "topic": "",
    "question_cn": "一个公司使用一个亚马逊 EC2 实例运行一个脚本，以便在一个亚马逊简单队列服务队列中对消息进行轮询和处理。该公司希望降低运营成本，同时保持其处理队列中越来越多的消息的能力。 解决方案架构师应该建议什么来满足这些需求?",
    "options_cn": {
      "A": "增加 EC2 实例的规模以更快地处理消息。",
      "B": "当实例未被充分利用时，使用亚马逊 EventBridge 关闭 EC2 实例。",
      "C": "使用适当的运行时将 EC2 实例上的脚本迁移到 Lambda 函数。",
      "D": "使用 系统管理器运行命令按需运行脚本。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Lambda",
      "SQS"
    ],
    "explanation": {
      "analysis": "此题考察降低 EC2 运营成本的方案。 社区共识认为 C 选项是最佳答案，将脚本迁移到 Lambda 函数，可以实现按需付费，降低成本。",
      "why_correct": "C 选项，将脚本迁移到 Lambda 函数，可以实现按需付费，当队列中没有消息时，不会产生费用，从而降低了运营成本。 Lambda 可以自动伸缩，处理消息的能力也可以满足。",
      "why_wrong": "A 选项，增加 EC2 实例的规模，会增加成本，不能降低成本。B 选项，关闭 EC2 实例会降低成本，但需要处理消息时需要启动实例，可能产生延迟。D 选项，使用系统管理器运行命令按需运行脚本，但是会产生 EC2 实例费用。"
    },
    "related_terms": [
      "EC2",
      "简单队列服务",
      "EventBridge",
      "Lambda",
      "系统管理器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 317,
    "topic": "",
    "question_cn": "一家公司使用遗留应用程序以CSV格式生成数据。遗留应用程序在亚马逊S3中存储输出数据。该公司正在部署一个新的商业现成COTS应用程序，该应用程序可以执行复杂的SQL查询来分析存储在亚马逊Redshift和Amazon Athena中的数据。然而，COTS应用程序无法处理CSV文件。该公司无法更新遗留应用程序以生成其他格式的数据。公司需要实现一个解决方案，以便COTS应用程序能够使用遗留应用程序产生的CSV数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个AWS Glue (ETL)作业，该作业根据时间表运行。配置Glue作业来处理CSV文件并将处理后的数据存储在Amazon Redshift中。",
      "B": "开发一个在亚马逊EC2实例上运行的询问器脚本来转换CSV文件。在一个时间表上调用该脚本以在亚马逊S3中存储输出文件。",
      "C": "创建一个AWS Lambda函数和一个Amazon SQS。使用SQS事件调用Lambda函数。配置Lambda函数来执行提取、转换和加载CSV文件作业并将处理后的数据存储在DynamoDB表中。",
      "D": "利用Amazon EMR来启动一个Amazon EMR集群每周的时间表。配置EMR集群来执行提取、转换和加载CSV文件作业并将处理后的数据存储在Amazon Redshift表中。"
    },
    "vote_percentage": "97%",
    "tags": [
      "ETL",
      "Glue",
      "Redshift",
      "Athena"
    ],
    "explanation": {
      "analysis": "考查ETL流程的设计和AWS Glue的使用。",
      "why_correct": "AWS Glue是专门为ETL设计的服务，可以方便地处理数据转换，并与Redshift集成。定期运行作业可以满足数据更新的需求。",
      "why_wrong": "B选项需要手动编写脚本，运维成本高。C选项将数据存储在DynamoDB中，不适合复杂SQL查询。D选项使用EMR，对于简单的ETL任务，过于复杂。"
    },
    "related_terms": [
      "S3",
      "AWS Glue",
      "ETL",
      "CSV",
      "Redshift",
      "Athena",
      "EC2",
      "Lambda",
      "SQS",
      "DynamoDB",
      "EMR"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 318,
    "topic": "",
    "question_cn": "最近一家公司将其整个IT环境迁移到了AWS云。该公司发现用户正在提供超大型亚马逊EC2实例，并在不使用适当的更改控制流程的情况下修改安全组规则。解决方案架构师必须设计一个战略来跟踪和审计这些库存和配置的变化。解决方案架构师应该采取哪些行动来满足这些需求？（选二）",
    "options_cn": {
      "A": "启用AWS CloudTrail并将其用于审计。",
      "B": "对亚马逊EC2实例使用数据生命周期策略。",
      "C": "启用AWS Trusted Advisor并引用安全仪表板。",
      "D": "启用AWS Config并创建用于审计和合规目的的规则。",
      "E": "用CloudFormation模板恢复以前的资源配置。"
    },
    "vote_percentage": "94%",
    "tags": [
      "CloudTrail",
      "AWS Config"
    ],
    "explanation": {
      "analysis": "考察使用 CloudTrail 和 AWS Config 进行审计和合规性管理。",
      "why_correct": "A: CloudTrail可以记录对 AWS 账户的 API 调用，实现审计跟踪。D: AWS Config可以记录资源的配置变化，并评估合规性。",
      "why_wrong": "B: 数据生命周期策略用于管理S3对象的生命周期，与审计无关。C: Trusted Advisor主要提供成本优化、安全性等方面的建议，不直接用于跟踪配置变化。E: CloudFormation 模板用于资源部署，无法记录已经发生的配置更改。"
    },
    "related_terms": [
      "EC2",
      "CloudTrail",
      "AWS Config",
      "AWS Trusted Advisor",
      "CloudFormation",
      "安全组"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 319,
    "topic": "",
    "question_cn": "一家公司拥有数百个亚马逊 EC2 基于 Linux 的实例。系统管理员已经使用共享 SSH 键来管理这些实例。在最近的一次审计之后，公司的安全团队授权删除所有共享密钥。解决方案架构师必须设计一个解决方案来提供对实例的安全访问。用最少的管理费用来满足这个需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS EC2 系统管理器会话管理器连接到实例。",
      "B": "使用 AWS STS (STS) 生成一次性 SSH 密钥的需求。",
      "C": "使用 SSH 允许共享 SSH 访问一组堡垒实例。配置所有其他实例只允许从堡垒实例访问。",
      "D": "使用亚马逊自定义授权人身份验证用户。调用一个 Lambda 函数来生成一个临时 SSH 密钥。"
    },
    "vote_percentage": "83%",
    "tags": [
      "EC2 Instance Access",
      "Session Manager"
    ],
    "explanation": {
      "analysis": "此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用Systems Manager Session Manager提供安全的实例访问，无需维护SSH密钥或堡垒主机。使用AWS Systems Manager可以简化访问和管理。",
      "why_correct": "AWS Systems Manager Session Manager提供了一种安全且无需密钥的 SSH 访问 EC2 实例的方式。它简化了访问，减少了维护成本和安全风险。",
      "why_wrong": "选项B涉及到使用STS生成一次性密钥，增加了复杂性。选项C涉及堡垒机，增加了管理负担。选项D涉及Lambda函数和自定义授权，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "SSH",
      "AWS EC2 系统管理器会话管理器",
      "STS",
      "堡垒实例",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 320,
    "topic": "",
    "question_cn": "一家公司正在使用亚马逊EC2实例来获取来自内部数据源的数据。数据采用JSON格式，摄入率可能高达1MB/s。当重新启动EC2实例时，飞行中的数据将丢失。该公司的数据科学团队希望以接近实时的方式查询所吸收的数据。哪个解决方案提供了可伸缩且数据损失最小的近实时数据查询？",
    "options_cn": {
      "A": "发布数据到Amazon Kinesis Data Streams，使用Kinesis Data Analytics查询数据。",
      "B": "发布数据以Amazon Redshift为目的地，使用Amazon Kinesis Data Firehose。使用Amazon Redshift查询数据。",
      "C": "将数据存储在EC2实例存储中。以Amazon S3为目的地发布数据到Amazon Kinesis Data Firehose。使用Amazon Athena查询数据。",
      "D": "将数据存储在Amazon EBS卷中。为Redis发布数据到Amazon EC2。订阅Redis通道来查询数据。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Kinesis Data Streams",
      "Kinesis Data Analytics"
    ],
    "explanation": {
      "analysis": "考察使用 Kinesis Data Streams 及其相关服务实现近实时数据摄取和查询。",
      "why_correct": "A: Kinesis Data Streams可以处理高吞吐量的数据流，Kinesis Data Analytics可以近实时查询数据，满足需求。",
      "why_wrong": "B: Kinesis Data Firehose用于将数据加载到Redshift，并非用于实时查询。C: 将数据存储在EC2实例存储中，会因实例重启而丢失数据。D: Redis 适用于缓存，不适合大规模数据查询，并且会因实例重启而丢失数据。"
    },
    "related_terms": [
      "EC2",
      "JSON",
      "Kinesis Data Streams",
      "Kinesis Data Analytics",
      "Kinesis Data Firehose",
      "S3",
      "Athena",
      "EBS",
      "Redis"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 321,
    "topic": "",
    "question_cn": "解决方案架构师应该如何确保上传到亚马逊S3桶中的所有对象都是加密的？",
    "options_cn": {
      "A": "更新S3桶策略以否认如果没有一个S3:x-amz-acl头集。",
      "B": "更新S3桶策略以拒绝如果计划中没有S3:x-amz-acl头设置为私有。",
      "C": "更新AWS桶策略以否认如果没有一个安全传输头设置为真实。",
      "D": "更新桶策略以否认如果没有一个服务器端加密头集。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "S3 Bucket Policy"
    ],
    "explanation": {
      "analysis": "考察通过 S3 桶策略强制加密上传对象。",
      "why_correct": "D: 通过桶策略，可以拒绝没有服务器端加密头 (x-amz-server-side-encryption) 的上传请求，从而强制所有对象加密。",
      "why_wrong": "A/B: S3:x-amz-acl控制的是对象的访问控制列表 (ACL)，与加密无关。C:  安全传输头（例如，TLS）控制的是传输过程的加密，而不是对象本身的加密。"
    },
    "related_terms": [
      "S3",
      "S3桶策略",
      "S3:x-amz-acl",
      "服务器端加密"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 322,
    "topic": "",
    "question_cn": "解决方案架构师正在为一家公司设计一个多层应用程序。应用程序的用户从移动设备上传图像。应用程序生成每个图像的缩略图，并将消息返回给用户以确认图像成功上传。缩略图生成可能需要60秒，但该公司希望为用户提供更快的响应时间以通知他们原始图像已经收到。解决方案架构师必须设计应用程序将请求异步地发送到不同的应用程序层。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "编写一个自定义的AWS Lambda函数来生成缩略图并提醒用户。使用图像上传过程作为事件源调用Lambda函数。",
      "B": "创建一个AWS Step Functions工作流。配置Step Functions来处理应用程序层之间的业务流程并在缩略图生成完成时提醒用户。",
      "C": "创建一个Amazon SQS消息队列。在上传图像时将消息放置在SQS队列上以便进行缩略图生成。通过应用程序消息提醒用户图像已经收到。",
      "D": "创建Amazon SNS通知主题和订阅。使用一个订阅与应用程序在图像上传完成后生成缩略图。在缩略图生成完成后通过推送通知的方式使用第二个订阅来传递用户的移动应用程序。"
    },
    "vote_percentage": "93%",
    "tags": [
      "SQS",
      "Asynchronous Processing"
    ],
    "explanation": {
      "analysis": "考察使用SQS实现异步处理以提高用户体验。",
      "why_correct": "C:  使用SQS队列，用户上传图像后，将消息放入队列，立即返回响应。后台Lambda函数从队列中获取消息生成缩略图，实现异步处理，用户体验好。",
      "why_wrong": "A: 虽然可以使用Lambda和事件源，但会增加用户等待的时间，不符合快速响应的要求。B: Step Functions适合编排复杂的流程，对于缩略图生成过于复杂。D: SNS适用于发布通知，不适合用于任务处理。"
    },
    "related_terms": [
      "AWS Lambda",
      "Step Functions",
      "Amazon SQS",
      "Amazon SNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 323,
    "topic": "",
    "question_cn": "一个公司的设施在整个大楼的每个入口都有徽章阅读器。当徽章被扫描时，读者通过HTTPS发送信息表明是谁试图进入该特定入口。解决方案架构师必须设计一个系统来处理来自传感器的这些消息。解决方案必须是高度可用的，结果必须提供给公司的安全小组分析。解决方案架构师应该推荐哪种系统架构？",
    "options_cn": {
      "A": "启动一个亚马逊EC2实例作为HTTPS端点并处理消息。配置EC2实例将结果保存到一个亚马逊S3桶。",
      "B": "在Amazon API Gateway中创建一个HTTPS端点。将API Gateway端点配置为调用Lambda函数以处理消息并将结果保存到Amazon DynamoDB表。",
      "C": "使用Amazon Route 53将接收到的传感器消息直接传递到一个AWS Lambda函数。配置Lambda函数来处理消息并将结果保存到Amazon DynamoDB表。",
      "D": "为Amazon VPC创建网关S3端点。从设备网络到VPC配置一个站点到站点的VPN连接，这样传感器数据就可以通过S3端点直接写入S3桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Lambda",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "考察如何使用AWS服务构建高可用、可扩展的系统来处理传入的HTTPS请求。",
      "why_correct": "B: API Gateway提供高可用性和可伸缩性，Lambda函数处理消息，DynamoDB存储数据，架构满足需求。",
      "why_wrong": "A:  EC2实例单点故障，可用性低。C: Route 53主要用于DNS解析，不适合直接接收HTTPS消息。D:  通过VPN和S3端点直接写入S3桶，无法处理消息，并且不便于安全小组分析。"
    },
    "related_terms": [
      "EC2",
      "HTTPS",
      "S3",
      "Amazon API Gateway",
      "Lambda",
      "DynamoDB",
      "Route 53",
      "VPC",
      "S3 端点",
      "VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 324,
    "topic": "",
    "question_cn": "一家公司希望为其主要的内部文件存储量实施一个灾难恢复计划。文件存储卷由本地存储服务器上的 ISCSI 设备安装。文件存储量存储数百兆字节的数据。该公司希望确保最终用户能够在不经历延迟的情况下保留对来自内部系统的所有文件类型的即时访问。哪种解决方案能满足这些要求而公司现有的基础设施变化最少？",
    "options_cn": {
      "A": "提供一个亚马逊文件网关作为一个虚拟机 (VM) 托管在现场。将本地缓存设置为 10 GB。修改现有应用程序通过 NFS 协议访问文件。为了从灾难中恢复过来提供一个亚马逊 EC2实例并安装包含文件的 S3 桶。",
      "B": "提供一个 AWS 存储网关磁带网关。使用数据备份解决方案将所有现有数据备份到虚拟磁带库。在初始备份完成后配置数据备份解决方案每晚运行。为了从灾难中恢复过来提供一个亚马逊 EC2实例并将数据从虚拟磁带库中的卷中还原到亚马逊 EBS 卷中。",
      "C": "提供一个 AWS 存储网关卷网关缓存卷，将本地缓存设置为 10 GB。使用 ISCSI 将卷网关缓存的卷安装到现有的文件服务器并将所有文件复制到存储卷。配置存储卷的预定快照。为了从灾难中恢复过来将快照还原到亚马逊 EBS 卷并将 EBS 卷附加到亚马逊 EC2 实例。",
      "D": "提供一个 AWS 存储网关卷网关存储卷与现有文件存储卷相同的磁盘空间。使用 ISCSI 将卷网关存储的卷安装到现有的文件服务器并将所有文件复制到存储卷。配置存储卷的预定快照。为了从灾难中恢复过来将快照还原到亚马逊 EBS 卷并将 EBS 卷附加到亚马逊 EC2 实例。"
    },
    "vote_percentage": "77%",
    "tags": [
      "Storage Gateway",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是提供了一个基于卷网关的解决方案，最符合题干中“现有基础设施变化最少”的要求。通过快照进行灾难恢复是可行的方法。",
      "why_correct": "选项D使用卷网关存储卷，与现有文件存储卷相同磁盘空间，并使用ISCSI，减少了对现有基础设施的更改。快照能够实现灾难恢复，且具有操作简单和恢复速度快的优势。",
      "why_wrong": "选项A涉及NFS协议，需要修改现有应用程序，不符合题意。选项B涉及磁带网关，恢复时间长，不满足“即时访问”要求。选项C中的缓存卷不如存储卷符合“变化最少”的要求。"
    },
    "related_terms": [
      "亚马逊文件网关",
      "NFS",
      "EC2",
      "S3",
      "AWS 存储网关",
      "虚拟磁带库",
      "EBS",
      "存储网关卷网关",
      "快照",
      "iSCSI"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 325,
    "topic": "",
    "question_cn": "一家公司正在托管一个来自亚马逊S3桶的网络应用程序。应用程序使用亚马逊Cognito作为身份提供者来认证用户并返回一个JSON Web Token (JWT)，该令牌提供对存储在另一个S3桶中的受保护资源的访问。在部署应用程序时，用户报告错误，无法访问受保护的内容。解决方案架构师必须通过提供适当的权限来解决这个问题，以便用户能够访问受保护的内容。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "更新亚马逊IAM角色以承担适当的IAM角色访问受保护的内容。",
      "B": "更新S3 ACL，允许应用程序访问受保护的内容。",
      "C": "将应用程序重新部署到Amazon S3以防止S3桶中最终一致的读取影响用户访问受保护内容的能力。",
      "D": "更新亚马逊Cognito池，使用身份池中的自定义属性映射并授予用户访问受保护内容的适当权限。"
    },
    "vote_percentage": "93%",
    "tags": [
      "IAM Role",
      "S3 Access"
    ],
    "explanation": {
      "analysis": "考查如何通过IAM角色实现对S3资源的访问控制。",
      "why_correct": "A:  通过更新IAM角色，应用程序可以代入具有访问另一个S3桶的权限的角色，从而允许用户访问受保护的资源。这是最安全和推荐的方法。",
      "why_wrong": "B: 修改S3 ACL，直接开放访问权限，不安全。C: 最终一致性读取的问题，与用户访问权限无关。D: Cognito池主要用于用户身份验证和授权，而不是控制对S3资源的访问。"
    },
    "related_terms": [
      "S3",
      "Cognito",
      "JWT",
      "IAM",
      "S3 ACL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 326,
    "topic": "",
    "question_cn": "一家图片托管公司将其巨额资产上传到亚马逊S3标准桶。该公司使用S3 API进行多部分并行上传，并在同一对象再次上传时覆盖。在上传后的30天内，将经常访问这些物品。30天后，对象的使用频率将降低，但每个对象的访问模式将不一致。公司必须优化存储成本，同时保持高可用性和存储资产的弹性。解决方案架构师应该推荐哪些操作组合来满足这些需求？（选二）",
    "options_cn": {
      "A": "30天后将资产转移到S3智能分层。",
      "B": "配置一个S3生命周期策略来清理不完整的多部分上传。",
      "C": "配置一个S3生命周期策略来清理过期的对象删除标记。",
      "D": "30天后将资产移至S3标准-不经常访问（S3-IA）。",
      "E": "30天后将资产移到S3不常访问的区域区域（S3-1Z）。"
    },
    "vote_percentage": "60%",
    "tags": [
      "S3 Lifecycle Policy",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "考查S3存储类别和生命周期策略的应用，以优化存储成本。",
      "why_correct": "A: S3智能分层会自动将对象移动到访问频率较低的存储层。B: 清理不完整的多部分上传可以节省存储空间。",
      "why_wrong": "C: 清理过期删除标记，与本题不相关。D: 标准-IA访问频率低，但对于不一致访问模式，成本并不一定低于智能分层。 E: S3单区不常访问(S3-1Z) 仅适用于单个可用区中的对象，不提供冗余，可能不符合弹性要求。"
    },
    "related_terms": [
      "S3",
      "S3标准",
      "多部分上传",
      "S3智能分层",
      "S3生命周期策略",
      "S3-IA",
      "S3-1Z"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 327,
    "topic": "",
    "question_cn": "解决方案架构师必须确保一个包含亚马逊EC2实例的VPC网络。EC2实例包含高度敏感的数据并在私有子网中运行。根据公司政策，在VPC中运行的EC2实例只能访问互联网上已批准的第三方软件存储库，用于使用第三方的软件产品更新。其他互联网流量必须被阻止。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "更新专用子网的路由表，将出站流量路由到网络防火墙。配置域列表规则组。",
      "B": "建立一个AWS WAF网络。创建自定义的一组规则根据源和目标IP地址范围集过滤流量请求。",
      "C": "执行严格的入站安全组规则。配置一个出站规则，通过指定URL，只允许流量进入互联网上授权的软件存储库。",
      "D": "在EC2实例前配置应用程序负载均衡器（ALB）。引导所有的出境交通到ALB。在ALB的目标群体中使用基于URL的规则监听器进行出站访问互联网。"
    },
    "vote_percentage": "89%",
    "tags": [
      "VPC",
      "Network Firewall"
    ],
    "explanation": {
      "analysis": "考察如何使用网络防火墙和路由表来控制 EC2 实例的出站流量。",
      "why_correct": "A:  通过将出站流量路由到网络防火墙，可以根据域列表等规则控制访问，只允许访问授权的软件存储库，其他流量被阻止，满足需求。",
      "why_wrong": "B: WAF用于保护Web应用程序，而非控制 EC2 实例的出站流量。C:  安全组无法基于URL进行出站流量控制。D: ALB主要用于负载均衡，无法直接实现基于URL的出站流量控制。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "互联网",
      "安全组",
      "网络防火墙",
      "AWS WAF",
      "ALB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 328,
    "topic": "",
    "question_cn": "一家公司在AWS云中托管一个三层电子商务应用程序。该公司在亚马逊S3上拥有网站，并将网站与处理销售请求的API集成在一起。该API包括静态和动态的前端内容以及异步处理销售请求的后端工作人员。该公司预计在推出新产品的活动期间，销售请求的数量将大幅和突然增加。解决方案架构师应该建议什么来确保所有的请求都被成功地处理？",
    "options_cn": {
      "A": "添加一个亚马逊CloudFront动态内容。增加EC2实例的数量以处理流量的增加。",
      "B": "为静态内容添加亚马逊CloudFront。将EC2实例放在一个自动缩放组中以基于网络流量启动新实例。",
      "C": "为API添加一个亚马逊CloudFront动态内容。在ALB前面添加一个亚马逊弹性计算机实例以减少要处理的流量。",
      "D": "为静态内容添加亚马逊CloudFront。添加一个亚马逊简单队列服务队列接收来自网站的请求，然后由EC2实例进行处理。"
    },
    "vote_percentage": "69%",
    "tags": [
      "CloudFront",
      "SQS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考察如何使用 CloudFront、SQS 和 Auto Scaling 来处理流量高峰。",
      "why_correct": "D:  使用CloudFront缓存静态内容，减轻负载。使用SQS队列异步处理销售请求，缓解瞬时流量峰值。后端EC2实例使用Auto Scaling组可以自动扩展，以处理增加的请求。",
      "why_wrong": "A:  没有利用Auto Scaling。B:  没有使用SQS异步处理请求，在高流量情况下，可能导致请求失败。C: 在ALB前面增加EC2实例，没有实际的意义。"
    },
    "related_terms": [
      "CloudFront",
      "EC2",
      "ALB",
      "弹性计算机实例",
      "SQS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 329,
    "topic": "",
    "question_cn": "一项安全审计显示亚马逊EC2实例没有被定期修复。解决方案架构师需要提供一个解决方案，该解决方案将在大量EC2实例中运行常规安全扫描。解决方案还应该按正常时间表对EC2实例进行补丁，并提供每个实例的补丁状态报告。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "建立亚马逊Macie扫描EC2实例的软件漏洞。在每个EC2实例上设置一个CRON作业，以便在一个正常的时间表上修补该实例。",
      "B": "在帐户中打开亚马逊的保护表。配置保护责任扫描EC2实例以检查软件的漏洞。建立系统管理器会话管理器按正常时间表对EC2实例补丁。",
      "C": "建立亚马逊侦探扫描EC2实例的软件漏洞。建立一个亚马逊事件桥计划规则以在一个正常的时间表上修补EC2实例。",
      "D": "打开帐户里的亚马逊Inspector。配置亚马逊Inspector扫描EC2实例以检查软件的漏洞。建立系统管理程序补丁管理器按正常时间表对EC2实例进行补丁。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Inspector",
      "Systems Manager Patch Manager"
    ],
    "explanation": {
      "analysis": "考察使用AWS Inspector和Systems Manager Patch Manager进行安全扫描和补丁管理。",
      "why_correct": "D: 使用Amazon Inspector进行漏洞扫描，使用Systems Manager Patch Manager进行补丁管理，可以满足安全扫描、补丁和状态报告的需求。",
      "why_wrong": "A: Macie用于数据安全，而非漏洞扫描。手动配置Cron作业难以维护。B: 保护表功能与此题不相关。C: Amazon Detective 用于安全调查，而非漏洞扫描和补丁管理。"
    },
    "related_terms": [
      "EC2",
      "亚马逊Macie",
      "CRON",
      "保护责任",
      "亚马逊Inspector",
      "亚马逊事件桥",
      "系统管理器会话管理器",
      "系统管理程序补丁管理器",
      "亚马逊侦探",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 330,
    "topic": "",
    "question_cn": "一家公司计划在亚马逊 RDS 数据库中存储数据。公司必须加密数据。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "在 AWS KMS 密钥管理服务中创建一个密钥。启用数据库实例的加密。",
      "B": "创建一个加密密钥。把钥匙放在AWS秘密管理器里。使用密钥加密数据库实例。",
      "C": "在 AWS 证书管理器 (ACM) 中生成 SSL/TLS 证书。通过使用证书在数据库实例上启用 SSL/TLS。",
      "D": "生成一个在 AWS 身份和访问管理 (IAM) 中的证书。通过使用证书在数据库实例上启用 SSL/TLS。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用KMS密钥直接对RDS数据库实例进行加密，这是AWS推荐的加密实践。选项C涉及SSL/TLS证书，主要用于保护客户端与数据库之间的连接，而并非数据库本身的静态数据加密。",
      "why_correct": "使用AWS KMS创建密钥并启用数据库实例的加密，可以对RDS数据库中的静态数据进行加密，满足需求。",
      "why_wrong": "选项B使用了AWS Secrets Manager，但它主要用于存储密钥和敏感信息，而不是直接用于加密数据库。选项C和D涉及SSL/TLS证书，用于加密客户端与数据库之间的连接，而不是数据库本身的加密。"
    },
    "related_terms": [
      "RDS",
      "加密",
      "AWS KMS",
      "密钥管理服务",
      "AWS 秘密管理器",
      "SSL/TLS",
      "AWS 证书管理器",
      "ACM",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 331,
    "topic": "",
    "question_cn": "一家公司必须在7天内将20TB的数据从数据中心迁移到AWS云。该公司的网络带宽限制在15Mbps，不能超过70%的利用率。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用AWS Snowball。",
      "B": "使用AWS 信息系统数据库。",
      "C": "使用VPN使用安全的连接。",
      "D": "使用S3 传输加速度。"
    },
    "vote_percentage": "91%",
    "tags": [
      "Snowball",
      "Data Migration"
    ],
    "explanation": {
      "analysis": "考察数据迁移方案的选择，考虑带宽限制和时限。",
      "why_correct": "Snowball是专门为大规模数据迁移设计的物理设备，可以离线传输数据，绕过带宽限制，满足时限要求。",
      "why_wrong": "VPN连接带宽受限，无法满足需求；S3 Transfer Acceleration 主要用于加速S3上传下载，不适用于大规模数据中心迁移；其他选项与数据迁移无关。"
    },
    "related_terms": [
      "20TB",
      "Snowball",
      "15Mbps",
      "S3 Transfer Acceleration"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 332,
    "topic": "",
    "question_cn": "公司需要向员工提供保密和敏感文件的安全访问权。该公司希望确保文件只能由授权用户访问。文件必须安全地下载到员工的设备上。这些文件存储在内部的Windows文件服务器中。然而由于远程使用的增加，文件服务器的容量正在耗尽。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将文件服务器迁移到公共子网中的Amazon EC2实例。配置安全组以限制入站流量到员工的IP地址。",
      "B": "将文件迁移到一个用于Windows FSx文件服务器文件系统的Amazon FSx。将Amazon FSx文件系统与现场活动目录集成。配置客户VPN端。",
      "C": "将文件迁移到Amazon S3并创建一个私有的VPC端点。创建一个签名的网址允许下载。",
      "D": "将文件迁移到Amazon S3并创建一个公共的供应商端点。允许员工与AWS IAM 身份中心（AWS SSO）登录。"
    },
    "vote_percentage": "95%",
    "tags": [
      "File Server",
      "Security",
      "FSx"
    ],
    "explanation": {
      "analysis": "考察文件共享的安全性、可用性以及与现有AD的集成。",
      "why_correct": "Amazon FSx for Windows File Server 提供了与 Windows Server 和 Active Directory的无缝集成，满足了安全性、容量和访问控制的需求，并支持VPN连接。",
      "why_wrong": "EC2实例方案需要自己维护文件服务器和安全组，工作量大，安全性也更复杂。S3方案需要额外处理身份验证和访问控制。D选项开放了公共访问，存在安全风险。"
    },
    "related_terms": [
      "EC2",
      "Windows FSx",
      "活动目录",
      "VPC",
      "S3",
      "IAM 身份中心",
      "AWS SSO",
      "SFTP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 333,
    "topic": "",
    "question_cn": "一个公司的应用程序运行在Amazon EC2实例后面的应用负载均衡器（ALB）。这些实例在Amazon Auto Scaling组中跨多个可用性区域运行。应用程序的CPU利用率在每个月的第一天午夜当月末财务计算批运行时达到100%，从而扰乱应用程序。解决方案架构师应该建议什么来确保应用程序能够处理工作量并避免停机？",
    "options_cn": {
      "A": "配置一个Amazon CloudFront分布在之前运行。",
      "B": "配置基于EC2 CPU利用率的Auto Scaling简单缩放策略。",
      "C": "根据每月计划配置EC2 Auto Scaling计划缩放策略。",
      "D": "配置Amazon EC2可伸缩性从实例中移除一些工作负载。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "考察Auto Scaling的配置，需要根据特定时间段的负载变化进行弹性伸缩。",
      "why_correct": "Scheduled Scaling可以根据预定的时间点和容量调整实例数量，完美匹配每月批处理任务的执行时间。",
      "why_wrong": "Simple Scaling策略基于CPU利用率，响应不及时，可能在应用程序负载过高时才启动缩放。CloudFront主要用于内容分发，与解决应用程序负载问题无关。从实例中移除负载无法解决问题。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "Auto Scaling",
      "CloudFront",
      "EC2 CPU利用率",
      "Auto Scaling"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 334,
    "topic": "",
    "question_cn": "一家公司希望让客户能够使用微软的活动目录来下载存储在亚马逊 S3 中的文件。客户的应用程序使用 SFTP 客户端下载文件。哪个解决方案可以用最少的操作开销来满足这些需求并且客户的应用程序不会有任何更改？",
    "options_cn": {
      "A": "为亚马逊 S3 公司建立 AWS Transfer Family。配置集成活动目录身份验证。",
      "B": "建立 AWS 数据库迁移服务 (AWS DMS) 以同步内部客户机和亚马逊 S3。配置集成活动目录身份验证。",
      "C": "通过使用 AWS 标识中心单点登录建立 AWS 数据监视器以同步酒店内的位置和 S3 位置。",
      "D": "用 SFTP 设置一个 Windows EC2 亚马逊实例将内部客户端与亚马逊 S3 连接起来。集成了 IAM。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "SFTP",
      "Active Directory"
    ],
    "explanation": {
      "analysis": "此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用AWS Transfer Family，无需修改客户端应用程序，并能够集成活动目录进行身份验证，满足了题目需求且操作开销最小。",
      "why_correct": "AWS Transfer Family 提供了对 S3 的 SFTP 支持，可以直接与活动目录集成，无需更改客户端配置。",
      "why_wrong": "选项B涉及DMS，通常用于数据库迁移，与文件下载场景不符。选项C涉及的数据监视器与题意不符。选项D 需要设置 EC2 实例，增加了管理成本。"
    },
    "related_terms": [
      "活动目录",
      "S3",
      "AWS Transfer Family",
      "AWS DMS",
      "AWS 标识中心",
      "IAM",
      "SFTP",
      "Windows EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 335,
    "topic": "",
    "question_cn": "一家公司正经历着需求的突然增长。该公司需要提供大型亚马逊 EC2 实例从一个亚马逊机器形象。实例将在一个自动缩放组中运行。公司需要一个提供最小初始化延迟的解决方案来满足需求。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS EC2 寄存器图像命令可以从快照创建一个 AMI。在自动缩放组中使用步骤函数来替换 AMI。",
      "B": "启用亚马逊 EBS 亚马逊弹性块存储 (EBS) 快速快照恢复快照。通过使用快照提供一个 AMI。将自动缩放组中的 AMI 替换为新的 AMI。",
      "C": "在亚马逊数据生命周期管理器 (DLM) 中创建并定义生命周期规则。在自动缩放组中创建一个 Lambda 函数，该函数将修改该参数。",
      "D": "使用亚马逊文文特布里奇调用提供的备份生命周期策略。将自动缩放组的容量限制配置为 DLM 中的事件源。"
    },
    "vote_percentage": "91%",
    "tags": [
      "EC2 Auto Scaling",
      "AMI",
      "EBS Fast Snapshot Restore"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是使用EBS快速快照恢复（FSR），它可以极大地缩短 AMI 启动时间，减少初始化延迟，从而满足了需求。",
      "why_correct": "启用 EBS 快速快照恢复可以加速从快照创建 AMI 的过程，显著缩短实例启动时间。使用快照来提供 AMI 也是一个有效的方法。",
      "why_wrong": "选项A涉及到使用步骤函数替换 AMI，增加了复杂性，不如直接使用FSR。选项C和D涉及DLM，它主要用于备份和管理，而并非用来解决快速启动实例的需求。"
    },
    "related_terms": [
      "EC2",
      "AMI",
      "Auto Scaling",
      "EBS",
      "EBS 快照",
      "DLM",
      "Lambda",
      "文特布里奇",
      "容量限制"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 336,
    "topic": "",
    "question_cn": "一家公司拥有一个多层Web应用程序，该应用程序使用Amazon Aurora集群进行存储。应用程序层被托管在Amazon EC2实例上。该公司的信息技术安全准则规定数据库凭证每14天加密一次并进行轮换。解决方案架构师应该如何用最少的工作来满足这个需求？",
    "options_cn": {
      "A": "创建一个新的AWS Key Management Service（AWS KMS）加密密钥。使用Secrets Manager创建一个新的秘密，它使用带有适当凭证的KMS密钥。将秘密与Aurora数据库集群联系起来。设置一个14天的自定义轮换周期。",
      "B": "在AWS Systems Manager Parameter Store中创建两个参数：一个用于作为字符串参数的用户名，另一个用于密码的安全字符串类型。为密码参数选择AWS Key Management Service（AWS KMS）加密并在应用程序层中加载这些参数。实现每14天旋转一次密码的Lambda函数。",
      "C": "存储一个在AWS Key Management Service（AWS KMS）加密的Amazon Elastic File System（EFS） Amazon EFS 文件系统中包含证书的文件。在应用程序层的所有EC2实例中安装EFS文件系统。限制对文件系统中文件的访问以便应用程序能够读取文件并且只有超级用户才能修改文件。实现一个Lambda函数，它每14天在Aurora旋转一次键并在文件中写入新的凭证。",
      "D": "存储一个文件，其中包含在AWS Key Management Service（AWS KMS）加密的Amazon S3桶中的凭证，应用程序使用它来加载凭证。定期将文件下载到应用程序中以确保使用正确的凭证。实现一个Lambda功能，该功能每14天旋转Aurora凭证并将这些凭证上传到S3桶中的文件中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "Aurora",
      "Rotation"
    ],
    "explanation": {
      "analysis": "考察数据库凭据的自动轮换，需要考虑安全性、简化程度和工作量。",
      "why_correct": "使用Secrets Manager可以自动轮换数据库凭据，并与Aurora集成，提供简单、安全、易于维护的解决方案。",
      "why_wrong": "B选项使用Parameter Store存储密码，不如Secrets Manager安全。C和D选项需要手动处理文件存储、下载和更新凭据的逻辑，复杂度和维护成本较高。"
    },
    "related_terms": [
      "Aurora",
      "EC2",
      "AWS KMS",
      "Secrets Manager",
      "Parameter Store",
      "Lambda",
      "EFS",
      "加密密钥"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 337,
    "topic": "",
    "question_cn": "一家公司已经在AWS RDS上部署了一个Web应用程序。该公司为MySQL提供了Amazon RDS后端数据库，其中包括一个主要的数据库实例和五个只读副本以支持缩放需求。只读副本必须落后于主数据库实例不超过1秒。数据库通常运行预定的存储过程。随着网站流量的增加，副本在峰值负载期间经历了额外的滞后。解决方案架构师必须尽可能减少复制延迟。解决方案架构师必须尽量减少对应用程序代码的更改并且必须尽量减少持续的操作开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到Amazon Aurora。将读取副本替换为Aurora副本并配置Aurora Auto Scaling。将存储过程替换为Aurora本地函数。",
      "B": "在数据库前为Redis集群部署一个Amazon ElastiCache。在应用程序查询数据库之前修改应用程序以检查缓存。将存储过程替换为Lambda函数。",
      "C": "将数据库迁移到在Amazon EC2实例上运行的MySQL数据库。选择大的计算优化实例。维护EC2实例上的存储过程。",
      "D": "将数据库迁移到Amazon DynamoDB。提供大量的读容量单位 (RCU)以支持所需的吞吐量并配置随需应变的容量。用DynamoDB流替换存储过程。"
    },
    "vote_percentage": "86%",
    "tags": [
      "MySQL Replication Lag",
      "Aurora"
    ],
    "explanation": {
      "analysis": "考察如何减少MySQL复制延迟，同时降低运营成本。",
      "why_correct": "Amazon Aurora 提供了更快的复制速度和更强的性能，并且易于迁移和配置Auto Scaling，最大限度减少了延迟和运维成本。",
      "why_wrong": "ElastiCache缓存方案需要修改应用代码，且无法根本解决复制延迟问题。在EC2上自建MySQL方案运维成本较高。DynamoDB是NoSQL数据库，不适用于MySQL的场景。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "只读副本",
      "Aurora",
      "ElastiCache",
      "Redis",
      "DynamoDB",
      "RCU"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 338,
    "topic": "",
    "question_cn": "解决方案架构师必须为作为服务（SaaS）平台的大容量软件创建灾难恢复计划。该平台的所有数据都存储在一个亚马逊 Aurora MySQL 集群中。AWS 博士计划必须将数据复制到一个次级的区域。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用 MySQL 二进制日志复制到次级区域的极光集群。为次级区域的极光集群提供一个数据库实例。",
      "B": "为数据库集群建立一个极光全球数据库。当安装完成后从第二区域中移除实例。",
      "C": "使用 AWS 数据库迁移服务 (AWS DMS) 持续复制数据到次级区域的极光集群。从次级区域中删除实例。",
      "D": "为数据库集群建立一个极光全球数据库。在第二区域指定至少一个 DB 实例。"
    },
    "vote_percentage": "56%",
    "tags": [
      "Aurora Global Database",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用Aurora Global Database可以实现跨区域的灾难恢复，提供较低的RTO和RPO，同时减少了管理负担。当数据库集群安装完毕后，从第二区域移除实例, 确保数据同步和灾备能力。",
      "why_correct": "Aurora Global Database 允许在不同区域之间进行快速的数据库复制，简化了灾难恢复流程，并且可以实现较低的RTO和RPO。",
      "why_wrong": "选项A涉及MySQL二进制日志复制，增加了管理负担。选项C使用DMS进行复制，虽然可行，但不如Aurora Global Database简洁高效。选项D描述了创建全球数据库，但未提及主备切换过程。"
    },
    "related_terms": [
      "SaaS",
      "Aurora MySQL",
      "Aurora",
      "MySQL",
      "极光集群",
      "AWS DMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 339,
    "topic": "",
    "question_cn": "公司有一个带有嵌入式凭证的定制应用程序可以从亚马逊 RDS MySQL 实例中检索信息。管理层说应用程序必须在最少的编程努力下变得更安全。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用 AWS KMS (AWSKMS) 密钥管理服务 创建键。配置应用程序以从 KMS 加载数据库凭据。启动自动键旋转。",
      "B": "为应用程序用户为 RDS MySQL 数据库在 AWS 上创建凭证并将凭证存储在 秘密管理器中。配置应用程序从秘密管理器加载数据库凭证。创建一个在秘密管理器中旋转凭证的 AWS Lambda 函数。",
      "C": "为应用程序用户为 RDS MySQL 数据库在 AWS 上创建凭证并将凭证存储在 秘密管理器中。配置应用程序从秘密管理器加载数据库凭证。使用秘密管理器为 RDS MySQL 数据库的应用程序用户设置全权证书轮换时间表。",
      "D": "为应用程序用户为 RDS MySQL 数据库创建 凭证并将凭证存储在 系统管理器参数存储中。将应用程序配置为从参数存储加载数据库凭据。使用参数存储为 RDS MySQL 数据库的应用程序用户设置全权证书轮换时间表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Security",
      "Secrets Manager"
    ],
    "explanation": {
      "analysis": "此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是使用AWS Secrets Manager来存储数据库凭证，并配置自动轮换功能。 这最大限度地减少了代码修改，并提高了安全性。",
      "why_correct": "使用 Secrets Manager 存储凭证，并利用其内置的凭证轮换功能，是满足安全性和最小化代码更改需求的理想选择。",
      "why_wrong": "选项A涉及使用KMS进行密钥管理，虽然增加了安全性，但并未解决凭据存储和轮换问题。选项B通过Lambda函数来实现凭证轮换，虽然可行，但比直接使用Secrets Manager的轮换功能更为复杂。选项D使用了系统管理器参数存储，其功能不如Secrets Manager强大，并且不支持自动轮换。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "AWS KMS",
      "密钥管理服务",
      "Lambda",
      "秘密管理器",
      "参数存储"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 340,
    "topic": "",
    "question_cn": "一家媒体公司在 AWS EC2 上开设网站。该网站应用程序的体系结构包括一个亚马逊 EC2 实例后面是一个应用负载平衡器 (ALB) 和一个在亚马逊 Aurora MySQL 上托管的数据库。该公司的网络安全团队报告说该应用程序很容易受到 SQL 注入的影响。公司应该如何解决这个问题？",
    "options_cn": {
      "A": "在 ALB 面前使用 AWS Web Application Firewall (WAF)。将适当的网络 ACLs 与 AWS WAF 联系起来。",
      "B": "创建 ALB 侦听器规则用固定的响应响应 SQL 注入。",
      "C": "订阅 AWS Shield Advanced 以自动阻止所有 SQL 注入尝试。",
      "D": "设置亚马逊检查员自动阻止所有 SQL 注入尝试。"
    },
    "vote_percentage": "100%",
    "tags": [
      "WAF",
      "SQL Injection"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用 AWS WAF 防御 SQL 注入攻击，是最佳实践。结合ALB和WAF可以有效保护应用程序。通过配置适当的网络ACLs，进一步增强了安全性。",
      "why_correct": "AWS WAF 是一种Web应用程序防火墙服务，可以用来防御SQL注入等常见的Web攻击。将其与 ALB 结合使用，可以保护应用程序免受攻击。",
      "why_wrong": "选项B通过创建监听器规则响应SQL注入，无法有效阻止攻击。选项C涉及AWS Shield Advanced，它主要用于DDoS防护，而非针对SQL注入。选项D使用亚马逊检查员进行安全扫描，而并非直接防御SQL注入攻击。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "Aurora MySQL",
      "SQL 注入",
      "AWS WAF",
      "网络ACLs",
      "AWS Shield Advanced",
      "亚马逊检查员"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 341,
    "topic": "",
    "question_cn": "一个公司有一个亚马逊 S3 数据湖，它受 湖组的控制。该公司希望通过将数据湖中的数据与存储在亚马逊奥罗拉数据库中的操作数据连接起来从而在亚马逊快眼网站上创建一个可视化的网站。该公司希望执行专栏级授权，这样公司的营销团队只能访问数据库 中的一个子集列。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 EMR 直接吸收数据从数据库到快速视觉香料引擎。仅包括所需列。",
      "B": "使用 AWS Glue 工作室从数据库中吸收数据到 S3 数据湖。向快视用户附加 IAM 策略以执行专栏级别的访问控制。使用亚马逊 S3 作为快视的数据源。",
      "C": "使用 AWS Glue 弹性视图为亚马逊 S3 的数据库创建一个物化视图。创建一个 S3 桶策略为快速视觉用户执行专栏级访问控制。使用 S3 亚马逊作为快视的数据源。",
      "D": "使用湖泊形成蓝图来吸收从数据库到 S3 数据湖的数据。使用湖泊形成强制执行快眼用户的专栏级访问控制。使用亚马逊 Athena作为数据源的快视。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lake Formation",
      "Column-level Authorization"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是使用Lake Formation蓝图和Athena结合，能够以最小的操作开销实现数据湖的专栏级授权和可视化。Lake Formation可以简化数据湖的构建， Athena用于查询和分析数据，并连接到快视。",
      "why_correct": "Lake Formation 蓝图简化了从数据库到数据湖的数据摄取流程。Athena 提供了一种查询和分析数据的便捷方式，而快视则可以用于数据的可视化。结合使用这三个服务，可以以最小的开销实现列级别的访问控制。",
      "why_wrong": "选项A使用EMR，虽然可以实现数据处理，但没有涉及专栏级授权。选项B通过Glue工作室和IAM策略，也涉及了数据湖的建设和权限控制，但是不如使用 Lake Formation 蓝图高效。选项C涉及Glue弹性视图和S3桶策略，不如利用 Lake Formation方便。"
    },
    "related_terms": [
      "S3",
      "Amazon Aurora",
      "Amazon QuickSight",
      "IAM",
      "AWS Glue",
      "S3",
      "Athena"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 342,
    "topic": "",
    "question_cn": "一个事务处理公司每周都有在Amazon EC2实例上运行的脚本批处理作业。EC2实例在一个自动缩放组中。事务的数量可能会有所不同，但每次运行中记录的基本CPU利用率至少是60%。公司需要在工作开始前30分钟提供生产能力，目前工程师通过手动修改自动缩放组参数来完成这项任务。该公司没有资源分析所需的能力趋势以自动缩放组计数。该公司需要一种自动化的方式来修改自动缩放组的预期容量。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为自动缩放组创建动态缩放策略。根据CPU利用率度量将策略配置为规模。将公制的目标值设置为60%。",
      "B": "为自动缩放组创建一个预定的缩放策略。设定适当的所需能力、最小能力和最大能力，每周一次。将启动时间设置为批处理作业运行前30分钟。",
      "C": "为自动缩放组创建预测缩放策略。根据预测将策略配置为规模。将尺度度量设置为CPU利用率。将公制的目标值设置为60%。在策略中设置实例提前30分钟启动工作运行。",
      "D": "当自动缩放组的CPU利用率度量值达到60%时，创建一个Amazon EventBridge事件以调用Lambda函数。配置Lambda功能将自动缩放组的期望容量和最大容量提高20%。"
    },
    "vote_percentage": "63%",
    "tags": [
      "Auto Scaling",
      "Predictive Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "考察Auto Scaling策略的选择，考虑预定的启动时间以及利用率的变化。",
      "why_correct": "使用预测性缩放策略可以根据预测结果提前调整EC2实例的数量，满足预定的启动时间要求。",
      "why_wrong": "动态缩放策略基于CPU利用率，无法满足预定的启动时间要求。预定缩放策略只能每周配置一次。Lambda函数方式需要自己编写逻辑。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "CPU",
      "自动缩放组",
      "Amazon EventBridge",
      "Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 343,
    "topic": "",
    "question_cn": "解决方案架构师正在设计公司的灾难恢复架构。该公司有一个 MySQL 数据库，该数据库运行在一个具有预定备份的私有子网中的亚马逊 EC2 实例上。该设计需要包括多个区域。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将 MySQL EC2 数据库迁移到多个 EC2 实例。在区域中配置一个备用 EC2 实例。打开复制。",
      "B": "将 MySQL RDS 数据库迁移到亚马逊 RDS。使用多 AZ 部署。打开不同可用性区域中的主数据库实例的读复制。",
      "C": "将 MySQL DMS 数据库迁移到亚马逊 Aurora 全球数据库。在主区域中托管主数据库集群。将二级数据库集群置于区域。",
      "D": "在为跨区域复制配置的亚马逊 S3 桶中存储 MySQL 数据库的预定备份。使用数据备份来恢复数据库中的区域。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Disaster Recovery",
      "MySQL",
      "Aurora Global Database"
    ],
    "explanation": {
      "analysis": "此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是使用Aurora Global Database，可以提供跨区域的灾难恢复能力，且能够实现较低的RTO和RPO，相比多AZ和备份恢复，减少了操作开销。",
      "why_correct": "Aurora Global Database 提供了跨区域的灾难恢复能力，可以快速地将数据库复制到其他区域，并实现快速故障转移，最大限度地减少了停机时间。",
      "why_wrong": "选项A和B涉及多AZ和读复制，虽然可以提高可用性，但无法提供跨区域的灾难恢复。选项D仅通过S3备份进行恢复，恢复时间较长，RTO较高，不符合最少操作开销的标准。"
    },
    "related_terms": [
      "MySQL",
      "EC2",
      "RDS",
      "Multi-AZ",
      "Aurora Global Database",
      "S3",
      "DMS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 344,
    "topic": "",
    "question_cn": "一个公司有一个Java应用程序，它使用Amazon Simple Queue Service (Amazon SQS)亚马逊来解析消息。应用程序无法解析大小大于256KB的消息。该公司希望实现一个解决方案使应用程序能够解析高达50MB的消息。在代码更改最少的情况下哪个解决方案能够满足这些要求？",
    "options_cn": {
      "A": "在Amazon SQS中使用Amazon SQS Extended Client Library来接收大于256KB的消息。",
      "B": "使用Amazon EventBridge来发布来自应用程序的大消息而不是Amazon SQS。",
      "C": "更改Amazon SQS服务协议中的限制以处理大于256KB的消息。",
      "D": "在Amazon Elastic File System (EFS) 中存储大于256KB的消息。配置Amazon SQS 以在消息中引用此位置。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Extended Client Library"
    ],
    "explanation": {
      "analysis": "考察处理大型SQS消息。",
      "why_correct": "使用 Amazon SQS Extended Client Library 可以将大型消息存储在S3中，并在SQS消息中包含对S3对象的引用，从而绕过SQS消息大小的限制。",
      "why_wrong": "EventBridge不提供队列功能。更改服务协议中的限制是不可能的。EFS 方案需要修改应用程序代码，且更复杂。"
    },
    "related_terms": [
      "SQS",
      "EC2",
      "Amazon SQS Extended Client Library",
      "Amazon EventBridge",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 345,
    "topic": "",
    "question_cn": "一家公司希望限制对其主要Web应用程序之一内容的访问，并通过使用AWS上可用的授权技术来保护内容。该公司希望为不到100个用户实现无服务器架构和身份验证解决方案。解决方案需要与主要的Web应用程序集成并在全球范围内为Web内容服务。解决方案还必须随着公司用户群的增长而扩展，同时提供尽可能最低的登录延迟。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用Amazon Cognito进行身份验证。使用Lambda@Edge授权。使用Amazon CloudFront服务于全球Web应用程序。",
      "B": "使用AWS Directory Service对微软活动目录进行身份验证。使用AWS WAF。使用一个应用程序负载均衡器为Web应用程序提供全局服务。",
      "C": "使用Amazon Cognito进行身份验证。使用AWS WAF。使用Amazon S3 传输加速为网络应用程序提供全球服务。",
      "D": "使用AWS Directory Service对微软活动目录进行身份验证。使用Lambda@Edge授权。使用AWS Elastic Beanstalk服务于全球的Web应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cognito",
      "Lambda@Edge",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考察无服务器身份验证方案、全球内容分发和低延迟。",
      "why_correct": "Amazon Cognito 提供了用户身份验证服务，Lambda@Edge 可以用于在CloudFront边缘位置进行授权， CloudFront用于全球内容分发，同时提供低延迟和高扩展性。",
      "why_wrong": "AWS Directory Service方案不如Cognito简便。ALB和Elastic Beanstalk不适用于全球内容分发，无法达到最低延迟。S3传输加速用于加速S3的上传和下载，与内容分发无关。"
    },
    "related_terms": [
      "Amazon Cognito",
      "Lambda@Edge",
      "CloudFront",
      "AWS Directory Service",
      "AWS WAF",
      "Elastic Beanstalk",
      "S3"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 346,
    "topic": "",
    "question_cn": "一家公司在其数据中心有一个老化网络连接存储 (NAS) 阵列。阵列向客户端工作站提供 SMB 和 NFS 共享。该公司不想购买一个新的 NAS 阵列。该公司也不想承担更新 NAS 阵列支持合同的费用。一些数据经常被访问但大部分数据是不活动的。解决方案架构师需要实现一个解决方案将数据迁移到亚马逊 S3，使用生命周期策略并维护客户端工作站的相同外观和感觉。解决 AWS 方案架构师已将 存储网关确定为解决方案的一部分。解决方案架构师应该提供哪种类型的存储网关来满足这些需求？",
    "options_cn": {
      "A": "卷网关",
      "B": "磁带网关",
      "C": "Amazon FSx 文件网关",
      "D": "Amazon S3 文件网关"
    },
    "vote_percentage": "100%",
    "tags": [
      "Storage Gateway",
      "S3",
      "NAS Migration"
    ],
    "explanation": {
      "analysis": "此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是亚马逊S3文件网关专门用于将本地文件存储迁移到S3，支持SMB和NFS协议，可以满足题目的需求，并且维护客户端的体验。",
      "why_correct": "Amazon S3 文件网关 支持 SMB 和 NFS 协议，可以用于将本地文件共享迁移到 Amazon S3。它能够保持客户端工作站的文件外观，并可以使用 S3 生命周期策略进行数据管理。",
      "why_wrong": "选项A是卷网关，主要用于提供基于块的存储。选项B是磁带网关，主要用于备份。选项C是FSx 文件网关，适用于Windows和Linux工作负载，但不如S3文件网关直接针对文件共享迁移场景。"
    },
    "related_terms": [
      "NAS",
      "SMB",
      "NFS",
      "S3",
      "存储网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 347,
    "topic": "",
    "question_cn": "一家公司有一个在亚马逊 EC2 实例上运行的应用程序。解决方案架构师根据公司当前的需求对公司的特定实例家族和各种实例大小 进行了标准化。该公司希望在未来 3 年内最大限度地节省应用程序的成本。该公司需要能够在未来 6 个月内根据应用程序的流行程度和使用情况改变 实例家族和规模。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "计算储蓄计划",
      "B": "EC2 实例节约计划",
      "C": "区域保留实例",
      "D": "标准保留实例"
    },
    "vote_percentage": "79%",
    "tags": [
      "EC2 Cost Optimization",
      "Savings Plan"
    ],
    "explanation": {
      "analysis": "此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是计算储蓄计划提供了最大的灵活性，能够覆盖EC2、Lambda 和 Fargate等多个服务的使用，并在实例系列和大小发生变化时提供折扣。选项C和D是保留实例，但缺乏灵活性。",
      "why_correct": "计算储蓄计划提供了最大的灵活性，可以在实例家族、大小和操作系统发生变化时节省成本。并且涵盖了EC2、Lambda 和 Fargate等多个服务，适合有变化的场景。",
      "why_wrong": "选项B不常用。选项C和D是保留实例，锁定实例规格，灵活性较差。不适用于未来6个月内要改变实例系列和规模的情况。"
    },
    "related_terms": [
      "EC2",
      "Compute Savings Plans",
      "EC2 实例节约计划",
      "保留实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 348,
    "topic": "",
    "question_cn": "一家公司从大量使用可穿戴设备的参与者那里收集数据。该公司将数据存储在亚马逊 DynamoDB 表中并使用应用程序来分析数据。数据 工作量是稳定和可预测的。该公司希望保持在或低于其预测的 DynamoDB 预算。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用供给模式和 DynamoDB 标准（-I）。为预测的工作量准备能力。",
      "B": "使用供给模式。指定读容量单位和写容量单位。",
      "C": "使用按需模式。设置读容量单位和写容量单位以适应工作量的变化。",
      "D": "使用按需模式。指定有保留容量的读容量单位和写容量单位。"
    },
    "vote_percentage": "86%",
    "tags": [
      "DynamoDB",
      "Provisioned vs. On-Demand"
    ],
    "explanation": {
      "analysis": "此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是数据工作负载是稳定和可预测的，使用供给模式并指定读写容量单位，可以在成本和性能之间取得平衡，满足预算要求。",
      "why_correct": "当工作负载可预测且稳定时，使用供给模式并指定适当的读写容量单位，可以更有效地控制成本，并确保性能满足需求。",
      "why_wrong": "选项A 涉及 DynamoDB 标准 (Standard-I) , 虽然可以降低存储成本, 但不能有效控制读写容量单位。选项C和D涉及按需模式，虽然无需预置容量，但无法控制预算。"
    },
    "related_terms": [
      "DynamoDB",
      "供给模式",
      "按需模式"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 349,
    "topic": "",
    "question_cn": "一家公司将机密数据存储在Amazon RDS后的数据库中，位于AP-东南3区域。该数据库是加密的，使用AWS KMS客户管理的密钥。该公司是最近收购的，必须安全地与收购公司在AP-东南2的帐户共享数据库备份。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个数据库快照。将快照复制到一个新的未加密快照。将新的快照与收购公司的帐户共享。",
      "B": "创建一个数据库快照。将收购公司的帐户添加到密钥策略中。将快照与收购公司的帐户共享。",
      "C": "创建一个数据库快照，使用不同的AWS KMS管理的键。将收购公司的帐户添加到键别名中。与收购公司的帐户共享快照。",
      "D": "创建一个数据库快照。下载数据库快照。上传数据库快照到一个Amazon S3桶。更新桶策略允许从收购公司的帐户访问。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "KMS",
      "Database Backup Sharing"
    ],
    "explanation": {
      "analysis": "考查共享加密RDS数据库备份的方法。",
      "why_correct": "将收购方的账户添加到KMS密钥策略中，允许其访问加密的数据库备份。这是安全共享加密数据库备份的正确方法。",
      "why_wrong": "A、共享未加密的快照会泄露敏感数据。C、修改密钥配置，过于复杂，且需要修改密钥。D、下载和上传快照到S3，增加了管理复杂性，且安全性较低。"
    },
    "related_terms": [
      "RDS",
      "AWS KMS",
      "快照",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 350,
    "topic": "",
    "question_cn": "一家公司使用Amazon RDS来存储用户事务，用于在美国东部1号区域的微软SQL Server单实例。该公司需要高可用性和自动恢复的数据库实例。RDS该公司还必须每年运行几次数据库报告。报告过程会使交易花费比通常更长的时间才能寄到客户的帐户上。该公司需要一个解决方案将改善业绩的报告过程。哪些步骤组合将满足这些要求？（选二）",
    "options_cn": {
      "A": "将数据库实例从单实例修改为多AZ部署。",
      "B": "对当前的数据库实例进行快照。将快照还原到另一个可用区中的新部署。",
      "C": "在不同的可用性区域中创建数据库实例的读副本。将所有报告请求指向读取副本。",
      "D": "将数据库迁移到自定义。",
      "E": "使用RDS代理将报告请求限制到维护窗口。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "High Availability",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "考查RDS高可用性，以及使用读副本进行报告，从而提高性能。",
      "why_correct": "A、多AZ部署提供高可用性。C、读副本可以分担报告负载，提高主实例的性能。",
      "why_wrong": "B、恢复快照并不能提高性能。D、将数据库迁移到自定义增加了管理复杂性。E、将报告请求限制到维护窗口并不能改善性能，反而会影响报告的及时性。"
    },
    "related_terms": [
      "RDS",
      "Multi-AZ",
      "快照",
      "RDS Proxy"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 351,
    "topic": "",
    "question_cn": "一家公司正在将其数据管理应用程序转移到AWS。该公司希望过渡到事件驱动的架构。体系结构需要更加分布化，并在执行工作流的不同方面时使用无服务器概念。该公司还希望尽量减少运营成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将工作流建立在AWS Glue中。使用Glue调用Lambda函数来处理工作流步骤。",
      "B": "在Amazon EC2实例上部署应用程序。使用步骤函数调用实例上的工作流步骤。",
      "C": "建立工作流程在Amazon EventBridge。在日程表中调用Lambda函数来处理工作流步骤。",
      "D": "建立工作流使用步骤函数创建状态机，使用状态机调用Lambda函数来处理工作流步骤。"
    },
    "vote_percentage": "88%",
    "tags": [
      "Serverless",
      "Step Functions",
      "Event-Driven Architecture"
    ],
    "explanation": {
      "analysis": "考察使用无服务器技术构建事件驱动型工作流程的最佳实践。",
      "why_correct": "D、使用AWS Step Functions可以构建状态机，实现复杂的无服务器工作流，并调用Lambda函数处理工作流步骤，从而满足事件驱动、分布化和降低运营成本的需求。",
      "why_wrong": "A、Glue主要用于数据ETL，不适合构建通用的工作流。B、在EC2上部署工作流，不符合无服务器原则。C、使用EventBridge的调度，不够灵活，无法构建复杂的流程。"
    },
    "related_terms": [
      "AWS Glue",
      "Lambda",
      "Amazon EventBridge",
      "步骤函数"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 352,
    "topic": "",
    "question_cn": "一家公司正在设计一个在线多人游戏的网络。该游戏使用UDP网络协议并将部署在8个区域。网络体系结构需要最小化延迟和包损失以使最终用户获得高质量的游戏体验。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在每个区域建立一个传送网关。在每个传送网关之间创建区域间窥视附件。",
      "B": "在每个区域建立UDP听众和端点组的Global Accelerator。",
      "C": "用Amazon CloudFront打开。在每个区域配置一个起源。",
      "D": "在每个区域之间建立一个VPC窥视网。为每个VPC打开UDP。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "UDP",
      "Network Latency"
    ],
    "explanation": {
      "analysis": "考查游戏应用的网络优化，降低延迟和丢包。",
      "why_correct": "B、Global Accelerator可以利用AWS的全球网络，优化UDP流量，降低延迟和丢包，提高游戏体验。",
      "why_wrong": "A、使用传送网关和窥视附件，虽然可以连接VPC，但无法优化UDP流量的延迟和丢包。C、CloudFront适用于静态内容分发，不适用于UDP游戏流量。D、VPC peering 无法优化UDP流量的延迟和丢包。"
    },
    "related_terms": [
      "UDP",
      "Global Accelerator",
      "CloudFront",
      "VPC",
      "VPC 窥视"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 353,
    "topic": "",
    "question_cn": "一个公司在一个单一可用性区域的Amazon EC2实例上拥有一个三层Web应用程序。Web应用程序使用一个自我管理的MySQL数据库。MySQL数据库存储在Amazon EBS卷中以便在Amazon弹性块存储（EBS）中存储数据。数据库目前使用的是一个提供1,000 IOPS的EBS卷。该公司预计在高峰流量时读写业务的流量为15,000 IOPS。该公司希望最大限度地减少任何干扰，稳定性能，降低成本，同时保留两倍的独立采购服务。该公司希望将数据库层转移到一个完全管理的解决方案，该解决方案具有高度的可用性和容错性。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用一个多AZ RDS MySQL数据库实例并有一个块快速EBS卷。",
      "B": "对于具有通用SSD（GP-2）卷的RDS MySQL数据库实例使用Amazon RDS的多AZ部署。",
      "C": "使用Amazon S3智能层访问层。",
      "D": "使用两个大的EC2实例在主动被动模式下托管数据库。"
    },
    "vote_percentage": "89%",
    "tags": [
      "RDS",
      "MySQL",
      "High Availability",
      "EBS"
    ],
    "explanation": {
      "analysis": "考查数据库迁移到RDS，并优化性能和可用性。",
      "why_correct": "B、使用RDS的MySQL数据库的多AZ部署，提供了高可用性，同时避免了自己管理数据库的复杂性。GP-2卷可以满足IOPS需求。",
      "why_wrong": "A、块快速卷无法满足数据库的需求。C、S3是对象存储，不能替代数据库。D、在EC2上使用主动/被动模式托管数据库，需要自己管理高可用性，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "MySQL",
      "EBS",
      "RDS",
      "Multi-AZ",
      "GP-2",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 354,
    "topic": "",
    "question_cn": "一个公司在AWS上拥有一个无服务的应用程序。该应用程序使用Amazon API Gateway、Lambda和Amazon RDS来建立后端数据库。该公司注意到在高峰流量或不可预测流量期间，由于数据库连接超时，应用程序错误增加。该公司需要一个解决方案以最少数量的代码更改减少应用程序失败。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "降低Lambda并发率。",
      "B": "启用RDS数据库实例上的代理。",
      "C": "重新调整RDS数据库实例类以接受更多连接。",
      "D": "将数据库迁移到Amazon DynamoDB随需扩展。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Proxy",
      "Database Connection Management"
    ],
    "explanation": {
      "analysis": "解决Lambda函数连接到RDS数据库时出现的连接超时问题。",
      "why_correct": "B、启用RDS代理可以复用数据库连接，减少连接建立开销，从而解决连接超时的问题，且代码更改最少。",
      "why_wrong": "A、降低Lambda并发率会影响性能。C、重新调整数据库实例类，无法有效解决连接超时问题。D、迁移到DynamoDB随需扩展，需要重构应用程序，代码更改量大。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "RDS",
      "DynamoDB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 355,
    "topic": "",
    "question_cn": "一家公司正在将一个旧的应用程序迁移到 AWS。该应用程序每小时运行一个批处理任务并且是 CPU 密集型的。在现场服务 器上批处理工作平均需要 15 分钟。该服务器有 64 个虚拟 CPU(vCPU) 和 512 GB 内存。哪个解决方案将在 15 分钟内运行批处理作业而操作开销最小？",
    "options_cn": {
      "A": "使用具有功能缩放功能的 Lambda。",
      "B": "使用亚马逊弹性集装箱服务 (Amazon ECS) 与亚马逊 Fargate。",
      "C": "使用亚马逊光帆自动缩放。",
      "D": "在亚马逊 EC2 上使用批处理。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Batch Processing",
      "EC2",
      "ECS"
    ],
    "explanation": {
      "analysis": "此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是在EC2上使用批处理，能够更好地控制环境，并可以利用现有的vCPU和内存，并且实现最小的操作开销。",
      "why_correct": "在 EC2 上使用批处理可以提供对计算资源的完全控制，并且可以利用现有的 CPU 和内存资源。满足在15分钟内完成批处理任务的需求。",
      "why_wrong": "选项A使用Lambda，对于CPU密集型批处理任务可能成本较高，且容易受到函数执行时间限制。选项B使用ECS with Fargate，需要容器化应用程序，增加了复杂性。选项C使用亚马逊光帆自动缩放，可能不具备足够的灵活性以满足需求。"
    },
    "related_terms": [
      "Lambda",
      "Amazon ECS",
      "Fargate",
      "Amazon EC2"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 356,
    "topic": "",
    "question_cn": "一家公司将其数据对象存储在Amazon S3标准存储器中。解决方案架构师发现75%的数据在30天后很少被访问。该公司需要所有数据都能以同样的高可用性和弹性立即访问，但该公司希望将存储成本降至最低。哪种存储方案能满足这些要求？",
    "options_cn": {
      "A": "30天后将数据对象移到冰川深处档案库。",
      "B": "30天后将数据对象移至S3标准不经常访问存储类。",
      "C": "30天后将数据对象移动到S3一个不常见的区域访问存储类。",
      "D": "立即将数据对象移动到S3一个不常见的区域访问存储类。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Storage Classes",
      "S3 Lifecycle Rules"
    ],
    "explanation": {
      "analysis": "考查S3存储类和生命周期策略，降低存储成本。",
      "why_correct": "B、S3标准不经常访问存储类，适合于不常访问的数据，并提供与标准存储相同的可用性和弹性，同时降低成本。",
      "why_wrong": "A、冰川深处档案库访问时间较长，不符合“立即访问”的要求。C、不常见的区域访问存储类，不满足高可用性和弹性的要求。D、立即移动数据到不常用的存储类，不符合访问频率的要求。"
    },
    "related_terms": [
      "S3",
      "冰川深处档案库",
      "S3 Standard-IA",
      "S3",
      "S3 Intelligent-Tiering"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 357,
    "topic": "",
    "question_cn": "一家游戏公司正在将其公共记分牌从数据中心转移到AWS云。该公司使用Amazon EC2窗口服务器实例背后的应用负载均衡器主机其动态应用程序。该公司需要一个非常可用的存储解决方案的应用。应用程序由静态文件和动态服务器端代码组成。解决方案架构师应该采取哪些步骤来满足这些需求？（选二）",
    "options_cn": {
      "A": "在Amazon S3上存储静态文件。使用Amazon CloudFront缓存边缘的对象。",
      "B": "在Amazon S3上存储静态文件。使用Amazon可伸缩性来缓存边缘的对象。",
      "C": "在Amazon EFS上存储服务器端代码。在每个EC2实例上安装EFS卷以共享文件。",
      "D": "在Amazon FSx for Windows文件服务器上存储服务器端代码。在每个EC2实例上安装FSx for Windows文件服务器卷的EFS以共享文件。",
      "E": "在通用SSD（GP-2）EBS卷上存储服务器端代码。在每个EC2实例上安装EBS卷以共享文件。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront",
      "EFS",
      "FSx"
    ],
    "explanation": {
      "analysis": "考查静态资源存储和缓存，以及服务器端代码的存储和共享。",
      "why_correct": "A、使用S3存储静态文件，并使用CloudFront进行缓存，可以提高性能和可用性。D、使用FSx for Windows File Server存储服务器端代码，可以在EC2实例之间共享文件，从而提高可用性。",
      "why_wrong": "B、使用Amazon可伸缩性缓存边缘的对象，不符合最佳实践。C、EFS是文件系统，不是S3，无法满足静态文件存储。E、EBS是块存储，不能用于共享文件。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "CloudFront",
      "S3",
      "EFS",
      "FSx for Windows File Server"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 358,
    "topic": "",
    "question_cn": "一家社交媒体公司在亚马逊 EC2 实例中运行其应用程序，其背后是一个应用负载平衡器 (ALB)。 CloudFront 是亚马逊云端分布的起源。该应用程序有超过十亿的图像存储在一个亚马逊 S3 桶中，每秒钟处理几千个图像。该公司希望动态调整图像大小并为客户提供适当的格式。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在 EC2 实例上安装外部图像管理库。使用图像管理库处理图像。",
      "B": "创建一个 CloudFront 源代码请求策略。使用此策略可以自动调整图像大小并在请求中基于用户 --HTML 头提供适当的格式。",
      "C": "使用带有外部图像管理库的 Lambda Edge 功能。将 Lambda Edge 函数与服务于图像的 CloudFront 行为联系起来。",
      "D": "创建一个 CloudFront 响应头策略。使用此策略可以自动调整图像大小并在请求中基于用户 --HTML 头提供适当的格式。"
    },
    "vote_percentage": "88%",
    "tags": [
      "CloudFront",
      "Lambda@Edge",
      "Image Optimization"
    ],
    "explanation": {
      "analysis": "此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是使用Lambda@Edge，可以在全球范围内实现图像动态调整大小和格式转换，而无需在EC2实例上维护基础设施。 与CloudFront集成，操作开销最小。",
      "why_correct": "使用 Lambda@Edge 可以在 CloudFront 的边缘位置运行代码，从而实现对图像的动态处理和优化，例如调整大小和格式转换，减少延迟，提高用户体验。这种方案操作开销最小。",
      "why_wrong": "选项A在EC2实例上安装库，增加了管理维护成本和复杂性。选项B和D 使用 CloudFront 策略，但策略不具备图像处理的能力，无法实现动态调整图像大小。"
    },
    "related_terms": [
      "CloudFront",
      "S3",
      "EC2",
      "Lambda Edge"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 359,
    "topic": "",
    "question_cn": "医院需要把病人记录存放在Amazon S3桶里。医院的合规小组必须确保所有受保护的健康信息在运输过程中和休息时加密。合规团队必须管理数据的加密密钥。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在AWS证书管理器（ACM）中创建公共SSL/TLS证书。将证书与Amazon S3联系起来。为每个S3桶配置默认加密，以便使用AWS KMS的服务器端加密（SSE-KMS）。分配合规团队管理KMS键。",
      "B": "使用桶策略上的安全传输条件，只允许在HTTPS(TLS)上加密连接。为每个S3桶配置默认加密，以便使用SSE-3的服务器端加密。指派合规团队管理KMS键。",
      "C": "使用桶策略上的安全传输条件，只允许在HTTPS(TLS)上加密连接。为每个S3桶配置默认加密，以便使用AWS KMS的服务器端加密（SSE-KMS）。分配合规团队管理KMS键。",
      "D": "使用桶策略上的安全传输条件，只允许在HTTPS(TLS)上加密连接。使用Amazon Macie保护储存在Amazon S3的敏感数据。指派合规小组管理Macie。"
    },
    "vote_percentage": "84%",
    "tags": [
      "S3 Encryption",
      "SSE-KMS",
      "HTTPS",
      "Data Compliance"
    ],
    "explanation": {
      "analysis": "考察S3数据的加密方法，满足合规要求。",
      "why_correct": "C、使用HTTPS(TLS)保证传输加密，使用SSE-KMS保证静态数据加密，并由合规团队管理KMS密钥，满足合规要求。",
      "why_wrong": "A、使用SSL/TLS证书与S3没有直接关系，不能直接实现加密。B、SSE-3不正确，SSE-S3是S3托管密钥。D、Macie用于数据安全审计，不是加密解决方案。"
    },
    "related_terms": [
      "S3",
      "ACM",
      "AWS KMS",
      "SSE-KMS",
      "HTTPS",
      "TLS",
      "Amazon Macie"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 360,
    "topic": "",
    "question_cn": "一家公司使用亚马逊 VPC 网关运行一个私人网关与两个 REST API 在同一 VPC 中。该服务调用了检查基金服务以确保在购买股票之前有足够的资金可用。该公司已经在流日志中注意到 REST API 服务通过互联网而不是通过 VPC 来调用 REKFYRETWeb 服务。解决方案架构师必须实现解决方案以便通过 VPC 进行通信。在代码更改最少的情况下哪个解决方案能够满足这些要求？",
    "options_cn": {
      "A": "在 API 网关中，在标题中添加一个 http 键头以获得授权。",
      "B": "使用接口端点。",
      "C": "使用网关端点。",
      "D": "在两个 REST API 之间添加一个亚马逊简单队列服务队列。"
    },
    "vote_percentage": "92%",
    "tags": [
      "VPC Endpoint",
      "API Gateway"
    ],
    "explanation": {
      "analysis": "此题考察在VPC内通过API Gateway访问后端服务的问题。社区共识是使用接口端点。使用接口端点允许从VPC内的资源私密地访问API Gateway，避免流量通过公共互联网。",
      "why_correct": "使用接口端点可以确保API Gateway 的流量保持在 VPC 内，满足了题目中关于私有通信的要求，并且减少了延迟和安全性风险。",
      "why_wrong": "A选项错误，在标题中添加HTTP头是授权机制，与题目要求不符。C选项错误，网关端点用于访问其他AWS服务，不是私有访问API Gateway的正确方式。D选项错误，使用SQS会增加复杂性和延迟，并且与题干不符。"
    },
    "related_terms": [
      "VPC",
      "REST API",
      "VPC",
      "Amazon SQS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 361,
    "topic": "",
    "question_cn": "一家公司在 AWS 上拥有一个多人游戏应用程序。该公司希望该应用程序能够读取次毫秒延迟的数据并对历史数据进行一次性查询。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "对经常访问的数据使用亚马逊 RDS。运行一个定期定制脚本将数据导出到一个 S3桶。",
      "B": "将数据直接存储在 S3 桶中。实现生命周期策略将旧数据转移到 S3 冰川深处档案库以便长期存储。使用亚马逊雅典娜对 S3 的数据进行一次性查询。",
      "C": "使用亚马逊 DynamoDB 与 DynamoDB Accelerator(DAX) 的数据经常访问。通过使用 DynamoDB 表导出将数据导出到 S3 桶。使用亚马逊雅典娜对 S3 的数据进行一次性查询。",
      "D": "对经常访问的数据使用亚马逊 DynamoDB。打开流到亚马逊运动数据流。使用亚马逊运动数据消防软管读取运动数据流的数 S3 据。把记录放在亚马逊的 S3 桶里。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "Amazon Athena"
    ],
    "explanation": {
      "analysis": "此题考察如何存储游戏数据以满足低延迟访问和历史数据查询需求。社区共识是使用DynamoDB和DAX，并使用Athena查询历史数据。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是， DynamoDB可以满足低延迟的需求， DAX提供缓存。并结合Athena可以进行历史数据查询。",
      "why_correct": "选项C使用DynamoDB存储频繁访问的实时游戏数据，使用DAX加速读取，满足低延迟的需求。同时将数据导出到S3，使用Athena进行历史数据分析，满足了对历史数据进行一次性查询的需求，并且具有成本效益。",
      "why_wrong": "选项A使用RDS不适合低延迟的需求。选项B将所有数据直接存放在S3，不满足低延迟访问的要求。选项D使用Kinesis Data Streams方案相对复杂，且成本较高。"
    },
    "related_terms": [
      "RDS",
      "S3",
      "S3 Transfer Acceleration",
      "S3 冰川深处档案库",
      "Athena",
      "DynamoDB",
      "DynamoDB Accelerator(DAX)",
      "运动数据流",
      "运动数据消防软管"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 362,
    "topic": "",
    "question_cn": "一家公司使用付款处理系统，该系统要求在发送的同一订单中接收特定付款标识。否则付款可能处理不当。解决方案架构师应该采取哪些行动来满足这一需求（选二）。",
    "options_cn": {
      "A": "用支付标识作为分区键将消息写入亚马逊 DynamoDB 表。",
      "B": "用支付 ID 作为分区键将消息写入亚马逊运动数据流。",
      "C": "用支付 ID 作为键将邮件写入到一个用于记忆缓存集群的亚马逊电子邮件。",
      "D": "将消息写入亚马逊简单队列服务队列。设置要使用支付 ID 的消息属性。",
      "E": "将消息写入亚马逊简单队列服务 FIFO 队列。设置消息组使用付款标识。"
    },
    "vote_percentage": "74%",
    "tags": [
      "SQS FIFO",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此题考察如何保证消息的顺序性和分组处理。社区共识是使用SQS FIFO队列和设置消息组ID。注意: 此题官方答案为BD，但社区共识(投票最高)为BE。社区倾向BE的原因是，通过使用FIFO队列和消息组可以保证消息的顺序。",
      "why_correct": "选项E: 使用 SQS FIFO 队列，FIFO 队列保证消息的顺序，设置消息组ID可以保证同一组的消息被顺序处理。选项B: 使用 DynamoDB 存储支付数据，并以支付ID作为分区键，可以保证同一支付ID的数据存储在一起，方便查询。",
      "why_wrong": "选项A:  使用 DynamoDB 并不能保证消息的顺序。选项C:  使用 Memcached 不适用于消息传递和顺序保证。选项D: 使用普通SQS不能保证消息顺序。"
    },
    "related_terms": [
      "DynamoDB",
      "运动数据流",
      "简单队列服务",
      "FIFO 队列"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 363,
    "topic": "",
    "question_cn": "一家公司正在建立一个游戏系统，需要将独特的事件发送到独立的领导板匹配和认证服务并发。该公司需要一个由事件驱动的系统来保证事件的顺序。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "Amazon EventBridge活动总线",
      "B": "Amazon Simple Notification Service",
      "C": "Amazon Simple Notification Service标准主题",
      "D": "Amazon Simple Queue Service"
    },
    "vote_percentage": "73%",
    "tags": [
      "SNS",
      "Event-driven"
    ],
    "explanation": {
      "analysis": "此题考察如何通过事件驱动实现消息传递和顺序保证。",
      "why_correct": "B: Amazon SNS 可以用于发布订阅模式，满足并发事件的需求。使用标准主题即可。",
      "why_wrong": "A: EventBridge主要用于事件路由和编排，不适合保证消息顺序；C: 标准主题无法保证顺序；D: SQS适合解耦异步任务，不是事件驱动的理想选择。"
    },
    "related_terms": [
      "EventBridge",
      "Simple Notification Service",
      "Simple Queue Service"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 364,
    "topic": "",
    "question_cn": "一家医院正在设计一种新的应用程序将患者的症状集中在一起。该医院已决定在架构中使用亚马逊简单队列服务和亚马逊简单通知服务。 解决方案架构师正在审查基础结构设计。数据必须在休息和传输时加密。只有医院的授权人员才能查阅数据。解决方案架构师应该采取哪些步骤来满足这些需求（选二）。",
    "options_cn": {
      "A": "打开服务端对简单通知服务协议组件的加密。更新默认的密钥策略将密钥的使用限制在一组授权的主体上",
      "B": "打开服务器端加密通过使用一个 AWS KMS 密钥管理服务客户管理密钥的信噪比组件。应用一个键策略将键的使用限制在一组授权的主体上",
      "C": "打开简单通知服务组件的加密。更新默认的密钥策略将密钥的使用限制在一组授权的主体上。在主题策略中设置条件只允许在 TLS 上加密连接。",
      "D": "通过使用 AWS KMS 密钥管理服务客户管理密钥来打开服务端加密。应用一个键策略将密钥的使用限制在一组授权的主体。在队列策略中设置一个条件只允许在 TLS 上加密连接。",
      "E": "通过使用 AWS KMS 密钥管理服务客户管理密钥来打开服务端加密。应用 IAM策略将密钥的使用限制在一组授权的主体上。在 TLS 队列策略中设置一个条件只允许在 上加密连接。"
    },
    "vote_percentage": "73%",
    "tags": [
      "SQS Encryption",
      "SNS Encryption"
    ],
    "explanation": {
      "analysis": "此题考察如何在SQS和SNS中实现数据加密和访问控制。社区共识是使用KMS客户管理密钥进行加密，并通过策略限制访问。注意: 此题官方答案为CD，但社区共识(投票最高)为BD。社区倾向BD的原因是，B和D选项涵盖了SQS和SNS的加密需求。",
      "why_correct": "选项B: 通过使用KMS进行加密，并使用密钥策略控制访问，实现了数据的静态加密。选项D: 通过使用KMS加密SQS消息，并在队列策略中限制TLS连接，实现了数据传输加密，满足了安全需求。",
      "why_wrong": "选项A、C没有涉及到SQS和SNS的双重加密。选项E，IAM策略虽然可以控制访问，但需要配置在正确的资源上，更容易出错。"
    },
    "related_terms": [
      "Simple Queue Service",
      "Simple Notification Service",
      "AWS KMS",
      "TLS",
      "IAM"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 365,
    "topic": "",
    "question_cn": "一家公司运行着一个由Amazon RDS支持的网络应用程序。一个新的数据库管理员由于在数据库表中意外编辑信息而导致数据丢失。为了帮助从这类事件中恢复过来，该公司希望能够在过去30天内发生任何变化之前5分钟将数据库恢复到状态。解决方案架构师在设计中应包括哪些功能以满足这一要求？",
    "options_cn": {
      "A": "阅读副本",
      "B": "手动快照",
      "C": "自动备份",
      "D": "多AZ部署"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Backup",
      "Point-in-time recovery"
    ],
    "explanation": {
      "analysis": "考察了RDS的数据库恢复功能。",
      "why_correct": "C: RDS的自动备份提供Point-in-time恢复功能，可以恢复到过去指定时间点。",
      "why_wrong": "A: 副本用于提高读取性能，不能用于恢复；B: 手动快照需要手动创建，不满足5分钟的恢复要求；D: 多AZ部署提高可用性，不能用于恢复。"
    },
    "related_terms": [
      "RDS",
      "Read Replica",
      "快照",
      "自动备份",
      "Multi-AZ"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 366,
    "topic": "",
    "question_cn": "一个公司的网络应用程序包括一个亚马逊 API 网关、一个 Lambda 函数和一个亚马逊 DynamoDB 数据库。 Lambda 函数处理业务逻辑，DynamoDB 表容纳数据。该应用程序使用亚马逊密码用户池来识别应用程序的个人用户。解决方案架构师需要更新应用程序这样只有订阅的用户才能访问高级内容。用最少的操作开销来满足这个需求的解决方案是什么？",
    "options_cn": {
      "A": "在 API 网关上启用缓存和节流。",
      "B": "在 API 网关上设置 WAF。创建一个规则来过滤有订阅的用户",
      "C": "对 DynamoDB 表中的高级内容应用细粒度 IAM 权限。",
      "D": "实施 API 密钥以限制没有订阅的用户的访问。"
    },
    "vote_percentage": "85%",
    "tags": [
      "API Gateway",
      "API Key"
    ],
    "explanation": {
      "analysis": "此题考察如何控制API访问，只允许订阅用户访问高级内容。社区共识是使用API Key进行访问控制。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，使用API Key可以实现简单有效的访问控制。",
      "why_correct": "选项D： 使用API密钥可以简单有效地控制访问。未订阅的用户无法获取API Key，从而无法访问高级内容。",
      "why_wrong": "选项A: 缓存和节流用于优化性能和保护后端，无法实现访问控制。选项B: WAF用于保护应用程序免受web攻击，与访问控制无关。选项C:  IAM权限用于控制对DynamoDB资源的访问，而非控制API的访问。"
    },
    "related_terms": [
      "API 网关",
      "Lambda",
      "DynamoDB",
      "API 密钥",
      "IAM",
      "WAF"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 367,
    "topic": "",
    "question_cn": "一家公司正在使用Amazon Route 53的延迟路由为世界各地的用户提供基于UDP的应用程序的路由请求。该应用程序在该公司位于美国、亚洲和欧洲的内部数据中心的冗余服务器上托管。该公司的合规要求规定申请必须在办公场所托管。公司希望改进应用程序的性能和可用性。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "在三个AWS区域配置三个网络负载平衡器（NLB）以解决现场端点。通过使用AWS Global Accelerator创建一个加速器并注册NLB作为其DNS终点。通过使用指向加速器的名称提供对应用程序的访问。",
      "B": "在三个AWS区域配置三个应用程序负载平衡器（ALB）来处理现场端点。通过使用AWS Global Accelerator创建一个加速器并将其注册为DNS结束点。通过使用指向加速器的名称提供对应用程序的访问。",
      "C": "在三个AWS区域配置三个网络负载平衡器（NLB）以解决现场端点。在Route 53公路上创建一个基于延迟的记录指向三个NLB并将DNS记录其作为Amazon CloudFront分布的来源。通过使用指向CloudFront的名称提供对应用程序的访问。",
      "D": "在三个AWS区域配置三个应用程序负载平衡器（ALB）来处理现场端点。在Route 53公路上创建一个基于延迟的记录指出这三个DNS位置并将其作为Amazon CloudFront分布的来源。通过使用指向CloudFront的名称提供对应用程序的访问。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "Route 53",
      "Latency Routing"
    ],
    "explanation": {
      "analysis": "该题考查如何使用Global Accelerator和Route 53来实现全球应用程序的性能和可用性优化。",
      "why_correct": "A: 使用NLB处理现场端点，Global Accelerator提供加速，Route 53实现延迟路由和DNS解析，提高应用程序性能和可用性。",
      "why_wrong": "B: ALB不适合UDP流量；C: CloudFront不适合UDP流量，并且NLB应该注册为Global Accelerator的终点；D: ALB不适合UDP流量，CloudFront不适合UDP流量。"
    },
    "related_terms": [
      "Route 53",
      "UDP",
      "网络负载平衡器（NLB）",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "ALB",
      "DNS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 368,
    "topic": "",
    "question_cn": "解决方案架构师希望所有新用户都有特定的复杂性要求和用户密码的强制性轮换期。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "为整个AWS账户设置一个总体密码策略。",
      "B": "为AWS账户中的每个IAM用户设置密码策略。",
      "C": "使用第三方供应商软件设置密码要求。",
      "D": "将Amazon CloudWatch规则附加到创建新用户事件上以设置具有适当要求的密码。"
    },
    "vote_percentage": "95%",
    "tags": [
      "IAM",
      "Password Policy"
    ],
    "explanation": {
      "analysis": "考察了IAM密码策略的设置方法。",
      "why_correct": "A: 可以在IAM中设置密码策略，应用于整个AWS账户。",
      "why_wrong": "B: 不能单独为每个用户设置密码策略；C: 第三方软件增加了复杂性，不推荐；D: CloudWatch不用于设置密码策略。"
    },
    "related_terms": [
      "IAM",
      "密码策略",
      "CloudWatch"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 369,
    "topic": "",
    "question_cn": "一家公司已经将一个应用程序迁移到了Amazon EC2实例。其中一个EC2实例按计划运行几个小时的任务。这些任务是由不同的团队编写的，没有共同的编程语言。当这些任务只在一个实例上运行时，公司关注的是性能和可伸缩性。解决方案架构师需要实现解决这些问题的解决方案。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS Batch作为作业运行任务。通过使用Amazon EventBridge的活动来安排工作。",
      "B": "将EC2实例转换为容器。使用应用程序运行程序来创建按需运行的容器作为作业来运行任务。",
      "C": "将任务复制到Lambda函数中。通过使用Amazon EventBridge事件来安排Lambda功能。",
      "D": "创建运行这些任务的EC2实例的Amazon机器映像。创建一个自动缩放组并与该组一起运行多个副本的实例。"
    },
    "vote_percentage": "65%",
    "tags": [
      "EC2",
      "Batch"
    ],
    "explanation": {
      "analysis": "考察了针对长时间运行的任务，如何提高性能和可伸缩性。",
      "why_correct": "A: 使用AWS Batch，可以提交作业，Batch会自动管理计算资源，并处理作业的调度和执行，满足性能和可伸缩性需求。",
      "why_wrong": "B: 将实例转换为容器，并不能解决性能问题，需要手动维护和扩展；C: Lambda 函数有执行时间限制，不适用于长时间运行的任务；D: 自动伸缩组仅用于弹性，无法解决任务调度问题。"
    },
    "related_terms": [
      "EC2",
      "AWS Batch",
      "Amazon EventBridge",
      "Lambda",
      "Amazon 机器映像",
      "自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 370,
    "topic": "",
    "question_cn": "一家公司在VPC中运行一个三级公共网络应用程序。该应用程序在Amazon EC2实例上跨多个可用性区域运行。在私有子网中运行的EC2实例需要通过互联网与许可证服务器进行通信。该公司需要一个管理解决方案，最大限度地减少业务维护。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在公共子网中提供NAT实例。用指向NAT实例的默认路由修改每个私有子网的路由表。",
      "B": "在私有子网中提供NAT实例。用指向NAT实例的默认路由修改每个私有子网的路由表。",
      "C": "在公共子网络中提供NAT网关。用指向NAT网关的默认路由修改每个私有子网的路由表。",
      "D": "在私人子网中提供NAT网关。用指向NAT网关的默认路由修改每个私有子网的路由表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC",
      "NAT Gateway"
    ],
    "explanation": {
      "analysis": "考察VPC中私有子网的互联网访问配置。",
      "why_correct": "C: NAT网关部署在公共子网，私有子网通过指向NAT网关的路由表访问互联网，满足需求。",
      "why_wrong": "A: NAT实例需要管理；B: NAT实例需要部署在公共子网，配置错误；D: NAT网关必须部署在公共子网。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "NAT",
      "NAT实例",
      "NAT网关"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 371,
    "topic": "",
    "question_cn": "一个公司需要创建一个亚马逊弹性库伯内特斯服务集群（EKS）以主办一个数字媒体流应用程序。 集群将使用一个受管理的节点组，该节点组由亚马逊弹性块存储（EBS） 亚马逊卷支持用于存储。公司必须使用存储在密钥管理服务中的客户管理密钥加密所有剩余数据。哪些操作组合将以最少的操作开销满足此需求（选二）。",
    "options_cn": {
      "A": "使用使用客户管理密钥执行数据加密的库伯内特斯插件。",
      "B": "创建 EKS 集群后定位 EBS 卷。使用客户管理密钥启用加密",
      "C": "默认情况下在创建 EKS 集群的区域中启用 EBS 加密。选择客户管理键作为默认键",
      "D": "创建 EKS 集群。创建一个 IAM 角色，该角色具有授予客户管理密钥权限的策略。将角色与集群联系起来。",
      "E": "在 EKS 集群中存储客户管理的密钥作为库伯内特斯机密。使用客户管理密钥加密 EBS 卷。"
    },
    "vote_percentage": "56%",
    "tags": [
      "EKS",
      "EBS Encryption"
    ],
    "explanation": {
      "analysis": "此题考察在EKS中使用客户管理密钥加密EBS卷。社区共识是，在创建EKS集群时启用EBS加密，并选择客户管理密钥。注意: 此题官方答案为AE，但社区共识(投票最高)为CD。社区倾向CD的原因是， CD 提供最便捷的方式进行EBS加密。",
      "why_correct": "选项C：在创建EKS集群时启用EBS加密，并选择客户管理密钥，这是最直接、最便捷的方式。选项D：创建IAM角色，授予KMS密钥权限，并将其关联到EKS集群，允许集群访问KMS密钥。这种方式实现了对KMS密钥的权限管理。",
      "why_wrong": "选项A：使用库伯内特斯插件，需要额外的配置，增加了复杂性。选项B：在集群创建后启用加密，需要额外操作。选项E：在集群中存储密钥不符合最佳实践。"
    },
    "related_terms": [
      "EKS",
      "EBS",
      "AWS KMS",
      "IAM",
      "客户管理密钥"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 372,
    "topic": "",
    "question_cn": "一家公司想将甲骨文数据库迁移到AWS。该数据库由一个单表组成，其中载有数百万张高分辨率的地理信息系统图像并通过地理代码加以识别。当自然灾害发生时，数以万计的图像每几分钟更新一次。每个地理代码都有一个与之相关的图像或行。该公司希望在此类事件中有一个高度可用和可伸缩的解决方案。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "将图像和地理代码存储在数据库表中，使用甲骨文运行在Amazon RDS多AZ数据库实例。",
      "B": "把这些图片存储在Amazon S3桶中。使用Amazon DynamoDB，以地理代码作为键和图像URL作为值。",
      "C": "将图像和地理代码存储在Amazon DynamoDB桌上。在高负荷时配置DynamoDB加速器（DAX）。",
      "D": "把这些图片存储在Amazon S3桶中。在数据库表中存储地理代码和图像URL。使用甲骨文运行在Amazon RDS多AZ数据库实例。"
    },
    "vote_percentage": "66%",
    "tags": [
      "DynamoDB",
      "S3"
    ],
    "explanation": {
      "analysis": "考察了针对频繁更新的图像存储和检索，如何选择合适的存储方案。",
      "why_correct": "B: 将图像存储在S3中，地理代码和图像URL作为DynamoDB的键值对，DynamoDB可以提供高可用性和可伸缩性。",
      "why_wrong": "A: RDS不适合频繁更新的图像存储；C: DAX 用于缓存 DynamoDB 的数据，不能直接存储图像；D: RDS 存储地理代码，S3存储图片，组合起来实现，效率较低。"
    },
    "related_terms": [
      "RDS",
      "S3",
      "DynamoDB",
      "DAX",
      "Multi-AZ"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 373,
    "topic": "",
    "question_cn": "一家公司有一个应用程序可以从汽车上的多用途传感器中收集数据。这些数据通过Amazon Kinesis Data Firehose在Amazon S3中进行流化和存储。这些数据每年产生数万亿个对象。每天早上公司都用过去30天的数据重新训练一套机器学习模型。该公司每年四次使用前12个月的数据进行分析和培训其他的ML模型。数据必须在最多一年的时间内尽可能少地提供。一年后必须保留这些数据以便存档。哪种存储方案最符合这些要求？",
    "options_cn": {
      "A": "使用S3智能层存储类。创建一个生命周期策略在一年后将目标转移到冰川深处档案库。",
      "B": "使用S3智能层存储类。配置S3智能层在一年后自动将物体转移到冰川深处档案库。",
      "C": "使用S3标准-不常访问（S3-IA）存储类。创建一个生命周期策略在一年后将目标转移到冰川深处档案库。",
      "D": "使用S3标准存储类。创建生命周期策略在30天后将目标转换为标准不经常访问（S3-IA），然后在1年后转换为冰川深度档案。"
    },
    "vote_percentage": "91%",
    "tags": [
      "S3 Storage Classes",
      "Lifecycle Policy"
    ],
    "explanation": {
      "analysis": "考察了S3存储类的选择和生命周期策略的使用，以满足不同数据访问频率和长期存储的需求。",
      "why_correct": "D: 使用S3标准存储类，保证短期内的数据访问；30天后转换为S3-IA，降低存储成本；1年后转换为Glacier Deep Archive，实现长期存档，符合题目需求。",
      "why_wrong": "A: 智能分层适合数据访问模式不确定的情况，不能满足30天内频繁访问的需求；B: 智能分层不适合一年内的频繁访问和一年后的存档需求；C: S3-IA不适合短期内频繁访问的需求。"
    },
    "related_terms": [
      "Kinesis Data Firehose",
      "S3",
      "S3智能层存储类",
      "S3 冰川深处档案库",
      "S3-IA",
      "S3标准"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 374,
    "topic": "",
    "question_cn": "一家公司正在美国东部1号地区三个独立的VPC中运行几个业务应用程序。应用程序必须能够在VPC之间进行通信。应用程序还必须能够始终如一地每天将数百千兆字节的数据发送到运行在一个内部数据中心中的对延迟敏感的应用程序。解决方案架构师需要设计一个能最大限度地提高成本效益的网络连接解决方案。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "配置从数据中心到VPC的三个站点到站点的VPN连接。通过为每个VPC配置一个VPN连接来建立连接。",
      "B": "在每个VPC中启动一个第三方虚拟网络设备。在数据中心和每个虚拟设备之间建立一个IPSEC VPN隧道。",
      "C": "在美国东部1号建立三个从数据中心直接连接到直接连接网关的Direct Connect。通过配置每个VPC使用其中一个Direct Connect连接来建立连接。",
      "D": "建立一个从数据中心到数据中心的Direct Connect连接。创建一个传送网关并将每个VPC连接到传送网关。在Direct Connect和中转网关之间建立连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Direct Connect",
      "Transit Gateway"
    ],
    "explanation": {
      "analysis": "考察了VPC互连和与本地数据中心的连接方案。",
      "why_correct": "D: 使用Direct Connect连接数据中心，使用Transit Gateway连接VPC，提供高吞吐量和高可用性，成本效益较高。",
      "why_wrong": "A: VPN连接带宽有限，不适合数百GB的数据传输；B: 第三方虚拟网络设备增加了复杂性，带宽有限；C: Direct Connect直接连接到每个VPC，管理复杂，成本高。"
    },
    "related_terms": [
      "VPC",
      "VPN",
      "Direct Connect",
      "Direct Connect 网关",
      "传送网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 375,
    "topic": "",
    "question_cn": "一家电子商务公司正在构建一个分布式应用程序，该应用程序涉及多个无服务功能和服务以完成订单处理任务。这些任务需要人工批准作为工作流程的一部分。解决方案架构师需要为订单处理应用程序设计一个架构。该解决方案必须能够将多个 Lambda 函数组合成响应的无服务应用程序。解决方案还必须对在亚马逊实例、容器或内部服务器上运行的数据和服务进行编排。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS 步骤函数构建应用程序。",
      "B": "将所有应用程序组件集成到 AWS 胶水作业中。",
      "C": "使用亚马逊简单队列服务构建应用程序。",
      "D": "使用 Lambda 函数和亚马逊 EventBridge 事件来构建应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Step Functions",
      "Serverless"
    ],
    "explanation": {
      "analysis": "此题考察如何设计一个工作流，其中包含人工审批，并结合多个Lambda函数。社区共识是使用AWS Step Functions。",
      "why_correct": "步骤函数最适合编排复杂的无服务器工作流，包括人工审核步骤。它提供了内置的状态管理和错误处理功能。",
      "why_wrong": "选项B:  AWS Glue主要用于数据转换和ETL，不适用于工作流编排。选项C:  SQS 主要用于消息队列，不具备工作流编排能力。选项D:  Lambda函数和EventBridge可以触发事件，但不如Step Functions方便编排复杂的流程，尤其是有用户审批的情况。"
    },
    "related_terms": [
      "Lambda",
      "AWS 步骤函数",
      "AWS 胶水",
      "Simple Queue Service",
      "EventBridge"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 376,
    "topic": "",
    "question_cn": "一家公司已经为RDS实例发布了一个亚马逊MySQL数据库。数据库的大部分连接来自无服务器应用程序。应用程序对数据库的流量在随机的时间间隔下发生显著变化。在需求量很大的时候用户报告他们的应用程序会经历数据库连接拒绝错误？用最少的操作开销来解决这个问题的解决方案是什么？",
    "options_cn": {
      "A": "在RDS代理中创建一个RDS数据库代理。通过数据库代理将用户的应用程序配置为使用RDS实例。",
      "B": "为用户应用程序和数据库实例之间的记忆存储部署亚马逊弹性计算。",
      "C": "将数据库实例迁移到具有更高I/O容量的不同实例类。将用户的应用程序配置为使用新的数据库实例。",
      "D": "为RDS实例配置多AZ。将用户的应用程序配置为在数据库实例之间切换。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Proxy",
      "Database Connection"
    ],
    "explanation": {
      "analysis": "考查如何使用 RDS Proxy 来解决数据库连接拒绝问题。由于数据库连接来自无服务器应用程序，并且流量波动较大，使用 RDS Proxy 可以有效管理数据库连接。",
      "why_correct": "选项 A 通过使用 RDS 代理来池化和复用数据库连接，减轻了数据库的负载，并提供了更好的可伸缩性和容错性。RDS 代理可以缓存数据库连接，从而减少应用程序与数据库之间的连接次数，提高性能。",
      "why_wrong": "选项 B 引入了不必要的复杂性，并且没有直接解决数据库连接问题。选项 C 仅升级了数据库实例的规格，没有解决连接限制问题，并且成本较高。选项 D 提供了高可用性，但没有解决数据库连接问题，并且需要更多的配置工作。"
    },
    "related_terms": [
      "RDS",
      "RDS 代理",
      "弹性计算",
      "I/O",
      "多AZ"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 377,
    "topic": "",
    "question_cn": "一家公司最近部署了一个新的审计系统来集中有关操作系统版本的信息为亚马逊EC2实例进行修补和安装软件。解决方案架构师必须确保所有通过自动缩放组提供的EC2实例一旦启动和终止就会成功地向审计系统发送报告？哪个解决方案能最有效地实现这些目标？",
    "options_cn": {
      "A": "使用计划的AWS Lambda函数并在所有EC2实例上远程运行脚本以将数据发送到审计系统。",
      "B": "使用EC2自动缩放生命周期挂钩运行自定义脚本以便在实例启动和终止时将数据发送到审计系统。",
      "C": "使用EC2自动缩放启动配置通过用户数据运行自定义脚本以便在启动和终止实例时将数据发送到审计系统。",
      "D": "在实例操作系统上运行自定义脚本将数据发送到审计系统。在实例启动和终止时配置将由EC2自动缩放组调用的脚本。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "Lifecycle Hooks"
    ],
    "explanation": {
      "analysis": "此题考察EC2 Auto Scaling的生命周期挂钩。生命周期挂钩允许在实例启动和终止过程中执行自定义操作，例如发送审计数据。",
      "why_correct": "选项 B 使用EC2自动缩放生命周期挂钩，能够在实例启动和终止时运行自定义脚本，从而满足需求，在实例启动和终止时将数据发送到审计系统。",
      "why_wrong": "选项 A 使用Lambda函数和计划任务，过于复杂，且需要额外的配置。选项 C 使用用户数据，用户数据只在实例启动时运行。选项 D 描述的方法虽然可行，但比使用生命周期挂钩更复杂，更容易出错，且需要更多维护。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "AWS Lambda",
      "生命周期挂钩",
      "用户数据"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 378,
    "topic": "",
    "question_cn": "一家公司正在开发一个实时的多人游戏，它使用UDP在一个自动缩放组的客户机和服务器之间进行通信。预计白天需求会激增，所以游戏服务器平台必须相应调整。开发人员希望在数据库解决方案中存储游戏玩家得分和其他非相关数据，这种解决方案将在没有干预的情况下进行规模化？解决方案架构师应该推荐哪种解决方案？",
    "options_cn": {
      "A": "使用亚马逊Route 53线路进行流量分布和亚马逊极光无服务器数据存储。",
      "B": "使用网络负载平衡器进行流量分配和亚马逊DynamoDB按需存储数据。",
      "C": "使用网络负载平衡器进行流量分布和亚马逊极光全球数据库进行数据存储。",
      "D": "使用应用程序负载平衡器进行流量分布和亚马逊DynamoDB全局表进行数据存储。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Game Server",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此题考查如何为实时多人游戏设计架构，包括流量分配和数据存储。需要能够弹性伸缩并且支持高并发的存储方案，并且游戏服务器使用UDP协议，通常使用网络负载均衡器。",
      "why_correct": "选项 B 使用网络负载平衡器（Network Load Balancer）进行流量分配，能够处理 UDP 流量，并且使用 DynamoDB 按需模式存储数据，DynamoDB 能够弹性伸缩且适合存储游戏分数等非关键数据。",
      "why_wrong": "选项 A 使用 Route 53 进行流量分发，不适合 UDP 流量。选项 C 的 Aurora Global Database 适用于需要跨区域复制的应用，对于本题需求过于复杂。选项 D 使用应用程序负载均衡器（Application Load Balancer），不直接支持 UDP，并且 DynamoDB 全局表会增加复杂性，对于此应用场景不合适。"
    },
    "related_terms": [
      "UDP",
      "Route 53",
      "Aurora Serverless",
      "网络负载平衡器",
      "DynamoDB",
      "Aurora 全球数据库",
      "应用程序负载平衡器",
      "DynamoDB 全局表"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 379,
    "topic": "",
    "question_cn": "一个公司拥有一个前端应用程序，它使用一个亚马逊 API 网关后端，该后端与 Lambda 集成。当 API 网关接收请求时， Lambda 函数加载了许多库。然后 Lambda 函数连接到亚马逊 RDS 数据库处理数据并将数据返回到前端应用程序。该公司希望确保其所有用户的响应延迟尽可能低而该公司的业务变化最少。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在前置应用程序和数据库之间建立连接通过绕过 Lambda 来更快地进行查询。",
      "B": "配置处理请求的 Lambda 函数的已配置并发。",
      "C": "在亚马逊 S3 中缓存查询结果以更快地检索类似数据集。",
      "D": "增加数据库的规模，增加兰布达一次性可以建立的连接数量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "Caching"
    ],
    "explanation": {
      "analysis": "此题考察如何优化API的响应延迟。社区共识是配置Lambda函数的已配置并发。注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，Lambda的并发是优化响应速度的关键因素。",
      "why_correct": "配置Lambda函数的已配置并发可以确保Lambda函数有足够的资源来处理请求，从而减少延迟。",
      "why_wrong": "选项A:  绕过Lambda函数直接访问数据库会破坏现有架构，不符合题目要求。选项C:  缓存可以提高读取性能，但不如配置并发直接。选项D:  增加数据库规模和Lambda连接数，并不能直接减少延迟，还会增加成本。"
    },
    "related_terms": [
      "API 网关",
      "Lambda",
      "RDS",
      "S3",
      "Lambda 函数",
      "并发"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 380,
    "topic": "",
    "question_cn": "一家公司正在将其公司内部的工作量转移到云端。该公司已经使用了几个亚马逊 EC2 实例和亚马逊 RDS 数据库实例。该公司希望有一个解决方案可以在工作时间之外自动启动和停止 EC2 实例和 RDS 实例。解决方案必须将成本和基础设施维护降到最低。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "用弹性调整尺寸来测量 EC2 实例。在工作时间之外将 EC2 实例扩展到零。",
      "B": "探索市场的合作伙伴解决方案，它将自动启动和停止 EC2 实例和 RDS 实例和日程表上的实例。",
      "C": "启动另一个 EC2 实例。配置一个 龙选项卡日程表来运行将启动和停止现有的 EC2 实例和日程表上的 RDS 实例的壳牌脚本。",
      "D": "创建一个 Lambda 函数，它将启动和停止 EC2 实例和 RDS 实例。配置亚马逊事件桥调用一个时间表上的 Lambda 函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "此题考察如何实现EC2和RDS实例的自动启动和停止，并最小化成本。社区共识是使用Lambda函数和EventBridge。注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是， D选项是经济高效、易于维护的解决方案。",
      "why_correct": "选项D: Lambda函数可以通过编程方式启动和停止EC2和RDS实例。EventBridge可以按照预定的时间表触发Lambda函数，实现自动化。该方案成本较低，维护简单。",
      "why_wrong": "选项A:  弹性伸缩不适用于关闭实例，只能缩减到0。选项B:  第三方解决方案增加了复杂性和成本。选项C:  额外的EC2实例和Shell脚本比Lambda函数更难维护。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "弹性",
      "Lambda",
      "事件桥"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 381,
    "topic": "",
    "question_cn": "一个公司拥有一个三层的 Web 应用程序，其中包括一个 PostgreSQL 数据库。数据库存储来自文档的元数据。公司在元数据中搜索关键术语以检索公司每月在报告中审查的文件。这些文件存放在亚马逊 S3 中。文件通常只写一次但经常更新。使用关系查询报告过程需要几个小时。报告程序不得阻止任何文件修改或添加新文件。解决方案架构师需要实现一个解决方案来加速报告过程。哪个解决方案能满足这些要求对应用程序代码的更改最少？",
    "options_cn": {
      "A": "建立一个新的亚马逊文档数据库集群，具有 MongoDB 兼容性，其中包括一个读副本。扩展读取副本以生成报表。",
      "B": "建立一个新的亚马逊极光后行的数据库集群，其中包括一个极光副本。向极光副本发出查询以生成报表。",
      "C": "建立一个新的亚马逊 RDS 为后 格拉多 数据库实例。配置报告模块来查询次级 RDS节点以便报告模块不影响主节点。",
      "D": "建立一个新的亚马逊 DynamoDB 台来存储文档。使用固定的写入容量来支持新的文档条目 自动扩大支持报告的阅读能力。"
    },
    "vote_percentage": "94%",
    "tags": [
      "RDS",
      "Read Replica"
    ],
    "explanation": {
      "analysis": "此题考察如何加速报告生成，同时不影响现有系统。社区共识是使用RDS的读副本。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，读副本可以实现不影响主数据库的读取操作。",
      "why_correct": "选项B:  使用Aurora读副本，可以分离读取流量，加速报告生成，且不影响主数据库的写入操作。是满足题目要求的理想解决方案。",
      "why_wrong": "选项A:  文档数据库与现有的PostgreSQL数据库不兼容，需要修改代码。选项C: RDS的多AZ可以提供高可用，但不是为了提升读取性能设计的。选项D:  使用DynamoDB存储文档，需要修改代码，并且不适用于关系查询。"
    },
    "related_terms": [
      "PostgreSQL",
      "MongoDB",
      "Amazon S3",
      "Read Replica",
      "Amazon Aurora",
      "Amazon RDS",
      "DynamoDB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 382,
    "topic": "",
    "question_cn": "一家公司在AWS上有三层应用程序，可以吸收用户设备中的传感器数据。流量通过一个网络负载平衡器，然后是EC2的网络层，最后是EC2的应用层。应用程序层对数据库进行调用？解决方案架构师应该如何改进传输中数据的安全性？",
    "options_cn": {
      "A": "配置TLS监听器。在NLB上部署服务器证书。",
      "B": "配置 AWS Shield Advanced. 在NLB上启用AWS WAF。",
      "C": "将负载平衡器更改为应用负载平衡器。使美国航空航天局在美国航空公司。",
      "D": "使用AWS Key Management Service（KMS）在EC2实例中加密亚马逊弹性块存储（EBS）亚马逊卷。"
    },
    "vote_percentage": "100%",
    "tags": [
      "TLS",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "此题考察如何保护网络流量的传输安全。使用 TLS 协议可以加密传输中的数据。",
      "why_correct": "选项 A 通过在 NLB 上配置 TLS 监听器，并在 NLB 上部署服务器证书，可以对传输中的数据进行加密，从而保证数据的安全性。",
      "why_wrong": "选项 B 侧重于保护应用程序免受 Web 攻击，而不是加密传输中的数据。选项 C 改变负载均衡器类型，对保护数据的传输没有直接的帮助。选项 D 加密 EBS 卷可以保护静态数据，但无法保护传输中的数据。"
    },
    "related_terms": [
      "TLS",
      "NLB",
      "AWS Shield Advanced",
      "AWS WAF",
      "Application Load Balancer",
      "AWS Key Management Service（KMS）",
      "Amazon Elastic Block Storage（EBS）"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 383,
    "topic": "",
    "question_cn": "一家公司正计划将一个现成的商业应用程序从其内部数据中心迁移到AWS。该软件有一个软件授权模型，使用可预测的容量和正常运行时间需求的接口和核心。该公司希望使用今年早些时候购买的现有许可证。哪个亚马逊EC2价格选择是最具成本效益的？",
    "options_cn": {
      "A": "专用保留主机",
      "B": "专用按需主机",
      "C": "专用保留实例",
      "D": "专用按需实例"
    },
    "vote_percentage": "89%",
    "tags": [
      "Dedicated Hosts",
      "Bring Your Own License (BYOL)"
    ],
    "explanation": {
      "analysis": "此题考察如何通过最有效的方式使用现有的软件许可证。 对于 BYOL 场景，需要使用专用主机。",
      "why_correct": "选项 A 使用专用保留主机，允许用户将现有的软件许可证迁移到AWS， 并且提供最经济的成本。",
      "why_wrong": "选项 B 和 D 使用按需实例，无法满足 BYOL 需求。选项 C 使用保留实例，但是不满足 BYOL 需求。"
    },
    "related_terms": [
      "Amazon EC2",
      "专用保留主机",
      "专用按需主机",
      "专用保留实例",
      "专用按需实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 384,
    "topic": "",
    "question_cn": "一家公司在亚马逊 EC2 实例上运行一个跨多个可用性区域的应用程序。该应用程序需要一个存储层是高度可用和可移植的操作 (POSIX) 系统接口兼容。存储层必须提供最大的数据耐久性并且必须在 EC2 实例中共享。存储层中的数据在头 30 天将经常被访问，在此之后将不经常被访问。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊 S3 标准存储类。创建一个生命周期策略将不经常访问的数据转移到 S3 冰川。",
      "B": "使用亚马逊 S3 标准存储类。创建一个生命周期策略将不经常访问的数据移动到 S3 标准 - 不经常访问。",
      "C": "使用亚马逊弹性文件系统 (EFS)。创建一个生命周期管理策略将不经常访问的数据转移到 EFS 标准不经常访问。",
      "D": "使用亚马逊弹性文件系统 (EFS)。创建一个生命周期管理策略将不经常访问的数据转移到 EFS 一个区域存储类。"
    },
    "vote_percentage": "93%",
    "tags": [
      "EFS",
      "Lifecycle Policy"
    ],
    "explanation": {
      "analysis": "此题考察如何选择存储方案以满足高可用性、可移植性、数据耐久性以及不同访问频率的需求。社区共识是使用EFS和生命周期策略来管理数据存储成本。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，EFS可以提供POSIX接口和共享存储。",
      "why_correct": "选项C：使用EFS可以满足POSIX接口和共享存储的需求。通过生命周期管理策略将不常访问的数据移动到EFS-IA可以优化存储成本。",
      "why_wrong": "选项A:  S3不提供POSIX接口。选项B: S3不提供POSIX接口。选项D: EFS一个区域存储类，不提供高可用性，不符合题干要求。"
    },
    "related_terms": [
      "Amazon EC2",
      "POSIX",
      "Amazon S3",
      "Amazon EFS",
      "S3 冰川",
      "EFS 标准不经常访问",
      "EFS 一个区域存储类"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 385,
    "topic": "",
    "question_cn": "解决方案架构师正在创建一个新的VPC设计。对于负载平衡器有两个公共子网，对于Web服务器有两个私有子网，对于MySQL服务器有两个私有子网。Web服务器只使用HTTPS 0.0.0.0/0 443端口。解决方案架构师已经为允许HTTPS端口的负载平衡器创建了一个安全组。公司策略要求每个资源，都要有最少的访问权才能继续执行任务？解决方案架构师应该使用哪种额外的配置策略来满足这些需求？",
    "options_cn": {
      "A": "为Web服务器创建一个安全组并允许HTTPS 0.0.0.0/0 443端口。为MySQL服务器创建一个安全组并允许来自Web服务器安全组的3306端口。",
      "B": "为Web服务器创建一个网络ACL并允许HTTPS 0.0.0.0/0 443端口。为MySQL服务器创建一个网络ACL并允许来自Web服务器安全组的3306端口。",
      "C": "为Web服务器创建一个安全组并允许从负载平衡器端口443端口。为MySQL服务器创建一个安全组并允许来自Web服务器安全组的端口3306端口。",
      "D": "为Web服务器创建一个网络ACL并允许从负载平衡器端口443端口。为MySQL服务器创建一个网络ACL并允许来自Web服务器安全组的端口3306端口。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Groups",
      "VPC Design"
    ],
    "explanation": {
      "analysis": "此题考察如何设计最小权限的 VPC 安全组。 负载均衡器已经开放了HTTPS 443 端口，需要对 Web 服务器和 MySQL 服务器配置安全组，以限制访问。",
      "why_correct": "选项 C 通过为 Web 服务器和 MySQL 服务器配置安全组，并允许来自负载均衡器的 443 端口流量以及来自Web服务器安全组的3306端口流量，来实现最小权限原则。使用安全组可以更灵活地控制流量，并且更易于管理。",
      "why_wrong": "选项 A 没有使用安全组，而是直接允许了所有流量，违反了最小权限原则。选项 B 和 D 使用网络 ACL，网络 ACL 过于复杂，并且无法满足最小权限原则。"
    },
    "related_terms": [
      "VPC",
      "HTTPS",
      "MySQL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 386,
    "topic": "",
    "question_cn": "一家电子商务公司正在运行一个多层次的应用程序。前端和后端层都运行在亚马逊EC2上，数据库运行在亚马逊RDS上的MySQL上。后端层与RDS实例通信。经常有从数据库返回相同数据集的调用导致性能下降？应该采取哪些行动来提高后端的性能？",
    "options_cn": {
      "A": "SRS实现亚马逊的存储数据库调用。",
      "B": "实现亚马逊灵活性以缓存大型数据集。",
      "C": "实现用于MySQL读取副本以缓存数据库调用。",
      "D": "实现Amazon Kinesis Data Firehose将调用流式传输到数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Caching",
      "MySQL Read Replica"
    ],
    "explanation": {
      "analysis": "此题考察如何通过缓存数据库查询结果来提高性能。",
      "why_correct": "选项 B 是最佳选择，在后端缓存大型数据集可以减少数据库的负载，从而提高性能。",
      "why_wrong": "选项 A 描述不清楚。 选项 C 使用 MySQL 读副本，读副本可以提高读取性能，但不能直接解决后端缓存的需求。选项 D 使用 Kinesis Data Firehose，这与提高数据库读取性能无关。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "SRS",
      "Amazon DynamoDB",
      "MySQL",
      "Kinesis Data Firehose"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 387,
    "topic": "",
    "question_cn": "一个新的员工加入了一个公司作为部署工程师。部署工程师将使用CloudFormation模板来创建多个AWS资源。解决方案架构师希望部署工程师执行工作活动，同时遵循最小特权原则？解决方案架构师应该采取哪些行动组合来实现这个目标？选二。",
    "options_cn": {
      "A": "请部署工程师使用AWS帐户根用户凭证来执行CloudFormation操作。",
      "B": "为部署工程师创建一个新的IAM用户并将IAM用户添加到一个附有电源用户策略的组中。",
      "C": "为部署工程师创建一个新的IAM用户并将IAM用户添加到附加了管理访问策略的组中。",
      "D": "为部署工程师创建一个新的IAM用户并将IAM用户添加到一个组中，该组具有一个IAM策略，该策略只允许CloudFormation操作。",
      "E": "为部署工程师创建一个IAM角色，以便使用该角色显式地定义CloudFormation堆栈和发射堆栈特有的权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "Least Privilege"
    ],
    "explanation": {
      "analysis": "此题考察如何使用 IAM 实现最小权限原则。",
      "why_correct": "选项 D 和 E 均符合最小权限原则。选项 D 通过创建一个 IAM 用户并将其添加到只允许 CloudFormation 操作的组中，限制了部署工程师的权限。选项 E 通过创建一个 IAM 角色，并明确定义 CloudFormation 堆栈和发射堆栈特有的权限，也满足最小权限原则。",
      "why_wrong": "选项 A 使用根用户，违背了最小权限原则。选项 B 使用 PowerUser 策略，权限过大。选项 C 使用管理访问策略，权限过大。"
    },
    "related_terms": [
      "CloudFormation",
      "IAM",
      "AWS帐户根用户",
      "IAM用户",
      "IAM策略",
      "CloudFormation堆栈",
      "IAM角色"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 388,
    "topic": "",
    "question_cn": "一家公司正在VPC中部署一个两级Web应用程序。网络层正在使用一个亚马逊EC2自动缩放组，它拥有跨越多个可用性区域的公共子网。MySQL数据库层由一个用于RDS实例的亚马逊MySQL数据库在单独的私有子网中组成。Web层需要访问数据库来检索产品信息。Web应用程序没有达到预期的效果。应用程序报告它无法连接到数据库，数据库已确认投入运行。网络ACL、安全组和路由表的 所有配置仍然处于默认状态？解决方案架构师应该推荐什么来修复应用程序？",
    "options_cn": {
      "A": "向私有子网的网络ACL添加一个明确的规则以允许来自EC2Web层的实例的流量。",
      "B": "在VPC路由表中添加一个路由以允许Web层的实例和数据库层之间的流量。",
      "C": "将Web层的EC2实例和数据库层的实例部署为两个独立的EC2实例并配置VPC窥视。",
      "D": "向数据库层的RDS实例的安全组添加入站规则以允许来自Web层安全组的流量。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Security Groups",
      "VPC Connectivity"
    ],
    "explanation": {
      "analysis": "此题考察如何解决Web应用程序无法连接到RDS数据库的问题。主要原因是安全组配置不正确，导致流量被阻止。",
      "why_correct": "选项 D 通过向数据库层的 RDS 实例的安全组添加入站规则，允许来自 Web 层安全组的流量，从而解决连接问题。",
      "why_wrong": "选项 A 和 B 都是针对网络 ACL 和路由表的，但题目描述了这些配置都处于默认状态，因此不可能是问题所在。选项 C 需要修改基础设施，并且引入了不必要的复杂性。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "MySQL",
      "RDS",
      "Web层",
      "MySQL",
      "Web层安全组"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 389,
    "topic": "",
    "question_cn": "一个公司有一个大型数据集用于其在线广告业务，存储在一个单一可用性区域的一个亚马逊 RDS MySQL 实例中。该公司希望业务报告查询的运行不会影响到生产 RDS 实例的编写操作。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "部署 RDS 读取副本来处理业务报告查询。",
      "B": "通过将该实例置于弹性负载平衡器后面水平地扩展该实例。",
      "C": "将 RDS 实例扩展到更大的实例类型以处理写入操作和查询。",
      "D": "在多个可用性区域中部署 RDS 实例以处理业务报告查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Read Replica",
      "MySQL"
    ],
    "explanation": {
      "analysis": "此题考察如何避免报表查询影响生产数据库的写入性能。社区共识是使用RDS的读副本。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，读副本可以实现不影响主数据库的读取操作。",
      "why_correct": "选项A:  部署RDS的读取副本，可以分担主实例的读取负载，从而避免业务报表查询影响生产数据库的写入操作。",
      "why_wrong": "选项B:  负载均衡主要用于高可用和负载分摊，不解决读取性能问题。选项C:  扩展实例规格可以提升性能，但无法避免读取操作影响写入操作。选项D:  多AZ部署主要为了高可用，不是为了优化读取性能而设计。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "RDS",
      "RDS 读取副本",
      "弹性负载平衡器",
      "可用性区域"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 390,
    "topic": "",
    "question_cn": "一家公司在亚马逊 EC2 实例中拥有一个三级电子商务应用程序。实例在应用程序负载平衡器后面的自动缩放组中运行。所有的电子商务数据都存储在一个亚马逊 RDS MySQL 数据库实例中。该公司希望在交易期间优化客户会话管理。应用程序必须长期存储会话数据。哪些解决方案能满足这些要求（选二）。",
    "options_cn": {
      "A": "打开 ALB 上的粘会话功能。",
      "B": "使用亚马逊 DynamoDB 表存储客户会话信息。",
      "C": "部署一个亚马逊密码用户池来管理用户会话信息。",
      "D": "为雷迪斯集群部署一个亚马逊弹性系统来存储客户会话信息。",
      "E": "在应用程序中使用 AWS 系统管理器应用程序管理器来管理用户会话信息。"
    },
    "vote_percentage": "44%",
    "tags": [
      "ALB Sticky Sessions",
      "ElastiCache"
    ],
    "explanation": {
      "analysis": "此题考察如何优化客户会话管理。社区共识是使用ALB的会话保持和ElastiCache来存储会话数据。注意: 此题官方答案为BD，但社区共识(投票最高)为AD。社区倾向AD的原因是，通过负载均衡器实现会话粘滞， 并使用Redis集群存储会话数据， 是最常见的方案。",
      "why_correct": "选项A：开启ALB的粘性会话，保证用户的请求被发送到同一个EC2实例，这样可以保持用户的会话。选项D：使用ElastiCache for Redis集群来存储客户会话信息，实现快速访问和持久化。",
      "why_wrong": "选项B: DynamoDB不适合存储会话数据。选项C: 用户池用于用户身份验证和授权，不是存储会话数据的方案。选项E: 系统管理器应用程序管理器不适合用于存储会话数据。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "自动缩放组",
      "RDS",
      "MySQL",
      "粘会话",
      "Amazon DynamoDB",
      "亚马逊密码用户池",
      "雷迪斯集群",
      "AWS 系统管理器应用程序管理器"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 391,
    "topic": "",
    "question_cn": "一个 Web 应用程序需要一个三级无状态 Web 应用程序的备份策略。 应用程序在一个自动缩放组中的亚马逊 EC2 实例中运行，它具有响应缩放事件的动态缩放策略。数据库层在亚马逊 RDS 上运行用于 PostgreSQL。 Web 应用程序不需要 EC2 实例上的临时本地存储。公司的恢复点 2 目标是 小时。对于这种环境备份策略必须最大限度地提高可伸缩性并优化资源利用率。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "以亚马逊弹性块存储（EBS） 亚马逊卷的 EC2 实例和数据库的快照每 2 小时满足 RTO。",
      "B": "配置快照生命周期策略以使用亚马逊弹性块存储（EBS） 快照。启用亚马逊 RDS 中的自动备份以满足 RTO。",
      "C": "保留最新的亚马逊机器图像 (AMI) 的 Web 和应用层。在亚马逊 RDS 中启用自动备份并使用点时恢复来满足 RTO。",
      "D": "以亚马逊弹性块商店（EBS） 亚马逊卷的 EC2 实例的快照每 2 小时。在亚马逊 RDS 中启用自动备份并使用点时恢复来满足 RTO。"
    },
    "vote_percentage": "87%",
    "tags": [
      "RDS Backup",
      "EC2 AMI"
    ],
    "explanation": {
      "analysis": "此题考察备份策略的设计，包括RTO和可伸缩性。社区共识是，使用AMI备份应用层，使用RDS自动备份和Point-in-time恢复。注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，更全面的涵盖了备份和恢复的方案。",
      "why_correct": "选项C：AMI备份Web应用层，确保了RTO要求。使用RDS自动备份和PITR，满足了RTO要求，保证了数据库的恢复。这种方案也易于维护和扩展。",
      "why_wrong": "选项A:  仅仅快照EC2和数据库，不能满足更快的恢复需求，恢复速度慢。选项B:  EBS快照只是存储了数据，不能满足Web应用层的恢复需求。选项D:  EBS快照仅仅存储了EC2 实例的数据，恢复周期慢。"
    },
    "related_terms": [
      "Web 应用程序",
      "自动缩放组",
      "EC2",
      "RDS",
      "PostgreSQL",
      "弹性块存储（EBS）",
      "快照",
      "快照生命周期策略",
      "RDS",
      "AMI",
      "点时恢复"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 392,
    "topic": "",
    "question_cn": "一家公司想在AWS EC2上部署一个新的公共网站应用程序。该应用程序包括一个使用亚马逊EC2实例的Web服务器层。该应用程序还包括RDS mysqdb数据库层，该层使用亚马逊RDS实例。对于具有动态IP地址的全球客户来说应用程序必须是安全和可访问的。解决方案架构师应该如何配置安全组以满足这些需求？",
    "options_cn": {
      "A": "配置Web服务器的安全组以允许从0.0.0/0在443端口上的入站流量。为RDS实例配置安全组以允许来自Web服务器安全组的端口3306上的入站流量。",
      "B": "配置网络服务器的安全组以允许从客户的IP地址进入端口443的流量。为RDS实例配置安全组以允许来自Web服务器安全组的端3306端口上的入站流量。",
      "C": "配置网络服务器的安全组以允许从客户的IP地址进入端口443的流量。为RDS实例配置安全组以允许来自客户IP地址的端口3306上的入站流量。",
      "D": "配置Web服务器的安全组以允许从0.0.0/0在443端口上的入站流量。为RDS实例配置安全组以允许端口3306上的入站流量。"
    },
    "vote_percentage": "83%",
    "tags": [
      "Security Group",
      "Web Application Security"
    ],
    "explanation": {
      "analysis": "考查安全组配置，特别是入站规则和不同安全组之间的依赖关系。",
      "why_correct": "A，开放443端口允许外部访问Web服务器，允许3306端口流量仅来自Web服务器的安全组，符合安全最佳实践。",
      "why_wrong": "B，允许特定IP访问不具有通用性，C，数据库端口对客户IP开放不安全，D，RDS实例的入站规则没有限定来源。"
    },
    "related_terms": [
      "AWS EC2",
      "Web",
      "RDS",
      "mysqdb",
      "RDS",
      "HTTPS",
      "MySQL",
      "安全组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 393,
    "topic": "",
    "question_cn": "一家支付处理公司记录所有与客户的语音通信并将音频文件存储在一个亚马逊S3桶中。公司需要从音频文件中捕捉文本。公司必须从文本中删除属于客户的任何个人识别信息。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用亚马逊运动视频流处理音频文件。使用一个Lambda函数扫描已知的PII模式。",
      "B": "当一个音频文件被上传到S3桶时调用一个Lambda函数来启动一个Amazon Transcribe任务来分析调用记录。",
      "C": "配置Amazon Transcribe工作与PII编辑打开。当一个音频文件被上传到S3桶调用一个Lambda函数启动转录工作。将输出存储在一个S3桶中。",
      "D": "创建一个亚马逊连接接触流吸收音频文件与转录打开。嵌入一个Lambda函数扫描已知的PII模式。当音频文件被上传到S3桶时使用亚马逊事件桥启动联系流。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Transcribe",
      "PII Redaction"
    ],
    "explanation": {
      "analysis": "考查语音转录，PII识别及删除，以及S3事件触发Lambda的流程。",
      "why_correct": "C，使用Amazon Transcribe，配置PII编辑，可以实现语音转录，并自动删除PII。S3事件触发Lambda启动转录任务，架构简洁高效。",
      "why_wrong": "A，使用Amazon Kinesis Video Streams处理音频文件，不适合该场景。B，缺少PII处理。D，Amazon Connect不适用于异步处理存储在S3中的音频文件。"
    },
    "related_terms": [
      "Amazon S3",
      "Lambda",
      "Amazon Transcribe",
      "PII",
      "Amazon Connect",
      "Amazon EventBridge"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 394,
    "topic": "",
    "question_cn": "一家公司正在运行一个多层次的电子商务网络应用程序。该应用程序在亚马逊 EC2 实例上运行，其中有一个用于 MySQL 数据库实例的亚马逊 RDS 数据库。亚马逊 RDS 配置了最新一代数据库实例存储在通用 亚马逊弹性块存储（EBS） 卷。数据库性能在高需求期间影响应用程序。数据库管理员分析了亚马逊云观察日志中的日志，发现当读写 ips 的数量超过 20,000 时，应用程序性能总是下降。 解决方案架构师应该如何改进应用程序性能？",
    "options_cn": {
      "A": "用磁体来替换音量",
      "B": "增加 Gp3 卷上的国际采购方案。",
      "C": "将该卷替换为预置的 SSD(io2) 卷。",
      "D": "用两个 1000GB Gp3 卷替换 2000GB Gp3 卷。"
    },
    "vote_percentage": "40%",
    "tags": [
      "EBS",
      "Provisioned IOPS"
    ],
    "explanation": {
      "analysis": "此题考察如何优化RDS数据库的I/O性能。社区共识是，使用预置的IOPS(io2)卷。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是， 通过增加 EBS 卷的数量，可以增加IOPS，解决性能问题。",
      "why_correct": "选项D:  增加 EBS 卷的数量可以增加IOPS，可以解决性能问题。选项C: 使用预置的IOPS(io2)卷，可以提供更好的IOPS，适用于高I/O负载的场景。",
      "why_wrong": "选项A:  磁盘磁体性能差，不适用于生产环境。选项B:  调整IOPS不一定能解决问题。"
    },
    "related_terms": [
      "EBS",
      "RDS",
      "MySQL",
      "Amazon CloudWatch",
      "gp3",
      "io2"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 395,
    "topic": "",
    "question_cn": "上周在一次生产部署中，IAM用户对其公司帐户中的 AWS资源进行了几次配置更改。解决方案架构师了解到一些安全组规则没有按需配置。解决方案架构师希望确认是哪个IAM用户负责进行更改。解决方案架构师应该使用哪种服务来寻找所需的信息？",
    "options_cn": {
      "A": "Amazon GuardDuty",
      "B": "Amazon Inspector",
      "C": "CloudTrail",
      "D": "AWS美国宇航协会"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS CloudTrail",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。CloudTrail 能够记录对AWS资源的API调用，因此可以用于审计用户操作，确定谁更改了安全组规则。",
      "why_correct": "CloudTrail记录了对AWS账户的API调用，包括配置更改，可以追踪到导致安全组规则更改的IAM用户。",
      "why_wrong": "Amazon GuardDuty用于威胁检测，Amazon Inspector用于漏洞扫描，它们都不能直接用于审计用户操作。AWS美国宇航协会不是有效选项。"
    },
    "related_terms": [
      "IAM",
      "AWS",
      "Amazon GuardDuty",
      "CloudTrail",
      "AWS SAA"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 396,
    "topic": "",
    "question_cn": "一家公司已经在AWS Route 53上实现了一个自我管理的DNS服务。解决办法包括：*亚马逊生态系统在不同AWS区域的实例；*全球加速器的标准加速器端点；*DDOS攻击。该公司希望保护解决方案不受DDOS攻击。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "订阅AWS Shield Advanced。添加加速器作为保护资源。",
      "B": "订阅AWS Shield Advanced。添加EC2实例作为保护资源。",
      "C": "创建一个包含基于费率的规则的Web ACL。将Web ACL与加速器联系起来。",
      "D": "创建一个包含基于费率的规则的Web ACL。将Web ACL与EC2实例关联起来。"
    },
    "vote_percentage": "96%",
    "tags": [
      "AWS Shield",
      "DDoS Protection"
    ],
    "explanation": {
      "analysis": "考查DDoS攻击防护，以及AWS Shield Advanced的使用。",
      "why_correct": "A，使用AWS Shield Advanced，并将其与Global Accelerator关联，可以提供DDoS防护。",
      "why_wrong": "B，AWS Shield Advanced 需要与实际的保护资源关联，而不是EC2实例。C、D，Web ACL与Global Accelerator配合使用，但如果没有开启高级防护，效果会大打折扣。"
    },
    "related_terms": [
      "Route 53",
      "DNS",
      "AWS",
      "全球加速器",
      "DDOS",
      "AWS Shield Advanced",
      "Web ACL",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 397,
    "topic": "",
    "question_cn": "一家电子商务公司需要运行一个预定的日常工作以收集和筛选销售记录的分析。该公司将销售记录存放在亚马逊S3桶中。每个对象10GB，CPU，.的大小可达。根据销售活动的数量这项工作可能需要一个小时才能完成。工作的CPU和内存的使用是常量的是预先知道的。解决方案架构师需要最小化运行任务所需的操作工作量。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个具有亚马逊事件桥通知的Lambda函数。安排每天一次的事件。",
      "B": "创建一个Lambda函数。创建一个亚马逊API网关并将其与该功能集成。创建一个API调用并调用函数的亚马逊事件。",
      "C": "创建一个亚马逊弹性容器服务集群（ECS），带有亚马逊ECS Fargate发射类型。创建一个亚马逊事件桥计划的事，ECS事件启动集群上的一个任务来运行任务。",
      "D": "创建一个具有亚马逊EC2发射类型和至少一个EC2实例的自动缩放组的亚马逊弹性容器服务集群。创建一个亚马逊事件桥，ECS计划的事件启动集群上的一个任务来运行任务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS Fargate",
      "Scheduled Task"
    ],
    "explanation": {
      "analysis": "考查预定任务的运行方式，以及ECS Fargate的适用场景。需要最小化操作工作量",
      "why_correct": "C，使用ECS Fargate，无需管理底层EC2实例，操作工作量最少。通过事件桥触发定时任务。",
      "why_wrong": "A，Lambda不适合处理长时间运行的任务，可能超时。B，复杂化架构，操作复杂。D，EC2 维护成本高，不符合最小化操作工作量的要求。"
    },
    "related_terms": [
      "Amazon S3",
      "Lambda",
      "Amazon API网关",
      "Amazon EventBridge",
      "ECS",
      "ECS Fargate",
      "EC2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 398,
    "topic": "",
    "question_cn": "一家公司需要将600TB的数据从其内部网络连接存储系统(NAS)传输到AWS云。数据传输必须在两周内完成。数据是敏感的，必须在传输过程中加密。该公司的互联网连接可以支持100Mbps的上传速度。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "使用Amazon S3多部分上传功能以HTTPS转移文件。",
      "B": "在NAS系统和最近的AWS区域之间创建一个VPN连接。将数据传输到VPN连接上。",
      "C": "使用AWS Snow Family控制台订购几个Snowball Edge存储优化设备。使用这些设备将数据传输到Amazon S3。",
      "D": "在公司的位置和最近的AWS区域之间建立一个10Gbps的直接连接。通过Direct Connect连接将数据传输到该区域以便在Amazon S3中存储数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Snowball Edge",
      "S3 Transfer Acceleration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。Snowball Edge 适合大批量数据的离线传输，满足时间限制和加密需求。",
      "why_correct": "Snowball Edge是为大规模数据迁移设计的，满足了数据量大、传输时间短、需要加密的要求。Snowball Edge支持离线运输，可以绕过100Mbps的带宽限制。",
      "why_wrong": "选项A: 100Mbps的上传速度对于600TB的数据传输来说时间过长。选项B: 建立VPN虽然安全，但上传速度受限于100Mbps。选项D: Direct Connect虽然速度快，但部署时间长，成本高，且不满足两周内完成的要求。"
    },
    "related_terms": [
      "NAS",
      "AWS",
      "Amazon S3",
      "HTTPS",
      "VPN",
      "AWS Snow Family",
      "Snowball Edge",
      "Direct Connect"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 399,
    "topic": "",
    "question_cn": "一家金融公司在AWS上拥有一个网络应用程序。该应用程序使用亚马逊API网关区域端点使用户能够检索当前股价。该公司的安全团队注意到API请求的数量有所增加。安全团队担心洪水攻击可能会使应用程序脱机。解决方案架构师必须设计一个解决方案来保护应用程序不受这种类型的攻击。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在API网关区域端点前创建一个亚马逊云端分布，最大TTL为24小时。",
      "B": "创建一个基于费率规则的区域性的Web ACL。将Web ACL与API网关阶段联系起来。",
      "C": "使用亚马逊云表度量来监控计数度量并在达到预先定义的速率时通知安全小组。",
      "D": "在API网关区域端点前创建一个亚马逊云端分布。创建一个Lambda函数以阻止来自超过预定速率的IP地址的请求。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Rate Limiting",
      "Web ACL"
    ],
    "explanation": {
      "analysis": "考查API网关的保护，防止洪水攻击的解决方案。",
      "why_correct": "B，使用Web ACL，配置基于费率的规则，可以限制API请求频率，防止攻击。",
      "why_wrong": "A，CloudFront缓存无法有效限制请求速率。C，云表监控不能直接阻止攻击。D，Lambda限制IP需要额外配置和运维。"
    },
    "related_terms": [
      "AWS",
      "API网关",
      "亚马逊云端分布",
      "Web ACL",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 400,
    "topic": "",
    "question_cn": "一家气象创业公司有一个定制的网络应用程序可以在网上向用户出售天气数据。该公司使用亚马逊DynamoDB存储其数据，并希望建立一个新服务，每次记录新的天气事件时向四个内部团队的经理发出警报。公司不希望这项新服务影响当前应用程序的性能。解决方案架构师应该如何用最少的操作开销来满足这些需求？",
    "options_cn": {
      "A": "使用DynamoDB事务向表写入新的事件数据。配置事务通知内部团队。",
      "B": "让当前的应用程序发布一条消息到四个亚马逊简单通知服务（SNS）主题。让每个团队订阅一个主题。",
      "C": "使亚马逊DynamoDB流在桌上。使用触发器写入到一个亚马逊简单通知服务（SNS）主题，团队可以订阅该主题。",
      "D": "向每个记录添加自定义属性以标记新项。编写一个Cron作业每分钟扫描表中的新项目并通知一个亚马逊简单队列服务(SQS) 队列，团队可以订阅该队列。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB Streams",
      "SNS"
    ],
    "explanation": {
      "analysis": "考查DynamoDB数据变更的通知机制，以及最小化操作开销的需求。",
      "why_correct": "C，使用DynamoDB Streams捕获数据变化，触发SNS通知，可以实现实时通知，且不影响原有应用性能。",
      "why_wrong": "A，DynamoDB事务不适合此场景。B，应用直接发布SNS，耦合度高，不推荐。D，轮询SQS，开销大，延迟高。"
    },
    "related_terms": [
      "DynamoDB",
      "SNS",
      "SNS",
      "DynamoDB",
      "SQS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 401,
    "topic": "",
    "question_cn": "一个公司希望使用AWS云使现有的应用程序具有高度的可用性和弹性。该应用程序的当前版本位于该公司的数据中心。应用程序最近在数据库服务器因意外断电而崩溃后经历了数据丢失。公司需要一个避免任何单一失败点的解决方案。解决方案必须使应用程序有能力扩展以满足用户的需求。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "通过在多个可用性区的自动缩放组中使用亚马逊EC2实例来部署应用服务器。在多AZ配置中使用亚马逊RDS数据库实例。",
      "B": "通过在单个可用性区域的自动缩放组中使用亚马逊EC2实例来部署应用服务器。在EC2实例上部署数据库。启动自动恢复。",
      "C": "通过在多个可用性区的自动缩放组中使用亚马逊EC2实例来部署应用服务器。在一个可用性区域中使用具有读副本的亚马逊RDS数据库实例。如果主数据库实例失败，则促进读取副本以替换主数据库实例。",
      "D": "通过在多个可用性区的自动缩放组中使用亚马逊EC2实例来部署应用服务器。跨多个可用性区在EC2实例上部署主数据库服务器和二级数据库服务器。使用亚马逊EBS创建实例之间的共享存储。"
    },
    "vote_percentage": "90%",
    "tags": [
      "High Availability",
      "RDS Multi-AZ"
    ],
    "explanation": {
      "analysis": "考查高可用性架构，数据库的容灾方案。",
      "why_correct": "A，应用服务器使用自动伸缩组和多AZ配置提供高可用性，RDS使用Multi-AZ，提供数据库的容灾。",
      "why_wrong": "B，数据库没有高可用性。C，读副本不是高可用性。D，共享存储不可靠。"
    },
    "related_terms": [
      "EC2",
      "可用性区",
      "自动缩放组",
      "RDS",
      "多AZ",
      "读副本",
      "EBS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 402,
    "topic": "",
    "question_cn": "一家公司需要吸收和处理大量的流数据其应用程序生成。该应用程序在亚马逊EC2实例上运行并将数据发送到亚马逊Kinesis数据流，该数据流配置为默认设置。每隔一天应用程序就会消耗数据并将数据写入一个亚马逊S3桶用于业务智能（BI）处理。该公司观察到亚马逊S3并没有接收到应用程序发送到Kinesis数据流的所有数据。解决方案架构师应该如何解决这个问题？",
    "options_cn": {
      "A": "通过修改数据保留期更新Kinesis数据流默认设置。",
      "B": "更新应用程序使用Kinesis生产者库将数据发送到Kinesis数据流。",
      "C": "更新Kinesis碎片（Shards）的数量来处理发送到Kinesis数据流的数据的吞吐量。",
      "D": "打开S3桶中的版本控制功能以保存S3桶中吸入的每个对象的每个版本。"
    },
    "vote_percentage": "64%",
    "tags": [
      "Kinesis Data Streams",
      "Kinesis Producer Library"
    ],
    "explanation": {
      "analysis": "考查Kinesis数据流的数据丢失问题和解决方案，可能由于吞吐量不足或数据保留时间过短导致。",
      "why_correct": "A，调整数据保留期可以保证数据流中的数据能够被下游消费者消费。",
      "why_wrong": "B，使用Kinesis Producer Library可以提高性能，但不能解决数据丢失的问题。C，调整碎片数量可以解决吞吐量问题，但不是根本原因。D，S3版本控制与数据丢失无关。"
    },
    "related_terms": [
      "EC2",
      "Kinesis",
      "S3",
      "Kinesis数据流",
      "碎片（Shards）",
      "版本控制"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 403,
    "topic": "",
    "question_cn": "开发人员有一个应用程序，该应用程序使用Lambda功能向Amazon S3上传文件，并需要执行任务所需的IAM权限。开发人员已经有了一个具有Amazon S3所需有效凭证的IAM用户。解决方案架构师应该如何授予权限？",
    "options_cn": {
      "A": "在Lambda函数的资源策略中添加所需的IAM权限。",
      "B": "使用Lambda函数中的现有IAM凭证创建一个签名请求。",
      "C": "创建一个新的IAM用户并使用Lambda函数中现有的IAM凭证。",
      "D": "创建一个具有所需IAM权限的IAM执行角色并将该角色附加到Lambda函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda IAM Role",
      "S3 Permissions"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。给Lambda函数分配IAM角色是最安全和推荐的方式，而不是直接在资源策略中添加权限。",
      "why_correct": "为Lambda函数创建一个IAM执行角色，赋予其访问S3的权限，并将该角色附加到Lambda函数，这是AWS的最佳实践。这避免了直接在函数代码中嵌入凭证，提高了安全性。",
      "why_wrong": "选项A: 在Lambda函数的资源策略中添加权限不是推荐的做法，容易导致权限管理复杂。选项B: 使用现有IAM用户的凭证创建签名请求，安全性较差。选项C: 创建新的IAM用户并使用Lambda函数中现有凭证，违背最佳实践，不安全。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "IAM",
      "IAM用户",
      "IAM执行角色"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 404,
    "topic": "",
    "question_cn": "一个公司已经部署了一个无服务器的应用程序，当新的文档被上传到亚马逊S3桶中时，它调用了一个Lambda函数。该应用程序使用Lambda函数来处理文档。在最近的一次营销活动之后，该公司注意到该应用程序没有处理许多文件。解决方案架构师应该做什么来改进这个应用程序的架构？",
    "options_cn": {
      "A": "将Lambda函数的运行时超时值设置为15分钟。",
      "B": "配置一个S3桶复制策略。将文档放在S3桶中供以后处理。",
      "C": "部署一个额外的Lambda函数。负载平衡跨两个Lambda函数处理文档。",
      "D": "创建一个亚马逊简单队列服务(SQS)队列。将请求发送到队列中。将队列配置为Lambda的事件源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "SQS",
      "S3 Event"
    ],
    "explanation": {
      "analysis": "考查Lambda并发限制和S3事件触发问题。",
      "why_correct": "D，使用SQS队列作为Lambda函数的事件源，可以缓解并发限制，并提供异步处理能力，保证所有文件都被处理。",
      "why_wrong": "A，增加超时时间，可能没有根本解决问题。B，S3复制策略与并发处理无关。C，增加Lambda函数，也不能解决并发限制问题。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "S3桶",
      "SQS",
      "事件源"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 405,
    "topic": "",
    "question_cn": "解决方案架构师正在设计软件演示环境的架构。环境将运行在Amazon EC2实例中，在应用程序负载平衡器后面的一个自动缩放组中。该系统在工作时间内的流量将大幅增加，但不需要在周末运行。解决方案架构师应该采取哪些组合行动来确保系统能够扩展以满足需求(选二)。",
    "options_cn": {
      "A": "根据请求率使用自动缩放来调整EC2容量。",
      "B": "使用VPC自动缩放来扩展互联网网关的容量。",
      "C": "在多个AWS区域启动EC2实例以将负载分布到不同区域。",
      "D": "根据实例CPU利用率使用目标跟踪扩展策略来扩展自动缩放组。",
      "E": "使用预定的缩放来改变自动缩放组的最小、最大和所需的容量，使之在周末为零，在本周开始时恢复到默认值。"
    },
    "vote_percentage": "63%",
    "tags": [
      "Auto Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为DE。DE都属于常见的自动缩放策略，用于调整容量，满足流量变化和周末停机的需求。",
      "why_correct": "D: 基于CPU利用率的目标跟踪策略可以根据负载情况动态调整实例数量。E: 预定的缩放可以在周末将实例数量设置为零，节省成本。",
      "why_wrong": "选项A: 根据请求率进行缩放是有效的，但D选项更为具体，也常用。选项B: 扩展互联网网关容量通常不是扩展EC2实例的直接方式。选项C: 在多个区域启动实例是一种容灾策略，不是满足负载变化的主要方式。"
    },
    "related_terms": [
      "EC2",
      "负载均衡器",
      "自动缩放组",
      "VPC",
      "自动缩放",
      "自动缩放组",
      "CPU利用率",
      "目标跟踪",
      "预定的缩放"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 406,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个两级架构其中包括一个公共子网和一个数据库子网。公共子网中的网络服务器必须在 443 端口对互联 Web 服务器开放。数据库子网中的 RDS 实例只能访问端口 3306 上的 MySQL 服务器。解决方案架构师应该采取哪些步骤来满足这些需求？（选择两个。）",
    "options_cn": {
      "A": "为公共子网络创建一个网络 ACL。在 ACL 中，添加一条规则，允许 3306 端口上的入站流量，并添加一条规则，拒绝将出站流量降至 0.0.0.0/0。",
      "B": "为 RDS 实例创建一个安全组，允许来自数据库子网块的 3306 端口的流量。",
      "C": "为公共子网中的 Web 服务器创建一个安全组。添加一条规则允许来自 443 端口的流量为 0.0.0.0/0。",
      "D": "为 RDS 实例创建一个安全组。添加一条规则允许来自 Web 服务器安全组的 3306 端口的流量。",
      "E": "db , , 3306 Web 为 实例创建一个安全组。添加一条规则拒绝所有流量除了来自端口 的 服务器安全组的流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Security",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "该问题考察了如何在 VPC 中配置安全组和网络 ACL 以满足特定的网络访问要求。",
      "why_correct": "选项 C 和 D 正确。选项 C 允许来自互联网的 HTTPS 流量访问 Web 服务器。选项 D 允许 Web 服务器访问数据库，符合题目的要求。",
      "why_wrong": "选项 A 的网络 ACL 配置不符合题目的安全要求。选项 B 允许所有数据库子网的流量访问数据库，不安全，应该限制访问来源。"
    },
    "related_terms": [
      "VPC",
      "RDS",
      "ACL",
      "安全组",
      "MySQL"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 407,
    "topic": "",
    "question_cn": "一家公司正在为位于AWS云中的游戏应用程序实现共享存储解决方案。该公司需要能够使用Gluster客户访问数据。解决办法必须得到充分管理。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个Amazon EFS作为可挂载文件系统共享数据。将文件系统安装到应用服务器上。",
      "B": "创建一个AWS存储网关文件网关。创建一个使用所需客户端协议的文件共享，将应用程序服务器连接到文件共享。",
      "C": "创建一个Amazon EFS弹性文件系统并配置它以支持Gluster。将文件系统连接到应用服务器上。",
      "D": "为Gluster文件系统创建一个Amazon FSx。将文件系统连接到应用服务器上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Lustre",
      "EFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。FSx for Lustre是专门为高性能计算和大规模数据集设计的，更适合Gluster。",
      "why_correct": "FSx for Lustre是一个针对高性能计算工作负载进行优化的服务，并且可以支持Gluster。选项D: FSx for Lustre可以提供与Gluster类似的性能，并且是完全托管的服务。",
      "why_wrong": "选项A: EFS不支持Gluster客户端。选项B: 存储网关文件网关不直接支持Gluster。选项C: EFS不支持Gluster客户端。"
    },
    "related_terms": [
      "EFS",
      "Gluster",
      "存储网关",
      "FSx"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 408,
    "topic": "",
    "question_cn": "一家公司运行一个应用程序，它接收来自使用 UDP 的数千个地理上分散的远程设备的数据。应用程序将立即处理数据并在必要时向设备发送消息。没有存储数据。该公司需要一个解决方案，最大限度地减少延迟的数据传输从设备。解决方案还必须为另一个区域提供快速故障转移。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Route 53 故障转移路由策略。在这两个地区各自创建一个网络负载平衡器 NLB。配置 NLB 调用一个 Lambda 函数来处理数据。",
      "B": "使用全球加速器。在这两个区域的每个区域创建一个网络负载平衡器 NLB 作为端点。创建一个 Amazon ECS 服务集群与 Fargate 启动类型。在集群上创建一个服务。将该服务作为亚马逊系统中数据处理的目标。",
      "C": "使用全球加速器。在这两个区域中的每个区域创建一个应用负载平衡器。创建一个 Amazon ECS 服务集群与 Fargate 启动类型。在集群上创建一个服务。设置为 ALB 的目标。处理亚马逊系统中的数据。",
      "D": "配置 Amazon Route 53 故障转移路由策略。在这两个区域中的每一个区域创建一个应用负载平衡器。创建一个 Amazon ECS 集装箱服务集群与 Fargate 启动类型。在集群上创建一个服务。设置为 ALB 的目标。处理亚马逊系统中的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "ECS Fargate"
    ],
    "explanation": {
      "analysis": "该题考察如何使用AWS Global Accelerator 及 ECS Fargate 解决低延迟和故障转移问题",
      "why_correct": "选项 B 正确。Global Accelerator 提供了低延迟的数据传输，结合 NLB 和 ECS Fargate 可以实现快速故障转移和高效的数据处理。",
      "why_wrong": "选项 A 使用 Route 53 故障转移路由，增加了配置复杂性，而且 NLB 相比 Global Accelerator 在延迟方面不占优势。选项 C 和 D 使用 ALB, ALB 无法直接支持UDP协议，因此不适用。"
    },
    "related_terms": [
      "UDP",
      "Route 53",
      "NLB",
      "Lambda",
      "全球加速器",
      "ALB",
      "ECS",
      "Fargate"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 409,
    "topic": "",
    "question_cn": "解决方案架构师必须将Windows IIS(互联网信息服务)应用程序迁移到AWS。该应用程序目前依赖于用户内部网络附加存储中的文件共享。解决方案架构师建议将IISWeb服务器迁移到Amazon EC2实例中的多个可用性区域，这些区域连接到存储解决方案，并配置连接到实例的弹性负载平衡器。哪一个更换的内部文件共享最有弹性和持久性？",
    "options_cn": {
      "A": "将文件共享迁移到Amazon RDS。",
      "B": "将文件共享迁移到AWS存储网关。",
      "C": "将文件共享迁移到Amazon FSx for Windows File Server。",
      "D": "将文件共享迁移到Amazon弹性文件系统(EFS)。"
    },
    "vote_percentage": "96%",
    "tags": [
      "FSx for Windows File Server",
      "EFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。FSx for Windows File Server是专门为Windows环境设计的，提供高可用性和持久性。",
      "why_correct": "FSx for Windows File Server是完全托管的Windows文件服务器，与Windows IIS应用程序兼容，并提供高可用性和持久性。它替代了内部的NAS。",
      "why_wrong": "选项A: RDS通常用于数据库存储，不适合作为文件共享。选项B: 存储网关不直接提供文件共享服务，而是连接到本地存储。选项D: EFS是Linux环境下的文件共享，不适合Windows IIS。"
    },
    "related_terms": [
      "IIS",
      "EC2",
      "EBS",
      "RDS",
      "存储网关",
      "FSx",
      "EFS",
      "弹性负载均衡器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 410,
    "topic": "",
    "question_cn": "一家公司正在 Amazon EC2 实例中部署一个新的应用程序。应用程序将数据写入 Amazon EBS 卷。该公司需要确保写入 EBS 卷的所有数据都在休息时加密。哪种解决方案能满足这一要求？",
    "options_cn": {
      "A": "创建指定 IAM 角色的加密密钥。将角色附加到 EC2 实例中。",
      "B": "创建 EBS 卷作为加密卷。将 EBS 卷附加到 EC2 实例中。",
      "C": "创建一个 EC2 实例标记，该标记具有加密键和真实值。标记所有需要 EBS 级别加密的实例。",
      "D": "创建一个 AWS KMS 密钥，密钥策略在帐户中强制执行 EBS 加密。确保关键政策是积极的。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "此题考察如何确保 EBS 卷的静态加密。",
      "why_correct": "选项 B 正确。创建加密 EBS 卷并将其附加到 EC2 实例即可满足要求。",
      "why_wrong": "选项 A 错误，IAM 角色用于控制访问权限，而不是加密。 选项 C 使用标签来标识需要加密的实例，但没有实际启用加密。选项 D 使用 KMS 密钥配置 EBS 加密，是正确方法，但是选项 B 更简洁直接。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "IAM",
      "KMS",
      "IAM角色",
      "AWS KMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 411,
    "topic": "",
    "question_cn": "一个公司有一个具有零星使用模式的 Web 应用程序。每个月开始时使用量很大，每周开始时使用量很小，一周内使用量也无法预测。该 Web 应用程序由在数据中心内运行的 MySQL 服务器和数据库服务器组成。该公司希望将应用程序转移到 AWS 云，并需要选择一个不需要修改数据库的成本效益高的数据库平台。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "Amazon DynamoDB",
      "B": "Amazon 最新数据集",
      "C": "与 MySQL 兼容的 Amazon Aurora",
      "D": "部署在 Amazon EC2 的一个自动缩放组中的 MySQL"
    },
    "vote_percentage": "89%",
    "tags": [
      "Amazon Aurora",
      "MySQL"
    ],
    "explanation": {
      "analysis": "此题考察迁移数据库到 AWS 的选择，需要考虑成本效益和兼容性。",
      "why_correct": "选项 C 正确。与 MySQL 兼容的 Amazon Aurora 提供了成本效益，与 MySQL 兼容，并且可以根据负载自动扩展。",
      "why_wrong": "选项 A 错误，DynamoDB 是一种 NoSQL 数据库，与 MySQL 不兼容。选项 B 错误，Amazon 数据集是用于分析的专用工具。选项 D 在 EC2 上部署 MySQL 数据库，无法充分利用 RDS 的优势，成本较高。"
    },
    "related_terms": [
      "DynamoDB",
      "MySQL",
      "Aurora",
      "EC2",
      "自动缩放组"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 412,
    "topic": "",
    "question_cn": "一家图片制作公司将其物品存储在 Amazon S3 桶中。该公司希望避免 S3 桶中的物品意外暴露给公众。整个帐户中的所有对象都需要保持私有。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 桶策略。创建一个自动补救操作规则，该规则使用 Lambda 函数来补救任何使对象公开的更改。",
      "B": "使用 AWS 信任的顾问找到可公开访问的 S3 桶。在检测到更改时在信任的顾问中配置电子邮件通知。如果允许公共访问，手动修改 S3 桶策略。",
      "C": "使用 AWS 资源访问管理器找到公开访问的 S3 桶。当检测到更改时使用 Amazon SNS 调用 Lambda 函数。部署一个以编程方式修正更改的 Lambda 函数。",
      "D": "在帐户级别上使用块公共访问功能。使用 IAM SCP 防止用户更改设置。将 SCP 应用到帐户中。"
    },
    "vote_percentage": "94%",
    "tags": [
      "S3 Public Access Block",
      "IAM SCP"
    ],
    "explanation": {
      "analysis": "此题考察如何通过阻止公共访问来保护 S3 桶中的数据。",
      "why_correct": "选项 D 正确。使用 S3 块公共访问功能，并结合 IAM SCP，可以阻止帐户中的所有 S3 桶被公开访问，从而保证数据的安全性。",
      "why_wrong": "选项 A 使用了 S3 桶策略和 Lambda 函数进行补救，但并不能完全阻止公共访问。选项 B 和 C 都依赖于手动操作或检测并修复，无法从根本上防止问题发生。"
    },
    "related_terms": [
      "S3",
      "S3桶",
      "Lambda",
      "IAM",
      "SCP",
      "块公共访问",
      "AWS Trusted Advisor",
      "SNS",
      "资源访问管理器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 413,
    "topic": "",
    "question_cn": "一家电子商务公司的用户流量正在增加。该公司的存储器部署在 Amazon EC2 实例中作为一个由一个 Web 层和一个单独的数据库层组成的两级应用程序。随着流量的增加，该公司注意到该架构在向用户发送及时的营销和订单确认电子邮件方面造成重大延误。该公司希望减少花费在解决复杂的电子邮件发送问题上的时间并将运营开销降至最低。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个单独的应用程序层使用 EC2 实例专用于电子邮件处理。",
      "B": "配置网络实例通过 Amazon SES 发送电子邮件。",
      "C": "配置网络实例以通过 Amazon SNS 发送电子邮件。",
      "D": "创建一个单独的应用程序层使用 EC2 实例专用于电子邮件处理。将实例放置在自动缩放组中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon SES",
      "Email Delivery"
    ],
    "explanation": {
      "analysis": "此题考察如何提高电子邮件发送效率和降低运营成本。",
      "why_correct": "选项 B 正确。使用 Amazon SES (Simple Email Service) 可以快速、可靠且经济高效地发送电子邮件。",
      "why_wrong": "选项 A 和 D 使用 EC2 实例发送电子邮件，需要自己管理邮件服务器，开销较大。 选项 C 使用 SNS 发送电子邮件，SNS 侧重于消息发布订阅，并不适合用于发送大量电子邮件。"
    },
    "related_terms": [
      "EC2",
      "SES",
      "SNS",
      "自动缩放组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 414,
    "topic": "",
    "question_cn": "一家公司有一个每天生成数百份报告的业务系统。业务系统将报告保存为CSV格式的网络共享。该公司需要将这些数据以接近实时的方式存储在AWS云中进行分析。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS数据源将文件转移到Amazon S3。创建一个在每天结束时运行的预定任务。",
      "B": "创建一个Amazon S3文件网关。更新业务系统使用文件网关的新网络共享。",
      "C": "使用AWS数据源API将文件转移到Amazon S3。创建一个在自动化工作流中使用数据化的应用程序。",
      "D": "为SFTP端点部署一个AWS传输。创建一个脚本检查网络共享中的新文件并使用SFTP上传新文件。"
    },
    "vote_percentage": "85%",
    "tags": [
      "S3 File Gateway",
      "S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。S3文件网关可以无缝集成到现有的文件共享环境中，接近实时地将数据上传到S3，管理开销最小。",
      "why_correct": "S3文件网关允许将数据以文件形式存储在S3中，并且可以配置为接近实时地将文件上传到S3。这样可以减少管理开销，并且满足了实时分析的需求。",
      "why_wrong": "选项A: 每天结束时运行的预定任务无法满足接近实时的需求。选项C: 数据源API适用于一些特定的数据源，不是最通用的解决方案。选项D: 使用SFTP需要额外的配置和维护，开销较大。"
    },
    "related_terms": [
      "S3",
      "AWS DataSync",
      "SFTP",
      "传输",
      "文件网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 415,
    "topic": "",
    "question_cn": "一家公司正在用 Amazon S3 标准存储一小部分数据。数据存储在多个 S3 桶中并以不同的频率访问。公司不知道所有数据的存取模式。该公司需要为每个 S3 桶实施一个解决方案以优化 S3 使用的成本。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "用规则创建一个生命周期配置以便将 S3 桶中的对象转换为 S3 智能层。",
      "B": "使用 S3 存储类分析工具来确定 S3 桶中每个对象的正确层。将每个对象移动到标识存储层。",
      "C": "用规则创建生命周期配置将 S3 桶中的对象转换为 冰川即时检索。",
      "D": "用一条规则创建一个生命周期配置以便将 S3 桶中的对象转换为 S3 不经常访问的区域。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle",
      "S3 Intelligent-Tiering"
    ],
    "explanation": {
      "analysis": "该题考察如何使用 S3 生命周期策略优化存储成本，特别是针对访问模式不明确的情况。",
      "why_correct": "选项 A 正确。S3 智能分层会自动将对象移动到访问频率较低的存储层，实现成本优化，并且无需事先了解对象的访问模式。",
      "why_wrong": "选项 B 需要人工分析访问模式，不适合访问模式未知的情况。选项 C 将对象转换为冰川即时检索，不适合经常访问的数据。选项 D 将数据转移到 S3 不经常访问的区域，如果数据经常被访问，会导致较高的检索成本。"
    },
    "related_terms": [
      "S3",
      "S3桶",
      "生命周期配置",
      "S3 智能层",
      "冰川即时检索",
      "S3 不经常访问的区域"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 416,
    "topic": "",
    "question_cn": "一个快速发展的全球电子商务公司正在其 Web 应用程序上提供服务。 Web 应用程序包括静态内容和动态内容。网站在 Amazon RDS 数据库中存储在线事务处理数据。网站用户正经历着页面负载的缓慢。解决方案架构师应该采取哪些行动组合来解决这个问题？（选择两个。）",
    "options_cn": {
      "A": "配置一个 Amazon Redshift 集群。",
      "B": "建立 Amazon CloudFront 分布。",
      "C": "在 Amazon S3 上拥有动态网站内容。",
      "D": "为 RDS 实例创建一个读副本。",
      "E": "配置数据库实例的多 AZ 部署。"
    },
    "vote_percentage": "87%",
    "tags": [
      "CloudFront",
      "RDS Read Replica"
    ],
    "explanation": {
      "analysis": "此题考察如何通过优化静态内容分发和数据库读取性能来提升 Web 应用程序的页面加载速度。",
      "why_correct": "选项 B 和 D 正确。选项 B 使用 CloudFront 进行内容分发，可以加速静态内容的加载速度。选项 D 创建 RDS 读副本，可以分担主数据库的读负载，提高数据库性能。",
      "why_wrong": "选项 A 使用 Redshift，Redshift 是数据仓库，不适用于解决页面加载慢的问题。选项 C 将动态内容存储在 S3 上，不合理。 选项 E 多 AZ 部署提高了可用性，但并不能解决页面加载速度慢的问题。"
    },
    "related_terms": [
      "RDS",
      "Redshift",
      "CloudFront",
      "S3",
      "读副本",
      "多 AZ"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 417,
    "topic": "",
    "question_cn": "一个公司使用 Amazon EC2 实例和 Lambda 函数运行其应用程序。该公司拥有在 VPC 帐户中有公共子网络和私人子网络。 EC2 实例在一个 VPC 中的私有子网中运行。对于应用程序的工作，Lambda 函数需要对 EC2 实例的直接网络访问。该应用程序将运行至少一年。该公司预计该应用程序在此期间使用的 Lambda 功能的数量将会增加。该公司希望在所有应用资源上最大限度地节省费用并保持服务之间的网络延迟时间较低。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "购买一个 EC2 实例节约计划以优化 Lambda 函数的持续时间、内存使用和调用次数。连接到包含 EC2 实例的私有子网。",
      "B": "购买一个 EC2 实例节约计划优化 Lambda 函数的持续时间和内存使用、调用次数和传输的数据量。在 EC2 实例运行的同一 VPC 中，将 Lambda 函数连接到公共子网。",
      "C": "购买一个计算储蓄计划。最大限度地优化 Lambda 函数的持续时间和内存使用、调用次数以及传输的数据量。连接到包含 EC2 实例的私有子网。",
      "D": "购买一个计算储蓄计划。最大限度地优化 Lambda 函数的持续时间和内存使用、调用次数以及传输的数据量。保持 Lambda VPC 功能在 Lambda 服务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Compute Savings Plans",
      "Lambda VPC"
    ],
    "explanation": {
      "analysis": "此题考察如何通过选择合适的储蓄计划和网络配置来优化成本和性能。",
      "why_correct": "选项 C 正确。购买计算储蓄计划可以覆盖 EC2 和 Lambda 的使用，最大限度地节省费用。将 Lambda 函数连接到与 EC2 实例相同的私有子网，可以降低网络延迟。",
      "why_wrong": "选项 A 和 B 使用 EC2 实例节约计划，但无法覆盖 Lambda 函数。 选项 D 保持 Lambda VPC 功能在 Lambda 服务，不明确，且无法优化成本。"
    },
    "related_terms": [
      "EC2",
      "Lambda",
      "VPC",
      "计算储蓄计划",
      "EC2 实例节约计划"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 418,
    "topic": "",
    "question_cn": "一个解决方案架构师需要允许团队成员在两个不同的 S3 桶帐户中访问 Amazon S3 桶：一个开发帐户和一个生产帐户。团队目前可以通过 IAM 使用分配给在开发帐户中具有适当权限的 IAM 组的唯一用户访问开发帐户中的 S3 桶。解决方案架构师在生产帐户中创建了 IAM 角色。该角色具有一种允许在生产帐户中访问 S3 桶的策略。在遵守最少特权原则的同时，哪种解决方案能够满足这些要求？",
    "options_cn": {
      "A": "将管理员访问策略附加到开发账户用户上。",
      "B": "在生产帐户中的作用的信托政策中加入开发帐户作为本金。",
      "C": "关闭生产帐户中 S3 桶上的块公共访问功能。",
      "D": "在生产帐户中为每个团队成员创建一个具有唯一凭证的用户。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Role",
      "Cross-Account Access"
    ],
    "explanation": {
      "analysis": "此题考察如何通过 IAM 角色实现跨账户访问，并遵循最小权限原则。",
      "why_correct": "选项 B 正确。通过在生产账户中角色的信任策略中添加开发账户，可以允许开发账户的用户通过扮演这个角色来访问生产账户的 S3 桶，满足跨账户访问的需求，并且遵循最少权限原则。",
      "why_wrong": "选项 A 错误，将管理员访问策略附加到开发帐户用户上，违背了最小权限原则，过度授权。选项 C 错误，块公共访问功能与跨账户访问无关。选项 D 错误，为每个团队成员创建用户，不便于管理，并且浪费资源。"
    },
    "related_terms": [
      "S3",
      "IAM",
      "IAM 组",
      "IAM 角色",
      "IAM 策略",
      "块公共访问"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 419,
    "topic": "",
    "question_cn": "一个公司使用具有所有功能的AWS组织，并在ap-southeast-2区域运行多个Amazon EC2工作负载。该公司有一个服务控制策略，防止在任何其他区域创建任何资源。安全策略要求该公司在休息时加密所有数据。IAM审计发现员工为EC2实例创建了Amazon EBS卷，但没有加密卷。该公司希望任何IAM用户或根用户在EC2中启动的任何新的EC2 EBS实例都能使用加密的EBS卷。该公司希望找到一种对创造EBS卷的员工影响最小的解决方案。哪些步骤组合将满足这些要求(选二)。",
    "options_cn": {
      "A": "在Amazon EC2控制台中选择EBS加密帐户属性并定义默认加密密钥。",
      "B": "创建一个IAM许可边界。将权限边界附加到根组织单元(OU)。定义拒绝在加密条件等于错误时创建卷的作用的边界。",
      "C": "创建一个SCP。将SCP连接到根组织单位(OU)。定义SCP来否定当加密的条件等于错误的时候。",
      "D": "更新每个帐户的IAM策略，当加密条件等于错误时拒绝创建过程。",
      "E": "在组织管理帐户中指定默认EBS卷加密设置。"
    },
    "vote_percentage": "75%",
    "tags": [
      "EBS Encryption",
      "SCP"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AD，但社区共识(投票最高)为CE。通过SCP和设置默认加密，可以确保所有EBS卷都被加密。",
      "why_correct": "C: 使用SCP可以强制所有在OU下的账户创建的EBS卷都进行加密。E: 在组织管理账户中指定默认EBS卷加密设置，可以确保EBS卷默认加密。",
      "why_wrong": "选项A: 在EC2控制台中定义默认加密密钥，只能影响新创建的卷，不能保证所有卷都被加密。选项B: 使用许可边界实现加密限制，实施较为复杂，不推荐。选项D: 更新每个账户的IAM策略，工作量大，且不能覆盖所有账户。 "
    },
    "related_terms": [
      "EC2",
      "EBS",
      "IAM",
      "IAM 用户",
      "KMS",
      "SCP",
      "EBS 加密",
      "服务控制策略（SCP）",
      "组织单元(OU)",
      "IAM 许可边界"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 420,
    "topic": "",
    "question_cn": "一个公司希望使用Amazon RDS来实现后备MySQL集群，以简化用于生产数据库工作负载的耗时的数据库管理任务。该公司希望确保其数据库高度可用，并将在不到30秒的时间内在大多数情况下提供自动故障转移支持。该公司希望卸下主要实例的读取并尽可能降低成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon RDS多AZ数据库实例部署。创建一个读副本并将读工作负载指向读副本。",
      "B": "使用一个Amazon RDS多AZ数据库部署，创建两个读副本并将读工作负载指向读副本。",
      "C": "使用Amazon RDS多AZ数据库实例部署。将读取工作负载指向多AZ对中的二级实例。",
      "D": "使用Amazon RDS多AZ数据库集群部署，将读取工作量指向读者端点。"
    },
    "vote_percentage": "82%",
    "tags": [
      "RDS Multi-AZ",
      "RDS Read Replicas"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。RDS多AZ集群中的读者端点可以用于读取，同时实现高可用性和故障转移。",
      "why_correct": "D: RDS多AZ数据库集群提供了高可用性和故障转移，读者端点提供了读扩展功能。这样可以卸载主实例的读取负载，满足了成本和可用性的要求。",
      "why_wrong": "选项A: RDS多AZ实例配合读副本可以实现读扩展和高可用性，但没有多AZ集群更优化。选项B: 创建两个读副本，成本较高。选项C: 将读取负载指向多AZ对中的二级实例，也可以实现读扩展，但不如使用专门的读端点高效。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "多AZ",
      "读副本"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 421,
    "topic": "",
    "question_cn": "一家公司经营着一个高度可用的SFTP服务。SFTP服务使用两个具有弹性IP地址的Amazon EC2 Linux实例来接受来自互联网上可信IP地址的流量。SFTP服务由附加到实例的共享存储支持。用户帐户是在SFTP服务器中创建和管理的。该公司想要一个无服务的选项，提供高性能和高度可配置的安全性。该公司还希望保持对用户权限的控制。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个加密的Amazon EBS卷。使用只允许可信IP地址的公共端点创建一个AWS传输家庭服务。将EBS卷附加到SFTP服务端点。授予用户访问SFTP服务。",
      "B": "创建一个加密的Amazon EFS卷。创建一个具有弹性IP地址和VPC端点的AWS传输家庭服务，该端点具有互联网访问。将安全组附加到只允许可信IP地址的端点上。将EFS卷附加到SFTP服务端点。授予用户访问SFTP服务。",
      "C": "创建一个默认加密启用的Amazon S3桶。创建一个使用公共端点的AWS传输家庭服务，该端点只允许受信任的IP地址。将S3桶连接到SFTP服务端点。授予用户使用SFTP服务的权限。",
      "D": "创建一个默认加密启用的Amazon S3桶。用VPC端点创建一个AWS传输家庭服务，该端点在私有子网中具有内部访问。附加一个只允许可信IP地址的安全组给S3桶，将S3桶连接到SFTP服务端点。授予用户访问SFTP服务。"
    },
    "vote_percentage": "82%",
    "tags": [
      "AWS Transfer Family",
      "SFTP"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。使用EFS和VPC端点的AWS Transfer Family可以提供高性能、安全性，同时保留用户权限控制。",
      "why_correct": "B: 使用EFS提供存储，VPC端点提供安全访问，AWS Transfer Family提供SFTP服务，满足了高可用性、安全性、权限控制和高性能的需求。",
      "why_wrong": "选项A:  使用 EBS 卷不如 EFS 弹性好。选项C:  S3 桶更适合对象存储，不适合文件共享。选项D: VPC端点是为内部访问设计的，不能满足公共可访问的需求。"
    },
    "related_terms": [
      "SFTP",
      "Amazon EC2",
      "弹性IP",
      "AWS Transfer Family",
      "VPC",
      "EBS",
      "EFS",
      "Amazon S3",
      "VPC 端点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 422,
    "topic": "",
    "question_cn": "一家公司正在开发一种新的机器学习模型解决方案。这些模型是作为独立的微服务开发的，在启动时从亚马逊S3获取大约1GB的模型API数据并将数据加载到内存中。用户通过异步API访问模型。用户可以发送请求或批请求并指定应在哪里发送结果。该公司向数百名用户提供模型。模型的使用模式不规则，有些型号可能会在几天或几周内不使用。其他型号可以一次收到成千上万的请求。解决方案架构师应该推荐哪种设计来满足这些需求？",
    "options_cn": {
      "A": "将API的请求引导到网络负载均衡器。将这些模型部署为由网络负载均衡器调用的Lambda函数。",
      "B": "将API的请求引导到应用程序负载均衡器。将这些模型部署为亚马逊弹性容器服务，从亚马逊简单队列服务队列中读取。使用应用程序网格以基于小规模服务协议队列大小的方式来扩展此集群的实例。",
      "C": "将来自API的请求引导到一个亚马逊简单队列服务队列中。将模型作为Lambda函数进行部署，这些函数由小数量服务协议事件调用。使用自动缩放以增加基于小规模服务协议队列大小的Lambda函数的数量。",
      "D": "将来自API的请求引导到一个亚马逊简单队列服务队列中。将模型部署为从队列中读取的亚马逊弹性容器服务。允许基于队列大小的集群和服务的副本在亚马逊ECS上自动缩放。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "SQS"
    ],
    "explanation": {
      "analysis": "考察如何设计一个可扩展、异步、低延迟的机器学习模型服务。",
      "why_correct": "选项D使用SQS作为消息队列，ECS作为模型部署平台，实现了异步处理和弹性伸缩，符合需求。",
      "why_wrong": "选项A没有使用消息队列，不具备异步处理能力。选项B使用了应用程序负载均衡器和应用程序网格，增加了复杂性，且不一定能很好地处理异步任务。选项C使用了Lambda函数，可能更适合处理简单的任务，但对于复杂的模型部署和管理，ECS可能更合适。"
    },
    "related_terms": [
      "网络负载均衡器",
      "Lambda",
      "应用程序负载均衡器",
      "Amazon ECS",
      "Amazon SQS",
      "应用程序网格",
      "自动缩放"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 423,
    "topic": "",
    "question_cn": "解决方案架构师希望使用以下JSON文本作为基于身份的策略来授予特定IAM权限？解决方案架构师可以将此策略附加到哪些主体上？（选二）",
    "options_cn": {
      "A": "角色",
      "B": "团体",
      "C": "组织",
      "D": "亚马逊弹性集装箱服务资源",
      "E": "EC2亚马逊资源"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Policy",
      "IAM Identity"
    ],
    "explanation": {
      "analysis": "考查IAM策略的附加位置。",
      "why_correct": "IAM策略可以附加到角色和组。选项A和B正确。",
      "why_wrong": "选项C，IAM策略不能直接附加到组织。选项D和E，IAM策略不能直接附加到资源上。"
    },
    "related_terms": [
      "IAM",
      "角色",
      "IAM",
      "EC2",
      "亚马逊弹性集装箱服务",
      "EC2"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 424,
    "topic": "",
    "question_cn": "一家公司正在运行亚马逊EC2定制应用程序。该应用程序的前置节点需要每天24小时、每周7天运行，后端节点只需要根据工作负载运行短时间。后端节点的数量在白天变化，在更多的情况下公司需要根据工作量扩大规模。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "为前置节点使用保留的实例。对后端节点使用法盖特。",
      "B": "为前置节点使用保留的实例。后端节点使用点实例。",
      "C": "对前置节点使用点实例。为后端节点使用保留的实例。",
      "D": "对前置节点使用点实例。对后端节点使用法盖特。"
    },
    "vote_percentage": "64%",
    "tags": [
      "EC2 Reserved Instance",
      "EC2 Spot Instance"
    ],
    "explanation": {
      "analysis": "考察EC2实例类型选择和成本优化。",
      "why_correct": "选项B，前置节点需要持续运行，使用保留实例最经济。后端节点工作负载波动，使用点实例可以降低成本。",
      "why_wrong": "选项A，前置节点用保留实例正确，但法盖特可能成本高于点实例。选项C，前置节点使用点实例不合适。选项D，前置节点使用点实例不合适，且法盖特可能成本高于点实例。"
    },
    "related_terms": [
      "Amazon EC2",
      "保留的实例",
      "Fargate",
      "点实例"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 425,
    "topic": "",
    "question_cn": "一家公司利用高的块存储能力在公司内部运行其工作量。该公司每日最高输入和输出交易每秒不超过15,000ips。该公司希望将工作负载迁移到亚马逊EC2，并提供与存储能力无关的磁盘性能。哪个亚马逊EBS卷类型将最符合这些要求的成本效益？",
    "options_cn": {
      "A": "Gp2卷类型",
      "B": "Io2卷类型",
      "C": "Gp3卷类型",
      "D": "Io1卷类型"
    },
    "vote_percentage": "94%",
    "tags": [
      "EBS",
      "Gp3"
    ],
    "explanation": {
      "analysis": "考察EBS卷类型的选择。",
      "why_correct": "选项C，Gp3卷类型提供单独的IOPS和吞吐量配置，可以满足高性能需求，且具有成本效益。",
      "why_wrong": "选项A，Gp2卷性能受卷大小限制。选项B和D，Io2和Io1卷性能更好，但成本更高，不一定是最佳选择。"
    },
    "related_terms": [
      "Amazon EC2",
      "EBS",
      "IOPS",
      "Gp2",
      "Io2",
      "Gp3",
      "Io1"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 426,
    "topic": "",
    "question_cn": "公司需要从医疗保健应用程序中存储数据。应用程序的数据经常变化。一项新的条例要求对存储数据的所有级别进行审计访问。该公司将该应用程序放在一个正在耗尽存储能力的内部基础设施上。解决方案架构师必须安全地将现有数据迁移到AWS，同时满足新的法规。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS数据化将现有数据转移到Amazon S3。使用CloudTrail记录数据事件。",
      "B": "使用AWS Snowcone移动现有数据到Amazon S3。使用CloudTrail记录管理事件。",
      "C": "使用Amazon S3传输加速将现有数据转移到Amazon S3。使用CloudTrail记录数据事件。",
      "D": "使用AWS存储网关将现有数据转移到Amazon S3。使用CloudTrail记录管理事件。"
    },
    "vote_percentage": "57%",
    "tags": [
      "S3",
      "CloudTrail"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。使用数据化进行迁移，并使用CloudTrail进行审计，是最直接、最有效的方法，满足了数据存储和审计的需求。",
      "why_correct": "A: 使用数据化可以将数据安全快速地迁移到S3，并且CloudTrail可以记录S3的操作，满足了审计要求。",
      "why_wrong": "选项B: Snowcone适合大量数据迁移，但对于数据经常变化的情况，不如数据化方便。选项C: 传输加速提升传输速度，但没有解决数据迁移问题，也没说明如何审计。选项D: 存储网关用于连接到本地存储，不是直接用于数据迁移。"
    },
    "related_terms": [
      "Amazon S3",
      "CloudTrail",
      "AWS DataSync",
      "AWS Snowcone",
      "AWS Snowball",
      "AWS Storage Gateway"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 427,
    "topic": "",
    "question_cn": "解决方案架构师正在使用MySQL数据库实现一个复杂的Java应用程序。该应用程序必须部署在Apache Tomcat并且必须是高度可用的。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "将应用程序部署到Lambda中。配置一个亚马逊API网关以连接到Lambda函数。",
      "B": "利用弹性Beanstalk进行应用。配置负载平衡环境和滚动部署策略。",
      "C": "将数据库迁移到亚马逊RDS。配置EC2安全组以允许从应用程序访问。",
      "D": "启动亚马逊EC2实例。在EC2实例上安装MySQL服务器。在服务器上配置应用程序。创建一个信息库。请使用该系统创建一 个带有自动缩放组的启动模板。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Elastic Beanstalk",
      "RDS"
    ],
    "explanation": {
      "analysis": "考察应用程序部署和高可用性。",
      "why_correct": "选项B，弹性Beanstalk提供完整的应用程序部署管理，并支持负载均衡和滚动部署，满足高可用性需求。",
      "why_wrong": "选项A，Lambda不适合部署复杂的Java应用程序。选项C，数据库迁移到RDS正确，但没有说明如何部署应用程序。选项D，手动部署EC2实例、MySQL和应用程序，工作量大，且没有提供高可用性。"
    },
    "related_terms": [
      "MySQL",
      "Apache Tomcat",
      "Lambda",
      "Amazon API Gateway",
      "弹性Beanstalk",
      "Amazon RDS",
      "EC2",
      "MySQL",
      "自动缩放组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 428,
    "topic": "",
    "question_cn": "一个无服务的应用程序使用亚马逊API网关，亚马逊Lambda函数和亚马逊DynamoDB。Lambda函数需要对DynamoDB表的读写权限。什么样的解决方案将最安全地给予Lambda函数访问DynamoDB表的权限？",
    "options_cn": {
      "A": "创建一个IAM用户并通过编程访问Lambda函数。为用户附加一个允许读写访问DynamoDB表的策略。存储作为Lambda环境变量的一部分的辅助和秘密辅助参数。确保其他的IAM用户没有读写访问Lambda函数配置。",
      "B": "创建一个IAM角色，其中包括作为可信任服务的Lambda。为允许读写访问DynamoDB表的角色附加一个策略。更新Lambda函数的配置以使用新的角色作为执行角色。",
      "C": "创建一个IAM用户并通过编程访问Lambda函数。为用户附加一个允许读写访问DynamoDB表的策略。在系统管理器参数存储中作为安全字符串参数存储辅助和秘密关键参数。在连接到DynamoDB表之前更新Lambda函数代码以检索安全的字符串参数。",
      "D": "创建一个IAM角色，其中包括作为可信任服务的DynamoDB。将一个策略附加到允许从Lambda函数读取和写入访问的角色上。更新Lambda函数代码，作为执行角色附加到新角色上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Role",
      "Lambda"
    ],
    "explanation": {
      "analysis": "考察Lambda函数的权限管理，安全访问DynamoDB。",
      "why_correct": "选项B，使用IAM角色，将权限附加到角色上，然后将角色分配给Lambda函数，是最佳实践。",
      "why_wrong": "选项A和C，使用IAM用户，不推荐，管理复杂，且容易泄露凭证。选项D，角色需要信任服务是Lambda，不是DynamoDB。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "DynamoDB",
      "IAM",
      "DynamoDB",
      "IAM",
      "IAM",
      "DynamoDB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 429,
    "topic": "",
    "question_cn": "下面的IAM策略附属于一个IAM组。这是适用于该组的唯一策略。对于组成员，此策略的有效权限是什么？",
    "options_cn": {
      "A": "允许团队成员在美国东1号区域内进行任何亚马逊EC2操作。不适用许可后的声明。",
      "B": "除非使用多因子身份验证(MFA)登录，否则在美国东1区域的亚马逊EC2权限将被拒绝。",
      "C": "小组可以使用EC2:停止实例和EC2:终止实例权限，当使用多因素身份验证(MFA)登录时。允许团队成员进行亚马逊EC2的任何其他操作。",
      "D": "小组可以使用EC2:停止实例和EC2:终止实例权限，只有在使用多因素身份验证(MFA)登录时，美国东1号区域的终止实例权限。小组成员可以在美国东1号区域内进行任何亚马逊EC2操作。"
    },
    "vote_percentage": "85%",
    "tags": [
      "IAM Policy",
      "MFA"
    ],
    "explanation": {
      "analysis": "考查IAM策略的权限和MFA的结合。",
      "why_correct": "选项D，策略允许MFA认证后停止和终止实例，同时允许在指定区域内进行任何EC2操作。",
      "why_wrong": "选项A，策略明确了需要MFA。选项B，策略不允许EC2访问。选项C，策略没有说明完全的权限。"
    },
    "related_terms": [
      "IAM",
      "EC2",
      "MFA",
      "EC2",
      "MFA",
      "EC2"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 430,
    "topic": "",
    "question_cn": "一家制造公司有CSV文件可以上传到S3桶。这些CSV文件必须转换成图像，并且必须尽快提供以便自动生成图形报告。一个月后，这些图像就变得无关紧要了，但是CSV文件必须保存以培训机器学习模型一年两次。机器学习培训和审计是提前数周计划的。哪些步骤组合将最符合这些要求？（选二）",
    "options_cn": {
      "A": "启动亚马逊EC2点实例，下载CSV文件，每小时生成图像文件，并将图像上传到S3桶。",
      "B": "设计一个转换的Lambda函数，将CSV文件转换为图像并存储的图像在S3桶中。调用Lambda函数时，已上传CSV文件。",
      "C": "为S3桶中的CSV文件和图像文件创建生命周期规则。过渡CSV文件从标准到Glacier在上传后的一天。30天后将图像文件过期。",
      "D": "为S3桶中的CSV文件和图像文件创建生命周期规则。过渡CSV文件从标准到不经常访问（IA）区域在上传后的一天。30天后将图像文件过期。",
      "E": "为S3桶中的CSV文件和图像文件创建生命周期规则。过渡CSV文件从标准到标准-IA。将图像文件保存在减少冗余存储（RRS）中。"
    },
    "vote_percentage": "89%",
    "tags": [
      "S3 Lifecycle",
      "Lambda"
    ],
    "explanation": {
      "analysis": "考察S3存储管理、数据转换和生命周期策略。",
      "why_correct": "选项B，Lambda函数可以自动转换文件，并且调用方便。选项C，生命周期策略可以自动将CSV文件归档到Glacier，并删除图像文件。",
      "why_wrong": "选项A，需要手动管理EC2实例，效率较低。选项D，过渡到IA不适合归档。选项E，RRS已经弃用。"
    },
    "related_terms": [
      "S3",
      "CSV",
      "EC2",
      "Lambda",
      "S3",
      "CSV",
      "标准-IA",
      "Glacier",
      "RRS"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 431,
    "topic": "",
    "question_cn": "一家公司开发了一个新的电子游戏作为网络应用程序。该应用程序位于VPC中的三层体系结构中，而数据库层中的MySQL则位于亚马逊RDS中。有几个玩家将同时在网上竞争。该游戏的开发者希望近实时展示前10名的记分牌，并提供在保持当前比分的同时停止和恢复游戏的能力。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "为要显示的应用程序设置一个用于内存缓存集群的亚马逊弹性数据缓存。",
      "B": "为Redis集群设置一个亚马逊弹性计算系统用于计算和缓存要显示的应用程序的分数。",
      "C": "在Web应用程序前面放置一个亚马逊CloudFront分布以便在应用程序的一个部分中缓存记分牌。",
      "D": "在亚马逊RDS上为MySQL创建一个读取副本用于运行查询以计算记分牌并为Web应用程序提供读取流量。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Redis",
      "Cache"
    ],
    "explanation": {
      "analysis": "考察游戏计分牌的实现方式和性能优化。",
      "why_correct": "选项B，使用Redis作为缓存可以近实时地展示计分牌，同时减轻数据库的压力。",
      "why_wrong": "选项A，弹性数据缓存用于缓存数据库数据，可能不是最优解。选项C，CloudFront缓存静态内容，不适合动态计分牌。选项D，MySQL读取副本可以用于分担数据库的读取压力，但不能满足近实时的需求。"
    },
    "related_terms": [
      "Amazon ElastiCache",
      "Redis",
      "Amazon CloudFront",
      "RDS",
      "MySQL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 432,
    "topic": "",
    "question_cn": "一家电子商务公司希望使用机器学习算法来建立和培训模型。该公司将使用这些模型来可视化复杂的场景并检测客户数据的趋势。ML架构团队希望将其ML模型与报告平台集成以分析增强数据并在业务智能仪表板中直接使用数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS Glue创建一个ML转换来构建和培训模型。使用亚马逊开放搜索服务来可视化数据。",
      "B": "使用亚马逊SageMaker建立和培训模型。使用亚马逊QuickSight可视化数据。",
      "C": "使用一个来自AWS Marketplace的预先构建的亚马逊机器镜像来构建和培训模型。使用亚马逊开放搜索服务来可视化数据。",
      "D": "使用亚马逊QuickSight建立和培训模型使用计算字段。使用亚马逊QuickSight可视化数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SageMaker",
      "QuickSight"
    ],
    "explanation": {
      "analysis": "考察机器学习模型构建和可视化方案。",
      "why_correct": "选项B，SageMaker用于模型构建和训练，QuickSight用于数据可视化，都是AWS的托管服务，易于集成。",
      "why_wrong": "选项A，Glue主要用于ETL，不适合模型训练。选项C，使用AMI需要手动管理，且不一定能提供最佳的模型训练效果。选项D，QuickSight用于可视化，不具备模型训练能力。"
    },
    "related_terms": [
      "AWS Glue",
      "Amazon OpenSearch Service",
      "Amazon SageMaker",
      "Amazon QuickSight",
      "AWS Marketplace"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 433,
    "topic": "",
    "question_cn": "一个公司正在运行其生产和非生产环境的工作负载在多个AWS账户。这些账户是在美国AWS组织的一个组织中。该公司需要设计一个解决方案防止修改成本使用标签。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个自定义的AWS配置规则以防止标签修改，但授权的主体除外。",
      "B": "在CloudTrail中创建自定义路径以防止标签修改。",
      "C": "创建一个服务控制策略（SCP）以防止标签修改，但授权的主体除外。",
      "D": "创建一个自定义亚马逊CloudWatch日志以防止标签修改。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SCP",
      "Tagging"
    ],
    "explanation": {
      "analysis": "考察如何通过策略来限制账户内的资源修改。",
      "why_correct": "选项C，服务控制策略（SCP）可以控制组织中账户的权限，包括限制标签修改。",
      "why_wrong": "选项A，配置规则主要用于合规性检查，无法强制执行权限。选项B，CloudTrail用于日志记录，无法防止修改。选项D，CloudWatch用于监控，无法防止修改。"
    },
    "related_terms": [
      "AWS",
      "CloudTrail",
      "SCP",
      "CloudWatch"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 434,
    "topic": "",
    "question_cn": "一家公司将其应用程序存储在AWS Cloud中。该应用程序运行在亚马逊EC2实例后面的一个弹性负载平衡器，在一个自动缩放组和一个亚马逊DynamoDB表。该公司希望确保该应用程序能够在较短的停机时间内在其他地区提供。解决方案架构师应该如何以最少的停机时间来满足这些需求？",
    "options_cn": {
      "A": "在灾难恢复区域创建一个自动缩放组和负载平衡器。将DynamoDB表配置为全局表。配置DNS故障转移指向新的灾难恢复区域的负载平衡器。",
      "B": "创建一个CloudFormation模板以创建EC2实例、负载平衡器和DynamoDB表。在需要时启动。配置DNS故障转移指向新的灾难恢复区域的负载平衡器。",
      "C": "创建一个CloudFormation模板以创建EC2实例和在需要时启动的负载平衡器。将DynamoDB表配置为全局表。配置DNS故障转移指向新的灾难恢复区域的负载平衡器。",
      "D": "在灾难恢复区域创建一个自动缩放组和负载平衡器。将DynamoDB表配置为全局表。创建一个亚马逊CloudWatch警报触发一个Route 53Lambda函数更新亚马逊Route 53线路指向灾后恢复负载平衡器。"
    },
    "vote_percentage": "52%",
    "tags": [
      "Disaster Recovery",
      "Global Table"
    ],
    "explanation": {
      "analysis": "考察应用程序的灾难恢复方案。",
      "why_correct": "选项A，使用全局表实现DynamoDB跨区域复制，创建备用区域的资源，DNS故障转移实现快速切换。",
      "why_wrong": "选项B，需要手动启动资源，且没有考虑数据库的同步。选项C，没有创建EC2实例，不完整。选项D，依赖CloudWatch和Lambda，不如DNS直接切换更快速。"
    },
    "related_terms": [
      "EC2",
      "ELB",
      "Auto Scaling",
      "DynamoDB",
      "DynamoDB",
      "DNS",
      "Route 53",
      "CloudWatch",
      "Route 53",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 435,
    "topic": "",
    "question_cn": "一个公司需要在两周内将MySQL数据库从它的内部数据中心迁移到AWS。数据库有20TB。该公司希望在最短的停机时间内完成迁移。哪个解决方案将迁移数据库最具成本效益？",
    "options_cn": {
      "A": "订购一个Snowball Edge存储优化装置。使用AWS数据库迁移服务(AWS DMS)与AWS架构转换工具(AWS SCT)迁移数据库与复制正在进行的更改。将雪球边缘设备发送到AWS完成迁移并继续进行复制。",
      "B": "订购一辆AWS雪车。使用AWS数据库迁移服务(AWS DMS)与AWS架构转换工具(AWS SCT)迁移数据库与持续的更改。将雪车送回AWS完成迁移并继续进行复制。",
      "C": "订购一个Snowball Edge计算优化设备。使用AWS数据库迁移服务(AWS DMS)与AWS架构转换工具(AWS SCT)迁移数据库与持续AWS的更改。将雪球装置发送到AWS完成迁移并继续进行复制",
      "D": "命令一个专用的Direct Connect连接以建立与数据中心的连接。使用AWS数据库迁移服务(AWS DMS)与AWS架构转换工具(AWS SCT)迁移数据库与复制正在进行的更改。"
    },
    "vote_percentage": "85%",
    "tags": [
      "AWS DMS",
      "AWS SCT"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。A使用Snowball Edge，适合离线传输，能最大限度减少停机时间。D依赖于Direct Connect，可能需要更长的设置时间。",
      "why_correct": "A: Snowball Edge可以离线传输数据，适用于大规模数据库迁移，可以最大限度地减少停机时间。AWS DMS 和 AWS SCT用于数据库迁移，并复制持续更改。",
      "why_wrong": "选项B: 雪车不适用，不用于数据库迁移。选项C: Snowball Edge计算优化设备功能多余，增加成本。选项D: Direct Connect的设置时间较长，无法满足两周内完成的要求，并且成本相对较高。"
    },
    "related_terms": [
      "MySQL",
      "Snowball Edge",
      "AWS DMS",
      "AWS SCT",
      "AWS Snowmobile",
      "Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 436,
    "topic": "",
    "question_cn": "一家公司将其网站内的后SQL数据库转移到了亚马逊RDS数据库。该公司成功地推出了一种新产品，数据库的工作量增加了。该公司希望在不增加基础设施的情况下适应更大的工作量。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "为总工作负载购买保留的RDS实例。使RDS实例的亚马逊计算能力更大。",
      "B": "将RDS数据库实例的亚马逊RDS设置到多AZ数据库实例。",
      "C": "为总工作负载购买保留的RDS实例。添加另一个亚马逊RDS数据库实例。",
      "D": "将RDS实例中的亚马逊RDS设置为按需数据库实例。"
    },
    "vote_percentage": "85%",
    "tags": [
      "RDS Performance",
      "RDS Scaling"
    ],
    "explanation": {
      "analysis": "考查 RDS 性能优化和成本控制。需要通过提升数据库性能来应对增长的工作负载，并控制成本。",
      "why_correct": "购买保留实例可以降低成本，提升 RDS 实例规格可以提升性能。提升RDS实例的计算能力能应对增加的工作负载。",
      "why_wrong": "选项 B 提升了可用性，但没有解决性能问题。选项 C 增加了数据库实例，会增加成本，且没有提升单个实例的性能。选项 D 无法满足性能需求，且按需实例成本较高。"
    },
    "related_terms": [
      "RDS",
      "Amazon RDS",
      "多AZ",
      "RDS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 437,
    "topic": "",
    "question_cn": "一家公司在亚马逊 EC2实例中运行一个电子商务网站，支持一个自动标度组的应用负载均衡器。该站点正在经历与来自非法外部系统 IP 地址的 DDOS 攻击有关的性能问题，IP 地址不断变化。安全小组担心可能攻击网站。公司必须以对合法用户影响最小的方式阻止非法的请求。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "部署亚马逊检查员并将其与美国律师协会联系起来。",
      "B": "部署AWS WAF，将其与ALB关联并配置一个速率限制规则。",
      "C": "将ALB ACLS规则部署到与ALB相关的网络上以阻止收入流量。",
      "D": "在配置保护表时部署亚马逊保护表并启用限价保护。"
    },
    "vote_percentage": "95%",
    "tags": [
      "AWS WAF",
      "DDoS Protection"
    ],
    "explanation": {
      "analysis": "考察 Web 应用程序的 DDoS 攻击防御。需要使用 WAF 进行流量过滤和速率限制。",
      "why_correct": "AWS WAF 结合 ALB 可以配置速率限制规则，有效阻止 DDoS 攻击。",
      "why_wrong": "选项 A 和 D  并不是针对 DDoS 攻击的。选项 C  ACLs 用于控制子网级别流量，无法进行精细的 HTTP 请求过滤。"
    },
    "related_terms": [
      "EC2",
      "ELB",
      "DDOS",
      "IP",
      "AWS WAF",
      "ALB",
      "ALB",
      "ALB",
      "ACLs",
      "AWS Shield Advanced"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 438,
    "topic": "",
    "question_cn": "一家公司希望与外聘审计师分享会计数据。数据存储在位于私有子网中的亚马逊 RDS 数据库实例中。审计员有自己的AWS账户并需要自己的数据库副本。公司与审计员共享数据库的最安全的方式是什么？",
    "options_cn": {
      "A": "创建数据库的读副本。配置IAM标准数据库身份验证以授予审计员访问权。",
      "B": "将数据库内容导出到文本文件中，将文件存储在一个亚马逊S3桶中。为审计员创建一个新的 IAM用户。允许用户访问S3桶。",
      "C": "将数据库的快照复制到一个亚马逊S3桶。创建一个 IAM用户。将用户的键与审计员共享以授予对S3桶中对象的访问权。",
      "D": "创建数据库的加密快照。与审计员共享快照。允许访问KMS加密密钥。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Security",
      "Database Sharing"
    ],
    "explanation": {
      "analysis": "考察 RDS 数据库的安全共享。需要考虑数据加密和访问控制。",
      "why_correct": "通过创建加密数据库快照并共享 KMS 加密密钥，可以确保数据的安全传输和访问控制。",
      "why_wrong": "选项 A 共享了数据库访问权限，安全性较低。选项 B 和 C 通过 S3 共享数据，但未加密，安全性较差。"
    },
    "related_terms": [
      "RDS",
      "IAM",
      "Amazon S3",
      "IAM",
      "S3",
      "KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 439,
    "topic": "",
    "question_cn": "解决方案架构师配置了一个 VPC，它具有小范围的 IP 地址。在 VPC 中的亚马逊 EC2实例数量正在增加，而用于未来工作负载的 IP 地址数量不足。用最少的操作开销解决这个问题的解决方案是什么？",
    "options_cn": {
      "A": "增加一个额外的 CIDR 块以增加 IP 地址的数量，并在 VPC 中创建额外的子网。使用新的 CIDR 在新的子网中创建新的资源。",
      "B": "用额外的子网创建第二个 VPC。使用窥视连接连接第二个 VPC 和第一个 VPC，更新路由并在第二个 VPC 的子网中创建新的资源。",
      "C": "使用过境网关添加一个过境网关并将第二个 VPC 与第一个 VPC 连接以确定过境网关和 VPC 的路线。在第二个 VPC 子网中创建新的资源。",
      "D": "创建第二个 VPC。在第一个 VPC 和第二个 VPC 之间使用亚马逊 EC2 上的主机解决方案和一个虚拟专用网关建立一个 VPN VPC 站点到站点的 VPN 连接。通过更新 VPC 到流量的路由。在第二个 VPC 子网中创建新的资源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC",
      "IP Addressing"
    ],
    "explanation": {
      "analysis": "考察 VPC 的 IP 地址扩展。需要通过增加 CIDR 块来扩展 IP 地址空间。",
      "why_correct": "增加 VPC 的 CIDR 块并创建新的子网，是最简单直接的方案，可以快速扩展 IP 地址空间。",
      "why_wrong": "其他选项都引入了额外的复杂性，增加了管理开销。例如使用 VPC peering 或 transit gateway 会使网络拓扑更复杂。"
    },
    "related_terms": [
      "VPC",
      "IP",
      "CIDR",
      "VPC",
      "VPC",
      "过境网关",
      "过境网关",
      "VPN",
      "VPN",
      "VPC",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 440,
    "topic": "",
    "question_cn": "在应用程序测试过程中，一家公司使用了一个Amazon RDS用于MySQL实例。在测试周期结束时终止实例之前，解决方案架构师创建了MySQL RDS的两个备份。解决方案架构师通过使用mysqldump工具创建了第一个备份，以创建一个数据库转储。解决方案架构师通过在终止时启用RDS的最后的快照选项创建了第二个备份。该公司目前正在计划一个新的测试周期，并希望从最近的备份中创建一个新的RDS实例。该公司选择了兼容的版本Aurora MySQL来托管RDS实例。哪些解决方案将创建新的数据库实例(选二)。",
    "options_cn": {
      "A": "RDS直接将RDS快照导入极光。",
      "B": "将RDS快照上传到Amazon S3。然后将RDS快照导入极光。",
      "C": "将数据库转储上传到Amazon S3。然后将数据库转储导入奥罗拉。",
      "D": "使用AWS数据库迁移服务将RDS快照导入奥罗拉。",
      "E": "将数据库转储上传到Amazon S3。然后使用AWS数据库迁移服务将数据库转储导入到极光。"
    },
    "vote_percentage": "80%",
    "tags": [
      "RDS",
      "Aurora MySQL"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AD，但社区共识(投票最高)为AC。可以直接使用RDS快照或数据库转储来创建Aurora MySQL实例。",
      "why_correct": "A:可以直接从RDS快照创建Aurora MySQL实例。C: 数据库转储可以上传到S3，然后导入到Aurora MySQL中，创建一个新的数据库实例。",
      "why_wrong": "选项B: 上传快照后不能直接导入，需要进一步处理。选项D: AWS DMS用于迁移数据库，不是用于从备份创建实例。选项E: 数据库转储可以直接导入Aurora，不需要使用AWS DMS。"
    },
    "related_terms": [
      "Amazon RDS",
      "MySQL",
      "RDS",
      "mysqldump",
      "RDS",
      "Aurora MySQL",
      "RDS",
      "Aurora",
      "Amazon S3",
      "AWS DMS"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 441,
    "topic": "",
    "question_cn": "在一个应用负载均衡器的背后，一个公司在亚马逊 EC2实例上拥有一个多层Web应用程序。实例在多个可用性区域的自动缩放组中运行。该公司观察到当应用程序的最终用户访问大量静态内容时，自动缩放组会推出更多的点播实例。公司想优化成本。解决方案架构师应该做什么才能最经济有效地重新设计应用程序？",
    "options_cn": {
      "A": "更新自动缩放组使用保留实例而不是按需实例。",
      "B": "通过启动现场实例而不是点播实例来更新自动缩放组。",
      "C": "创建一个亚马逊 CloudFront 分布以主机从亚马逊S3桶静态内容。",
      "D": "在亚马逊 API 网关背后创建一个 Lambda 函数以容纳静态网站内容。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "考察 Web 应用程序的静态内容优化。使用 CDN 可以有效降低成本。",
      "why_correct": "将静态内容存储在 S3 中，并通过 CloudFront 提供服务，可以有效降低成本，提高性能。",
      "why_wrong": "选项 A 和 B  仅优化了 EC2 实例的成本，对静态内容访问的优化效果有限。 选项 D 使用 Lambda 不适合静态内容的托管。"
    },
    "related_terms": [
      "EC2",
      "应用负载均衡器",
      "自动缩放组",
      "点播实例",
      "保留实例",
      "CloudFront",
      "S3",
      "Lambda",
      "API 网关"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 442,
    "topic": "",
    "question_cn": "一个公司在多个 AWS 账户中存储几个字节的数据。该公司利用 AWS Lake Formation 管理其数据湖。该公司的数据科学团队希望安全地与该公司的工程团队共享其账户中的选定数据以进行分析。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将所需数据复制到一个共同账户。在那个账户中创建一个 IAM 访问角色。通过指定一个权限策略授予访问权限，该权限策略将工程团队账户中的用户作为受信任实体。",
      "B": "在数据存储的每个帐户中使用 Lake Formation 权限授予命令允许所需的工程团队用户访问数据。",
      "C": "使用 AWS 数据交换将所需数据私下发布到所需的工程团队账户中。",
      "D": "使用基于 Lake Formation 标记的访问控制来授权和授予工程团队帐户所需数据的交叉帐户权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lake Formation",
      "Cross-Account Access"
    ],
    "explanation": {
      "analysis": "考查数据湖的安全共享和访问控制。Lake Formation 提供了更便捷的方案。",
      "why_correct": "使用 Lake Formation 基于标签的访问控制，可以简化跨账户的数据访问控制配置。",
      "why_wrong": "选项 A 需要复制数据，增加了开销。选项 B 虽然可以使用 Lake Formation 权限，但需要在每个账户上配置，操作比较繁琐。选项 C 使用数据交换，不适合内部数据共享。"
    },
    "related_terms": [
      "AWS Lake Formation",
      "IAM",
      "Lake Formation",
      "AWS 数据交换"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 443,
    "topic": "",
    "question_cn": "一家公司希望在AWS上托管一个可伸缩的 Web 应用程序。该应用程序将由来自世界不同地理区域的用户访问。应用程序用户将能够下载和上传高达千兆字节的唯一数据。开发团队想要一个成本效益高的解决方案以最小化上传和下载延迟并最大化性能。解决方案架构师应该做什么来实现这个目标？",
    "options_cn": {
      "A": "使用带有传输加速的亚马逊 S3 来主机应用程序。",
      "B": "使用亚马逊 S3 与 CloudFront 来主机应用程序。",
      "C": "使用亚马逊 EC2 与自动缩放和亚马逊 CloudFront 应用程序主机。",
      "D": "使用亚马逊 EC2 与自动缩放和亚马逊可伸缩性以主机应用程序。"
    },
    "vote_percentage": "65%",
    "tags": [
      "S3 Transfer Acceleration",
      "CloudFront",
      "Web Application"
    ],
    "explanation": {
      "analysis": "考察全球用户的上传下载性能优化。 S3 Transfer Acceleration 和 CloudFront 可以有效提升性能",
      "why_correct": "使用 S3 Transfer Acceleration 和 CloudFront 组合，可以有效提升上传下载性能，降低延迟。",
      "why_wrong": "EC2 本身不适合静态内容分发和全球用户的访问。选项 D 描述不准确。"
    },
    "related_terms": [
      "S3",
      "传输加速",
      "CloudFront",
      "EC2",
      "自动缩放"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 444,
    "topic": "",
    "question_cn": "一家公司聘请了一个解决方案架构师为其应用设计一个可靠的架构。应用程序包括一个亚马逊 RDS 数据库实例和两个手动提供的运行 Web EC2实例的亚马逊 EC2实例。EC2 实例位于一个可用性区域。数据库实例最近被删除，因此应用程序24小时内无法使用。公司关心的是其环境的整体可靠性。解决方案架构师应该如何最大限度地提高应用程序基础结构的可靠性？",
    "options_cn": {
      "A": "删除一个EC2实例并在另一个EC2实例上启用终止保护。将RDS实例更新为多AZ并启用删除保护。",
      "B": "将RDS实例更新为多AZ并启用删除保护。将EC2实例放在应用程序负载均衡器后面，然后在多个可用性区域中运行EC2自动缩放组中。",
      "C": "创建一个额外的数据库实例以及一个亚马逊 API 网关和一个 Lambda 函数。将应用程序配置为通过API 网关调用 Lambda 函 数。将数据写入两个数据库实例。",
      "D": "将EC2实例放置在一个自动缩放组中，该组具有位于多个可用性区域中的多个子网。使用现场实例而不是点播实例。设置 Amazon CloudWatch 报警器以监控实例的健康性将数据库实例更新为多AZ并启用删除保护。"
    },
    "vote_percentage": "100%",
    "tags": [
      "High Availability",
      "RDS",
      "EC2",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "考查提高应用程序的可靠性，需要实现高可用和容错能力。",
      "why_correct": "选项 B 提供了多可用区（AZ）的 RDS 配置和 EC2 实例部署在 ALB 后的自动缩放组中，实现了高可用。删除保护保证了实例不会被误删。",
      "why_wrong": "选项 A 仅部分提升了可靠性，没有实现高可用。选项 C 引入了复杂性，并且数据写入双数据库实例不一定能提升可靠性。选项 D 增加了成本，不能解决问题，实例使用 Spot 实例可能导致可用性下降。"
    },
    "related_terms": [
      "RDS",
      "EC2",
      "多AZ",
      "删除保护",
      "应用程序负载均衡器",
      "API 网关",
      "Lambda",
      "CloudWatch"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 445,
    "topic": "",
    "question_cn": "一家公司正在其企业数据中心的一个大型网络连接存储系统上存储700兆字节数据。该公司拥有一个混合环境，直接连接连接90天。经过监管机构的审计，该公司有10 Gbps的时间将数据转移到云计算中。该公司需要高效且不受干扰地移动数据。在传输窗口期间，公司仍然需要能够访问和更新数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在企业数据中心中创建一个 AWS 数据源代理。创建数据传输任务，启动向亚马逊 S3桶的传输。",
      "B": "备份数据到 Snowball Edge 存储优化设备。将设备运送到美国信息系统数据中心。安装一个目标亚马逊 S3桶在现场文件系统。",
      "C": "使用 Direct Connect 同步直接将数据从本地存储器复制到指定的亚马逊 S3桶。",
      "D": "备份磁带上的数据。把录像带运到美国宇航局的数据中心。安装一个目标亚马逊 S3桶在现场文件系统。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Data Migration",
      "AWS DataSync",
      "S3"
    ],
    "explanation": {
      "analysis": "考查大规模数据迁移的最佳实践。需要考虑迁移速度，数据可用性和成本。",
      "why_correct": "使用AWS DataSync可以在线将数据同步到 S3，满足了快速迁移、数据可用性和更新数据的需求。",
      "why_wrong": "Snowball Edge 适合大规模离线数据传输，迁移速度慢，不满足数据更新的需求。Direct Connect 只是网络连接方式，不能完成数据传输。选项 D  磁带传输速度慢，不满足需求。"
    },
    "related_terms": [
      "Direct Connect",
      "S3",
      "Snowball Edge",
      "Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 446,
    "topic": "",
    "question_cn": "一家公司用PDF格式在Amazon S3桶中存储数据。该公司必须遵守一项法律要求在Amazon S3上保留所有新的和现有的数据七年。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "打开S3桶的版本控制功能。配置生命周期以删除7年后的数据。为所有对象配置多因素身份验证(MFA)删除。",
      "B": "打开带有治理保留模式的S3桶对象锁。将保留期定为七年后期满。重新整理所有现有对象使现有数据符合要求。",
      "C": "打开S3对象锁并采用桶的合规性保留模式。将保留期定为七年后期满。重新整理所有现有对象使现有数据符合要求。",
      "D": "打开S3对象锁并采用桶的合规性保留模式。将保留期定为七年后期满。使用S3批量操作使现有数据符合要求。"
    },
    "vote_percentage": "83%",
    "tags": [
      "S3 Object Lock",
      "S3 Lifecycle"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。使用对象锁的合规性保留模式和S3批量操作，可以实现数据保留要求，且操作开销最小。",
      "why_correct": "D: 使用对象锁的合规性保留模式可以防止对象被删除或覆盖。使用S3批量操作可以高效地将现有数据设置为合规性保留模式，减少管理开销。",
      "why_wrong": "选项A: 版本控制和生命周期规则用于版本管理和过期删除，不能满足保留数据的需求。选项B: 治理保留模式可以防止意外删除，但是需要手动重新整理数据。选项C: 采用合规性保留模式，但缺乏批量操作。"
    },
    "related_terms": [
      "S3",
      "S3桶",
      "版本控制",
      "生命周期",
      "多因素身份验证(MFA)",
      "S3对象锁",
      "合规性保留模式",
      "S3批量操作"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 447,
    "topic": "",
    "question_cn": "一个公司有一个无状态的 Web 应用程序，它运行在由亚马逊 API 网关调用的 Lambda 函数上。该公司希望在多个 AWS 区域部署应用程序，以提供区域故障转移功能。解决方案架构师应该如何将流量路由到多个区域？",
    "options_cn": {
      "A": "为每个地区创建亚马逊 Route 53 号公路健康检查。使用活动主动故障转移配置。",
      "B": "创建一个亚马逊 CloudFront 分布每个区域的起源。使用 CloudFront 健康检查路线交通。",
      "C": "创建一个传送网关。在每个区域将转运网关附加到 API 网关端点。将传输网关配置为路由请求。",
      "D": "在主区域中创建应用程序负载平衡器。设置目标组指向每个区域的 API 网关端点主机名。"
    },
    "vote_percentage": "87%",
    "tags": [
      "Route 53",
      "Global Application",
      "API Gateway",
      "Lambda"
    ],
    "explanation": {
      "analysis": "考查全球应用程序的流量路由和故障转移。 Route 53 提供了健康检查和故障转移功能。",
      "why_correct": "使用 Route 53 健康检查功能，可以监控 API 网关的健康状态，当主区域出现故障时，自动将流量切换到备用区域。",
      "why_wrong": "CloudFront 更适合静态内容的加速分发。 Transit Gateway 用于 VPC 间的连接。 ALB 不支持API Gateway 的流量路由。"
    },
    "related_terms": [
      "Route 53",
      "CloudFront",
      "API 网关",
      "传输网关"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 448,
    "topic": "",
    "question_cn": "一家公司有两个VPC，叫做管理和生产。管理 VPC使用VPN通过客户网关连接到数据中心中的单个设备。生产 VPC 使用一个虚拟专用网关和两个连接的AWS Direct Connect。管理 VPC和生产 VPC 都使用一个VPC peering 连接来允许应用程序之间的通信。解决方案架构师应该做些什么来缓解这个架构中的任何单一失败点？",
    "options_cn": {
      "A": "在管理VPC和生产VPC之间添加一组VPN。",
      "B": "添加第二个虚拟专用网关并将其附加到管理VPC上。",
      "C": "从第二个客户网关设备向管理 VPC添加第二组VPN。",
      "D": "在管理 VPC和生产 VPC之间添加第二个VPC peering连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC",
      "VPN",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考察VPC网络架构的单点故障。需要通过冗余来提高可靠性。",
      "why_correct": "从第二个客户网关设备向管理 VPC添加第二组 VPN，可以提供 VPN 连接的冗余，从而提高管理 VPC 网络的可靠性。",
      "why_wrong": "选项 A，在管理和生产VPC之间添加 VPN，无法解决管理 VPC 与本地数据中心连接的单点故障。选项 B，只能解决一个方向的故障。选项 D，VPC peering 的故障会导致 VPC 间通信中断，而非单点故障。"
    },
    "related_terms": [
      "VPC",
      "VPN",
      "客户网关",
      "Direct Connect",
      "虚拟专用网关",
      "VPC peering"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 449,
    "topic": "",
    "question_cn": "一家公司在甲骨文数据库中运行其应用程序。由于数据库、备份管理和数据中心维护的资源有限，该公司计划快速迁移到AWS。应用程序使用第三方数据库功能，这些功能需要有特权访问。哪个解决方案能帮助公司将数据库迁移到AWS最具成本效益？",
    "options_cn": {
      "A": "将数据库迁移到Amazon RDS for Oracle。用云服务取代第三方功能。",
      "B": "将数据库迁移到Amazon RDS for Oracle定制。自定义数据库设置以支持第三方功能。",
      "C": "将数据库迁移到为甲骨文提供的Amazon EC2 Amazon机器镜像。自定义数据库设置以支持第三方功能。",
      "D": "通过改写应用程序代码来删除对甲骨文先端的依赖，将数据库迁移到Amazon RDS中。"
    },
    "vote_percentage": "94%",
    "tags": [
      "RDS for Oracle",
      "Database Migration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。B使用RDS for Oracle并支持第三方功能，可以最大限度地减少代码更改和停机时间。",
      "why_correct": "B: RDS for Oracle允许在AWS上托管Oracle数据库，可以最大限度地减少管理开销。自定义数据库设置支持第三方功能，避免了应用程序代码的修改，更具成本效益。",
      "why_wrong": "选项A: 用云服务取代第三方功能可能导致功能损失，或需要重写应用程序。选项C: EC2上的Oracle数据库管理开销高于RDS。选项D: 改变应用程序代码耗时，且成本高。"
    },
    "related_terms": [
      "Amazon RDS for Oracle",
      "Amazon EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 450,
    "topic": "",
    "question_cn": "一个公司有一个三层的 Web 应用程序，该应用程序在一个 AWS EC2服务器中。该公司希望将应用程序迁移到 AWS 云。该公司还希望该应用程序与架构良好的框架保持一致，并与推荐的安全性、可伸缩性和弹性最佳实践保持一致。哪些解决方案能够满足这些要求？( ) 选三。",
    "options_cn": {
      "A": "在两个可用性区域中创建一个VPC。在每个可用性区域的私有子网中在具有自动缩放组的EC2实例上用现有体系结构来托管应用程序。用安全组和网络访问控制列表(ACLs) 保护 EC2 实例。",
      "B": "建立安全组和网络访问控制列表(ACLs)以控制对数据库层的访问。在私人子网中建立一个单独的RDS数据库。",
      "C": "在两个可用性区域中创建一个VPC。重构应用程序以主机层、应用程序层和数据库层。在自己的私有子网上为Web层和应用程序层设置自动缩放组。",
      "D": "使用一个单一的RDS数据库。只允许从应用程序层安全组访问数据库。",
      "E": "在网络层前使用弹性负载平衡器。通过使用包含每个层的安全组的引用的安全组进行控制访问。",
      "F": "在私人子网中使用RDS数据库多AZ集群部署。只允许从应用程序层安全组访问数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC",
      "EC2 Auto Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为ACF，但社区共识(投票最高)为CEF。社区倾向CEF的原因是，它同时考虑了应用程序的高可用性，可伸缩性以及安全性。选项CEF都体现了在VPC中部署多层架构，使用自动伸缩组提供可伸缩性，以及使用安全组控制访问。",
      "why_correct": "选项CEF组合提供了最佳实践。C选项通过在多个可用区部署应用程序和Web层、应用层，以及数据库层使用安全组实现高可用性和可伸缩性。E选项使用负载均衡器，提高了可用性和性能。F选项使用RDS多AZ，实现数据库层的高可用性。",
      "why_wrong": "A选项尽管在两个可用区部署EC2实例，但没有考虑数据库的高可用性。B选项只提供了数据库层的保护，未考虑应用程序层，所以不是最佳选择。D选项使用单个数据库，不满足高可用性要求。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "自动缩放组",
      "安全组",
      "网络访问控制列表(ACLs)",
      "RDS",
      "应用程序负载平衡器",
      "RDS数据库多AZ集群"
    ],
    "best_answer": [
      "C",
      "E",
      "F"
    ],
    "official_answer": [
      "A",
      "C",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 451,
    "topic": "",
    "question_cn": "一家公司正在将其应用程序和数据库迁移到 AWS 云。该公司将使用 Amazon ECS (亚马逊弹性容器服务) 直接连接 Amazon RDS (关系型数据库服务)。哪些活动将由公司的业务团队管理？选三。",
    "options_cn": {
      "A": "管理 Amazon RDS 亚马逊 RDS 基础设施层、操作系统和平台",
      "B": "创建 Amazon RDS 数据库实例并配置预定维护窗口",
      "C": "为监测、补丁管理、日志管理和主机入侵检测配置 Amazon RDS 系统上的附加软件组件",
      "D": "为 Amazon RDS 的所有小型和主要数据库版本安装补丁",
      "E": "确保数据中心 Amazon RDS 基础设施的实体安全",
      "F": "通过直接连接传输的数据的加密"
    },
    "vote_percentage": "97%",
    "tags": [
      "RDS Management",
      "ECS Integration"
    ],
    "explanation": {
      "analysis": "考查企业团队在迁移到云平台后，对 RDS 的管理职责。选项 B、C、F 是业务团队应负责的任务，涵盖实例创建、配置、安全和数据加密。",
      "why_correct": "选项 B、C 和 F 是业务团队的责任。业务团队负责数据库实例的创建和配置，应用额外的监控和安全措施，以及通过安全连接传输数据。",
      "why_wrong": "选项 A 和 E 是基础设施团队的责任，而选项 D 通常是数据库管理团队或云服务提供商的责任。"
    },
    "related_terms": [
      "ECS",
      "RDS",
      "RDS",
      "Amazon RDS",
      "RDS"
    ],
    "best_answer": [
      "B",
      "C",
      "F"
    ],
    "official_answer": [
      "B",
      "C",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 452,
    "topic": "",
    "question_cn": "一家公司在 Amazon EC2 实例中经营一项基于 Java 的工作。这项工作每小时运行一次，运行 10 秒钟。作业在一个预定的间隔上运行并消耗 1GB 的 CPU 和内存。这个实例的利用率很低，除了短时间内的工作使用最大的可用性。该公司想优化成本来经营这项工作？哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon ECS 集装箱 将工作进行集装箱化，使用 0.5 CPU 和 1GB 内存来运行这个任务作为一个亚马逊弹性容器服务任务。",
      "B": "将代码复制到一个具有 1GB 内存的 Lambda 函数中。创建一个 Amazon EventBridge 计划规则来运行每个小时的代码。",
      "C": "使用 Amazon ECS 集装箱 将工作进行集装箱化。将容器安装在现有的亚马逊机器图像中，确保任务结束时计划停止容器。",
      "D": "配置现有的时间表以便在作业完成时停止 EC2 实例并在下一个作业启动时重新启动 EC2 实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "核心考点是成本优化，针对周期性且低负载的 Java 工作负载，考察使用 Lambda 函数的优势。",
      "why_correct": "选项 B 使用 Lambda 函数，对于间歇性的任务，可以根据使用量付费，从而实现成本优化，并且不需要管理服务器。",
      "why_wrong": "选项 A 虽然也是容器化方案，但是需要维护 ECS 相关的基础设施，成本比 Lambda 更高；选项 C 需要维护 ECS 和 EC2，成本更高，并且需要考虑容器的启动和停止过程；选项 D 增加了 EC2 实例的启动和停止的开销，并且在可用性和成本上都不占优势。"
    },
    "related_terms": [
      "ECS",
      "Lambda",
      "EventBridge",
      "EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 453,
    "topic": "",
    "question_cn": "一家公司希望为亚马逊S3数据和多个亚马逊EC2系统实现备份策略。由于监管要求，公司必须保留一个特定时间段的备份文件。在保留期内，公司不得更改文件。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Backup 创建一个具有治理模式中的保险库锁的备份保险库。创建所需的备份计划。",
      "B": "使用亚马逊数据生命周期管理器创建所需的自动快照策略。",
      "C": "使用亚马逊S3文件网关创建S3备份。配置适当的生命周期管理。",
      "D": "使用 AWS Backup 创建一个具有符合性模式的保险库锁的备份保险库。创建所需的备份计划。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Backup",
      "S3 Object Lock"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，D选项使用了AWS Backup的合规模式，提供了更严格的保护，以满足监管要求，确保备份文件在保留期内不可更改。",
      "why_correct": "D选项使用了AWS Backup的合规模式，能够满足监管要求，保证文件在保留期内不可修改。 通过使用AWS Backup的备份保险库，并配置符合性模式的保险库锁，可以满足不可更改的需求。",
      "why_wrong": "A选项使用治理模式，安全性不如符合性模式。B选项使用快照策略，适用于EBS，不适用于S3备份。C选项使用S3文件网关，增加了复杂性，且无法满足不可更改的需求。"
    },
    "related_terms": [
      "AWS Backup",
      "S3",
      "EC2",
      "S3",
      "AWS Backup"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 454,
    "topic": "",
    "question_cn": "一个公司拥有跨越多个AWS区域和账户的资源。一位新聘用的解决方案架构师发现前员工没有提供有关资源清单的详细信息。解决方案架构师需要构建和映射所有帐户中各种工作负载的关系细节。哪个解决方案将以最有效的方式满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Systems Manager Inventory 从详细的视图报告生成地图视图。",
      "B": "使用 AWS 步骤函数来收集工作量细节。手动构建工作负载的体系结构图。",
      "C": "使用AWS CloudWatch 工作负载发现生成工作负载的体系结构图。",
      "D": "使用 AWS X-Ray 查看工作量细节。构建具有关系的体系结构图。"
    },
    "vote_percentage": "95%",
    "tags": [
      "AWS CloudWatch",
      "Resource Discovery"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，AWS CloudWatch 工作负载发现能够自动化地发现和映射AWS资源的关系，生成工作负载的架构图，更高效地满足需求。",
      "why_correct": "C选项使用CloudWatch工作负载发现来自动发现和映射资源关系，从而构建工作负载的架构图，是最有效的方法。",
      "why_wrong": "A选项使用Systems Manager Inventory虽然可以生成详细的资源报告，但生成地图视图的功能不如CloudWatch的发现功能强大。B选项手动构建图表效率低。D选项X-Ray主要用于应用程序性能分析，不适用于资源架构图的构建。"
    },
    "related_terms": [
      "AWS Systems Manager Inventory",
      "AWS 步骤函数",
      "AWS CloudWatch",
      "AWS X-Ray"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 455,
    "topic": "",
    "question_cn": "一个公司使用的是 AWS Organizations 的组织。该公司希望用不同的预算来运营其一些账户。该公司希望收到警报，并在某一特定时期达到分配的预算门槛时自动防止在美国 AWS 账户上提供额外资源。哪些解决方案能够满足这些要求？选三。",
    "options_cn": {
      "A": "使用 AWS Budgets 来创建预算。在成本和使用报告项下设定所需的 AWS Organizations 账户的预算金额。",
      "B": "使用 AWS Budgets 来创建预算。在所需的 AWS Organizations 账户的账单仪表板下设置预算金额。",
      "C": "为 AWS Budgets 创建一个 IAM 用户来运行具有所需权限的预算操作。",
      "D": "为 AWS Budgets 创建一个 IAM 角色以运行具有所需权限的预算操作。",
      "E": "添加通知当每个账户达到预算阈值通知公司，添加一个预算操作该动作选择使用适当配置规则创建的 IAM 标识以防止提供额外 资源。",
      "F": "添加通知当每个账户达到预算阈值通知公司，添加一个预算操作该动作选择使用适当的服务控制策略 (SCP) 创建的 IAM 标识以防止提供额外资源。"
    },
    "vote_percentage": "66%",
    "tags": [
      "AWS Budgets",
      "SCP"
    ],
    "explanation": {
      "analysis": "核心是使用 AWS Budgets 进行成本控制，包括设置预算、告警、以及阻止超出预算的行为。",
      "why_correct": "选项 B 和 F 都是正确的。选项 B 设置预算金额；选项 F 通过 SCP 控制账户的资源使用，阻止超出预算的行为，是最佳实践；选项 D 创建 IAM 角色，用于预算操作。",
      "why_wrong": "选项 A 描述的设置方式是错误的，Budgets 设置应该在预算 dashboard 中；选项 C 描述了 IAM 用户的设置，但这不是最佳实践；选项 E 虽然触发了通知和 budget action，但没有实现限制资源的功能。"
    },
    "related_terms": [
      "AWS Organizations",
      "AWS Budgets",
      "IAM",
      "SCP"
    ],
    "best_answer": [
      "B",
      "D",
      "F"
    ],
    "official_answer": [
      "B",
      "D",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 456,
    "topic": "",
    "question_cn": "一家公司在 Amazon EC2 实例中运行应用程序。该公司希望将 EC2 实例备份到第二个区域。该公司还希望在第二个区域提供资源，并从一个账户集中管理 EC2 实例。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个灾难恢复计划，该计划在第二区域具有类似的 EC2 实例。配置数据复制。",
      "B": "创建 EC2 实例的实时 Amazon EBS (弹性块存储) Amazon 快照。定期将快照复制到第二个区域。",
      "C": "使用 AWS Backup 创建一个备份计划。为 EC2 实例配置跨区域备份到第二区域。",
      "D": "在第二区域部署类似数量的 EC2 实例。使用数据采集器将数据从源区域转移到第二区域。"
    },
    "vote_percentage": "79%",
    "tags": [
      "AWS Backup",
      "Cross-Region Backup"
    ],
    "explanation": {
      "analysis": "考察 EC2 实例的备份和跨区域复制，重点是 AWS Backup 和跨区域备份的能力。",
      "why_correct": "选项 C 使用 AWS Backup，可以自动实现 EC2 实例的备份和跨区域复制，是最有效的方法。",
      "why_wrong": "选项 A 仅描述了灾难恢复计划，但没有具体说明备份机制；选项 B 使用快照，但手动复制流程，需要手动配置和管理；选项 D 需要单独部署实例，增加了复杂性，且未说明备份和恢复方法。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "快照",
      "AWS Backup"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 457,
    "topic": "",
    "question_cn": "一家使用 AWS 的公司正在构建一个应用程序，以便将数据传递给产品制造商。公司有自己的身份提供者。当用户使用应用程序来传输数据 (AS2) 时，该公司希望内部数据处理器对应用程序用户进行身份验证。公司必须使用适用性声明协议。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 来传输数据。创建一个用于 IDP 身份验证的 Lambda 函数。",
      "B": "使用 Amazon AppFlow 来传输数据。创建一个 Amazon ECS 任务为 IDP 身份验证。",
      "C": "使用 AWS Transfer Family 来传输数据。创建一个用于 IDP 身份验证的 Lambda 函数。",
      "D": "使用 AWS Storage Gateway 来传输数据。创建一个 Amazon Cognito 身份池用于 IDP 身份验证。"
    },
    "vote_percentage": "86%",
    "tags": [
      "AWS Transfer Family",
      "AS2"
    ],
    "explanation": {
      "analysis": "考察使用 AS2 协议进行安全数据传输。AWS Transfer Family 支持 AS2，并可以与 Lambda 函数集成。",
      "why_correct": "选项 C 使用 AWS Transfer Family，它可以支持 AS2 协议，并可与 Lambda 函数集成，进行用户身份验证。",
      "why_wrong": "选项 A 使用 DataSync，不适用 AS2 协议；选项 B 使用 AppFlow，不支持 AS2 协议；选项 D 使用 Storage Gateway，也不支持 AS2 协议。"
    },
    "related_terms": [
      "AWS DataSync",
      "Lambda",
      "Amazon AppFlow",
      "Amazon ECS",
      "AWS Transfer Family",
      "AWS Storage Gateway",
      "Amazon Cognito"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 458,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计 Amazon API Gateway 中的 Rest API 用于现金偿还服务。应用程序的计算资源需要 1GB 内存和 2GB 存储。应用程序将要求数据采用关系格式。哪些附加的服务将以最少的行政努力来满足这些要求？选二。",
    "options_cn": {
      "A": "Amazon EC2",
      "B": "Amazon Lambda",
      "C": "Amazon RDS",
      "D": "Amazon DynamoDB",
      "E": "Amazon EKS (弹性库伯内特斯服务)"
    },
    "vote_percentage": "86%",
    "tags": [
      "API Gateway",
      "Lambda",
      "RDS"
    ],
    "explanation": {
      "analysis": "核心是设计 API Gateway 后端服务，选择合适的计算和存储服务。考察 Lambda 和 RDS 的组合",
      "why_correct": "选项 B 和 C 是正确的，Amazon Lambda 用于计算，Amazon RDS 用于关系型数据库存储。",
      "why_wrong": "选项 A 虽然可以使用 EC2，但需要更多的管理工作，不符合要求；选项 D 是 NoSQL 数据库，不满足关系型数据要求；选项 E 虽然可以使用 EKS，但管理复杂度较高。"
    },
    "related_terms": [
      "API Gateway",
      "EC2",
      "Lambda",
      "RDS",
      "DynamoDB",
      "EKS"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 459,
    "topic": "",
    "question_cn": "一个公司使用AWS Organizations在多个AWS帐户中运行工作负载。当公司创建标记时，标记策略将部门标记添加到EC2资源中。一个会计团队需要确定亚马逊EC2消费的支出。会计团队必须决定由哪些部门负责成本，不论帐户。会计团队对组织内的所有 AWS 帐户都有访问成本资源管理器的权限，并且需要访问成本资源管理器的所有报告。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "从组织管理帐户账单控制台激活一个用户定义的费用分配标签，名称为部门。在成本资源管理器分组中创建一个按标记名称分类的成本报告并按EC2 进行筛选。",
      "B": "从组织管理帐户账单控制台激活一个预定义的成本分配标签，称为部门。在成本资源管理器分组中创建一个按标记名称分类的成本报告并按EC2 进行筛选。",
      "C": "从组织成员帐户账单控制台激活一个用户定义的费用分配标签，名称为部门。在成本资源管理器分组中创建一个由标记名称组成的成本报告并由EC2 进行筛选。",
      "D": "从组织成员帐户账单控制台激活一个由预定义的成本分配标记，称为部门。在成本资源管理器分组中创建一个按标记名称分类的成本报告并按EC2 进行筛选。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Cost Explorer",
      "Cost Allocation Tags"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A选项描述了正确的步骤和配置，从组织管理账户激活用户定义的费用分配标签，然后在成本资源管理器中创建报告。这确保了成本追踪和报告的正确性。",
      "why_correct": "A选项正确地描述了配置步骤：从组织管理账户激活用户定义的费用分配标签，并使用Cost Explorer进行成本分析。确保了成本追踪的正确性。",
      "why_wrong": "B选项使用了预定义的标签，这不符合题目中需要自定义部门的需求。C和D选项是从成员账户配置标签，这会导致配置不一致，不能覆盖所有账户。同时，C使用了用户自定义标签，符合需求，D使用了预定义标签不符合需求。"
    },
    "related_terms": [
      "AWS Organizations",
      "EC2",
      "成本资源管理器",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 460,
    "topic": "",
    "question_cn": "一家公司希望在其 SaaS (软件即服务) 应用程序销售员帐户和 Amazon S3 之间安全地交换数据。公司必须使用 KMS (密钥管理服务) 客户管理 (CMKs) API 管理密钥 加密剩余的数据。公司还必须加密传输中的数据。该公司已经启用了对销售员帐户的访问。",
    "options_cn": {
      "A": "创建 Lambda 函数以安全地将数据从销售人员传输到 Amazon S3。",
      "B": "创建一个 Step Functions 工作流。定义将数据安全地从销售队传输到 Amazon S3 的任务。",
      "C": "创建 Amazon AppFlow 流以便安全地将数据从销售人员传输到 Amazon S3。",
      "D": "为销售力量创建一个自定义连接器以便安全地将数据从销售力量传输到 Amazon S3。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon AppFlow",
      "KMS",
      "S3"
    ],
    "explanation": {
      "analysis": "核心是安全的数据传输和使用 KMS 加密，考察 Amazon AppFlow。",
      "why_correct": "选项 C 使用 Amazon AppFlow，它提供安全的数据传输，并支持加密功能。可以使用客户管理的 KMS 密钥进行数据加密。",
      "why_wrong": "选项 A 和 B 虽然可以使用 Lambda 函数或 Step Functions，但需要手动实现安全性和加密功能，比 AppFlow 复杂；选项 D 需要自定义连接器，增加了开发和维护成本。"
    },
    "related_terms": [
      "KMS",
      "S3",
      "Lambda",
      "Step Functions",
      "Amazon AppFlow"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 461,
    "topic": "",
    "question_cn": "一家公司正在开发一个移动游戏应用程序。该应用程序在一个自动缩放组中运行多个亚马逊EC2实例。该公司将应用程序数据存储在亚马逊DynamoDB上。该应用程序通过在用户和服务器之间使用TCP流量和UDP流量进行通信。该应用程序将在全球使用。该公司希望确保所有用户的延迟时间尽可能小。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用全球加速器建立一个加速器(ALS)。在加速器端点后面创建一个应用程序负载均衡器(ALB)，该端点使用全局加速器集成，并在TCP和UDP端口上监听。更新自动缩放组以便在ALB上注册实例。",
      "B": "使用全球加速器建立一个加速器。在加速器端点后面创建一个网络负载均衡器(NLB)，该端点使用全局加速器集成，并在TCP和UDP端口上监听。更新自动缩放组在NLB注册实例。",
      "C": "创建一个亚马逊云前内容传递网络(CDN)端点。在端点后面创建一个网络负载均衡器(NLB)并监听TCP和UDP端口。更新自动缩放组在NLB注册实例。更新云端CDN以NLB为起点。",
      "D": "创建一个亚马逊云前内容传递网络(CDN)端点。在端点后面创建一个应用程序负载均衡器(ALB)并在TCP和UDP端口上监听。更新自动缩放组以便在ALB上注册实例。更新云端使用ALB作为起源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Global Accelerator",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，B选项使用了全球加速器和NLB，能够同时支持TCP和UDP流量，并且全球加速器能够优化用户体验。",
      "why_correct": "B选项使用了全球加速器和NLB。全球加速器可以优化全球用户的延迟。NLB支持TCP和UDP协议，满足游戏应用的需求。",
      "why_wrong": "A选项使用ALB，仅支持TCP/UDP端口的监听，但Global Accelerator与ALB的集成需要额外配置，相对复杂。C选项使用了CDN，虽然可以缓存静态内容，但对于UDP的动态流量优化效果不如Global Accelerator。D选项同C，且ALB不支持作为CDN的源。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "DynamoDB",
      "TCP",
      "UDP",
      "全球加速器",
      "加速器端点",
      "应用程序负载均衡器(ALB)",
      "网络负载均衡器(NLB)",
      "Amazon CloudFront",
      "CDN",
      "CDN端点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 462,
    "topic": "",
    "question_cn": "一家公司有一个处理客户订单的应用程序。该公司将应用程序保存在 Amazon EC2 实例中，该实例将订单保存到 Amazon Aurora 数据库中。偶尔，当流量很大时，工作量不够快处理订单。解决方案架构师应该如何尽可能快地将订单可靠地写入数据库？",
    "options_cn": {
      "A": "当流量高时增加 EC2 实例的实例大小。向 Amazon Simple Notification Service (Amazon SNS) 发出订单。将数据库端点订阅到 SNS 主题。",
      "B": "向 Amazon Simple Queue Service (SQS) (Amazon SQS) 队列编写订单。在应用程序负载平衡器后面的自动缩放组中使用 EC2 实例来读取来自 SQS 队列和流程订单到数据库中的内容。",
      "C": "向 Amazon Simple Notification Service (Amazon SNS) (Amazon SNS) 发出订单。将数据库端点订阅到 SNS 主题。在应用程序负载平衡器后面的自动 EC2 缩放组中使用 EC2 实例来读取来自 SNS 主题的内容。",
      "D": "当 EC2 实例达到 CPU 阈值时向 Amazon Simple Queue Service (Amazon SQS) 队列编写订单。在应用程序负载平衡器后面的一个自动缩放 EC2 组中使用计划的实例缩放以便将该队列和流程订单读取到数据库中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Load Shedding"
    ],
    "explanation": {
      "analysis": "考察在高负载情况下，如何将订单写入数据库，并且需要保证可靠性。使用 SQS 解耦前端和数据库写入，实现负载削减和异步处理。",
      "why_correct": "选项 B 使用 SQS 队列，应用程序将订单写入 SQS，然后由后台的 EC2 实例从队列中读取并处理订单。这实现了异步处理，避免了数据库过载，并提高了可靠性。",
      "why_wrong": "选项 A 增加实例大小，无法解决突发流量的问题，且成本较高。选项 C 使用 SNS，无法实现可靠的消息传递和队列功能。选项 D 没有说明后端实例如何读取队列，且计划缩放不够灵活。"
    },
    "related_terms": [
      "EC2",
      "Amazon Aurora",
      "Amazon SNS",
      "SQS",
      "EC2",
      "应用程序负载平衡器(ALB)",
      "自动缩放组",
      "CPU",
      "Amazon SQS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 463,
    "topic": "",
    "question_cn": "一家多技术公司正在发布一个床垫，它有传感器来收集用户睡眠数据。这些传感器将把数据发送到一个 Amazon S3 桶。这些传感器每天为每个床垫收集大约 2GB 的数据。公司必须处理和总结每个床垫的数据。需要尽快提供结果。数据处理将需要 2GB 的内存并将在 30 秒内完成。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "用 AWS Glue 和 AWS Lake Formation 工作",
      "B": "使用带有阿帕奇 Spark 脚本的 Amazon EMR",
      "C": "使用 AWS Lambda 与 Python 脚本",
      "D": "在 AWS Glue 中工作"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Lambda",
      "S3 Processing"
    ],
    "explanation": {
      "analysis": "核心是处理 S3 中的数据，并快速得到处理结果，考虑使用 Lambda 函数。",
      "why_correct": "选项 C 使用 AWS Lambda，Lambda 函数可以快速处理数据，并且符合 30 秒的时限要求。",
      "why_wrong": "选项 A 和 D 使用 AWS Glue，不适合快速处理，Glue 更适合大规模数据处理；选项 B 使用 EMR，启动时间较长，不符合快速处理的要求。"
    },
    "related_terms": [
      "Amazon S3",
      "AWS Glue",
      "AWS Lake Formation",
      "Amazon EMR",
      "AWS Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 464,
    "topic": "",
    "question_cn": "一家公司拥有一个在线购物应用程序，该应用程序将所有订单存储在 Amazon RDS (关系型数据库) 数据库实例中。管理层希望消除单点故障，并要求解决方案架构师推荐一种方法，以尽量减少数据库的停机时间，而不需要对应用程序代码进行任何修改。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "通过修改数据库实例并指定多 AZ 选项将现有数据库实例转换为多 AZ 部署。",
      "B": "创建新的 RDS 多 AZ 部署。获取当前 RDS 实例的快照并使用快照恢复新的多 AZ 部署。",
      "C": "在另一个可用性区域中创建后数据库的只读副本。使用 Amazon Route 53 加权记录集在数据库中分发请求。",
      "D": "将 RDS 数据库的 EC2 放在 Amazon EC2 自动缩放组中，最小组尺寸为 2。使用 Amazon Route 53 加权记录集分发请求跨实 例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Multi-AZ",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考察 RDS 高可用性，以及在不修改应用程序代码的情况下，如何减少数据库停机时间。",
      "why_correct": "选项 A 通过将现有数据库实例转换为多 AZ 部署，可以实现高可用性，并且不需要修改应用程序代码。",
      "why_wrong": "选项 B 涉及迁移，会产生停机时间。选项 C 创建只读副本，无法保证高可用性。选项 D 将 RDS 放在自动伸缩组，不适合 RDS，且实现方式不正确。"
    },
    "related_terms": [
      "Amazon RDS",
      "Multi-AZ",
      "Amazon Route 53",
      "EC2",
      "自动缩放组",
      "Route 53",
      "EC2 自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 465,
    "topic": "",
    "question_cn": "一家公司正在开发一个支持客户需求的应用程序。该公司希望在同一可用性区域内将该应用程序部署到多个基于 Amazon 硝基的 EC2 实例上。该公司还希望使应用程序能够同时在多个 硝化实例中写入多个块存储卷以实现更高的应用程序可用性。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用通用 SSD (Gp3) EBS 卷与 Amazon EBS 弹性块存储，并启用 Amazon 多连接",
      "B": "使用具有 Amazon EBS 弹性块存储 的 HDD (ST1) EBS 卷",
      "C": "使用提供 SSD (Io2) EBS 卷与 Amazon EBS 弹性块存储，并启用 Amazon 多连接",
      "D": "使用通用 SSD (Gp2) EBS 卷与 Amazon EBS 弹性块存储，并启用 Amazon 多连接"
    },
    "vote_percentage": "94%",
    "tags": [
      "EBS Multi-Attach",
      "EBS Volume Types"
    ],
    "explanation": {
      "analysis": "考察 EC2 实例的块存储，以及多连接 (Multi-Attach) 的特性。",
      "why_correct": "选项 C 使用提供 SSD (Io2) EBS 卷，支持 Multi-Attach。 Multi-Attach 允许将一个 EBS 卷同时附加到多个 EC2 实例，从而实现更高的应用程序可用性。",
      "why_wrong": "选项 A 使用通用 SSD (Gp3)，支持 Multi-Attach，但 IO2 卷性能更好，更适合关键业务；选项 B 使用 HDD 卷 (ST1)，不适合高性能应用；选项 D 使用通用 SSD (Gp2)，性能不如 Io2。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "Gp3",
      "EBS 弹性块存储",
      "多连接",
      "HDD",
      "ST1",
      "Io2",
      "Gp2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 466,
    "topic": "",
    "question_cn": "一家公司设计了一个无状态的两级应用程序，该应用程序在一个可用性区域和一个亚马逊RDS数据库实例中使用亚马逊EC2。新的公司管理层希望确保该应用程序能得到广泛的应用。解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "配置应用程序以使用多AZ EC2自动缩放并创建应用程序负载平衡器",
      "B": "配置应用程序以获取EC2实例的快照并将其发送到不同的区域",
      "C": "配置应用程序以使用亚马逊Route 53的延迟路由向应用程序提供请求",
      "D": "配置亚马逊Route 53规则来处理传入的请求并创建一个多AZ应用程序负载平衡器"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "RDS Multi-AZ"
    ],
    "explanation": {
      "analysis": "考点是应用程序高可用性和可扩展性的设计。正确答案提供多 AZ 和负载均衡，满足高可用和高扩展需求。",
      "why_correct": "选项 A 采用了多可用区、自动伸缩和负载均衡，提供了高可用性和可伸缩性。负载均衡器确保流量分配，自动伸缩组根据负载调整实例数量，多可用区保证了故障转移能力。",
      "why_wrong": "选项 B 涉及快照和跨区域复制，但没有解决高可用性和自动扩展问题。选项 C 仅使用 Route 53 延迟路由，没有解决实例故障的问题。选项 D 仅配置 Route 53，没有高可用性和自动扩展功能。"
    },
    "related_terms": [
      "EC2",
      "Multi-AZ",
      "RDS",
      "EC2",
      "自动缩放",
      "应用程序负载平衡器",
      "Amazon Route 53",
      "Route 53",
      "应用程序负载平衡器(ALB)"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 467,
    "topic": "",
    "question_cn": "一家公司使用的是美国劳工协会的组织。一个会员帐户购买了一个计算储蓄计划。由于成员账户内工作量的变化，账户不再获得计算储蓄计划承付款的全部好处。该公司使用不到其购买的计算能力的50%。解决方案架构师应该做什么来解决这个问题？",
    "options_cn": {
      "A": "从购买计算储蓄计划的会员账户中的帐户控制台的账单优先权部分打开折扣共享。",
      "B": "打开公司组织管理账户中帐户控制台的账单优先权部分的折扣共享。",
      "C": "将额外的计算负载从另一个AWS账户迁移到具有计算节约计划的账户。",
      "D": "在保留的实例市场上出售多余的储蓄计划承诺。"
    },
    "vote_percentage": "68%",
    "tags": [
      "Compute Savings Plans",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "考点是理解 AWS Organizations 和 Savings Plans 之间的关系以及如何优化成本。 通过组织账单共享可以优化成本。",
      "why_correct": "选项 B 是正确的，通过在组织管理账户中启用账单优先共享，可以使组织内的所有账户共享 Savings Plans 的折扣。这是优化成本的最有效方法。",
      "why_wrong": "选项 A 在会员账户中操作，无法实现组织级别的成本优化。选项 C 将额外负载迁移到另一个账户，不能解决现有 Savings Plans 的利用率问题。选项 D 涉及出售保留实例市场上的储蓄计划，较为复杂，而且不一定是最佳的解决方案。"
    },
    "related_terms": [
      "AWS",
      "计算储蓄计划",
      "AWS",
      "AWS账户"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 468,
    "topic": "",
    "question_cn": "一家公司正在开发一个微服务应用程序，为客户提供一个搜索目录。公司必须使用REST API向用户展示应用程序的正面。其余的API必须访问公司在私有VPC子网容器中的后端服务。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊API网关设计一个网络接口。在一个私人子网中的亚马逊弹性容器服务中托管该应用程序。为API网关创建一个VPC专用链接以访问亚马逊系统。",
      "B": "使用亚马逊API网关设计REST API。在一个私人子网中的亚马逊弹性容器服务中托管该应用程序。为API网关创建一个专用的VPC链接以访问亚马逊系统。",
      "C": "使用亚马逊API网关设计一个网络接口。在一个私人子网中的亚马逊弹性容器服务中托管该应用程序。创建一个安全组为API网关访问亚马逊系统。",
      "D": "使用亚马逊API网关设计REST API。在一个私人子网中的亚马逊弹性容器服务中托管该应用程序。创建一个安全组为API网关访问亚马逊系统。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "VPC",
      "ECS"
    ],
    "explanation": {
      "analysis": "考点是设计一个安全的、可访问的 API 架构，其中涉及 API Gateway、ECS 和 VPC 专用链接。",
      "why_correct": "选项 B 正确使用了 API 网关，在私有子网中托管应用程序，并通过 VPC 专用链接安全地连接 API 网关和后端服务，满足安全性和私有网络的需要。使用了 REST API。",
      "why_wrong": "选项 A 虽然使用了 API 网关和 VPC 专用链接，但是缺少 REST API 的描述，因此不符合题目要求。选项 C 使用安全组，这不如 VPC 专用链接安全。选项 D 使用了安全组，而且没有 REST API 的描述，不如选项 B 完整和安全。"
    },
    "related_terms": [
      "Amazon API Gateway",
      "REST API",
      "VPC",
      "Amazon ECS",
      "VPC",
      "专用链接",
      "安全组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 469,
    "topic": "",
    "question_cn": "一家公司用亚马逊S3桶存储原始数据。数据用于代表公司客户进行的几种类型的分析。请求的分析类型决定了S3对象上的访问模式。该公司无法预测或控制访问模式。该公司希望降低其S3成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用S3复制将不经常访问的对象过渡到S3标准不经常访问(S3-IA)存储类。",
      "B": "使用S3生命周期规则将对象从S3标准转换为S3标准不经常访问(S3-IA)。",
      "C": "使用S3生命周期规则将对象从S3标准转换为S3智能分层。",
      "D": "使用S3库存来识别和转换未从S3标准访问到S3智能分层的对象。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Storage Classes",
      "S3 Lifecycle Rules"
    ],
    "explanation": {
      "analysis": "考点是S3存储类和生命周期规则的使用，以优化存储成本。智能分层可以根据访问频率自动调整存储类别。",
      "why_correct": "选项 C 使用 S3 生命周期规则将对象转换为 S3 智能分层。S3 智能分层会自动将对象移动到访问频率较低的存储层，从而降低成本。因为访问模式不可预测，智能分层是最佳选择。",
      "why_wrong": "选项 A 使用复制，会增加存储成本。选项 B 只转换为 S3 标准不经常访问，这不适合不可预测的访问模式。选项 D 使用库存来识别和转换对象，这增加了管理复杂性，而且不如智能分层自动化。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "S3",
      "S3 Transfer Acceleration",
      "S3标准不经常访问(S3-IA)",
      "S3生命周期规则",
      "S3智能分层",
      "S3库存"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 470,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例中使用IPv6地址托管应用程序。应用程序必须启动与使用互联网的其他外部应用程序的通信。然而，该公司的安全政策规定任何外部服务都不能启动对EC2实例的连接。解决方案架构师应该建议什么来解决这个问题？",
    "options_cn": {
      "A": "创建一个NAT网关并使它成为子网路由表的目的地",
      "B": "创建一个互联网网关并使它成为子网路由表的目的地",
      "C": "创建一个虚拟专用网关使其成为子网路由表的目的地",
      "D": "创建一个仅限出站互联网网关并使它成为子网路由表的目的地"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 IPv6",
      "Internet Gateway"
    ],
    "explanation": {
      "analysis": "考点是使用 IPv6 和出站互联网连接。IPv6 不支持 NAT，需要配置出站互联网网关。",
      "why_correct": "选项 D 描述了使用一个仅限出站的互联网网关。这满足了 IPv6 的需求，并且允许 EC2 实例启动到外部服务的连接，同时阻止外部服务主动连接到 EC2 实例。这样可以满足安全策略，同时允许出站流量。",
      "why_wrong": "选项 A 描述了使用 NAT 网关，NAT 网关不适用于 IPv6。选项 B 描述了使用互联网网关，但没有指定出站。选项 C 描述了使用虚拟专用网关，虚拟专用网关与互联网连接无关。"
    },
    "related_terms": [
      "EC2",
      "IPv6",
      "NAT网关",
      "互联网网关",
      "VPC",
      "虚拟专用网关",
      "仅限出站互联网网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 471,
    "topic": "",
    "question_cn": "一家公司正在创建一个应用程序，它在VPC中的容器上运行。应用程序存储和访问数据在一个亚马逊S3桶。在开发阶段，应用程序将每天存储和访问亚马逊S3中的1TB数据。该公司希望尽可能降低成本，并在可能的情况下防止流量通过互联网。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为S3桶启用S3智能分层",
      "B": "使S3桶的传输加速",
      "C": "为VPC创建亚马逊S3网关端点。将此端点与VPC中的所有路由表关联",
      "D": "在VPC中为亚马逊S3创建一个接口端点。将此端点与VPC中的所有路由表关联"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 VPC Endpoint",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考点是降低S3存储和数据传输成本，以及避免通过公共互联网传输数据。S3 网关端点提供 VPC 内的 S3 访问，而无需通过 Internet。",
      "why_correct": "选项 C 为 VPC 创建 S3 网关端点。这允许容器化的应用程序在 VPC 内访问 S3，而无需流量通过互联网。网关端点不收取数据传输费用，有助于降低成本。",
      "why_wrong": "选项 A 启用智能分层优化的是存储成本，不是网络传输成本。选项 B 启用传输加速优化的是S3上传性能，而非成本。选项 D 创建接口端点，接口端点会产生费用，并且也增加了复杂性，不如网关端点。"
    },
    "related_terms": [
      "VPC",
      "S3",
      "Amazon S3",
      "S3",
      "S3智能分层",
      "S3",
      "S3",
      "传输加速",
      "亚马逊S3网关端点",
      "VPC",
      "亚马逊S3",
      "接口端点",
      "VPC"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 472,
    "topic": "",
    "question_cn": "一家公司拥有一个移动聊天应用程序，其数据库位于亚马逊DynamoDB。用户希望在尽可能少的延迟情况下读取新消息。解决方案架构师需要设计一个最优的解决方案，它只需要最小的应用程序更改。解决方案架构师应该选择哪种方法？",
    "options_cn": {
      "A": "为新消息表配置亚马逊DynamoDB加速器(DAX)。更新代码以使用DAX端点。",
      "B": "添加DynamoDB读取副本来处理增加的读取负载。更新应用程序以指向读取副本的读取端点。",
      "C": "在DynamoDB中新消息表的读容量单位的两倍。继续使用现有DynamoDB端点。",
      "D": "为缓存添加一个亚马逊弹性缓存到应用程序栈。更新应用程序以指向缓存端点而不是DynamoDB。"
    },
    "vote_percentage": "93%",
    "tags": [
      "DynamoDB DAX",
      "Caching"
    ],
    "explanation": {
      "analysis": "考点是利用 DAX (DynamoDB Accelerator) 来减少 DynamoDB 的读取延迟。DAX 是针对 DynamoDB 的缓存解决方案，可以显著提高性能。",
      "why_correct": "选项 A 为新消息表配置 DAX。DAX 是一种为 DynamoDB 设计的缓存服务，可以显著减少读取延迟。通过更新应用程序以使用 DAX 端点，可以实现最小的应用程序更改。",
      "why_wrong": "选项 B 涉及读取副本，但读取副本主要用于提高读取吞吐量，而不是降低延迟。选项 C 增加读取容量单元，有助于提高吞吐量，但不会显著降低延迟。选项 D 引入了 ElastiCache，需要进行更大的应用程序更改。"
    },
    "related_terms": [
      "DynamoDB",
      "DAX",
      "DynamoDB",
      "读取副本",
      "弹性缓存"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 473,
    "topic": "",
    "question_cn": "一个公司在一个应用负载平衡器(ALB)背后的亚马逊EC2实例上拥有一个网站。网站提供静态内容。网站流量正在增加，公司担心成本可能增加。",
    "options_cn": {
      "A": "创建一个亚马逊CloudFront分布以缓存边缘位置的状态文件",
      "B": "创建一个亚马逊弹性计算集群。将ALB连接到弹性计算集群以提供缓存文件",
      "C": "创建一个AWS WAF WebACL网络并将其与ALB联系起来。向WebACL添加一条规则来缓存静态文件",
      "D": "在另一个区域创建第二个ALB。将用户流量路由到最近区域以尽量减少数据传输成本"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Caching"
    ],
    "explanation": {
      "analysis": "考点是使用 CloudFront 内容分发网络来缓存静态内容，以减少负载均衡器的负载和降低延迟。",
      "why_correct": "选项 A 创建一个 CloudFront 分布以缓存静态文件。CloudFront 是一种内容分发网络，可以将静态内容缓存在边缘位置，从而减少服务器负载和数据传输成本，并提高用户体验。",
      "why_wrong": "选项 B 虽然提到缓存，但使用了 Elastic Compute Cluster，不如 CloudFront 适合静态内容缓存。选项 C 使用 WAF 来缓存静态文件，WAF 主要用于安全防护，缓存功能相对有限。选项 D 涉及到在另一个区域创建 ALB，用于减少数据传输成本，但没有解决原始服务器的负载问题。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "CloudFront",
      "弹性计算集群",
      "AWS WAF",
      "WebACL",
      "ALB",
      "数据传输"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 474,
    "topic": "",
    "question_cn": "一个公司在AWS区域拥有多个VPC来支持和运行与其他区域的工作负载隔离的工作负载。由于最近的应用启动要求，该公司的VPC必须与所有区域的所有其他VPC通信。用最少的行政努力来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "使用VPC窥视来管理单个区域的VPC通信。使用跨区域窥视管理VPC通信。",
      "B": "使用直接连接所有区域的网关来连接跨区域的VPC通信和管理VPC通信。",
      "C": "使用传输网关来管理单个区域的VPC通信和跨区域的传输网关来管理VPC通信。",
      "D": "使用所有区域的私人链接连接各区域的VPC通信并管理VPC通信"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Peering",
      "Transit Gateway"
    ],
    "explanation": {
      "analysis": "考点是跨 VPC 之间安全、高效且易于管理的通信。使用 Transit Gateway 是最佳实践。",
      "why_correct": "选项 C 使用 Transit Gateway 来管理区域内的 VPC 通信以及跨区域的 VPC 通信。Transit Gateway 简化了跨多个 VPC 的连接，减少了管理开销。",
      "why_wrong": "选项 A 使用 VPC 窥视，管理多个 VPC 之间的连接会变得复杂。选项 B 使用直接连接所有区域的网关，无法横向扩展。选项 D 使用 PrivateLink，虽然安全，但不如 Transit Gateway 灵活且成本高。"
    },
    "related_terms": [
      "VPC",
      "VPC",
      "VPC",
      "VPC",
      "VPC",
      "VPC",
      "VPC 窥视",
      "VPC",
      "跨区域窥视",
      "网关",
      "传输网关",
      "私人链接"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 475,
    "topic": "",
    "question_cn": "一家公司正在设计一个集装箱化的应用程序，它将使用亚马逊弹性容器服务。该应用程序需要访问一个高度持久性的共享文件系统，AWS 8小时。该系统可以将数据恢复到另一个区域，恢复点目标是8小时。文件系统需要提供一个挂载目标，在区域内的每个可用区域AWS解决方案架构师希望使用备份来管理到另一个区域的复制。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用多AZ部署的亚马逊FSx for Windows File Server",
      "B": "使用多AZ部署的亚马逊FSx for NetApp ONTAP",
      "C": "具有标准存储类别的亚马逊弹性文件系统",
      "D": "亚马逊FSx for OpenZFS"
    },
    "vote_percentage": "88%",
    "tags": [
      "EFS",
      "FSx",
      "Multi-AZ"
    ],
    "explanation": {
      "analysis": "考点是选择合适的共享文件系统，支持多可用区部署和区域间复制。",
      "why_correct": "选项 C 弹性文件系统(EFS) 具有标准存储类别，支持多可用区部署，满足了对高度持久性和可用性的要求。可以跨区域复制。",
      "why_wrong": "选项 A 和 B 使用 FSx，但可能不如 EFS 灵活，没有描述其复制功能。选项 D FSx for OpenZFS 在这里并不适用。"
    },
    "related_terms": [
      "ECS",
      "FSx for Windows File Server",
      "FSx for NetApp ONTAP",
      "EFS",
      "FSx for OpenZFS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 476,
    "topic": "",
    "question_cn": "一家公司预计在不久的将来会快速增长。解决方案架构师需要配置现有用户并在AWS上授予新用户权限。解决方案架构师已经决定使用IAM创建组。解决方案架构师将向基于部门的IAM组添加新的用户。哪个附加操作是授予新用户权限的最安全的方式？",
    "options_cn": {
      "A": "应用服务控制策略来管理访问权限",
      "B": "创建具有最少特权权限的IAM角色。将角色赋予机构间管理小组",
      "C": "创建一个授予最少特权权限的IAM策略。向机构间管理小组提供IAM策略。",
      "D": "创建IAM角色。将角色与定义最大权限的权限边界关联"
    },
    "vote_percentage": "92%",
    "tags": [
      "IAM",
      "Least Privilege"
    ],
    "explanation": {
      "analysis": "考点是确保 IAM 策略的安全性和最小特权原则。创建和提供 IAM 策略是正确的方式。",
      "why_correct": "选项 C 创建一个授予最少特权权限的IAM策略。向机构间管理小组提供IAM策略。这是实现最小特权访问的最佳方法。授予用户仅执行其任务所需的权限。",
      "why_wrong": "选项 A 使用服务控制策略（SCP）来管理访问权限，SCP 主要用于 AWS Organizations，而不是在单个账户中管理用户权限。选项 B 使用 IAM 角色，这通常用于在不同账户或服务之间委托权限，而不是直接为用户授予权限。选项 D 使用权限边界，权限边界定义了 IAM 角色或用户的最大权限，但无法授予最小特权。"
    },
    "related_terms": [
      "IAM",
      "IAM",
      "IAM",
      "IAM",
      "服务控制策略",
      "IAM角色",
      "IAM策略",
      "权限边界"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 477,
    "topic": "",
    "question_cn": "一个组需要权限来列出一个亚马逊S3桶并从桶中删除对象。管理员创建了下列IAM策略以提供访问桶的权限并将该策略应用于组。组无法删除桶中的对象。该公司遵循最低特权准入规则。解决方案架构师应该在策略中添加哪个语句来纠正桶访问？",
    "options_cn": {
      "A": "无",
      "C": "无"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "S3 Permissions"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。D选项是正确的，因为它提供了删除对象的权限。",
      "why_correct": "D选项需要在策略中添加s3:DeleteObject权限，以允许组删除桶中的对象，满足题目要求。",
      "why_wrong": "由于题目缺少策略的具体内容，无法细致分析其他选项的错误。"
    },
    "related_terms": [
      "S3",
      "IAM",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 478,
    "topic": "",
    "question_cn": "律师事务所需要与公众分享信息。这些信息包括数百个必须公开可读的文件。禁止任何人在指定的未来日期之前修改或删除文件。哪个解决方案将以最安全的方式满足这些要求？",
    "options_cn": {
      "A": "将所有文件上传到为静态网站托管配置的亚马逊S3桶。对访问S3桶直到指定日期的任何主体授予只读 IAM权限。",
      "B": "创建一个新的亚马逊S3桶与版本控制启用。使用S3对象锁定并根据指定日期保留时间。配置静态网站托管的S3桶。设置一个S3桶策略允许只读访问对象。",
      "C": "创建一个新的亚马逊S3桶与版本控制启用。在对象修改或删除的情况下配置事件触发器来运行Lambda函数。配置Lambda函数用私有S3桶中的原始版本替换对象。",
      "D": "将所有文件上传到为静态网站托管配置的亚马逊S3桶。选择包含文件的文件夹。使用S3对象锁定并根据指定日期保留时间。向访问S3桶的任何IAM主体授予只读 IAM权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Object Lock",
      "S3 Versioning",
      "Static Website Hosting"
    ],
    "explanation": {
      "analysis": "考点是 S3 对象锁定、版本控制和静态网站托管，以实现文件的不可变性和公开访问。",
      "why_correct": "选项 B 结合了 S3 对象锁定，版本控制，静态网站托管和桶策略，提供了最安全、最可靠的解决方案。S3 对象锁定可以防止删除或修改文件，版本控制可以保留文件的历史版本，确保了文件的不可变性。",
      "why_wrong": "选项 A 仅使用桶策略，没有实现文件锁定，无法保证文件的不可变性。选项 C 使用 Lambda 函数来替换对象，这增加了复杂性，并且可能存在漏洞。选项 D 描述了使用对象锁定，但没有启用版本控制，也容易发生数据丢失。"
    },
    "related_terms": [
      "S3",
      "S3",
      "IAM",
      "S3",
      "版本控制",
      "S3对象锁定",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 479,
    "topic": "",
    "question_cn": "一家公司正在手动提供必要的基础设施为其新网站制作基础设施原型。该基础设施包括一个自动缩放组、一个应用负载平衡器和一个RDS亚马逊数据库。在配置被彻底验证后，该公司希望能够以自动化的方式在两个可用性区域立即部署用于开发和生产的基础设施。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "使用AWS系统管理器在两个可用性区域复制和提供原型基础设施",
      "B": "通过使用原型基础结构作为指南来定义基础结构作为代码模板。部署基础设施与AWS CloudFormation。",
      "C": "使用AWS配置来记录原型基础结构中使用的资源目录。使用AWS配置将原型基础结构部署到两个可用性区域。",
      "D": "使用AWS弹性豆柄并将其配置为使用原型基础结构的自动引用以在两个可用性区自动部署新环境。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFormation",
      "Infrastructure as Code"
    ],
    "explanation": {
      "analysis": "考点是使用基础设施即代码 (IaC) 工具（如 CloudFormation）来实现自动化部署和基础设施管理。",
      "why_correct": "选项 B 通过使用原型基础设施作为指南，定义基础架构作为代码模板，并使用 AWS CloudFormation 部署基础设施，这提供了最灵活、可重复、可维护的解决方案，符合 IaC 最佳实践。",
      "why_wrong": "选项 A 使用系统管理器，但系统管理器主要用于管理和运维，而不是基础设施部署。选项 C 使用 AWS 配置，主要用于合规性和审计，而不是用于部署。选项 D 使用 Elastic Beanstalk，虽然适用于部署 Web 应用程序，但不如 CloudFormation 灵活，不能完全满足要求。"
    },
    "related_terms": [
      "自动缩放组",
      "应用负载平衡器",
      "RDS",
      "AWS CloudFormation",
      "AWS",
      "AWS弹性豆柄"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 480,
    "topic": "",
    "question_cn": "一个业务应用程序在亚马逊EC2上托管并使用亚马逊S3进行加密对象存储。首席信息安全官已指示这两个部门之间的应用程序流量不应通过公共互联网。解决方案架构师应该使用哪种能力来满足合规性要求？",
    "options_cn": {
      "A": "主要管理服务",
      "B": "VPC端点",
      "C": "私有子网",
      "D": "虚拟专用网关"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "Security"
    ],
    "explanation": {
      "analysis": "考点是保证 EC2 和 S3 之间的数据流量不通过公共互联网，满足安全合规性要求。VPC 端点是实现这一目标的关键。",
      "why_correct": "选项 B 使用 VPC 端点。VPC 端点允许 EC2 实例通过 VPC 内部的网络连接到 S3，而无需流量经过公共互联网，从而满足安全合规性要求。",
      "why_wrong": "选项 A 主要管理服务，这是一个广泛的术语，不能直接满足需求。选项 C 私有子网只是隔离网络的一部分，并不能阻止流量通过互联网。选项 D 虚拟专用网关与此情景无关，主要用于 VPN 连接。"
    },
    "related_terms": [
      "EC2",
      "Amazon S3",
      "VPC",
      "VPC",
      "VPC端点",
      "虚拟专用网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 481,
    "topic": "",
    "question_cn": "一家公司在AWS云中拥有一个三层的应用程序。对于数据库层来说，一个多亚马逊RDS形成了数据库层，亚马逊弹性缓存形成了缓存层。该公司需要一种缓存策略，当客户向数据库添加项目时，该策略可以在缓存中添加或更新数据。缓存中的数据必须始终与数据库中的数据相匹配。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "实现懒惰加载缓存策略",
      "B": "实施书面缓存策略",
      "C": "实施TTL添加缓存策略",
      "D": "执行应用程序缓存策略"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Caching"
    ],
    "explanation": {
      "analysis": "考查RDS数据库的缓存策略，需要数据在缓存和数据库中保持同步。",
      "why_correct": "书面缓存策略可以保证数据在写入数据库时，同时写入缓存，实现同步。",
      "why_wrong": "懒惰加载会在读取时才加载缓存，无法保证同步；TTL会使缓存过期；选项D不是一个明确的缓存策略。"
    },
    "related_terms": [
      "RDS",
      "Amazon ElasticCache",
      "懒惰加载缓存策略",
      "TTL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 482,
    "topic": "",
    "question_cn": "一家公司希望将100GB的历史数据从一个内部位置迁移到一个亚马逊S3桶。该公司在酒店内有100兆比特每秒的互联网连接。公司需要将传输中的数据加密到S3桶。该公司将直接在亚马逊S3上存储新数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS CLI 中的同步命令将数据直接移动到S3桶",
      "B": "使用 AWS DataSync 将数据从现场位置迁移到S3桶",
      "C": "使用AWS Snowball将数据移动到S3桶",
      "D": "建立一个IPSec VPN 从酒店内的位置到 AWS。使用AWS CLI中的cp命令将数据直接移动到S3桶"
    },
    "vote_percentage": "59%",
    "tags": [
      "S3 Data Transfer",
      "AWS DataSync"
    ],
    "explanation": {
      "analysis": "考查如何将数据高效地迁移到S3桶，需要考虑网络带宽、数据量和加密需求。",
      "why_correct": "AWS DataSync专门用于数据迁移，提供加密、带宽优化等功能，最适合。",
      "why_wrong": "AWS CLI同步命令效率较低，不适合大批量数据迁移；Snowball 适用于大量离线数据迁移，不适用；VPN+AWS CLI需要手动设置，开销较大。"
    },
    "related_terms": [
      "S3",
      "AWS CLI",
      "AWS DataSync",
      "AWS Snowball",
      "IPSec VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 483,
    "topic": "",
    "question_cn": "一家公司用容器装了一个Windows工作。该工作基于一个Windows容器，该公司希望在AWS云中运行这项工作。这项工作每十分钟进行一次。作业的运行时间从1分钟到3分钟不等。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "根据工作的容器图像创建一个Lambda函数。每隔十分钟配置一次亚马逊事件桥来调用此功能。",
      "B": "使用AWS Batch创建一个使用Fargate资源的作业。将作业调度配置为每十分钟运行一次。",
      "C": "使用亚马逊弹性容器服务 (ECS) 亚马逊服务在AWS Fargate运行的工作。根据作业的容器图像每十分钟创建一个预定任务。",
      "D": "使用亚马逊弹性容器服务 (ECS) 亚马逊服务在AWS Fargate运行的工作。根据作业的容器映像创建一个独立的任务。使用Windows任务调度程序运行作业。"
    },
    "vote_percentage": "53%",
    "tags": [
      "AWS ECS",
      "AWS Fargate"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，C选项提供了最直接、最适合容器化工作负载的解决方案。它使用ECS和Fargate来运行容器，并使用ECS的计划任务功能，每十分钟运行一次任务。",
      "why_correct": "C选项使用ECS和Fargate，最适合容器化工作负载。ECS的计划任务功能可以每十分钟运行一次任务。",
      "why_wrong": "A选项使用Lambda函数，不太适合长时间运行的任务，且Lambda启动可能需要时间，效率不如ECS。B选项使用AWS Batch，Batch更适合大规模批处理任务，对于十分钟一次的任务来说，过于重量级。D选项需要使用Windows的任务调度程序，增加了复杂性。"
    },
    "related_terms": [
      "Lambda",
      "Amazon EventBridge",
      "AWS Batch",
      "Fargate",
      "ECS",
      "Windows容器",
      "Windows任务调度程序"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 484,
    "topic": "",
    "question_cn": "一家公司希望从许多独立的AWS账户转向一个统一的多账户体系结构。该公司计划为不同的业务部门创建许多新的AWS账户。公司需要使用集中的企业目录服务来验证对这些账户的访问。解决方案架构师应该推荐哪些操作组合来满足这些需求？选二。",
    "options_cn": {
      "A": "在AWS Organizations中创建一个具有所有功能的新组织。在组织中创建新的AWS账户。",
      "B": "建立一个Amazon身份池。配置IAM Identity Center(IAM 身份中心) 单一登录来接受身份验证。",
      "C": "配置AWS服务控制策略(SCP)来管理AWS账户。将IAM Identity Center 单点登录添加到目录服务中。",
      "D": "在AWS Organizations中创建一个新的组织。将组织的身份验证机制配置为直接使用目录服务。",
      "E": "在IAM Organizations中建立IAM Identity Center(IAM 身份中心)单一登录。配置IAM Identity Center(IAM 身份中心)并将其集成到公司的企业目录服务中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Organizations",
      "IAM Identity Center",
      "SCP"
    ],
    "explanation": {
      "analysis": "考查使用AWS Organizations进行多账户管理，并集成IAM Identity Center实现SSO。",
      "why_correct": "A: 创建组织并创建子账户是多账户体系结构的基础；E: 配置IAM Identity Center进行SSO，实现集中认证。",
      "why_wrong": "B: Amazon身份池通常用于移动端应用，不适用；C: SCP用于账户权限管理，而非SSO；D: 无法直接使用目录服务进行身份验证。"
    },
    "related_terms": [
      "AWS Organizations",
      "IAM Identity Center",
      "IAM 身份中心",
      "SCP",
      "AWS服务控制策略",
      "目录服务"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 485,
    "topic": "",
    "question_cn": "一家公司正在寻找一种可以从旧新闻片段中存储视频档案的解决方案。公司需要尽量减少成本，也很少需要恢复这些文件。当需要文件时，必须在最多五分钟内提供。最具成本效益的解决办法是什么？",
    "options_cn": {
      "A": "将视频档案存放在亚马逊S3 Glacier并使用快速检索。",
      "B": "将视频档案存放在亚马逊S3 Glacier并使用标准检索。",
      "C": "将视频档案存放在亚马逊S3标准-不常访问（S3-IA）标准。",
      "D": "将视频档案存放在亚马逊S3区域不常访问(S3-IA)区域。"
    },
    "vote_percentage": "96%",
    "tags": [
      "S3 Glacier",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A选项提供了最低的存储成本，并且可以使用快速检索在规定时间内检索文件。",
      "why_correct": "A选项提供了最低的存储成本(S3 Glacier)，并且可以使用快速检索，满足了成本和检索时间的需求。",
      "why_wrong": "B选项使用S3 Glacier标准检索，检索时间较长。C和D选项使用S3-IA，存储成本较高，无法满足题目中对最低成本的要求。"
    },
    "related_terms": [
      "S3 Glacier",
      "快速检索",
      "标准检索",
      "S3-IA",
      "S3-IA",
      "区域不常访问"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 486,
    "topic": "",
    "question_cn": "一家公司正在建立一个三层的应用程序。演示层将服务于静态网站，逻辑层是一个集装箱化的应用程序。这个应用程序将在关系数据库中存储数据。该公司希望简化部署并降低运营成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon S3来托管静态内容。使用Amazon Elastic Container Service(ECS)的Fargate计算。在数据库中使用受管理的Amazon RDS集群。",
      "B": "使用Amazon EC2来存储静态内容。使用Amazon Elastic Container Service(ECS)结合 Amazon EC2计算。在数据库中使用受管理的Amazon RDS集群。",
      "C": "使用Amazon S3来主机静态内容。使用Amazon Elastic Kubernetes Service(EKS)结合Amazon Fargate计算。在数据库中使用受管理的 RDS集群。",
      "D": "使用Amazon EC2保留实例来托管静态内容。使用Amazon Elastic Kubernetes Service(EKS)与Amazon EC2计算。在数据库RDS中使用受管理的Amazon RDS集群。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "ECS",
      "Fargate",
      "RDS"
    ],
    "explanation": {
      "analysis": "考查构建三层应用，需要选择合适的服务，降低运营成本。",
      "why_correct": "A: S3托管静态网站，ECS+Fargate运行容器化应用，RDS提供数据库服务，均为托管服务，便于运维。",
      "why_wrong": "B: EC2需要管理，运维成本高；C: EKS和Fargate组合虽然可行，但复杂度增加；D: EC2和EKS组合复杂度更高，同时需要维护EC2实例。"
    },
    "related_terms": [
      "S3",
      "ECS",
      "Fargate",
      "RDS",
      "EC2",
      "EKS",
      "EC2保留实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 487,
    "topic": "",
    "question_cn": "公司为其应用寻求存储解决方案。解决方案必须是高度可用和可伸缩的。解决方案还必须作为一个文件系统的功能可以通过本地协议在Linux实例中和在本地的多个VPN实例上进行移植并且没有最小规模的需求。该公司已经建立了一个站点到现场的VPN以便从其内部VPC网络进入其AWS。哪些存储方案满足这些要求？",
    "options_cn": {
      "A": "Amazon FSx for Lustre，多AZ部署",
      "B": "Amazon EBS",
      "C": "具有多个安装目标的Amazon EFS",
      "D": "具有单个挂载目标和多个访问点的Amazon EFS"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "File System",
      "VPN"
    ],
    "explanation": {
      "analysis": "考查选择合适的存储方案，需要考虑可用性、可扩展性、文件系统功能以及VPN访问。",
      "why_correct": "EFS具有高度可用和可伸缩性，支持多个挂载目标，方便通过VPN访问，满足所有要求。",
      "why_wrong": "FSx for Lustre 适用于高性能计算场景；EBS是块存储，不提供文件系统功能；D不具备高可用性。"
    },
    "related_terms": [
      "Amazon FSx for Lustre",
      "多AZ",
      "EBS",
      "EFS",
      "站点到现场的VPN",
      "VPC"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 488,
    "topic": "",
    "question_cn": "一家有4年历史的媒体公司正在使用AWS Organizations的所有功能设置以组织其AWS账户。根据该公司的财务团队，任何人包括会员账户的用户都不得获取会员账户上的账单信息。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将所有财务团队的用户添加到IAM组中。向该组附上一个称为账单的托管策略。",
      "B": "附加基于身份的策略以拒绝包括根用户在内的所有用户访问账单信息。",
      "C": "创建一个服务控制策略(SCP) 来拒绝访问账单信息。将SCP连接到根组织单元(OU)。",
      "D": "从组织转换所有功能功能设置到组织合并账单功能集。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Organizations",
      "SCP",
      "Billing"
    ],
    "explanation": {
      "analysis": "考查如何通过SCP限制对账单信息的访问。",
      "why_correct": "SCP可以全局性地控制账户权限，将SCP连接到OU可以限制OU下所有账户对账单的访问。",
      "why_wrong": "IAM策略限制的是用户权限，无法全局限制账户；B策略过于严格，可能会影响其他操作；D不是一个正确的解决方案。"
    },
    "related_terms": [
      "AWS Organizations",
      "IAM",
      "IAM组",
      "SCP",
      "OU",
      "组织单元",
      "合并账单"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 489,
    "topic": "",
    "question_cn": "一家电子商务公司在AWS云中运行一个应用程序，该应用程序与内部仓库解决方案集成在一起。该公司使用Amazon Simple Notification Service(SNS) 将订单消息发送到现场的端点，以便仓库应用程序可以处理订单。本地数据中心团队已经检测到一些订单消息没有收到。解决方案架构师需要保留未传递的消息并对消息进行长达14天的分析。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "配置一个具有Amazon SQS数据流目标且保留期为14天的Amazon死信队列。",
      "B": "添加一个Amazon Simple Queue Service(SQS) 队列保留期为14天之间的应用程序和Amazon SNS。",
      "C": "配置一个具有Amazon SQS目标且保留期为14天的Amazon死信队列。",
      "D": "配置具有TTL属性的Amazon DynamoDB目标且保留期为14天的Amazon死字队列。"
    },
    "vote_percentage": "71%",
    "tags": [
      "SNS",
      "SQS",
      "Dead Letter Queue"
    ],
    "explanation": {
      "analysis": "考查使用死信队列保留未传递消息，并进行分析。",
      "why_correct": "在SNS和SQS之间配置一个死信队列，将未传递的消息发送到SQS，并设置保留时间。",
      "why_wrong": "选项A没有指定目标；B无法保留未传递的消息；D将DynamoDB作为目标不正确。"
    },
    "related_terms": [
      "SNS",
      "SQS",
      "死信队列",
      "TTL",
      "DynamoDB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 490,
    "topic": "",
    "question_cn": "一家游戏公司使用Amazon DynamoDB存储用户信息，如地理位置、玩家数据和领导板。该公司需要配置持续备份到一个Amazon S3桶，最少的编码量。备份不得影响应用程序的可用性，也不得影响为表定义的读容量单元。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用Amazon EMR集群。创建一个Apache Hive任务以支持数据到Amazon S3。",
      "B": "通过连续备份直接将数据从DynamoDB输出到Amazon S3。打开表的实时恢复。",
      "C": "配置Amazon DynamoDB流。创建一个Lambda函数以消耗流并将数据导出一个Amazon S3桶。",
      "D": "创建一个Lambda函数定期将数据库表中的数据导出到Amazon S3。打开表的实时恢复。"
    },
    "vote_percentage": "87%",
    "tags": [
      "DynamoDB Backup",
      "DynamoDB Streams"
    ],
    "explanation": {
      "analysis": "考查DynamoDB数据备份，需要考虑可用性和性能影响。",
      "why_correct": "通过连续备份直接将数据备份到S3，并且开启实时恢复，可以实现最少编码量，且不影响应用程序可用性。",
      "why_wrong": "EMR方案需要额外的运维成本，且实现相对复杂；C方案会影响读写性能；D方案实现需要定期运行，数据不连续。"
    },
    "related_terms": [
      "DynamoDB",
      "S3",
      "EMR",
      "Apache Hive",
      "DynamoDB流",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 491,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个异步应用程序来处理银行的信用卡数据验证请求。应用程序必须是安全的并且能够处理每个请求至少一次。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用AWS Lambda事件源映射。设置Amazon Simple Queue Service(SQS)的标准队列作为事件源。使用AWS Key Management Service(KMS)进行加密。添加KMS: 解密对Lambda执行角色的权限。",
      "B": "使用Lambda事件源映射。使用Amazon Simple Queue Service(SQS)的FIFO队列作为事件源。使用小规模集管理加密密钥 (SSE-QS) 进行Lambda加密。为 Lambda 函数添加加密密钥调用权限。",
      "C": "使用Lambda事件源映射。设置Amazon Simple Queue Service(SQS)的FIFO队列作为事件源。使用KMS键(SSE-KMS)。添加KMS: 解密对Lambda执行角色的权限。",
      "D": "使用Lambda事件源映射。设置Amazon Simple Queue Service(SQS)的标准队列作为事件源。使用KMS键 进行Lambda加密。为 Lambda 函数添加加密密钥调用权限。"
    },
    "vote_percentage": "69%",
    "tags": [
      "Lambda",
      "SQS",
      "KMS",
      "Event Source Mapping"
    ],
    "explanation": {
      "analysis": "考查异步应用设计，需要保证安全性、至少一次处理，以及可靠的消息传递。",
      "why_correct": "使用Lambda事件源映射，SQS标准队列作为事件源，KMS加密，并赋予Lambda解密权限，可以保证消息处理的安全性。",
      "why_wrong": "FIFO队列不支持事件源映射，不适用；B使用SSE-QS，安全性较低；D的加密方案不完整。"
    },
    "related_terms": [
      "Lambda",
      "SQS",
      "KMS",
      "SSE-QS",
      "FIFO队列"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 492,
    "topic": "",
    "question_cn": "一家公司有多个AWS账户用于开发工作。一些员工一贯使用超大型Amazon EC2实例，这导致公司超过了年度开发账户预算。该公司希望在这些账户中集中限制建立AWS资源。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用批准的AWS CloudFormation 创建过程的系统管理器模板。使用已批准的系统管理器模板提供EC2实例。",
      "B": "利用AWS Organizations将账户组织成组织单位。定义并附加服务控制策略(SCP) 以控制EC2实例类型的使用。",
      "C": "配置在创建 EC2实例时调用Lambda函数的Amazon EventBridge规则。停止不允许的EC2实例类型。",
      "D": "为工作人员建立服务目录产品以创建允许的EC2实例类型。确保员工只能通过使用服务目录产品来部署EC2实例。"
    },
    "vote_percentage": "94%",
    "tags": [
      "EC2",
      "SCP",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "考查限制EC2实例类型的使用，控制成本。",
      "why_correct": "B: 使用AWS Organizations和SCP，可以集中控制账户中的EC2实例类型。",
      "why_wrong": "A需要手动创建和维护 CloudFormation 模板；C需要Lambda和EventBridge，实现较为复杂；D需要额外配置，实现相对复杂。"
    },
    "related_terms": [
      "EC2",
      "AWS CLI",
      "AWS CloudFormation",
      "系统管理器",
      "AWS Organizations",
      "SCP",
      "服务控制策略",
      "Amazon EventBridge",
      "Lambda",
      "服务目录"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 493,
    "topic": "",
    "question_cn": "一家公司希望使用人工智能(AI)来确定其客户服务呼叫的质量。该公司目前管理四种不同语言的电话，包括英语。公司将来将提供新的语言。公司没有资源定期维护机器学习模型。公司需要从客户服务呼叫记录中创建书面情绪分析报告。客户服务呼叫记录文本必须翻译成英文。哪些步骤组合将满足这些要求？选三。",
    "options_cn": {
      "A": "使用Amazon Comprehend将录音翻译成英语。",
      "B": "使用Amazon Lex创建书面情绪分析报告。",
      "C": "使用Amazon Polly将录音转换成文本。",
      "D": "使用Amazon Transcribe将任何语言的录音转换成文本。",
      "E": "使用Amazon Translate将文本翻译成英语。",
      "F": "使用Amazon Comprehend创建情绪分析报告。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Transcribe",
      "Amazon Translate",
      "Amazon Comprehend",
      "AI"
    ],
    "explanation": {
      "analysis": "考查使用AWS AI服务进行客户服务呼叫的情绪分析。",
      "why_correct": "D: 使用Amazon Transcribe将录音转换为文本；E: 使用Amazon Translate将文本翻译成英语；F: 使用Amazon Comprehend创建情绪分析报告。",
      "why_wrong": "A: Amazon Comprehend无法直接将录音翻译；B: Amazon Lex 用于构建对话交互；C: Amazon Polly 用于文本转语音。"
    },
    "related_terms": [
      "Amazon Comprehend",
      "Amazon Lex",
      "Amazon Polly",
      "Amazon Transcribe",
      "Amazon Translate"
    ],
    "best_answer": [
      "D",
      "E",
      "F"
    ],
    "official_answer": [
      "D",
      "E",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 494,
    "topic": "",
    "question_cn": "一家公司使用Amazon EC2实例来托管其内部系统。作为部署操作的一部分，管理员尝试使用 AWS CLI终止EC2实例。然而管理员接收到403(访问被拒绝)错误消息。署长使用的是IAM角色，并附有以下IAM策略。为何申请不成功？",
    "options_cn": {
      "A": "法院有一项以资源为基础的策略并有否认的声明。",
      "B": "策略声明中没有具体说明委托人。",
      "C": "操作字段不授予终止EC2实例所需的操作。",
      "D": "终止EC2实例的请求并非来自组或 CIDR 192.0.2/24 203.0.113.0/24。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "EC2"
    ],
    "explanation": {
      "analysis": "考查 IAM 策略权限问题，排查拒绝访问错误。",
      "why_correct": "请求并非来自允许的来源，检查策略的限制，确保访问请求的来源在策略的允许范围内。",
      "why_wrong": "A: 如果有拒绝声明，策略会直接拒绝访问，一般会有错误信息；B: IAM角色没有具体指明主体，由角色扮演者决定；C: 操作字段没有授权终止实例的权限则会报错，但此处可能由其他因素引起。"
    },
    "related_terms": [
      "EC2",
      "AWS CLI",
      "IAM",
      "IAM策略",
      "CIDR"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 495,
    "topic": "",
    "question_cn": "一家公司正在进行内部审计。该公司希望确保Amazon S3桶中与公司的湖组数据湖相关的数据不包含敏感的客户或员工数据。该公司希望发现个人身份识别信息或财务信息，包括护照号码和信用卡号码。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在账户上配置审计经理。选择支付卡行业数据安全标准(PCIDSS)进行审核。",
      "B": "配置Amazon S3库存，并在桶配置Amazon Athena查询库存。",
      "C": "配置Amazon Macie运行数据发现作业，该作业使用所需数据类型的托管标识符。",
      "D": "使用Amazon S3 Select在S3桶中运行一个报表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Data Security",
      "Amazon Macie"
    ],
    "explanation": {
      "analysis": "考查数据安全审计，需要发现S3桶中的敏感数据。",
      "why_correct": "Amazon Macie专门用于数据安全审计，可以使用托管标识符来发现敏感数据。",
      "why_wrong": "A: PCIDSS审计并非用于检测数据湖中的敏感数据；B: S3 Inventory用于列出S3对象， Athena用于查询，无法发现敏感数据；D: S3 Select 用于查询特定对象数据，不适用于审计场景。"
    },
    "related_terms": [
      "S3",
      "审计经理",
      "PCIDSS",
      "Amazon Athena",
      "Amazon Macie",
      "S3 Select"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 496,
    "topic": "",
    "question_cn": "一家公司使用内部服务器来主机其应用程序。这家公司的存储能力已用完了。应用程序同时使用块存储和NFS存储。该公司需要一个高性能的解决方案支持本地缓存而不必重新构建现有的应用程序。解决方案架构师应该采取哪些行动组合来满足这些需求？选二。",
    "options_cn": {
      "A": "将亚马逊S3作为一个文件系统提供给内部服务器。",
      "B": "部署一个存储网关文件网关来替换NFS存储。",
      "C": "部署滚雪球边缘提供EFS安装到内部服务器。",
      "D": "部署一个存储网关卷网关来替换块存储",
      "E": "部署亚马逊弹性文件系统(Amazon EFS)卷并将其安装到内部服务器上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "Storage Gateway"
    ],
    "explanation": {
      "analysis": "考查EFS和存储网关的使用场景，以及如何替换NFS和块存储。",
      "why_correct": "B和D选项通过使用存储网关的文件网关和卷网关，分别替换NFS和块存储，满足了题目需求，并保持了本地缓存的特性。",
      "why_wrong": "A选项使用S3作为文件系统，不适合本地缓存；C选项的滚雪球不适合用于替换NFS，E选项直接部署EFS，但没有替换块存储。"
    },
    "related_terms": [
      "S3",
      "存储网关",
      "EFS",
      "Snowball Edge",
      "NFS",
      "块存储",
      "文件网关",
      "卷网关"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 497,
    "topic": "",
    "question_cn": "一家公司拥有一种服务，可以在同一VPC区域的亚马逊S3桶中读取和编写大量数据。该服务部署在亚马逊EC2实例中的一个私有子网中，通过NAT网关与亚马逊S3通信。然而该公司希望找到一个能够降低数据输出成本的解决方案。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在公共子网络中提供一个专用的EC2 NAT实例。为私有子网配置路由表以使用这个实例的弹性网络接口作为所有S3流量的目标。",
      "B": "在专用子网中提供一个专用的EC2 NAT实例。为公共子网配置路由表以使用这个实例的弹性网络接口作为所有S3流量的目标。",
      "C": "提供VPC S3网关端点。为私有子网配置路由表以使用网关端点作为所有S3流量的路由。",
      "D": "提供第二个NAT网关。为私有子网配置路由表以使用此NAT网关作为所有S3流量的目的地。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3 Data Transfer Cost"
    ],
    "explanation": {
      "analysis": "考查VPC Endpoint, NAT Gateway和数据传输成本优化。",
      "why_correct": "C选项使用VPC S3网关端点，可以使私有子网中的EC2实例通过VPC内的连接访问S3，避免了数据传输经过Internet和NAT网关，从而降低了数据传输成本。",
      "why_wrong": "A和B选项通过NAT实例访问S3，虽然节省了公网IP费用，但仍然会产生数据传输费用。D选项使用第二个NAT网关，无法优化成本，而且增加了复杂性。"
    },
    "related_terms": [
      "VPC",
      "S3",
      "EC2",
      "NAT网关",
      "NAT实例",
      "VPC S3网关端点"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 498,
    "topic": "",
    "question_cn": "一个公司使用亚马逊S3存储高分辨率图片在一个S3桶。为了尽量减少应用程序的变化，该公司将图片存储为S3对象的最新版本。公司只需要保留这两张最新版本的图片。公司想降低S3成本。该公司已确定S3桶是一个巨大的费用。哪一种解决方案可以用最少的操作开销来降低S3成本？",
    "options_cn": {
      "A": "使用S3生命周期删除过期对象版本并保留两个最新版本。",
      "B": "使用AWS Lambda函数检查旧版本，删除所有版本，除了两个最新版本。",
      "C": "使用S3批处理操作删除非当前对象版本，只保留两个最新版本。",
      "D": "关闭S3桶上的版本控制并保留两个最新版本。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle",
      "S3 Versioning"
    ],
    "explanation": {
      "analysis": "考查S3版本控制和成本优化，侧重于使用生命周期规则删除旧版本。",
      "why_correct": "A选项使用S3生命周期策略，可以自动删除旧版本的对象，只保留最新的两个版本，能够以最少的运维开销实现成本优化。",
      "why_wrong": "B选项使用Lambda函数，增加了运维复杂性，且可能会有延迟。C选项使用S3批处理操作，增加了复杂性，不如生命周期规则方便。D选项关闭版本控制会丢失历史数据，不符合题目需求。"
    },
    "related_terms": [
      "S3",
      "S3生命周期",
      "AWS Lambda",
      "S3批处理"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 499,
    "topic": "",
    "question_cn": "一家公司需要最小化成本的1 Gbps直接连接连接。公司的平均连接利用率不到10%。解决方案架构师必须推荐一种能够在不损害安全性的情况下降低成本的解决方案。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "建立一个新的1gbps直接连接连接，共享与另一个帐户的连接。",
      "B": "在AWS管理控制台上建立一个新的200Mbps直接连接连接。",
      "C": "联系一个直接连接伙伴，订购一个1Gbps连接共享与另一个帐户的连接。",
      "D": "联系一个直接连接伙伴以订购一个200Mbps托管连接的现有帐户。"
    },
    "vote_percentage": "83%",
    "tags": [
      "AWS Direct Connect",
      "Hosted Connection"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，D选项提供了成本效益最高的方案。托管连接允许公司仅为实际使用的带宽付费，并且提供了比独享连接更低的成本，同时满足安全性需求。",
      "why_correct": "D选项通过订购200Mbps托管连接，降低了成本，并且托管连接可以根据实际带宽使用量计费，更具成本效益。托管连接也保持了安全性。",
      "why_wrong": "A选项共享连接虽然可以降低成本，但可能存在安全风险。B选项虽然建立200Mbps连接，但无法动态调整带宽，可能造成浪费。C选项订购共享连接，但不如托管连接灵活。"
    },
    "related_terms": [
      "Direct Connect"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 500,
    "topic": "",
    "question_cn": "一家公司内部有多个Windows文件服务器。该公司希望迁移和合并其文件到一个亚马逊FSx for Windows文件服务器文件系统。必须保存文件权限以确保访问权不会改变。哪些解决方案能满足这些要求？选二。",
    "options_cn": {
      "A": "在现场部署AWS数据监视系统。将数据传输到FSx for Windows文件服务器文件系统。",
      "B": "将每个文件服务器上的共享复制到亚马逊S3桶中使用AWS CLI。将数据传输到FSx for Windows文件服务器文件系统。",
      "C": "从每个文件服务器上移除驱动器。将驱动器运送到AWS以便导入亚马逊S3。将数据传输到FSx for Windows文件服务器文件系统的FSX。",
      "D": "订购一个自动雪锥装置。将设备连接到内部网络。在设备上启动数据化代理。将数据传输到FSx for Windows文件系统。",
      "E": "订购一个雪球边缘存储优化装置。将设备连接到内部网络。通过使用AWS CLI将数据复制到设备上。将设备送回AWS，以便导入亚马逊S3。将数据传输到FSx for Windows文件系统。"
    },
    "vote_percentage": "95%",
    "tags": [
      "FSx for Windows File Server",
      "Data Migration"
    ],
    "explanation": {
      "analysis": "考查使用AWS Snow Family 和DataSync进行数据迁移。",
      "why_correct": "A选项使用DataSync，可以保持文件权限，并将数据传输到FSx。D选项使用AWS Snowcone，可以快速将数据迁移到FSx。",
      "why_wrong": "B选项使用S3和AWS CLI，没有保持文件权限。C选项将驱动器运送，耗时较长，并且没有考虑到文件权限的迁移。E选项使用Snowball Edge，过于复杂。"
    },
    "related_terms": [
      "FSx for Windows",
      "AWS DataSync",
      "S3",
      "AWS CLI",
      "雪锥",
      "雪球边缘存储优化"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 501,
    "topic": "",
    "question_cn": "一家公司希望将客户支付数据输入亚马逊S3的公司数据湖。公司平均每分钟收到付款数据。公司想实时分析付款数据，然后公司想把数据输入数据湖。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊Kinesis Data Streams来吸收数据。用Lambda实时分析数据。",
      "B": "用AWS Glue吸收数据。使用亚马逊Kinesis Data Analytics实时分析数据。",
      "C": "使用亚马逊Kinesis Data Firehose吸收数据。使用亚马逊Kinesis Data Analytics实时分析数据。",
      "D": "使用API网关获取数据。用Lambda实时分析数据。"
    },
    "vote_percentage": "93%",
    "tags": [
      "Kinesis Data Firehose",
      "Kinesis Data Analytics"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，C选项使用Kinesis Data Firehose直接将数据导入S3，并且使用Kinesis Data Analytics进行实时分析，是更直接的解决方案。",
      "why_correct": "C选项使用Kinesis Data Firehose将数据导入S3，并使用Kinesis Data Analytics进行实时分析，可以满足实时分析和数据湖输入的需求。",
      "why_wrong": "A选项使用Kinesis Data Streams，需要Lambda处理，增加了复杂性。B选项使用Glue，用于ETL，不适用于实时分析。D选项使用API网关，需要Lambda处理，增加了复杂性。"
    },
    "related_terms": [
      "S3",
      "Kinesis Data Streams",
      "Lambda",
      "Glue",
      "Kinesis Data Analytics",
      "Kinesis Data Firehose",
      "API Gateway"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 502,
    "topic": "",
    "question_cn": "一家公司经营着一个网站，该网站使用亚马逊EC2上的内容管理系统。在一个EC2实例上运行了该系统，并在数据层中使用了一个亚马逊Aurora MySQL多AZ数据库实例。网站图像存储在亚马逊EBS弹性块存储EC2卷中安装在EC2实例中。解决方案架构师应该采取哪些组合行动来提高网站的性能和复原力？选二。",
    "options_cn": {
      "A": "将网站图像移动到安装在每个EC2实例上的亚马逊S3桶中。",
      "B": "通过使用来自主要EC2实例的NFS共享来共享网站图像。在其他EC2实例上安装此份额。",
      "C": "将网站图像移动到安装在每个EC2实例上的亚马逊EFS弹性文件系统亚马逊文件系统上。",
      "D": "从现有的EC2实例中创建一个亚马逊机器映像。将应用程序负载平衡器后面的新实例作为自动缩放组的一部分。配置自动缩放组以保持至少两个实例。为网站配置全球加速器。",
      "E": "从现有的EC2实例中创建一个亚马逊机器映像。将应用程序负载平衡器后面的新实例作为自动缩放组的一部分。配置自动缩放组以保持至少两个实例。为网站配置亚马逊云区分布。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Amazon S3",
      "Amazon EFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为DE，但社区共识(投票最高)为CE。社区倾向CE的原因是，它们从图像存储和计算弹性两个方面提高了网站性能和复原力。",
      "why_correct": "C选项使用EFS存储网站图像，实现了共享存储，提高了可用性。E选项使用自动缩放组和云区分布，提高了应用程序的弹性和性能。",
      "why_wrong": "A选项可以使用S3存储图像，但不是最佳实践。B选项使用NFS共享存储，增加了复杂性。D选项使用全球加速器，不能直接提高计算实例的性能。"
    },
    "related_terms": [
      "EC2",
      "Aurora MySQL",
      "Multi-AZ",
      "EBS",
      "NFS",
      "EFS",
      "AMI",
      "Application Load Balancer",
      "Auto Scaling",
      "Global Accelerator",
      "CloudFront"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 503,
    "topic": "",
    "question_cn": "一家公司经营着基础设施监控服务。该公司正在开发一个新功能，使该服务能够监控客户账户中的数据。这个新功能将在客户账户中调用AWS API来描述亚马逊EC2实例并读取亚马逊CloudWatch指标。公司应该如何以最安全的方式获得客户帐户的访问权？",
    "options_cn": {
      "A": "确保客户在他们的账户中创建一个IAM角色，使用只读EC2和CloudWatch权限以及公司帐户的信任策略。",
      "B": "创建一个无服务器AWS API，实现一个令牌自动售货机，为具有只读EC2和CloudWatch权限的角色提供临时的AWS凭证。",
      "C": "确保客户在其帐户中创建具有只读EC2和CloudWatch权限的用户。在保密管理系统中加密和存储客户访问密钥和密码。",
      "D": "确保客户在他们的账户中创建一个亚马逊代码用户，使用只读EC2和CloudWatch权限的角色。在一个秘密管理系统中加密和存储亚马逊密码用户和密码。"
    },
    "vote_percentage": "93%",
    "tags": [
      "IAM Role",
      "Cross-account Access"
    ],
    "explanation": {
      "analysis": "考查跨账户访问，使用IAM角色实现最安全的访问。",
      "why_correct": "A选项让客户创建IAM角色，并配置信任策略，授予公司账户访问权限，是跨账户访问最安全的方式。",
      "why_wrong": "B选项使用令牌自动售货机，增加了复杂性，且安全性不如IAM角色。C和D选项让客户创建用户，并存储访问密钥，安全性较低，并且难以管理。"
    },
    "related_terms": [
      "IAM",
      "EC2",
      "CloudWatch",
      "Lambda",
      "AWS API",
      "API",
      "AWS凭证",
      "代码用户",
      "AWS凭证"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 504,
    "topic": "",
    "question_cn": "一家公司需要连接美国东1号地区和美国西2号地区的几个VPC，这些公司覆盖了数百个账户。该公司的网络团队有自己的账户来管理云网络。什么是连接VPC的最有效的操作解决方案？",
    "options_cn": {
      "A": "在每个VPC之间建立VPC窥视连接。更新每个相关子网的路由表",
      "B": "在每个VPC中配置一个NAT网关和一个因特网网关，以便通过因特网连接每个VPC。",
      "C": "在网络团队的账户中创建一个AWS VPC中转网关。从每个VPC中配置静态路由。",
      "D": "在每个VPC中部署VPN网关。在网络团队的账户中创建一个传输VPN连接到每个VPC。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Peering",
      "Transit Gateway"
    ],
    "explanation": {
      "analysis": "考查VPC互联，以及Transit Gateway和VPC Peering的优缺点。",
      "why_correct": "C选项使用AWS Transit Gateway，可以简化VPC之间的连接，易于管理和扩展，是多VPC互联最有效的方案。",
      "why_wrong": "A选项使用VPC peering，在VPC数量较少时适用，但随着VPC数量增加，管理复杂度增加。B选项使用NAT网关和Internet网关，会经过Internet，增加了安全风险，且增加了成本。D选项使用VPN网关，性能较差，配置复杂。"
    },
    "related_terms": [
      "VPC",
      "VPC Peering",
      "NAT Gateway",
      "Internet Gateway",
      "VPC Transit Gateway",
      "VPN",
      "VPN Gateway"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 505,
    "topic": "",
    "question_cn": "一家公司有亚马逊EC2实例运行每晚的批处理作业来处理数据。EC2实例运行在一个使用点播账单的自动标度组中。如果一个作业在12:00到6:00一个实例中失败，另一个实例将重新处理作业。这些批处理工作每天在当地时间上午6:00到早上7:00之间进行。哪个解决方案将提供EC2实例以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "为自动缩放组的实例家族购买一个为期一年的储蓄计划，涵盖批处理工作使用的自动缩放组的实例家族。",
      "B": "为批处理工作使用的自动缩放组中的实例的特定实例类型和操作系统购买一个一年的保留实例。",
      "C": "为自动缩放组创建一个新的启动模板。设置实例以发现CPU使用量。设置一个根据CPU使用量扩展的策略。",
      "D": "为自动缩放组创建一个新的启动模板。增加实例大小。设置一个根据CPU使用量扩展的策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "Spot Instances",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "考查如何通过Auto Scaling，Spot实例和Savings Plans来优化EC2成本",
      "why_correct": "C选项 使用Spot实例，可以获得最大的成本效益。利用自动缩放组，在Spot实例不可用时，还可以保证任务的自动重试。",
      "why_wrong": "A选项：储蓄计划，只能节省固定负载的成本。B选项：保留实例，锁定实例类型，灵活性较差。D选项：调整实例大小。 成本优化效果有限，无法充分利用Spot实例的优势。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "点播",
      "实例家族",
      "储蓄计划",
      "保留实例",
      "实例类型",
      "启动模板",
      "CPU",
      "Auto Scaling"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 506,
    "topic": "",
    "question_cn": "一家社交媒体公司正在为其网站建立一个功能。该功能将使用户能够上传照片。该公司预计大型活动期间需求会大幅增加，必须确保网站能够处理用户上传的流量。哪个解决方案最能满足这些需求？",
    "options_cn": {
      "A": "从用户浏览器上传文件到应用服务器。把文件转移到一个亚马逊S3桶。",
      "B": "提供一个存储网关文件网关。直接从用户浏览器上传文件到文件网关。",
      "C": "在应用程序中生成亚马逊S3预先签名的URL。直接从用户浏览器上传文件到S3桶。",
      "D": "提供一个亚马逊弹性文件系统(Amazon EFS)文件系统。直接从用户浏览器上传文件到文件系统。"
    },
    "vote_percentage": "92%",
    "tags": [
      "S3 Pre-signed URL",
      "Scalability",
      "Security"
    ],
    "explanation": {
      "analysis": "考查用户上传文件到S3的方案，以及性能和安全性。",
      "why_correct": "C选项在应用程序中生成S3预先签名的URL，允许用户直接从浏览器上传文件到S3桶。这减轻了应用服务器的负担，提高了性能，并保证了安全性。",
      "why_wrong": "A选项通过应用服务器上传，会增加服务器的负载，性能较差。B选项使用存储网关，增加了复杂性，不适合用户上传。D选项使用EFS，不适合大规模用户上传，且性能不如S3。"
    },
    "related_terms": [
      "S3",
      "存储网关",
      "EFS",
      "预先签名的URL",
      "Application",
      "Browser",
      "S3桶"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 507,
    "topic": "",
    "question_cn": "一家公司有旅游票务的网络应用程序。该应用程序基于一个运行在北美单一数据中心的数据库。该公司希望扩大应用程序为全球用户群服务。该公司需要将该应用程序部署到多个AWS区域。在更新预订数据库时平均延迟时间必须小于1秒。该公司希望在多个区域分别部署其网络平台。然而该公司必须维护一个全局一致的原始预订数据库。解决方案架构师应该推荐哪种解决方案来满足这些需求？",
    "options_cn": {
      "A": "转换应用程序使用亚马逊DynamoDB。使用中心预订表的全局表。在每个区域部署中使用正确的区域端点。",
      "B": "将数据库迁移到亚马逊Aurora的MySQL数据库。在每个区域部署读极光副本。在每个区域部署中使用正确的区域端点访问数据库。",
      "C": "将数据库迁移到一个用于MySQL数据库的亚马逊RDS。在每个区域部署读取副本。在每个区域部署中使用正确的区域端点访问数据库。",
      "D": "迁移到亚马逊极光无服务器数据库的应用程序。在每个区域部署数据库实例。在每个区域部署中使用正确的区域端点访问 AWS 数据库。使用Lambda函数处理每个区域的事件流来同步数据库。"
    },
    "vote_percentage": "58%",
    "tags": [
      "Amazon DynamoDB",
      "Global Tables"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，A选项使用了DynamoDB全局表，可以提供更低的延迟和全局一致性，满足了题目的要求。",
      "why_correct": "A选项使用DynamoDB全局表，可以提供低延迟和全局一致性。在每个区域部署应用程序，使用正确的区域端点可以进一步提高性能。",
      "why_wrong": "B选项使用Aurora MySQL，虽然可以提供读取副本，但是延迟会高于DynamoDB全局表。C选项使用RDS MySQL读取副本，延迟更高，不满足题目要求。D选项使用Aurora Serverless数据库和Lambda同步，增加了复杂性，且同步可能导致延迟。"
    },
    "related_terms": [
      "DynamoDB",
      "MySQL",
      "Aurora",
      "RDS",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 508,
    "topic": "",
    "question_cn": "一家公司已经将多个微软Windows服务器工作负载迁移到在美国西部地区运行的亚马逊EC2实例。该公司手动备份工作负载以创建图像所需。在美国西部1区发生自然灾害的情况下，该公司希望迅速恢复西部1区的工作量。该公司希望在EC2实例上的数据损失不超过24小时。该公司还希望使EC2实例的任何备份自动化。用最少的行政努力哪些解决方案能满足这些要求？选二。",
    "options_cn": {
      "A": "创建一个由亚马逊支持的亚马逊机器映像生命周期策略，以创建一个基于标签的备份。安排备份每天运行两次。按需复制图像",
      "B": "创建一个由亚马逊支持的亚马逊机器映像生命周期策略，以创建一个基于标签的备份。安排备份每天运行两次。将副本配置到美国西部2区。",
      "C": "在美国西部1区和美国西部2区创建备份保险库，通过使用AWS Backup备份。根据标签值为EC2实例创建备份计划。创建一个作为计划作业运行的Lambda函数，以便将备份数据复制到美国西部2区。",
      "D": "通过使用AWS Backup创建一个备份保险库。使用AWS Backup为EC2实例创建基于标记值的备份计划。将副本的目的地定义为美国西部2区。指定每天运行两次的备份计划",
      "E": "通过使用AWS Backup创建一个备份保险库。使用AWS Backup为EC2实例创建基于标记值的备份计划。指定每天运行两次的备份计划。按需复制到美国西部2区。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Backup",
      "Amazon Data Lifecycle Manager (DLM)"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BC，但社区共识(投票最高)为BD。社区倾向BD的原因是，这两个选项均提供了自动化的、基于标签的备份，并且将备份数据复制到另一个区域，以满足快速恢复和数据损失最小化的要求。",
      "why_correct": "B和D选项均利用了AWS Backup，实现了自动化备份，并通过复制到另一个区域满足了灾难恢复的需求。B使用DLM，D使用Backup。 D 提供了更全面的备份策略。",
      "why_wrong": "A选项仅创建备份，没有异地备份。 C选项使用Lambda函数，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "AMI",
      "AWS Backup",
      "Lambda"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 509,
    "topic": "",
    "question_cn": "一家公司经营一个两级Web应用程序用于图像处理。应用程序使用两个可用性区域，每个区域有一个公共子网和一个私有子网。用于Web层的应用程序负载平衡器(ALB)使用公共子网。应用程序层的亚马逊EC2实例使用私有子网。用户报告说应用程序的运行速度比预期的要慢。对服务器日志文件的安全性审计显示应用程序正在接收少数IP地址的数百万个非法请求。解决方案架构师需要解决眼前的性能问题，而公司则需要研究更永久的解决方案。解决方案架构师应该建议什么来满足这个需求？",
    "options_cn": {
      "A": "修改Web层的入站安全组。为消耗资源的IP地址添加拒绝规则",
      "B": "修改Web层子网的网络ACL。为正在消耗资源的IP地址添加入站拒绝规则。",
      "C": "修改应用程序层的入站安全组。为消耗资源的IP地址添加拒绝规则",
      "D": "修改应用层子网的网络ACL。为正在消耗资源的IP地址添加入站拒绝规则。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Security Group",
      "Network ACL",
      "Denial of Service"
    ],
    "explanation": {
      "analysis": "考查Web应用程序的DoS攻击防护，以及安全组和网络ACL的作用。",
      "why_correct": "B选项修改Web层子网的网络ACL，添加拒绝规则。 网络ACL在子网级别过滤流量，可以拦截恶意流量，提高应用程序的性能。",
      "why_wrong": "A选项修改安全组，只对实例级别起作用，效果不如网络ACL。C选项修改应用层安全组，会影响应用程序的正常流量。D选项修改应用层网络ACL，会影响应用程序的正常流量。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "安全组",
      "网络ACL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 510,
    "topic": "",
    "question_cn": "一家全球营销公司的应用程序在亚太东南部地区和欧盟西部地区运行。在欧盟西部VPC-1中运行的应用程序需要安全地与在亚太东南部VPC-2中运行的数据库进行通信。哪些网络设计将满足这些要求？",
    "options_cn": {
      "A": "在欧盟西部和东南之间创建一个VPC窥视连接。在欧盟西部应用程序安全组中创建一个入站规则，该规则允许亚太东南安全组中来自数据库服务器地址的流量。",
      "B": "配置亚太东南部和欧盟西部之间的VPC窥视连接。更新子网路由表。在数据库安全组中创建一个入站规则，该规则引用欧盟应用程序服务器的安全组 ID。",
      "C": "配置亚太东南部和欧盟西部 的VPC窥视连接。对子网路由表进行排序。在数据库安全组中创建一个入站规则，该规则允许来自欧盟西部应用程序服务器地址的流量。",
      "D": "在欧盟西部和东南之间创建一个监视附件的传输网关。在适当查看传输网关并配置路由之后，在数据库安全组中创建一个入站规则，引用欧盟西部应用程序服务器的安全组 ID。"
    },
    "vote_percentage": "87%",
    "tags": [
      "VPC Peering",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，C选项描述了正确的 VPC 窥视连接的配置和安全组规则，以允许应用程序访问数据库。这保证了网络连接和安全性。",
      "why_correct": "C选项描述了正确的VPC窥视连接设置。设置安全组规则，允许应用程序安全组访问数据库安全组，满足了安全访问的需求。",
      "why_wrong": "A选项虽然建立了VPC窥视连接，但安全组规则可能配置错误。B选项配置正确，但说法不够明确。D选项使用了传输网关，增加了复杂性，而且是多VPC互联的最佳实践，本题为两个VPC互联。"
    },
    "related_terms": [
      "VPC",
      "VPC Peering",
      "安全组",
      "Transit Gateway"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 511,
    "topic": "",
    "question_cn": "一家公司正在开发一种使用PostgreSQL数据库架构的软件。公司需要为开发人员配置多个开发环境和数据库。平均而言，每个开发环境用于8小时工作日的一半。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用自己的亚马逊极光后PostgreSQL数据库配置每个开发环境",
      "B": "使用自己的亚马逊RDS来配置每个开发环境用于PostgreSQL单AZ数据库实例",
      "C": "配置每个开发环境及其亚马逊极光按需后兼容数据库",
      "D": "使用亚马逊S3对象选择使用自己的亚马逊S3桶配置每个开发环境"
    },
    "vote_percentage": "59%",
    "tags": [
      "Amazon Aurora PostgreSQL",
      "Amazon RDS PostgreSQL"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，C选项使用Aurora按需数据库，可以根据实际使用情况付费，满足了低成本且高可用性的要求。",
      "why_correct": "C选项使用Aurora按需数据库，提供了更灵活、更经济的解决方案，适用于开发环境，并且支持PostgreSQL。",
      "why_wrong": "A选项虽然使用Aurora，但没有按需，成本较高。B选项使用RDS单AZ实例，可用性较低。D选项使用S3对象选择，与数据库无关。"
    },
    "related_terms": [
      "PostgreSQL",
      "Aurora PostgreSQL",
      "RDS",
      "S3",
      "单AZ"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 512,
    "topic": "",
    "question_cn": "一家公司使用的是具有帐户标记的资源的 AWS 组织。该公司还使用备份支持其基础设施资源。该公司需要支持所有 AWS 服务的资源。 用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 AWS 配置来识别所有未标记的资源。以编程方式标记已标识的资源。在备份计划中使用标记。",
      "B": "使用 AWS 配置来标识所有未运行的资源。把这些资源添加到后备保险库中。",
      "C": "要求所有账户所有者审查他们的资源以确定需要备份的资源。",
      "D": "使用亚马逊检查员识别所有不符合要求的资源。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Backup",
      "Resource Tagging"
    ],
    "explanation": {
      "analysis": "考察如何使用标签和备份策略来管理AWS资源。",
      "why_correct": "A选项通过使用AWS配置规则检测未标记的资源，并自动标记，然后使用标签筛选备份，是最有效率的方式。",
      "why_wrong": "B选项只备份未运行的资源，无法满足备份所有资源的要求。C选项需要人工干预，效率低下。D选项是安全评估工具，不是备份方案。"
    },
    "related_terms": [
      "AWS Config",
      "S3"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 513,
    "topic": "",
    "question_cn": "一家社交媒体公司希望允许其用户在位于云的应用程序中上传图像。该公司需要一个解决方案自动调整图像大小以便图像可以显示在多个设备类型。应用程序在一天中体验到不可预测的流量模式。该公司正在寻求一个高度可用的解决方案最大化可伸缩性。 解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个位于 Amazon S3 的静态网站，该网站调用 Lambda 功能以调整图像的大小并将图像存储在一个 Amazon S3 桶中。",
      "B": "创建一个位于亚马逊云端的静态网站调用步骤功能来调整图像的大小并将图像存储在亚马逊数据库中。",
      "C": "在运行亚马逊 EC2实例的服务器上创建一个动态网站。配置一个在 EC2实例上运行的流程以调整图像的大小并将图像存储 S3 在一个亚马逊 S3 桶中。",
      "D": "在亚马逊弹性容器服务集群上创建一个动态的网站在亚马逊简单队列服务中创建一个调整任务。建立一个在亚马逊 EC2 实例上运行的图像修复程序以处理调整大小的作业。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Lambda",
      "Image Processing"
    ],
    "explanation": {
      "analysis": "考察图片处理的架构，重点是可伸缩性和可用性。",
      "why_correct": "A选项使用S3存储图片，Lambda处理图片调整大小，静态网站提供访问，符合高可用和可伸缩的需求。",
      "why_wrong": "B选项使用Step Functions和数据库，不适合图片存储和处理。C选项在EC2上运行，扩展性受限。D选项架构复杂，不如A选项简洁。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "EC2",
      "ECS",
      "EKS",
      "SQS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 514,
    "topic": "",
    "question_cn": "一家公司正在亚马逊 EC2实例上运行一个微服务应用程序。为了可伸缩性该公司希望将应用程序迁移到亚马逊弹性库伯内特斯服务 EKS 集群。该公司必须配置亚马逊控制平面与端点私有访问设置为真实和端点公共访问设置为假以维护安全合规性。公司还必须将数据平面放在私人子网中。然而由于节点无法加入集群该公司收到了错误通知。 哪个解决方案允许节点加入集群？",
    "options_cn": {
      "A": "IAM (IAM) 对亚马逊势利者角色授予身份和访问管理所需的权限。",
      "B": "创建 VPC 接口端点允许节点访问控制平面。",
      "C": "在公共子网中的恢复节点。限制节点的安全组。",
      "D": "允许节点安全组中的出站流量。"
    },
    "vote_percentage": "53%",
    "tags": [
      "EKS",
      "VPC Endpoint"
    ],
    "explanation": {
      "analysis": "考查 EKS 集群的私有访问配置和网络连通性问题。",
      "why_correct": "B选项通过创建 VPC 接口端点，允许节点通过私有网络访问 EKS 控制平面，解决节点无法加入集群的问题。",
      "why_wrong": "A选项涉及IAM权限，但不是根本原因。C选项将节点放置在公共子网，不符合私有访问的需求。D选项涉及安全组，但不能解决节点无法访问控制平面的问题。"
    },
    "related_terms": [
      "EC2",
      "EKS",
      "IAM",
      "VPC 接口端点",
      "安全组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 515,
    "topic": "",
    "question_cn": "一家公司正在将一个内部应用程序迁移到 AWS。该公司希望用 Amazon Redshift 作为解决方案。 在这种情况下哪些用例适合 Amazon Redshift？ 选三。",
    "options_cn": {
      "A": "API 用传统的、集装箱化的和事件驱动的应用程序访问数据的辅助数据",
      "B": "支持客户端和服务器端加密",
      "C": "在指定时间内和当应用程序不活动时建筑物分析工作量",
      "D": "缓存数据以减少后端数据库的压力",
      "E": "在全球范围扩展以支持五字节数据和千万次每分钟请求",
      "F": "使用管理控制台创建集群的次级副本"
    },
    "vote_percentage": "57%",
    "tags": [
      "Amazon Redshift",
      "Data Warehousing"
    ],
    "explanation": {
      "analysis": "考察 Redshift 的适用场景。",
      "why_correct": "B、C、E选项均是 Redshift 的适用场景。 Redshift 支持加密（B），适用于大规模数据分析和报表（C），以及高并发查询（E）。",
      "why_wrong": "A选项中，Redshift 并非用于访问辅助数据，而是用于分析和数据仓库。D选项， Redshift 无法缓存数据。 F 选项是 Redshift 集群副本的创建方式，并不直接适用。"
    },
    "related_terms": [
      "Redshift",
      "API",
      "SSL",
      "加密",
      "Redshift 集群",
      "复制"
    ],
    "best_answer": [
      "B",
      "C",
      "E"
    ],
    "official_answer": [
      "B",
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 516,
    "topic": "",
    "question_cn": "一家公司向客户提供一个 API 接口以便客户能够检索他们的财务信息。该公司预计在一年中使用高峰期会有更多的请求。 API 的响应一致低延迟以确保客户满意。公司需要为 API 提供一个计算主机。 用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用一个应用负载均衡器和亚马逊弹性容器服务 CCS 亚马逊 。",
      "B": "使用 Amazon API 网关和与供应并发的 Lambda 功能。",
      "C": "使用一个应用程序负载平衡器和一个亚马逊弹性库伯内特斯服务 EKS 亚马逊 集群。",
      "D": "使用具有保留并发性的 Amazon API 网关和 Lambda 功能。"
    },
    "vote_percentage": "74%",
    "tags": [
      "API Gateway",
      "Lambda",
      "Performance"
    ],
    "explanation": {
      "analysis": "考察 API 服务的构建，注重低延迟和高可用。",
      "why_correct": "B选项使用 API 网关和 Lambda，可以实现低延迟和弹性伸缩。 并且通过供应并发，可以应对峰值流量。",
      "why_wrong": "A选项和C选项使用ECS和EKS，管理开销较高。D选项虽然也使用了API Gateway和Lambda，但没有保留并发，可能无法保证高峰期的性能。"
    },
    "related_terms": [
      "Application Load Balancer",
      "ECS",
      "API Gateway",
      "Lambda",
      "EKS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 517,
    "topic": "",
    "question_cn": "一家公司希望将所有的系统管理器会话管理器日志发送到一个亚马逊S3桶以便存档。哪种解决方案能最有效地满足这一要求？",
    "options_cn": {
      "A": "启用系统管理器控制台中的S3日志记录。选择一个S3桶将会话数据发送到。",
      "B": "安装亚马逊云表代理。把所有日志都推到云表日志组。将日志从组中导出到S3桶以便存档。",
      "C": "创建一个系统管理器文档将所有服务器日志上传到一个中央S3桶。使用亚马逊文特布里奇来运行系统管理器文档针对每天帐 户中的所有服务器。",
      "D": "安装一个亚马逊云表代理。把所有日志都推到云表日志组。创建云表日志订阅将任何传入的日志事件推到亚马逊移动数S3据消防管传递流。将亚马逊S3设定为目的地。"
    },
    "vote_percentage": "92%",
    "tags": [
      "CloudWatch Logs",
      "S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是使用S3日志记录是直接且最简单的解决方案。",
      "why_correct": "选项A是最直接的解决方案，通过启用系统管理器控制台中的日志记录，并将日志发送到S3桶，满足了将日志存档的需求。",
      "why_wrong": "选项B、D引入了额外的复杂性，使用CloudWatch Logs和Firehose，增加了配置和管理的工作量。选项C使用 Systems Manager 文档，增加了配置的复杂性。"
    },
    "related_terms": [
      "S3",
      "系统管理器",
      "CloudWatch",
      "CloudWatch Logs",
      "EventBridge",
      "S3桶"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 518,
    "topic": "",
    "question_cn": "一个应用程序使用一个 Amazon RDS MySQL 数据库实例。 数据库在磁盘空间中越来越低。解决方案架构师希望增加磁盘空间而不需要停机。 用最少的努力来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "在 RDS 中启用存储自动分解",
      "B": "增加 RDS 数据库实例规模",
      "C": "将 RDS 数据库实例存储类型更改为提供的",
      "D": "备份 RDS 数据库增加存储能力恢复数据库并停止前一个实例"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Storage",
      "MySQL"
    ],
    "explanation": {
      "analysis": "考察 RDS 数据库存储空间的扩容，要求零停机。",
      "why_correct": "A选项启用存储自动扩展，可以自动增加存储空间，无需停机。",
      "why_wrong": "B选项涉及实例规模调整，可能会导致停机。C选项涉及存储类型变更，可能需要停机。D选项涉及备份恢复，停机时间更长。"
    },
    "related_terms": [
      "RDS",
      "自动分解",
      "RDS",
      "MySQL",
      "存储类型",
      "备份",
      "RDS数据库"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 519,
    "topic": "",
    "question_cn": "一家咨询公司为世界各地的客户提供专业服务，该公司为客户提供解决方案和工具以加快收集和分析 AWS 的数据。该公司需要集中管理和部署一套共同的解决方案和工具供客户为自助目的使用。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为客户创建 AWS CloudFormation 模板。",
      "B": "为客户创建 AWS 服务目录产品。",
      "C": "为客户创建 AWS System Manager 模板。",
      "D": "为客户创建 AWS 配置项目。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Service Catalog",
      "CloudFormation"
    ],
    "explanation": {
      "analysis": "考查为客户提供自助服务解决方案。",
      "why_correct": "B选项使用服务目录，可以集中管理和部署标准化的解决方案和工具，供客户自助使用。",
      "why_wrong": "A选项CloudFormation 模板需要客户手动部署，不便于管理。C选项 System Manager 主要用于管理 EC2 实例。D选项 Config 项目用于配置合规性，与题目要求不符。"
    },
    "related_terms": [
      "CloudFormation",
      "AWS 服务目录",
      "AWS Systems Manager",
      "AWS Config"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 520,
    "topic": "",
    "question_cn": "一家公司正在设计一种将在 Amazon EC2 实例上运行的新的 Web 应用程序。该应用程序将使用 Amazon DynamoDB 进行后端数据存储。应用程序流量将是不可预测的。该公司预计应用程序对数据库的读写吞吐量将是中等至高。该公司需要根据应用程序流量进行扩展。 哪个 DynamoDB 表配置最符合这些要求？",
    "options_cn": {
      "A": "通过使用 DynamoDB 标准表类配置配备的读写 DynamoDB。设置 DynamoDB 自动缩放到最大设定容量",
      "B": "使用标准表类按需配置 DynamoDB。",
      "C": "通过使用不经常访问 DynamoDB 标准表类配置配备的读写功能。设置 DynamoDB 自动缩放到最大设定容量",
      "D": "通过使用 DynamoDB 标准不经常访问 DynamoDB 标准表类按需配置 DynamoDB。"
    },
    "vote_percentage": "63%",
    "tags": [
      "DynamoDB",
      "Provisioned vs On-Demand"
    ],
    "explanation": {
      "analysis": "考查 DynamoDB 表配置的选择，尤其关注按需容量和自动扩展。",
      "why_correct": "B选项使用标准表类的按需容量模式，可以根据流量自动伸缩，无需预先配置容量，适合流量不可预测的应用。",
      "why_wrong": "A、C 选项需要预先设置容量，不适用于流量不可预测的情况。D 选项使用不经常访问表类，不适合高吞吐量应用。"
    },
    "related_terms": [
      "DynamoDB",
      "读写吞吐量"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 521,
    "topic": "",
    "question_cn": "一家零售公司有几个业务，每个业务的 IT 团队管理自己的帐户。每个团队帐户是一个组织的一部分在 AWS 组织中。每个团队在 Amazon DynamoDB 表中自己的帐户中监控其产品库存水平。 AWS  该公司正在将一个中央库存报告应用程序部署到一个共享的 帐户中。应用程序必须能够读取所有团队的 DynamoDB 表中的项目。 哪个认证选项将最安全地满足这些要求？",
    "options_cn": {
      "A": "在库存应用程序帐户中将 DynamoDB 与 AWS Secrets Manager 整合。将应用程序配置为使用来自机密管理器的正确秘密以验证和读取 DynamoDB 表。每 30 天安排一次秘密轮换。",
      "B": "在每个业务帐户中创建一个具有编程访问的 IAM 用户。将应用程序配置为使用正确的 IAM 用户访问键标识和秘密访问键来认证 IAM 和读取 DynamoDB 表。每 30 天手动旋转 IAM 访问键。",
      "C": "在每一个业务帐户中创建一个名为 Role 的角色，它带有一个策略使角色访问 DynamoDB 表和一个信任策略以信任库存应用帐户中 STSAssumerOL APP_ 的特定角色。在库存帐户中创建一个名为 APP_Role 的角色允许访问 STS 操作。将应用程序配置为使用 APP_Role 角色并承担 B_ 交叉帐户角色 角色来读取 DynamoDB 表。",
      "D": "将 DynamoDB 与 AWS 证书管理器 集成。生成身份证明来验证 DynamoDB。将应用程序配置为使用正确的证书来验证和读取 DynamoDB 表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "Cross-Account Access",
      "IAM"
    ],
    "explanation": {
      "analysis": "考察跨账户访问 DynamoDB 表的安全最佳实践。",
      "why_correct": "C选项使用跨账户 IAM 角色，允许库存应用程序扮演其他业务账户中的角色，从而安全地访问 DynamoDB 表。",
      "why_wrong": "A选项使用 Secrets Manager 管理密钥，但需要维护和轮换密钥，不如 IAM 角色安全。B选项使用 IAM 用户，不推荐，管理困难。D选项无法实现跨账号访问。"
    },
    "related_terms": [
      "DynamoDB",
      "IAM",
      "IAM 用户",
      "AWS Secrets Manager",
      "STS",
      "IAM 访问键"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 522,
    "topic": "",
    "question_cn": "一家公司通过使用 Amazon Elastic Kubernetes Service (EKS) 运营容器应用程序。公司一整天的工作量并不一致 该公司希望 Amazon EKS 能够根据工作量的大小进行扩展。 哪些步骤组合将以最少的操作开销满足这些要求？ 选二。",
    "options_cn": {
      "A": "使用 Lambda 函数来调整 EKS 集群的大小。",
      "B": "使用 Kubernetes 度量服务器来激活水平 Pod 自动卡线。",
      "C": "使用 Kubernetes 集群自动计算器来管理集群中的节点数。",
      "D": "使用 Amazon API 网关并连接到 Amazon EKS。",
      "E": "使用应用程序网眼观察网络活动。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EKS",
      "Horizontal Pod Autoscaling",
      "Cluster Autoscaler"
    ],
    "explanation": {
      "analysis": "考察 EKS 集群的弹性伸缩方案。",
      "why_correct": "B、C选项结合，可以实现 EKS 集群的弹性伸缩。B选项使用水平 Pod 自动伸缩（HPA），基于Pod的资源利用率自动调整Pod数量。C选项使用集群自动伸缩器（CA），根据Pod的需求自动调整集群中的节点数量。",
      "why_wrong": "A选项使用Lambda函数调整EKS集群大小, 维护成本较高。D选项API网关与EKS关系不大。E选项主要用于网络监控，与自动伸缩无关。"
    },
    "related_terms": [
      "EKS",
      "Lambda",
      "Kubernetes",
      "水平 Pod 自动卡线",
      "API Gateway",
      "节点",
      "Kubernetes 集群自动计算器"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 523,
    "topic": "",
    "question_cn": "一家公司运行一个基于微服务的无服务Web应用程序。应用程序必须能够从多个Amazon DynamoDB表中检索数据。解决方案架构师需要给 予应用程序在不影响应用程序基线性能的情况下检索数据的能力。哪个解决方案将以最有效的方式满足这些要求？",
    "options_cn": {
      "A": "管道解析器",
      "B": "在亚马逊云前带Lambda边缘功能",
      "C": "API Gateway经过边缘优化的亚马逊Lambda函数",
      "D": "Amazon Athena联合查询与DynamoDB连接器"
    },
    "vote_percentage": "49%",
    "tags": [
      "DynamoDB",
      "Amazon Athena"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是使用Athena的联合查询能够查询多个DynamoDB表，并且性能较好。",
      "why_correct": "选项D使用Amazon Athena联合查询和DynamoDB连接器，允许应用程序查询多个DynamoDB表，且Athena可以缓存结果以提高性能。",
      "why_wrong": "选项A、B、C 解决方案的效率和适用性不如Athena的联合查询，也可能涉及更复杂的配置和性能优化。"
    },
    "related_terms": [
      "DynamoDB",
      "Lambda",
      "API Gateway",
      "Lambda Edge",
      "Amazon Athena",
      "DynamoDB连接器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 524,
    "topic": "",
    "question_cn": "一家公司希望分析并排除与 IAM 权限相关的被拒绝的访问错误和未经授权的错误。公司的云跟踪已经打开了。 用最少的努力哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用 Glue 并编写自定义脚本来查询云跟踪日志的错误。",
      "B": "使用批处理并编写自定义脚本来查询云跟踪日志中的错误。",
      "C": "用 Amazon Athena 搜索 CloudTrail 日志来识别错误。",
      "D": "用 Amazon QuickSight 搜索 CloudTrail 日志。创建一个仪表板来识别错误。"
    },
    "vote_percentage": "68%",
    "tags": [
      "CloudTrail",
      "Athena",
      "IAM"
    ],
    "explanation": {
      "analysis": "考察如何通过 CloudTrail 日志排查 IAM 权限问题。",
      "why_correct": "C选项使用 Amazon Athena 查询 CloudTrail 日志，可以高效地搜索和分析日志，找到 IAM 权限相关的错误。",
      "why_wrong": "A和B选项使用 Glue 和 Batch，需要编写自定义脚本，比较繁琐。D选项使用 QuickSight，需要先配置仪表盘，不如Athena方便。"
    },
    "related_terms": [
      "IAM",
      "CloudTrail",
      "Glue",
      "Amazon Athena",
      "Amazon QuickSight"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 525,
    "topic": "",
    "question_cn": "一家公司想将其现有的AWS使用成本添加到其运营成本仪表板上。解决方案架构师需要推荐一种解决方案，这种解决方案将使公司能以编程方式访问其使用成本。公司必须能够获得本年度的成本数据和未来12个月的预测成本。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用带有分页的AWS Cost Explorer API访问使用成本相关数据。",
      "B": "通过使用可下载的AWS Cost Explorer报告访问使用成本相关数据。CSV文件。",
      "C": "配置AWS预算行动通过FTP向公司发送使用成本数据。",
      "D": "为使用成本数据创建AWS信息系统预算报告。通过将数据发送到公司。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Cost Explorer",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是使用Cost Explorer API，可以编程访问成本数据，实现自动化，并获取本年度和未来预测数据。",
      "why_correct": "选项A使用AWS Cost Explorer API，可以编程方式访问使用成本相关数据，包括年度和未来12个月的预测成本，满足了题目需求，并且操作开销最少。",
      "why_wrong": "选项B通过下载CSV文件，需要手动操作。选项C和D使用预算报告和FTP，增加了复杂性和延迟。"
    },
    "related_terms": [
      "AWS Cost Explorer API",
      "AWS 预算",
      "CSV",
      "AWS预算行动"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 526,
    "topic": "",
    "question_cn": "解决方案架构师正在审查应用程序的复原力。解决方案架构师注意到数据库管理员最近在应用程序的Amazon Aurora后格来格数据库编写实例中失败，这是一个扩展练习的一部分。故障转移导致应用程序 分钟的停机时间。哪个解决方案可以减少使用最少的操作开销来扩展练习的停机时间",
    "options_cn": {
      "A": "在集群中创建更多的Aurora读取副本以便在故障转移期间处理负载。",
      "B": "在同一区域建立一个次级Aurora集群。在故障转移期间更新应用程序以使用次级集群的编写端点。",
      "C": "在故障转移过程中创建一个用于管理负载的内存缓存集群的亚马逊弹性计算。",
      "D": "为数据库设置Amazon RDS 代理。更新应用程序以使用代理端点。"
    },
    "vote_percentage": "72%",
    "tags": [
      "Aurora",
      "RDS Proxy"
    ],
    "explanation": {
      "analysis": "该问题考察了如何在Aurora数据库发生故障时减少停机时间。正确答案是使用RDS Proxy，它能自动处理数据库连接并减少故障切换时间。",
      "why_correct": "RDS Proxy可以缓存数据库连接，并在发生故障转移时快速切换到新的数据库实例，从而减少停机时间。",
      "why_wrong": "选项A创建读取副本，虽然可以提高读取性能，但不能减少故障转移时间。选项B需要手动切换数据库端点，不能实现自动故障转移。选项C提供的解决方案与数据库故障转移无关。"
    },
    "related_terms": [
      "Amazon Aurora",
      "RDS",
      "故障转移",
      "Aurora读取副本",
      "弹性计算",
      "Amazon RDS 代理"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 527,
    "topic": "",
    "question_cn": "一家公司有一个基于区域订阅的Web流服务运行在单个的EC2区域。体系结构由Amazon EC2实例上的Web服务器和应用服务器组成。实例是在弹性负载平衡器后面的自动缩放组。该架构包括一个Amazon Aurora Global Database集群，该集群跨越多个可用性区域。该公司希望扩大全球业务并确保其应用的停机时间最少。哪个解决方案能提供最大的容错性？",
    "options_cn": {
      "A": "将Web层和应用程序层的自动缩放组扩展到第二区域的可用性区域中部署实例。使用Aurora Global Database在主区域和第二区域部署数据库。使用Amazon Route 53健康检查与故障转移路由策略到第二区域。",
      "B": "将Web层和应用程序层部署到第二区域。在第二区域添加一个Aurora跨区域Aurora副本。使用Amazon Route 53健康检查与故障转移路由策略到第二区域。根据需要将中学升为小学。",
      "C": "将Web层和应用程序层部署到第二区域。在第二区域创建Aurora后，使用AWS数据库迁移服务将主数据库复制到第二区域。使用Amazon Route 53健康检查与故障转移路由策略到第二区域。",
      "D": "将Web层和应用程序层部署到第二区域。使用Amazon Aurora Global Database在主区域和第二区域部署数据库。使用Amazon Route 53健康检查与故障转移路由策略到第二区域。根据需要将中学升为小学。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Aurora Global Database",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是 Aurora Global Database 提供了跨区域的灾难恢复能力，且实现停机时间最小化。",
      "why_correct": "选项D使用Aurora Global Database，在主区域和第二区域部署数据库，提供了最高级别的容错性和RTO/RPO目标，可以最大限度减少停机时间。",
      "why_wrong": "选项A 使用单独的数据库实例，无法达到与Global Database相同的容错级别。选项B虽然使用了跨区域副本，但是没有Global Database 那么方便。选项C使用了DMS，增加了复制的复杂性，不如Global Database直接。"
    },
    "related_terms": [
      "EC2",
      "Aurora Global Database",
      "Route 53",
      "故障转移路由策略",
      "AWS数据库迁移服务"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 528,
    "topic": "",
    "question_cn": "一家数据分析公司希望将其批处理系统迁移到AWS。该公司通过FTP每天定期收到几千个小数据文件。现场的批处理作业一夜之间处理数据文件。然而批处理工作需要几个小时才能完成。该公司希望AWS解决方案能够在对发送文件的客户端进行最小修改的情况下尽快处理传入的数据文件。解决方案必须在文件被成功处理后删除传入的数据文件。每个文件的处理需要3-8分钟。哪个解决方案将以最有效的方式满足这些要求？",
    "options_cn": {
      "A": "使用运行FTP服务器的Amazon EC2实例在Amazon S3 冰川的灵活检索中存储作为对象的传入文件。在批处理中配置作业队列。使用Amazon EventBridge规则调用作业来处理每晚从冰川灵活检索的对象。删除作业处理完对象后的对象",
      "B": "使用运行FTP服务器的Amazon EC2实例在Amazon EBS 卷中存储传入的文件。在批处理中配置作业队列。使用Amazon EventBridge规则调用作业来每晚从EBS卷中处理文件。在作业处理完文件后删除文件",
      "C": "使用AWS Transfer Family创建FTP服务器在Amazon EBS卷上存储传入文件。在批处理中配置作业队列。当每个文件到达时使用一个Amazon S3事件通知来调用批处理中的作业。在作业处理完文件后删除文件",
      "D": "使用AWS Transfer Family创建FTP服务器以在Amazon S3标准中存储传入的文件。创建一个Lambda函数来处理文件并在处理文件后删除文件。当文件到达时使用S3事件通知调用Lambda函数。"
    },
    "vote_percentage": "93%",
    "tags": [
      "AWS Transfer Family",
      "S3 Event Notifications",
      "Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是使用 AWS Transfer Family + S3 + Lambda 的组合，可以实现文件处理的自动化，并满足删除文件要求。",
      "why_correct": "选项D 使用AWS Transfer Family直接将文件上传到S3，然后通过S3事件触发Lambda函数处理文件，可以实现自动化，减少延迟，并满足删除文件的要求。",
      "why_wrong": "选项A 将文件存储在Glacier Flexible Retrieval中，会增加检索延迟。选项B 将文件存储在 EBS 中，不利于扩展和成本。选项C 虽然使用了事件通知，但使用了 EBS 而非 S3，并且配置略显复杂。"
    },
    "related_terms": [
      "S3",
      "EC2",
      "FTP",
      "冰川",
      "EventBridge",
      "EBS",
      "Transfer Family"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 529,
    "topic": "",
    "question_cn": "一家公司正在将其工作量转移到AWS。该公司的数据库中有交易数据和敏感数据。该公司希望使用云解决方案来提高安全性，减少数据库的运行开销。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到Amazon EC2。使用AWS KMS管理密钥进行加密。",
      "B": "将数据库迁移到Amazon RDS。配置加密在休息。",
      "C": "将数据迁移到Amazon S3。使用Amazon Macie进行数据安全和保护",
      "D": "将数据库迁移到Amazon RDS。使用Amazon CloudWatch日志进行数据安全和保护。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Encryption",
      "Database Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是RDS提供了开箱即用的加密 at rest 功能，并简化了管理。",
      "why_correct": "选项B 将数据库迁移到 RDS，并启用“加密在休息”功能，满足了安全性和减少运行开销的需求。 RDS 简化了加密管理。",
      "why_wrong": "选项A 使用EC2，需要手动管理数据库和加密，增加了管理复杂性。选项C，S3用于存储，不适用于数据库迁移。选项D 使用 CloudWatch Logs，主要用于监控和日志记录，而非数据库加密。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "KMS",
      "加密",
      "S3",
      "Macie",
      "CloudWatch"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 530,
    "topic": "",
    "question_cn": "一家公司有一个在线游戏应用程序，它具有UDP和HTML多人游戏功能。该公司使用Amazon Route 53将应用程序流量指向位于不同区域的多个网络负载平衡器。公司需要提高应用性能，减少在线游戏的延迟，为用户增长做准备。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "在NLBs前面添加Amazon CloudFront分布。增加Cache MAX-AGE控制年龄参数。",
      "B": "用应用负载平衡器替换NLBs。将Route 53配置为使用基于延迟的路由。",
      "C": "在NLBs前面添加AWS Global Accelerator。配置Global Accelerator端点以使用正确的侦听器端口。",
      "D": "在NLBs后面添加一个Amazon API Gateway端点。启用API缓存。覆盖不同阶段的方法缓存。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "Network Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是Global Accelerator可以改善用户体验，减少延迟。",
      "why_correct": "选项C 在NLBs前面添加AWS Global Accelerator，Global Accelerator通过使用AWS全球网络，可以优化网络性能，减少延迟，提高用户体验。",
      "why_wrong": "选项A CloudFront主要是用于CDN，对UDP和游戏场景优化有限。选项B 切换到ALB并使用延迟路由，并不能保证最优的性能。选项D API Gateway 主要用于 API 管理，不适合UDP和游戏流量。"
    },
    "related_terms": [
      "Route 53",
      "NLB",
      "CloudFront",
      "Cache MAX-AGE",
      "应用负载均衡器",
      "Global Accelerator",
      "API Gateway"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 531,
    "topic": "",
    "question_cn": "公司需要与第三方数据源集成。当新数据准备好供使用时，数据提要会发送一个网络挂钩通知外部服务。开发人员编写了一个Lambda函数，当公司收到一个网络挂钩的回调时来检索数据。开发人员必须使Lambda函数可供第三方调用。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "为Lambda函数创建一个Lambda URL。为网络钩提供Lambda函数URL给第三方。",
      "B": "将一个应用负载平衡器部署在Lambda函数前面。提供网站链接到第三方。",
      "C": "创建一个Amazon SNS主题。把这个话题附加到Lambda函数上。为网络钩提供向第三方提供的SNS主题的公共主机名。",
      "D": "创建一个Amazon SQS队列。将队列附加到Lambda函数上。向网络钩的第三方提供该SQS队列的公共主机名。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda URL",
      "API Integration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是 Lambda URL 为 Lambda 函数提供了直接的 HTTPS 接口，方便第三方调用。",
      "why_correct": "选项A 使用 Lambda URL 为 Lambda 函数创建了一个可以直接调用的URL。提供该URL给第三方，满足了第三方调用Lambda函数的需求，简单直接。",
      "why_wrong": "选项B 应用负载均衡器，增加了不必要的复杂性。选项C、D使用SNS或SQS，增加了额外的复杂性，也并不适合直接的HTTP调用。"
    },
    "related_terms": [
      "Lambda",
      "Lambda URL",
      "API Gateway",
      "SNS",
      "SQS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 532,
    "topic": "",
    "question_cn": "一家公司的工作量在一个AWS区域。客户通过使用Amazon API Gateway连接并访问工作负载。该公司使用Amazon Route 53作为其DNS URL提供商。该公司希望为所有客户提供单独和安全的API。(选择3个) 哪些步骤组合能最有效地满足这些要求？",
    "options_cn": {
      "A": "在Route 53托管区域中创建通配符自定义域名，并在指向 API Gateway端点的区域中进行记录。",
      "B": "请求一个通配符证书该证书与另一个区域的ACM中的域相匹配。",
      "C": "根据Route 53的要求为每个客户创建托管区域。创建指向API Gateway端点的区域记录。",
      "D": "请求一个通配符证书该证书与位于同一区域的ACM中的自定义域名相匹配。",
      "E": "在API Gateway中为每个客户创建多个端点。",
      "F": "在API Gateway中为其他创建自定义域名。从ACM导入证书。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Route 53",
      "ACM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CFD，但社区共识(投票最高)为ADF。社区倾向ADF的原因是提供了客户隔离，安全性和域名的自定义。",
      "why_correct": "选项A：在Route 53中创建通配符域名，简化了客户域名的管理。选项D：使用 ACM 的通配符证书保证了域名的安全性。选项F: 在 API Gateway 中为每个客户配置自定义域名，并导入 ACM 证书，确保了每个客户 API 的独立性和安全性。",
      "why_wrong": "选项 B：通配符证书与区域无关，并不需要与另一个区域的 ACM 匹配。选项 C：每个客户创建托管区域, 增加了管理复杂度。选项E：在 API Gateway 中为每个客户创建多个端点, 增加了管理复杂度。"
    },
    "related_terms": [
      "API Gateway",
      "Route 53",
      "ACM"
    ],
    "best_answer": [
      "A",
      "D",
      "F"
    ],
    "official_answer": [
      "C",
      "D",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 533,
    "topic": "",
    "question_cn": "一家公司用Amazon S3存储数据。根据条例，数据不得含有可识别个人身份的信息。该公司最近发现S3桶中含有PII的物品。公司需要自动检测S3桶中的PII并通知公司的安全小组。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon Macie。创建一个Amazon EventBridge规则以过滤来自 Macie 发现的敏感数据事件类型并向安全团队发送一个Amazon SNS通知。",
      "B": "使用Amazon GuardDuty。创建一个Amazon EventBridge规则以过滤关键事件类型从 GuardDuty 任务发现并发送一个Amazon SNS通知安全团队。",
      "C": "使用Amazon Macie。创建一个Amazon EventBridge规则以过滤敏感数据 对象 个人事件类型从Macie发现并发送一个Amazon SQS通知安全团队。",
      "D": "使用Amazon GuardDuty。创建一个Amazon EventBridge规则以过滤关键事件类型从 GuardDuty 任务发现并发送一个Amazon SQS通知安全团队。"
    },
    "vote_percentage": "83%",
    "tags": [
      "Amazon Macie",
      "EventBridge",
      "SNS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是Macie专门用于检测 S3 中的 PII 数据，并且使用 SNS 通知团队。",
      "why_correct": "选项A 使用Amazon Macie检测S3桶中的PII数据，然后使用EventBridge触发SNS通知发送给安全团队，完美匹配题目要求。",
      "why_wrong": "选项B、D 使用GuardDuty，GuardDuty 专注于威胁检测，并不专门用于 PII 数据检测。 选项C 使用SQS通知安全团队，不如SNS方便。"
    },
    "related_terms": [
      "S3",
      "PII",
      "Amazon Macie",
      "EventBridge",
      "SNS",
      "GuardDuty",
      "SQS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 534,
    "topic": "",
    "question_cn": "一家公司希望为它的多个AWS帐户建立一个日志解决方案。该公司目前将所有帐户的记录存入一个集中帐户。该公司已经在集中账户中创建了一个Amazon S3桶以存储VPC流日志和CloudTrail日志。所有日志必须有30天的高可用性以进行频繁分析，保留60天以供备份，并在创建后90天删除。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在创建后30天向S3标准存储类过渡对象。在90天后编写指向Amazon S3删除对象的过期操作。",
      "B": "在创建后30天内向S3标准-IA存储类别过渡。60天后将所有物体移到冰川灵活存储舱。在90天后编写指向Amazon S3删除对象的过期操作。",
      "C": "在创建后30天向冰川灵活检索存储舱过渡对象。在90天后编写指向Amazon S3删除对象的过期操作。",
      "D": "在创建后30天内向S3-IA存储类过渡对象。60天后将所有物体移到冰川灵活存储舱。在90天后编写指向Amazon S3删除对象的过期操作。"
    },
    "vote_percentage": "62%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，30天内保留，需要快速检索；30天后需要低成本，但是还需要备份，选择Glacier Flexible Retrieval是最佳实践。",
      "why_correct": "选项C 在创建后30天向冰川灵活检索存储舱过渡对象，在30天内提供高可用性分析，满足频繁访问的需求，并提供较低的存储成本，在90天后删除，满足保留策略",
      "why_wrong": "选项A 只有30天的数据分析，60天备份无法满足。选项B 和D ，虽然满足了 30 天和 60 天的数据保留要求，但是增加了存储成本。"
    },
    "related_terms": [
      "S3",
      "VPC 流日志",
      "CloudTrail",
      "S3 标准存储类",
      "S3 标准-IA",
      "冰川灵活检索",
      "S3 删除对象的过期操作"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 535,
    "topic": "",
    "question_cn": "一家公司正在建立一个Amazon Elastic Kubernetes Service (EKS)集群。所有存储在Amazon EKS中的秘密必须在Kubernetes电子数据存储中心加密。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个新的AWS KMS密钥。使用机密管理器来管理、旋转和存储Amazon EKS中的所有机密。",
      "B": "创建一个新的AWS KMS密钥。允许Amazon EKS秘密加密在Amazon EKS集群。",
      "C": "创建具有默认选项的Amazon EKS集群。使用Amazon EBS容器存储接口驱动程序作为一个附加。",
      "D": "用别名创建一个新的密钥管理服务密钥。为帐户启用默认Amazon EBS卷加密。"
    },
    "vote_percentage": "95%",
    "tags": [
      "EKS",
      "KMS",
      "Secrets Management"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是可以使用 KMS 直接对EKS中的秘密进行加密。",
      "why_correct": "选项B 创建一个新的AWS KMS密钥，允许EKS秘密加密，满足题目要求。AWS KMS 提供了加密功能。",
      "why_wrong": "选项A 使用机密管理器，增加了不必要的复杂性。选项C，使用 EBS 容器存储接口驱动程序，和秘密加密无关。选项D 是启用 EBS 卷加密，并不能直接对 EKS 秘密加密。"
    },
    "related_terms": [
      "EKS",
      "KMS",
      "Secrets Manager",
      "EBS",
      "AWS KMS密钥",
      "EKS 秘密加密"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 536,
    "topic": "",
    "question_cn": "一家公司希望为数据科学家提供接近实时的只读访问该公司生产的Amazon RDS的PostgreSQL数据库。该数据库目前配置为一个单可用区数据库。数据科学家使用不影响生产数据库的复杂查询。公司需要一个非常有效的解决方案。哪个解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在维护窗口中扩展现有的生产数据库为数据科学家提供足够的动力。",
      "B": "将设置从单可用区更改为具有较大的二级备用实例的多可用区实例部署。提供数据科学家访问二级实例",
      "C": "将设置从单可用区更改为多可用区实例部署。为数据科学家提供两个额外的阅读副本。",
      "D": "将设置从单可用区更改为具有两个可读的备用实例的多集群部署。向数据科学家提供读取端点。"
    },
    "vote_percentage": "82%",
    "tags": [
      "RDS Read Replicas",
      "PostgreSQL"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是可以使用RDS 多可用区部署，并且给数据科学家提供读取端点，来实现高可用和读取分离。",
      "why_correct": "选项D将设置从单可用区更改为具有两个可读的备用实例的多集群部署。向数据科学家提供读取端点。 使用 Multi-AZ with Read Replicas，提供了高可用性，并且给数据科学家提供读取端点，实现读取流量分离，满足题目要求。",
      "why_wrong": "选项A 扩展现有的生产数据库，会影响生产数据库的性能。选项B 切换到Multi-AZ with Standby，数据科学家只能访问 Standby 实例，不能进行读取分离。选项C 选项和D类似，只是没有明确说明提供读取端点。"
    },
    "related_terms": [
      "RDS",
      "PostgreSQL",
      "多可用区",
      "二级备用实例",
      "读取副本",
      "多集群"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 537,
    "topic": "",
    "question_cn": "一家公司在AWS云中运行一个三层Web应用程序，它在三个可用性区域中运行。应用程序体系结构有一个应用程序负载平衡器，一个Web服务器以及一个运行在EC2实例上的MySQL数据库。该公司预计应用程序流量会突然增加。该公司希望能够扩大规模以满足未来的应用能力需求并确保所有三个可用性区的高可用性。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用多可用区数据库集群部署将MySQL数据库迁移到Amazon RDS。使用具有高可用性的Amazon EC2来存储会话数据和缓存读取。将Web服务器迁移到三个可用性区域中的自动缩放组。",
      "B": "使用多可用区数据库集群部署将MySQL数据库迁移到Amazon RDS。使用Amazon EC2来存储具有高可用性的会话数据和缓存读取。将Web服务器迁移到三个可用性区域中的自动缩放组。",
      "C": "将MySQL数据库迁移到Amazon DynamoDB，使用DynamoDB加速器缓存读取。将会话数据存储在DynamoDB中。将Web服务器迁移到三个可用性区域中的自动缩放组。",
      "D": "将MySQL数据库迁移到Amazon RDS中的单个可用性区域。使用具有高可用性的Amazon EC2来存储会话数据和缓存读取。将Web服务器迁移到三个可用性区域中的自动缩放组。"
    },
    "vote_percentage": "79%",
    "tags": [
      "RDS Multi-AZ",
      "Auto Scaling",
      "High Availability"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用 Multi-AZ RDS部署，将会话数据存储在 EC2 中，并使用自动缩放组，确保了所有组件的高可用性。",
      "why_correct": "选项A 使用 Multi-AZ RDS 部署，提供了数据库层的高可用性。 将Web服务器迁移到三个可用性区域中的自动缩放组，确保了应用程序层的高可用性。将 session 数据存放在高可用性的 EC2 实例中，保证了session 的高可用性，能够满足高可用性需求。",
      "why_wrong": "选项B 和 A 类似，区别在于 session 存储的 EC2 实例是不是高可用的。 选项C 使用 DynamoDB 和 DAX，增加了复杂性，且不适合关系型数据库的应用场景。选项D使用 单可用区 的 RDS 实例，无法满足 HA 的要求。"
    },
    "related_terms": [
      "Web应用程序",
      "EC2",
      "MySQL",
      "RDS",
      "应用程序负载均衡器",
      "自动缩放组",
      "DynamoDB",
      "DynamoDB加速器"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 538,
    "topic": "",
    "question_cn": "一家全球视频流媒体公司将Amazon CloudFront作为内容发布网络 (CDN)。该公司希望在多个国家分阶段推出内容。该公司需要确保那些在公司发布内容的国家之外的观众无法查看内容。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "通过使用允许列表在CloudFront的内容中添加地理限制。设置自定义错误消息。",
      "B": "设置一个新的URL限制内容。通过使用签名的URL和饼干授权访问。设置自定义错误消息",
      "C": "为公司发布的内容加密数据。设置自定义错误消息",
      "D": "为受限内容创建一个新的URL。为签署的URL设置一个有时限的访问策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "Geo-Restriction",
      "Signed URLs"
    ],
    "explanation": {
      "analysis": "该问题考察了如何限制CloudFront内容的分发区域。正确答案是使用地理限制。",
      "why_correct": "CloudFront支持地理限制，通过允许列表或阻止列表来限制内容的访问区域。这可以确保只有指定国家的用户才能访问内容。",
      "why_wrong": "选项B使用了签名的URL，虽然可以控制访问权限，但无法实现基于地理位置的限制。选项C使用了加密，但无法限制特定区域的访问。选项D使用签署的URL，并不能控制地理位置。"
    },
    "related_terms": [
      "CloudFront",
      "CDN",
      "地理限制",
      "签名的URL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 539,
    "topic": "",
    "question_cn": "一家公司希望使用AWS云来改进其内部的灾难恢复配置。该公司的核心生产业务应用程序使用微软的SQL Server标准，该标准在虚拟机 (VM)上运行。该应用程序具有30秒或更少的恢复点目标和60分钟的恢复时间目标。DR解决方案需要尽可能降低成本。哪个解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用微软SQL Server企业在现场服务器和AWS之间配置一个多站点的活动/活动设置并始终使用可用性组。",
      "B": "配置一个热待机Amazon RDS用于在AWS上的SQL Server数据库。配置AWS数据库迁移服务以使用更改数据捕获 (CDC)。",
      "C": "使用AWS弹性灾难恢复配置将磁盘更改复制为Amazon S3作为领航灯。",
      "D": "每晚使用第三方备份软件捕捉备份。在Amazon S3存储一个备用备份集。"
    },
    "vote_percentage": "58%",
    "tags": [
      "Disaster Recovery",
      "RDS for SQL Server",
      "AWS DMS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用 RDS for SQL Server with DMS 可以满足RTO/RPO，且成本相对较低。",
      "why_correct": "选项B 使用RDS for SQL Server，并结合DMS 进行 CDC 复制，可以满足RTO/RPO要求，并且成本相对较低。",
      "why_wrong": "选项A 虽然提供了HA，但是成本高昂。选项C 使用了AWS Elastic Disaster Recovery，可能无法达到RPO和RTO的需求。选项D 只能实现备份，不能满足 RTO/RPO 的需求。"
    },
    "related_terms": [
      "SQL Server",
      "VM",
      "RDS",
      "CDC",
      "弹性灾难恢复",
      "Amazon S3",
      "DR",
      "灾难恢复",
      "可用性组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 540,
    "topic": "",
    "question_cn": "公司有一个内部服务器使用甲骨文数据库来处理和存储客户信息。该公司希望使用Amazon RDS数据库服务来实现更高的可用性并提高应用程序性能。该公司还希望从其主要数据库系统中删除报表。哪个解决方案将以最有效的方式满足这些要求",
    "options_cn": {
      "A": "使用AWS Database Migration Service (DMS) 创建一个Amazon RDS数据库实例在多个可用区。将报表函数指向与主数据库实例分离的数据库实例。",
      "B": "在单可用区 (AZ) 部署中使用Amazon RDS 创建甲骨文数据库。在与主数据库实例相同的区域中创建读副本。将报告函数引导到读取副本。",
      "C": "使用部署在多可用区 (AZ) 集群部署中的Amazon RDS创建甲骨文数据库。引导报告函数在集群部署中使用读者实例。",
      "D": "使用部署在多个可用区 (AZ) 实例部署中的Amazon RDS创建Amazon Aurora数据库。将报告功能引导到读者实例。"
    },
    "vote_percentage": "67%",
    "tags": [
      "RDS",
      "Read Replicas",
      "Performance",
      "High Availability"
    ],
    "explanation": {
      "analysis": "该问题考察了如何提高Oracle数据库的可用性和性能，并分离报表负载。正确答案是使用Aurora的多可用区集群部署。",
      "why_correct": "在Aurora数据库的多可用区集群部署中，可以使用读取器实例来处理报表负载，减轻主数据库的压力，提高性能。多可用区部署也提供了高可用性。这种方案满足了所有需求。",
      "why_wrong": "选项A使用DMS，主要用于数据库迁移，不适合创建读副本。选项B和C创建了读取副本，但无法提供Aurora的性能和可用性优势。"
    },
    "related_terms": [
      "RDS",
      "Oracle",
      "DMS",
      "多可用区",
      "读副本",
      "Amazon Aurora"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 541,
    "topic": "",
    "question_cn": "一家公司想在AWS上建立一个网络应用程序。客户端访问网站的请求是不可预测的可以长期闲置。只有支付了订阅费的客户才能注册和使用应用程序。哪些步骤组合将最符合这些要求？ 选三。",
    "options_cn": {
      "A": "使用AWS API Gateway创建一个Lambda函数从Amazon DynamoDB检索用户信息。创建一个Amazon API Gateway端点来接受API调用。将调用发送到Lambda函数。",
      "B": "在应用程序负载平衡器的背后创建一个Amazon Elastic Container Service以从Amazon RDS检索用户信息。创建一个Amazon API Gateway端点来接受REST API调用。将调用发送到Lambda函数。",
      "C": "创建一个Amazon Cognito用户池来验证用户。",
      "D": "创建一个Amazon Cognito身份池来认证用户。",
      "E": "使用AWS Amplify使用HTML,CSS,js和为前置网站内容提供服务。使用一个集成的Amazon CloudFront配置。",
      "F": "使用Amazon S3静态网络托管与php,CSS,js。使用Amazon CloudFront服务于前沿网站内容。"
    },
    "vote_percentage": "80%",
    "tags": [
      "API Gateway",
      "Lambda",
      "Cognito",
      "Amplify",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "此题考察如何构建一个需要用户认证和前端Web应用的应用。正确答案组合涵盖了API Gateway, Lambda, Cognito 以及 Amplify, CloudFront等。其中A,C,E满足需求，B选项使用ECS不合适, D 选项不完整，F选项缺少用户认证机制",
      "why_correct": "A,C,E: A选项使用API Gateway调用Lambda函数从DynamoDB检索用户数据，C选项使用Cognito用户池验证用户，E选项使用Amplify简化前端部署",
      "why_wrong": "B: 使用ECS不合适，不能满足题目的需求。D: 仅使用Cognito Identity Pool，没有用户注册和身份验证，不完整。F: 缺少用户认证机制。"
    },
    "related_terms": [
      "AWS API Gateway",
      "Lambda",
      "Amazon DynamoDB",
      "Amazon API Gateway",
      "REST API",
      "Amazon Cognito",
      "AWS Amplify",
      "Amazon CloudFront",
      "Amazon S3"
    ],
    "best_answer": [
      "A",
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 542,
    "topic": "",
    "question_cn": "一家媒体公司利用Amazon CloudFront的分销方式在互联网上传递内容。该公司只希望高级客户能够访问媒体流和文件内容。该公司将所有内容存储在Amazon S3桶中。该公司还按需向客户提供特定用途的内容如电影租赁或音乐下载。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon S3生成并提供签名的饼干给高级客户。",
      "B": "为优质客户生成和提供CloudFront签名的URL。",
      "C": "使用Origin Access Control (OAC) 限制非高级客户的访问。",
      "D": "生成和激活现场加密以阻止非高级客户。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFront",
      "S3",
      "Signed URL"
    ],
    "explanation": {
      "analysis": "题目考察CloudFront的访问控制。 确保高级用户访问S3中的内容。 使用CloudFront 签名的 URL 可以满足要求。",
      "why_correct": "B: CloudFront 签名的URL允许控制对内容的访问。",
      "why_wrong": "A: S3 签名的cookie 较老，CloudFront 签名的 URL 是更佳的解决方案。 C: OAC 限制源站的访问，不是针对单个用户的授权访问。 D: 现场加密过于复杂，无法满足按需访问。"
    },
    "related_terms": [
      "Amazon CloudFront",
      "Amazon S3",
      "CloudFront signed URLs",
      "Origin Access Control",
      "现场加密"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 543,
    "topic": "",
    "question_cn": "一家公司在多个AWS账户中运行Amazon EC2实例，每个帐户都有储蓄。该公司最近购买了储蓄计划。由于公司业务需求的变化，公司已经退出了大量的EC2实例。该公司希望将其储蓄计划折扣用于其他账户。哪些步骤组合将满足这些要求？ 选二。",
    "options_cn": {
      "A": "从管理账户的AWS Cost Management控制台打开从账单优先权部分的折扣分享。",
      "B": "从购买现有储蓄计划的帐户的AWS Cost Management控制台打开从账单优惠部分的折扣分享。包括所有帐户。",
      "C": "从AWS Organizations管理账户使用 AWS Resource Access Manager与其他账户共享储蓄计划。",
      "D": "在美国国际服务组织中创建一个新的支付人账户。请其他美国职业介绍所账户从管理账户加入本组织。",
      "E": "利用现有的EC2实例和储蓄计划在现有的AWS账户中的AWS Organizations中创建一个组织。请其他账户从管理账户加入本组织。"
    },
    "vote_percentage": "45%",
    "tags": [
      "Savings Plans",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "此题考察如何共享储蓄计划。主要方式是通过Organizations实现。正确答案包括管理账户的设置以及通过AWS Organizations共享。 D 创建新的组织，不合适。",
      "why_correct": "A, E: A正确， 通过在管理帐户的Cost Management控制台中设置折扣共享。 E正确，在组织中创建组织，然后邀请其他账户加入。",
      "why_wrong": "B: 错误，必须从管理账号操作。C:  可以使用RAM共享，但更推荐组织操作。D: 错误的创建组织方法。"
    },
    "related_terms": [
      "AWS Cost Management",
      "储蓄计划",
      "AWS Organizations",
      "AWS Resource Access Manager",
      "美国国际服务组织",
      "EC2实例"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 544,
    "topic": "",
    "question_cn": "一家零售公司使用区域性Amazon API Gateway作为其公共休息API。API Gateway端点是指向Amazon Route 53别名记录的自定义域名。解决方案架构师需要创建一个解决方案该方案对客户的影响最小，发布新版本的API数据损失最小。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为API Gateway创建一个金丝雀发布部署阶段。部署最新的API版本。将适当百分比的流量指向加那利台。在验证后将金丝雀阶段推广到生产阶段。",
      "B": "创建一个新的API Gateway端点与一个新的版本的API，在开放API文件格式。在API Gateway的API中使用合并模式下的重要更新操作。将新版本的API部署到生产阶段。",
      "C": "创建一个新的API Gateway端点与一个新的版本的API，在开放API文件格式。在API Gateway的API中使用覆盖模式中的重要更新操作。将新版本的API部署到生产阶段。",
      "D": "使用Route 53定义的API新版本创建一个新的API Gateway端点。为新的API Gateway创建自定义域名。将路由别名记录指向新的API Gateway API自定义域名。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Canary Deployment",
      "Route 53"
    ],
    "explanation": {
      "analysis": "此题考察API Gateway的金丝雀发布，这是对客户影响最小，数据损失最小的发布策略。D选项创建新endpoint，会影响域名配置，不合适。",
      "why_correct": "A: 金丝雀发布是最合适的策略，通过逐步将流量转移到新版本来实现无缝升级。",
      "why_wrong": "B, C: 覆盖/合并更新模式可能导致问题。 D: 直接创建新的端点会影响现有配置，造成影响。"
    },
    "related_terms": [
      "Amazon API Gateway",
      "Amazon Route 53",
      "金丝雀发布",
      "API",
      "API Gateway"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 545,
    "topic": "",
    "question_cn": "如果公司的主网站不可用，公司希望引导用户访问备份静态错误页面。主要网站的DNS记录在Amazon Route 53上。该域指向应用程序负载平衡器(ALB)。公司需要一个能最大限度减少变化和基础设施开销的解决方案。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "更新Route 53记录以使用延迟路由策略。向记录中添加一个存储在Amazon S3桶中的静态错误页面以便将流量发送到最响应的端点。",
      "B": "建立一个Route 53的无源故障转移配置。当第Route 53号路线健康检查确定ALB端点是不健康的时，将流量直接指向位于Amazon S3桶中的静态错误页面。",
      "C": "建立一个Route 53的活动配置与ALB和Amazon EC2实例作为端点的静态错误页面。配置Route 53号路由只在ALB的健康检查失败时将请求发送到实例。",
      "D": "更新Route 53记录使用多值响应路由策略。做个健康检查。如果健康检查合格可以直接访问网站，如果健康检查不通过则将S3流量引导到位于Amazon S3的静态错误页面。"
    },
    "vote_percentage": "86%",
    "tags": [
      "Route 53",
      "Failover",
      "ALB"
    ],
    "explanation": {
      "analysis": "此题考察使用Route 53实现故障转移。正确答案是使用无源故障转移，当ALB不健康时，将流量导向S3中的静态页面。 多值响应和延迟路由策略都不是最优解决方案",
      "why_correct": "B: 使用Route 53的无源故障转移配置，实现自动故障转移。",
      "why_wrong": "A: 延迟路由策略不适合故障转移。C: 混合了活动和静态，更复杂。D: 多值响应策略不适用，无法实现故障转移。"
    },
    "related_terms": [
      "Amazon Route 53",
      "ALB",
      "Amazon S3",
      "S3",
      "延迟路由策略",
      "无源故障转移",
      "多值响应路由策略"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 546,
    "topic": "",
    "question_cn": "最近对一家公司IT费用的分析表明需要降低备份成本。该公司的首席信息官希望通过取消使用物理备份磁带来简化内部备份基础设施并降低成本。公司必须保留现有的投资在现场的备份应用程序和工作流程。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "建立AWS Storage Gateway使用NFS接口连接备份应用程序。",
      "B": "建立一个Amazon EFS文件系统使用NFS接口连接到备份应用程序。",
      "C": "建立一个Amazon EFS文件系统使用iSCSI接口连接到备份应用程序。",
      "D": "建立AWS Storage Gateway以连接到备份应用程序使用虚拟磁带库 (VTL) 接口。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Storage Gateway",
      "VTL"
    ],
    "explanation": {
      "analysis": "题目考察如何将本地备份迁移到云端。 使用VTL 接口可以保留现有备份应用程序和工作流程，并降低成本。",
      "why_correct": "D: 使用Storage Gateway的VTL接口可以模拟磁带库，实现现有备份迁移。",
      "why_wrong": "A, B, C: NFS/iSCSI 接口无法兼容磁带备份的应用程序。"
    },
    "related_terms": [
      "AWS Storage Gateway",
      "NFS",
      "Amazon EFS",
      "iSCSI",
      "虚拟磁带库 (VTL)"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 547,
    "topic": "",
    "question_cn": "一家公司在不同的地点有数据采集传感器。数据采集传感器向公司输送大量数据。该公司希望设计一个基于AWS的平台以吸收和处理大容量流数据。解决方案必须是可伸缩的并支持近实时的数据收集。该公司必须将数据存储在Amazon S3中以备今后的报告。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用Amazon Kinesis Data Firehose将流数据传递到Amazon S3。",
      "B": "使用AWS Glue将流媒体数据传递到Amazon S3。",
      "C": "使用AWS Lambda传输流数据并将数据存储到Amazon S3。",
      "D": "使用AWS Database Migration Service (AWS DMS) 向Amazon S3提供流媒体数据。"
    },
    "vote_percentage": "84%",
    "tags": [
      "Kinesis Data Firehose",
      "S3"
    ],
    "explanation": {
      "analysis": "题目考察流数据的摄入和存储。 Kinesis Data Firehose 是最合适的解决方案，因为它易于部署和管理，并能将数据直接传输到S3",
      "why_correct": "A: Kinesis Data Firehose是专门为流数据摄入设计的服务，并能直接将数据写入S3。",
      "why_wrong": "B:  Glue主要用于ETL, 不适合实时数据摄入。 C:  Lambda需要自定义代码, 维护成本高。 D: DMS主要用于数据库迁移, 不适用于流数据。"
    },
    "related_terms": [
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "AWS Glue",
      "AWS Lambda",
      "AWS Database Migration Service (AWS DMS)"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 548,
    "topic": "",
    "question_cn": "一个公司有独立的美国金融服务公司的财务数据分析和开发部门。由于成本和安全考虑，该公司希望控制哪些服务每个账户可以使用。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS System Manager模板来控制每个部门可以使用的服务。",
      "B": "为美国世界卫生组织的每个部门创建组织单位(OU)。将服务控制策略附加到OU上。",
      "C": "使用AWS CloudFormation自动地只提供每个部门可以使用的服务。",
      "D": "在AWS账户中的AWS Service Catalog中设置一个产品列表以管理和控制特定服务的使用。"
    },
    "vote_percentage": "89%",
    "tags": [
      "SCP",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "此题考察服务控制策略的使用。使用服务控制策略(SCP) 是控制AWS账户可以使用哪些服务最简单和最有效的方法。",
      "why_correct": "B: 服务控制策略是控制组织账户访问权限的有效方式。",
      "why_wrong": "A: System Manager 适用于配置管理，不适用于控制服务权限。 C: CloudFormation不适用于控制服务权限，且部署配置比较复杂。 D: Service Catalog 适用于发布产品，但不能限制服务的访问。"
    },
    "related_terms": [
      "AWS System Manager",
      "OU",
      "AWS Organizations",
      "AWS CloudFormation",
      "AWS Service Catalog"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 549,
    "topic": "",
    "question_cn": "一家公司为其电子商务网站创建了一个多层应用程序。该网站使用位于公共子网中的应用负载平衡器、公共子网中的Web层和位于Amazon EC2实例中的专用子网中的MySQL数据库集群。数据库需要检索由第三方提供者在互联网上托管的产品目录和定价信息。解决方案架构师必须设计一种策略在不增加操作开销的情况下最大限度地提高安全性。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "在VPC中部署一个NAT实例。通过NAT实例路由所有基于互联网的通信。",
      "B": "在公共子网络中部署一个NAT网关。修改专用子网路由表以将所有互联网上的流量引导到NAT网关。",
      "C": "配置一个互联网网关并将其附加到VPC上。修改专用子网络路由表以引导互联网访问网关。",
      "D": "配置虚拟专用网关并将其附加到VPC上。修改专用子网路由表以将互联网上的流量导向虚拟专用网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "NAT Gateway",
      "VPC",
      "Security"
    ],
    "explanation": {
      "analysis": "此题考察如何让私有子网中的资源访问互联网, 同时保证安全性。 采用NAT Gateway是最简单和最安全的方法。",
      "why_correct": "B: NAT网关允许私有子网中的实例访问互联网，但外部无法直接访问私有子网中的实例。",
      "why_wrong": "A:  NAT实例需要运维。 C: 互联网网关允许公网访问，不安全。 D: 虚拟专用网关与此场景无关。"
    },
    "related_terms": [
      "应用负载平衡器",
      "Amazon EC2",
      "VPC",
      "NAT实例",
      "NAT网关",
      "互联网网关",
      "虚拟专用网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 550,
    "topic": "",
    "question_cn": "一个公司正在使用AWS Key Management Service (AWS KMS)密钥来加密Lambda环境变量。解决方案架构师需要确保所需权限到位以解密和使用环境变量。解决方案架构师必须采取哪些步骤来实现正确的权限？ 选二。",
    "options_cn": {
      "A": "在Lambda资源策略中添加AWS KMS权限。",
      "B": "在Lambda执行角色中添加AWS KMS权限。",
      "C": "在Lambda函数策略中添加AWS KMS权限。",
      "D": "允许在AWS KMS 密钥策略中的Lambda执行角色。",
      "E": "允许Lambda资源策略在AWS KMS的关键策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "KMS",
      "Lambda",
      "IAM"
    ],
    "explanation": {
      "analysis": "Lambda访问KMS需要两个方面的权限设置：lambda的执行角色要有解密密钥的权限，在KMS key policy中也要允许lambda执行角色使用密钥。",
      "why_correct": "B, D: B, 需要在Lambda执行角色中添加KMS解密权限。D, 在KMS Key policy中添加lambda执行角色的使用权限。",
      "why_wrong": "A: 资源策略通常用于跨账户访问，不适用于此场景。C: Lambda 函数策略不存在。E: Lambda资源策略是不存在的。"
    },
    "related_terms": [
      "AWS Key Management Service (AWS KMS)",
      "Lambda",
      "KMS"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 551,
    "topic": "",
    "question_cn": "一家公司有一个财务应用程序可以编写报告。这些报告平均大小为50kb，存储在亚马逊S3中。这些报告通常在生产后的第一周就被访问，但必须储存数年。必须在小时内检索报告。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "使用S3标准。使用生命周期规则将报告在7天后转换为S3冰川。",
      "B": "使用S3标准 (S3-Ia)。使用生命周期规则在7天后将报告过渡到S3标准和S3标准标准 。",
      "C": "使用S3智能层。配置S3智能层将报告过渡到S3标准和S3冰川。",
      "D": "使用S3标准。使用生命周期规则将报告在7天后转换为冰川深度档案。"
    },
    "vote_percentage": "65%",
    "tags": [
      "S3 Lifecycle",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，该题考查S3存储类的选择，需要满足访问频率和存储成本的平衡。对于访问频率低的数据，需要使用Glacier来实现最低的存储成本。选项A直接将报告转换为Glacier，满足了成本要求。",
      "why_correct": "选项A直接使用生命周期策略，将7天后的报告迁移到Glacier，满足了低成本存储和检索需求。而B在标准和标准(IA)之间转换不能满足低成本存储的需求。",
      "why_wrong": "选项B在标准和标准-IA之间转换不能满足低成本存储的需求。C使用了智能分层，但是智能分层不是长期归档的选项，对于长期归档，Glacier是更合适的选择。D选项的 Glacier Deep Archive 成本更低，但检索时间更长，不满足小时内检索的要求。"
    },
    "related_terms": [
      "S3",
      "S3标准",
      "S3 Glacier",
      "S3标准 (S3-Ia)",
      "S3智能层",
      "冰川深度档案"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 552,
    "topic": "",
    "question_cn": "一家公司需要优化其亚马逊EC2实例的成本。该公司还需要每2-3个月改变其EC2实例的类型和家庭。公司应如何满足这些要求？",
    "options_cn": {
      "A": "购买三年期的部分提前保留实例。",
      "B": "购买一个没有提前计算的一年期储蓄计划。",
      "C": "购买所有提前保留的项目为期一年。",
      "D": "购买一个为期一年的全部预付实例储蓄计划。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Savings Plans",
      "EC2 Reserved Instances"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，Savings Plans是最灵活的，允许在不同实例类型之间切换，以优化成本。而Reserved Instances需要匹配实例的类型和区域，不灵活。",
      "why_correct": "选项B购买一个没有提前计算的一年期储蓄计划，可以提供灵活性和成本优化，满足了公司每月改变实例类型和系列的需求。",
      "why_wrong": "选项A是保留实例，无法灵活地更改实例类型。选项C也是保留实例，灵活性较差。选项D是预付实例储蓄计划，在更改实例类型时，可能无法完全利用储蓄计划的折扣。"
    },
    "related_terms": [
      "Amazon EC2",
      "提前保留",
      "储蓄计划"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 553,
    "topic": "",
    "question_cn": "解决方案架构师需要回顾公司的Amazon S3桶以发现个人识别信息（PII）。该公司在美国东1区和美国西2区存储个人信息基础设施数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在每个区域配置Amazon Macie。创建一个工作分析数据在Amazon S3。",
      "B": "为所有区域配置AWS安全枢纽。创建一个配置规则来分析Amazon S3中的数据。",
      "C": "配置Amazon Inspector分析Amazon S3中的数据。",
      "D": "配置Amazon GuardDuty分析Amazon S3中的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Macie",
      "S3",
      "PII"
    ],
    "explanation": {
      "analysis": "此题考察如何检测S3桶中的PII数据。 Amazon Macie是专门用于检测和保护数据的服务，可以扫描S3桶。",
      "why_correct": "A:  Macie是专门用于识别和保护敏感数据的服务，非常适合这个用例。",
      "why_wrong": "B: 安全枢纽主要用于安全合规，不适用于查找PII。 C:  Inspector用于应用程序安全，不适用。 D: GuardDuty用于威胁检测, 不适用。"
    },
    "related_terms": [
      "Amazon S3",
      "Amazon Macie",
      "AWS安全枢纽",
      "Amazon Inspector",
      "Amazon GuardDuty"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 554,
    "topic": "",
    "question_cn": "一家公司的SAP应用程序在内部环境中拥有后端SQL Server数据库。该公司希望将其在现场的SAP应用程序和数据库服务器迁移到AWS。该SAP公司需要一个实例类型满足其数据库的高要求。现场性能数据显示SAP应用程序和数据库都有很高的内存利用率。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在应用程序中使用计算优化实例家族。对数据库使用内存优化实例家族",
      "B": "对应用程序和数据库都使用存储优化实例家族。",
      "C": "对应用程序和数据库都使用内存优化实例家族。",
      "D": "使用高性能计算 (HPC) 优化实例家庭的应用。对数据库使用内存优化实例家族"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Instance Types",
      "SAP",
      "Memory Optimization"
    ],
    "explanation": {
      "analysis": "此题考察EC2实例类型的选择。 由于应用程序和数据库都具有高内存利用率，所以选择内存优化实例。",
      "why_correct": "C: 内存优化实例家族是满足应用程序和数据库高内存需求的最佳选择。",
      "why_wrong": "A, B, D: 这些选项不适合高内存利用率的场景。"
    },
    "related_terms": [
      "SAP",
      "SQL Server",
      "EC2",
      "内存优化实例",
      "HPC"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 555,
    "topic": "",
    "question_cn": "一个公司在一个具有公共和私人子网的VPC中运行一个应用程序。该VPC扩展到多个可用性区域。该应用程序在私有子网络中的Amazon EC2实例上运行。该应用程序使用一个Amazon简单队列服务（SQS）队列。解决方案架构师需要设计一个安全的解决方案以建立EC2实例和SQS队列之间的连接。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为Amazon SQS实现一个接口VPC端点。配置端点使用私有子网络。将具有一个入站访问规则的安全组添加到端点，该规则允许来自私有子网中的EC2实例的流量。",
      "B": "为Amazon SQS实现一个面向接口的VPC端点。配置端点使用公共子网络。附加到接口端点的端点策略允许从私有子网中的实例访问。",
      "C": "为Amazon SQS实现一个面向接口的VPC端点。配置端点使用公共子网络。在接口端点上附加一个Amazon IAM访问策略，该端点只允许来自指定的供应商端点的请求。",
      "D": "实现Amazon SQS的网关端点。向私有子网添加一个NAT网关。将一个IAM角色附加到允许访问SQS队列的EC2实例上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "SQS",
      "Security"
    ],
    "explanation": {
      "analysis": "此题考察如何让私有子网中的EC2实例安全访问SQS。 最佳方法是使用接口VPC端点，并配置安全组规则。",
      "why_correct": "A:  接口 VPC 端点允许EC2实例通过私有网络安全访问SQS，并且安全组规则控制访问。",
      "why_wrong": "B: 使用公共子网不安全。C:  IAM访问策略不是最好的安全实践，过于复杂，且没有提到安全组。D: NAT网关增加了不必要的复杂性，使用接口VPC端点更简单。"
    },
    "related_terms": [
      "VPC",
      "Amazon EC2",
      "Amazon SQS",
      "VPC端点",
      "接口VPC端点",
      "网关端点",
      "NAT网关"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 556,
    "topic": "",
    "question_cn": "解决方案架构师正在使用AWS CloudFormation模板来部署三层Web应用程序。应用程序由 Web 层和应用程序层组成。它们存储和检索用户数据在Amazon DynamoDB发电机表中。网站和应用程序层被托管在Amazon EC2实例上，数据库层无法公开访问。应用程序实例需要访问发电机表，而API不需要在模板中公开IAM凭证。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "创建一个IAM角色来读取发电机表。通过引用实例概要文件将角色与应用程序实例关联起来。",
      "B": "创建一个IAM角色，该角色具有从发电机表读取和写入所需的权限。将角色添加到EC2实例概要文件并将实例概要文件与应用程序实例关联起来。",
      "C": "使用AWS CloudFormation模板中的参数部分，让用户从一个已经创建的IAM用户那里获得访问密钥和秘密密钥，该用户拥有从发电机表读取和写入的所需权限。",
      "D": "在AWS CloudFormation模板中创建一个IAM用户，该模板具有从发电机表读取和写入的所需权限。使用GetAtt函数检索访问权和密匙，并通过用户数据将它们传递到应用程序实例。"
    },
    "vote_percentage": "87%",
    "tags": [
      "IAM Roles",
      "DynamoDB Access"
    ],
    "explanation": {
      "analysis": "该问题考察了如何安全地授予EC2实例访问DynamoDB表的权限，同时遵循最佳实践。",
      "why_correct": "选项B通过IAM角色和实例概要文件提供了最安全、最有效的方法。这避免了将凭证硬编码到实例中。",
      "why_wrong": "选项A没有提供写入权限。选项C和D涉及凭证管理，不推荐使用，因为它们可能导致凭证泄露。"
    },
    "related_terms": [
      "AWS CloudFormation",
      "Amazon DynamoDB",
      "IAM",
      "EC2",
      "IAM角色",
      "实例概要文件",
      "GetAtt",
      "IAM用户"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 557,
    "topic": "",
    "question_cn": "解决方案架构师管理分析应用程序。应用程序在一个亚马逊S3桶中存储大量的半结构化数据。解决方案架构师希望使用并行数据处理来更快地处理数据。解决方案架构师还希望使用存储在亚马逊红移数据库中的信息来丰富数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊Athena来处理S3数据。使用Glue与亚马逊红移数据丰富数据。",
      "B": "使用亚马逊EMR来处理S3数据。使用亚马逊Glue与亚马逊红移数据丰富数据。",
      "C": "使用亚马逊EMR来处理S3数据。使用亚马逊运动数据流将数据移动到亚马逊红移以便数据可以被丰富。",
      "D": "使用Glue处理S3数据。利用亚马逊红移数据来丰富数据。"
    },
    "vote_percentage": "71%",
    "tags": [
      "EMR",
      "Glue",
      "Amazon Redshift"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，EMR是处理大数据比较好的选择，Glue可以用来丰富数据，并且和Redshift集成。D选项没有说明如何处理数据。",
      "why_correct": "选项B使用EMR处理S3数据，EMR适合处理大规模数据。使用Glue进行数据转换和丰富，并且Glue可以与Redshift集成，可以从Redshift读取数据，从而实现数据丰富。",
      "why_wrong": "选项A使用Athena处理S3数据，Athena适合交互式查询，但可能不是最适合并行处理的选择。选项C使用Kinesis Data Firehose将数据移动到Amazon Redshift，没有利用EMR，并且没有使用Glue数据丰富数据。D选项仅使用Glue，无法有效处理S3的数据。"
    },
    "related_terms": [
      "Amazon S3",
      "亚马逊Athena",
      "亚马逊EMR",
      "Amazon Redshift",
      "Glue",
      "亚马逊运动数据流"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 558,
    "topic": "",
    "question_cn": "一家公司有两个VPC位于美国西部地区的同一AWS账户中。公司需要允许这些VPC之间的网络流量。VPC之间将每月进行大约500GB的数据传输。连接这些VPC的最具成本效益的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS VPC中转网关连接VPC。更新每个VPC的路由表以使用传输网关进行VPC间通信。",
      "B": "在VPC之间实现一个站点到现场的VPN隧道。更新每个VPC的路由表以便使用VPN隧道进行VPC间通信。",
      "C": "在VPC之间建立一个VPC窥视连接。更新每个VPC的路由表使用窥视连接进行VPC间通信。",
      "D": "在VPC之间建立一个1GB的直接连接连接。更新每个VPC的路由表使用通信的直接连接连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Peering",
      "VPC Connectivity"
    ],
    "explanation": {
      "analysis": "此问题考察了VPC互连的成本效益。由于在同一区域，VPC Peering通常是最经济的解决方案。",
      "why_correct": "选项C使用VPC Peering，这是最经济有效的方案。",
      "why_wrong": "选项A使用中转网关，比VPC Peering成本高。选项B使用VPN，性能差，成本较高。选项D直接连接，成本高，适合更复杂的需求，如多个VPC互连。"
    },
    "related_terms": [
      "VPC",
      "AWS VPC",
      "VPC中转网关",
      "VPN隧道",
      "VPC窥视连接",
      "直接连接"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 559,
    "topic": "",
    "question_cn": "一个公司为不同的产品系列在AWS EC2上拥有多个应用程序。应用程序使用不同的计算资源，包括Amazon EC2实例和应用程序负载均衡器。这些应用程序在不同的AWS账户中运行，在多个区域的AWS组织中，且在同一组织下。每个产品系列的团队都在每个账户中标记了每个计算资源。该公司希望从各组织的合并账单功能中获得更多关于每一产品线成本的细节。哪些步骤组合将满足这些要求（选二）？",
    "options_cn": {
      "A": "在AWS计费控制台中选择一个特定的生成的标签。",
      "B": "在AWS计费控制台中选择一个特定的用户定义标记。",
      "C": "在AWS资源组控制台中选择一个特定的用户定义标记。",
      "D": "从每个AWS账户中激活所选标签。",
      "E": "从组织管理账户中激活选定的标签。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cost Allocation",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "此问题考察了如何使用标签分配成本并从组织层面跟踪成本。",
      "why_correct": "选项B和E是正确的。需要在计费控制台中选择用户定义的标签，然后在组织管理账户中激活标签。",
      "why_wrong": "选项A选择生成的标签，不能自定义。选项C是创建资源组，与成本分配无关。选项D是在各个账户中激活标签，但是要在管理账号中开启才能生效。"
    },
    "related_terms": [
      "AWS EC2",
      "应用程序负载均衡器",
      "AWS Organizations",
      "AWS账户",
      "AWS计费控制台",
      "AWS资源组控制台"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 560,
    "topic": "",
    "question_cn": "一个公司的解决方案架构师正在设计一个使用AWS Organizations的多帐户解决方案。解决方案架构师将公司的帐户组织成组织单位(OU)。解决方案架构师需要一个解决方案，该解决方案将标识OU层次结构的任何更改。解决方案还需要将任何变化通知公司的运营团队。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用AWS Control Tower提供AWS账户。使用账户漂移通知来识别OU层次结构的变化。",
      "B": "使用AWS Control Tower提供AWS账户。使用AWS Config聚合规则来识别OU层次结构的更改。",
      "C": "使用AWS Service Catalog在组织中创建账户。使用CloudTrail组织跟踪来识别OU层次结构的变化。",
      "D": "使用CloudFormation模板在组织中创建帐户。使用栈上的漂移检测操作来识别OU层次结构的变化"
    },
    "vote_percentage": "79%",
    "tags": [
      "AWS Control Tower",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "该问题考察了使用AWS Control Tower管理多账户环境，并监控帐户结构的变化。",
      "why_correct": "选项A使用Control Tower提供帐户，并使用帐户漂移通知。这提供了检测OU层次结构变化的最简单的方法。",
      "why_wrong": "选项B使用AWS Config，需要额外配置。选项C使用Service Catalog，和监控OU结构无关。选项D使用CloudFormation，不够自动化。"
    },
    "related_terms": [
      "AWS Organizations",
      "OU",
      "AWS Control Tower",
      "账户漂移",
      "AWS Config",
      "CloudTrail",
      "CloudFormation"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 561,
    "topic": "",
    "question_cn": "一家公司的Web应用程序每天处理数百万个请求，请求的数量继续增加。解决方案架构师需要改进Web应用程序的响应时间。解决方案架构师确定在从Amazon DynamoDB发电机表中检索产品细节时应用程序需要减少延迟。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "建立一个DynamoDB Accelerator(DAX)集群。通过DAX路由所有读取请求。",
      "B": "在DynamoDB表和Web应用程序之间建立Redis的Amazon ElastiCache。将所有的读取请求通过Redis路由。",
      "C": "在DynamoDB表和Web应用程序之间建立Amazon ElastiCache。将所有的阅读请求通过缓存传递。",
      "D": "在DynamoDB表上设置Amazon DynamoDB Streams，并在表上读到Lambda并填充Amazon ElastiCache。将所有的阅读请求通过ElastiCache处理。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DAX",
      "DynamoDB Optimization"
    ],
    "explanation": {
      "analysis": "该问题考察了如何优化DynamoDB的读取性能。",
      "why_correct": "选项A使用DAX，这是DynamoDB的缓存解决方案，专门为DynamoDB优化。这是最直接和最有效的方法。",
      "why_wrong": "选项B使用Redis的ElastiCache，没有针对DynamoDB优化。选项C使用ElastiCache通用缓存，没有针对DynamoDB优化。选项D使用DynamoDB Streams，适用于复杂场景，开销较高。"
    },
    "related_terms": [
      "DynamoDB",
      "DynamoDB Accelerator(DAX)",
      "ElastiCache",
      "Redis",
      "DynamoDB Streams",
      "Lambda",
      "ElastiCache"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 562,
    "topic": "",
    "question_cn": "解决方案架构师需要确保在VPC中的Amazon EC2实例中的API调用不会在互联网上移动。解决方案架构师应该采取哪些步骤组合来满足这一要求 (选二)？",
    "options_cn": {
      "A": "为API端点创建一个路由表项。",
      "B": "为DynamoDB创建一个网关端点。",
      "C": "为EC2创建一个接口端点。",
      "D": "为VPC的每个子网中的端点创建一个弹性网络接口。",
      "E": "在端点的安全组中创建一个安全组条目以提供访问。"
    },
    "vote_percentage": "69%",
    "tags": [
      "VPC Endpoint",
      "Private Connectivity"
    ],
    "explanation": {
      "analysis": "该问题考察了如何通过VPC Endpoint确保EC2实例与AWS服务的通信不经过Internet。",
      "why_correct": "选项A和B是正确的。创建网关端点以及正确的路由表配置，可以确保流量不经过互联网。EC2实例访问DynamoDB，需要使用网关端点。",
      "why_wrong": "选项C是接口端点，可以用于访问其他服务。选项D 多个弹性网卡，不适用。选项E 安全组设置，不适用于VPC端点。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "API",
      "DynamoDB",
      "网关端点",
      "接口端点",
      "VPC",
      "弹性网络接口",
      "安全组"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 563,
    "topic": "",
    "question_cn": "一家公司在Amazon Elastic Kubernetes Service (EKS)集群和酒店内Kubernetes集群上运行其应用程序。该公司希望从一个中心位置查看所有集群和工作负载。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用Amazon CloudWatch Container Insights收集和分组集群信息。",
      "B": "使用Amazon EKS Connector注册和连接所有Kubernetes集群。",
      "C": "使用AWS Systems Manager来收集和查看集群信息。",
      "D": "在任何地方使用Amazon EKS作为主集群来查看使用本地Kubernetes命令的其他集群。"
    },
    "vote_percentage": "92%",
    "tags": [
      "EKS Connector",
      "Kubernetes Management"
    ],
    "explanation": {
      "analysis": "此问题考察了如何统一管理EKS集群和其他Kubernetes集群。",
      "why_correct": "选项B使用Amazon EKS Connector，这是连接和管理本地Kubernetes集群的理想方法。",
      "why_wrong": "选项A 使用CloudWatch Container Insights，主要用于监控，无法统一管理本地集群。选项C使用System Manager，不直接支持Kubernetes集群管理。选项D，操作复杂。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "Kubernetes",
      "CloudWatch Container Insights",
      "EKS Connector",
      "AWS Systems Manager",
      "EKS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 564,
    "topic": "",
    "question_cn": "一家公司正在开发电子商务应用程序并需要存储敏感的客户信息。公司需要给予客户在网站上完成采购交易的能力。该公司还需要确保敏感的客户数据得到保护，甚至不受数据库管理员的影响。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将敏感数据存储在Amazon EBS弹性块存储Amazon EBS卷中。使用IAM加密加密数据。使用实例角色来限制访问。",
      "B": "为MySQL RDS在Amazon RDS中存储敏感数据。使用AWS KMS 密钥管理服务 客户端加密加密数据。",
      "C": "在Amazon S3存储敏感数据。使用AWS KMS 密钥管理服务 服务器端加密加密数据。使用桶策略限制访问。",
      "D": "为Windows FSx 服务器在Amazon FSx存储敏感数据。在应用服务器上安装文件共享。使用文件权限限制访问"
    },
    "vote_percentage": "100%",
    "tags": [
      "KMS",
      "Data Encryption"
    ],
    "explanation": {
      "analysis": "此问题考察了保护敏感数据的最佳实践，特别关注了如何防止数据库管理员访问数据。",
      "why_correct": "选项B通过客户端加密可以防止数据库管理员访问加密的数据。使用RDS结合AWS KMS进行加密。",
      "why_wrong": "选项A没有提供客户端加密，数据库管理员仍然可以访问。选项C是服务器端加密，数据库管理员仍然可以访问。选项D使用文件权限，不安全。"
    },
    "related_terms": [
      "EBS",
      "IAM",
      "KMS",
      "MySQL RDS",
      "KMS",
      "S3",
      "KMS",
      "桶策略",
      "FSx",
      "FSx",
      "FSx",
      "文件权限"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 565,
    "topic": "",
    "question_cn": "一个公司有一个内部的MySQL数据库来处理事务数据。该公司正在将数据库迁移到AWS云。迁移后的数据库必须与使用该数据库的公司的应用程序保持兼容性。迁移数据库还必须在需求增加期间自动进行规模化。哪些迁移方案将满足这些要求？",
    "options_cn": {
      "A": "使用本地MySQL工具将数据库迁移到用于MySQL的Amazon RDS。配置弹性存储缩放。",
      "B": "通过使用mysqldump实用程序将数据库迁移到Amazon Redshift。为Amazon Redshift集群打开自动缩放。",
      "C": "使用AWS Database Migration Service (DMS)将数据库迁移到Amazon Aurora。打开Aurora自动缩放。",
      "D": "使用AWS Database Migration Service (DMS)将数据库迁移到Amazon DynamoDB。配置自动缩放策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DMS",
      "Database Migration"
    ],
    "explanation": {
      "analysis": "该问题考察了将MySQL数据库迁移到AWS的最佳实践。",
      "why_correct": "选项C使用DMS迁移到Aurora，Aurora与MySQL兼容，并支持自动缩放。",
      "why_wrong": "选项A迁移到RDS，不一定能自动伸缩。选项B迁移到Redshift，不兼容MySQL。选项D迁移到DynamoDB，与MySQL不兼容。"
    },
    "related_terms": [
      "MySQL",
      "Amazon RDS",
      "Elastic scaling",
      "mysqldump",
      "Amazon Redshift",
      "AWS Database Migration Service (DMS)",
      "Amazon Aurora",
      "Aurora",
      "Amazon DynamoDB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 566,
    "topic": "",
    "question_cn": "一家公司在VPC中运行多个亚马逊EC2实例跨越两个可用性区域。实例托管使用分层目录结构的应用程序。应用程序需要快速地读和写并同时用于共享存储。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "创建一个亚马逊S3桶。允许从VPC中的所有EC2实例访问。",
      "B": "创建一个亚马逊弹性文件系统 (EFS) 文件系统。从每个EC2实例挂载EFS文件系统。",
      "C": "创建一个文件系统在提供的亚马逊弹性块存储 (EBS) 亚马逊卷。将EBS卷附加到所有EC2实例。",
      "D": "在亚马逊弹性块存储 (EBS) 亚马逊卷上创建文件系统这些卷附加到每个EC2实例。同步不同EC2实例的 EBS卷。"
    },
    "vote_percentage": "93%",
    "tags": [
      "EFS",
      "Shared File System"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，EFS是最适合多可用区共享存储的方案，易于配置和使用。S3适用于对象存储，EBS适用于单实例存储。",
      "why_correct": "选项B创建EFS，EFS是专门为多个EC2实例提供共享文件系统的服务，并且易于配置和使用，满足了读写和共享存储的要求。",
      "why_wrong": "选项A使用S3作为共享存储，S3是对象存储，不适合文件系统级别的共享读写。选项C使用EBS作为共享存储，EBS是块存储，不能直接在多个EC2实例间共享，需要配置复杂的文件系统和同步机制。选项D 多个EC2实例的 EBS卷需要进行同步，增加了复杂性和风险。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "S3",
      "EFS",
      "EC2",
      "EBS",
      "EBS",
      "EC2",
      "EBS",
      "EBS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 567,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个工作负载，它将存储商业租户在建筑物中每小时的能耗。这些传感器将通过HTTP请求输入数据库，这些请求将增加每个租户的使用量。解决方案架构师必须在可能的情况下使用托管服务。随着解决方案架构师添加独立的组件，工作负载将在未来获得更多的特性。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用具有API Gateway功能的Amazon Lambda接收来自传感器的数据，处理数据并将数据存储在Amazon DynamoDB发电机表中。",
      "B": "使用一个弹性负载平衡器，由Amazon EC2实例的一个自动缩放组支持，以接收和处理来自传感器的数据。使用Amazon S3桶存储处理数据。",
      "C": "使用具有Lambda功能的Amazon API Gateway接收来自传感器的数据，处理数据并将数据存储在Amazon EC2实例中的微软SQL Server快速数据库中。",
      "D": "使用一个弹性负载平衡器，由Amazon EC2实例的一个自动缩放组支持，以接收和处理来自传感器的数据。使用Amazon EFS弹性文件系统共享文件系统来存储已处理的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Serverless",
      "API Gateway",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此问题考察了如何构建一个具有可扩展性和托管服务的解决方案来处理传感器数据。",
      "why_correct": "选项A使用了托管服务，包括API Gateway、Lambda和DynamoDB。这是最简单和最具成本效益的方法。",
      "why_wrong": "选项B使用了EC2实例，需要手动管理。选项C使用了EC2和SQL Server，也需要手动管理。选项D使用了EC2实例，并使用EFS，过于复杂。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "DynamoDB",
      "API Gateway",
      "EC2",
      "Elastic Load Balancer",
      "EC2",
      "Amazon S3",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 568,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计一个用于存储和查看工程图纸的新的Web应用程序的存储架构。所有的应用程序组件都将部署在AWS基础设施上。应用程序设计必须支持缓存以减少用户等待工程图纸加载的时间。应用程序必须能够存储5GB数据。解决方案架构师应该使用哪些存储和缓存组合？",
    "options_cn": {
      "A": "Amazon S3具有Amazon CloudFront",
      "B": "Amazon S3具有Amazon Glacier",
      "C": "Amazon EBS卷与Amazon ElastiCache",
      "D": "AWS Storage Gateway具有Amazon ElastiCache"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "此问题考察了存储和缓存的选择，用于存储静态内容。",
      "why_correct": "选项A使用S3存储数据，CloudFront进行缓存，可以满足大文件存储和快速访问的需求。",
      "why_wrong": "选项B使用Glacier，不适合频繁访问。选项C使用EBS和ElastiCache，成本高，不合适。选项D使用Storage Gateway，不适合Web应用程序。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "Glacier",
      "EBS",
      "ElastiCache",
      "AWS Storage Gateway",
      "ElastiCache"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 569,
    "topic": "",
    "question_cn": "API Gateway的Amazon EventBridge规则目标第三方API。第三方没有收到任何传入的流量。解决方案架构师需要确定是否满足了规则条件以及是否调用了规则的目标。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在EventBridge事件的Amazon CloudWatch表中的指标中检查。",
      "B": "回顾Amazon Simple Queue Service中的死信队列事件。",
      "C": "检查Amazon CloudWatch表日志中的事件。",
      "D": "检查在AWS CloudTrail的路径以确定是否发生了EventBridge事件。"
    },
    "vote_percentage": "69%",
    "tags": [
      "EventBridge",
      "Monitoring"
    ],
    "explanation": {
      "analysis": "此问题考察了如何监控EventBridge规则是否触发。",
      "why_correct": "选项A通过CloudWatch指标检查，可以确定规则是否触发，以及指标是否匹配规则。",
      "why_wrong": "选项B是SQS的死信队列，与EventBridge关系不大。选项C检查CloudWatch日志，只能看到事件，不能判断是否触发。选项D检查CloudTrail，只能看到EventBridge的配置变化，不能看到事件触发情况。"
    },
    "related_terms": [
      "API Gateway",
      "EventBridge",
      "API",
      "CloudWatch",
      "Simple Queue Service",
      "CloudWatch",
      "AWS CloudTrail",
      "EventBridge"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 570,
    "topic": "",
    "question_cn": "一家公司每周五晚上的工作量很大。该工作负载运行在亚马逊EC2实例中，位于美国东1区区域的两个可用性区域中。通常情况下，公司必须在任何时候运行不超过两个实例。然而该公司希望每周五扩大到6个实例以处理经常重复增加的工作量。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个提醒在亚马逊EventBridge以扩展实例。",
      "B": "创建一个具有预定动作的自动缩放组。",
      "C": "创建一个使用手动缩放的自动缩放组。",
      "D": "创建一个使用自动缩放的自动缩放组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，自动伸缩组配合计划缩放可以满足按时间调度的需求，实现自动扩容和缩容，最符合题意。",
      "why_correct": "选项B创建具有预定动作的自动缩放组，自动缩放组的计划动作能够满足每周五扩容的需求。",
      "why_wrong": "选项A使用EventBridge提醒，实现扩容需要额外的组件和配置，操作复杂。选项C手动缩放，不符合自动化的需求。选项D没有说明如何进行自动扩容，不符合题意。"
    },
    "related_terms": [
      "EC2",
      "EventBridge",
      "自动缩放组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 571,
    "topic": "",
    "question_cn": "一家公司正在创建一个 REST API。公司对使用 TLS 有严格的要求。该公司要求在 API 端点上使用 TLS tlsv1.3。公司还要求特定的公共第三方 (CA) TLS 证书机构签署证书。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在 AWS ACM 中创建一个由第三方 CA 签名的证书。使用 AWS 证书管理器 将证书签入 证书管理器。在具有自定义域的 Amazon API 网关中创建一个 HTTP API。将自定义域配置为使用证书",
      "B": "在 AWS ACM 中创建一个由第三方 CA 签名的证书。在 AWS 证书管理器 中创建一个 HTTP API。将自定义域配置为使用证书",
      "C": "使用 AWS ACM 创建一个由第三方 CA 签名的证书。将证书导入 AWS 证书管理器。创建一个 Lambda 函数与一个 URL。配置用于使用证书的 Lambda 函数。",
      "D": "在 AWS ACM 中创建一个由第三方 CA 签名的证书。创建一个 Lambda 函数与一个 URL。配置用于使 URL 用证书的 Lambda 函数。"
    },
    "vote_percentage": "72%",
    "tags": [
      "TLS",
      "ACM"
    ],
    "explanation": {
      "analysis": "此题考察如何通过 API Gateway 和 ACM 配置 TLS 证书。",
      "why_correct": "选项 A 提供了最完整的解决方案，利用 ACM 生成和管理证书，在 API Gateway 中配置自定义域名，并使用 TLS。",
      "why_wrong": "选项 B 缺少 ACM 管理证书的过程。选项 C 和 D 虽然使用了 Lambda，但没有利用 API Gateway 的优势。"
    },
    "related_terms": [
      "TLS",
      "ACM",
      "TLS",
      "CA",
      "ACM",
      "HTTP API",
      "ACM",
      "Lambda",
      "URL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 572,
    "topic": "",
    "question_cn": "一家公司运行一个应用程序。应用程序收到的使用量不一致。应用程序使用直接连接连接到现场的 MySQL 兼容数据库。数据库始终使用最少两字节的内存。该公司希望将公司内部的数据库迁移到一个受管理的 RDS 服务。该公司希望使用自动缩放功能来管理意外增加的工作量。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "提供具有默认读写容量设置的 Amazon DynamoDB 数据库。",
      "B": "提供一个 Amazon Aurora 数据库，最小容量为 1 个 Aurora Capacity Unit (ACU)。",
      "C": "提供一个 Amazon Aurora Serverless v2 数据库，最小容量为 1 个 Aurora Capacity Unit (ACU)。",
      "D": "为 MySQL 数据库提供一个具有 2 GB 内存的 Amazon RDS 数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Aurora Serverless"
    ],
    "explanation": {
      "analysis": "考察 RDS 服务，以及 Aurora Serverless 针对弹性伸缩的使用场景。",
      "why_correct": "选项 C 使用 Aurora Serverless v2，提供自动伸缩，满足题干对弹性伸缩的需求，且能以较低成本运行。",
      "why_wrong": "选项 A 使用 DynamoDB，不兼容 MySQL。选项 B 使用 Aurora 但不是 Serverless，无法自动伸缩。选项 D 虽然是 RDS，但不是 Serverless 无法自动伸缩。"
    },
    "related_terms": [
      "RDS",
      "DynamoDB",
      "Aurora",
      "Aurora Serverless v2",
      "MySQL",
      "Amazon RDS",
      "Aurora",
      "Aurora Capacity Unit (ACU)"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 573,
    "topic": "",
    "question_cn": "一个公司希望使用一个事件驱动的程序设计模型与Lambda。该公司希望减少运行在Lambda上的函数的启动延迟。公司对这些应用程序没有严格的延迟要求。该公司希望在函数扩大时减少冷启动和异常延迟。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置Lambda并发。",
      "B": "增加Lambda函数的超时。",
      "C": "增加Lambda函数的内存。",
      "D": "配置Lambda快速启动。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda Concurrency",
      "Lambda Provisioned Concurrency"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，Lambda的快速启动功能，可以减少冷启动时间，改善延迟。并发配置可以提高并发处理能力，但不能直接减少冷启动时间，增加内存影响不大。",
      "why_correct": "选项D配置Lambda快速启动，可以预先初始化lambda函数，减少冷启动的延迟，实现快速启动，满足了题目对减少冷启动的要求。",
      "why_wrong": "选项A配置Lambda并发，无法解决冷启动问题。选项B增加Lambda函数的超时，与减少延迟无关。选项C增加Lambda函数的内存，对于冷启动的改善有限。"
    },
    "related_terms": [
      "Lambda",
      "Lambda",
      "Lambda",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 574,
    "topic": "",
    "question_cn": "一家金融服务公司推出了一个新的应用程序，它将 Amazon RDS 用于 MySQL 数据库。该公司利用该应用程序跟踪股市走势。公司需要在每个周末只运行 2 小时的应用程序。公司需要优化数据库的运行成本。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "将 MySQL 数据库的现有 RDS 迁移到一个无 Aurora Serverless v2 数据库集群。",
      "B": "将 MySQL 数据库中的现有 RDS 迁移到 Aurora 数据库集群中。",
      "C": "将 MySQL 数据库的现有 RDS 迁移到运行 EC2 实例的 Amazon EC2 实例。为 EC2 实例购买实例预留。",
      "D": "将 MySQL 数据库中的现有 RDS 迁移到使用容器镜像运行任务的 Amazon Elastic Container Service 集群。"
    },
    "vote_percentage": "88%",
    "tags": [
      "RDS",
      "Aurora Serverless"
    ],
    "explanation": {
      "analysis": "考察 RDS 数据库的成本优化，以及 Aurora Serverless 的适用场景。",
      "why_correct": "选项 A 将 MySQL 数据库迁移到 Aurora Serverless v2 数据库，该服务可以根据使用情况自动伸缩，实现成本优化，满足周末低负载需求。",
      "why_wrong": "选项 B 迁移到 Aurora，没有 Serverless 特性，无法有效优化成本。选项 C 和 D 涉及 EC2 和 ECS，增加运维复杂度，成本也高于 Aurora Serverless。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "Aurora Serverless v2",
      "MySQL",
      "Aurora",
      "EC2",
      "EC2",
      "Amazon Elastic Container Service",
      "容器镜像"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 575,
    "topic": "",
    "question_cn": "一个公司将其应用部署在亚马逊弹性库伯内特斯服务（Amazon EKS）后面的一个应用负载平衡器在一个美国世界服务。该应用程序需要GREGSQL将数据存储在后数据库引擎中。该公司希望数据库中的数据能够非常容易获得。该公司还需要增加阅读工作量。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个由全局表配置的亚马逊发电机（DynamoDB）数据库表。",
      "B": "创建一个具有多AZ部署的亚马逊RDS数据库。",
      "C": "创建一个具有多AZ数据库集部署的亚马逊RDS数据库。",
      "D": "创建一个由跨区域读取副本配置的亚马逊RDS数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Multi-AZ",
      "RDS Read Replicas"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，为了增加读取工作量，多AZ部署，并且有多数据库集是更好的选择。选项B是单个数据库，而选项C可以支持多个数据库。",
      "why_correct": "选项C创建具有多AZ数据库集部署的亚马逊RDS数据库。使用多AZ数据库集，既满足了高可用性，又可以通过增加数据库集的数量来增加读取吞吐量。",
      "why_wrong": "选项A使用了DynamoDB，但题目要求使用数据库引擎，且不匹配RDS的要求。选项B使用多AZ部署，可以提供高可用性，但是没有解决增加读取负载的问题。选项D使用了跨区域读取副本，可以增加读取性能，但是故障切换时间较长，不符合“容易获得”的要求。"
    },
    "related_terms": [
      "Amazon EKS",
      "Amazon EKS",
      "ALB",
      "RDS",
      "DynamoDB",
      "RDS",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 576,
    "topic": "",
    "question_cn": "一家公司正在通过使用 Amazon API Gateway 和 Lambda 构建一个无服务的无休息网络应用程序。这个 API 应用程序的用户将在地理上分布。公司希望减少向这些用户提出 API 请求的延迟时间。解决方案架构师应该使用哪种端点来满足这些需求？",
    "options_cn": {
      "A": "专用端点",
      "B": "区域终点",
      "C": "接口供应端点",
      "D": "边缘优化端点"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Edge Optimized"
    ],
    "explanation": {
      "analysis": "考察 API Gateway 的端点类型，以及针对全球用户访问的延迟优化。",
      "why_correct": "选项 D 使用边缘优化端点，可以将 API 部署到 CloudFront 的边缘站点，从而减少用户的访问延迟。",
      "why_wrong": "选项 A, B 和 C 均不能有效降低全球用户访问延迟。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "API",
      "边缘优化端点"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 577,
    "topic": "",
    "question_cn": "一家公司利用亚马逊的云前分销服务其网站的内容页面。公司需要确保客户在访问公司网站时使用TLS证书。该公司希望将证书的创建和更新自动化。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用云区安全策略创建证书。",
      "B": "使用云前原产地访问控制 (OAC)创建证书。",
      "C": "使用亚马逊证书管理器（ACM）创建证书。对域使用DNS验证。",
      "D": "使用亚马逊证书管理器（ACM）创建证书。对该域使用电子邮件验证。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ACM",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，ACM结合CloudFront，可以自动管理证书，并且DNS验证比电子邮件验证更加便捷。 DNS验证可以实现证书的快速部署和更新。如果已经使用Route 53管理DNS，则DNS验证更简单。",
      "why_correct": "选项C使用ACM创建证书，并使用DNS验证。使用ACM可以自动处理证书的创建、部署和续订，可以满足自动化需求。 使用DNS验证能够实现快速部署，并且与CloudFront无缝集成。",
      "why_wrong": "选项A云区安全策略与证书无关。选项B使用云前原产地访问控制与证书无关。选项D使用ACM，但使用电子邮件验证，通常需要人工干预，不如DNS验证方便。"
    },
    "related_terms": [
      "CloudFront",
      "TLS",
      "ACM",
      "ACM",
      "DNS",
      "ACM",
      "电子邮件验证"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 578,
    "topic": "",
    "question_cn": "一个公司部署了一个使用 Amazon DynamoDB 作为数据库层的无服务器应用程序。该应用程序的用户大幅增加。该公司希望将数据库响应时间从毫秒提高到微秒并将请求缓存到数据库。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用 DynamoDB Accelerator (DAX)。",
      "B": "将数据库迁移到 Amazon Redshift。",
      "C": "将数据库迁移到 Amazon RDS。",
      "D": "使用 Amazon Elastic Redis。"
    },
    "vote_percentage": "88%",
    "tags": [
      "DynamoDB",
      "DAX"
    ],
    "explanation": {
      "analysis": "考察 DynamoDB 的性能优化，以及 DAX 的使用场景。",
      "why_correct": "选项 A  使用 DynamoDB Accelerator (DAX) 可以缓存 DynamoDB 数据，显著降低读取延迟，并减少操作开销。",
      "why_wrong": "选项 B 和 C 将 DynamoDB 迁移到其他数据库，与题干不符。选项 D 虽然可以缓存，但增加了架构复杂度和运维成本。"
    },
    "related_terms": [
      "DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "DynamoDB",
      "Amazon Redshift",
      "Amazon RDS",
      "Elastic Redis"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 579,
    "topic": "",
    "question_cn": "一家公司运行了一个应用程序，该应用程序使用亚马逊RDS来实现PostgreSQL。该应用程序只在工作时间的工作日接收流量。该公司希望在这种使用的基础上优化成本，减少运营成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS上的实例计划程序来配置启动和停止计划。",
      "B": "关闭自动备份。创建数据库的每周手动快照。",
      "C": "创建一个自定义的Lambda函数以基于最小CPU利用率启动和停止数据库。",
      "D": "购买所有预先保留的RDS实例。"
    },
    "vote_percentage": "95%",
    "tags": [
      "RDS Instance Scheduler",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，实例计划程序可以自动启动和停止RDS实例，减少成本。手动方式运维成本高。",
      "why_correct": "选项A，使用实例计划程序自动控制RDS实例的启动和停止，可以减少非工作时间的运行成本，并且运维简单。",
      "why_wrong": "选项B手动快照，不能减少非工作时间的运行成本。选项C需要额外的lambda函数，运维复杂，并且需要人工配置。选项D预留实例，不能按需启动和停止，无法优化成本。"
    },
    "related_terms": [
      "RDS",
      "PostgreSQL",
      "实例计划程序",
      "自动备份",
      "Lambda",
      "CPU",
      "RDS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 580,
    "topic": "",
    "question_cn": "一家公司使用本地附加存储器在公司内部运行对延迟敏感的应用程序。该公司正在使用电梯和转移方法将应用程序移动到云。该公司不想改变应用程序架构。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "用亚马逊FSx 实例配置一个自动缩放组。使用亚马逊FSx for Lustre文件系统运行应用程序。",
      "B": "在亚马逊EC2实例上托管该应用程序。使用亚马逊弹性块存储（EBS）亚马逊GP-2卷运行应用程序。",
      "C": "用亚马逊FSx实例配置一个自动缩放组。使用亚马逊FSx for Windows File Server 来运行该应用程序。",
      "D": "在亚马逊EC2实例上托管该应用程序。使用亚马逊弹性块商店（EBS）亚马逊Gp3卷运行应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS",
      "FSx"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，EBS GP3是性能和成本的平衡选择，可以满足低延迟的需求，并且不需要修改应用程序架构。其他选项的配置较为复杂。",
      "why_correct": "选项D，EBS GP3卷可以提供高性能和低延迟，并且不需要修改现有的应用程序架构。GP3 卷提供了更高的性能基准和可配置的 IOPS，满足对延迟敏感的应用需求。",
      "why_wrong": "选项A使用FSx for Lustre，FSx for Lustre更适合于计算密集型工作负载，不一定满足对延迟敏感的需求。选项B使用了GP2，GP2的性能不如GP3。选项C使用了FSx for Windows File Server，不一定能满足低延迟的需求。"
    },
    "related_terms": [
      "EC2",
      "FSx",
      "FSx",
      "EBS",
      "EC2",
      "EBS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 581,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例上运行一个有状态的生产应用程序。应用程序需要至少两个EC2实例才能始终运行。解决方案架构师需要为应用程序设计一个高可用性和容错性的架构。解决方案架构师创建一个自动缩放组。解决方案架构师应该采取哪些额外步骤来满足这些需求？",
    "options_cn": {
      "A": "将自动缩放组的最小容量设为2。在一个可用性区域部署一个随需应变的实例，在第二个可用性区域部署一个随需应变的实例。",
      "B": "将自动缩放组的最小容量设为4。在一个可用性区域部署两个随需应变的实例，在第二个可用性区域部署两个随需应变的实例。",
      "C": "将自动缩放组的最小容量设为2。在一个可用性区域中部署四个现货实例。",
      "D": "将自动缩放组的最小容量设为4。在一个可用性区域部署两个按需实例，在第二个可用性区域部署两个现货实例。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Auto Scaling",
      "High Availability"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，为了达到高可用性和容错，需要将实例分布在多个可用区。至少需要4个实例，分在两个可用区各两个。而D选项使用了spot实例，并不稳定。",
      "why_correct": "选项B，设置自动缩放组的最小容量为4，并在两个可用区部署按需实例，实现了高可用性和容错性。如果一个可用区出现故障，另一个可用区的实例可以继续提供服务。将实例分散到多个AZ是高可用性设计的重要原则。",
      "why_wrong": "选项A只部署了两个实例，不能满足高可用性的要求。选项C只部署在一个可用区，不满足高可用性。选项D使用了Spot实例，可靠性不如按需实例。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "Availability Zone",
      "按需实例",
      "现货实例"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 582,
    "topic": "",
    "question_cn": "一家电子商务公司使用 Amazon Route 53 作为其 DNS 供应商。该公司的网站在网站所在地和云中。该公司的内部数据中心靠近美国 1 西部地区。该公司使用欧盟中心 1 号区域作为网站的主机。公司希望尽可能减少网站的负载时间。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "建立一个地理定位路由策略。将靠近美国西部的流量发送到内部数据中心。把靠近欧盟中心 1 号的交通送到欧盟中心 1 号。",
      "B": "建立一个简单的路由策略，将所有靠近欧盟中心的流量路由到欧盟中心，并将所有靠近酒店内数据中心的流量路由到酒店内数据中心。",
      "C": "设置延迟路由策略。将该政策与美国西部 1 号联系起来。",
      "D": "建立加权路由策略。欧盟中心 1 号和内部数据中心平均分配流量。"
    },
    "vote_percentage": "85%",
    "tags": [
      "Route 53",
      "Geolocation Routing",
      "Latency"
    ],
    "explanation": {
      "analysis": "考察 Route 53 的 DNS 路由策略，以及如何根据用户地理位置优化访问延迟。",
      "why_correct": "选项 A 使用地理定位路由，将用户流量导向最近的数据中心，从而减少延迟。",
      "why_wrong": "选项 B 使用简单路由，无法根据地理位置进行优化。选项 C 使用延迟路由，无法针对内部数据中心进行优化。选项 D 加权路由，无法根据地理位置进行优化。"
    },
    "related_terms": [
      "Route 53",
      "DNS",
      "地理定位路由",
      "简单的路由策略",
      "延迟路由",
      "加权路由策略"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 583,
    "topic": "",
    "question_cn": "一家公司有五分之一的物理磁带存档数据。公司需要将磁带上的数据保存 10 年以达到合规的目的。该公司希望在未来 6 个月内迁移 1Gbps 到美国航空服务公司。存储磁带的数据中心有一个 6 Mbps 的互联网连接。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "从现场的磁带上看数据。将数据放在本地 NFS 存储器中。使用数据网络将数据迁移到 Amazon Glacier 的灵活检索。",
      "B": "使用现场备份应用程序读取磁带数据并直接写入 Amazon Glacier 深度档案。",
      "C": "订购多个具有磁带网关的 Snowball 设备。把物理磁带拷贝到雪球的虚拟磁带上。把雪球装置运到美国航空公司。创建一个生命周期策略，将磁带转移到 Amazon Glacier 深处档案馆。",
      "D": "配置现场磁带网关。在云中创建虚拟磁带。使用备份软件复制物理磁带到虚拟磁带"
    },
    "vote_percentage": "97%",
    "tags": [
      "Snowball",
      "AWS Snow Family",
      "Glacier"
    ],
    "explanation": {
      "analysis": "考察大规模数据迁移方案，特别是针对带宽有限的场景。",
      "why_correct": "选项 C 使用 Snowball 设备，解决了数据传输的带宽限制问题，并且可以自动将数据存档到 Glacier Deep Archive，满足合规要求。",
      "why_wrong": "选项 A 和 B 使用互联网传输，带宽不足。选项 D 同样依赖互联网。"
    },
    "related_terms": [
      "Amazon Glacier",
      "Snowball",
      "Amazon Glacier 深度档案",
      "磁带网关",
      "NFS",
      "生命周期策略",
      "虚拟磁带"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 584,
    "topic": "",
    "question_cn": "一家公司正在部署一个可以并行处理大量数据的应用程序。该公司计划使用 Amazon EC2 实例处理工作量。为了防止节点组共享相同的底层硬件，网络体系结构必须是可配置的。哪些网络解决方案符合这些要求？",
    "options_cn": {
      "A": "在扩展放置组中运行 EC2 实例。",
      "B": "将 EC2 实例分类到单独的账户中。",
      "C": "用专用租约配置 EC2 实例。",
      "D": "用共享租赁配置 EC2 实例。"
    },
    "vote_percentage": "82%",
    "tags": [
      "EC2",
      "Placement Groups"
    ],
    "explanation": {
      "analysis": "考察 EC2 实例的网络隔离，以及 Placement Groups 的作用。",
      "why_correct": "选项 A 在扩展放置组中运行 EC2 实例，可以确保实例分布在不同的底层硬件上，满足并行处理的需求。",
      "why_wrong": "选项 B, C 和 D 均不能满足网络隔离的需求。"
    },
    "related_terms": [
      "EC2",
      "放置组",
      "专用租赁",
      "共享租赁"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 585,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计一个灾难恢复策略以在故障转移区域提供亚马逊EC2容量。业务需求声明，策略必须满足故障转移区域的能力。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在故障转移区域中的按需购买实例。",
      "B": "在故障转移区域购买储蓄计划。",
      "C": "购买故障转移区域中的区域保留实例。",
      "D": "在故障转移区域购买一个容量保留。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Capacity Reservations",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，为了确保在灾难发生时有足够的容量，应该使用容量保留。容量保留是确保在特定可用区拥有EC2容量的最好方式。",
      "why_correct": "选项D在故障转移区域购买一个容量保留。容量保留可以确保在灾难发生时有足够的EC2容量，满足了业务需求。",
      "why_wrong": "选项A是按需购买实例，不能保证有足够的容量。选项B不适用。选项C使用了区域保留实例，但是区域保留实例无法满足容量的需求。"
    },
    "related_terms": [
      "EC2",
      "故障转移",
      "按需购买实例",
      "储蓄计划",
      "区域保留实例",
      "容量保留"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 586,
    "topic": "",
    "question_cn": "一家公司在美国世界卫生组织中有五个组织单位作为其组织的一部分。每个都与公司拥有的五个业务相关。公司的研发业务正在脱离公司，将需要自己的组织。解决方案架构师为此创建一个单独的新管理帐户。解决方案架构师应该在新管理帐户中做什么？",
    "options_cn": {
      "A": "在过渡期间让研究与发展协会的帐户成为两个组织的一部分。",
      "B": "请研究与发展协会帐户成为新组织的一部分后，研究与发展协会帐户已离开先前的组织。",
      "C": "在新的组织中创建一个新的研发帐户。将资源从以前的研究与发展帐户转移到新的研究与发展帐户。",
      "D": "让研究与发展协会帐户加入新的组织。使新的管理帐户成为先前组织的成员。"
    },
    "vote_percentage": "87%",
    "tags": [
      "AWS Organizations",
      "Account Migration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，研发部门离开组织后，需要先将账户移动到新的组织，再移除旧组织，防止出现安全问题。",
      "why_correct": "选项B，在研发账户加入新组织后，就可以安全地将研发账户从原组织移除，保障了安全性。",
      "why_wrong": "选项A和选项D都不安全，因为无法同时属于两个组织。选项C需要新建账户，而研发部门有自己的账户，需要直接迁移，不需要新建。"
    },
    "related_terms": [
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 587,
    "topic": "",
    "question_cn": "一家公司正在设计一种解决方案来捕捉不同Web应用中的客户活动以处理分析和做出预测。应用程序中的客户活动是不可预测的，并且会突然增加。该公司需要一个与其他Web应用集成的解决方案。为了安全起见，解决方案必须包括授权步骤。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在亚马逊弹性容器服务容器实例前配置一个网关负载平衡器 (GWLB)。该实例存储公司在亚马逊弹性文件系统（EFS） 亚马逊文件系统中接收的信息。授权在GWLB中解决。",
      "B": "在亚马逊运动数据流前配置亚马逊 API网关端点。该数据流存储公司在亚马逊S3桶中接收的信息。使用Lambda函数来解析授权。",
      "C": "将亚马逊API网关端点配置到亚马逊动态信息数据消防管的前面。该消防管存储公司在亚马逊S3桶中接收到的信息。使用网关Lambda授权器来解析授权。",
      "D": "在亚马逊弹性容器服务容器实例的前面配置网关负载平衡器 (GWLB)。该实例存储公司在亚马逊弹性文件系统（EFS）亚马逊文件系统中接收的信息。使用Lambda函数来解析授权。"
    },
    "vote_percentage": "84%",
    "tags": [
      "API Gateway",
      "Kinesis Data Firehose",
      "Lambda Authorizer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，API Gateway和Kinesis Data Firehose的组合是数据流管道的常用方案。使用网关Lambda授权器可以进行授权。EFS和GWLB不是合适的选择。",
      "why_correct": "选项C，将API网关配置到Kinesis Data Firehose的前面，使用API Gateway的Lambda授权器进行授权，符合题目的要求，API Gateway是好的入口。Kinesis Data Firehose用于存储数据，安全性和可扩展性也得到了保证。",
      "why_wrong": "选项A使用了GWLB和EFS，GWLB是用于网络流量的，EFS是文件存储，这两种方式都不适合接收客户端事件和分析。选项B没有使用Kinesis Data Firehose，安全性略差。选项D和A类似。"
    },
    "related_terms": [
      "网关负载平衡器 (GWLB)",
      "弹性容器服务",
      "弹性文件系统（EFS）",
      "API网关",
      "运动数据流",
      "S3",
      "Lambda",
      "Lambda授权器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 588,
    "topic": "",
    "question_cn": "一家电子商务公司希望为其运行微软SQL服务器企业版的亚马逊RDS数据库实例提供灾难恢复解决方案。公司目前的恢复点目标和恢复时间目标是24小时。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建跨区域读副本并将读副本推广到主要实例。",
      "B": "使用数据库迁移服务（AWS DMS）创建跨区域复制。",
      "C": "每24小时使用跨区域复制将本地备份复制到亚马逊S3桶。",
      "D": "每24小时将自动快照复制到另一个区域。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Disaster Recovery",
      "Cross-Region Replication"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，快照的恢复速度最快，而且满足RTO和RPO。B选项涉及数据迁移，时间较长。",
      "why_correct": "选项D，每24小时将自动快照复制到另一个区域，可以满足24小时的RTO和RPO需求。 使用快照进行灾备恢复，方便简单。复制快照是快速恢复的有效方法。",
      "why_wrong": "选项A是创建跨区域读副本，提供了高可用性，但不是灾备的最佳选择。选项B使用DMS，DMS主要用于数据库迁移，用于灾备恢复复杂且时间较长。选项C的RTO较高，不满足要求。"
    },
    "related_terms": [
      "RDS",
      "跨区域读副本",
      "数据库迁移服务（AWS DMS）",
      "跨区域复制",
      "Amazon S3",
      "自动快照"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 589,
    "topic": "",
    "question_cn": "一个公司在亚马逊 EC2实例上运行一个Web应用程序，该应用程序在一个应用程序负载平衡器后面的一个自动缩放组中。该程序的会话具有粘性。Web服务器目前是用户会话状态的主机。该公司希望确保高可用性并避免在服务器中断时用户会话状态的损失。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊弹性计算机来存储会话数据。更新应用程序以使用弹性计算机来存储会话状态。",
      "B": "使用亚马逊弹性卡西为雷迪斯存储会话状态。更新应用程序以便使用弹性计算机来存储会话状态。",
      "C": "使用存储网关缓存的卷存储会话数据。更新应用程序使用存储网关缓存的卷存储会话状态。",
      "D": "使用亚马逊RDS存储会话状态。更新应用程序以使用亚马逊RDS存储会话状态。"
    },
    "vote_percentage": "89%",
    "tags": [
      "Session Management",
      "Elasticache"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用Amazon ElastiCache，可以缓存会话数据，提高应用程序性能和可用性。",
      "why_correct": "Amazon ElastiCache for Redis提供了高性能的内存缓存，非常适合存储会话状态，并且应用程序可以快速访问这些状态。这比数据库更有效。",
      "why_wrong": "A选项使用弹性计算存储会话数据，通常指EC2，不适合存储会话数据，且维护成本高。 C选项使用Storage Gateway，不适合会话存储。 D选项RDS适合存储持久化数据，不适合会话存储，会带来额外的开销。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "自动缩放组",
      "弹性计算",
      "弹性卡西",
      "存储网关",
      "RDS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 590,
    "topic": "",
    "question_cn": "一家公司将一个MySQL数据库从公司的内部数据中心迁移到一个亚马逊RDS实例用于MySQL数据库。公司对MySQL数据库实例进行了调整以满足公司每天的平均工作量。当公司为报告运行查询时数据库每个月运行一次。该公司希望有能力运行报告和维护日常工作量的性能。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "创建数据库的读副本。将查询指向读取副本。",
      "B": "创建数据库的备份。将备份还原到另一个RDS实例。将查询引导到新数据库。",
      "C": "将数据输出到亚马逊 S3。使用 Amazon Athena 查询S3桶。",
      "D": "为适应额外的工作量重新调整RDS实例"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "考查如何优化 RDS 数据库的性能，特别是在报告查询导致性能问题时。读副本是一个很好的解决方案。",
      "why_correct": "选项 A 描述了创建读副本，并将报告查询指向读副本，可以减轻主数据库的负载。",
      "why_wrong": "选项 B 描述了备份和恢复数据库，用于灾难恢复。选项 C 使用 Athena 查询 S3 中的数据，需要将数据导出，过程复杂。选项 D 重新调整RDS实例，虽然可以提升性能，但成本较高。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "读副本",
      "Amazon S3",
      "Athena"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 591,
    "topic": "",
    "question_cn": "一家公司通过使用亚马逊弹性库伯内特斯服务运行一个容器应用程序。该应用程序包括管理客户和订单的微型服务。该公司需要将收到的请求路由到适当的微型服务。哪种解决方案能最有效地满足这一要求？",
    "options_cn": {
      "A": "使用负载平衡器控制器提供网络负载平衡器。",
      "B": "使用负载平衡器控制器提供一个应用负载平衡器。",
      "C": "使用一个Lambda函数连接请求到亚马逊EKS。",
      "D": "使用亚马逊API网关连接到亚马逊EKS请求。"
    },
    "vote_percentage": "75%",
    "tags": [
      "EKS",
      "Application Load Balancer",
      "Service routing"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是使用Application Load Balancer是EKS中微服务之间请求路由的常用方法，负载均衡器控制器可以自动配置ALB并将流量路由到正确的服务。",
      "why_correct": "使用ALB作为EKS集群的入口点，可以根据路径、主机名等规则将流量路由到不同的微服务，ALB提供了负载均衡、健康检查等功能。",
      "why_wrong": "A选项使用网络负载均衡器，不提供基于内容的路由。 C选项使用Lambda函数，虽然可行，但是增加了复杂性。 D选项使用API网关，通常用于外部访问EKS集群的API，不适合微服务内部路由。"
    },
    "related_terms": [
      "弹性库伯内特斯服务",
      "负载平衡器",
      "网络负载平衡器",
      "应用负载平衡器",
      "Lambda",
      "API网关",
      "EKS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 592,
    "topic": "",
    "question_cn": "一个公司使用和销售获得版权的图片。该公司的全球客户群需要能够快速访问这些图片。该公司必须拒绝特定国家的用户访问。公司希望尽可能减少成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊S3存储图像。打开多因素认证和公共桶访问。为客户提供一个链接到S3桶。",
      "B": "使用亚马逊S3存储图像。为每个客户创建一个IAM用户。将用户添加到具有访问S3桶权限的组中。",
      "C": "使用Application Load Balancers (ALBs) 后面 的Amazon EC2实例存储图像。仅在公司服务的国家/地区部署实例。为客户提供指向其特定国家/地区的实例的ALB链接。",
      "D": "使用亚马逊S3存储图像。使用亚马逊云区来分发带有地理限制的图像。为每个客户提供一个签名的URL以访问云端的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "CloudFront",
      "Geo Restriction"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是使用CloudFront配合S3，使用地理限制，可以快速分发图片，并且限制特定国家的访问。",
      "why_correct": "CloudFront可以缓存S3中的图片，并提供全球CDN加速，同时可以通过地理限制来阻止特定国家的访问。提供带地理限制的签名的URL，可以实现精细的访问控制，并且降低成本。",
      "why_wrong": "A选项打开S3多因素认证，与题目要求无关，并且增加了配置复杂度和运营成本。 B选项使用IAM用户，每个用户需要单独管理，维护成本高。 C选项使用EC2和ALB，增加了维护成本，并且无法直接实现地理限制。"
    },
    "related_terms": [
      "S3",
      "IAM",
      "Application Load Balancers (ALBs)",
      "Amazon EC2",
      "CloudFront"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 593,
    "topic": "",
    "question_cn": "一个解决方案架构师正在设计一个基于Redis的高可用性 Amazon ElastiCache 解决方案。解决方案架构师需要确保故障不会导致性能下降或数据丢失，并且在同一区域内。解决方案需要在节点级和区域级提供高可用性。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "使用含有多个节点的碎片的多AZ Redis复制组。",
      "B": "使用包含多个节点的Redis碎片，只添加打开的文件。",
      "C": "使用 Multi-AZ Redis集群，并在复制组中包含多个读副本。",
      "D": "使用包含多个节点并打开Auto Scaling的Redis碎片。"
    },
    "vote_percentage": "75%",
    "tags": [
      "ElastiCache",
      "Redis",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考查如何设计 ElastiCache Redis 的高可用性方案。Multi-AZ 复制组是关键。",
      "why_correct": "选项 A 描述了使用多 AZ Redis 复制组，可以保证节点级和区域级的高可用性。",
      "why_wrong": "选项 B 描述了Redis碎片和添加打开的文件，不保证高可用性。选项 C 使用 Multi-AZ Redis 集群和多个读副本，虽然可以提高可用性，但没有提及碎片。选项 D 使用开启了 Auto Scaling 的 Redis 碎片，虽然可以提高弹性，但没有保证区域级的高可用性。"
    },
    "related_terms": [
      "ElastiCache",
      "Multi-AZ",
      "Redis",
      "Auto Scaling"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 594,
    "topic": "",
    "question_cn": "一家公司计划迁移到 AWS 并使用 Amazon EC2 按需实例进行应用。在迁移测试阶段，一个技术团队观察到应用程序需要很长时间才能启动和加载内存，从而实现充分的生产。在下一个测试阶段，哪个解决方案可以减少应用程序的启动时间",
    "options_cn": {
      "A": "启动两个或更多的EC2 点播实例。打开自动缩放功能在下一个测试阶段提供随需应变实例。",
      "B": "启动 2个点实例以支持应用程序并扩展应用程序使其在下一个测试阶段可用。",
      "C": "启动EC2随需实例。在下一个测试阶段配置自动缩放暖池。",
      "D": "按需发射EC2可预订容量。在下一测试阶段启动额外的EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "Auto Scaling",
      "Warm Pools"
    ],
    "explanation": {
      "analysis": "考查如何通过优化 EC2 实例的启动时间来提高应用程序的性能。暖池是关键。",
      "why_correct": "选项 C 描述了使用暖池，可以在自动缩放组中预先启动一部分 EC2 实例，从而减少应用程序的启动时间。",
      "why_wrong": "选项 A 描述了简单的自动缩放，没有利用暖池。选项 B 描述了预留实例，不能缩短启动时间。选项 D 描述了预订容量，不能缩短启动时间。"
    },
    "related_terms": [
      "EC2",
      "自动缩放",
      "点播实例",
      "暖池"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 595,
    "topic": "",
    "question_cn": "一个公司的应用程序运行在 Amazon EC2 实例中的自动缩放组。该公司注意到它的应用程序会在一周中的任意几天突然增加流量。该公司希望在突然增加流量时保持应用程序的性能。哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "使用手动缩放来改变自动缩放组的大小。",
      "B": "使用预测缩放来改变自动缩放组的大小。",
      "C": "使用动态缩放来改变自动缩放组的大小。",
      "D": "使用时间表缩放来改变自动缩放组的大小。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "Auto Scaling",
      "Dynamic Scaling"
    ],
    "explanation": {
      "analysis": "考查如何根据流量变化动态调整 EC2 自动缩放组的大小。动态缩放是最佳选择。",
      "why_correct": "选项 C 使用动态缩放，可以根据实时的指标（如 CPU 利用率）自动调整自动缩放组的大小，以响应流量的变化。",
      "why_wrong": "选项 A 使用手动缩放，需要人工干预。选项 B 使用预测缩放，预测缩放可以预先扩展，但对突发流量不敏感。选项 D 使用时间表缩放，只能在预定的时间点进行缩放，不适用于不可预测的流量。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "手动缩放",
      "预测缩放",
      "动态缩放",
      "时间表缩放"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 596,
    "topic": "",
    "question_cn": "电子商务应用程序使用在亚马逊 EC2实例上运行的后 SQL数据库。在每月的销售活动中，数据库使用率增加，导致应用程序的数据库连接问题。随后的月度销售活动流量无法预测，这影响了销售预测。当流量不可预测地增加时，公司需要保持业绩。哪个解决方案以最具成本效益的方式解决这个问题？",
    "options_cn": {
      "A": "迁移到亚马逊 Aurora Serverless v2后SQL数据库。",
      "B": "为EC2实例上的后SQL数据库启用自动缩放以适应更多的使用。",
      "C": "使用更大的实例类型将后SQL数据库迁移到亚马逊RDS。",
      "D": "将后SQL数据库迁移到亚马逊Redshift以适应更多的使用。"
    },
    "vote_percentage": "93%",
    "tags": [
      "Aurora Serverless",
      "Database scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是Aurora Serverless v2可以根据数据库的负载自动伸缩，无需预先规划容量，适合不可预测的负载。",
      "why_correct": "Aurora Serverless v2可以根据数据库负载自动伸缩计算资源，实现成本优化。当负载增加时，可以自动增加容量，并且在负载降低时，自动减少容量。",
      "why_wrong": "B选项EC2实例数据库启用自动缩放，需要手动配置，并且无法像Aurora Serverless那样精细的控制容量。 C选项迁移到RDS，选择更大的实例，不能弹性伸缩，成本较高。 D选项将数据库迁移到Redshift，Redshift是数据仓库，不适用于OLTP应用程序。"
    },
    "related_terms": [
      "EC2",
      "SQL",
      "Aurora Serverless v2",
      "RDS",
      "Redshift"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 597,
    "topic": "",
    "question_cn": "一家公司通过使用 Amazon API Gateway 和 AWS Lambda在AWS上拥有一个内部无服务器应用程序。当公司员工每天开始使用应用程序时，他们会报告高延迟的问题。公司希望减少延迟。哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "增加 API 网关节流限制。",
      "B": "在员工每天开始使用应用程序之前，建立一个预定的扩展以增加Lambda提供的并发性。",
      "C": "创建一个Amazon CloudWatch警报，启动一个作为每天开始时的警报目标的Lambda函数。",
      "D": "增加Lambda函数记忆。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Lambda",
      "Concurrency"
    ],
    "explanation": {
      "analysis": "考查如何优化 API Gateway 和 Lambda 应用程序的性能，减少延迟。预置并发是关键。",
      "why_correct": "选项 B 描述了使用预置并发，可以在应用程序启动前预先启动 Lambda 函数实例，从而减少延迟。",
      "why_wrong": "选项 A 描述了增加 API Gateway 的节流限制，这无法减少延迟。选项 C 描述了使用 CloudWatch 警报，无法解决延迟问题。选项 D 描述了增加Lambda函数的内存，可以提高性能，但对延迟影响有限。"
    },
    "related_terms": [
      "API Gateway",
      "AWS Lambda",
      "CloudWatch",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 598,
    "topic": "",
    "question_cn": "一家研究公司使用内部设备生成数据进行分析。该公司希望使用云来分析数据。设备会产生CSV文件，并支持将数据写入SMB文件共享。公司分析师必须能够使用SQL命令查询数据。分析师将在一天中周期性地运行查询。哪些步骤组合将最符合这些要求？选三。",
    "options_cn": {
      "A": "在AWS网站上以Amazon S3文件网关模式部署一个存储网关。",
      "B": "在Amazon FSx for Windows文件网关的内部部署一个存储网关。",
      "C": "设置一个AWS Glue爬虫根据Amazon S3中的数据创建一个表。",
      "D": "用Amazon EMR文件系统建立一个Amazon EMR集群来查询Amazon S3中的数据。允许分析人员进入。",
      "E": "建立一个Amazon Redshift集群来查询Amazon S3中的数据。允许分析人员进入。",
      "F": "安装Amazon Athena来查询Amazon S3中的数据。允许分析人员进入。"
    },
    "vote_percentage": "96%",
    "tags": [
      "File Gateway",
      "Athena",
      "Glue",
      "EMR"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CEF，但社区共识(投票最高)为ACF。社区倾向ACF的原因是使用存储网关将SMB文件共享数据导入S3，然后使用Athena查询S3中的数据，同时使用Glue爬虫创建表，可以实现数据的ETL和查询。",
      "why_correct": "A: 使用文件网关，将SMB共享的文件转换为S3上的对象。 C: 使用Glue爬虫，自动创建S3数据的表结构，方便后续查询。 F: 使用Athena，可以直接查询S3上的数据，不需要额外的基础设施。",
      "why_wrong": "B: FSx文件网关不常用。 D: EMR对于简单的查询来说，过于复杂。 E: Redshift是数据仓库，不适用于这种场景。"
    },
    "related_terms": [
      "Amazon S3",
      "存储网关",
      "Amazon FSx for Windows",
      "AWS Glue",
      "Amazon EMR",
      "Amazon Redshift",
      "Athena"
    ],
    "best_answer": [
      "A",
      "C",
      "F"
    ],
    "official_answer": [
      "C",
      "E",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 599,
    "topic": "",
    "question_cn": "一家公司希望使用亚马逊弹性容器服务集群和亚马逊RDS数据库实例来构建和运行支付处理应用程序。该公司将在其内部数据中心运行该应用程序以符合要求。AWS解决方案架构师希望使用Outposts作为解决方案的一部分。解决方案架构师正在与该公司的业务团队合作构建应用程序。公司的业务团队负责哪些活动？选三。",
    "options_cn": {
      "A": "为Outposts机架提供弹性电源和网络连接",
      "B": "AWS管理在前哨上运行的虚拟化管理程序、存储系统和EC2服务",
      "C": "数据中心环境的物理安全性和访问控制",
      "D": "Outposts基础设施的可用性，包括Outposts机架内的电源、服务器和网络设备",
      "E": "Outposts部门的实物维护",
      "F": "为亚马逊EKS集群提供额外能力以缓解服务器故障和维护事件"
    },
    "vote_percentage": "50%",
    "tags": [
      "AWS Outposts",
      "Responsibilities"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为ACE，但社区共识(投票最高)为ACF。社区倾向ACF的原因是业务团队需要负责数据中心的物理安全、网络和供电，以及在outposts上部署的应用程序的可用性和故障转移。A: 负责向Outposts提供电力和网络。C: 负责数据中心的物理安全和访问控制。F: 负责EKS集群的弹性，解决服务器故障。",
      "why_correct": "A，C，F 都属于业务团队的职责，保证应用可用性。",
      "why_wrong": "B，D，E 属于AWS的职责。"
    },
    "related_terms": [
      "弹性容器服务",
      "RDS",
      "Outposts",
      "EC2",
      "EKS"
    ],
    "best_answer": [
      "A",
      "C",
      "F"
    ],
    "official_answer": [
      "A",
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 600,
    "topic": "",
    "question_cn": "一家公司正计划将基于TCP的应用程序迁移到该公司的VPC中。该应用程序可以通过公司数据中心的硬件设备在一个非标准的TCP端口3000上公开访问。这个公共端点每秒可以处理高达 10,000 次请求，延迟时间较低。该公司要求相同水平的性能新的公共端点在美国信息系统。解决方案架构师应该建议什么来满足这个需求",
    "options_cn": {
      "A": "部署网络负载平衡器（NLB）。将 NLB 配置为在应用程序所需的TCP端口上公开访问。",
      "B": "部署一个应用负载平衡器（ALB）。将 ALB 配置为可在应用程序所需的TCP端口上公开访问的。",
      "C": "部署一个 Amazon CloudFront 分发，该分发可以在应用程序所需的TCP端口上监听。使用应用程序负载平衡器作为起源。",
      "D": "部署一个 Amazon API 网关。该 API 网关配置为应用程序所需的TCP端口。配置具有配置并发性的 Lambda函数来处理请求。"
    },
    "vote_percentage": "100%",
    "tags": [
      "NLB",
      "Load Balancing",
      "TCP"
    ],
    "explanation": {
      "analysis": "考查如何将基于 TCP 的应用程序迁移到 VPC 中，并保持高性能和低延迟。网络负载平衡器是最佳选择。",
      "why_correct": "选项 A 描述了部署网络负载平衡器 (NLB)。 NLB 能够处理 TCP 流量，并可以保持低延迟，是最佳解决方案。",
      "why_wrong": "选项 B 描述了部署应用负载平衡器 (ALB)。 ALB 适用于 HTTP/HTTPS 流量，不适用于 TCP 流量。选项 C 描述了部署 Amazon CloudFront，CloudFront 用于内容分发，不适用于 TCP 流量。选项 D 描述了部署 Amazon API Gateway 和 Lambda，API Gateway 适用于 REST API，不适合直接转发 TCP 流量，而且增加延迟。"
    },
    "related_terms": [
      "VPC",
      "网络负载平衡器",
      "ALB",
      "Amazon CloudFront",
      "Amazon API 网关",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 601,
    "topic": "",
    "question_cn": "一家公司在Amazon RDS上运行它的关键数据库用于后数据库实例。该公司希望迁移到Amazon Aurora后最少的停机时间和数据损失。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为后行RDS数据库实例创建一个快照以填充一个新的Aurora后行数据库集群。",
      "B": "为后行RDS数据库实例创建一个Aurora读取副本。促进Aurora读复制到一个新的Aurora后数据库集群。",
      "C": "使用来自Amazon S3的数据导入将数据库迁移到一个Aurora后数据库集群。",
      "D": "使用Pg_dump实用程序来备份后RDS数据库的SQL数据库。将备份恢复到一个新的Aurora后数据库集群。"
    },
    "vote_percentage": "85%",
    "tags": [
      "RDS to Aurora",
      "Database Migration"
    ],
    "explanation": {
      "analysis": "考查从RDS到Aurora的迁移策略，并关注最少停机时间。",
      "why_correct": "选项B通过创建Aurora读取副本，提供了接近零停机时间的迁移方案，数据复制是异步的，不影响源数据库的性能。最终将读取副本提升为独立的Aurora数据库。",
      "why_wrong": "选项A需要快照，停机时间会较长。选项C使用S3导入，增加了数据迁移的复杂性。选项D使用Pg_dump，迁移过程可能会有停机时间。"
    },
    "related_terms": [
      "Amazon RDS",
      "Amazon Aurora",
      "快照",
      "Aurora 读取副本",
      "Amazon S3",
      "Pg_dump"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 602,
    "topic": "",
    "question_cn": "一家公司的基础设施包括数百个使用Amazon EBS的EC2实例。解决方案架构师必须确保灾难后的每个EC2实例都可以恢复。解决方案架构师应该做些什么以最小的努力来满足这个需求？",
    "options_cn": {
      "A": "获取附加到每个EC2实例的EBS存储的快照。从EBS存储器中创建一个CloudFormation模板来启动新的EC2实例。",
      "B": "获取附加到每个EC2实例的EBS存储的快照。利用AWS Elastic Beanstalk在EC2模板的基础上设置环境并附加EBS存储。",
      "C": "使用AWS Backup为整个EC2实例组设置备份计划。使用AWS Backup或AWS CLI来加速多个EC2实例的还原过程。",
      "D": "创建一个Lambda函数以获取连接到每个EC2实例的EBS存储的快照并复制Amazon机器镜像(AMI)。创建另一个Lambda函数用复制的AMI执行还原并附加EBS存储。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Backup",
      "EBS Snapshot"
    ],
    "explanation": {
      "analysis": "考察使用EBS快照进行EC2实例灾难恢复的策略和工具。",
      "why_correct": "选项C使用AWS Backup，提供了一种自动化的备份和恢复方案，能够方便地管理多个EC2实例的备份和恢复，且使用AWS提供的服务能够提高效率。",
      "why_wrong": "选项A和B都需要手动创建和管理模板或设置环境，工作量大。选项D需要自己编写Lambda函数，实现复杂。选择AWS Backup能简化操作，降低管理成本。"
    },
    "related_terms": [
      "Amazon EBS",
      "EC2",
      "快照",
      "CloudFormation",
      "AWS Elastic Beanstalk",
      "AWS Backup",
      "AWS CLI",
      "Lambda",
      "Amazon机器镜像(AMI)"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 603,
    "topic": "",
    "question_cn": "一家公司最近迁移到了AWS云。该公司希望为大规模的按需并行处理半结构数据集提供无服务器解决方案。数据由S3日志、媒体文件、销售事务和存储在Amazon DynamoDB中的传感器数据组成。该公司希望解决方案能够并行处理数据集中的数千项。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用AWS Step Functions在内联模式下映射状态来并行处理数据。",
      "B": "使用AWS Step Functions在分布式模式下映射状态来并行处理数据。",
      "C": "使用AWS Glue并行处理数据。",
      "D": "使用几个Lambda函数并行处理数据。"
    },
    "vote_percentage": "94%",
    "tags": [
      "AWS Step Functions",
      "Serverless Data Processing"
    ],
    "explanation": {
      "analysis": "考察使用无服务器服务并行处理大规模数据集的解决方案。",
      "why_correct": "选项B使用AWS Step Functions的分布式模式，能有效地并行处理大规模数据，非常适合处理需要协调多个任务的场景。",
      "why_wrong": "选项A的内联模式适合简单的顺序流程。选项C的AWS Glue主要用于ETL，不适合大规模并行处理。选项D需要手动管理Lambda函数的调用和协调，较为复杂。"
    },
    "related_terms": [
      "AWS Step Functions",
      "S3",
      "Amazon DynamoDB",
      "AWS Glue",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 604,
    "topic": "",
    "question_cn": "一家公司将在6周内将数据转移到亚马逊S3。目前的数据中心有500Mbps的互联网链接。其他房地内的应用程序共享上电汇。公司80%可以使用网络的带宽来完成这个一次性迁移任务。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将数据迁移到亚马逊S3并自动验证数据。",
      "B": "使用aws rsync同步直接将数据传输到亚马逊S3。",
      "C": "使用AWS CLI和多个拷贝进程直接将数据发送到亚马逊S3。",
      "D": "订购多个AWS Snowball装置。将数据复制到设备上。将设备发送到AWS以便将数据复制到亚马逊S3。"
    },
    "vote_percentage": "94%",
    "tags": [
      "Snowball",
      "Data Transfer",
      "S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是Snowball设备适用于大量数据的迁移，即使带宽有限，也可以在6周内完成数据迁移。",
      "why_correct": "Snowball设备适合大量数据的迁移，可以缓解网络带宽的限制。将数据复制到Snowball设备，然后将设备运送到AWS，完成数据的迁移。",
      "why_wrong": "A: 没有说明如何迁移数据，并且自动验证可能耗时。 B: rsync适合小量数据。 C: AWS CLI复制数据，效率低。"
    },
    "related_terms": [
      "亚马逊S3",
      "AWS Snowball",
      "AWS CLI"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 605,
    "topic": "",
    "question_cn": "一家公司有几个内部因特网小型计算机系统接口(iSCSI)网络存储服务器。该公司希望通过移动到云来减少这些服务器的数量。解决方案架构师必须提供对经常使用的数据的低延迟访问并在基础设施变化最少的情况下减少对内部服务器的依赖。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "部署一个Amazon S3文件网关。",
      "B": "部署Amazon EBS和Amazon S3备份的Amazon弹性块存储(EBS)。",
      "C": "部署一个与存储卷配置的AWS存储网关卷网关。",
      "D": "部署一个与缓存卷配置的AWS存储网关卷网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Storage Gateway",
      "iSCSI",
      "Caching"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是存储网关的卷网关可以配置缓存，实现低延迟访问，减少对内部存储的依赖。",
      "why_correct": "存储网关卷网关的缓存模式，可以缓存常用数据，实现低延迟访问，并且可以和iSCSI环境集成，减少迁移的复杂性。",
      "why_wrong": "A: 文件网关不适用于iSCSI环境。 B: EBS与iSCSI没有直接关系。 C: 存储卷模式不提供缓存。"
    },
    "related_terms": [
      "iSCSI",
      "Amazon S3",
      "Amazon EBS",
      "AWS存储网关",
      "存储卷",
      "缓存卷"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 606,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个应用程序允许业务用户将对象上传到Amazon S3。解决方案需要最大限度地提高对象的耐久性。对象也必须在任何时间随时可用。用户将在上传对象后的头30天内经常访问对象，但用户更不可能访问超过30天的对象。哪种解决方案最符合这些要求？",
    "options_cn": {
      "A": "使用S3生命周期规则将所有的物体储存在S3标准中，以便在30天后将物体转移到冰川。",
      "B": "将所有对象存储在S3标准中并使用生命周期规则在30天后将对象转换为S3标准-IA (S3-IA)。",
      "C": "将所有对象存储在S3标准中并使用生命周期规则在30天后将对象转换为S3标准-IA (S3-IA)。",
      "D": "将所有对象存储在S3智能层中使用生命周期规则将对象过渡到标准标准30天后。"
    },
    "vote_percentage": "90%",
    "tags": [
      "S3 Storage Classes",
      "S3 Lifecycle Rules"
    ],
    "explanation": {
      "analysis": "考察根据访问频率和耐久性要求选择合适的S3存储类。",
      "why_correct": "选项B将对象存储在S3标准中，前30天提供高频率访问，之后转换为S3标准-IA，降低存储成本，同时保持数据可用性。",
      "why_wrong": "选项A将对象转移到冰川，读取速度会降低。选项C重复，有误。选项D使用智能层，在频繁访问的场景中可能成本较高。"
    },
    "related_terms": [
      "Amazon S3",
      "S3标准",
      "冰川",
      "S3标准-IA (S3-IA)",
      "S3智能层"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 607,
    "topic": "",
    "question_cn": "一家公司已经将一个两级应用程序从其内部数据中心迁移到了AWS云。数据层是Amazon RDS的多AZ部署用于Oracle，使用EBS存储。该应用程序旨在将文档作为二进制大对象(BLOB)处理和存储在数据库中，平均文档大小为6MB。随着时间的推移数据库的规模有所增加，降低了性能，增加了存储成本。该公司必须提高数据库性能并需要一个高可用性和弹性的解决方案。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "减少RDS数据库实例大小。将存储能力提高到24TB。将存储类型改为磁存储。",
      "B": "增加RDS数据库实例大小。将存储容量提高到24TB。使用SSD的存储类型以提供IOPS。",
      "C": "创建一个Amazon S3桶。更新应用程序以存储S3桶中的文档。在现有数据库中存储对象元数据。",
      "D": "创建一个Amazon DynamoDB。更新应用程序以使用DynamoDB。使用AWS Database Migration Service (DMS)将数据从Oracle数据库迁移到DynamoDB。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Performance",
      "S3 Offload"
    ],
    "explanation": {
      "analysis": "考察如何优化数据库性能和存储成本，以及利用S3存储大对象。",
      "why_correct": "选项C将文档存储在S3桶中，降低了RDS的存储成本和负载，同时在RDS中存储元数据，提高了查询效率。",
      "why_wrong": "选项A减少数据库实例大小会降低性能。选项B增加存储容量和实例大小是提升性能，但成本也增加。选项D将数据库迁移到DynamoDB，改动过大，可能不适合现有应用。"
    },
    "related_terms": [
      "Amazon RDS",
      "Oracle",
      "EBS",
      "BLOB",
      "IOPS",
      "Amazon S3",
      "Amazon DynamoDB",
      "AWS Database Migration Service (DMS)"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 608,
    "topic": "",
    "question_cn": "一家公司有一个应用程序为部署在世界各地多个零售店的客户提供服务。应用程序包括在443端口的HTTPS上公开的后端服务，运行在应用程序负载均衡器(ALB)后面的EC2实例中。零售点通过公共互联网与网络应用程序进行通信。该公司允许每个零售点注册其本地互联网服务提供商分配的零售点IP地址。该公司的安全团队建议通过限制只访问零售点注册的IP地址来提高应用程序端点的安全性。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将一个AWS Web ACL与AWS ALB联系起来。在Web ACL上使用IP规则集来过滤流量。更新规则中的IP地址以包括注册的IP地址。",
      "B": "部署AWS Firewall Manager来管理ALB。配置防火墙规则以将流量限制到IP地址。修改防火墙规则以包括注册的IP地址。",
      "C": "将IP地址存储在Amazon DynamoDB表中。在ALB上配置一个Lambda授权功能以验证传入的请求来自注册的IP地址。",
      "D": "在包含公共接口的子网上配置网络ACL。用每个注册IP地址的条目更新网络ACL上的入口规则。"
    },
    "vote_percentage": "88%",
    "tags": [
      "ALB Security",
      "Web ACL"
    ],
    "explanation": {
      "analysis": "考察如何限制ALB的访问，实现基于IP地址的安全控制。",
      "why_correct": "选项A使用AWS Web ACL（WAF的一部分），能够通过IP规则集过滤流量。这种方案简单高效，可以根据注册的IP地址来限制访问。",
      "why_wrong": "选项B使用Firewall Manager较为复杂，不适用于简单场景。选项C使用Lambda授权，增加了复杂性，增加了维护成本。选项D使用网络ACL，配置较为底层，管理难度较大，不适用于ALB。"
    },
    "related_terms": [
      "HTTPS",
      "EC2",
      "ALB",
      "AWS Web ACL",
      "IP",
      "AWS Firewall Manager",
      "Amazon DynamoDB",
      "Lambda",
      "网络ACL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 609,
    "topic": "",
    "question_cn": "一家公司正在利用AWS湖组在S3上建立一个数据分析平台。该平台将吸收亚马逊RDS和亚马逊S3等不同来源的数据。该公司需要一个安全的解决方案以防止访问含有敏感信息的部分数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个IAM角色，其中包括访问湖泊形成表的权限。",
      "B": "创建数据过滤器来实现行级安全和单元级安全。",
      "C": "在湖泊形成吸收数据之前，创建一个Lambda函数来移除敏感信息。",
      "D": "创建一个自动查询和从湖泊形成表中删除敏感信息的Lambda函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Data Lake",
      "Security",
      "Row-Level Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是数据过滤器可以实现行级安全，在Athena中实现数据过滤可以满足需求，开销最小。",
      "why_correct": "通过数据过滤可以对数据进行精细的控制，实现行级或列级安全，保证只有特定用户才能访问敏感数据，并且开销最小。",
      "why_wrong": "A: IAM 角色控制访问，但不能过滤数据。 C: 需要额外的Lambda函数进行数据清洗，增加了复杂性。 D: 自动删除敏感信息，可能导致数据丢失，并且开销较大。"
    },
    "related_terms": [
      "AWS",
      "S3",
      "Amazon RDS",
      "IAM",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 610,
    "topic": "",
    "question_cn": "一个公司部署在VPC中运行的EC2实例。EC2实例将源数据加载到Amazon S3桶中以便将来能够处理这些数据。根据遵守法律数据不得通过公共互联网传输。公司内部数据中心的服务器将消耗运行在EC2实例上的应用程序的输出。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为Amazon S3部署一个接口VPC端点。在该公司和VPC之间创建一个站点到站点的VPN连接。",
      "B": "为Amazon S3部署网关VPC端点。在现场网络和VPC之间建立一个Direct Connect连接。",
      "C": "建立一个从VPC到S3桶的传输网关连接。在该公司和VPC之间创建一个站点到站点的VPN连接。",
      "D": "设置NAT网关。配置代理EC2实例，这些实例具有通往NAT网关的路由。配置代理EC2实例来获取S3数据并为应用程序实例提供信息。"
    },
    "vote_percentage": "86%",
    "tags": [
      "VPC Endpoint",
      "S3 Private Access"
    ],
    "explanation": {
      "analysis": "考察如何在VPC内安全访问S3，并连接到本地数据中心。",
      "why_correct": "选项B，通过VPC网关端点实现对S3的私有访问，通过Direct Connect实现与本地数据中心的私有连接。能够避免数据通过公共互联网传输。",
      "why_wrong": "选项A，接口端点会产生额外的成本，并且可能比网关端点慢，而通过VPN连接实现本地访问，增加了网络延迟。选项C，使用传输网关增加了复杂性。选项D，设置NAT网关会产生额外的费用，且性能较低。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "Amazon S3",
      "接口VPC端点",
      "VPN",
      "站点到站点的VPN连接",
      "网关VPC端点",
      "Direct Connect",
      "传输网关",
      "NAT网关",
      "代理EC2实例"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 611,
    "topic": "",
    "question_cn": "一个公司有一个基于REST接口的应用程序，它允许从第三方供应商那里近实时接收数据。一旦收到应用程序将处理和存储数据以供进一步分析。该应用程序正在EC2实例上运行。第三方供应商在向应用程序发送数据时收到了503（服务不可用）错误。当数据量激增时计算能力达到最大限度，应用程序无法处理所有请求。解决方案架构师应该推荐哪种设计来提供更可伸缩的解决方案？",
    "options_cn": {
      "A": "使用Amazon Kinesis Data Streams来吸收数据。使用Lambda函数处理数据。",
      "B": "在现有应用程序之上使用Amazon API Gateway。为第三方供应商创建一个有配额限制的使用计划。",
      "C": "使用Amazon Simple Notification Service (SNS)来吸收数据。将EC2实例放在应用程序负载平衡器后面的自动缩放组中。",
      "D": "将应用程序重新打包为容器。使用具有自动缩放组的EC2启动类型使用Amazon Elastic Container Service (ECS)来部署应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Scalability",
      "Serverless Architecture"
    ],
    "explanation": {
      "analysis": "考察如何设计可扩展的应用程序，以处理来自第三方的数据激增。",
      "why_correct": "选项A使用Kinesis Data Streams作为数据入口点，Lambda函数处理数据，这种组合提供了高度的可扩展性和弹性。Kinesis处理了流量峰值，Lambda函数可以根据需求自动扩展。",
      "why_wrong": "选项B，API Gateway可以处理流量控制，但无法解决应用程序的计算资源瓶颈。选项C，SNS作为数据入口，可以增强可用性，但无法解决数据处理瓶颈。选项D，使用ECS，能够改善扩展性，但比起serverless方案，运维成本较高。"
    },
    "related_terms": [
      "REST",
      "EC2",
      "Amazon Kinesis Data Streams",
      "Lambda",
      "Amazon API Gateway",
      "Amazon Simple Notification Service (SNS)",
      "ALB",
      "EC2",
      "Amazon Elastic Container Service (ECS)"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 612,
    "topic": "",
    "question_cn": "一个公司有一个应用程序在一个私有的子网中运行在亚马逊EC2实例上。应用程序需要处理来自亚马逊S3桶的敏感信息。应用程序不得使用互联网连接到S3桶。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置一个互联网网关。更新S3桶策略允许从互联网网关访问。更新应用程序以使用新的互联网网关。",
      "B": "配置VPN连接。更新S3桶策略以允许从VPN连接访问。更新应用程序以使用新的VPN连接。",
      "C": "配置一个NAT网关。更新S3桶策略允许从NAT网关访问。更新应用程序以使用新的NAT网关。",
      "D": "配置一个VPC端点。更新S3桶策略允许从VPC端点访问。更新应用程序以使用新的VPC端点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3",
      "Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是VPC端点提供了一个私有的方式访问S3，不需要经过互联网，更加安全。",
      "why_correct": "VPC端点允许从VPC内部安全地访问S3，而不需要经过互联网，提高安全性，降低复杂性。",
      "why_wrong": "A: 使用互联网网关，不符合题目要求，通过互联网访问S3桶，不安全。 B: VPN，需要额外的配置，且增加了复杂性。 C: 使用NAT网关，也需要经过互联网，不安全。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "互联网网关",
      "VPN",
      "NAT网关",
      "VPC端点"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 613,
    "topic": "",
    "question_cn": "一个公司使用Amazon Elastic Kubernetes Service (EKS) 运行一个容器应用程序。EKS 集群存储Kubernetes机密对象中的敏感信息。公司希望确保信息加密。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用容器应用程序通过使用AWS Key Management Service (KMS)加密信息。",
      "B": "通过使用AWS Key Management Service (KMS)在EKS集群中实现机密加密。",
      "C": "实现使用AWS Key Management Service (KMS)加密信息的Lambda函数。",
      "D": "使用AWS Systems Manager Parameter Store通过使用AWS Key Management Service (KMS)加密信息。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EKS",
      "KMS Encryption"
    ],
    "explanation": {
      "analysis": "考察在EKS集群中实现机密加密的解决方案。",
      "why_correct": "选项B，通过使用KMS在EKS集群中实现机密加密。EKS原生支持与KMS集成，无需编写额外代码，即可实现机密数据的加密，是最简单的方案。",
      "why_wrong": "选项A需要编写代码，增加了复杂性。选项C需要实现Lambda函数，过于复杂。选项D使用Systems Manager Parameter Store，增加了额外组件，运维复杂，不太适合Kubernetes机密存储。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "Kubernetes",
      "AWS Key Management Service (KMS)",
      "AWS Systems Manager Parameter Store"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 614,
    "topic": "",
    "question_cn": "一家公司正在设计一种新的多层网络应用程序，它由下列组件组成：EC2 Web服务器，作为自动缩放组的一部分在亚马逊EC2实例上运行的应用程序服务器，RDS亚马逊数据库数据存储实例。解决方案架构师需要限制对应用服务器的访问，这样只有Web服务器才能访问它们。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在应用程序服务器前部署自动链接。将网络ACL配置为只允许Web服务器访问应用程序服务器。",
      "B": "在应用服务器前部署一个VPC端点。配置安全组只允许Web服务器访问应用程序服务器。",
      "C": "部署一个网络负载平衡器目标组，包含应用程序服务器的自动缩放组。将网络ACL配置为只允许Web服务器访问应用程序服务 器。",
      "D": "将应用程序负载平衡器部署到包含应用程序服务器自动缩放组的目标组中。配置安全组只允许Web服务器访问应用程序服务器。"
    },
    "vote_percentage": "83%",
    "tags": [
      "Security Groups",
      "Application Load Balancer",
      "Network Architecture"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是ALB 和安全组可以控制应用程序服务器的访问，确保只有Web服务器可以访问。",
      "why_correct": "ALB可以将流量分发到应用服务器，安全组可以控制流量的来源，确保只有Web服务器可以访问应用服务器。",
      "why_wrong": "A: 使用网络ACL，增加了配置复杂度，并且不够灵活。 B: VPC端点与此场景无关。 C: 使用负载均衡器和网络ACL，增加了配置复杂度，并且不够灵活。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "RDS",
      "VPC端点",
      "安全组",
      "网络负载均衡器",
      "网络ACL",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 615,
    "topic": "",
    "question_cn": "一家公司在亚马逊弹性库伯内特斯服务(EKS)上运行一个面向客户的关键应用程序。该应用程序具有微服务架构。该公司需要实现一个解决方案，该解决方案收集、聚合并从集中位置的应用程序中总结度量和日志。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在现有的EKS集群中运行亚马逊云表代理。在云表控制台中查看度量和日志。",
      "B": "在现有的EKS集群中运行AWS应用程序。查看应用程序网眼控制台中的度量和日志。",
      "C": "配置AWS CloudTrail以捕捉数据事件。通过使用亚马逊开放搜索服务查询CloudTrail。",
      "D": "在现有的EKS集群中配置亚马逊云表容器。在云表控制台中查看度量和日志。"
    },
    "vote_percentage": "90%",
    "tags": [
      "CloudWatch Container Insights",
      "EKS",
      "Monitoring"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是使用CloudWatch Container Insights，可以收集EKS集群的度量和日志，并在CloudWatch控制台中查看。",
      "why_correct": "CloudWatch Container Insights可以帮助用户监视，排除和隔离容器化应用程序的问题。它提供集群和容器级别的指标，以及日志聚合。",
      "why_wrong": "A: 云表代理配置较为复杂。 B: 应用程序网眼控制台，不是常用的监控方式。 C: CloudTrail 记录API调用，不是收集应用程序指标和日志的合适方法。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "EKS",
      "CloudWatch",
      "AWS",
      "CloudTrail",
      "Amazon 开放搜索服务",
      "亚马逊云表容器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 616,
    "topic": "",
    "question_cn": "一家公司已经将其最新产品部署到了美国航空公司。该产品运行在网络负载平衡器后面的一个自动缩放组中。该公司把产品的物品放在一个亚马逊S3桶里。该公司最近经历了对其系统的恶意攻击。该公司需要一个解决方案，该解决方案可以持续监控AWS账户中的恶意活动、工作负载和对S3桶的访问模式。解决方案还必须报告可疑活动并在仪表板上显示信息。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置亚马逊马西以监测和报告调查结果的美国航空服务协会的配置。",
      "B": "配置亚马逊检查员以监测和报告发现到的美国天文台云道。",
      "C": "配置亚马逊保护任务以监控和报告发现到的美国安全服务中心。",
      "D": "配置亚马逊 EventBridge以监测和报告结果。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon GuardDuty",
      "S3",
      "Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是使用Amazon GuardDuty，可以持续监控AWS账户中的恶意活动和S3桶的访问模式，并提供报告和仪表盘。",
      "why_correct": "Amazon GuardDuty可以监测恶意活动，如异常的API调用，并对S3桶访问模式进行监控，并提供报告和仪表板。",
      "why_wrong": "A: 马西与监控恶意活动不相关。 B: 亚马逊检查员主要用于安全评估。 D: EventBridge主要用于事件驱动的架构，不是用于安全监控。"
    },
    "related_terms": [
      "网络负载平衡器",
      "自动缩放组",
      "Amazon S3",
      "Amazon Macie",
      "亚马逊检查员",
      "亚马逊保护任务",
      "亚马逊 EventBridge"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 617,
    "topic": "",
    "question_cn": "一家公司想将一个内部数据中心迁移到AWS。数据中心的主机是存储服务器，存储服务器将数据存储在基于NFS的文件系统中，200GB数据。存储服务器存储的文件200GB的数据。公司需要不间断地将数据迁移到现有的AWS服务中。AWS中的多个资源必须能够通过使用NFS协议访问数据。哪些步骤组合将最符合这些要求？选二。",
    "options_cn": {
      "A": "为光泽文件系统创建一个亚马逊FSx。",
      "B": "创建一个亚马逊弹性文件系统(EFS)作为亚马逊文件系统。",
      "C": "创建一个Amazon S3 bucket to receive the data.",
      "D": "手动使用一个操作系统拷贝命令将数据推送到AWS目标。",
      "E": "在酒店内的数据中心安装一个美国信息系统数据合成代理。在内部位置和AWS之间使用数据化监视任务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "Data Migration",
      "NFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AB，但社区共识(投票最高)为BE。社区倾向BE的原因是，EFS提供NFS协议，可以在AWS中提供NFS共享。DataSync可以加速数据传输。",
      "why_correct": "B: 使用EFS提供NFS共享。 E: DataSync用于加速数据迁移，减少停机时间。",
      "why_wrong": "A: FSx for Lustre 不提供 NFS 协议。 C: S3不提供NFS协议支持。 D: 手动拷贝命令可能导致停机。"
    },
    "related_terms": [
      "NFS",
      "Amazon FSx",
      "EFS",
      "Amazon S3",
      "AWS",
      "美国信息系统数据合成代理"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 618,
    "topic": "",
    "question_cn": "一家公司希望将 Amazon FSx for Windows File Server 用于其 Amazon EC2 实例的文件服务器，这些实例将一个 SMB 文件共享作为卷在美国东 1 号区域。该文件服务器有 5 分钟的恢复点目标 (RPO) 用于计划的系统维护或计划外的服务中断。该公司需要将该文件系统复制到美国西部 2 号地区。任何用户五年内不得删除复制数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在具有单 AZ 部署类型的 FSx for Windows File Server 文件系统创建一个 AWS 备份。使用 AWS Backup 创建一个每日备份计划，其中包括一个备份规则，该规则将备份复制到美国西部 2 号。为美国西部 2 号的目标保险库配置符合模式的备份保险库锁。设定 5 年的最低保留期限。",
      "B": "在具有多 AZ 部署类型的 FSx for Windows File Server 文件系统创建一个 AWS 备份。使用 AWS Backup 创建一个每日备份计划，其中包括一个备份规则，该规则将备份复制到美国西部 2 号。在治理模式下为美国西部 2 号的目标保险库配置 AWS Backup 保险库锁。设定 5 年的最低期限。",
      "C": "在具有多 AZ 部署类型的 FSx for Windows File Server 文件系统创建一个 AWS 备份。使用 AWS Backup 创建一个每日备份计划，其中包括一个备份规则，该规则将备份复制到美国西部 2 号。为美国西部 2 号的目标保险库配置符合模式的 AWS Backup 保险库锁。设定 5 年的最低期限。",
      "D": "在具有单 AZ 部署类型的 FSx for Windows File Server 文件系统创建一个 AWS 备份。使用 AWS Backup 创建一个每日备份计划，其中包括一个备份规则，该规则将备份复制到美国西部 2 号。在治理模式下为美国西部 2 号的目标保险库配置 AWS Backup 保险库锁。设定 5 年的最低期限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Windows File Server",
      "AWS Backup"
    ],
    "explanation": {
      "analysis": "考查使用 AWS Backup 备份 FSx 文件服务器并满足 RPO 和数据保留要求的能力。",
      "why_correct": "多 AZ 部署提供高可用性，AWS Backup 提供了备份和复制功能。",
      "why_wrong": "单 AZ 部署不具备高可用性。"
    },
    "related_terms": [
      "Amazon FSx for Windows File Server",
      "Amazon EC2",
      "SMB",
      "AWS",
      "AWS Backup",
      "美国西部 2 号",
      "RPO",
      "单 AZ",
      "多 AZ",
      "备份保险库锁",
      "治理模式"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 619,
    "topic": "",
    "question_cn": "一个解决方案架构师正在为一个公司设计一个安全解决方案，该公司希望通过 AWS 组织向开发人员提供单独的 AWS 帐户，同时维护标准的 AWS 安全控制。由于单个开发人员将拥有 AWS 帐户根用户级访问自己帐户的权限，因此解决方案架构师希望确保不修改应用于新开发人员 AWS 帐户的强制性 CloudTrail 配置。哪些行动符合这些要求？",
    "options_cn": {
      "A": "创建一个禁止更改 CloudTrail 的 IAM 策略。把它连接到根用户上。",
      "B": "使用启用的组织路径选项从开发人员帐户中创建一个新的 CloudTrail。",
      "C": "创建一个禁止更改 CloudTrail 的服务控制策略 (SCP) 并将其附加到开发人员帐户中。",
      "D": "为 CloudTrail 创建一个与服务相关的角色，其策略条件只允许在管理帐户中更改 Amazon 资源名 (ARN)。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SCP",
      "CloudTrail"
    ],
    "explanation": {
      "analysis": "考查如何通过 SCP 阻止开发人员修改 CloudTrail 配置。",
      "why_correct": "使用 SCP 可以限制开发人员对账户的访问权限，确保 CloudTrail 配置不被修改。",
      "why_wrong": "IAM 策略附加到根用户，会影响所有用户；开发人员创建新的 CloudTrail 无法满足题意；与服务相关的角色通常用于其他服务访问。"
    },
    "related_terms": [
      "AWS",
      "CloudTrail",
      "IAM",
      "SCP",
      "Amazon"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 620,
    "topic": "",
    "question_cn": "一家公司正计划在 AWS 云中部署一个对业务至关重要的应用程序。应用程序需要具有一致、低延迟性能的持久存储。解决方案架构师应该推荐哪种类型的存储来满足这些需求？",
    "options_cn": {
      "A": "实例存储卷",
      "B": "用于记忆存储集群的 Amazon ElastiCache",
      "C": "供应 IOPS 的 Amazon EBS 卷",
      "D": "HDD 优化容量的 Amazon EBS 卷"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS",
      "Storage"
    ],
    "explanation": {
      "analysis": "考查选择合适的存储类型来满足低延迟和持久性需求。",
      "why_correct": "EBS 卷，特别是 IOPS 优化的 EBS 卷，提供了持久性、一致的性能和低延迟。",
      "why_wrong": "实例存储是临时的；ElastiCache 用于缓存；HDD 优化的 EBS 用于吞吐量优化，而非低延迟。"
    },
    "related_terms": [
      "Amazon EBS",
      "ElastiCache",
      "供应 IOPS",
      "HDD"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 621,
    "topic": "",
    "question_cn": "一家在线照片共享公司将其照片存储在 Amazon S3 桶中，该桶位于美国西部 1 号地区。该公司需要在美国东 1 号地区储存所有新照片的副本。用最少的操作性努力，哪种解决方案能满足这一要求？",
    "options_cn": {
      "A": "在美国东 1 号创建第二个 S3 桶。使用 S3 跨区域复制从现有的 S3 桶复制照片到第二个 S3 桶。",
      "B": "创建现有 S3 桶的跨来源资源共享 (CORS) 配置。在 CORS 规则的授权来源元素中指定美国东 1 号。",
      "C": "跨多个可用性区在美国东 1 号创建第二个 S3 桶。创建一个生命周期规则将照片保存到第二个 S3 桶。",
      "D": "在美国东 1 号创建第二个 S3 桶。在对象创建上配置 S3 事件通知，并更新事件以调用 Lambda 函数将照片从现有的 S3 桶复制到第二个 S3 桶。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3 Cross-Region Replication",
      "S3"
    ],
    "explanation": {
      "analysis": "考查使用 S3 跨区域复制来复制对象。",
      "why_correct": "S3 跨区域复制提供了最简单的解决方案，可以自动复制数据到另一个区域。",
      "why_wrong": "CORS 用于跨域访问；生命周期规则用于数据生命周期管理；Lambda 函数复制方案需要更多的操作工作量。"
    },
    "related_terms": [
      "S3",
      "S3 跨区域复制",
      "Lambda",
      "CORS",
      "生命周期规则",
      "S3 事件通知"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 622,
    "topic": "",
    "question_cn": "一家公司正在为其订户创建一个新的Web应用程序。应用程序将由一个静态的单页面和一个持久的数据库层组成。该应用程序将有4数百万计的用户在早上4小时内使用，但在一天的剩余时间里，该应用程序仅有几千个用户。该公司的数据架构师要求有能力快速发展他们的架构。哪些解决方案将满足这些需求并提供最大的可伸缩性？选二。",
    "options_cn": {
      "A": "部署亚马逊DynamoDB作为数据库解决方案。按需提供能力。",
      "B": "部署亚马逊Aurora作为数据库解决方案。选择无服务器数据库引擎模式。",
      "C": "部署亚马逊DynamoDB作为数据库解决方案。确保DynamoDB自动缩放启用。",
      "D": "将静态内容部署到一个亚马逊S3桶中。提供一个亚马逊云端分布以S3桶的起源。",
      "E": "将Web服务器部署到自动缩放组中的亚马逊EC2实例中的静态内容。将实例配置为从亚马逊弹性文件系统(EFS) 亚马逊EFS卷中定期刷新内容。"
    },
    "vote_percentage": "60%",
    "tags": [
      "DynamoDB",
      "S3",
      "CloudFront",
      "Scalability"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CD，但社区共识(投票最高)为AD。社区倾向AD的原因是使用DynamoDB按需模式，配合S3和CloudFront，可以实现高性能、高可用、可伸缩的Web应用程序。",
      "why_correct": "A: DynamoDB按需模式，可以自动伸缩，满足高并发的需求。 D: S3和CloudFront，可以实现静态内容的快速分发，提供高可用性。",
      "why_wrong": "B: Aurora Serverless更适合OLTP，不适合高并发。 C: DynamoDB自动伸缩，但不如按需模式更灵活。 E: EC2, EFS 架构复杂，成本高，不能满足高并发的需求。"
    },
    "related_terms": [
      "DynamoDB",
      "Aurora",
      "EC2",
      "S3",
      "CloudFront",
      "EFS",
      "自动缩放组"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 623,
    "topic": "",
    "question_cn": "一家公司使用Amazon API Gateway来管理第三方服务提供商访问的其余API。公司必须保护其余的API不受SQL注入和跨站点脚本攻击。什么最有效的业务解决方案符合这些要求？",
    "options_cn": {
      "A": "配置AWS WAF保护。",
      "B": "配置一个AWS WAF。",
      "C": "建立一个与Amazon CloudFront集成的API Gateway。在CloudFront配置WAF。",
      "D": "建立一个与Amazon CloudFront集成的API Gateway。在CloudFront配置无线电。"
    },
    "vote_percentage": "89%",
    "tags": [
      "API Gateway",
      "WAF"
    ],
    "explanation": {
      "analysis": "此题考察API Gateway和WAF的结合使用。社区倾向于选择使用AWS WAF来防护API Gateway，以应对SQL注入和跨站点脚本攻击。官方答案是A，但B更直接、简洁。",
      "why_correct": "AWS WAF是专门用于保护Web应用程序的Web应用程序防火墙，可以防御常见的Web攻击，如SQL注入和跨站点脚本攻击。配置在API Gateway之前，可以有效拦截恶意请求。",
      "why_wrong": "A选项中，配置了AWS WAF，符合要求。C选项涉及CloudFront，虽然可以提供安全性和内容分发，但不是最直接的解决方案。D选项提及了无线电，这与保护API无关。"
    },
    "related_terms": [
      "API Gateway",
      "AWS WAF",
      "CloudFront"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 624,
    "topic": "",
    "question_cn": "一家公司希望为用户提供访问 AWS 资源的权限。该公司拥有 1,500 个用户，并通过公司网络上的 Active Directory 用户组管理其对内部 AWS 资源的访问。然而，公司不希望用户必须维护另一个身份才能访问 AWS 资源。解决方案架构师必须管理使用者对 AWS 资源的访问，同时保存对现场资源的访问。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "为公司的每个用户创建一个 IAM 用户。为每个用户附加适当的策略。",
      "B": "使用 Amazon Cognito 和一个活动目录用户池。根据相应的政策设置角色。",
      "C": "用所附的适当政策界定跨账户角色。将角色映射到活动目录组。",
      "D": "配置安全断言标记语言 (SAML) 2.0 联合。用适当的策略创建角色并将角色映射到活动目录组。"
    },
    "vote_percentage": "92%",
    "tags": [
      "SAML",
      "IAM"
    ],
    "explanation": {
      "analysis": "考查使用 SAML 联合来实现单点登录 (SSO) 和访问 AWS 资源。",
      "why_correct": "SAML 2.0 联合允许用户使用现有的身份验证系统（例如 Active Directory）登录到 AWS。",
      "why_wrong": "IAM 用户是独立的账户；Cognito 通常用于移动和 Web 应用程序；跨账户角色用于不同 AWS 账户之间的访问。"
    },
    "related_terms": [
      "IAM",
      "Amazon Cognito",
      "Active Directory",
      "SAML",
      "IAM 用户",
      "IAM 策略"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 625,
    "topic": "",
    "question_cn": "一家公司在多个应用程序负载均衡器后面开设了一个网站。该公司在世界各地拥有不同的销售权。解决方案架构师需要确保用户在不侵犯发布权的情况下获得正确的内容。解决方案架构师应该选择哪种配置来满足这些需求？",
    "options_cn": {
      "A": "配置Amazon CloudFront与美国无线电通信。",
      "B": "AWS WAF将应用程序负载平衡器配置为",
      "C": "采用地理定位策略配置Amazon Route 53。",
      "D": "采用地理邻近路由策略配置Amazon Route 53。"
    },
    "vote_percentage": "77%",
    "tags": [
      "Route 53",
      "Geolocation Routing"
    ],
    "explanation": {
      "analysis": "此题考查Route 53的地理定位策略。社区认为，使用Route 53的地理定位策略配置DNS解析，可以根据用户的地理位置将用户定向到不同的内容服务器，从而满足不同地区的版权要求。官方答案是A，但C更直接相关。",
      "why_correct": "Amazon Route 53 的地理定位路由策略允许您根据用户的地理位置将用户定向到不同的资源。这对于满足内容发布授权要求非常有用，因为您可以根据用户的位置提供不同的内容。",
      "why_wrong": "A 选项涉及CloudFront，但没有直接解决根据地理位置提供内容的问题。B 选项涉及 WAF，这与地理位置控制无关。 D 选项提及了地理邻近路由策略，但这不如地理定位策略更直接。"
    },
    "related_terms": [
      "CloudFront",
      "AWS WAF",
      "Amazon Route 53",
      "地理定位"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 626,
    "topic": "",
    "question_cn": "一家公司将其数据存储在公司内部。数据量的增长超过了公司的能力。该公司希望将其数据从内部位置迁移到 Amazon S3 桶。该公司需要一个解决方案，将自动验证完整的数据后转移。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "订购一个 AWS Snowball Edge 设备。配置 Snowball Edge 设备以执行在线数据传输到 S3 桶",
      "B": "在现场部署一个 AWS DataSync 代理。将 DataSync 代理配置为执行在线数据传输到 S3 桶。",
      "C": "在现场创建一个 Amazon 文件网关，配置文件网关以执行在线数据传输到 S3 桶",
      "D": "在内部配置 Amazon S3 传输加速器。配置加速器执行在线数据传输到 S3 桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DataSync",
      "S3"
    ],
    "explanation": {
      "analysis": "考查数据迁移，并确保数据的完整性。",
      "why_correct": "AWS DataSync 代理可以执行在线数据传输，并在传输后验证数据的完整性。",
      "why_wrong": "Snowball Edge 适合大数据量、离线迁移；文件网关主要用于混合云存储；S3 传输加速器用于优化上传速度，不提供数据完整性验证。"
    },
    "related_terms": [
      "S3",
      "Snowball Edge",
      "AWS DataSync",
      "Amazon 文件网关",
      "S3 传输加速器"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 627,
    "topic": "",
    "question_cn": "一家公司想将两个 DNS 服务器迁移到 AWS。这些服务器共容纳大约 200 个区域，平均每天收到 100 万个请求。该公司希望最大限度地增加可用性，同时最大限度地减少与这两个服务器的管理有关的运营开销。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "在 Amazon Route 53 控制台中导入区域文件，创建 200 个新的托管区域。",
      "B": "推出一个大型 Amazon EC2 实例导入区域瓷砖。配置 Amazon CloudWatch 警报和通知以提醒公司任何停机时间。",
      "C": "使用 AWS Server Migration Service 将服务器迁移到 AWS。配置 Amazon CloudWatch 警报和通知以提醒公司任何停机时间。",
      "D": "在两个可用性区域启动 Amazon EC2 实例。导入区域文件。将自动缩放组的期望容量设置为 1，最大容量设置为 3。根据 CPU 利用率将缩放报警器配置为缩放报警器"
    },
    "vote_percentage": "94%",
    "tags": [
      "Route 53",
      "DNS Migration"
    ],
    "explanation": {
      "analysis": "考查如何将 DNS 记录迁移到 Route 53，并实现高可用性。",
      "why_correct": "使用 Route 53 管理托管区域，可以简化 DNS 管理，并利用 Route 53 的全球 Anycast 网络实现高可用性。",
      "why_wrong": "EC2 实例需要手动管理和维护，运维成本高；Server Migration Service 主要是服务器迁移；自动缩放方案增加了复杂性，不一定更简单。"
    },
    "related_terms": [
      "Amazon Route 53",
      "Amazon EC2",
      "CloudWatch",
      "AWS Server Migration Service",
      "可用性区",
      "自动缩放组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 628,
    "topic": "",
    "question_cn": "一家全球性的公司在美国 AWS 多个 AWS 帐户中运行其应用程序。该公司的应用程序使用多部分上传数据到 S3 桶在多个区域。公司希望报告不完整的多部分上传以符合成本。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "用一个规则配置 Amazon S3 事件通知，配置来报告不完整的多部分上传对象计数。",
      "B": "创建一个服务控制策略 (SCP) 来报告不完整的多部分上传对象计数。",
      "C": "配置 S3 存储镜头报告不完整的多部分上传对象计数。",
      "D": "创建一个 S3 多区域访问点来报告不完整的多部分上传对象计数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Storage Lens",
      "S3"
    ],
    "explanation": {
      "analysis": "考查如何报告 S3 桶中不完整的多部分上传对象以进行成本优化。",
      "why_correct": "S3 存储镜头可以提供对 S3 桶存储情况的深入分析，包括不完整的多部分上传，方便进行成本优化。",
      "why_wrong": "S3 事件通知用于触发其他操作；SCP 用于账户安全策略；多区域访问点主要用于跨区域访问 S3 对象。"
    },
    "related_terms": [
      "S3",
      "多部分上传",
      "Amazon S3 事件通知",
      "SCP",
      "S3 存储镜头",
      "S3 多区域访问点"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 629,
    "topic": "",
    "question_cn": "一家公司为 MySQL 在 Amazon RDS 上运行一个生产数据库。由于安全性的原因，该公司希望对数据库版本进行升级。由于数据库中包含关键数据，该公司希望能够在不丢失任何数据的情况下快速地解决升级和测试功能的问题。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建 RDS MySQL 手动快照。为 RDS 升级到 Amazon 的新版本 MySQL。",
      "B": "使用本地备份和还原。为 RDS 还原数据到更新的 Amazon MySQL 版本。",
      "C": "使用 AWS 数据库迁移服务 (DMS) 将数据复制到更新的 Amazon MySQL 最新版本的 RDS 中。",
      "D": "使用 Amazon 蓝/绿部署来部署和测试生产变化。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Blue/Green deployments",
      "MySQL"
    ],
    "explanation": {
      "analysis": "考查 MySQL 数据库升级和测试，要求快速、无数据丢失、操作开销最小。",
      "why_correct": "使用 RDS 蓝/绿部署可以快速升级，在测试完毕后，切换流量即可。",
      "why_wrong": "快照和恢复可能需要更长时间；DMS 主要用于数据库迁移；本地备份和恢复涉及手动操作，而且需要更长的恢复时间。"
    },
    "related_terms": [
      "Amazon RDS",
      "MySQL",
      "RDS MySQL",
      "快照",
      "AWS 数据库迁移服务 (DMS)",
      "Amazon 蓝/绿部署"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 630,
    "topic": "",
    "question_cn": "一个解决方案架构师正在创建一个数据处理作业，该作业每天运行一次，可花费 2 小时完成。如果作业被中断，它必须从一开始就重新启动。解决方案架构师应该如何以最具成本效益的方式解决这个问题？",
    "options_cn": {
      "A": "创建一个脚本在本地运行的 Amazon EC2 保留的实例是触发一个 Cron 作业。",
      "B": "创建一个由 Amazon EventBridge 计划事件触发的 Lambda 函数。",
      "C": "使用 Amazon Elastic Container Service (ECS) Amazon Fargate 任务启动 Amazon EventBridge 计划事件。",
      "D": "使用在 Amazon EC2 实例上运行的 Amazon Elastic Container Service 任务，由 Amazon EventBridge 计划事件触发。"
    },
    "vote_percentage": "87%",
    "tags": [
      "ECS Fargate",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "考查如何以最具成本效益的方式运行可中断的数据处理作业。",
      "why_correct": "使用 ECS Fargate 可以按需运行容器化任务，无需管理服务器。并使用 EventBridge 进行调度，在作业中断时自动重新运行。",
      "why_wrong": "EC2 实例需要管理和维护；Lambda 函数可能不适合长时间运行的作业。"
    },
    "related_terms": [
      "Amazon EC2",
      "Cron",
      "Amazon EventBridge",
      "Lambda",
      "ECS",
      "Fargate"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 631,
    "topic": "",
    "question_cn": "一家社交媒体公司希望在AWS云中存储其用户配置文件、关系和交互的数据库。公司需要一个应用程序来监控数据库中的任何变化，应用程序需要分析数据实体之间的关系并向用户提供建议。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用亚马逊海王星存储信息。使用亚马逊运动数据流来处理数据库中的更改。",
      "B": "使用亚马逊海王星存储信息。使用海王星流处理数据库中的更改。",
      "C": "使用亚马逊量子分类账数据库(QLDB)存储信息。使用亚马逊运动数据流来处理数据库中的更改。",
      "D": "使用亚马逊量子分类账数据库(QLDB)存储信息。使用海王星流处理数据库中的更改。"
    },
    "vote_percentage": "88%",
    "tags": [
      "Amazon Neptune",
      "Neptune Streams"
    ],
    "explanation": {
      "analysis": "考查NoSQL数据库的选择和流处理。海王星提供图数据库功能，而海王星流提供数据变更捕获。",
      "why_correct": "海王星和海王星流的组合能有效存储社交媒体的用户关系和互动数据，并通过流捕获变更。",
      "why_wrong": "QLDB是账本数据库，不适合图数据的存储和分析。亚马逊运动数据流功能不如海王星流。"
    },
    "related_terms": [
      "Amazon Neptune",
      "Amazon Kinesis Data Streams",
      "QLDB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 632,
    "topic": "",
    "question_cn": "一家公司正在创建一个新的应用程序，它将存储大量数据。这些数据将每小时分析一次，并将被部署在多个可用性区域的亚马逊EC2实例上。未来6个月所需的存储空间将继续增加。解决方案架构师应该推荐哪种存储解决方案来满足这些需求？",
    "options_cn": {
      "A": "将数据存储在亚马逊S3冰川。更新冰川库策略允许访问应用实例。",
      "B": "将数据存储在Amazon EBS卷中。在应用程序实例上挂载 EBS 卷。",
      "C": "将数据存储在Amazon EFS文件系统中。在应用程序实例上安装EFS文件系统。",
      "D": "将数据存储在应用程序实例之间共享的Amazon EBS中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "Storage"
    ],
    "explanation": {
      "analysis": "考察适合高增长、多实例共享访问的数据存储方案。EFS是理想选择。",
      "why_correct": "EFS提供可扩展的文件存储，可以被多个EC2实例同时访问，满足增长需求。",
      "why_wrong": "S3 Glacier 适用于归档，不适合频繁访问。EBS卷是单实例存储，无法被多个实例共享。"
    },
    "related_terms": [
      "S3",
      "S3 Glacier",
      "EBS",
      "EFS",
      "可用性区域",
      "EC2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 633,
    "topic": "",
    "question_cn": "一家公司管理着一个应用程序，该应用程序将数据存储在Amazon RDS上用于后端数据库实例。流量的增加导致性能问题。该公司确定数据库查询是性能缓慢的主要原因。解决方案架构师应该如何改进应用程序的性能？",
    "options_cn": {
      "A": "从多AZ服务备用副本读取流量。",
      "B": "配置数据库实例以使用传输加速度。",
      "C": "创建一个从源数据库实例读取副本。服务从读取副本读取流量。",
      "D": "使用Amazon Kinesis Data Firehose between the application and Amazon RDS to increase the concurrency of database requests."
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Read Replica",
      "Database Performance"
    ],
    "explanation": {
      "analysis": "考查RDS性能优化，主要是通过读副本分担读流量。",
      "why_correct": "创建RDS读副本，将读请求分流到副本，从而提高数据库的读取性能。",
      "why_wrong": "使用传输加速不直接解决读性能问题。Kinesis Data Firehose不用于加速数据库查询。"
    },
    "related_terms": [
      "Amazon RDS",
      "多AZ",
      "读取副本",
      "传输加速度",
      "Amazon Kinesis Data Firehose"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 634,
    "topic": "",
    "question_cn": "一家公司每天从各种机器上收集10GB的遥测数据。该公司将数据存储在一个源数据帐户中的Amazon S3桶中。该公司聘请了几家咨询机构使用这些数据进行分析。每个机构都需要为其分析员读取数据。公司必须从源数据帐户中共享数据。选择能够最大限度地提高安全性和操作效率的解决方案。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置S3全局表为每个机构复制数据。",
      "B": "在有限的时间内公布S3桶。只通知机构。",
      "C": "为S3桶配置跨账户访问权限以访问各机构拥有的账户。",
      "D": "为源数据帐户中的每个分析员设置一个IAM用户。允许每个用户访问S3桶。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3 Cross-Account Access",
      "IAM"
    ],
    "explanation": {
      "analysis": "考查S3跨账户访问的安全和效率问题。跨账户访问是最优解决方案。",
      "why_correct": "配置跨账户访问权限，允许机构账户访问源S3桶，安全高效。",
      "why_wrong": "S3全局表不适用于这种数据共享场景。公布桶会带来安全风险。为每个分析员设置IAM用户，管理复杂，操作成本高。"
    },
    "related_terms": [
      "S3",
      "IAM",
      "S3 桶",
      "IAM用户"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 635,
    "topic": "",
    "question_cn": "一家公司使用Amazon FSx for CIFS和NFS在其主要的AWS区域中的网络应用程序来获得文件共享。在Amazon EC2实例上运行的应用程序访问文件共享。该公司需要在二级区域的存储灾难恢复解决方案。需要使用与主区域相同的协议来访问在第二区域复制的数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个Lambda函数将数据复制到一个Amazon S3桶。将S3桶复制到第二区域。",
      "B": "FSx通过使用备份为点播卷创建FSx备份。将各卷复制到第二区域，从备份中创建一个新的点播实例。",
      "C": "创建一个FSx for Windows File Server用于第二区域的点播实例。使用网上应用程序的镜像来复制从主要区域到第二区域的数据。",
      "D": "创建一个Amazon EFS卷。将当前数据迁移到卷中，把卷复制到第二区域。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx Disaster Recovery",
      "File System Replication"
    ],
    "explanation": {
      "analysis": "考察FSx的灾难恢复方案。直接复制FSx卷到另一个区域是最优的。",
      "why_correct": "FSx支持卷的备份和恢复，可以将FSx卷复制到另一个区域，实现灾备。",
      "why_wrong": "Lambda函数复制到S3，需要额外的转换操作。EFS不支持跨区域复制。"
    },
    "related_terms": [
      "FSx for CIFS",
      "FSx for NFS",
      "EC2",
      "Lambda",
      "Amazon S3",
      "FSx",
      "Amazon EFS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 636,
    "topic": "",
    "question_cn": "一个开发团队正在创建一个基于事件的应用程序，该应用程序使用AWS Lambda函数。当文件添加到Amazon S3桶时，事件将生成。该开发团队目前拥有亚马逊简单通知服务(SNS)配置为来自亚马逊S3的事件目标。解决方案架构师应该如何以可伸缩的方式处理来自Amazon S3的事件？",
    "options_cn": {
      "A": "创建一个用于处理SNS事件的SNS订阅，在事件运行之前在亚马逊弹性容器服务中处理事件。",
      "B": "创建一个用于处理亚马逊弹性库伯内特斯服务(EKS)中事件运行之前事件的SNS订阅。",
      "C": "创建一个将事件发送到Amazon简单队列服务(SQS)的SNS订阅。配置SQS队列以触发一个Lambda函数。",
      "D": "创建一个将事件发送到服务器迁移服务(SMS)的SNS订阅。从短信事件中配置Lambda函数来投票。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Event Notification",
      "Lambda",
      "SQS"
    ],
    "explanation": {
      "analysis": "考察S3事件触发Lambda函数的最佳实践。通过SQS解耦是最佳方案。",
      "why_correct": "SNS -> SQS -> Lambda。通过SQS实现解耦，提高可伸缩性、可靠性，并且支持异步处理。",
      "why_wrong": "SNS直接触发Lambda可能导致并发问题。EC2/EKS与本场景不相关。SMS与S3事件不相关。"
    },
    "related_terms": [
      "AWS Lambda",
      "Amazon S3",
      "SNS",
      "SQS",
      "ECS",
      "EKS",
      "SMS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 637,
    "topic": "",
    "question_cn": "解决方案架构师正在设计Amazon API网关背后的新服务。服务的请求模式将是不可预测的，并且会突然从0个请求变为每秒超过500个1GB的请求。需要在后端数据库中持久保存的数据的总尺寸目前不到1GB，未来增长不可预测。可以使用简单的键值请求查询数据。哪些服务组合能够满足这些要求？(选二)",
    "options_cn": {
      "A": "法盖特",
      "B": "阿斯兰布达",
      "C": "亚马逊发电机",
      "D": "EC2亚马逊自动缩放",
      "E": "Mysql与兼容的亚马逊极光"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Lambda",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "考查API Gateway后端服务的设计。Lambda和DynamoDB是理想的选择。",
      "why_correct": "Lambda提供无服务器计算，按需扩展，适合突发流量。DynamoDB是键值存储，支持快速查询，并能自动扩展，满足数据存储需求。 （本题为多选题，正确项为：B、C，需全部选对才得分。）",
      "why_wrong": "Fargate是容器服务，对于这种场景过于复杂。EC2需要手动管理。极光数据库不适合键值存储。"
    },
    "related_terms": [
      "Fargate",
      "Lambda",
      "DynamoDB",
      "EC2",
      "Auto Scaling",
      "Aurora"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 638,
    "topic": "",
    "question_cn": "一家公司收集研究数据并与全世界的员工分享。该公司希望在一个Amazon S3桶中收集和存储数据，并在AWS云中处理数据。公司将与AWS公司的员工分享数据。该公司需要一个安全的解决方案，在AWS云最大限度地减少运营开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Lambda函数创建一个S3预先签名的URL。指示员工使用该URL。",
      "B": "为每个员工创建一个IAM用户。为每个员工创建一个允许S3访问的IAM策略。指导员工使用AWS管理控制台。",
      "C": "创建一个S3文件网关。创建上传、共享和下载共享。允许员工在本地电脑上安装股票，使用文件网关。",
      "D": "配置AWS Transfer FamilySFTP端点。选择自定义身份提供者选项，使用秘密管理器管理用户凭证。指导员工使用转移家庭。"
    },
    "vote_percentage": "39%",
    "tags": [
      "S3 Secure Access",
      "AWS Transfer Family"
    ],
    "explanation": {
      "analysis": "考查安全的文件共享方案，尽量减少管理开销。AWS Transfer Family提供安全的文件传输服务。",
      "why_correct": "AWS Transfer Family提供SFTP端点，安全方便，并且可以使用秘密管理器进行用户凭证管理。",
      "why_wrong": "预签名URL需要管理。IAM用户管理复杂。文件网关不适用于大量员工访问。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "IAM",
      "AWS Transfer Family SFTP",
      "S3预先签名的URL",
      "IAM用户",
      "IAM策略",
      "S3 文件网关",
      "SFTP",
      "秘密管理器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 639,
    "topic": "",
    "question_cn": "一家公司正在开发一种新的家具库存应用程序。该公司已将该应用程序部署在一个EC2实例舰队中，跨越多个可用性区域。EC2实例在其VPC的应用程序负载平衡器(ALB)后面运行。解决方案架构师注意到传入的流量似乎倾向于一个EC2实例，导致一些请求的延迟。解决方案架构师应该如何解决这个问题？",
    "options_cn": {
      "A": "禁用ALB的粘性会话。",
      "B": "用网络负载平衡器替换ALB。",
      "C": "在每个可用区域增加EC2实例的数目。",
      "D": "调整ALB目标群体的健康检查频率。"
    },
    "vote_percentage": "89%",
    "tags": [
      "ALB Sticky Session",
      "Load Balancing"
    ],
    "explanation": {
      "analysis": "考察ALB粘性会话的影响，禁用会话保持一致性，解决流量倾斜。",
      "why_correct": "禁用ALB的粘性会话，确保流量在所有EC2实例间均匀分布。",
      "why_wrong": "更换NLB不能解决粘性会话问题。增加实例数量并不能解决流量倾斜。调整健康检查不能直接解决流量倾斜。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "ALB",
      "可用性区域"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 640,
    "topic": "",
    "question_cn": "一个公司有一个应用程序工作流，它使用一个Lambda函数来下载和解密来自Amazon S3的文件。这些文件是加密的，使用AWS密钥管理服务(KMS)键。解决方案架构师需要设计一个能够确保正确设置所需权限的解决方案。哪些操作组合实现了这一点？(选二)",
    "options_cn": {
      "A": "附加解密权限到Lambda函数的资源策略",
      "B": "授予KMS键策略中的IAM角色的解密权限",
      "C": "授予KMS密钥策略中的Lambda资源策略的解密权限。",
      "D": "用IAM创建一个新的策略 解密权限并将该策略附加到Lambda函数上。",
      "E": "用IAM创建一个新的角色 解密权限并将执行角色附加到Lambda函数。"
    },
    "vote_percentage": "85%",
    "tags": [
      "KMS",
      "Lambda Permissions"
    ],
    "explanation": {
      "analysis": "考察KMS和Lambda的权限设置。需要KMS密钥策略授权和Lambda的执行角色授权。",
      "why_correct": "在KMS密钥策略中授予IAM角色解密权限，并且创建IAM角色附加到Lambda函数，授予Lambda执行权限。 （本题为多选题，正确项为：B、E，需全部选对才得分。）",
      "why_wrong": "Lambda的资源策略不能授予访问KMS的权限。KMS密钥策略应授予IAM角色权限。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "KMS",
      "IAM",
      "解密权限",
      "KMS 键策略",
      "资源策略"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 641,
    "topic": "",
    "question_cn": "一家公司想监控其AWS金融服务体系的成本以进行财务审查。云操作团队正在设计一个在组织管理帐户中的架构以查询所有成员帐户的AWS成本和使用报告。团队必须每月运行一次这个查询并提供对账单的详细分析。哪个解决方案是满足这些需求的最可扩展和成本效益最高的方法？",
    "options_cn": {
      "A": "使成本和使用报告在管理帐户向亚马逊运动提供报告。使用亚马逊EMR进行分析。",
      "B": "使成本和使用报告在管理帐户使用Amazon Athena来分析AWS报告。",
      "C": "启用成员账户的成本和使用情况报告。将报告发送到Amazon S3。使用亚马逊红移进行分析。",
      "D": "启用成员账户的成本和使用情况报告。把报告交给亚马逊云跟踪。使用亚马逊速效分析。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cost Analysis",
      "Athena"
    ],
    "explanation": {
      "analysis": "考察AWS成本分析的最佳实践。Athena是针对S3中数据分析的理想选择。",
      "why_correct": "启用成本和使用报告，将报告存储在S3中，然后使用Amazon Athena分析成本。",
      "why_wrong": "EMR和Redshift不适合这种场景。CloudTrail不用于成本分析。"
    },
    "related_terms": [
      "AWS",
      "EMR",
      "Athena",
      "S3",
      "Redshift",
      "CloudTrail",
      "QuickSight"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 642,
    "topic": "",
    "question_cn": "一家公司希望在Amazon EC2实例上运行一个游戏应用程序，这些实例是AWS云中自动缩放组的一部分。应用程序将使用UDP数据包传输数据。该公司希望确保随着流量的增加和减少，应用程序能够扩展。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将网络负载平衡器连接到自动缩放组。",
      "B": "将应用程序负载平衡器附加到自动缩放组。",
      "C": "部署一个带加权策略的Amazon Route 53记录集来适当路由流量。",
      "D": "部署一个配置了端口转发的NAT实例到自动缩放组中的EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "NLB",
      "Auto Scaling",
      "UDP"
    ],
    "explanation": {
      "analysis": "考察游戏应用程序负载均衡的方案，UDP流量需要使用网络负载均衡器。",
      "why_correct": "将网络负载平衡器（NLB）连接到自动缩放组，支持UDP流量，并且自动扩展。",
      "why_wrong": "应用程序负载均衡器（ALB）不支持UDP。Route 53不提供负载均衡功能。NAT实例不提供负载均衡功能。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "UDP",
      "网络负载均衡器",
      "应用程序负载均衡器",
      "Route 53",
      "NAT",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 643,
    "topic": "",
    "question_cn": "一家公司为其不同的品牌在AWS上运营多个网站。每个网站每天生成数十千兆字节的网络流量日志。解决方案架构师需要设计一个可伸缩的解决方案，使公司的开发人员能够分析公司所有网站的流量模式。在几个月的时间里，开发人员将根据需求每周进行一次SQL分析。解决方案必须用标准的SQL支持查询。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "把日志放在Amazon S3上。使用Amazon Athena分析。",
      "B": "在Amazon RDS中存储日志。使用数据库客户端进行分析。",
      "C": "将日志存储在亚马逊开放搜索服务中。使用开放搜索服务进行分析。",
      "D": "将日志存储在亚马逊EMR集群中使用支持的开源框架进行基于SQL的分析。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3",
      "Athena",
      "Log Analysis"
    ],
    "explanation": {
      "analysis": "考察日志分析的最佳方案。Athena基于S3的查询是成本效益最高的方案。",
      "why_correct": "将日志存储在S3上，并使用Amazon Athena进行SQL查询分析。",
      "why_wrong": "RDS存储日志成本高，且不适合这种大数据量。开放搜索服务不适用于SQL查询。EMR成本较高，需要管理。"
    },
    "related_terms": [
      "S3",
      "Athena",
      "RDS",
      "开放搜索服务",
      "EMR",
      "SQL"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 644,
    "topic": "",
    "question_cn": "一家国际公司为其经营的每个国家都有一个子域名。子域名被格式化为example.com、国家和国家。该公司的工作量落后于一个应用负载平衡器。该公司希望加密正在传输的网站数据。哪些步骤组合将满足这些要求？(选二)",
    "options_cn": {
      "A": "使用AWS证书管理器（ACM）控制台请求为顶级顶级域example.com提供公共证书，为*.example.com提供通配符证书。网站。",
      "B": "Use the AWS Certiﬁcate Manager (ACM) console to request a private certiﬁcate for the apex top domain example.com and a wildcard certiﬁcate for *.example.com.",
      "C": "使用AWS证书管理器（ACM）控制台请求为顶级顶级域名测试网站提供公共和私人证书。",
      "D": "通过电子邮件地址验证域名所有权，通过向DNS提供程序添加所需的DNS记录切换到DNS验证。",
      "E": "通过向DNS提供程序添加所需的DNS记录来验证域的域所有权。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ACM",
      "SSL Certificate"
    ],
    "explanation": {
      "analysis": "考察ACM证书的申请和部署。选择正确的证书和验证方法。",
      "why_correct": "使用ACM请求公共证书以及通配符证书(A)。通过添加DNS记录来验证域名所有权(E)。",
      "why_wrong": "私有证书不适用于公共网站。DNS验证是验证域所有权的方法。"
    },
    "related_terms": [
      "AWS",
      "ACM",
      "DNS",
      "example.com",
      "*.example.com",
      "DNS"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 645,
    "topic": "",
    "question_cn": "公司必须在其内部密钥管理器中使用密码密钥。由于监管和合规要求，关键管理器不受AWS云的影响。该公司希望通过使用保存在AWS云之外的加密密钥来管理加密和解密。这些密钥支持来自不同供应商的各种外部密钥管理器。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用由一个云的集群支持的云的关键商店。",
      "B": "使用由外部密钥管理器支持的AWS密钥管理服务(AWS KMS)外部密钥存储。",
      "C": "使用默认的AWS密钥管理服务(AWS KMS)管理的密钥存储。",
      "D": "使用一个自定义的密钥商店支持一个美国克劳姆集群。"
    },
    "vote_percentage": "93%",
    "tags": [
      "KMS",
      "External Key Store"
    ],
    "explanation": {
      "analysis": "考察使用外部密钥存储的 KMS。 KMS 支持与外部密钥管理器的集成。",
      "why_correct": "使用由外部密钥管理器支持的AWS KMS外部密钥存储，可以满足需求。",
      "why_wrong": "默认密钥存储无法使用外部密钥管理器。其他的选择都不适用。"
    },
    "related_terms": [
      "AWS KMS",
      "外部密钥管理器",
      "AWS KMS",
      "密钥存储",
      "AWS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 646,
    "topic": "",
    "question_cn": "解决方案架构师需要在云中存储高性能计算(HPC)工作负载。工作量将运行在数百个亚马逊EC2实例上，并将需要对共享文件系统进行并行访问，以便能够对大型数据集进行分布式处理。数据集将通过多个实例同时访问。工作负载需要在1毫秒范围内的访问延迟。在处理完成后，工程师将需要访问数据集进行手动后处理。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon EFS作为共享文件系统。访问Amazon EFS数据集。",
      "B": "使用Amazon S3桶作为共享文件系统。直接从S3桶执行后处理。",
      "C": "使用Amazon FSx作为共享文件系统。将文件系统链接到一个Amazon S3桶进行后处理。",
      "D": "配置AWS资源访问管理器共享一个Amazon S3桶以便将其安装到所有实例中进行处理和后处理。"
    },
    "vote_percentage": "100%",
    "tags": [
      "HPC",
      "FSx"
    ],
    "explanation": {
      "analysis": "考点是高性能计算场景下，对文件系统的需求，包括低延迟、共享访问和后处理。",
      "why_correct": "Amazon FSx for Lustre 专为高性能计算工作负载设计，提供了低延迟和高吞吐量，可以满足并行访问需求。",
      "why_wrong": "选项A EFS延迟相对较高，不适合高性能计算；选项B S3 不是文件系统，不提供并行访问；选项D 资源访问管理器主要用于资源共享，不能直接提供文件系统。"
    },
    "related_terms": [
      "HPC",
      "EC2",
      "EFS",
      "S3",
      "FSx",
      "Amazon FSx for Lustre",
      "Amazon S3",
      "AWS",
      "EC2",
      "S3"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 647,
    "topic": "",
    "question_cn": "一家游戏公司正在开发一个具有IP功能的语音应用程序。该应用程序将为世界各地的用户服务流量。该应用程序需要具有自动故障转移的区域的高度可用性。该公司希望尽量减少用户的延迟，而不依赖于用户设备上的IP地址缓存。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "使用AWS全球加速器进行健康检查。",
      "B": "使用具有地理定位路由策略的Amazon Route 53线路。",
      "C": "创建一个包含多个起源的Amazon CloudFront分布。",
      "D": "创建一个应用程序负载平衡器，使用基于路径的路由。"
    },
    "vote_percentage": "96%",
    "tags": [
      "Global Accelerator",
      "Latency"
    ],
    "explanation": {
      "analysis": "考点是全球加速器解决全球用户访问的低延迟和高可用性问题。",
      "why_correct": "AWS全球加速器通过在全球AWS边缘站点上提供静态Anycast IP地址，加速用户流量，并提供健康检查和自动故障转移，以最小化延迟。",
      "why_wrong": "选项B Route 53主要用于DNS解析和流量路由，而不是加速流量；选项C CloudFront主要用于内容分发，对语音应用程序的加速效果有限；选项D 应用程序负载平衡器主要用于负载分发，而不是解决全球延迟问题。"
    },
    "related_terms": [
      "IP",
      "AWS 全球加速器",
      "Route 53",
      "CloudFront",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 648,
    "topic": "",
    "question_cn": "一个天气预报公司需要处理数百千兆字节的数据，并有亚毫秒的延迟。该公司在其数据中心拥有高性能计算(HPC)环境，并希望扩大其预测能力。解决方案架构师必须识别一个非常可用的云存储解决方案，它可以处理大量的可持续吞吐量。存储在解决方案中的文件应该可以被几千个同时访问和处理整个数据集的计算实例访问。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "使用Amazon FSx for Lustre作为刮刮文件系统。",
      "B": "使用Amazon FSx for Lustre作为持久性文件系统。",
      "C": "使用具有爆发吞吐量模式的Amazon EFS。",
      "D": "使用具有供应吞吐量模式的Amazon EFS。"
    },
    "vote_percentage": "100%",
    "tags": [
      "HPC",
      "FSx"
    ],
    "explanation": {
      "analysis": "考点是高性能计算场景下的文件存储解决方案选择，需要考虑高吞吐量、低延迟和并发访问。",
      "why_correct": "Amazon FSx for Lustre 专为高性能计算工作负载设计，提供了低延迟和高吞吐量，能够满足需求。",
      "why_wrong": "选项C, D EFS虽然也提供文件存储，但性能不如 FSx，且 EFS 主要为通用型文件系统，不针对高性能计算优化。"
    },
    "related_terms": [
      "HPC",
      "FSx for Lustre",
      "EFS",
      "爆发吞吐量",
      "供应吞吐量"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 649,
    "topic": "",
    "question_cn": "一家电子商务公司在网站上运行一个PostgreSQL数据库。数据库存储数据的方法是使用高I/O的Amazon EBS块存储。数据库每天最高的I/O超过15,000 IOPS。该公司希望将数据库迁移到Amazon RDS以实现PostgreSQL，并提供独立于磁盘存储IOPS能力的磁盘性能。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置通用 SSD (GP2) EBS卷存储类型，并提供15,000 IOPS。",
      "B": "配置预置IOPS SSD (IO1) EBS卷存储类型，并提供15,000 IOPS。",
      "C": "配置通用 SSD (GP3) EBS卷存储类型，并提供15,000 IOPS。",
      "D": "配置磁体类型以实现最大的EBSIOPS。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "EBS"
    ],
    "explanation": {
      "analysis": "考点是 RDS 数据库的存储类型选择，需要满足 IOPS 需求。",
      "why_correct": "GP3 卷可以单独配置 IOPS 而不改变存储大小，并且有更灵活的性能调整能力，性价比高。",
      "why_wrong": "选项 A，GP2 的 IOPS 随着存储容量增加而增加，需要计算；选项 B， IO1 是预置 IOPS，成本较高；选项 D，磁体类型不适用于 RDS，且性能较差。"
    },
    "related_terms": [
      "PostgreSQL",
      "EBS",
      "IOPS",
      "RDS",
      "GP2",
      "IO1",
      "GP3",
      "EBS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 650,
    "topic": "",
    "question_cn": "一家公司希望将其内部的微软SQL Server企业版数据库迁移到AWS。该公司的在线应用程序使用数据库来处理交易。数据分析小组使用相同的生产数据库来运行用于分析处理的报告。该公司希望通过尽可能转向托管服务来减少运营管理费用。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "迁移到Amazon RDS for Microsoft SQL Server。为报告目的使用阅读副本。",
      "B": "迁移到Amazon EC2上的Microsoft SQL Server。在阅读副本中始终用于报告目的。",
      "C": "迁移到Amazon DynamoDB。使用DynamoDB按需复制品进行报告。",
      "D": "迁移到Amazon Aurora。使用Aurora读副本报告目的。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "SQL Server"
    ],
    "explanation": {
      "analysis": "考点是数据库迁移策略和减少运营管理费用。",
      "why_correct": "Amazon RDS for SQL Server 是托管数据库服务，可以减少运营负担，且使用只读副本可以满足报告需求。",
      "why_wrong": "选项 B 需要自行管理 EC2 上的数据库，运维成本较高；选项 C DynamoDB 是 NoSQL 数据库，不兼容 SQL Server；选项 D 虽然 Aurora 也是托管数据库，但其兼容的数据库是 MySQL 和 PostgreSQL。"
    },
    "related_terms": [
      "Microsoft SQL Server",
      "AWS",
      "RDS",
      "EC2",
      "DynamoDB",
      "Aurora",
      "读副本"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 651,
    "topic": "",
    "question_cn": "一家公司在Amazon S3桶中存储了大量的图像文件。在最初的180天里，图像需要随时提供。在接下来的180天里，这些图像很少被访问。360天后，图像需要存档，但必须根据要求即时提供。五年后，只有审计员才能访问图像。审计员必须能够在2小时内找回图像。在此过程中图像不能丢失。开发人员将在第一个180天使用标准存储。开发人员需要配置一个生命周期规则。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "180天后将对象转换为S3标准不经常访问(S3-IA)。360天后将对象转换为S3 Glacier即时检索。5年后将对象转换为S3 Glacier深度档案。",
      "B": "180天后将对象转换为S3标准不经常访问(S3-IA)。360天后将对象转换为S3 Glacier可灵活检索。5年后将对象转换为S3 Glacier深度档案。",
      "C": "180天后将对象转换为S3标准不经常访问(S3-IA)。360天后将对象过渡到S3 Glacier即时检索。5年后将对象过渡到S3 Glacier深度档案。",
      "D": "180天后将对象转换为S3标准不经常访问(S3-IA)。360天后将对象转换为S3 Glacier可灵活检索。5年后将对象进行S3 Glacier深度档案。"
    },
    "vote_percentage": "82%",
    "tags": [
      "S3 Lifecycle",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "考点是S3生命周期规则以及不同存储类别的选择，需要考虑访问频率、检索时间和成本。",
      "why_correct": "标准不经常访问(S3-IA)用于访问频率较低的数据，S3 Glacier即时检索用于需要快速检索的归档数据，S3 Glacier深度档案用于长期归档，且检索时间可接受。",
      "why_wrong": "选项 B 选择了Glacier可灵活检索，但其检索时间不如即时检索；选项 A 与选项 C 的区别在于 5年后的存储类别，都使用深度档案是正确的；选项D, 5年后, 无深度档案，是错误的。"
    },
    "related_terms": [
      "S3",
      "S3-IA",
      "Glacier",
      "Glacier 即时检索",
      "Glacier 可灵活检索",
      "Glacier 深度档案"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 652,
    "topic": "",
    "question_cn": "一家公司有大量的数据工作量，每天运行6个小时。在流程运行期间，公司不能丢失任何数据。解决方案架构师正在设计Amazon EMR集群配置以支持这一关键的数据工作量。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置一个运行较长的集群，该集群根据需求实例运行主节点和核心节点，并根据Spot实例运行任务节点。",
      "B": "配置一个瞬态集群，在按需实例上运行主节点和核心节点，并在Spot实例上运行任务节点。",
      "C": "配置一个临时集群，该集群运行按需实例上的主节点以及Spot实例上的核心节点和任务节点。",
      "D": "配置运行时间较长的集群，该集群运行按需实例上的主节点、Spot实例上的核心节点和Spot实例上的任务节点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EMR",
      "Spot Instances"
    ],
    "explanation": {
      "analysis": "考点是 EMR 集群的配置以及Spot实例的使用，需要考虑可用性和成本。",
      "why_correct": "瞬态集群（Transient cluster）在按需实例上运行主节点和核心节点，Spot实例运行任务节点。Spot 实例提供了成本优化，按需实例保证了核心节点的稳定性，确保了数据的安全性。",
      "why_wrong": "选项A和D使用了较长的集群，成本高；选项C核心节点使用Spot实例，可靠性不高。"
    },
    "related_terms": [
      "EMR",
      "Spot",
      "按需实例",
      "主节点",
      "核心节点",
      "任务节点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 653,
    "topic": "",
    "question_cn": "一家公司维护一个Amazon RDS数据库，将用户映射到成本中心。该公司在美国职业安全协会的一个组织中设有账户。该公司需要一个AWS ID解决方案，它将标记在组织中特定的帐户中创建的所有资源。解决方案必须用创建资源的用户的成本中心标记每个资源。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "(SCP)，将具体的美国世界卫生组织账户从管理账户移至各组织的一个新的组织单位。创建服务控制策略 该策略要求所有现有资源在创建资源之前具有正确的成本中心标记。将 SCP应用于新资源。",
      "B": "RDS，AWS Lambda在从数据库中查找适当的成本中心后创建一个函数来标记资源。配置一个对CloudTrail事件作出反应的Amazon EventBridge，Lambda规则以调用函数。",
      "C": "AWS Lambda，RDS创建一个CloudFormation栈来部署Lambda函数。配置函数以便从数据库中查找适当的成本中心和标记资源。创建一个亚马逊事件桥计划规则来调用CloudFormation栈。",
      "D": "AWS Lambda创建一个Lambda函数用默认值标记资源。配置一个对CloudTrail事件作出反应的亚马逊EventBridge规则以便在资源缺少成本中心标记时调用函数。"
    },
    "vote_percentage": "54%",
    "tags": [
      "SCP",
      "EventBridge",
      "Lambda"
    ],
    "explanation": {
      "analysis": "此题考察如何通过AWS服务实现资源的标记。社区认为，使用SCP来强制标记是一种有效的方案。官方答案是B，但A更侧重于组织级资源的控制。",
      "why_correct": "使用SCP（服务控制策略）可以强制组织内的帐户在创建资源时必须包含特定的标签，例如成本中心。 这确保了所有资源都被正确标记，有助于成本跟踪和管理。",
      "why_wrong": "B 选项使用Lambda和EventBridge来实现标记，这是一种间接的方法，并且实现和维护的复杂性更高。 C 选项也涉及Lambda和CloudFormation，增加了复杂性。 D 选项使用默认值标记资源，但不能保证所有资源都有正确的标记。"
    },
    "related_terms": [
      "RDS",
      "AWS",
      "SCP",
      "IAM",
      "Lambda",
      "CloudTrail",
      "EventBridge",
      "CloudFormation",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 654,
    "topic": "",
    "question_cn": "一家公司最近将其Web应用程序迁移到了AWS云。该公司使用一个Amazon EC2实例来运行多个进程来主机应用程序。这些进程包括一个为静态内容服务的Apache服务器、一个使用本地Redis服务器进行用户会话的Web应用程序。该公司希望重新设计架构，使其具有很高的可用性，并使用AWS管理的解决方案。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS Elastic Beanstalk来主机静态内容和PHP应用程序。配置Elastic Beanstalk将其EC2实例部署到公共子网中。分配一个公共IP地址。",
      "B": "使用Lambda来主机静态内容和PHP应用程序。使用Amazon API Gateway来代理对Lambda函数的请求。设置API Gateway CORS配置。为Redis配置响应域名。配置Amazon ElastiCache来处理会话信息。",
      "C": "将后端代码保存在EC2实例上。为具有多AZ启用的Redis集群创建一个Amazon ElastiCache。在集群模式下为ElastiCache集群配置ElastiCache。将静态资源复制到Amazon S3。配置后端代码以引用S3实例。",
      "D": "用Amazon S3端点配置到一个S3桶，该桶配置为主机静态内容。配置一个应用程序负载均衡器，该平衡器针对Amazon Elastic Container Service (ECS)，PHP服务，Amazon RDS服务，该服务为PHP应用程序运行Fargate任务。将PHP应用程序配置为在多个可用性区运行的ECS集群使用Amazon ElastiCache。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Elastic Beanstalk",
      "High Availability"
    ],
    "explanation": {
      "analysis": "考点是重新设计现有应用程序以实现高可用性和使用 AWS 托管服务，以及静态内容的部署和会话管理。",
      "why_correct": "选项 D 提供了高可用性架构，静态内容通过 S3 提供，使用负载均衡器，后端代码通过 ECS 和 Fargate 部署，使用 RDS 管理数据库，并使用 ElastiCache 进行会话管理。 充分利用了 AWS 的托管服务。",
      "why_wrong": "选项 A Elastic Beanstalk虽然简单，但对于高可用性和扩展性支持有限。选项 B， Lambda 和 API Gateway 处理静态内容效率不高。 选项 C 使用 ElastiCache 但架构整体可用性不够高，且EC2实例单点故障。"
    },
    "related_terms": [
      "EC2",
      "Elastic Beanstalk",
      "PHP",
      "Lambda",
      "API Gateway",
      "CORS",
      "ElastiCache",
      "S3"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 655,
    "topic": "",
    "question_cn": "一家公司在Amazon EC2实例中运行一个具有目标群体的自动缩放组的Web应用程序。该公司设计的应用程序与会话亲和力(粘性会话)一起工作以获得更好的用户体验。Web应用程序必须作为端点在互联网上公开提供。为了获得额外的安全性，必须将Web ACL 应用到端点。会话关联性(粘性会话)必须在端点上配置。哪些步骤组合将满足这些要求？（选2）",
    "options_cn": {
      "A": "创建一个公共网络负载均衡器。指定应用程序目标组",
      "B": "创建一个网关负载均衡器。指定应用程序目标组",
      "C": "创建一个公共应用程序负载均衡器。指定应用程序目标组",
      "D": "创建第二个目标群体。在EC2实例中添加弹性IP地址。",
      "E": "创建一个Web ACL在AWS WAF中。将Web ACL与端点联系起来"
    },
    "vote_percentage": "100%",
    "tags": [
      "ALB",
      "WAF"
    ],
    "explanation": {
      "analysis": "考点是配置应用程序负载均衡器，安全性和会话保持，以满足Web应用程序的需求。",
      "why_correct": "选项 C：使用公共应用程序负载均衡器（ALB），可以配置粘性会话，满足会话亲和性要求。 选项 E： 使用 AWS WAF (Web ACL) 可以实现对应用程序的保护。",
      "why_wrong": "选项 A，网络负载均衡器不支持会话粘性。选项 B，网关负载均衡器主要用于第三方设备，不适用于该场景。 选项 D,  手动配置弹性IP地址和第二个目标群体，增加了维护复杂性，不是最优解。"
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "Web ACL",
      "端点",
      "应用程序负载均衡器",
      "目标组",
      "网关负载均衡器",
      "弹性IP",
      "AWS WAF"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 656,
    "topic": "",
    "question_cn": "一家公司经营着一个存储历史事件图像的网站。网站用户需要能够根据图片中事件发生的年份搜索和查看图像。平均而言，用户每年只要求一次或两次图像。该公司希望有一个非常可用的解决方案来存储和传递图像给用户。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在Amazon弹性块商店的Amazon EC2 Web服务器上存储图像。使用在Amazon EC2上运行的Web服务器。",
      "B": "将图像存储在Amazon EFS中。使用在Amazon EC2上运行的Web服务器。",
      "C": "在Amazon S3标准存储中存储图像。使用Amazon S3标准通过静态网站直接传递图像。",
      "D": "将图像存储在Amazon S3标准(S3-IA)或S3不经常访问(S3-I)标准中。使用Amazon S3标准通过静态网站直接传送图像。"
    },
    "vote_percentage": "90%",
    "tags": [
      "S3",
      "S3-IA",
      "Static Website Hosting"
    ],
    "explanation": {
      "analysis": "此题考查S3存储类的选择。社区认为，对于不经常访问的数据，使用S3标准-IA或S3-不经常访问存储类更经济高效。官方答案是C，但D更经济。",
      "why_correct": "S3标准-IA（不频繁访问）和S3不经常访问存储类是为不经常访问的数据设计的，它们比S3标准存储成本更低。对于每年只访问一两次的图像，使用这些存储类可以最大限度地降低存储成本。通过S3静态网站托管，可以直接提供这些图像，无需额外的EC2服务器。",
      "why_wrong": "A和B选项涉及EC2服务器，增加了运维复杂性和成本。C选项使用S3标准存储，虽然可用，但对于不经常访问的数据来说，成本相对较高。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "EFS",
      "S3",
      "S3-IA",
      "S3-I"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 657,
    "topic": "",
    "question_cn": "公司在不同业务单位使用的一个组织中有多个AWS账户。该公司在世界各地设有多个办事处。该公司需要更新安全组规则，以允许新的办公室CIDR范围或删除旧的CIDR范围，在整个组织。该公司希望集中管理安全组规则，以最小化更新CIDR范围所需的管理开销。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在组织的管理账户中创建VPC安全组。当需要更新CIDR范围时，更新安全组。",
      "B": "创建一个客户管理前缀列表，其中包含CIDR列表。使用资源访问管理器(RAM)在整个组织共享前缀列表。在整个组织的安全组中使用前缀列表。",
      "C": "创建一个AWS管理的前缀列表。使用AWS安全中心策略强制整个组织的安全组更新。当CIDR范围改变时，使用Lambda函数自动更新前缀列表。",
      "D": "在中央行政账户中创建安全组。为整个组织创建一个防火墙管理器通用安全组策略。在策略中选择先前创建的安全组作为主要组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Groups",
      "Prefix Lists"
    ],
    "explanation": {
      "analysis": "考点是集中管理安全组规则，以支持更新CIDR范围并减少管理开销。",
      "why_correct": "使用客户管理的前缀列表，结合资源访问管理器(RAM)，可以集中管理CIDR范围，并在整个组织共享，当需要更新范围时，只需更新前缀列表即可，所有使用该列表的安全组规则会自动更新。",
      "why_wrong": "选项 A 在管理账户中更新安全组，需要手动修改每个账户的安全组。 选项 C 使用AWS 管理的前缀列表，且 Lambda 和安全中心策略过于复杂。 选项 D 使用防火墙管理器，功能类似，但配置相对复杂。"
    },
    "related_terms": [
      "CIDR",
      "VPC",
      "安全组",
      "RAM",
      "Lambda",
      "AWS",
      "防火墙管理器"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 658,
    "topic": "",
    "question_cn": "一家公司使用一个内部网络附加存储(NAS)系统，提供高性能计算(HPC)工作负载的文件共享。该公司希望将其对延迟敏感的HPC工作负载及其存储迁移到AWS云。公司必须能够提供NFS和SMB多协议访问文件系统。哪个解决方案能以最小的延迟满足这些需求？（选2）",
    "options_cn": {
      "A": "将优化的EC2实例部署到集群放置组中。",
      "B": "将优化的EC2实例部署到分区放置组中。",
      "C": "将EC2实例附加到一个Amazon FSx for Lustre文件系统。",
      "D": "将EC2实例附加到一个Amazon FSx for OpenZFS文件系统。",
      "E": "将EC2实例附加到一个Amazon FSx for NetApp ONTAP文件系统。"
    },
    "vote_percentage": "85%",
    "tags": [
      "FSx",
      "HPC"
    ],
    "explanation": {
      "analysis": "考点是选择合适的文件系统和 EC2 实例部署选项，以满足HPC工作负载的低延迟和多协议访问需求。",
      "why_correct": "选项 A: 将优化的 EC2 实例部署到集群放置组中可以减少实例间的网络延迟。选项 E:  FSx for NetApp ONTAP 支持 NFS 和 SMB 协议，可以满足多协议访问的需求。",
      "why_wrong": "选项 B:  分区放置组主要用于隔离实例，而不是优化延迟。选项 C:  FSx for Lustre虽然提供了高性能，但不直接支持 SMB 协议。 选项 D: FSx for OpenZFS支持 NFS协议，但不支持 SMB。"
    },
    "related_terms": [
      "HPC",
      "NFS",
      "SMB",
      "EC2",
      "FSx for Lustre",
      "FSx for OpenZFS",
      "FSx for NetApp ONTAP",
      "EC2"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 659,
    "topic": "",
    "question_cn": "一家公司正在搬迁其数据中心，并希望在两周内安全地将50 TB数据转移到AWS。现有的数据中心有一个站点到站点的VPN连接到AWS VPC。解决方案架构师应该使用哪一种服务来满足这些需求？",
    "options_cn": {
      "A": "使用AWS数据同步器，带VPC端点。",
      "B": "直接连接。",
      "C": "AWS雪球边缘存储优化。",
      "D": "存储网关。"
    },
    "vote_percentage": "93%",
    "tags": [
      "Snowball Edge",
      "Data Transfer"
    ],
    "explanation": {
      "analysis": "考点是快速、安全地将大量数据迁移到AWS，并考虑现有网络连接和时间限制。",
      "why_correct": "AWS Snowball Edge 针对大批量数据的离线传输而设计，可以快速、安全地将数据转移到AWS，并支持离线和在线数据传输两种模式。",
      "why_wrong": "选项A, 数据同步器主要用于在线数据同步，两周内完成50TB的迁移，速度较慢。 选项 B， Direct Connect用于建立持续的专用网络连接，不适用于一次性数据迁移。 选项 D, 存储网关用于混合云存储，不适用于一次性数据迁移。"
    },
    "related_terms": [
      "AWS",
      "VPN",
      "VPC",
      "AWS 数据同步器",
      "VPC 端点",
      "雪球边缘存储优化",
      "存储网关"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 660,
    "topic": "",
    "question_cn": "一家公司在一个自动缩放组中的Amazon EC2按需实例上拥有一个应用程序。申请高峰时间每天同时发生。应用程序用户在高峰时段开始2-3小时报告应用程序性能缓慢。应用程序通常在高峰时段开始后2小时执行。公司希望确保申请在高峰时段开始时能正常工作。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置应用程序负载均衡器，将流量适当分配到实例。",
      "B": "为自动缩放组配置动态缩放策略，以启动基于内存利用率的新实例。",
      "C": "为自动缩放组配置动态缩放策略，以基于CPU利用率启动新实例。",
      "D": "为自动缩放组配置一个预定的缩放策略，以便在高峰时间前启动新的实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Scheduled Scaling"
    ],
    "explanation": {
      "analysis": "考点是使用自动缩放组配置，以满足应用程序高峰时段的需求。",
      "why_correct": "使用预定的缩放策略，可以在高峰时间开始前启动新的实例，提前准备好资源，避免应用程序在高峰时段性能下降。",
      "why_wrong": "选项 A负载均衡器负责流量分发，无法解决应用程序在高峰时段开始时的性能问题。 选项 B 和 C 基于内存或 CPU 利用率的动态缩放策略，可能在高峰到来时才触发缩放，无法提前准备。 "
    },
    "related_terms": [
      "EC2",
      "自动缩放组",
      "应用程序负载均衡器",
      "CPU",
      "内存",
      "预定的缩放策略"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 661,
    "topic": "",
    "question_cn": "一家公司在AWS RDS上运行连接到Amazon RDS数据库的应用程序。在周末和一年中的高峰期申请表都有比例。该公司希望更有效地扩展数, 据库使其连接到数据库的应用程序。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用与数据库目标组配置的连接池的Amazon DynamoDB。更改应用程序以使用DynamoDB端点。",
      "B": "使用Amazon RDS代理与目标组的数据库。更改应用程序以使用代理端点。",
      "C": "使用在Amazon EC2上运行的自定义代理作为数据库的中介。更改应用程序以使用自定义代理端点。",
      "D": "使用Lambda函数为数据库提供目标组配置的连接池。更改应用程序来使用函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Proxy",
      "Connection Pooling"
    ],
    "explanation": {
      "analysis": "此题考察如何通过连接池提高数据库性能和可伸缩性。正确答案是B，利用RDS代理，减少应用程序和数据库之间的连接开销。",
      "why_correct": "Amazon RDS Proxy 是一个完全托管的数据库代理，可以帮助提高应用程序的可伸缩性、提高数据库应用程序的可用性以及增强安全性。通过连接池，RDS Proxy可以减少与数据库建立新连接的开销。",
      "why_wrong": "A选项提到了DynamoDB，但题目是RDS，不相关。C 选项需要自定义代理，增加了运维复杂性。D选项使用Lambda，不如RDS Proxy直接。"
    },
    "related_terms": [
      "RDS",
      "DynamoDB",
      "RDS代理",
      "EC2",
      "Lambda",
      "DynamoDB端点",
      "代理端点",
      "Lambda函数"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 662,
    "topic": "",
    "question_cn": "一家公司使用AWS成本资源管理器来监控其AWS成本。该公司注意到Amazon EBS存储和快照的成本每月增加。然而该公司不购买额外的EBS存储每月。该公司希望为其当前的存储使用优化每月成本？用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用Amazon CloudWatch日志来监控Amazon EBS的存储利用。使用Amazon EBS弹性卷减少卷的规模。",
      "B": "使用自定义脚本监视空格使用情况。使用Amazon EBS弹性卷减少卷的规模。",
      "C": "删除所有过期和未使用的快照以减少快照成本。",
      "D": "删除所有不必要的快照。使用Amazon 数据生命周期管理器根据公司的快照策略需求创建和管理快照。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS",
      "Data Lifecycle Manager",
      "Snapshots"
    ],
    "explanation": {
      "analysis": "此题考察EBS成本优化，重点在于快照管理。正确答案是D，使用数据生命周期管理器自动管理快照，删除不必要的快照，从而降低存储成本。",
      "why_correct": "Amazon Data Lifecycle Manager 允许您根据定义的策略自动创建、保留和删除 EBS 快照，从而降低存储成本和管理负担。 删除不必要的快照，减少了存储成本。",
      "why_wrong": "A和B 选项涉及减少卷的规模，如果卷已使用，会导致数据丢失。C选项只是手动删除快照，不够自动化。"
    },
    "related_terms": [
      "EBS",
      "快照",
      "CloudWatch",
      "EBS弹性卷",
      "EBS",
      "快照",
      "快照成本",
      "数据生命周期管理器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 663,
    "topic": "",
    "question_cn": "一家公司正在开发一种新的应用程序。应用程序包括一个Amazon ECS集群、一个包含应用程序资产的Amazon S3桶和一个包含应用程序数据集的MySQL RDS数据库的Amazon RDS。数据集包含敏感信息。该公司希望确保只有ECS集群能够访问S3数据和RDS桶中的数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建新的AWS KMS客户托管密钥为MySQL数据库加密桶和S3。确保密钥策略包括加密和解密对ECS任务执行角色的权限。",
      "B": "创建AWS KMS管理的密钥可以为MySQL数据库加密桶和S3。确保桶策略指定作为任务执行角色。",
      "C": "创建一个S3桶策略该策略限制桶访问到任务执行角色。为RDS创建VPC端点。更新RDS安全组，以便只允许访问那些将在其中产生任务的那些子网。",
      "D": "为RDS创建VPC端点。更新RDS安全组，以便只允许访问那些将在其中产生任务的那些子网。为S3创建VPC端点。更新S3桶策略只允许从端点访问。"
    },
    "vote_percentage": "61%",
    "tags": [
      "KMS",
      "IAM",
      "VPC Endpoint",
      "Security Groups",
      "S3 Bucket Policy"
    ],
    "explanation": {
      "analysis": "此题考察如何保护ECS集群、S3桶和RDS数据库之间的访问。正确答案是A，使用KMS加密数据库和S3桶，并配置正确的IAM权限。",
      "why_correct": "使用KMS（密钥管理服务）加密 RDS 数据库和 S3 桶，可以保护敏感数据。通过配置 KMS 密钥策略，限制 ECS 任务执行角色对密钥的使用权限，从而控制对数据的访问。 桶策略也应该限制对任务执行角色的访问。",
      "why_wrong": "B 选项使用 AWS KMS 管理的密钥，不够灵活。C和D选项依赖于 VPC 端点和安全组，虽然提供网络层面的安全，但没有解决数据的加密问题。"
    },
    "related_terms": [
      "ECS",
      "S3",
      "MySQL RDS",
      "RDS",
      "AWS KMS",
      "RDS",
      "VPC",
      "VPC端点",
      "RDS安全组",
      "S3桶策略",
      "S3",
      "VPC端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 664,
    "topic": "",
    "question_cn": "一家公司有一个在公司内部运行的网络应用程序。应用程序在高峰时间经历了延迟问题。延迟问题每月发生两次。在延迟问题开始时，CPU利用率立即增加到正常值的10倍。该公司希望将应用程序迁移到AWS以提高延迟时间。该公司还希望在应用需求增加时自动扩展应用程序。公司将使用弹性豆柄进行应用部署。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置一个有弹性的豆柄环境在无限模式下使用燃烧性能实例。根据请求将环境配置为规模。",
      "B": "配置一个有弹性的豆柄环境来使用优化的计算实例。根据请求将环境配置为规模。",
      "C": "配置一个有弹性的豆柄环境来使用优化的计算实例。将环境配置为按计划进行规模化。",
      "D": "配置一个弹性豆柄环境来使用突发性能实例。配置环境，以预测指标进行扩展。"
    },
    "vote_percentage": "56%",
    "tags": [
      "Elastic Beanstalk",
      "Auto Scaling",
      "Instance Types"
    ],
    "explanation": {
      "analysis": "此题考察Elastic Beanstalk环境配置和自动伸缩。社区认为，使用优化计算实例是更通用的选择，并根据请求进行伸缩。",
      "why_correct": "使用优化的计算实例（如M5，M6之类）可以满足应用程序的计算需求。根据请求扩展环境可以确保应用程序在负载增加时能够自动调整资源，从而提高性能和可用性。 弹性伸缩可以响应突发流量，解决延迟问题。",
      "why_wrong": "A 选项使用突发性能实例，虽然成本可能较低，但性能有限，不适合持续高负载。 C 选项使用计划伸缩，不够灵活。D 选项使用预测指标，不如根据请求伸缩更及时响应。"
    },
    "related_terms": [
      "延迟",
      "弹性豆柄",
      "CPU",
      "弹性豆柄",
      "突发性能实例",
      "优化的计算实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 665,
    "topic": "",
    "question_cn": "一家公司的客户遍布世界各地。该公司希望利用自动化来确保其系统和网络基础设施的安全。公司的安全团队必须能够追踪和审核基础设施的所有增量变化。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS CloudTrail建立基础设施。使用AWS CloudWatch配置跟踪更改。",
      "B": "使用AWS CloudFormation建立基础设施。使用AWS CloudTrail配置跟踪更改。",
      "C": "使用AWS CloudFormation建立基础设施。使用服务目录来跟踪更改。",
      "D": "使用AWS CloudFormation建立基础设施。使用服务目录来跟踪更改。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudFormation",
      "CloudTrail"
    ],
    "explanation": {
      "analysis": "此题考察安全审计和跟踪基础设施变更。正确答案是B，使用CloudFormation管理基础设施，并用CloudTrail审计变更。",
      "why_correct": "使用 CloudFormation 模板定义基础设施，方便版本控制和自动化部署。CloudTrail 记录了账户中所有API调用，包括配置更改，这提供了审计和跟踪基础设施变更的强大能力。",
      "why_wrong": "A 选项无法正确建立基础设施。 C 和 D 选项 使用了 服务目录，这并非为了跟踪基础设施变更，而是为了管理可供用户使用的服务目录。"
    },
    "related_terms": [
      "CloudTrail",
      "CloudWatch",
      "CloudFormation",
      "服务目录",
      "CloudTrail",
      "CloudFormation",
      "服务目录"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 666,
    "topic": "",
    "question_cn": "一家初创公司正在Amazon EC2实例中为其客户托管一个网站。该网站由一个无状态的询问应用程序和一个MySQL数据库组成。该网站只提供少量流量。该公司担心实例的可靠性需要迁移到一个非常可用的架构。公司无法修改应用程序代码。解决方案架构师应该采取哪些组合行动来实现网站的高可用性？ (选二)",
    "options_cn": {
      "A": "在每个可用区域提供互联网网关。",
      "B": "将MySQL数据库迁移到一个用于多AZ数据库实例的Amazon RDS。",
      "C": "将数据库迁移到Amazon DynamoDB并启用DynamoDB自动缩放。",
      "D": "使用AWS数据监视器同步多个EC2实例的数据库数据。",
      "E": "创建一个应用程序负载平衡器将流量分配到跨两个可用性区域分布的EC2实例的自动缩放组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "MySQL",
      "RDS",
      "Load Balancer",
      "High Availability"
    ],
    "explanation": {
      "analysis": "此题考察如何实现EC2实例上的网站高可用性。正确答案是B和E，将数据库迁移到RDS，并使用负载均衡器和多可用区部署EC2实例。",
      "why_correct": "B选项：将数据库迁移到 RDS（多可用区部署）可以提高数据库的可用性和容错能力。E选项：使用应用程序负载均衡器和跨可用区分布的EC2实例可以实现负载均衡和高可用性。 应用程序将流量分散到不同AZ 的多个EC2 实例，从而减少了单点故障的可能性。",
      "why_wrong": "A选项提供了互联网网关，这与高可用性无关。C 选项需要修改应用程序代码，并且不适用于MySQL数据库。 D 选项数据监控器无法提供高可用性，同时同步数据会增加复杂性。"
    },
    "related_terms": [
      "EC2",
      "MySQL",
      "RDS",
      "DynamoDB",
      "DynamoDB自动缩放",
      "EC2",
      "多AZ",
      "应用程序负载平衡器",
      "自动缩放组"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 667,
    "topic": "",
    "question_cn": "在一个多年的迁移项目中一家公司正在将其数据和应用程序转移到AWS。该公司希望能够安全地访问Amazon S3上的数据，从AWS区域和公司的内部位置。数据不得穿过互联网。该公司已在其区域和所在地之间建立了一个Direct Connect连接。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为Amazon S3创建网关端点。使用网关端点安全地访问来自区域和现场地点的数据。",
      "B": "在过境网关中创建一个网关，从该区域和酒店内安全进入Amazon S3。",
      "C": "为Amazon S3创建接口端点。使用接口端点安全地访问来自区域和现场位置的数据。",
      "D": "使用KMS键管理服务键安全地从区域和现场位置访问数据。"
    },
    "vote_percentage": "82%",
    "tags": [
      "S3",
      "Direct Connect",
      "VPC Endpoint"
    ],
    "explanation": {
      "analysis": "此题考查如何通过Direct Connect安全访问S3数据。社区认为，使用接口端点是最佳选择。官方答案是A，但C的安全性更高。",
      "why_correct": "使用接口端点（AWS PrivateLink）通过Direct Connect访问S3，数据流量不会经过公共互联网。接口端点在VPC内创建，提供更安全的访问方式。 接口端点通过私有 IP 地址实现 S3 的私有连接。",
      "why_wrong": "A选项使用网关端点，虽然可以访问S3，但其功能不如接口端点强大。B选项涉及过境网关，增加了复杂性。 D 选项只提供了KMS，并没有解决S3的访问问题。"
    },
    "related_terms": [
      "S3",
      "Direct Connect",
      "Direct Connect",
      "Direct Connect",
      "Amazon S3",
      "网关端点",
      "过境网关",
      "S3",
      "接口端点",
      "KMS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 668,
    "topic": "",
    "question_cn": "一家公司在美国职业安全协会组织中创建了一个新的组织。该组织拥有公司开发团队的多个帐户。开发团队成员使用 IAM 标识（AWS）通过单一登录访问帐户。对于公司的每个应用程序，开发团队必须使用预先定义的应用程序名称来标记创建的资源。解决方案架构师需要设计一个解决方案使开发团队只有在应用程序名称标记具有认可值时才能创建资源。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个具有条件允许策略的 IAM 组，该策略要求为要创建的资源指定应用程序名称标记。",
      "B": "为具有应用程序名称标记的任何资源创建具有拒绝策略的交叉帐户角色。",
      "C": "在资源组中创建一个资源组以验证标签应用于所有帐户中的所有资源。",
      "D": "在拥有允许的应用程序名称列表的组织中创建标记策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "Tagging",
      "SCP"
    ],
    "explanation": {
      "analysis": "此题考察如何通过AWS IAM和组织级别的策略来强制资源标签。正确答案是D，在组织级别创建标记策略来强制执行应用程序名称标记。",
      "why_correct": "在组织级别创建标记策略可以强制要求在创建资源时必须添加应用程序名称标记，并且限制标记的值。这确保了所有资源都按照公司策略进行标记，并且只有被认可的应用程序名称才能被使用，从而实现合规性。",
      "why_wrong": "A 选项涉及IAM组，但组策略仅影响组内的用户，无法强制整个组织。B选项创建了拒绝策略，但是无法限制特定值的标签。C选项资源组是用来组织资源的，而不是用来强制标记的。"
    },
    "related_terms": [
      "IAM",
      "IAM",
      "IAM",
      "IAM",
      "IAM",
      "IAM",
      "IAM"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 669,
    "topic": "",
    "question_cn": "一家公司在Amazon RDS上运行其PostgreSQL数据库。该公司需要一个安全的解决方案来管理主用户密码，每30天轮换一次密码。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用Amazon EventBridge来安排一个自定义的Lambda功能，每30天旋转一次密码。",
      "B": "使用AWS CLI DB-instance命令更改密码。",
      "C": "将Secrets Manager集成到Amazon RDS后，实现密码自动旋转。",
      "D": "将系统管理器参数存储与Amazon RDS集成用于后，实现密码自动旋转。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "Secrets Manager",
      "Password Rotation"
    ],
    "explanation": {
      "analysis": "此题考察RDS密码轮换的最佳实践。正确答案是C，使用Secrets Manager的密码自动轮换功能。",
      "why_correct": "AWS Secrets Manager 提供密码轮换功能，可以自动轮换数据库密码、API密钥等敏感信息。 Secrets Manager与 RDS 集成，可以自动轮换 PostgreSQL 数据库的密码，满足安全需求。 这是最简单和最安全的方法。",
      "why_wrong": "A选项需要手动编写Lambda函数和EventBridge规则，增加了复杂性。B选项是手动更改密码，不能满足自动轮换的需求。D选项虽然也与System Manager相关，但并没有提供密码轮换的自动化功能，不如Secrets Manager方便。"
    },
    "related_terms": [
      "RDS",
      "PostgreSQL",
      "Secrets Manager",
      "EventBridge",
      "Lambda",
      "AWS CLI",
      "Secrets Manager",
      "RDS",
      "系统管理器参数存储",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 670,
    "topic": "",
    "question_cn": "一家公司对使用Amazon DynamoDB表的应用程序进行测试。这些测试每周进行一次，每次4小时。在测试期间该公司知道应用程序每秒钟对表执行多少读写操作。该公司目前不使用DynamoDB任何其他用例。解决方案架构师需要优化表的成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "选择按需模式。适当更新读写容量单元",
      "B": "选择供给模式。适当更新读写容量单元",
      "C": "购买DynamoDB保留一年任期的能力。",
      "D": "购买DynamoDB保留三年任期的能力。"
    },
    "vote_percentage": "75%",
    "tags": [
      "DynamoDB",
      "Provisioned Capacity",
      "On-Demand Capacity",
      "Reserved Capacity"
    ],
    "explanation": {
      "analysis": "此题考察DynamoDB的容量模式和成本优化。社区认为，根据测试期间已知的读写操作，选择供给模式，并适当设置读写容量单元，能更有效地控制成本。官方答案是A，但B能更有效控制成本。",
      "why_correct": "在测试期间，已知每秒钟的读写操作，使用预置容量模式可以精确控制 DynamoDB 的成本。根据测试期间的负载，预先配置适当的读写容量单元，可以避免因过度预置而产生的浪费，并能保证性能。",
      "why_wrong": "A选项：按需模式虽然无需预置容量，但是成本较高，对于已知负载的场景，不如预置模式。C和D选项：保留容量更适合于长期、稳定的负载，对于每周测试4小时的场景，并不适用。"
    },
    "related_terms": [
      "DynamoDB",
      "读写容量单元",
      "按需模式",
      "供给模式",
      "DynamoDB",
      "DynamoDB",
      "DynamoDB保留",
      "读写容量单元"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 671,
    "topic": "",
    "question_cn": "一家公司在Amazon EC2实例上运行其应用程序。该公司定期对其金融服务成本进行财务评估。该公司最近发现了不寻常的支出。该公司需要一个防止异常支出的解决方案。解决方案必须监测成本并在支出异常时通知负责任的利益攸关方。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS预算模板创建一个零支出预算。",
      "B": "在AWS账单和成本管理控制台中创建一个成本异常检测监视器。",
      "C": "为当前运行的工作负载定价详细信息创建定价计算器估计数。",
      "D": "使用Amazon CloudWatch来监控成本和识别不寻常的支出。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Budgets",
      "Cost Anomaly Detection"
    ],
    "explanation": {
      "analysis": "此题考察AWS成本控制。社区认为，使用AWS账单和成本管理控制台中的成本异常检测监视器，可以自动检测异常支出，并通知相关人员。官方答案是C，但B更直接、有效。",
      "why_correct": "AWS 账单和成本管理控制台中的成本异常检测功能，可以监测实际支出，并在支出超过预设阈值或出现异常时发送警报通知，从而帮助用户及时发现并处理异常费用。 成本异常检测能够主动识别并通知异常支出。",
      "why_wrong": "A 选项创建了零支出预算，过于严格，不能灵活地反映实际费用。 C 选项生成定价计算器， 只是对成本的预估，不能监控实际开销，也无法实现自动通知。D 选项使用CloudWatch，虽然可以监控成本，但不能直接检测异常支出。"
    },
    "related_terms": [
      "AWS预算",
      "CloudWatch",
      "预算",
      "CloudWatch"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 672,
    "topic": "",
    "question_cn": "一家营销公司从一个营销活动中收到了亚马逊S3的大量新的点击流数据。该公司需要快速分析亚马逊S3的点击流数据。然后公司需要决定是否在数据管道中进一步处理数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在AWS Glue中配置作业以查询数据。在 Amazon Athena 中创建外部表。",
      "B": "配置一个 AWS Glue 爬虫来爬行数据。配置 Amazon Athena 来查询数据。",
      "C": "在蜂巢超存储库中创建外部表。在 Amazon EMR中配置 Spark 作业来查询数据。",
      "D": "配置一个 AWS Glue 爬虫来爬行数据。配置 Amazon Kinesis Data Analytics使用SQL 查询数据。"
    },
    "vote_percentage": "92%",
    "tags": [
      "Amazon Athena",
      "AWS Glue"
    ],
    "explanation": {
      "analysis": "此题考查如何使用最少的操作开销来分析S3数据。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用Glue爬虫和Athena组合更简单快捷。 Kinesis Data Analytics涉及实时流处理，比Athena更复杂。",
      "why_correct": "选项B使用 AWS Glue 和 Amazon Athena。Glue 爬虫可以自动发现 S3 中的数据模式，并创建表供 Athena 查询。Athena 是一种无服务器查询服务，非常适合快速分析和临时查询。",
      "why_wrong": "选项A和C都需要手动创建外部表，增加了配置复杂性。选项D涉及 Kinesis Data Analytics，虽然可以查询，但复杂度和成本都高于 Athena 和 Glue 的组合。"
    },
    "related_terms": [
      "S3",
      "Glue",
      "Athena",
      "Glue",
      "Athena",
      "EMR",
      "Spark",
      "Kinesis Data Analytics"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 673,
    "topic": "",
    "question_cn": "一家公司在其数据中心运行一个SMB文件服务器。文件服务器存储公司经常访问的大型文件，文件创建日期之后7天。7天后，公司需要能够在最长24小时的检索时间内访问这些文件。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS DataSync来复制从SMB文件服务器到S3的超过7天的数据。",
      "B": "创建一个Amazon S3文件网关以增加公司的存储空间。创建一个S3生命周期策略在7天后将数据转换为Glacier Deep Archive。",
      "C": "创建一个Amazon FSx文件网关以增加公司的存储空间。创建一个Amazon S3生命周期策略以便在7天后转换数据。",
      "D": "为每个用户配置Amazon S3接入。创建S3生命周期策略在7天后将数据转换为Glacier的灵活检索。"
    },
    "vote_percentage": "82%",
    "tags": [
      "S3 Lifecycle",
      "S3 Glacier Deep Archive"
    ],
    "explanation": {
      "analysis": "此题考查SMB文件服务器归档需求，以及S3生命周期策略的应用。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是同时满足了7天存储和24小时内检索的需求，成本也更低。",
      "why_correct": "选项B：使用S3文件网关将文件存储在S3中，满足增加存储空间的需求。设置生命周期策略将7天后的文件移动到Glacier Deep Archive，满足低成本归档需求。 Glacier Deep Archive提供了在12小时内检索数据的能力，满足检索时间要求。",
      "why_wrong": "选项A：DataSync是用于数据迁移的工具，不适用于持续归档。选项C：FSx是文件存储服务，用于增加文件存储空间，但无法自动归档。选项D：直接配置S3访问较为复杂，且Glacier Flexible Retrieval的检索时间为1-5分钟，不满足24小时内的检索需求。"
    },
    "related_terms": [
      "SMB",
      "S3",
      "AWS DataSync",
      "S3",
      "S3",
      "Glacier Deep Archive",
      "FSx",
      "S3",
      "Glacier",
      "S3",
      "S3生命周期策略",
      "S3",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 674,
    "topic": "",
    "question_cn": "一家公司在一个自动缩放组中运行亚马逊EC2实例的网络应用程序。应用程序使用一个在Amazon RDS上运行的数据库用于后端的应用程序实例。当流量增加时，应用程序执行缓慢。数据库在高流量期间经历了大量的读取负载。解决方案架构师应该采取哪些行动来解决这些性能问题？(选二)",
    "options_cn": {
      "A": "打开数据库实例的自动缩放。",
      "B": "为RDS数据库实例创建一个读副本。配置应用程序将读流量发送到读副本。",
      "C": "将RDS数据库实例转换为多AZ实例部署。配置应用程序将读取流量发送到备用数据库实例。",
      "D": "创建一个Amazon ElastiCache集群。将应用程序配置为缓存查询的结果在ElastiCache集群中。",
      "E": "配置自动缩放组子网，以确保EC2实例在与RDS实例相同的可用性区域中提供。"
    },
    "vote_percentage": "86%",
    "tags": [
      "RDS Read Replica",
      "ElastiCache"
    ],
    "explanation": {
      "analysis": "本题考察数据库性能优化方案，主要是针对数据库读负载高的问题。注意: 此题官方答案为AC，但社区共识(投票最高)为BD。社区倾向BD的原因是更直接有效的解决了读负载问题。",
      "why_correct": "选项B：创建RDS读副本可以分担数据库的读负载。配置应用程序将读流量发送到读副本，从而提高性能。选项D：ElastiCache是一种缓存服务，可以缓存数据库查询结果，减少数据库的负载。",
      "why_wrong": "选项A：数据库自动缩放主要针对计算资源，无法解决读负载问题。选项C：多AZ部署提供了高可用性，但不能直接提高读性能。选项E：将EC2实例放置在相同的AZ，可能影响高可用性，且与性能优化关系不大。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "读副本",
      "多AZ",
      "ElastiCache",
      "ElastiCache",
      "自动缩放组",
      "RDS"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 675,
    "topic": "",
    "question_cn": "一个公司使用亚马逊EC2实例和亚马逊弹性块存储 (EBS) 卷运行一个应用程序。公司每天创建每个 EBS卷的快照以满足合规要求。该公司希望实现一种防止意外删除 EBS卷快照的架构。解决方案不得更改存储管理员用户的管理权。用最少的行政努力来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个具有删除快照权限的 IAM角色。将这个角色附加到一个新的EC2实例中。使用来自新EC2实例的AWS CLI删除快照。",
      "B": "创建一个拒绝快照删除的IAM策略。将该策略附加到存储管理员用户上。",
      "C": "将标记添加到EBS快照中。为具有标记的快照在回收站中创建保留规则。",
      "D": "锁定EBS快照以防止删除。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS Snapshot Lock",
      "IAM"
    ],
    "explanation": {
      "analysis": "此题考查 EBS 快照的保护措施，特别是防止误删除。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是直接提供了锁定快照的功能，最简单有效。",
      "why_correct": "选项D: EBS 快照锁定功能可以直接防止快照被删除。这是最直接、最简单的解决方案，不需要更改存储管理员的管理权。",
      "why_wrong": "选项A:  需要创建 IAM 角色和 EC2 实例，增加了复杂性。选项B:  通过策略限制删除操作，但不够直接。选项C：将标记添加到 EBS 快照中，但是并不能直接阻止删除，还需要设置回收站保留规则，相对复杂。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "EBS",
      "IAM",
      "EBS",
      "IAM",
      "EBS",
      "EC2",
      "AWS CLI",
      "EBS",
      "快照",
      "回收站",
      "EBS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 676,
    "topic": "",
    "question_cn": "一个公司的应用程序使用网络负载均衡器、自动缩放组、亚马逊EC2实例和部署在亚马逊VPC中的数据库。该公司希望在其亚马逊VPC中以接近实时的方式捕捉有关网络接口的流量信息。该公司希望将信息发送到亚马逊开放搜索服务进行分析。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在亚马逊CloudWatch日志中创建一个日志组。配置VPC流日志将日志数据发送到日志组。使用亚马逊Kinesis Data Streams将日志组中的日志流到开放搜索服务中。",
      "B": "在亚马逊CloudWatch日志中创建一个日志组。配置VPC流日志将日志数据发送到日志组。使用亚马逊Kinesis Data Firehose将日志流到开放搜索服务中。",
      "C": "在亚马逊CloudTrail中配置流日志。配置VPC流日志将日志数据发送到跟踪。使用亚马逊Kinesis Data Streams来将日志从路径流流到开放搜索服务。",
      "D": "在亚马逊CloudTrail中配置流日志。配置VPC流日志将日志数据发送到跟踪。使用亚马逊Kinesis Data Firehose将日志从路径流到开放搜索服务。"
    },
    "vote_percentage": "92%",
    "tags": [
      "VPC Flow Logs",
      "Kinesis Data Firehose"
    ],
    "explanation": {
      "analysis": "此题考察如何通过 VPC 流日志捕获网络流量，并将其发送到 Amazon OpenSearch Service。 核心是选择正确的数据传输服务。",
      "why_correct": "选项B：VPC流日志需要将数据发送到CloudWatch Logs，然后使用Kinesis Data Firehose将日志发送到 OpenSearch Service。Firehose 能够将数据流直接写入 OpenSearch Service，简化了流程。",
      "why_wrong": "选项A:  使用 Kinesis Data Streams 增加了复杂性，需要额外的处理逻辑。选项C和D:  CloudTrail用于审计日志，不适合 VPC 流日志的收集。 "
    },
    "related_terms": [
      "VPC",
      "VPC",
      "VPC",
      "VPC",
      "网络接口",
      "开放搜索服务",
      "CloudWatch",
      "VPC流日志",
      "Kinesis Data Streams",
      "开放搜索服务",
      "CloudWatch",
      "VPC流日志",
      "Kinesis Data Firehose",
      "开放搜索服务",
      "CloudTrail",
      "VPC流日志",
      "跟踪",
      "Kinesis Data Streams",
      "开放搜索服务",
      "CloudTrail",
      "VPC流日志",
      "跟踪",
      "Kinesis Data Firehose",
      "开放搜索服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 677,
    "topic": "",
    "question_cn": "一家公司正在开发一个应用程序，该应用程序将运行在生产亚马逊弹性 Kubernetes 服务 (EKS) 亚马逊集群中。 EKS 集群已经管理了提供随需应变实例的节点组。 EKS 该公司需要一个专门的 EKS 集群的发展工作。公司将不经常使用开发集群来测试应用程序的弹性。 集群必须管理所有节点。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个只包含现场实例的托管节点组。",
      "B": "创建两个托管节点组。提供一个节点组和随需应变的实例。提供第二节点组的 SPOT实例。",
      "C": "创建一个自动缩放组，它具有使用 SPOT实例的启动配置。将用户数据配置为将节点添加到 EKS 集群。",
      "D": "创建一个只包含按需实例的托管节点组。"
    },
    "vote_percentage": "50%",
    "tags": [
      "EKS",
      "Spot Instances"
    ],
    "explanation": {
      "analysis": "此题考查在 EKS 集群中使用Spot实例进行开发环境的部署。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是使用spot实例能够大幅降低成本，且开发环境对于可用性的要求相对较低。",
      "why_correct": "选项A：创建一个只包含Spot实例的托管节点组，可以最大限度地降低开发集群的成本，同时满足需求。",
      "why_wrong": "选项D：使用按需实例，成本较高，不符合题目的要求。选项B和C：Spot实例和按需实例的组合，无法最大化成本优化。此外，C选项需要手动配置，运维成本高。"
    },
    "related_terms": [
      "EKS",
      "EKS",
      "EKS",
      "EKS",
      "SPOT",
      "EKS",
      "EKS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 678,
    "topic": "",
    "question_cn": "一家公司在亚马逊S3中存储敏感数据。解决方案架构师需要创建加密解决方案。该公司需要完全控制用户创建、旋转和禁用加密密钥的能力，而对任何必须加密的数据要尽最小的努力。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用默认服务器端加密与亚马逊S3托管加密密钥(SSE-S3)存储敏感数据。",
      "B": "使用 AWS Key Management Service (AWS KMS) 创建客户管理密钥。使用新的密钥通过使用 KMS密钥的服务器端加密(SSE-KMS)加密S3对象。",
      "C": "通过使用密钥管理服务创建客户管理的密钥。使用新的密钥通过使用 KMS密钥的服务器端加密(SSE-KMS)加密S3对象。",
      "D": "将S3对象下载到亚马逊EC2实例。使用客户管理的密钥加密对象。上传加密对象回到亚马逊S3。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "本题考察S3加密方式。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是能够完全控制密钥，符合题目的要求。",
      "why_correct": "选项B：使用 KMS 客户管理密钥可以完全控制密钥，满足客户的要求，且使用 SSE-KMS 方式加密，在S3侧进行加密，无需下载到EC2，操作简单。SSE-KMS在S3端完成，数据安全、管理方便。",
      "why_wrong": "选项A：使用SSE-S3，密钥由AWS管理，无法满足客户对密钥的控制需求。选项C：与B类似，但是表述不清晰，容易混淆。选项D：需要下载到EC2，操作繁琐，成本高。"
    },
    "related_terms": [
      "S3",
      "SSE-S3",
      "AWS Key Management Service",
      "AWS KMS",
      "KMS",
      "SSE-KMS",
      "EC2",
      "S3",
      "SSE-KMS",
      "AWS KMS",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 679,
    "topic": "",
    "question_cn": "一家公司想把它的内部虚拟机备份到S3。该公司的备份解决方案将现场备份作为对象输出到亚马逊S3桶中。备份必须保留30天。30天后必须自动删除。哪些步骤组合将满足这些要求？(选三)",
    "options_cn": {
      "A": "创建一个具有 S3 对象锁定功能的S3桶。",
      "B": "创建一个已启用对象版本控制的S3桶。",
      "C": "为对象配置一个30天的默认保留期。",
      "D": "配置一个S3生命周期策略来保护30天的对象。",
      "E": "配置一个S3生命周期策略在30天后使对象失效。",
      "F": "配置备份解决方案在30天的保留期内标记对象。"
    },
    "vote_percentage": "69%",
    "tags": [
      "S3 Object Lock",
      "S3 Lifecycle"
    ],
    "explanation": {
      "analysis": "本题考察S3备份数据的保留和删除策略，要求满足保留30天并自动删除的功能。注意: 此题官方答案为CEF，但社区共识(投票最高)为ACE。社区倾向ACE的原因是更容易实现目标。",
      "why_correct": "选项A：启用S3对象锁定功能可以保护对象，防止被意外删除。选项C：为对象配置30天的默认保留期，保证数据保留。选项E：配置S3生命周期策略在30天后使对象失效，可以实现自动删除。",
      "why_wrong": "选项B：启用对象版本控制，可以管理对象版本，但不能直接实现保留和删除策略。选项D：配置生命周期策略来保护对象，与保留时间要求冲突。选项F：标记对象需要其他逻辑处理，相对复杂。"
    },
    "related_terms": [
      "S3",
      "S3",
      "S3",
      "S3 对象锁定",
      "对象版本控制",
      "S3",
      "S3生命周期策略"
    ],
    "best_answer": [
      "A",
      "C",
      "E"
    ],
    "official_answer": [
      "C",
      "E",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 680,
    "topic": "",
    "question_cn": "解决方案架构师需要将文件从一个亚马逊S3桶复制到一个亚马逊弹性文件系统 (EFS) 文件系统和另一个S3桶。文件必须连续复制。新文件被添加到原来的S3桶一致。只有在源文件更改时才应覆盖复制的文件。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为目标S3桶和EFS文件系统创建一个AWS DataSync数据监视器位置。为目标S3桶和EFS文件系统创建一个DataSync任务。设置传输模式只传输已更改的数据。",
      "B": "创建一个AWS Lambda函数。将文件系统安装到函数上。设置S3事件通知以便在亚马逊S3中创建和更改文件时调用该函数。配置该函数以将文件复制到文件系统和目标S3桶。",
      "C": "为目标S3桶和EFS文件系统创建一个AWS DataSync数据监视器位置。为目标S3桶和EFS文件系统创建一个DataSync任务。设置传输模式来传输所有数据。",
      "D": "在与文件系统相同的VPC中启动一个亚马逊EC2实例。安装文件系统。创建一个脚本以例行同步所有在原桶中更改到目标S3桶和安装的文件系统的对象。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DataSync",
      "EFS"
    ],
    "explanation": {
      "analysis": "本题考查文件从S3到EFS以及S3的持续复制，以及仅复制更改的内容。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是使用DataSync是最简单、最合适的方案。",
      "why_correct": "选项A：AWS DataSync 提供了将数据从 S3 复制到 EFS 和 S3 的功能，并支持仅复制已更改数据。 DataSync 能够持续监控和同步文件，满足了连续复制和仅复制更改文件的需求。",
      "why_wrong": "选项B：使用 Lambda 函数复制文件较为复杂，需要手动编写代码，运维成本高。选项C：DataSync需要传输所有数据，不符合仅复制更改的要求。选项D：EC2 实例方案需要手动编写脚本同步，配置复杂，且不具备持续同步能力。"
    },
    "related_terms": [
      "S3",
      "EFS",
      "S3",
      "AWS DataSync",
      "EFS",
      "DataSync",
      "S3",
      "Lambda",
      "S3",
      "EFS",
      "S3",
      "VPC",
      "EC2",
      "EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 681,
    "topic": "",
    "question_cn": "一家公司使用亚马逊EC2实例并在亚马逊弹性块存储 (EBS) 卷存储数据。公司必须确保所有数据都是通过使用 AWS Key Management Service (AWS KMS)进行加密的。公司必须能够控制加密密钥的轮换。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个客户管理的密钥。使用密钥加密 EBS 卷。",
      "B": "使用AWS KMS托管密钥加密 EBS 卷。使用键配置自动键旋转。",
      "C": "使用导入的密钥材料创建一个外部KMS 键。使用密钥加密 EBS 卷。",
      "D": "使用AWS拥有的密钥加密 EBS 卷。"
    },
    "vote_percentage": "94%",
    "tags": [
      "KMS",
      "EBS Encryption"
    ],
    "explanation": {
      "analysis": "此题考察 EBS 卷的加密方式以及密钥管理。注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是能够完全控制密钥，满足题目的要求。",
      "why_correct": "选项A：创建一个客户管理的KMS密钥，并使用该密钥加密EBS卷。这样可以满足对密钥的完全控制和轮换的需求，并且操作简单。客户管理密钥可以完全控制，满足了对密钥控制的要求。",
      "why_wrong": "选项B：使用托管密钥虽然简化了操作，但无法完全控制密钥。选项C：使用导入密钥的操作较为复杂。选项D：使用 AWS 拥有的密钥无法满足控制密钥的需求。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "AWS Key Management Service (AWS KMS)",
      "EBS 卷",
      "客户管理的密钥",
      "AWS KMS托管密钥",
      "自动键旋转",
      "外部KMS 键",
      "AWS拥有的密钥"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 682,
    "topic": "",
    "question_cn": "一个公司需要一个解决方案来执行亚马逊EC2实例中的数据加密。解决方案必须自动识别不符合要求的资源并强制执行关于结果的 遵守政策。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用IAM策略允许用户只创建加密的亚马逊弹性块存储 (EBS) 卷。使用 AWS Config 和AWS System Manager自动检测和修复未加密的EBS卷。",
      "B": "使用AWS Key Management Service (AWS KMS) 管理对加密的EBS卷的访问。使用 Lambda和亚马逊EventBridge自动检测和补救未加密的EBS卷。",
      "C": "使用亚马逊Macie检测未加密亚马逊弹性块存储 (EBS) 卷。使用System Manager自动化规则自动加密现有和新的 EBS 卷。",
      "D": "使用亚马逊Inspector检测未加密的EBS卷。使用System Manager自动化规则自动加密现有和新的 EBS 卷。"
    },
    "vote_percentage": "94%",
    "tags": [
      "EBS Encryption",
      "AWS Config",
      "AWS Systems Manager"
    ],
    "explanation": {
      "analysis": "本题考查实现 EBS 卷加密并自动合规。注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是结合IAM、Config和Systems Manager更符合最佳实践。",
      "why_correct": "选项A：使用IAM策略限制创建未加密的 EBS 卷。使用 AWS Config 监控 EBS 卷的合规性，并通过 AWS Systems Manager 自动修复未加密的 EBS 卷，能够满足要求。",
      "why_wrong": "选项B：AWS KMS 主要用于密钥管理，与自动检测和修复 EBS 卷的流程关系不大。选项C：Amazon Macie 用于数据安全性和合规性，检测的是数据，而非未加密的 EBS 卷。选项D：Amazon Inspector 用于应用程序安全评估，不适用此场景。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "IAM",
      "EBS 卷",
      "AWS Config",
      "AWS System Manager",
      "AWS Key Management Service (AWS KMS)",
      "Lambda",
      "EventBridge",
      "亚马逊Macie",
      "EBS 卷",
      "System Manager",
      "Inspector",
      "EBS 卷"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 683,
    "topic": "",
    "question_cn": "一家公司正在将其多层次的内部应用程序迁移到AWS。应用程序由一个单节点 MySQL数据库和一个多节点 Web 层组成。在迁移过程中公司必须尽量减少对应用程序的更改。该公司希望在迁移后提高应用程序的弹性。哪些步骤组合将满足这些要求？(选二)",
    "options_cn": {
      "A": "在应用程序负载平衡器后面的自动缩放组中将Web层迁移到亚马逊EC2实例。",
      "B": "在网络负载平衡器后面的自动缩放组中将数据库迁移到亚马逊EC2实例。",
      "C": "将数据库迁移到亚马逊RDS多AZ部署。",
      "D": "将Web层迁移到AWS Lambda函数。",
      "E": "将数据库迁移到亚马逊DynamoDB表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Multi-AZ",
      "EC2 Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考察如何将传统应用迁移到 AWS 并提高弹性。注意: 此题官方答案为CE，但社区共识(投票最高)为AC。社区倾向AC的原因是同时实现了弹性伸缩和高可用性。",
      "why_correct": "选项A：将Web层迁移到EC2实例并使用自动缩放组，可以提高弹性。选项C：将数据库迁移到RDS多AZ部署，可以实现高可用性。",
      "why_wrong": "选项B：网络负载均衡器主要用于分发流量，对弹性提升有限。选项D：Web 层迁移到 Lambda，需要大幅度修改应用程序。选项E：将数据库迁移到DynamoDB，需要修改数据库访问方式，工作量大。"
    },
    "related_terms": [
      "EC2",
      "MySQL",
      "Web层",
      "RDS",
      "EC2实例",
      "Web层",
      "Lambda",
      "DynamoDB",
      "应用程序负载平衡器",
      "自动缩放组",
      "网络负载平衡器",
      "多AZ",
      "RDS",
      "DynamoDB"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 684,
    "topic": "",
    "question_cn": "一家公司希望将其网络应用程序从内部迁移到AWS。该公司位于欧盟中部地区附近。由于法规的限制，该公司无法在欧盟中部地区启动其部分应用程序。该公司希望实现个位数毫秒的延迟。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将应用程序部署在欧盟中部-1区域。将公司的VPC从欧盟中部延伸到亚马逊云区的边缘位置。",
      "B": "通过将公司的VPC从欧盟中部扩展到选定的本地区域，将应用程序部署到本地区域。",
      "C": "将应用程序部署在欧盟中部-1区域。将公司的VPC从欧盟中部延伸到亚马逊云区的区域边缘缓存。",
      "D": "通过将公司的VPC从欧盟中部扩展到选定的波长区，将应用部署在波长区。"
    },
    "vote_percentage": "72%",
    "tags": [
      "AWS Local Zones",
      "VPC"
    ],
    "explanation": {
      "analysis": "本题考察如何在满足合规要求的前提下，降低应用程序的延迟。 本地区域可以帮助减少延迟。因此答案是B。",
      "why_correct": "选项B：将应用程序部署到本地区域，可以将应用程序的计算和存储资源放置在更靠近最终用户的位置，从而缩短延迟。",
      "why_wrong": "选项A：区域边缘缓存主要用于缓存内容，不能降低延迟。选项C：区域边缘缓存主要用于缓存内容，不能降低延迟。选项D：波长区是5G相关的，不适用于这种传统网络应用程序。"
    },
    "related_terms": [
      "VPC",
      "欧盟中部-1区域",
      "VPC",
      "亚马逊云区",
      "本地区域",
      "波长区"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 685,
    "topic": "",
    "question_cn": "一家公司的电子商务网站有不可预测的流量，并使用AWS Lambda功能直接访问一个私有 Amazon RDS for MySQL数据库实例。该公司希望保持可预测的数据库性能并确保 Lambda调用不会因连接过多而使数据库过载。解决方案架构师应该如何满足这些需求？",
    "options_cn": {
      "A": "将RDS VPC指向客户端驱动程序的自定义端点。在 VPC 中部署Lambda函数。",
      "B": "将RDS VPC指向客户端驱动程序的代理端点。在 VPC 中部署Lambda函数。",
      "C": "将RDS VPC指向客户端驱动程序的自定义端点。在 VPC 之外部署Lambda函数。",
      "D": "将RDS VPC指向客户端驱动程序的代理端点。在 VPC 之外部署Lambda函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "RDS Proxy"
    ],
    "explanation": {
      "analysis": "此题考查 Lambda 函数访问 RDS 数据库时的连接管理和性能优化。 RDS 代理可以帮助缓解数据库连接过载的问题，而将其部署在VPC内部是最佳实践。",
      "why_correct": "选项B:  使用 RDS Proxy 代理客户端连接，可以减少数据库连接的压力，从而提高数据库的性能和稳定性。  将 Lambda 函数部署在 VPC 内部，可以访问 RDS 数据库。",
      "why_wrong": "选项A:  自定义端点不具备连接池和连接复用功能，无法解决数据库连接过载的问题。选项C和D:  在 VPC 之外部署 Lambda 函数，需要复杂的网络配置，增加了安全风险和运维成本。"
    },
    "related_terms": [
      "Lambda",
      "RDS",
      "MySQL",
      "VPC"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 686,
    "topic": "",
    "question_cn": "一家公司正在创建一个应用程序。该公司在多个地点存储测试应用程序的数据。该公司需要在 AWS VPC中将公司内部的位置与VPC连接起来。下一年账户和VPC的数量将增加。网络架构必须简化新连接的管理并提供扩展的能力。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在VPC之间创建一个窥视连接。在VPC和内部位置之间创建VPN连接。",
      "B": "启动亚马逊 EC2 实例。在这个实例中包括使用 VPN 连接连接所有VPC和内部位置的软件。",
      "C": "创建一个传送网关。为VPC连接创建附件。为内部连接创建VPN附件。",
      "D": "在内部位置和中心VPC之间创建一个直接连接连接。使用窥视连接将中央VPC连接到其他VPC。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Transit Gateway",
      "VPC Peering"
    ],
    "explanation": {
      "analysis": "此题考查如何设计一个可扩展的混合云网络架构，连接多个 VPC 和内部网络。 注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是传送网关更易于管理和扩展。",
      "why_correct": "选项C：使用传送网关可以简化跨多个VPC和内部网络的连接。传送网关作为中心枢纽，可以简化连接管理，并提高可扩展性。传送网关简化了网络连接的管理和扩展，使其易于添加新的VPC和内部网络。",
      "why_wrong": "选项A：VPC对等连接需要手动管理，扩展性差。VPN连接需要手动配置，管理复杂。选项B：EC2实例方案增加了单点故障的风险，且管理复杂。选项D：Direct Connect方案成本高，且配置复杂。"
    },
    "related_terms": [
      "VPC",
      "VPC",
      "窥视连接",
      "VPN连接",
      "EC2 实例",
      "VPN",
      "传送网关",
      "VPC",
      "VPN",
      "直接连接",
      "窥视连接",
      "VPC"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 687,
    "topic": "",
    "question_cn": "一家使用Amazon S3的公司需要一个解决方案来预测每个月制造流程所需的资源。解决方案必须使用目前存储在Amazon S3桶中的历史值。该公司没有机器学习经验，希望利用托管服务进行培训和预测。哪些步骤组合将满足这些要求？(选择两个)",
    "options_cn": {
      "A": "部署一个Amazon SageMaker模型。为推理创建一个SageMaker端点。",
      "B": "使用Amazon SageMaker训练模型使用桶中的历史数据。",
      "C": "配置一个Lambda函数，它使用Amazon SageMaker端点来创建基于输入的预测。",
      "D": "配置一个Lambda函数，该函数使用Amazon Forecast预测器来创建一个预测。",
      "E": "通过使用桶中的历史数据来训练Amazon Forecast预测器。"
    },
    "vote_percentage": "63%",
    "tags": [
      "Amazon S3",
      "Amazon Forecast"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CD，但社区共识(投票最高)为DE。社区倾向DE的原因是: 题目要求预测，DE使用了Amazon Forecast服务，更符合要求。",
      "why_correct": "选项D和E提供了使用Amazon Forecast进行预测的解决方案，满足了题目的需求。选项D配置Lambda函数，E使用S3桶中的历史数据训练预测器。",
      "why_wrong": "选项A和B使用了SageMaker，但SageMaker主要用于机器学习模型的训练和部署，而不是用于时间序列预测。选项C虽然使用了SageMaker端点，但是缺少了预测所需的Forecast服务。"
    },
    "related_terms": [
      "Amazon S3",
      "Amazon SageMaker",
      "Amazon S3",
      "Lambda",
      "Amazon Forecast"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 688,
    "topic": "",
    "question_cn": "一家公司在美国职业学校的组织中管理多个AWS账户。公司使用AWS IAM 身份识别中心进行单点登录和控制塔配置。公司希望管理所有账户的多个用户权限。用户权限将由多个IAM用户使用，必须在开发人员和管理员团队之间进行分配。每个团队需要不同的权限。该公司希望有一个解决方案包括两个团队都雇佣的新用户。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在身份中心为每个账户创建个人用户。在身份中心创建单独的开发人员和管理员组。将用户分配给适当的组。为每个IAM组创建自定义策略以设置细粒度权限。",
      "B": "在身份中心为每个账户创建个人用户。在身份中心创建单独的开发人员和管理员组。将用户分配给适当的组。根据细粒度权限的需要向每个用户附加AWS IAM管理的策略。",
      "C": "在身份识别中心创建个人用户。在身份中心创建新的开发人员和管理员组。创建新的权限集，其中包括适合每个组的策略。分配新的组到适当的账户。将新的权限集分配给新的组。当雇佣新用户时将他们添加到适当的组中。",
      "D": "在身份识别中心创建个人用户。创建新的权限集，其中包括适合每个用户的策略。将用户分配到适当的账户。从特定账户中向用户授予额外的IAM权限。当雇佣新的用户时将他们添加到身份识别中心并将他们分配到账户中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS IAM Identity Center",
      "IAM Permissions"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是：C选项通过权限集管理用户权限，更适合大规模用户管理和权限控制。B选项使用IAM托管策略不够灵活，难以满足题目需求。",
      "why_correct": "选项C在AWS IAM Identity Center中创建用户、组和权限集，并通过将组分配给账户实现权限管理。这种方式更易于管理，并且可以更好地控制不同团队的权限。",
      "why_wrong": "选项A使用了自定义策略，这需要更多的维护工作。选项B使用了IAM托管策略，这不够灵活，不能满足精细权限的需求。选项D将用户分配到账户，并授予额外的IAM权限，这种方式不易于管理，且容易出错。"
    },
    "related_terms": [
      "AWS",
      "IAM",
      "AWS IAM",
      "IAM",
      "IAM",
      "身份中心",
      "AWS IAM",
      "身份中心",
      "IAM",
      "IAM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 689,
    "topic": "",
    "question_cn": "一家公司希望规范其Amazon EBS卷加密策略。该公司还希望最大限度地降低运行卷加密检查所需的成本和配置努力。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "编写API调用来描述EBS卷并确认卷是加密的。使用Amazon EventBridge来安排一个Lambda函数来运行API调用。",
      "B": "编写API调用来描述EBS卷并确认卷是加密的。运行API调用的是一个Fargate任务。",
      "C": "创建一个需要使用卷上标记的IAM策略。使用成本资源管理器显示没有正确标记的资源。手动加密未标记的资源。",
      "D": "为Amazon EBS创建一个配置规则以评估卷是否加密，如果未加密则标记卷。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS Encryption",
      "AWS Config"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是: D使用了AWS Config，可以自动检测EBS加密状态并标记未加密的卷，更省时省力。",
      "why_correct": "选项D使用AWS Config配置规则，可以自动检测EBS卷是否加密，并对未加密的卷进行标记，满足了题目对规范加密策略和降低成本的需求。",
      "why_wrong": "选项A和B需要编写和维护自定义脚本来检查加密状态，增加了运维成本。选项C需要手动操作，效率较低，而且容易出错。"
    },
    "related_terms": [
      "Amazon EBS",
      "EBS",
      "API",
      "EBS",
      "Amazon EventBridge",
      "Lambda",
      "API",
      "Fargate",
      "IAM",
      "EBS",
      "成本资源管理器",
      "Amazon EBS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 690,
    "topic": "",
    "question_cn": "一家公司定期将500GB大小的文件上传到Amazon S3。在公司上传文件后，该公司使用了一组Amazon EC2实例来对文件格式进行转码。当公司将数据从内部数据中心上传到Amazon S3时，当该公司将数据从Amazon S3下载到EC2实例时，该公司需要扩大吞吐量。哪些解决方案能满足这些要求？(选择两个)",
    "options_cn": {
      "A": "使用S3桶接入点而不是直接访问桶。",
      "B": "将文件上传到多个S3桶中。",
      "C": "使用多部分上传。",
      "D": "获得一个平行物体的多个字节。",
      "E": "上传文件时为每个对象添加一个随机前缀。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon S3",
      "S3 Transfer Acceleration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AC，但社区共识(投票最高)为CD。社区倾向CD的原因是:  CD都能够提升S3的上传/下载性能，提高吞吐量，满足了题目的需求。",
      "why_correct": "选项C使用多部分上传，可以将大文件分成多个部分并行上传，从而提高上传速度。选项D暗示了使用多线程或多进程并行下载，从而提高下载速度。",
      "why_wrong": "选项A和B虽然也能一定程度提高性能，但不如多部分上传和并行下载直接。选项E增加随机前缀是为了避免S3的性能瓶颈，但是并不能直接提高吞吐量。"
    },
    "related_terms": [
      "Amazon S3",
      "EC2",
      "S3",
      "S3",
      "S3",
      "多部分上传",
      "S3",
      "桶接入点"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 691,
    "topic": "",
    "question_cn": "一个Web应用程序解决方案架构师正在为部署在多个可用性区域的EC2应用程序设计共享存储解决方案。网络应用程序运行在Amazon EC2实例中，这些实例在一个自动缩放组中。公司计划频繁修改内容，一旦变更发生，解决方案在返回新内容时必须具有强有力的一致性。哪些解决方案符合这些要求？(选择两个)",
    "options_cn": {
      "A": "使用存储网关卷网关(iSCSI)阻塞存储安装到单个EC2实例。",
      "B": "创建一个Amazon EFS文件系统。在单个EC2实例上安装文件系统。",
      "C": "创建一个共享的Amazon EBS卷。在单个EC2实例上安装卷。",
      "D": "在自动缩放组中使用数据同步来执行主机之间的数据连续同步。",
      "E": "创建一个Amazon S3桶存储内容。将控制标头的元数据设置为无缓存。使用Amazon CloudFront来传递内容。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon EFS",
      "Amazon CloudFront"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AD，但社区共识(投票最高)为BE。社区倾向BE的原因是: BE的方案更容易实现共享存储，且满足了强一致性需求。其中，E使用CloudFront缓存，可以提高性能。",
      "why_correct": "选项B使用Amazon EFS，可以在多个可用性区域的EC2实例之间共享文件系统，满足了共享存储和强一致性的要求。选项E使用S3存储内容，并将CloudFront作为CDN，可以提供高性能的内容分发，同时也支持强一致性需求。",
      "why_wrong": "选项A和C都不能在多个可用区之间提供共享存储，因为iSCSI和EBS卷只能在一个EC2实例上使用。选项D的数据同步方式在跨区域共享数据时可能会出现延迟和一致性问题。"
    },
    "related_terms": [
      "EC2",
      "EFS",
      "EC2",
      "自动缩放组",
      "S3",
      "CloudFront",
      "存储网关",
      "iSCSI",
      "Amazon EFS",
      "EBS",
      "Amazon EFS",
      "CloudFront"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 692,
    "topic": "",
    "question_cn": "一个公司正在使用一个应用负载平衡器在三个区域部署一个应用程序。Amazon Route 53将用于在这些地区之间分配流量。解决方案架构师应该使用哪一种路由配置来提供最高性能的体验？",
    "options_cn": {
      "A": "用延迟策略创建一个记录。",
      "B": "用地理定位策略创建一个记录。",
      "C": "用故障转移策略创建一个记录。",
      "D": "用地理邻近策略创建一个记录。"
    },
    "vote_percentage": "81%",
    "tags": [
      "Route 53",
      "Latency-based routing"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是: 延迟策略可以根据客户端到服务器的延迟情况，将用户流量路由到延迟最低的区域，从而提高性能。",
      "why_correct": "选项A，使用延迟策略，Route 53会根据用户的地理位置，将流量路由到延迟最低的区域，以提供最佳的用户体验。",
      "why_wrong": "选项B, 地理位置策略，根据用户的地理位置将流量路由到不同的区域，但不能保证最低延迟。选项C, 故障转移策略，用于在主资源不可用时，将流量转移到备用资源，不适用于优化性能。选项D, 地理邻近策略，根据用户和资源的地理位置分配流量，但需要额外的配置，不如延迟策略简单直接。"
    },
    "related_terms": [
      "应用程序负载平衡器",
      "Route 53",
      "地理定位"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 693,
    "topic": "",
    "question_cn": "一个NoSQL Web应用程序公司有一个包括嵌入式数据库的应用程序。该应用程序在应用程序负载平衡器后面的Amazon EC2实例上运行。这些EC2实例在Amazon自动缩放组中的单个可用性区域中运行。最近流量的增加要求应用程序具有很高的可用性，并最终使数据库保持一致。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "用网络负载平衡器替换应用程序负载平衡器。维护嵌入的数据库及其在EC2实例上的复制服务。",
      "B": "用网络负载平衡器替换应用程序负载平衡器。通过使用数据库迁移服务将嵌入式NoSQL数据库迁移到Amazon DynamoDB。",
      "C": "将自动缩放组修改为在三个可用性区域中使用EC2实例。维护嵌入的数据库及其在EC2实例上的复制服务。",
      "D": "将自动缩放组修改为在三个可用性区域中使用EC2实例。通过使用数据库迁移服务将嵌入式NoSQL数据库迁移到Amazon DynamoDB。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Application Load Balancer",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是: D同时考虑了高可用性和数据库的扩展性。将EC2实例部署到多个AZ可以提高可用性，DMS将数据库迁移到DynamoDB提供了更好的扩展性。",
      "why_correct": "选项D，通过将EC2实例分布在三个可用性区域中，可以提高应用程序的可用性。 使用数据库迁移服务 (DMS) 将嵌入式数据库迁移到 Amazon DynamoDB，可以实现数据库的扩展性和高可用性，同时减轻管理数据库的负担。",
      "why_wrong": "选项A，虽然使用了NLB和多AZ部署，但是嵌入式数据库无法水平扩展，依然无法满足流量增加的需求。选项B，虽然使用NLB、DMS，但是没有考虑高可用。选项C，多AZ部署虽然提高了可用性，但是嵌入式数据库无法扩展，不能满足流量增加的需求。"
    },
    "related_terms": [
      "应用程序负载平衡器",
      "EC2",
      "DynamoDB",
      "网络负载平衡器",
      "数据库迁移服务",
      "EC2实例",
      "DynamoDB",
      "数据库迁移服务",
      "EC2实例"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 694,
    "topic": "",
    "question_cn": "一家公司正在美国航空公司建立一个购物应用程序。该应用程序提供了一个目录，该目录每月更改一次，并需要根据流量进行扩展。公司希望从应用程序中获得可能的最低延迟。每个用户的购物车上的数据需要高度可用。即使用户是断开连接和重新连接的，也必须提供用户会话数据。解决方案架构师应该如何确保购物车数据在任何时候都得到保存？",
    "options_cn": {
      "A": "配置一个应用程序负载平衡器以启用粘会话特性(会话亲和力)来访问亚马逊极光的目录。",
      "B": "为Amazon ElastiCache 配置Amazon DynamoDB来缓存来自Amazon DynamoDB的目录数据和来自用户会话的购物车数据。",
      "C": "配置Amazon OpenSearch Service以缓存来自Amazon DynamoDB的目录数据和来自用户会话的购物车数据。",
      "D": "配置Amazon EC2实例与Amazon EBS存储目录和购物车。配置自动快照。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon ElastiCache",
      "Session Management"
    ],
    "explanation": {
      "analysis": "购物车数据需要高度可用，并且会话数据需要持久化。B选项使用ElastiCache缓存购物车数据，并使用DynamoDB存储会话数据，满足了可用性、低延迟和数据持久化的需求。",
      "why_correct": "选项B使用Amazon ElastiCache来缓存目录数据和购物车数据。使用Amazon DynamoDB来存储用户会话的购物车数据，满足了低延迟、高可用性和数据持久化的需求。",
      "why_wrong": "选项A使用了粘性会话，但粘性会话只是在单个实例上维护会话数据，无法满足高可用性需求。选项C, OpenSearch更适合搜索和分析，不适合存储用户的购物车会话数据。选项D 使用EBS，但EC2实例可能会宕机，快照并不能保证高可用性。"
    },
    "related_terms": [
      "应用程序负载平衡器",
      "ElastiCache",
      "DynamoDB",
      "OpenSearch Service",
      "EC2",
      "EBS",
      "自动快照",
      "应用程序负载平衡器",
      "ElastiCache",
      "DynamoDB",
      "OpenSearch Service",
      "EC2",
      "EBS",
      "自动快照"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 695,
    "topic": "",
    "question_cn": "一家公司正在开发一个基于微服务的应用程序，该应用程序将部署在Amazon Elastic Kubernetes Service (EKS)上。微服务将相互作用。该公司希望确保应用程序能够被观察到以确定未来的性能问题。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置应用程序来使用Amazon EKS来减少发送到微服务的请求数量。",
      "B": "配置Amazon CloudWatch Container Insights从EKS集群收集度量。配置AWS X-Ray跟踪微服务之间的请求。",
      "C": "配置AWS CloudTrail API调用。构建一个Amazon QuickSight仪表板来观察微服务交互。",
      "D": "使用AWS Trusted Advisor来理解应用程序的性能。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon EKS",
      "AWS X-Ray",
      "CloudWatch Container Insights"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是: 选项B结合了CloudWatch Container Insights和X-Ray，提供了一个全面的微服务监控方案。CloudWatch Container Insights可以收集集群级别的度量，X-Ray可以跟踪微服务间的请求。",
      "why_correct": "选项B 使用 CloudWatch Container Insights 收集EKS集群的度量指标，并使用 X-Ray 跟踪微服务之间的请求，提供了对微服务应用程序的全面监控能力。",
      "why_wrong": "选项A 无法满足监控需求。选项C，CloudTrail用于审计，QuickSight用于数据可视化，但缺乏对微服务内部行为的洞察。选项D，Trusted Advisor主要用于优化成本和安全，不能满足微服务的监控需求。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "EKS",
      "CloudWatch",
      "EKS",
      "X-Ray",
      "CloudTrail",
      "QuickSight",
      "Trusted Advisor",
      "EKS",
      "CloudWatch",
      "EKS",
      "X-Ray",
      "CloudTrail",
      "QuickSight",
      "Trusted Advisor"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 696,
    "topic": "",
    "question_cn": "一家公司需要向客户提供对其数据的安全访问。该公司处理客户数据并将结果存储在Amazon S3桶中。所有数据都必须遵守严格的规定和安全要求。数据必须在休息时加密。每个客户必须能够只访问他们的数据从他们的账户。公司员工不得访问数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为每位客户提供证书管理员证书加密数据客户端。在私有证书策略中，除了客户提供的角色之外，拒绝所有主体访问证书。",
      "B": "为每位客户提供单独的密钥管理服务(KMS)密钥。加密数据服务器端。在S3桶策略中，拒绝解密除客户提供的角色以外的所有主体的数据。",
      "C": "为每位客户提供单独的密钥管理服务(KMS)密钥。加密数据服务器端。在每个密钥策略中，拒绝解密除客户提供的角色以外的所有主体的数据。",
      "D": "为每位客户提供证书管理员证书加密数据客户端。在公共证书策略中，除了客户提供的角色之外，拒绝所有主体访问证书。"
    },
    "vote_percentage": "73%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是: 选项C提供了最佳的安全性，使用KMS对每个客户的数据进行加密，并在密钥策略中限制访问，确保了数据只能被对应的客户访问。",
      "why_correct": "选项C为每个客户使用单独的KMS密钥，在服务器端加密数据，并在密钥策略中拒绝除客户提供的角色以外的所有主体访问密钥。这种做法提供了最高级别的安全性，确保了数据只能被其所属的客户访问，并满足了所有安全要求。",
      "why_wrong": "选项A和D使用了客户端加密，这需要客户管理密钥，增加了复杂性，并且安全性不如服务器端加密。选项B使用了服务器端加密，但桶策略无法精确控制每个客户的访问权限，安全性不如密钥策略。"
    },
    "related_terms": [
      "Amazon S3",
      "KMS",
      "KMS",
      "S3",
      "KMS",
      "KMS",
      "S3"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 697,
    "topic": "",
    "question_cn": "解决方案架构师创建一个VPC，其中包括两个公共子网和两个私有子网。企业安全任务要求解决方案架构师在私有子网中启动所有Amazon EC2实例。然而，当解决方案架构师启动一个EC2实例，该实例在私有子网上运行端口80和443上的Web服务器时，外部互联网流量无法连接到服务器。解决方案架构师应该如何解决这个问题？",
    "options_cn": {
      "A": "将EC2实例附加到私有子网中的自动缩放组。确保网站的DNS记录解析到自动缩放组标识符。",
      "B": "在公共子网中提供一个互联网面向的应用负载平衡器。将EC2实例添加到与网站的DNS记录关联的目标组中。",
      "C": "在一个私人子网中启动一个NAT网关。更新专用子网的路由表以向NAT网关添加默认路由。在NAT网关上附加一个公共弹性IP地址。",
      "D": "确保附加于EC2实例的安全组允许在端口80上的HTTP流量和在端口443上的HTTPS流量。确保网站的DNS记录解析到EC2实例IP的公共地址。"
    },
    "vote_percentage": "83%",
    "tags": [
      "VPC",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是:  B方案使用ALB，可以对外提供服务，且ALB部署在公有子网，满足了题目的要求。",
      "why_correct": "选项B在公共子网中部署一个应用负载平衡器(ALB)，将EC2实例添加到ALB的目标组中，然后配置网站的DNS记录指向ALB。这样，外部流量可以通过ALB访问私有子网中的EC2实例，满足了题目对外部访问的需求。",
      "why_wrong": "选项A没有提供外部访问的方式。选项C创建了NAT网关，可以使私有子网的实例访问互联网，但是无法接受外部的访问。选项D，虽然配置了安全组，但是EC2实例的IP是私有IP，无法直接对外提供服务。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "Web服务器",
      "DNS",
      "EC2",
      "DNS",
      "NAT网关",
      "NAT网关",
      "弹性IP",
      "EC2",
      "HTTP",
      "HTTPS",
      "DNS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 698,
    "topic": "",
    "question_cn": "一家公司正在部署一个新的应用程序到Amazon Elastic Kubernetes Service (EKS)与一个Fargate集群。应用程序需要一个数据持久性的存储解决方案。解决方案必须具有高度的可用性和容错性。解决方案还必须在多个应用程序容器之间共享。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建Amazon EBS卷，在相同的可用性区域工作节点被放置。在EKS集群上的存储器对象中注册卷。使用EBS多连接在容器之间共享数据。",
      "B": "创建一个Amazon EFS文件系统。在EKS集群上的存储器对象中注册文件系统。对所有容器使用相同的文件系统。",
      "C": "创建一个Amazon EBS卷。在EKS集群上的存储器对象中注册该卷。所有容器使用相同的体积。",
      "D": "在放置工作节点的相同可用性区域中创建Amazon EFS文件系统。在EKS集群上的存储器对象中注册文件系统。创建一个Lambda函数来同步文件系统之间的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon EKS",
      "Amazon EFS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是: EFS提供了高度的可用性、容错性，并且可以被多个容器共享，更容易满足题目的要求。",
      "why_correct": "选项B使用了Amazon EFS。EFS是为Kubernetes设计的， 提供了共享存储，满足了高度可用性和容错性需求，并且易于在多个应用程序容器之间共享。",
      "why_wrong": "选项A 使用了EBS卷。 EBS卷不能在多个容器之间共享，多连接方式维护成本较高，而且EBS的可用性不如EFS。选项C也使用了EBS卷，同样无法满足共享需求。选项D虽然使用了EFS，但是用Lambda同步数据增加了不必要的复杂性。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "Fargate",
      "EBS",
      "EKS",
      "EFS",
      "EKS",
      "Lambda",
      "Amazon EFS",
      "EBS",
      "EKS",
      "Lambda",
      "EFS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 699,
    "topic": "",
    "question_cn": "一家公司在其本地数据中心有一个使用码头容器的应用程序。应用程序运行在一个容器主机上，它将持久性数据存储在主机上的卷中。容器实例使用存储的持久性数据。该公司希望将应用程序转移到完全管理的服务，因为该公司不想管理任何服务器或存储基础设施。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon Elastic Kubernetes Service (EKS)和自我管理节点。创建一个Amazon EBS卷附加到Amazon EC2实例。使用EBS卷作为安装在容器中的持久卷。",
      "B": "使用Amazon Elastic Container Service (ECS)与一个Fargate发射类型。创建一个Amazon EFS卷。将EFS卷添加为安装在容器中的持久存储卷。",
      "C": "使用Amazon Elastic Container Service (ECS)与一个Fargate发射类型。创建一个Amazon S3桶。将S3桶映射为安装在容器中的持久存储量。",
      "D": "使用具有Amazon Fargate发射类型的Amazon Elastic Container Service。创建一个Amazon EFS卷。将EFS卷添加为安装在容器中的持久存储卷。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Amazon ECS",
      "Fargate",
      "Amazon EFS"
    ],
    "explanation": {
      "analysis": "B选项使用ECS和Fargate，意味着不需要管理服务器，并且使用EFS作为持久存储卷，符合题目的要求。",
      "why_correct": "选项B使用了Amazon ECS搭配Fargate启动类型，完全托管了容器运行环境。使用Amazon EFS作为持久卷，提供了持久存储，满足了对服务器和存储基础设施零管理的需求。",
      "why_wrong": "选项A使用了EKS和EC2实例，需要维护EC2实例。选项C使用S3作为持久存储，不太适合作为容器的持久存储卷。选项D与B基本一致，但表述稍有不同。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service (EKS)",
      "ECS",
      "Fargate",
      "EBS",
      "EC2",
      "EBS",
      "ECS",
      "Fargate",
      "EFS",
      "ECS",
      "Fargate",
      "Amazon S3",
      "Amazon S3",
      "ECS",
      "Fargate",
      "EFS",
      "ECS",
      "Fargate",
      "EFS",
      "EFS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 700,
    "topic": "",
    "question_cn": "一家游戏公司希望在多个区域推出一个面向互联网的新应用。该应用程序将使用UDP协议进行通信。该公司需要为全球用户提供高可用性和最低延迟。解决方案架构师应该采取哪些行动组合来满足这些需求？(选择两个)",
    "options_cn": {
      "A": "在每个区域的应用程序前面创建内部网络负载平衡器。",
      "B": "在每个区域的应用程序前面创建外部应用程序负载平衡器。",
      "C": "创建一个Amazon Global Accelerator加速器，将流量路由到每个区域的负载平衡器。",
      "D": "配置Amazon Route 53使用地理定位路由策略来分配流量。",
      "E": "配置Amazon CloudFront以处理每个区域的流量和路径请求"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BC，但社区共识(投票最高)为AC。社区倾向AC的原因是: AC结合使用内部NLB和Global Accelerator，更适合UDP流量的优化和全局加速。",
      "why_correct": "选项A 在每个区域的应用程序前面创建内部网络负载平衡器，用于负载均衡。选项C，创建一个Amazon Global Accelerator加速器，Global Accelerator提供全局加速，减少延迟，并将流量路由到每个区域的负载均衡器。",
      "why_wrong": "选项B, ALB主要用于HTTP/HTTPS流量，不能很好地支持UDP流量。选项D, Route 53的地理位置策略，不如Global Accelerator的全局加速效果好。选项E, CloudFront主要用于静态内容分发，不适合UDP流量。"
    },
    "related_terms": [
      "UDP",
      "Amazon Global Accelerator",
      "Route 53",
      "CloudFront",
      "应用程序负载平衡器",
      "Amazon Global Accelerator",
      "Route 53",
      "CloudFront",
      "Amazon Global Accelerator",
      "Route 53",
      "CloudFront"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 701,
    "topic": "",
    "question_cn": "一个城市已经部署了一个在Amazon EC2实例上运行的Web应用程序，并支持一个应用程序负载平衡器(ALB)。应用程序的用户已经报告了零星的性能，这似乎与来自随机IP地址的DDoS攻击有关。城市需要一个需要最小配置更改的解决方案，并为源提供审计线索。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在ALB上启用一个AWS WAF，并配置规则来阻止来自未知来源的流量。",
      "B": "订阅Amazon Inspector。让AWS响应团队将缓解控制整合到服务中。",
      "C": "订阅AWS Shield Advanced。让AWS响应团队将缓解控制整合到服务中。",
      "D": "为应用程序创建一个Amazon CloudFront分布并将ALB设置为起源。启用一个关于分布的AWS WAF，并配置规则来阻止来自未知来源的流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS WAF",
      "AWS Shield Advanced"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是: 选项C提供了最佳的DDoS防护，并提供了审计线索。",
      "why_correct": "选项C，订阅AWS Shield Advanced，并由AWS响应团队进行缓解控制，提供了针对DDoS攻击的最佳防护。同时AWS Shield Advanced提供了审计日志，满足了题目的要求。",
      "why_wrong": "选项A, 仅使用WAF可能不足以应对大规模DDoS攻击。选项B, Amazon Inspector 主要是安全评估服务，不直接提供DDoS防护。选项D, 将ALB作为CloudFront的源，虽然可以缓存静态内容，但是无法提供针对DDoS攻击的防护。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "AWS WAF",
      "DDoS",
      "Amazon CloudFront",
      "AWS WAF"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 702,
    "topic": "",
    "question_cn": "一家公司将最近一次海洋调查中的200TB数据复制到了雪球边缘存储优化设备上。该公司拥有一个高性能计算(HPC)集群，该集群位于美国，用于寻找石油和天然气储量。解决方案架构师必须为集群提供一致的次毫秒延迟和对雪球边缘存储优化设备上数据的高吞吐量访问。该公司正在把这些设备送回去。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "创建一个亚马逊S3桶。将数据导入S3桶。配置一个存储网关文件网关来使用S3桶。从HPC集群实例访问文件网关。",
      "B": "创建一个亚马逊S3桶。将数据导入S3桶。为光泽文件系统配置一个亚马逊FSX并将其与S3桶集成。从HPC集群实例中访问光泽FSX文件系统的。",
      "C": "创建一个亚马逊S3桶和一个亚马逊弹性文件系统(EFS)文件系统。将数据导入S3桶。将S3桶中的数据复制到HPC文件系统中。从HPC集群实例访问EFS文件系统。",
      "D": "为光泽文件系统创建一个亚马逊FSX。直接导入数据到FSX。从HPC集群实例中访问光泽文件系统的。"
    },
    "vote_percentage": "53%",
    "tags": [
      "Snowball Edge",
      "FSx for Lustre"
    ],
    "explanation": {
      "analysis": "此题考察如何通过Snowball Edge以及网络文件系统来优化HPC集群的数据访问。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是FSx for Lustre更适合HPC场景，提供低延迟高性能。",
      "why_correct": "FSx for Lustre是为高性能计算工作负载设计的，可以提供所需的低延迟和高吞吐量。",
      "why_wrong": "A选项使用存储网关，不适合高性能场景。B选项FSx与S3集成，不如直接使用FSx。C选项EFS，性能不如FSx。"
    },
    "related_terms": [
      "Snowball",
      "HPC",
      "S3",
      "FSx",
      "EFS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 703,
    "topic": "",
    "question_cn": "一个公司在一个内部数据中心有NFS服务器需要定期备份少量数据到亚马逊S3。哪一种解决方案符合这些要求而且成本效益最高?",
    "options_cn": {
      "A": "建立AWS Glue从内部服务器到亚马逊S3复制数据。",
      "B": "在内部服务器上设置一个AWS DataSync代理并将数据同步到亚马逊S3。",
      "C": "建立一个SFTP同步使用SFTP传输为同步数据从内部到亚马逊S3。",
      "D": "在内部数据中心和VPC之间建立一个Direct Connect连接并将数据复制到亚马逊S3。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DataSync",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察使用AWS DataSync进行数据备份。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是DataSync是专门为数据同步设计的，最符合题意。",
      "why_correct": "AWS DataSync专门用于在本地存储和AWS S3之间进行数据同步，能提供最高效和成本效益的解决方案。",
      "why_wrong": "A选项Glue用于ETL，不适合简单的数据备份。C选项SFTP，运维复杂。D选项Direct Connect，成本高昂，且不必要。"
    },
    "related_terms": [
      "S3",
      "AWS Glue",
      "AWS DataSync",
      "SFTP",
      "Direct Connect",
      "VPC"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 704,
    "topic": "",
    "question_cn": "一家在线视频游戏公司必须为其游戏服务器保持超低的延迟。游戏服务器运行在亚马逊EC2实例上。该公司需要一个能够每秒处理数百 UDP 万个网络流量请求的解决方案。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "用互联网流量所需的协议和端口配置应用程序负载平衡器。指定EC2实例为目标。",
      "B": "为互联网流量配置网关负载平衡器。指定EC2实例为目标。",
      "C": "用互联网流量所需的协议和端口配置网络负载平衡器。指定EC2实例为目标。",
      "D": "在独立的EC2区域的EC2实例上启动一套相同的游戏服务器。将互联网流量路由到两套EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Network Load Balancer",
      "EC2"
    ],
    "explanation": {
      "analysis": "此题考察在游戏服务器中负载均衡器的选择。注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是网络负载均衡器(NLB)提供最低延迟。",
      "why_correct": "网络负载均衡器（NLB）设计用于处理对性能敏感的应用程序的流量，提供最低延迟。",
      "why_wrong": "A选项应用负载均衡器（ALB）不适合UDP流量。B选项网关负载均衡器延迟高。D选项，多区域部署，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "UDP",
      "网关负载平衡器",
      "NLB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 705,
    "topic": "",
    "question_cn": "一家公司在VPC中运行一个三层应用程序。数据库层使用一个亚马逊RDS实例用于MySQL数据库。该公司计划将RDS MySQL实例的迁移到一个亚马逊极光后行行的集群。该公司需要一个解决方案来复制迁移到新数据库时发生的数据库更改。( ) 哪些步骤组合将满足这些要求 选二。",
    "options_cn": {
      "A": "使用AWS Database Migration Service模式转换来转换数据库对象。",
      "B": "使用AWS Database Migration Service模式转换来为RDS MySQL实例在Aurora MySQL上创建一个极光后行读取副本。",
      "C": "为RDS MySQL实例的配置奥罗拉读取副本。",
      "D": "定义一个数据库迁移服务任务更改数据捕获迁移数据。",
      "E": "当副本延迟为零时促进极光后行集群的读副本。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DMS",
      "Aurora MySQL"
    ],
    "explanation": {
      "analysis": "此题考察使用DMS进行数据库迁移。注意: 此题官方答案为AE，但社区共识(投票最高)为AD。社区倾向AD的原因是AD都与数据迁移有关，而E是Aurora的只读副本策略，与数据库迁移无关。",
      "why_correct": "使用DMS进行模式转换和数据迁移，可以满足数据库迁移的需求。DMS可以迁移数据，并支持CDC，满足需求。 （本题为多选题，正确项为：A、D，需全部选对才得分。）",
      "why_wrong": "B选项创建读取副本, 不是迁移。C选项配置奥罗拉读取副本, 是提高可用性, 而非迁移。E选项主要与Aurora读取副本相关，不能完成迁移任务。"
    },
    "related_terms": [
      "RDS",
      "MySQL",
      "Aurora",
      "AWS Database Migration Service",
      "RDS MySQL",
      "Aurora MySQL",
      "极光后行读取副本"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 706,
    "topic": "",
    "question_cn": "一个公司拥有一个数据库，该数据库运行在亚马逊RDS实例上，部署到多个可用性区域。该公司定期在数据库上运行一个脚本以报告添加到数据库中的新条目。针对数据库运行的脚本对关键应用程序的性能产生负面影响。公司需要以最低的成本改进应用程序性能。用最少的操作开销来满足这些需求的解决方案是什么?",
    "options_cn": {
      "A": "将功能添加到脚本中以识别活动连接最少的实例。将脚本配置为从该实例读取来报告全部新条目。",
      "B": "创建数据库的读副本。将脚本配置为仅查询读取副本以报告全部新条目。",
      "C": "指示开发团队在每天结束时手动导出数据库中的新条目。",
      "D": "使用亚马逊弹性计算机来缓存脚本在数据库中运行的常见查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Read Replica",
      "Performance Optimization"
    ],
    "explanation": {
      "analysis": "此题考察如何通过读副本提高数据库性能。答案B，使用读副本可以分担主数据库的负载。",
      "why_correct": "创建读副本可以分担主数据库的负载，提高性能。脚本查询读副本，不影响主数据库。",
      "why_wrong": "A选项，负载均衡，不能从根本上解决性能问题。C选项，手动导出，运维复杂。D选项使用弹性计算缓存查询，不能解决数据库性能瓶颈。"
    },
    "related_terms": [
      "RDS",
      "读副本",
      "弹性计算"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 707,
    "topic": "",
    "question_cn": "一家公司正在使用一个应用负载平衡器(ALB)向互联网展示它的应用。该公司发现整个应用程序的异常流量访问模式。解决方案架构师需要提高基础设施的可见性以帮助公司更好地理解这些异常。符合这些要求的最有效的业务解决方案是什么?",
    "options_cn": {
      "A": "在亚马逊Athena为美国天文台的云迹日志创建一个桌子。为相关信息创建查询。",
      "B": "允许访问亚马逊S3。在亚马逊Athena创建一个表格然后查询S3日志。",
      "C": "允许访问亚马逊S3。在文本编辑器中打开每个S3文件并搜索每一行中的相关信息。",
      "D": "在专门的亚马逊EC2实例上使用亚马逊EMR直接查询ALB获取流量访问日志信息。"
    },
    "vote_percentage": "100%",
    "tags": [
      "CloudWatch Logs",
      "Athena"
    ],
    "explanation": {
      "analysis": "此题考察如何通过分析访问日志来诊断异常流量。注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是将日志存储在S3中，然后使用Athena查询是最优解。",
      "why_correct": "将ALB的日志存储在S3中，然后使用Athena进行查询分析，是AWS推荐的日志分析方案，可以快速分析和查询日志数据。",
      "why_wrong": "A选项没有指定日志来源。C选项手动查找，效率低。D选项使用EMR，过度设计。"
    },
    "related_terms": [
      "ALB",
      "Athena",
      "CloudTrail",
      "S3",
      "EC2",
      "EMR"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 708,
    "topic": "",
    "question_cn": "一个公司希望在它的VPC环境中使用NAT网关。该公司的亚马逊EC2实例在私有子网必须能够通过NAT网关连接到公共互联网。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "在与EC2实例相同的私有子网中创建公共NAT网关。",
      "B": "在与EC2实例相同的私有子网中创建私有NAT网关。",
      "C": "在与EC2实例相同的VPC中在公共子网络中创建公共NAT网关。",
      "D": "在与EC2实例相同的VPC中在公共子网络中创建私有NAT网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "NAT Gateway",
      "VPC"
    ],
    "explanation": {
      "analysis": "此题考察NAT网关的部署。注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是在公共子网创建公共NAT网关，才能让私有子网的EC2实例访问互联网。",
      "why_correct": "在VPC的公共子网中创建NAT网关，能让私有子网的EC2实例访问互联网。",
      "why_wrong": "A选项，私有子网中无法创建公共NAT网关。B选项，私有NAT网关无意义。D选项，私有NAT网关没有公共IP。"
    },
    "related_terms": [
      "VPC",
      "NAT网关",
      "EC2",
      "私有子网",
      "公共子网络"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 709,
    "topic": "",
    "question_cn": "公司在美国职业安全组织中有一个组织(OU)。该公司经营亚马逊EC2实例在四个账户的根组织单位(OU)。有三个非生产帐户和一个生产帐户。该公司希望禁止用户在非生产帐户中启动一定规模的EC2实例。该公司已经创建了一个服务控制策略(SCP)来拒绝访问使用禁用类型的启动实例。部署SCP的哪些解决方案将满足这些要求 选二。",
    "options_cn": {
      "A": "将SCP连接到组织的根上。",
      "B": "将SCP附加到三个非生产组织的成员帐户上。",
      "C": "将SCP附加到组织管理帐户。",
      "D": "为生产帐户创建一个OU。将SCP连接到OU上。将生产成员帐户移到新的OU。",
      "E": "为所需帐户创建OU。将SCP连接到OU上。将非生产成员的账户移到新的OU。"
    },
    "vote_percentage": "83%",
    "tags": [
      "SCP",
      "Organizations"
    ],
    "explanation": {
      "analysis": "此题考察SCP策略的应用。注意: 此题官方答案为DE，但社区共识(投票最高)为BE。社区倾向BE的原因是将SCP应用于非生产账号上，达到控制资源的目的。",
      "why_correct": "将SCP附加到非生产账户，阻止启动指定大小的EC2实例。 （本题为多选题，正确项为：B、E，需全部选对才得分。）",
      "why_wrong": "A选项将SCP连接到根，会影响所有帐户。C选项将SCP附加到管理账号，不正确。D和E选项，创建OU，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "OU",
      "SCP"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 710,
    "topic": "",
    "question_cn": "公司在亚马逊EC2实例中的一个网站处理存储在亚马逊S3中的分类数据。出于安全考虑，该公司要求在其EC2资源和亚马逊S3之间建立一个私人和安全的连接。哪种解决方案符合这些要求?",
    "options_cn": {
      "A": "为S3设置VPC端点，允许从端点访问S3桶。",
      "B": "设置一个IAM策略授予对S3桶的读写权限。",
      "C": "建立一个NAT网关来访问私有子网之外的资源。",
      "D": "设置一个访问键标识和一个秘密访问键来访问S3桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察如何实现EC2和S3之间的私有连接。答案A，使用VPC端点，能够避免数据通过公网传输。",
      "why_correct": "通过S3 VPC端点访问S3，数据流量停留在Amazon网络中，提供了私有和安全的连接。",
      "why_wrong": "B选项，IAM策略管理访问权限，而非网络连接。C选项，NAT网关用于访问互联网，而非S3。D选项，访问密钥容易泄露。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "VPC",
      "VPC端点",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 711,
    "topic": "",
    "question_cn": "一家电子商务公司在美国航空公司运营其应用程序。该应用程序使用了一个基于多模式的亚马逊极光后的SQL集群作为基础数据库。在最近的一次推广活动中该应用程序经历了重读负载和写负载。当用户试图访问应用程序时会遇到超时问题。解决方案架构师需要使应用程序体系结构更具可伸缩性和高度可用性。哪种解决方案能在最短的停机时间内满足这些要求?",
    "options_cn": {
      "A": "创建一个亚马逊事件桥规则将极光集群作为源。创建一个Lambda函数来记录极光集群的状态变化事件。添加Lambda函数将其作为一个目标。添加失败的额外阅读器节点。",
      "B": "修改极光集群并激活零关闭时间重新启动(ZDH)功能。使用集群上的数据库活动流来跟踪集群状态",
      "C": "为极光集群添加额外的读者实例。为极光集群创建一个亚马逊代理目标群体。",
      "D": "为Redis缓存创建一个亚马逊弹性计算机。通过使用一种书面循环的方法使用数据库迁移服务复制从极光集到Redis的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora",
      "Read Replica"
    ],
    "explanation": {
      "analysis": "此题考察如何通过增加读实例来提高Aurora的性能。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是增加读实例可以分担读负载，并且使用数据库代理可以提高可用性。",
      "why_correct": "添加Aurora读实例可以分担读负载，提高性能。使用数据库代理可以提高可用性，并且故障转移速度更快，以减少停机时间。",
      "why_wrong": "A选项，与负载均衡和扩容无关。B选项，ZDH功能，不能解决读负载问题。D选项，Redis缓存，不能解决数据库负载问题，并且增加了复杂性。"
    },
    "related_terms": [
      "Aurora",
      "SQL",
      "Lambda",
      "Amazon EventBridge",
      "极光集群",
      "ZDH",
      "Database Migration Service",
      "Redis",
      "弹性计算",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 712,
    "topic": "",
    "question_cn": "一家公司正在设计一个基于VPC的网络应用程序。该应用程序将在公司现有的数据中心和公司的VPC之间使用VPN连接。该应用程序使用亚马逊Route 53作为其DNS服务。应用程序必须使用专用DNS记录与VPC的内部服务进行通信。哪个解决方案将以最安全的方式满足这些要求?",
    "options_cn": {
      "A": "创建一个Route 53私有托管区。创建一个路由解析器出站端点。创建解析器规则。将解析器规则与VPC关联。",
      "B": "创建一个Route 53私有托管区。创建一个路由解析器入站端点。创建解析器规则。将解析器规则与VPC关联。",
      "C": "创建一个Route 53私有托管区。将私有托管区与VPC联系起来。",
      "D": "创建一个Route 53公共托管区。为每个服务创建一个记录以允许服务通信。"
    },
    "vote_percentage": "91%",
    "tags": [
      "Route 53 Resolver",
      "Private Hosted Zone"
    ],
    "explanation": {
      "analysis": "此题考察VPC和本地数据中心通过VPN互联时，DNS解析的设置。注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是使用出站解析器可以实现本地DNS向VPC的解析，更加灵活，更贴合题目场景。",
      "why_correct": "创建一个私有托管区，然后创建出站解析器，将私有托管区与解析器关联，最后将解析器规则与VPC关联。这样可以实现从本地数据中心到VPC的DNS解析。",
      "why_wrong": "B选项，入站端点用于VPC内部DNS解析。C选项，只创建私有托管区，没有实现本地DNS解析。D选项，创建公共托管区，不安全。"
    },
    "related_terms": [
      "VPC",
      "VPN",
      "Route 53",
      "DNS",
      "私有托管区",
      "路由解析器",
      "入站端点",
      "出站端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 713,
    "topic": "",
    "question_cn": "一家公司正在美国东部1号地区经营一个图片托管服务。这项服务使多个国家的用户能够上传和查看照片。一些照片长达数月，另一些20MB则不到一周。该应用程序允许上传每个照片最多1MB。该服务使用照片元数据来确定向每个用户显示哪些照片。哪个解决方案提供适当的用户访问最具成本效益?",
    "options_cn": {
      "A": "把照片放在亚马逊发电机里。打开发电机加速器来缓存经常查看的项目。",
      "B": "将照片存放在亚马逊S3智能层存储课程中。将照片元数据及其S3位置存储在发电机中。",
      "C": "将照片存放在亚马逊S3标准存储类。建立一个生命周期策略将超过30天的照片移动到S3标准-不常访问的存储类。使用对象标记来跟踪元数据。",
      "D": "将照片存放在亚马逊S3冰川存储课程中。建立一个生命周期策略将超过30天的照片转移到冰川深度档案存储类。在S3亚马逊开放搜索服务中存储照片元数据及其S3位置。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Intelligent-Tiering",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此题考察S3存储类和DynamoDB的选择。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是S3智能分层存储类可以根据访问频率自动切换存储层，结合DynamoDB来存储元数据，成本更低，更适合。",
      "why_correct": "S3智能分层根据访问模式自动调整存储成本，并结合DynamoDB存储元数据，可以实现成本效益。照片存储在智能分层中，热数据使用标准存储，冷数据转为不经常访问的存储。 DynamoDB 存储元数据，提供快速查询。",
      "why_wrong": "A选项，使用DynamoDB加速器，不合理。C选项，存储类切换，性能不如智能分层。D选项，冰川存储，访问延迟高。"
    },
    "related_terms": [
      "S3",
      "S3智能层存储",
      "S3标准-不常访问的存储类",
      "S3冰川存储",
      "S3",
      "EC2",
      "发电机",
      "亚马逊开放搜索服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 714,
    "topic": "",
    "question_cn": "一个公司在亚马逊EC2实例中运行一个高度可用的Web应用程序，支持一个应用程序负载平衡器。该公司使用亚马逊云表指标。随着对Web应用程序的流量增加，一些EC2实例被许多未完成的请求重载。云观察指标显示处理的请求数量和接收一些EC2实例响应的时间都高于其他EC2实例。该公司不希望将新请求转发给已经重载的EC2实例。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "使用基于请求目标和主动计数云表度量的循环罗宾路由算法。",
      "B": "使用基于请求定位和激活计数云表度量的最小未完成请求算法。",
      "C": "使用基于请求计数和目标响应的循环罗宾路由算法。",
      "D": "使用基于请求计数和目标响应的最不突出请求算法。"
    },
    "vote_percentage": "79%",
    "tags": [
      "ALB",
      "CloudWatch Metrics"
    ],
    "explanation": {
      "analysis": "此题考察ALB负载均衡算法的选择。注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是最小未完成请求算法能够动态检测实例的负载，避免将新请求转发给已过载的实例。",
      "why_correct": "基于最小未完成请求算法，ALB会避免将新请求发送给处理请求数较多的目标，从而确保性能和可用性。",
      "why_wrong": "A和C，循环罗宾算法不能动态感知实例负载。D选项，没有明确的算法名称。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "云表指标"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 715,
    "topic": "",
    "question_cn": "一家公司使用Amazon EC2、AWS Fargate和AWS Lambda来运行多个工作负载在公司的AWS账户中。该公司希望充分利用其Compute Savings Plans。该公司希望在Compute Savings Plans的覆盖率下降时收到通知。哪个解决方案将以最大的运营效率满足这些要求?",
    "options_cn": {
      "A": "通过使用美国世界银行的预算为储蓄计划创建一个每日预算。配置包含覆盖阈值的预算以便向适当的电子邮件接收者发送通知。",
      "B": "创建一个Lambda函数它根据储蓄计划运行覆盖报告。使用亚马逊简单电子邮件服务（SES）将报告发送给适当的电子邮件接收者。",
      "C": "为储蓄计划预算创建一个美国世界卫生组织预算报告。把频率设置为每天",
      "D": "创建一个储蓄计划通知订阅。启用所有通知选项。输入一个电子邮件地址接收通知"
    },
    "vote_percentage": "76%",
    "tags": [
      "Compute Savings Plans",
      "AWS Budgets"
    ],
    "explanation": {
      "analysis": "此题考察如何监控Compute Savings Plans的覆盖率。注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是使用AWS Budgets可以直接配置覆盖率阈值并接收通知，操作效率最高。",
      "why_correct": "使用AWS Budgets设置一个包含覆盖阈值的预算，可以自动发送通知，符合需求，并且操作效率最高。",
      "why_wrong": "B选项，使用Lambda和SES，实现方式复杂，运维成本较高。C选项，没有通知机制。D选项，通知订阅，不够灵活。"
    },
    "related_terms": [
      "EC2",
      "AWS Fargate",
      "AWS Lambda",
      "Compute Savings Plans",
      "美国世界银行",
      "SES"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 716,
    "topic": "",
    "question_cn": "一个公司运行一个实时的数据摄入解决方案的AWS MSK。该解决方案由亚马逊最新版本的阿帕奇卡夫卡管理流组成。该解决方案部署在三个可用区域的私有子网中的VPC中。解决方案架构师需要重新设计在互联网上公开的数据摄取解决方案。传输中的数据也必须加密。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "为VPC中的现有MSK集群配置公共子网。在公共子网络中部署MSK集群。更新MSK集群安全设置以启用相互TLS身份验证。",
      "B": "为VPC创建一个具有公共子网络的新VPC。在公共子网络中部署MSK集群。更新MSK集群安全设置以启用相互TLS身份验证。",
      "C": "部署使用专用子网的应用程序负载平衡器(ALB)。配置一个安全组入站规则允许HTTPS协议的VPC CIDR块中的入站流量。",
      "D": "部署使用专用子网的网络负载平衡器(NLB)。设置一个NLB的监听器用于通过互联网进行通信。"
    },
    "vote_percentage": "100%",
    "tags": [
      "MSK",
      "TLS"
    ],
    "explanation": {
      "analysis": "此题考察MSK的安全访问。注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，为已有的MSK集群配置公网访问，同时启用TLS认证，可以保证安全。",
      "why_correct": "配置公共子网、启用TLS，保证数据安全。使用ALB，暴露MSK的HTTPS endpoint。",
      "why_wrong": "B选项，创建新的VPC, 没必要。D选项，没有启用TLS。配置NLB，没有配置HTTPS。"
    },
    "related_terms": [
      "AWS MSK",
      "Apache Kafka",
      "VPC",
      "ALB",
      "HTTPS",
      "NLB",
      "TLS",
      "相互TLS身份验证"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 717,
    "topic": "",
    "question_cn": "一家公司希望将一个内部遗留应用程序迁移到AWS。该应用程序吸收了来自企业资源规划系统的客户订单文件。然后应用程序将文件上传到SFTP服务器。应用程序使用一个预定的作业每小时检查订单文件。该公司已经有了一个与公司内部网络连接的AWS帐户。上的新应用程序必须支持与现有企业资源规划系统的集成。新的应用程序SFTP必须是安全和有弹性的并且必须使用协议来处理来自企业资源规划系统的订单。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在两个可用性区域中创建一个 AWS Transfer Family 互联网接口服务器。使用亚马逊S3存储器。创建一个Lambda函数来处理订单文件。使用S3事件通知来发送创建的对象事件到Lambda函数。",
      "B": "在一个可用性区域中创建一个 AWS Transfer Family 网络接口服务器。使用亚马逊弹性文件系统存储。创建一个Lambda函数来处理订单文件。使用传输家族管理的工作流调用Lambda函数。",
      "C": "在两个可用性区域中创建一个 AWS Transfer Family 内部服务器。使用亚马逊弹性文件系统存储。创建一个步骤函数状态机来处理订单文件。使用亚马逊事件桥调度器调用状态机来定期检查亚马逊S3的订单文件。",
      "D": "在两个可用性区域中创建一个 AWS Transfer Family 内部服务器。使用亚马逊S3存储器。创建一个Lambda函数来处理订单文件。使用传输家族管理的工作流调用Lambda函数。"
    },
    "vote_percentage": "76%",
    "tags": [
      "AWS Transfer Family",
      "Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，D选项同时满足了安全性(Transfer Family)、S3存储，Lambda处理，以及工作流控制，相较于A选项更符合题意。",
      "why_correct": "D选项使用了 AWS Transfer Family, 该服务专门用于通过 SFTP、FTPS 和 FTP 协议安全地传输文件，满足了题目对SFTP协议的要求。 同时，使用Lambda函数处理文件，结合S3存储和Transfer Family，搭建了完整的解决方案。",
      "why_wrong": "A选项使用互联网接口服务器，可能存在安全风险。B选项使用弹性文件系统，不符合文件传输需求。C选项使用了步骤函数，可能过于复杂，并且没有使用SFTP协议。"
    },
    "related_terms": [
      "Transfer Family",
      "S3",
      "Lambda",
      "EFS",
      "SFTP",
      "事件桥",
      "内部服务器",
      "步骤函数"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 718,
    "topic": "",
    "question_cn": "一家公司的应用程序使用阿帕奇哈多普和阿帕奇火花公司在现场处理数据。现有的基础设施不具有可伸缩性而且管理起来很复杂。解决方案架构师必须设计一个可伸缩的解决方案以降低操作复杂性。解决方案必须保持数据处理在现场。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS VPN网站到现场的VPN来访问内部的分布式文件系统数据和应用程序。使用亚马逊EMR集群来处理数据。",
      "B": "使用Amazon EMR数据监视器连接到酒店内的哈多普分布式文件系统集群。创建一个亚马逊EMR集群来处理数据。",
      "C": "将阿帕奇哈多普应用程序和阿帕奇火花应用程序迁移到亚马逊EMR集群。使用EMR集群来处理数据。",
      "D": "使用Snowball设备将数据迁移到亚马逊S3桶。创建一个亚马逊EMR集群来处理数据。"
    },
    "vote_percentage": "83%",
    "tags": [
      "Amazon EMR",
      "VPN"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，C选项直接使用EMR处理Hadoop和Spark，在AWS上运行应用，同时保持数据处理在本地，简化了管理。",
      "why_correct": "C选项使用EMR，可以有效处理Hadoop和Spark，满足了题目中对可伸缩性和降低复杂性的要求。在EMR上运行Hadoop和Spark，无需维护现场基础设施，简化了运维。",
      "why_wrong": "A选项使用VPN连接本地数据中心，增加了复杂性。B选项使用了数据监视器，可能无法满足可伸缩性的要求。D选项涉及数据迁移，与题目要求的“保持数据处理在现场”相悖。"
    },
    "related_terms": [
      "Apache Hadoop",
      "Apache Spark",
      "AWS VPN",
      "EMR",
      "HDFS",
      "Snowball",
      "S3",
      "VPC"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 719,
    "topic": "",
    "question_cn": "一家公司正在将大量的数据从内部存储转移到AWS。在相同的区域中，Windows、Mac和Linux为基础的亚马逊EC2实例将通过使用SMB和NFS存储协议访问数据。该公司将按常规访问一部分数据。公司将很少访问剩余的数据。公司需要设计一个解决方案来存储数据。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个亚马逊弹性文件系统(EFS)亚马逊EFS卷，使用智能分层。使用数据源代码将数据迁移到EFS卷。",
      "B": "为EC2实例创建一个亚马逊FSx。用使用自动分档策略的根卷来创建一个用于卸载文件系统的FSx。将数据迁移到FSx以获取点击量。",
      "C": "创建一个使用智能层的亚马逊S3桶。通过使用存储网关亚马逊文件网关将数据迁移到S3桶。",
      "D": "创建一个亚马逊FSx for OpenZFS卷。将数据迁移到新卷中。"
    },
    "vote_percentage": "70%",
    "tags": [
      "Amazon FSx",
      "S3 Intelligent-Tiering"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，B选项使用FSx，可以提供高性能的文件共享服务，并且支持自动分层，符合题目需求。",
      "why_correct": "B选项使用Amazon FSx，支持SMB和NFS协议，满足了EC2实例访问文件的需求。 FSx可以提供高性能，并且支持自动分层，将不常用的数据移动到更经济的存储层，降低成本。 这符合题目中对存储和访问的频率的要求。",
      "why_wrong": "A选项使用EFS，可能成本较高。 C选项使用S3存储网关，增加了复杂性，不符合最少操作开销的要求。D选项使用FSx for OpenZFS，可能不支持SMB或NFS。"
    },
    "related_terms": [
      "EC2",
      "SMB",
      "NFS",
      "EFS",
      "智能分层",
      "FSx",
      "FSx for OpenZFS",
      "S3",
      "存储网关",
      "文件网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 720,
    "topic": "",
    "question_cn": "一个制造公司运行其报告生成应用程序的AWS。应用程序在大约20分钟内生成每个报告。该应用程序是作为一个整体构建的，运行在一个亚马逊EC2实例上。应用程序需要经常更新其紧密耦合的模块。随着公司增加新功能该应用程序变得复杂而难以维护。每次公司修补软件模块时应用程序都会经历停机时间。报告生成必须在中断后从一开始就重新启动。该公司希望重新设计应用程序，使其具有灵活性、可伸缩性和逐步改进。该公司希望尽量减少应用程序的停机时间。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将应用程序作为一个具有最大并发供给的单一功能运行在AWS Lambda上。",
      "B": "在亚马逊Spot实例上运行应用程序作为带有车队默认分配策略的微服务。",
      "C": "在亚马逊弹性容器服务上运行应用程序作为服务自动缩放的微服务。",
      "D": "将该应用程序作为一个具有一次性部署策略的单一应用程序环境运行在弹性豆柄上。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon ECS",
      "Microservices"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，C选项使用ECS运行微服务，可以提供更好的弹性和扩展性，满足应用程序的灵活性、可伸缩性和逐步改进的需求。",
      "why_correct": "C选项使用Amazon ECS运行微服务架构，每个模块可以独立部署和更新，减少了停机时间。 ECS提供自动缩放，可以根据负载变化调整资源。 这满足了题目中的所有要求。",
      "why_wrong": "A选项使用Lambda，可能不适合长时间运行的报告生成任务。B选项使用Spot实例，可能存在中断风险。 D选项使用弹性豆柄，无法满足微服务的要求。"
    },
    "related_terms": [
      "EC2",
      "Lambda",
      "Spot",
      "Fargate",
      "弹性容器服务",
      "Elastic Beanstalk"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 721,
    "topic": "",
    "question_cn": "一家公司希望重新设计一个大型Web应用程序用于无服务器的微服务体系结构。该应用程序使用亚马逊EC2实例并且是用pydn编写的。该公司选择了Web应用程序中的一个组件作为微服务进行测试。组件每秒支持数百个请求。该公司希望创建和测试微服务上的一个AWS解决方案支持比达顿。解决方案还必须自动扩大规模并需要最低限度的基础设施和最低限度的业务支持。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用一个对运行最新的亚马逊Linux操作系统的EC2实例进行自动缩放的点车队。",
      "B": "使用具有高可用性配置的AWS弹性豆柄服务器环境。",
      "C": "使用亚马逊弹性库伯内特斯服务。启动自管理EC2实例的自动缩放组。",
      "D": "使用运行自定义开发代码的Lambda函数。"
    },
    "vote_percentage": "80%",
    "tags": [
      "AWS Lambda",
      "Microservices"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，D选项使用Lambda，完全符合无服务器架构，可以自动缩放并减少基础设施的管理。 Lambda 非常适合处理数百个请求的组件。",
      "why_correct": "D选项使用AWS Lambda。Lambda非常适合无服务器微服务。它自动扩展，无需管理服务器。符合题目的所有要求。",
      "why_wrong": "A选项使用EC2实例，需要管理服务器。 B选项使用弹性豆柄，管理较为复杂。 C选项使用EKS, 管理复杂度较高。"
    },
    "related_terms": [
      "EC2",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 722,
    "topic": "",
    "question_cn": "一家公司有从其所在地直接连接到AWS帐户的直接连接。该公司的帐户在同一AWS区域有30个不同的VPC。使用专用虚拟接口。每个VPC都有一个VPC CIDR块，不与公司控制下的其他网络重叠。该公司希望集中管理网络架构，同时允许每个VPC与所有其他VPC和内部网络进行通信。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个传输网关并将直接连接连接与一个新的传输网关作连接。打开传送网关的路径传播功能。",
      "B": "创建一个直接连接网关。重新创建使用新网关的私人VPC。通过创建新的虚拟专用网关将每个VPC关联起来。",
      "C": "创建一个传输VPC连接到传输VPC的直接连接创建该区域所有其他VPC之间的窥视连接。更新路线表。",
      "D": "创建从内部到每个VPC的网站到站点的VPN连接。确保每一个连接都有两个VPN隧道。打开路由传播功能。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Transit Gateway",
      "VPC"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，A选项使用传输网关，能最便捷的连接VPC和Direct Connect，简化了网络管理。",
      "why_correct": "A选项使用AWS Transit Gateway。Transit Gateway 可以连接 VPC 和 Direct Connect，简化了 VPC 之间的连接，并提供了集中的路由控制，降低了操作复杂性，符合题目要求。",
      "why_wrong": "B选项使用Direct Connect网关和VPN网关，增加了复杂性。C选项使用VPC peering，需要管理大量的连接。 D选项使用VPN连接，增加了管理负担。"
    },
    "related_terms": [
      "VPC",
      "Direct Connect",
      "传输网关",
      "VPN",
      "VPN隧道"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 723,
    "topic": "",
    "question_cn": "一家公司有在亚马逊EC2实例上运行的应用程序。EC2实例通过使用具有相关IAM角色的IAM角色连接到亚马逊RDS数据库。该公司希望使用AWS Systems Manager在不干扰运行中的应用程序的情况下补丁EC2实例。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个新的IAM角色。将亚马逊管理的即时通信策略附加到新的IAM角色上。将新的IAM角色附加到EC2实例和现有的IAM角色上。",
      "B": "创建一个IAM用户。将亚马逊管理的实例通信策略附加到IAM用户上。配置系统管理器以使用IAM用户来管理EC2实例。",
      "C": "启用系统管理器中的默认主机配置管理来管理EC2实例。",
      "D": "从现有的IAM角色中删除现有的策略。将亚马逊管理的即时通信策略添加到现有的IAM角色中。"
    },
    "vote_percentage": "60%",
    "tags": [
      "AWS Systems Manager",
      "IAM Roles"
    ],
    "explanation": {
      "analysis": "C选项: 启用Systems Manager中的默认主机配置管理来管理EC2实例。 这利用了Systems Manager的基本功能，不需要额外的IAM配置，最简单直接。",
      "why_correct": "C选项，利用了 Systems Manager 的默认主机配置管理功能，使得在无需过多 IAM 权限设置的情况下，即可通过 SSM 补丁EC2实例。 减少了操作的复杂性。",
      "why_wrong": "A选项需要创建新的 IAM 角色并修改现有 IAM 角色，增加了配置的复杂度。 B选项使用IAM用户而非角色，违背了AWS最佳实践。 D选项修改了现有的 IAM 角色策略，这可能会影响到应用程序。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "IAM",
      "IAM角色",
      "AWS Systems Manager"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 724,
    "topic": "",
    "question_cn": "一家公司通过使用亚马逊弹性库伯内特斯服务(EKS)和库伯内特斯水平吊舱自动卡表运行集装箱应用程序。工作量全天不一致。解决方案架构师注意到当集群中现有节点达到最大容量时节点的数量不会自动扩展这将导致性能问题。用最少的管理费用来解决这个问题的解决方案是什么？",
    "options_cn": {
      "A": "通过跟踪内存使用情况来扩展节点。",
      "B": "使用库伯内特斯集群自动计算器来管理集群中的节点数。",
      "C": "使用Lambda函数自动调整EKS集群的大小。",
      "D": "使用亚马逊EC2自动缩放组来分配工作负载。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Kubernetes Cluster Autoscaler",
      "EKS"
    ],
    "explanation": {
      "analysis": "B选项: 使用 Kubernetes 集群自动计算器来管理集群中的节点数。这是 Kubernetes 内置的解决方案，专门用于根据pod的资源需求自动调整集群规模。",
      "why_correct": "B选项，Kubernetes 集群自动计算器 (Cluster Autoscaler) 专门设计用于根据 Pod 资源请求来自动调整 EKS 集群的节点数量。 减少了管理成本，并确保了集群资源的弹性。 This is a best practice.",
      "why_wrong": "A选项，仅凭内存使用情况来扩展节点可能不够全面，无法正确响应所有负载变化。 C选项，使用 Lambda 函数手动调整集群大小，增加了复杂性。 D选项，使用EC2自动缩放组，不如 Kubernetes 集群自动计算器更智能，且维护成本更高。"
    },
    "related_terms": [
      "EKS",
      "Lambda",
      "EC2",
      "EC2 自动缩放组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 725,
    "topic": "",
    "question_cn": "一家公司每月在亚马逊S3标准存储区保持大约300个结核病。对象的大小一般在50GB左右，经常被全局应用程序的多部分上传所取代。对象的数量和尺寸保持不变，但该公司的S3存储成本每个月都在增加。在这种情况下解决方案架构师应该如何降低成本？",
    "options_cn": {
      "A": "从多部分上传切换到亚马逊S3传输加速度。",
      "B": "启用删除不完整的多部分上传的生命周期策略。",
      "C": "配置S3库存以防止对象归档太快。",
      "D": "配置亚马逊云前以减少存储在亚马逊S3的物体数量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，B选项可以清除未完成的多部分上传，避免了产生不必要的存储成本。",
      "why_correct": "B选项，启用删除不完整的多部分上传的生命周期策略，可以删除因各种原因未完成上传的文件，从而降低存储成本。 这是针对多部分上传的有效成本优化策略。",
      "why_wrong": "A选项，Amazon S3 传输加速可以加速上传，但不会直接降低存储成本。 C选项，S3 库存报告是用来审计对象和元数据的，无法直接降低成本。 D选项，CloudFront 用于加速内容分发，对降低S3的存储成本没有直接作用。"
    },
    "related_terms": [
      "S3",
      "S3 Transfer Acceleration",
      "多部分上传",
      "CloudFront"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 726,
    "topic": "",
    "question_cn": "一家公司已经为移动设备部署了一个多人游戏。游戏需要根据经纬度实时追踪玩家的位置。游戏的数据存储必须支持快速更新和位置检索。该游戏使用亚马逊RDS来存储具有读取副本的PostgreSQL实例的位置数据。在使用高峰期数据库无法维护读写更新所需的性能。游戏的用户群正在迅速增加。解决方案架构师应该如何改进数据层的性能？",
    "options_cn": {
      "A": "对现有的数据库实例进行快照。启用多AZ恢复快照。",
      "B": "从亚马逊RDS迁移到亚马逊开放搜索服务与开放搜索仪表板。",
      "C": "在现有的数据库实例前部署亚马逊发电机加速器(DAX)。修改游戏使用DAX。",
      "D": "在现有的RDS实例前为Redis集群部署一个亚马逊灵活性。修改游戏使用雷迪斯。"
    },
    "vote_percentage": "60%",
    "tags": [
      "Amazon ElastiCache",
      "Redis"
    ],
    "explanation": {
      "analysis": "D选项: 在现有的RDS实例前为Redis集群部署一个亚马逊灵活性。修改游戏使用雷迪斯。 Redis 可以作为缓存层，加速读操作，提高性能。",
      "why_correct": "D选项，使用 Amazon ElastiCache (Redis) 作为缓存，可以缓存常用的位置数据，显著减少RDS的负载，从而提高性能。 Redis 非常适合这种场景。",
      "why_wrong": "A选项，对数据库进行快照无法提高性能。 B选项，迁移到 OpenSearch 不适合读写频繁的位置数据。 C选项，DAX 适用于 DynamoDB，不适用于RDS。"
    },
    "related_terms": [
      "RDS",
      "PostgreSQL",
      "Read Replica",
      "DAX",
      "Amazon ElastiCache for Redis"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 727,
    "topic": "",
    "question_cn": "一家公司将关键数据存储在亚马逊发电机表中的AWS帐户中。一个IT管理员不小心删除了一个发电机表。删除造成了大量的数据损失并扰乱了公司的运营。该公司希望在未来防止这种破坏。用最少的操作开销来满足这个需求的解决方案是什么？",
    "options_cn": {
      "A": "在云路上设计一条小路。为删除操作创建一个亚马逊事件桥规则。创建一个Lambda函数自动恢复删除的发电机表。",
      "B": "为发电机表创建备份和恢复计划。手动恢复发电机表。",
      "C": "配置发电机表上的删除保护。",
      "D": "启用发电机表上的实时恢复。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "Point-in-time Recovery"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，C选项配置删除保护，是最直接有效的解决方案，避免了人为误删除。",
      "why_correct": "C选项，配置 DynamoDB 的删除保护，是最直接有效的解决方案，可以防止表被意外删除。 这解决了题目中“防止这种破坏”的核心需求， 且操作开销最小。",
      "why_wrong": "A选项，设计云路径和 Lambda 函数恢复表，过于复杂。 B选项，需要手动恢复，增加了操作开销。 D选项，实时恢复是在表被删除后才能使用，无法防止删除。"
    },
    "related_terms": [
      "DynamoDB",
      "CloudTrail",
      "Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 728,
    "topic": "",
    "question_cn": "一家公司有一个内部数据中心，存储能力已经耗尽。该公司希望将其存储基础设施迁移到AWS，同时将带宽成本降至最低。解决方案必须能够立即检索数据而不需要增加费用。如何满足这些要求？",
    "options_cn": {
      "A": "部署亚马逊S3冰川拱顶并能够快速检索。启用为工作负载提供的检索能力。",
      "B": "使用缓存的卷部署存储网关。使用存储网关在亚马逊S3存储数据，同时保留本地经常访问的数据子集的副本。",
      "C": "部署使用存储的卷存储数据的存储网关。使用存储网关异步备份数据到亚马逊S3的点时快照。",
      "D": "部署Direct Connect直接连接到内部数据中心。将存储网关配置为本地存储数据。使用存储网关异步备份数据到亚马逊S3的点时快照。"
    },
    "vote_percentage": "56%",
    "tags": [
      "AWS Storage Gateway",
      "S3"
    ],
    "explanation": {
      "analysis": "B选项: 使用缓存的卷部署存储网关。使用存储网关在亚马逊S3存储数据，同时保留本地经常访问的数据子集的副本。 缓存卷可以实现本地缓存，满足了立即检索数据的需求，并且将数据存储在S3上，满足了迁移到AWS的需求。",
      "why_correct": "B选项，使用存储网关中的缓存卷，可以实现在本地保留数据的副本，确保快速检索。同时，存储网关会将数据异步备份到 S3，满足了迁移到 AWS 的需求。  这是最符合题意的方案。",
      "why_wrong": "A选项，使用 Glacier Vault 存储，检索需要时间，不符合快速检索的需求。 C选项，只做备份，无法立即检索数据。 D选项，增加了Direct Connect，增加了复杂性和成本。"
    },
    "related_terms": [
      "S3",
      "存储网关",
      "Direct Connect",
      "S3 Glacier"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 729,
    "topic": "",
    "question_cn": "一家公司在VPC中跨多个可用性区运行一个三层Web应用程序。亚马逊EC2实例在应用程序层的自动缩放组中运行。该公司需要制定一个自动化的扩展计划，分析每个资源每日和每周的历史工作量趋势。配置必须根据预测和实际使用的变化适当地扩展资源。解决方案架构师应该推荐哪种扩展策略来满足这些需求？",
    "options_cn": {
      "A": "基于EC2实例中的平均CPU利用率实现基于步骤的动态缩放。",
      "B": "使预测扩展到预测和规模。配置带有目标跟踪的动态缩放。",
      "C": "根据Web应用程序的流量模式创建一个自动排定的扩展动作。",
      "D": "建立一个简单的扩展策略。根据EC2实例启动时间增加冷却时间。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Application Auto Scaling",
      "Target Tracking Scaling"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，B选项结合了预测和目标跟踪缩放，可以更好地应对负载变化。",
      "why_correct": "B选项，使用目标跟踪与预测扩展相结合，可以基于历史流量预测，并根据实际情况进行调整，以满足根据预测和实际使用的变化适当地扩展资源的需求。目标跟踪策略可以自动调整容量，而预测扩展可以提前预热资源。",
      "why_wrong": "A选项，仅基于CPU利用率，可能无法完全满足负载的变化。 C选项，自动排定扩展策略，可能不够灵活，无法根据实际负载变化。 D选项，只增加了冷却时间，无法实现动态扩展。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "自动缩放组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 730,
    "topic": "",
    "question_cn": "一个包传递公司有一个应用程序使用亚马逊EC2实例和一个亚马逊奥罗拉MySQL数据库集群。随着应用程序变得越来越流行，EC2实例的使用率仅略有增加。数据库集群的使用增长速度快得多。该公司添加了一个读副本在短时间内减少了RDS集群的使用。然而负荷继续增加。导致数据库集群使用量增加的操作都是与交付细节相关的重复读语句。公司需要减轻重复读取对数据库集群的影响。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在应用程序和数据库集群之间实现雷迪斯集群的亚马逊弹性。",
      "B": "向数据库集群添加一个额外的读副本。",
      "C": "配置极光自动缩放为极光读取副本。",
      "D": "将数据库集群修改为具有多个编写实例。"
    },
    "vote_percentage": "86%",
    "tags": [
      "Amazon ElastiCache",
      "Redis"
    ],
    "explanation": {
      "analysis": "A选项: 在应用程序和数据库集群之间实现雷迪斯集群的亚马逊弹性。  Redis是一个缓存，可以存储重复读取的数据，减少数据库的负载。",
      "why_correct": "A选项，在应用程序和数据库集群之间部署 ElastiCache (Redis) 作为缓存。  Redis 可以缓存重复读取的数据，显著减少数据库的负载，从而提高性能，特别适用于读取密集型工作负载。 This is a best practice.",
      "why_wrong": "B选项，添加额外的只读副本，可以提高读取性能，但对于减轻重复读取问题效果有限。 C选项，极光自动缩放读副本，可以根据负载自动扩展读副本，但没有解决重复读取的问题。 D选项，修改为多主实例，增加了复杂性，且不一定能解决重复读取问题。"
    },
    "related_terms": [
      "EC2",
      "Aurora MySQL",
      "RDS",
      "Read Replica",
      "Amazon ElastiCache for Redis",
      "Aurora 自动缩放"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 731,
    "topic": "",
    "question_cn": "一个公司有一个使用亚马逊发电机表存储的应用程序。解决方案架构师发现对表的许多请求没有返回最新数据。该公司的用户没有报告数据库性能的任何其他问题。延迟在一个可接受的范围内。解决方案架构师应该推荐哪些设计更改？",
    "options_cn": {
      "A": "在表中添加读副本。",
      "B": "使用全局二级索引(GSI)。",
      "C": "请求表的读内容完全一致。",
      "D": "请求最终一致的读表。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "Consistency"
    ],
    "explanation": {
      "analysis": "C选项: 请求表的读内容完全一致。 如果请求没有返回最新数据，说明数据一致性出现了问题，使用完全一致读可以解决这个问题。",
      "why_correct": "C选项，请求 DynamoDB 的完全一致性读取，可以确保读取操作返回的数据是最新的。 这解决了“对表的许多请求没有返回最新数据”的问题。 完全一致性读取会带来更高的延迟，但在确保数据一致性方面是必要的。",
      "why_wrong": "A选项，添加读副本可以提高读取性能，但不能保证数据一致性。 B选项，使用 GSI 可以加速查询，但不能解决数据一致性问题。 D选项，最终一致性读取，不能保证获取最新的数据，无法解决问题。"
    },
    "related_terms": [
      "DynamoDB",
      "Read Replica",
      "GSI"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 732,
    "topic": "",
    "question_cn": "一家公司已经在亚马逊 EC2实例中使用了亚马逊 RDS 数据库。该公司使用了最小权限原则配置数据库访问凭证。该公司的安全团队希望保护该应用程序和数据库免遭SQL注入和其他网络攻击。? 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "使用安全组和网络 ACL 来保护数据库和应用服务器。",
      "B": "使用AWS WAF保护应用程序。使用参数组配置安全设置。",
      "C": "使用AWS网络防火墙保护应用程序和数据库。",
      "D": "在应用程序代码中为不同的功能使用不同的数据库帐户，避免授予数据库用户过多的权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS WAF",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是使用AWS WAF可以有效保护应用程序免受SQL注入攻击，而使用参数组可以配置数据库的安全设置，是最直接且开销最小的方案。",
      "why_correct": "AWS WAF是专门针对Web应用程序的防火墙，可以防御常见的Web攻击，如SQL注入。 使用参数组配置数据库安全设置可以增强安全性，并且操作简单。",
      "why_wrong": "选项A，使用安全组和网络ACL只能提供基本的网络层保护，对于SQL注入等应用层攻击防御能力有限。选项C，AWS网络防火墙功能比AWS WAF更复杂，开销也更大。 选项D, 在代码中管理数据库用户权限是一种最佳实践，但不能直接解决SQL注入问题，且操作复杂，开销较大。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "安全组",
      "WAF",
      "AWS 网络防火墙"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 733,
    "topic": "",
    "question_cn": "一家电子商务公司在美国职业教育协会的帐户中运行应用程序。这些帐户是美国职业教育协会组织的一部分。这些应用程序运行在亚马逊 Aurora 数据库后。该公司需要防止恶意活动并必须识别异常失败和不完整的登录尝试数据库。? 哪个解决方案将以最有效的方式满足这些要求",
    "options_cn": {
      "A": "将服务控制策略附加到组织的根以标识失败的登录尝试。",
      "B": "在亚马逊 RDS 中启用亚马逊保护功能，为组织的成员帐户保护税。",
      "C": "将极光常规日志发布到亚马逊 CloudWatch 日志中的一个日志组。将日志数据导出到亚马逊 S3 桶。",
      "D": "将所有在 CloudTrail 中的极光数据库事件发布到一个中央亚马逊 S3 桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon RDS",
      "CloudTrail"
    ],
    "explanation": {
      "analysis": "RDS 监控功能可以帮助检测数据库的异常行为，而 CloudTrail 可以捕获数据库相关的事件，从而满足了检测恶意活动和识别异常登录尝试的需求。 选项B 正确的理由是它结合了 RDS 数据库监控能力和 CloudTrail 事件审计。",
      "why_correct": "RDS 提供的监控功能可以检测异常行为。 CloudTrail 可以审计数据库相关事件，帮助识别失败和不完整的登录尝试。",
      "why_wrong": "选项A，服务控制策略 (SCPs) 主要用于控制组织中账户可以执行的操作，并不能直接检测数据库的异常行为。选项C, 将Aurora日志导出到CloudWatch和S3可以用于日志分析，但没有主动的监控和告警机制，不能快速响应安全问题。 选项D，将数据库事件发布到 CloudTrail 并不能直接帮助识别数据库异常。"
    },
    "related_terms": [
      "Aurora",
      "RDS",
      "CloudWatch",
      "CloudTrail",
      "S3"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 734,
    "topic": "",
    "question_cn": "一家公司有一个从公司数据中心直接连接到它在美东 1 地区的 VPC 的直接连接。该公司最近收购了一家公司，该公司拥有几家 VPC, - 2 VPC CIDR 并在其内部数据中心和欧盟 西方 1 地区之间建立了直接连接。公司和公司的 VPC 的块并不重叠。该公司需要两个地区和数据中心之间的连接。公司需要一个可伸缩的解决方案同时减少运营开销。? 解决方案架构师应该如何满足这些需求",
    "options_cn": {
      "A": "建立区域间 VPC 对等连接，在美国东 1 号的 VPC 和欧盟 西方 1 号的 VPC 之间。",
      "B": "创建从美国东 1 号直接连接连接到欧盟西 1 号 的专用虚拟接口。",
      "C": "使用 EC2 VPN 电器，在由亚马逊托管的完全网状的 AWS VPN 网络中建立VPN。在数据中心和每个 VPC 之间使用云枢纽来发送和接收数据。",
      "D": "将现有的直接连接连接到直接连接网关，从每个区域的虚拟专用网关到直接连接网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Direct Connect",
      "Direct Connect Gateway"
    ],
    "explanation": {
      "analysis": "直接连接网关 (Direct Connect Gateway) 允许将多个 VPC 和 Direct Connect 连接关联起来，从而实现跨区域和跨网络的连接。 该方案提供了可伸缩性，并减少了运营开销。",
      "why_correct": "Direct Connect Gateway 提供了集中管理和路由的功能，简化了网络管理并提高了可扩展性。 它允许通过单个连接实现多个 VPC 和数据中心的互连。",
      "why_wrong": "选项A，VPC对等连接仅限于同一区域，不能跨区域连接。选项B，创建新的专用虚拟接口需要额外的配置和资源，增加了复杂性。选项C，VPN 电器和云枢纽的解决方案增加了运营复杂性，并且可能导致更高的延迟和成本。"
    },
    "related_terms": [
      "VPC",
      "Direct Connect",
      "EC2",
      "VPN",
      "Direct Connect Gateway",
      "VPC 对等连接"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 735,
    "topic": "",
    "question_cn": "一家公司正在开发一款移动游戏。该游戏可以向后端处理器发送升级成绩单，然后将结果发布在领先板上。解决方案架构师需要设计一个解决方案，可以处理大流量高峰，按接收顺序处理移动游戏更新，并将经过处理的更新存储在高可用性数据库中。公司还希望尽量减少维护解决方案所需的管理开销。? 解决方案架构师应该做什么来满足这些需求",
    "options_cn": {
      "A": "将得分更新推到亚马逊 Kinesis 数据流。处理更新的 Lambda。存储处理更新在亚马逊 DynamoDB。",
      "B": "将得分更新推到亚马逊 Kinesis 数据流。用为自动缩放而设置的亚马逊 EC2 实例来处理更新。在亚马逊 Redshift 存储经过处理的更新。",
      "C": "将得分更新推到亚马逊简单通知服务 亚马逊 SNS 主题。将 Lambda函数订阅到 SNS 主题来处理更新。在运行在亚马逊 EC2 实例上 SQL 的 数据库中存储经过处理的更新。",
      "D": "将计分更新推到亚马逊简单队列服务亚马逊 SQS 队列。使用一个具有自动缩放功能的亚马逊 EC2 实例库来处理 SQS 队列中 RDS 多 AZ 的更新。将经过处理的更新存储在亚马逊 多 数据库实例中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Kinesis Data Streams",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，Kinesis Data Streams 适合处理流数据，Lambda 可以处理数据流，DynamoDB 提供了高可用性和可扩展性，非常适合存储游戏数据，且维护成本低。",
      "why_correct": "Kinesis Data Streams 用于实时数据处理，Lambda 提供了无服务器计算能力，DynamoDB 提供了高可用性和自动缩放功能，适用于高流量场景，且 DynamoDB 维护成本低。",
      "why_wrong": "选项B，Redshift 是数据仓库，不适合实时数据处理。选项C，SNS用于发布订阅，不能保证数据处理顺序。选项D，SQS 用于异步消息传递，但是需要通过EC2实例来处理，维护成本相对较高。"
    },
    "related_terms": [
      "Lambda",
      "Kinesis Data Streams",
      "DynamoDB",
      "Redshift",
      "SNS",
      "SQS",
      "EC2",
      "RDS",
      "多AZ"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 736,
    "topic": "",
    "question_cn": "一个公司拥有多个 AWS 账户，其应用程序部署在美国西部 2 地区。应用程序日志存储在每个帐户的亚马逊 S3 桶中。该公司希望建立一个集中的日志分析解决方案，使用单一的 S3 桶。日志不得离开美国西部 2 区域。公司公司希望产生最小的运营开销。? 哪一种解决方案符合这些要求而且成本效益最高",
    "options_cn": {
      "A": "创建一个 S3 生命周期策略，将对象从一个应用程序 S3 桶复制到中央 S3 桶。",
      "B": "使用 S3 相同区域复制，将日志从 S3 桶复制到 us-west-2 中的另一个 S3 桶。使用这个 S3 桶进行日志分析。",
      "C": "编写一个脚本，每天都要使用 putob API 操作来将桶中的全部内容复制到美国西部的另一个 S3 桶中。使用这个 S3 桶进行日志分析。",
      "D": "在这些帐户中写入 Lambda 函数，每次将日志发送到 S3 桶时，这些帐户都会触发创建对象事件。把日志复制到美国西部 2 的另一个 S3 桶。使用这个 S3 桶进行日志分析。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Replication",
      "S3 Lifecycle Rules"
    ],
    "explanation": {
      "analysis": "使用 S3 相同区域复制是最简单、成本最低、并且满足要求的解决方案。它允许将日志实时复制到另一个桶中，方便集中分析。 选项B 正确，因为它满足了所有要求。",
      "why_correct": "S3 相同区域复制是一种简单、可靠且成本有效的解决方案，用于将日志从一个桶复制到另一个桶，满足了数据不出区域的要求，并减少了运维开销。",
      "why_wrong": "选项A，S3 生命周期策略只能在对象创建后进行复制，无法实现近实时复制。选项C，编写脚本并使用 putob API 复制桶中的内容，增加了复杂性，且效率较低。选项D，虽然Lambda 可以触发复制，但是配置相对复杂，且增加了额外的成本。"
    },
    "related_terms": [
      "S3",
      "S3 桶",
      "S3 生命周期策略",
      "S3 相同区域复制",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 737,
    "topic": "",
    "question_cn": "一家公司有一个应用程序，可以向世界各地的学生提供点播培训视频。该应用程序还允许授权内容开发人员上传视频。这些数据存储在位于美国东南地区的亚马逊 S3 桶中。该公司已经在欧盟 西方 1 地区创建了一个 S3 桶，在美国 东南 1 地区创建了一个 S3 桶。该公司希望将数据复制到新的 S3 桶中。该公司需要最大限度地减少上传视频的开发人员的延迟时间以及在欧盟 西方 1 和 东南 1 附近播放视频的学生的延迟时间。? 哪些步骤组合将满足这些要求最少更改应用程序 (选二)。",
    "options_cn": {
      "A": "配置从美国 1 东 S3 桶到欧盟 西方 S3 桶的单向复制。将单向复制从美国 1 东 S3 桶配置到东南 S3 桶。",
      "B": "配置从美国 1 东 S3 桶到欧盟 西方 S3 桶的单向复制。从欧盟 西方 S3 桶到东南 S3 桶配置单向复制。",
      "C": "在所有三个区域的 S3 桶中配置双向复制。",
      "D": "创建一个多区域接入点。修改应用程序以使用多区域视频流访问点的亚马逊资源名称。不要修改视频上传的应用程序。",
      "E": "创建一个多区域接入点。修改应用程序以使用多区域访问点的亚马逊资源名称 进行视频流播和上传。"
    },
    "vote_percentage": "85%",
    "tags": [
      "S3 Multi-Region Access Point",
      "S3 Replication"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AB，但社区共识(投票最高)为CE。社区倾向CE的原因是，多区域访问点能够为用户提供最低的延迟，无论他们位于哪个区域，而修改应用程序来使用多区域访问点ARN是实现这一目标的方式。",
      "why_correct": "选项C，双向复制无法满足开发者的上传视频的延迟。选项E，通过创建多区域接入点，用户可以从最近的S3桶中获取视频，从而减少延迟。 修改应用程序使用多区域访问点可以确保视频上传和播放的低延迟。",
      "why_wrong": "选项A，配置单向复制对于上传视频的开发者来说，没有减少延迟的效果。 选项B，从美国东部复制到欧盟西部再复制到东南，会增加延迟。 选项D， 虽然多区域接入点可以减少视频播放的延迟，但不能减少视频上传的延迟。且不修改视频上传的应用程序，无法让开发者使用多区域访问点，无法达到最低延迟的目的。"
    },
    "related_terms": [
      "S3",
      "S3 桶",
      "CloudFront",
      "多区域接入点"
    ],
    "best_answer": [
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 738,
    "topic": "",
    "question_cn": "一家公司有一个新的移动应用程序。在世界任何地方用户都可以看到关于他们选择的主题的本地新闻。用户还可以在应用程序内部上传照片和视频。用户通常在内容发布后的第一分钟访问内容。新内容很快就取代了旧的内容，然后旧的内容就消失了。新闻的本地性意味着用户在其 aws 90% 上传的区域中消费了 的内容。? 哪个解决方案将通过为内容上传提供最低延迟来优化用户体验",
    "options_cn": {
      "A": "在亚马逊 S3 上上传和存储内容。上传时使用亚马逊 CloudFront。",
      "B": "在亚马逊 S3 上上传和存储内容。使用传输加速上传。",
      "C": "在最接近用户的区域将内容上传到亚马逊 EC2 实例。将数据复制到亚马逊 S3。",
      "D": "在用户最近的区域中将内容上传并存储在 Amazon S3 中。 使用多个 Amazon CloudFront 分布。"
    },
    "vote_percentage": "93%",
    "tags": [
      "S3 Transfer Acceleration",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是S3 传输加速可以加速上传，并且内容消费者的区域具有本地性，使用传输加速可以减少上传延迟，提升用户体验。",
      "why_correct": "S3 传输加速利用了 AWS 的全球网络，加速上传，可以减少上传延迟，提高用户体验。",
      "why_wrong": "选项A，使用 CloudFront 可以加速内容分发，但是不能加速内容上传。选项C，将内容上传到EC2实例，并复制到S3，增加了复杂性。选项D，在用户最近的区域上传，可以减少下载延迟，但是没有解决上传延迟的问题。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "EC2",
      "传输加速"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 739,
    "topic": "",
    "question_cn": "一家公司正在构建一个使用无服务架构的新应用程序。该体系结构将包括一个亚马逊 API 网关和管理传入请求的 Lambda 函数。该公司希望添加一种服务可以将从 API 网关 接收到的消息发送到多个目标 Lambda 函数来进行处理。服务必须提供消息过滤使 目标Lambda函数能够只接收函数所需的消息。? 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "将 API 网关 的请求发送到亚马逊简单通知服务 亚马逊 SNS 主题。订阅亚马逊简单队列服务 亚马逊 SQS 队列的 SQS 主题。配置目标Lambda函数以对不同的 SQS 队列进行轮询。",
      "B": "将 API 网关 中的请求发送到亚马逊 EventBridge。配置 EventBridge 以调用目标 Lambda 函数。",
      "C": "将 API 网关 的请求发送到亚马逊管理的 Apache Kafka 流 亚马逊 MSK。配置亚马逊 MSK 将消息发布到目标兰巴达函数。",
      "D": "将 API 网关 的请求发送到多个亚马逊简单队列服务 亚马逊 SQS 队列。配置目标Lambda函数以对不同的 SQS 队列进行 轮询。"
    },
    "vote_percentage": "68%",
    "tags": [
      "SNS",
      "SQS",
      "Lambda"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，SNS和SQS结合可以实现消息的发布订阅和过滤，满足题目需求，Lambda函数可以消费SQS队列的消息，开销最小。",
      "why_correct": "SNS 允许消息发布到多个订阅者(Lambda函数)，SQS 可以提供队列和异步处理，结合使用可以实现消息过滤和异步处理，且成本低廉。Lambda 函数可以作为消费者处理来自 SQS 队列的消息，满足需求。",
      "why_wrong": "选项B，EventBridge 适合事件驱动的架构，但配置和管理相对复杂。选项C，MSK适用于大规模数据流处理，配置和管理复杂，开销较高。选项D，直接将消息发送到SQS队列，无法满足消息过滤需求。"
    },
    "related_terms": [
      "API 网关",
      "Lambda",
      "SNS",
      "SQS",
      "EventBridge",
      "MSK"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 740,
    "topic": "",
    "question_cn": "一家公司将数百万个档案文件迁移到亚马逊 S3。解决方案架构师需要实现一个解决方案，该解决方案将使用客户提供的密钥加密所有 归档数据。解决方案必须加密现有的未加密对象和未来的对象。? 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "通过过滤亚马逊 S3 库存报告创建一个未加密对象列表。配置一个批处理操作作业用客户提供的密钥通过服务器端加密 (SSE-C)对列表中的对象进行加密。配置 默认加密功能以使用用户提供的密钥的服务器端加密 (SSEC)。",
      "B": "使用 S3 存储透镜指标来识别未加密的 S3 桶。配置 默认加密功能以便使用AWS KMS 键的服务器端加密(SSE-KMS)。",
      "C": "通过过滤亚马逊 S3 的 使用报告创建一个未加密对象列表。配置一个批处理作业以使用 AWS KMS 键的服务器端加密 (SSE-KMS)对列表中的对象进行加密。配置 默认加密功能以便使用AWS KMS 键的服务器端加密 (SSE-KMS)。",
      "D": "通过过滤亚马逊 S3 的 使用报告创建一个未加密对象列表。配置 默认加密功能以使用用户提供的密钥的服务器端加密 (SSEC)。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "SSE-C"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，通过使用SSE-C，并配置S3默认加密策略，可以满足使用客户提供的密钥加密现有和未来对象的需求。",
      "why_correct": "通过 S3 库存报告识别未加密对象, 然后使用 S3 批处理对现有对象进行 SSE-C 加密。 配置S3默认加密策略，确保新上传的对象也使用 SSE-C 加密。满足了题目要求。使用客户提供的密钥进行加密, 确保了数据的安全性。",
      "why_wrong": "选项B, SSE-KMS使用AWS KMS进行加密，而不是客户提供的密钥。选项C，使用AWS KMS加密,不满足题目使用客户提供密钥加密的需求。选项D, 没有使用批处理操作加密现有文件，不满足题目的需求。"
    },
    "related_terms": [
      "S3",
      "SSE-C",
      "SSE-KMS",
      "KMS",
      "S3 存储透镜"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 741,
    "topic": "",
    "question_cn": "作为公司域名记录主机的DNS提供商正经历着故障，这给在AWS上运行的网站造成了服务中断。该公司需要迁移到一个更有弹性的管理DNS服务，并希望该服务运行在AWS上。? 解决方案架构师应该如何快速迁移 DNS 托管服务",
    "options_cn": {
      "A": "为域名创建一个亚马逊 Route 53 公共托管区。导入包含由前提供程序托管的域记录的区域文件",
      "B": "为域名创建一个亚马逊 Route 53 私有托管区。导入包含由前提供程序托管的域记录的区域文件",
      "C": "在 AWS DNS 服务中创建一个简单的广告目录。在 DNS 提供程序和目录服务之间启用区域转移，用于微软活动目录的域记录。",
      "D": "在 VPC 中创建一个亚马逊 Route 53 解析器入站端点。指定 DNS 提供者的 IP 地址。将转发查询的地址。配置提供者的 DNS 查询，将域的 DNS IP 查询转发到入站端点中指定的 IP 地址。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Route 53",
      "DNS Migration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，创建一个 Route 53 公共托管区并导入区域文件，是快速迁移DNS记录最简单、直接的方法。",
      "why_correct": "创建一个 Route 53 公共托管区，然后导入现有的 DNS 记录，可以快速、有效地将 DNS 服务迁移到 Route 53。",
      "why_wrong": "选项B，私有托管区用于内部域名解析。选项C，配置 AD 目录服务，增加复杂性。选项D，配置 Route 53 解析器，适用于将 DNS 查询转发给内部 DNS 服务器，不是快速迁移 DNS 托管服务的最佳方法。"
    },
    "related_terms": [
      "Route 53",
      "公共托管区",
      "区域文件",
      "Route 53 私有托管区",
      "VPC",
      "Route 53 解析器入站端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 742,
    "topic": "",
    "question_cn": "一家公司正在建立一个应用程序，它连接到亚马逊 RDS 数据库。该公司希望管理应用程序配置并安全地存储和检索数据库和其他服务的凭证。? 用最少的管理费用来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "使用 AWS AppConfig 存储和管理应用程序配置。使用 Secrets Manager 来存储和检索凭证。",
      "B": "使用 Lambda 存储和管理应用程序配置。使用 Systems Manager 参数存储来存储和检索凭证。",
      "C": "使用加密的应用程序配置文件。将文件存储在亚马逊 S3 中用于应用程序配置。创建另一个 S3 文件来存储和检索凭证。",
      "D": "使用 AWS AppConfig 存储和管理应用程序配置。使用亚马逊 RDS 存储和检索凭证。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "AppConfig"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，AppConfig专门用来管理应用程序配置，Secrets Manager专门用来存储和检索凭证，且管理成本最低。",
      "why_correct": "使用 AWS AppConfig 管理应用程序配置，使用 Secrets Manager 存储和检索数据库和其他服务的凭证。这些服务都提供了专门的功能，并且减少了管理开销。",
      "why_wrong": "选项B，使用Lambda存储管理配置，增加了复杂性。选项C，使用S3存储配置和凭证，管理复杂且安全性低。选项D， RDS 无法存储凭证。"
    },
    "related_terms": [
      "RDS",
      "Secrets Manager",
      "Lambda",
      "Systems Manager 参数存储",
      "S3",
      "AppConfig",
      "RDS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 743,
    "topic": "",
    "question_cn": "为了满足安全要求，公司需要在传输过程中加密所有应用程序数据，同时与亚马逊 RDS 实例进行通信。最近的一次安全审计显示，AWS KMS(AWSKMS) 可以对 REST API 进行加密，但是没有启用传输中的数据。? 解决方案架构师应该如何满足安全需求",
    "options_cn": {
      "A": "IAM 允许数据库上的数据库认证。",
      "B": "RDS 提供自签名证书。在所有与 RDS 实例的连接中使用证书。",
      "C": "获取 RDS 实例的快照。将快照还原到启用加密的新实例。",
      "D": "下载AWS RDS 提供的根证书。提供所有连接到 RDS 实例的证书。"
    },
    "vote_percentage": "81%",
    "tags": [
      "SSL/TLS",
      "RDS Encryption"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，为了确保数据在传输过程中加密，需要配置SSL/TLS连接，提供证书。",
      "why_correct": "下载RDS提供的根证书，客户端使用证书连接数据库，可以加密传输中的数据。 这是确保RDS传输数据加密的标准做法。",
      "why_wrong": "选项A，IAM 允许数据库认证，只能用于身份验证，不能加密传输中的数据。选项B, RDS自签名证书不够安全，不推荐使用。 选项C，快照和还原无法解决传输加密的问题。"
    },
    "related_terms": [
      "RDS",
      "AWS KMS",
      "IAM",
      "RDS",
      "RDS",
      "快照",
      "RDS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 744,
    "topic": "",
    "question_cn": "一家公司正在设计一种新的 Web 服务，它将在一个弹性负载平衡器(ELB)负载平衡器的背后在亚马逊 EC2 实例上运行。然而许多 Web 服务客户端只能到达其防火墙上授权的 IP 地址。? 解决方案架构师应该推荐什么来满足客户的需求",
    "options_cn": {
      "A": "具有相关弹性 IP 地址的网络负载平衡器。",
      "B": "具有相关弹性 IP 地址的应用程序负载平衡器。",
      "C": "一个亚马逊 Route 53 线路托管区的一个记录指向一个弹性 IP 地址。",
      "D": "在负载平衡器前面运行公共 IP 地址作为代理运行的 EC2 实例。"
    },
    "vote_percentage": "92%",
    "tags": [
      "Network Load Balancer",
      "Elastic IP"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，网络负载均衡器可以分配静态的弹性IP地址，满足客户端防火墙的访问需求。",
      "why_correct": "使用具有弹性 IP 地址的网络负载均衡器(NLB)，可以为客户端提供一个固定的 IP 地址，从而满足客户端防火墙的限制。NLB设计用于处理 TCP、UDP 和 TLS 流量，并能够处理大量的流量。",
      "why_wrong": "选项B，应用程序负载均衡器(ALB)不支持弹性IP。 选项C，Route 53 指向弹性 IP 地址，无法满足负载均衡的需求。 选项D，在负载均衡器前面运行EC2实例作为代理，增加了复杂性，且维护成本高。"
    },
    "related_terms": [
      "ELB",
      "EC2",
      "弹性 IP",
      "网络负载均衡器",
      "应用程序负载平衡器",
      "Route 53",
      "弹性 IP",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 745,
    "topic": "",
    "question_cn": "一家公司建立了一个新的AWS美国世界银行账户。帐户是新准备的，没有改变默认设置。公司关注的是帐户根用户的安全性。? 应该如何保护根用户",
    "options_cn": {
      "A": "为日常管理任务创建 IAM 用户。禁用根用户。",
      "B": "为日常管理任务创建 IAM 用户。对根用户启用多因素身份验证。",
      "C": "为根用户生成一个访问密钥。使用访问密钥进行日常管理任务而不是使用 管理控制台。",
      "D": "向最高级的解决方案架构师提供根用户凭证。让解决方案架构师使用根用户进行日常管理任务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Best Practices",
      "MFA"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，为了提高根用户的安全性，需要启用多因素身份验证，并创建IAM用户管理日常任务。",
      "why_correct": "创建 IAM 用户并为日常管理任务使用它们，是最佳实践。对根用户启用多因素身份验证 (MFA) 可以显著增强账户安全性。",
      "why_wrong": "选项A，虽然创建 IAM 用户并禁用根用户是安全最佳实践，但是仅禁用根用户并不能提供最高的安全性。选项C，使用根用户的访问密钥不安全。选项D，共享根用户凭证是绝对不安全的行为。"
    },
    "related_terms": [
      "IAM",
      "IAM",
      "根用户",
      "IAM",
      "多因素身份验证",
      "根用户",
      "访问密钥",
      "控制台",
      "根用户"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 746,
    "topic": "",
    "question_cn": "一家公司正在部署一个应用程序，可以近实时地处理流数据。该公司计划使用亚马逊 EC2 实例处理工作量。网络体系结构必须是可配置的，以便在节点之间提供尽可能低的延迟。? 哪些网络解决方案组合将满足这些要求 (选二)。",
    "options_cn": {
      "A": "在每个 EC2 实例上启用和配置增强网络。",
      "B": "将 EC2 实例分类到单独的 AWS 账户中。",
      "C": "在集群放置组中运行 EC2 实例。",
      "D": "将多个弹性网络接口附加到每个 EC2 实例。",
      "E": "使用亚马逊弹性块存储并使用亚马逊优化的实例类型。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Enhanced Networking",
      "Placement Groups"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BE，但社区共识(投票最高)为AC。社区倾向AC的原因是，启用增强网络和在集群放置组中运行实例可以最大程度地减少EC2实例之间的延迟。",
      "why_correct": "选项A，启用增强网络 (EFA or ENA) 可以显著降低 EC2 实例的网络延迟。选项C，将 EC2 实例放置在集群放置组中，保证了实例之间的低延迟通信。",
      "why_wrong": "选项B，将 EC2 实例分类到单独的账户中，与减少网络延迟没有直接关系。 选项D，将多个弹性网络接口附加到 EC2 实例，通常用于不同的网络配置，对降低延迟作用有限。 选项E，EBS和优化实例类型，对于降低网络延迟，作用有限。"
    },
    "related_terms": [
      "EC2",
      "增强网络",
      "EC2",
      "AWS 账户",
      "EC2",
      "弹性网络接口",
      "EBS",
      "EC2"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 747,
    "topic": "",
    "question_cn": "一家金融服务公司希望关闭两个数据中心并将超过 100 个结核数据转移到美国世界银行。数据具有复杂的目录结构在子文件夹的深 SMB 层次结构中存储了数百万个小文件。大多数数据是非结构化的公司的文件存储由来自多个供应商的基于 的存储类型组成。该公 司不希望在迁移后改变其应用程序来访问数据。 ? 解决方案架构师应该如何用最少的操作开销来满足这些需求",
    "options_cn": {
      "A": "使用AWS S3直接连接将数据迁移到亚马逊 S3。",
      "B": "使用AWS FSX数据采集器将数据迁移到亚马逊 FSX来获得光泽。",
      "C": "使用AWS Windows FSX数据系统将数据迁移到Amazon 文件服务器。",
      "D": "使用存储网关卷网关将数据在现场文件存储迁移到存储网关卷网关。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Data Migration",
      "AWS FSx for Windows File Server"
    ],
    "explanation": {
      "analysis": "此题考察大规模数据迁移方案选择。社区共识选择 Windows FSx，以满足数据迁移到云端，且无需改变应用程序访问数据的需求。FSx for Windows File Server 提供与本地Windows文件服务器的兼容性。",
      "why_correct": "FSx for Windows File Server 提供了对 SMB 协议的支持，以及与现有 Windows 文件服务器环境的兼容性，无需修改应用程序即可访问数据。数据采集器可用于数据迁移。",
      "why_wrong": "选项A: S3 是对象存储，无法直接兼容 SMB 协议，且迁移复杂。选项B:  FSx 数据采集器，不够具体，无法满足windows文件服务器的迁移需求。选项D: 存储网关卷网关，虽然可以迁移数据，但配置和管理更复杂，操作开销较高。"
    },
    "related_terms": [
      "S3",
      "FSX",
      "FSX",
      "SMB",
      "S3",
      "FSX",
      "FSX",
      "存储网关",
      "卷网关"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 748,
    "topic": "",
    "question_cn": "一个公司使用一个组织在美国职业教育协会的组织来管理包含应用程序的美国职业教育协会帐户。该公司在本组织设立了一个专门 的监测成员账户。该公司希望通过使用亚马逊云表来查询和可视化整个帐户的可观察性数据。 ? 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "启用云观察监测帐户的交叉帐户可观察性。在每个帐户中部署一个由监视帐户提供的 云图模板以便与监视帐户共享数据。",
      "B": "(SCPS), (OU) 建立服务控制策略在组织的根组织单位 下提供进入监控账户的云监视。",
      "C": "在监视帐户中配置一个新的IAM 用户。在每个帐户中配置一个 IAM 策略来访问帐户中的云表数据并使其可视化。将新的 IAM 策略附加到新的 用户上。",
      "D": "在监视帐户中创建一个新的 IAM 用户。在每个帐户中创建跨帐户 IAM 策略。将 IAM 策略附加到新的 IAM 用户上。"
    },
    "vote_percentage": "86%",
    "tags": [
      "CloudWatch Cross-Account Monitoring",
      "CloudWatch Dashboard"
    ],
    "explanation": {
      "analysis": "此题考察跨账户云监控的实现。注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，A通过CloudWatch跨账户监控功能，可以实现集中监控所有账户的日志，并可视化。",
      "why_correct": "选项A，通过 CloudWatch 的跨账户监控功能，可以集中监控来自多个 AWS 账户的指标和日志。在监控账户中创建 CloudWatch 仪表板，可以方便地可视化来自所有账户的数据。",
      "why_wrong": "选项C，需要在每个账户中配置 IAM 策略，管理复杂。选项B: 服务控制策略主要用于限制组织成员的操作权限，而不是监控。选项D: 跨账户 IAM 策略，实现方式复杂，配置工作量大。"
    },
    "related_terms": [
      "CloudWatch",
      "云图",
      "IAM",
      "云表",
      "IAM",
      "IAM",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 749,
    "topic": "",
    "question_cn": "一家公司的网站被用来向公众销售产品。该网站运行在亚马逊 EC2 实例在一个应用负载平衡器后面的一个自动标尺组。还有一 AWS WAF 和 AWS CloudFront，并且正在使用 来防止 IP 注入攻击。 CloudFront 是云端分布的起源。最近对安全日志的审查显示需要阻止外部恶意 访问网站。 ? 解决方案架构师应该做什么来保护应用程序",
    "options_cn": {
      "A": "修改云面分布上的网络 ACL 为恶意 IP 地址添加拒绝规则。",
      "B": "修改 AWS WAF 的配置添加匹配条件以阻止恶意 IP 地址。",
      "C": "修改 EC2 背后目标组中的 实例的网络 ACL 以拒绝恶意 IP 地址。",
      "D": "修改 EC2 背后目标组的实例的安全组以拒绝恶意 IP 地址。"
    },
    "vote_percentage": "81%",
    "tags": [
      "AWS WAF",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "此题考察如何通过AWS WAF阻止恶意IP访问。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，WAF是专门用来防御Web攻击的，通过WAF配置匹配规则可以有效阻止恶意IP访问，且WAF可以与CloudFront集成。",
      "why_correct": "选项B：AWS WAF 专门用于保护 Web 应用程序，可以配置规则来阻止来自特定 IP 地址的流量，并且能与 CloudFront 完美集成。",
      "why_wrong": "选项A:  ACL 主要用于网络层面的控制，配置较为复杂，且不如 WAF 专门。选项C:  修改EC2实例的网络ACL，无法充分利用 CloudFront 和 WAF 的优势。选项D:  修改EC2安全组，主要用于控制实例的入站流量，无法防御Web应用层攻击。"
    },
    "related_terms": [
      "EC2",
      "ELB",
      "AWS WAF",
      "AWS CloudFront",
      "IP 注入",
      "CloudFront",
      "EC2",
      "网络 ACL",
      "AWS WAF",
      "EC2",
      "安全组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 750,
    "topic": "",
    "question_cn": "一家公司在美国职业介绍所的组织中设立一个包含 10 个 AWS 帐户的组织。解决方案架构师必须设计一个解决方案为几千 Aws 名员工提供对帐户的访问。公司有一个现有的身份提供者。该公司希望使用现有的内部数据处理器来认证 。 ? 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在所需的 AWS 帐户中为员工创建 IAM 用户。将 IAM 用户连接到现有的国内流离失所者。为 IAM 用户配置联合身份验证。",
      "B": "建立 AWS 帐户根用户与用户电子邮件地址和密码这些是同步的与现有的国内流离失所者。",
      "C": "使用AWS IAM 身份识别中心(AWS IAM Identity Center) 配置单一登录(SSO)。将身份识别中心连接到现有的国内流离失所者。提供现有国内流离失所者的用户和 团体。",
      "D": "使用 AWS 资源访问管理器(AWS RAM) 与现有内部文件管理器中的用户共享对 AWS 帐户的访问。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS IAM Identity Center (SSO)",
      "SAML"
    ],
    "explanation": {
      "analysis": "此题考察如何实现用户通过现有身份提供商访问AWS账户。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，IAM Identity Center提供集中式用户管理和 SSO 功能，可以与现有身份提供商集成。",
      "why_correct": "选项C: 使用 IAM Identity Center (先前称为 AWS SSO)，可以与现有的身份提供商集成，实现集中式用户管理和 SSO。用户只需使用现有凭证登录，即可访问多个 AWS 账户。",
      "why_wrong": "选项B：使用根用户不符合安全最佳实践。选项A： 需要在每个账户创建用户，管理成本太高。选项D：资源访问管理器用于共享资源，而非用户身份认证。"
    },
    "related_terms": [
      "AWS",
      "IAM",
      "IAM",
      "联合身份验证",
      "IAM",
      "AWS IAM Identity Center",
      "SSO",
      "AWS RAM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 751,
    "topic": "",
    "question_cn": "一个解决方案架构师正在为一个公司的 AWS 帐户设计一个 IAM 标识和访问管理 授权模型。该公司指定了五名特定员工使他们能 AWS 够充分利用美国职业服务协会在 账户中的服务和资源。解决方案架构师为 5 个指定员工中的每个人创建了一个 IAM 用户并创建了一个 IAM 用户组。 ? 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将基于管理层访问资源的 IAM 策略附加到 IAM 用户组。将 5 个指定员工 用户中的每个用户放在 IAM 用户组中。",
      "B": "将基于系统管理员身份的策略附加到 IAM 用户组。将 5 个指定员工 用户中的每个用户放在 IAM 用户组中。",
      "C": "将基于管理访问身份的 IAM 策略附加到 IAM 用户组。将 5 个指定员工 用户中的每个用户放在 IAM 用户组中。",
      "D": "将基于系统管理员资源的 IAM 策略附加到 IAM 用户组。将 5 个指定员工 用户中的每个用户放在 IAM 用户组中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Permissions",
      "IAM User Groups"
    ],
    "explanation": {
      "analysis": "此题考察IAM用户权限的配置方式。 正确答案是基于管理访问身份的IAM策略附加到用户组。",
      "why_correct": "选项 C: 为了授予用户对 AWS 资源的访问权限，需要将策略附加到用户组。这些策略应授予用户所需的权限。基于管理访问身份的策略，是指根据用户身份进行授权，而不是针对特定资源。",
      "why_wrong": "选项A: 管理层访问资源，描述不清晰，容易引起误解。选项B: 基于系统管理员身份的策略，过于笼统，不符合最佳实践。选项D: 系统管理员资源，过于笼统，不符合最佳实践。"
    },
    "related_terms": [
      "IAM",
      "IAM",
      "IAM",
      "IAM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 752,
    "topic": "",
    "question_cn": "公司拥有基于虚拟机的多层支付处理应用程序。层与层之间的通信是异步通过第三方中间件解决方案进行的该解决方案保证了一次 有效的交付。 该公司需要的解决方案要求最少的基础设施管理量。解决方案必须有效地保证应用程序消息传递一旦完成。 ? 哪些行动组合将满足这些要求 选二。",
    "options_cn": {
      "A": "在体系结构中使用 Lambda 计算层。",
      "B": "EC2 架构中的计算层使用亚马逊 实例。",
      "C": "使用亚马逊简单通知服务(SNS) 亚马逊简单通知服务作为计算层之间的消息传递组件。",
      "D": "使用亚马逊简单队列服务(SQS) 亚马逊简单队列服务 队列作为计算层之间的消息传递组件。",
      "E": "使用基于亚马逊弹性库伯内特斯服务(EKS) 亚马逊 容器进行架构中的计算层。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS",
      "Lambda"
    ],
    "explanation": {
      "analysis": "此题考察应用程序消息传递方案的选择，需要保证消息传递的有效性，并减少基础设施管理。答案选AD",
      "why_correct": "选项 A 和 D：Lambda 和 SQS 都是 AWS 提供的无服务器服务，可以减少基础设施的管理量。Lambda 可以作为计算层，SQS可以作为消息传递组件，实现异步消息传递，并保证消息传递的有效性，因为 SQS 提供了消息的可靠传递。因此，这两个选项的组合满足了题目要求。",
      "why_wrong": "选项 B：EC2 需要管理 EC2 实例，管理开销较大。选项 C：SNS 用于发布消息，而不能保证消息的有效性。选项 E：EKS 需要管理 Kubernetes 集群，管理开销较大。"
    },
    "related_terms": [
      "Lambda",
      "SNS",
      "SQS",
      "EKS"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 753,
    "topic": "",
    "question_cn": "一个公司有一个夜间批处理程序分析一个内部文件系统每天通过 SFTP 接收的报告文件。该公司希望将解决方案转移到 云。解决 方案必须具有高度的可用性和弹性。解决方案还必须尽量减少业务努力。 ? 哪种解决方案符合这些要求",
    "options_cn": {
      "A": "为 SFTP 和一个亚马逊弹性文件系统 (EFS)  文件系统部署 AWS EC2 传输。在具有预定扩展策略的自动扩展组中使用亚马逊 EC2 实例 来运行批处理操作。",
      "B": "部署一个运行 Linux SFTP 服务和 EC2 服务的亚马逊 EC2 实例。使用亚马逊弹性块存储 (EBS)  卷存储。使用一个自动缩放组其中最小的 1 实例数和设置为 的理想实例数。",
      "C": "部署运行 Linux SFTP 服务和 EC2 服务的亚马逊 EC2 实例。使用亚马逊弹性文件系统 (EFS) 文件系统进行存储。使用一个自动缩放组 1 其中最小的实例数和设置为 的理想实例数。",
      "D": "为 SFTP 和一个亚马逊 S3 桶的存储而部署的  AWS EC2 传输。修改应用程序将批处理文件从亚马逊 S3 拉到亚马逊 EC2 实例进行处理。 在具有计划的扩展策略的自动扩展组中使用 EC2 实例来运行批处理操作。"
    },
    "vote_percentage": "63%",
    "tags": [
      "SFTP",
      "EFS"
    ],
    "explanation": {
      "analysis": "此题考察SFTP文件传输的方案选择，要求高可用、弹性和减少业务工作量。注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，使用EFS，可以提供共享文件存储，并且可以通过自动伸缩组提供弹性，易于管理。",
      "why_correct": "选项 A:  使用 EFS 作为共享存储，可以轻松实现高可用性和弹性。 自动伸缩组可以根据负载自动调整 EC2 实例的数量。减少了业务工作量，易于管理。",
      "why_wrong": "选项B:  EBS 是块存储，无法提供共享存储，不适用于多个实例访问。选项 C: EFS 可以提供共享存储，但单个实例无法满足高可用性需求。选项D: 需要修改应用程序，增加工作量，使用S3 需要额外配置。"
    },
    "related_terms": [
      "SFTP",
      "EFS",
      "EC2",
      "EC2",
      "EBS",
      "SFTP",
      "S3",
      "EC2",
      "S3",
      "EC2"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 754,
    "topic": "",
    "question_cn": "一家公司在世界各地都有用户访问其基于 http 的应用程序该应用程序部署在亚马逊 EC2 实例中的多个 区域。该公司希望改进应用 Web 程序的可用性和性能。该公司还希望保护应用程序不受可能影响可用性、损害安全性或消耗过多资源的常见 漏洞的影响。需要 IP 静态 地址 ? 解决方案架构师应该建议什么来实现这个目标",
    "options_cn": {
      "A": "将 EC2 实例放在每个区域的网络负载平衡器 NLBS 后面。在 NLBS 上部署无线武器。使用 AWS 全球加速器创建一个加速器并注册 NLBS 作为终点。",
      "B": "将 EC2 实例放在每个区域的应用程序负载平衡器(ALBS) 后面。部署在ALB上的 AWS WAF。创建一个加速器使用 全球加速器和注册 ALBS 作为终点。",
      "C": "将 EC2 实例放在每个区域的网络负载平衡器 NLBS 后面。在 NLBS 上部署无线武器。创建一个亚马逊云端分布其来源是使用亚马 53 路由的延迟路由到 NLBS 的路由请求。",
      "D": "将 EC2 实例放在每个区域的应用程序负载平衡器 后面。创建一个亚马逊云端分布其来源是使用亚马逊路由的延迟 ALBS 路由请求到 。在云端分布上部署无线电波。"
    },
    "vote_percentage": "83%",
    "tags": [
      "Global Accelerator",
      "WAF",
      "ALB"
    ],
    "explanation": {
      "analysis": "此题考察如何通过负载均衡、WAF和Global Accelerator来提高应用程序的可用性、性能和安全性。注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，Global Accelerator 提供了静态 IP 地址，并与WAF集成，提供安全性和性能优化。",
      "why_correct": "选项B:  使用 ALBS，可以提供负载均衡。WAF用于保护应用程序免受常见漏洞攻击。Global Accelerator 提供了静态 IP 地址，并提高了应用程序的性能，且与 WAF 兼容。",
      "why_wrong": "选项A: NLB不提供WAF功能，安全性不足。选项C: 53 路由，延迟路由性能相对差。选项D: 未提及WAF，安全防护不足。"
    },
    "related_terms": [
      "EC2",
      "NLB",
      "AWS Global Accelerator",
      "ALB",
      "AWS WAF",
      "AWS Global Accelerator",
      "Route 53",
      "ALB",
      "AWS WAF"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 755,
    "topic": "",
    "question_cn": "一家公司的数据平台使用的是亚马逊奥罗拉的 mysql 数据库。数据库具有多个读取副本和跨不同可用性区域的多个数据库实例。最 近用户从数据库中报告错误表明连接过多。当阅读副本被提升到主要作者时公司希望将故障转移时间减少 20% 。 ? 哪种解决方案能满足这一要求",
    "options_cn": {
      "A": "从奥罗拉切换到亚马逊 RDS 多 AZ 集群部署。",
      "B": "在极光数据库前使用亚马逊 RDS 代理。",
      "C": "切换到亚马逊发电机(DynamoDB) 与发电机加速器 (DAX) 读取连接。",
      "D": "切换到具有迁移能力的亚马逊红移(Redshift)。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Proxy",
      "Aurora"
    ],
    "explanation": {
      "analysis": "此题考察Aurora数据库的优化方案。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，RDS Proxy可以减少连接过多问题和故障转移时间。",
      "why_correct": "选项B:  RDS Proxy 可以有效减少数据库连接过多问题，提高数据库的可用性，并加快故障转移时间，满足了题目的要求。RDS Proxy 可以复用数据库连接，减少了数据库的负载。",
      "why_wrong": "选项A:  RDS 多 AZ 集群部署，虽然可以提高可用性，但无法解决连接过多问题。选项 C: DynamoDB 和 DAX 适用于 NoSQL 数据库，不适用于 MySQL 数据库。选项D: Redshift 是数据仓库，不适用于OLTP应用程序。"
    },
    "related_terms": [
      "Aurora",
      "MySQL",
      "RDS",
      "RDS",
      "Aurora",
      "RDS",
      "DynamoDB",
      "DAX",
      "Redshift"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 756,
    "topic": "",
    "question_cn": "一家公司用亚马逊 S3 存储文本文件。文本文件包括客户聊天信息、日期和时间信息以及客户个人识别信息。该公司需要一个解决方案向外部服务供应商提供对话样本以进行质量控制。外部服务提供商需要随机收集到最近的对话的样本。公 司不得与外部服务提供商分享客户信息。当客户对话次数增加时解决方案必须扩大。 ? 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "创建一个 S3 对象兰布达访问点。创建一个 Lambda 函数当函数读取文件时，该函数将重新分配 PII 。指示外部服务提供者访问对 象兰布达访问点。",
      "B": "在亚马逊 EC2 实例中创建一个 Web 应用程序，该应用程序提供一个文件列表从文件中编辑 PII 并允许外部服务提供者下载经过编辑的文件的新版本。",
      "D": "创建一个亚马逊 DynamoDB 发电机。创建一个 Lambda 函数，它只读取不包含 PII 的文件中的数据。在将一个新文件写入到亚马逊 S3 时配置 Lambda 函数来存储发电机表中的非 PII 数据。授予外部服务提供者访问发电机表的权限。"
    },
    "vote_percentage": "91%",
    "tags": [
      "Lambda",
      "S3",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此题考察如何向外部服务提供商提供数据，同时保护客户隐私。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，使用 Lambda 函数可以从S3对象中提取非PII数据，可以满足隐私保护的需求，并且可以扩展。",
      "why_correct": "选项 A:  使用 Lambda 函数读取 S3 对象，并在读取时编辑 PII 数据，可以确保外部服务提供商无法获取 PII 数据，同时可以提供随机样本。S3 访问点提供了简便的访问方式，满足了需求。",
      "why_wrong": "选项 B:  EC2 方案需要维护 EC2 实例，管理开销较大，且没有考虑数据的隐私保护。选项D:  DynamoDB 的使用增加了复杂性，且维护成本较高。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "PII",
      "S3",
      "EC2",
      "PII",
      "DynamoDB",
      "Lambda",
      "S3",
      "PII",
      "DynamoDB"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 757,
    "topic": "",
    "question_cn": "一家公司正在亚马逊 EC2 实例上运行一个遗留系统。不能修改应用程序代码系统不能在多个实例上运行。解决方案架构师必须设计 一个能够提高系统恢复时间的弹性解决方案。 ? 解决方案架构师应该建议什么来满足这些需求",
    "options_cn": {
      "A": "启用 EC2 实例的终止保护。",
      "B": "配置多 AZ 部署的 EC2 实例。",
      "C": "创建一个亚马逊云表(CloudWatch) 警报以在失败的情况下恢复 EC2 实例。",
      "D": "启动 EC2 实例与两个亚马逊弹性块存储 (EBS)  卷使用 RAID 配置存储冗余。"
    },
    "vote_percentage": "68%",
    "tags": [
      "CloudWatch Alarms",
      "EC2 Recovery"
    ],
    "explanation": {
      "analysis": "此题考察提高单实例系统恢复时间的方案。注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，通过CloudWatch 监控实例，并在实例失败时自动恢复，可以提高恢复时间。",
      "why_correct": "选项 C: 使用 CloudWatch 警报监控 EC2 实例的健康状态。当实例失败时，警报可以触发自动恢复操作。 可以缩短恢复时间。",
      "why_wrong": "选项A: 启用 EC2 实例的终止保护，防止实例被意外终止，不能提高系统恢复时间。选项B: 多 AZ 部署不适用于单实例系统。选项D: RAID 配置可以提高存储的冗余性，但不能提高系统的恢复时间。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "云表(CloudWatch)",
      "EC2",
      "EBS",
      "RAID"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 758,
    "topic": "",
    "question_cn": "一个公司希望在三个可用性区域将其集装箱化的应用程序工作负载部署到 VPC 上。该公司需要的解决方案是高度可用的跨可用性 区。解决方案必须对应用程序进行最低限度的更改。 ? 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "使用亚马逊弹性集装箱服务(ECS)。配置亚马逊 ECS 服务自动缩放以使用目标跟踪缩放。将最低容量设为 3.用可用性区域属性设置任务 放置策略类型",
      "B": "使用亚马逊弹性库伯内特斯服务 (EKS) 亚马逊自管理节点。配置应用程序自动缩放以使用目标跟踪缩放。将最低容量设为 3.",
      "C": "使用 EC2  保留实例。在扩展放置组中启动三个 EC2 实例。配置一个自动缩放组来使用目标跟踪缩放 将最低容量设为 3.",
      "D": "使用 VPC 的 Lambda 函数。配置 Lambda 函数以连接到 VPC。配置应用程序自动缩放以使用作为可伸缩的目标。将最低容量设为 3."
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS",
      "Availability Zones",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考察容器化应用程序在VPC上的部署方案，要求高可用性，跨可用区，并减少运维开销。注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是，ECS是完全托管的服务，可以简化部署和管理。",
      "why_correct": "选项 A:  使用 ECS 可以轻松部署和管理容器化应用程序。配置 ECS 服务自动缩放，可以在多个可用区中实现高可用性。通过设置任务放置策略，可以确保任务分布在不同的可用区。是最优解。",
      "why_wrong": "选项 B:  EKS 的运维管理复杂度高于 ECS。选项 C: EC2 保留实例，需要手动管理EC2，维护工作量大。选项 D: Lambda 函数不支持容器部署。"
    },
    "related_terms": [
      "VPC",
      "ECS",
      "EKS",
      "Lambda",
      "VPC",
      "自动缩放",
      "可用性区域",
      "目标跟踪",
      "EC2",
      "自动缩放",
      "弹性块存储器 (EBS)",
      "弹性文件系统 (EFS)"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 759,
    "topic": "",
    "question_cn": "一家媒体公司用亚马逊 S3 存储电影。每一部电影都存储在一个大小从 1GB 到 10GB 的视频文件中。该公司必须能够在用户购买后 5 分钟内提供电影的流媒体内容。对不到 20 年的电影的需求高于对超过 20 年的电影的需求。该公司希望 根据需求将托管服务成本降至最低。 ? 哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将所有媒体内容存储在亚马逊 S3 上。当电影需求减少时使用生命周期策略将媒体数据移动到不常访问的层中。",
      "B": "以 S3 标准存储更新的电影视频文件。在 S3 标准 - 不常访问 (S3-IA) 标准 中存储旧的电影视频文件。当用户订购一部旧电影时使用标准检索来检索视频文件。",
      "C": "在 S3 智能层中储存更新的电影视频文件。储存老电影视频文件在 冰川灵活检索。当用户订购一部旧电影时使用快速检索来 检索视频文件。",
      "D": "以 S3 标准存储更新的电影视频文件。储存老电影视频文件在 冰川灵活检索。当用户订购一部旧电影时通过大量检索来 检索视频文件。"
    },
    "vote_percentage": "50%",
    "tags": [
      "S3 Storage Tiers",
      "Lifecycle Policies"
    ],
    "explanation": {
      "analysis": "此题考察如何通过存储层和生命周期策略来优化电影存储的成本。注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，结合了智能分层和Glacier Flexible Retrieval，能够针对不同访问频率的电影，最大限度地节省存储成本，并满足快速访问的需求。",
      "why_correct": "选项 C:  使用 S3 智能分层存储更新的电影，可以自动将不经常访问的电影移动到较低成本的存储层。将老电影存储在 Glacier Flexible Retrieval 中，可以进一步降低存储成本，并且快速检索。 满足了性能和成本的需求。",
      "why_wrong": "选项 A:  只是简单地使用生命周期策略，没有考虑存储的性能和成本的平衡。选项 B:  S3 标准-IA 存储成本低于标准存储，但检索成本较高。选项 D:  大量检索不适用于频繁检索旧电影的场景。"
    },
    "related_terms": [
      "S3",
      "S3",
      "生命周期策略",
      "S3",
      "S3-IA",
      "S3",
      "冰川灵活检索",
      "S3",
      "冰川灵活检索"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 760,
    "topic": "",
    "question_cn": "解决方案架构师需要为一个应用程序设计体系结构该应用程序由供应商提供作为一个码头容器映像。容器需要 50GB 的存储空间来存 储临时文件 基础设施必须是无服务的。 ? 用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "创建一个使用亚马逊 S3 安装的空间超过 50GB 空间的码头集装箱图像的 Lambda 函数。",
      "B": "创建一个使用了具有以上空间的亚马逊弹性块存储器 (EBS)  的码头集装箱图像的 Lambda 函数。",
      "C": "创建一个亚马逊弹性容器服务 (ECS) 集群该集群使用 法盖特发射类型。为具有亚马逊弹性文件系统 (EFS)  卷的容器图像创 建任务定义。用任务定义创建一个服务。",
      "D": "创建一个亚马逊弹性容器服务集群使用亚马逊 EC2 发射类型的亚马逊弹性块商店 (EBS)  卷有超过 50GB 的空间。为容 器映像创建任务定义 用任务定义创建一个服务。"
    },
    "vote_percentage": "91%",
    "tags": [
      "ECS Fargate",
      "EFS"
    ],
    "explanation": {
      "analysis": "此题考察无服务器容器存储方案的选择。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，使用 ECS Fargate 可以实现无服务器容器的部署，EFS 提供持久存储。",
      "why_correct": "选项 C:  使用 ECS  Fargate，可以实现无服务器容器的部署，无需管理底层服务器。EFS 提供持久的存储空间，满足了对临时文件存储的需求。",
      "why_wrong": "选项 A:  Lambda 函数不支持容器镜像，无法运行容器。选项 B:  Lambda 函数没有持久存储能力。选项 D:  ECS EC2 需要管理 EC2 实例，不符合无服务器的要求。"
    },
    "related_terms": [
      "Lambda",
      "S3",
      "EBS",
      "ECS",
      "Fargate",
      "EFS",
      "ECS",
      "EC2",
      "EBS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 761,
    "topic": "",
    "question_cn": "一个公司需要使用其内部的 LDAP 目录服务来认证其用户到 AWS 管理控制台。目录服务与安全断言标记语言 (SAML) 不兼容。 ? 哪种解决方案符合这些要求",
    "options_cn": {
      "A": "使 AWS 身份识别中心 (AWS IAM Identity Center) 单点登录(SSO) 之间的 AWS 和内部 LDAP。",
      "B": "创建一个使用 LDAP 凭证的 IAM 策略并将该策略集成到 IAM 中。",
      "C": "设置一个流程每当 LDAP 凭证更新时，它将旋转 IAM 凭证。",
      "D": "开发一个现场自定义身份代理应用程序或流程该应用程序或流程使用 AWS 安全令牌服务 (AWS STS) 来获得短期凭证。"
    },
    "vote_percentage": "100%",
    "tags": [
      "STS",
      "LDAP"
    ],
    "explanation": {
      "analysis": "此题考察如何通过内部LDAP目录服务认证用户到AWS控制台。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，STS可以用于临时凭证，与LDAP结合可以实现认证。",
      "why_correct": "选项 D:  STS 可以用于获取临时的 AWS 凭证，应用程序可以利用 STS 通过 LDAP 进行身份验证。是一种可行的方案。",
      "why_wrong": "选项 A:  SSO通常与SAML结合使用，不兼容LDAP。选项 B:  直接将LDAP凭证集成到IAM策略中是不安全的做法。选项 C:  每当LDAP凭证更新，旋转IAM凭证，过于复杂。"
    },
    "related_terms": [
      "LDAP",
      "AWS IAM Identity Center",
      "SSO",
      "IAM",
      "IAM 策略",
      "AWS STS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 762,
    "topic": "",
    "question_cn": "一家公司在一个AWS账户中存储多个亚马逊机器图像以启动其亚马逊EC2实例。非苏特派团载有公司业务所需的关键数据和配置。该公司希望实现一个解决方案，以快速有效地恢复意外删除的美国信息系统。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建亚马逊弹性块存储(EBS)亚马逊快照的非苏特派团。将快照存储在一个单独的账户中。",
      "B": "定期将所有非苏特派团复制到另一个非苏特派团账户。",
      "C": "在回收站中创建一个保存规则。",
      "D": "使用S3上传到具有跨区域复制的亚马逊桶中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EBS Snapshots",
      "S3 Cross-Region Replication"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，在回收站配置保留规则是防止数据意外删除的最直接方案。该选项可以帮助快速恢复已删除的AMI。其他选项的操作成本或复杂性较高。",
      "why_correct": "在回收站中配置保留规则提供了一种防止数据意外删除的保护机制，当AMI被删除时，可以从回收站中恢复，操作简单，且是针对该场景最合适的解决方案。",
      "why_wrong": "A选项创建EBS快照虽然可以备份数据，但操作复杂性较高，并且恢复AMI并不直接。B选项将非苏特派团复制到其他账户，增加了复杂性和成本。D选项使用S3跨区域复制，主要用于数据冗余和灾难恢复，不适合AMI的快速恢复。"
    },
    "related_terms": [
      "Amazon EC2",
      "EBS",
      "快照",
      "S3",
      "跨区域复制"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 763,
    "topic": "",
    "question_cn": "一家公司有150GB的存档图像数据存储在办公场所，需要在下个月转移到AWS云。该公司目前的网络连接允许最多100Mbps的上传速度，为此目的在夜间上传。转移这些数据和遵守移徙期限的最具成本效益的机制是什么？",
    "options_cn": {
      "A": "使用AWS Snowball设备来传送数据到AWS。",
      "B": "订购多个AWS Snowball设备以运送数据到AWS。",
      "C": "启用Amazon S3传输加速和安全上传数据。",
      "D": "创建一个Amazon S3 VPC端点并建立一个VPN来上传数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Snowball",
      "S3 Transfer Acceleration"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，根据题目给出的数据量和网络带宽，使用多个Snowball设备可以更快地完成数据迁移，符合时间要求。",
      "why_correct": "使用多个Snowball设备可以并行传输数据，加速数据迁移过程，满足题目中对截止日期的要求，并且在数据量较大，网络带宽有限的情况下，Snowball是性价比最高的方案。",
      "why_wrong": "A选项使用单个Snowball设备虽然可行，但可能不能满足时间限制。C选项S3传输加速虽然可以提高传输速度，但是对于如此大的数据量，效果有限。D选项创建S3 VPC端点并建立VPN，增加了复杂性，不适合大规模数据传输，并且速度也受限。"
    },
    "related_terms": [
      "AWS Snowball",
      "Amazon S3 Transfer Acceleration",
      "S3 VPC 端点",
      "VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 764,
    "topic": "",
    "question_cn": "一家公司希望将其三层应用程序从公司内部迁移到AWS。Web层和应用程序层在第三方虚拟机上运行。数据库层在MySQL上运行。公司需要迁移应用程序，尽可能减少对架构的更改。该公司还需要一个数据库解决方案，可以将数据恢复到特定的时间点。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将Web层和应用程序层迁移到Amazon EC2实例。将数据库层迁移到Amazon RDS for MySQL用于在私有子网中使用。",
      "B": "将Web层迁移到Amazon EC2实例的公共子网络中。将应用程序层迁移到私有子网中的EC2实例。将数据库层迁移到私有子网中的Amazon Aurora MySQL。",
      "C": "将Web层迁移到Amazon EC2实例的公共子网络中。将应用程序层迁移到私有子网中的EC2实例。将数据库层迁移到Amazon RDS for MySQL用于在私有子网中使用。",
      "D": "在公共子网络中将Web层和应用层迁移到Amazon EC2实例。将数据库层迁移到公共子网络中的Amazon Aurora MySQL。"
    },
    "vote_percentage": "93%",
    "tags": [
      "EC2",
      "RDS for MySQL",
      "Aurora MySQL"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，Amazon Aurora MySQL提供了时间点恢复(PITR)功能，满足题目中对数据库恢复到特定时间点的要求。并且B选项架构分离更加合理。",
      "why_correct": "B选项使用Aurora MySQL，Aurora MySQL提供了PITR功能，满足了题目的要求。 Aurora的性能和可伸缩性也优于RDS MySQL。应用程序层使用EC2，可以更好地控制，将Web层部署到公共子网可以方便访问。",
      "why_wrong": "A选项使用RDS for MySQL， 虽然操作简单，但性能和功能不如Aurora。C选项也是使用了RDS for MySQL，不支持PITR功能。D选项将Aurora部署在公共子网中，安全风险较高。"
    },
    "related_terms": [
      "Amazon EC2",
      "MySQL",
      "RDS",
      "私有子网",
      "Amazon Aurora MySQL",
      "公共子网"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 765,
    "topic": "",
    "question_cn": "一个开发团队正在与另一家公司合作开发一个集成产品。另一家公司需要访问一个包含在开发团队帐户中的Amazon Simple Queue Service(SQS)队列。另一家公司希望在不放弃自己帐户权限的情况下对队列进行轮询。解决方案架构师应该如何提供对SQS队列的访问？",
    "options_cn": {
      "A": "创建一个SQS实例配置文件提供其他公司访问队列的权限。",
      "B": "创建一个IAM策略提供其他公司访问SQS队列的权限。",
      "C": "创建一个SQS访问策略提供其他公司访问SQS队列的权限。",
      "D": "创建一个Amazon Simple Notification Service (SNS) 访问策略，该策略提供其他公司访问SQS队列的权限。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS Access Policy",
      "IAM Policy"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，SQS访问策略是最适合控制对SQS队列访问的机制，可以细粒度地控制哪些账户可以访问该队列。",
      "why_correct": "C选项使用SQS访问策略是正确答案。SQS访问策略允许指定哪些AWS账户或IAM用户可以访问SQS队列，并且可以精确地控制权限，满足了题目中对访问控制的要求。",
      "why_wrong": "A选项使用实例配置文件，实例配置文件主要用于赋予EC2实例访问AWS资源的权限，不适用于跨账户访问SQS队列。B选项使用IAM策略，IAM策略用于控制IAM用户和角色对AWS资源的访问，但对于跨账户访问SQS队列，SQS访问策略更直接。D选项使用SNS，SNS是发布/订阅服务，与SQS的访问控制无关。"
    },
    "related_terms": [
      "SQS",
      "IAM",
      "SQS",
      "SQS访问策略",
      "SNS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 766,
    "topic": "",
    "question_cn": "一家公司的开发人员想要一种安全的方式来获得在Amazon EC2实例中运行最新版本Amazon Linux的SSH访问。开发人员在公司办公室远程工作。EC2实例在VPC的私有子网中托管，并通过部署在公共子网中的NAT网关访问互联网。解决方案架构师应该做什么才能最经济有效地满足这些需求？",
    "options_cn": {
      "A": "在与EC2实例相同的子网中创建一个堡垒主机。向开发人员授予IAM创建连接许可。安装EC2实例连接以便开发人员能够连接到EC2实例。",
      "B": "在公司网络和AWS VPC之间创建一个AWS VPN站点到站点的VPN连接。当开发人员在企业网络上时，指示开发人员使用网站到网站的VPN连接来访问EC2实例。指示开发人员在远程工作时为访问设置另一个VPN连接。",
      "C": "在VPC的公共子网中创建一个堡垒主机，配置该堡垒主机的安全组和SSH密钥只允许从开发人员的企业网络和远程网络连接和SSH身份验证。指示开发人员通过堡垒主机连接使用SSH到达EC2实例。",
      "D": "将Amazon管理的IAM实例角色策略附加到与EC2实例关联的IAM角色上。指示开发人员使用系统管理器会话管理器访问EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Instance Connect",
      "AWS Systems Manager Session Manager"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，使用AWS Systems Manager Session Manager（会话管理器）提供了一种安全且经济高效的方式，无需打开SSH端口，即可通过IAM权限安全地访问EC2实例，并简化了开发人员的远程访问过程。",
      "why_correct": "D选项使用AWS Systems Manager Session Manager。会话管理器提供了一种安全且无SSH密钥的管理EC2实例的方式，无需打开入站SSH端口，安全性高，且无需维护堡垒主机或VPN配置，成本更低，更适合远程访问场景。",
      "why_wrong": "A选项使用堡垒主机，虽然安全，但需要管理堡垒主机，增加了管理成本。B选项建立VPN连接，增加了复杂性，远程办公情况下需要额外的配置。C选项使用堡垒主机，与A选项类似，增加了管理成本和复杂性。"
    },
    "related_terms": [
      "Amazon EC2",
      "VPC",
      "NAT网关",
      "堡垒主机",
      "安全组",
      "SSH",
      "IAM",
      "VPN",
      "SSH",
      "系统管理器会话管理器",
      "IAM 实例角色"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 767,
    "topic": "",
    "question_cn": "一家制药公司正在研制一种新药。过去几个月里，该公司生成的数据量呈指数增长。该公司的研究人员经常要求所有数据集中的一个子集在最短的时间内立即可用。然而，不需要每天访问整个数据集。目前所有的数据都存放在内部存储阵列中，公司希望减少持续的资本支出。解决方案架构师应该推荐哪种存储解决方案来满足这些需求？",
    "options_cn": {
      "A": "将数据管理系统作为计划中的Cron工作运行，将数据持续迁移到Amazon S3桶。",
      "B": "部署一个AWS Storage Gateway文件网关与一个Amazon S3桶作为目标存储。将数据迁移到存储网关设备。",
      "C": "部署一个AWS Storage Gateway卷网关与缓存的卷作为目标存储，Amazon S3桶。将数据迁移到存储网关设备。",
      "D": "配置一个从现场环境到Amazon EFS的网络服务的连接。将数据迁移到Amazon Elastic File System。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Storage Gateway",
      "S3"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，卷网关结合S3的对象存储，可以提供缓存功能，并且数据最终存储在S3中，满足了数据量大、需要快速访问子集数据的需求，同时降低了成本。并且卷网关可以更方便的与现有存储系统集成。",
      "why_correct": "C选项使用Storage Gateway的卷网关。卷网关提供了一个本地缓存，可以加速对常用数据的访问。数据最终存储在S3中，满足了成本和扩展的需求。对于需要快速访问数据子集的情况，卷网关可以提供最佳性能。",
      "why_wrong": "A选项虽然可以将数据迁移到S3，但没有缓存机制，无法满足快速访问子集数据的需求。B选项使用文件网关，适用于文件共享，对于制药公司的大量数据和快速访问的需求，不如卷网关合适。D选项使用EFS，EFS的成本较高，且不适合作为长期存储解决方案。"
    },
    "related_terms": [
      "AWS Storage Gateway",
      "Amazon S3",
      "EFS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 768,
    "topic": "",
    "question_cn": "一个公司有一个业务关键的应用程序运行在Amazon EC2实例。应用程序将数据存储在Amazon DynamoDB表中。公司必须能够在过去24小时内将表格恢复到任何位置。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "配置表的点时恢复。",
      "B": "对表使用AWS Backup。",
      "C": "使用一个Lambda功能，每小时按需对桌子进行备份。",
      "D": "打开表上的流捕捉过去24小时内表上所有更改的日志。在Amazon S3桶中存储一条河的拷贝。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB Point-in-time Recovery (PITR)",
      "DynamoDB Backup and Restore"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，DynamoDB的点时恢复(PITR)功能，能够在过去35天内的任何时间点恢复表，满足了快速恢复、操作开销最小的要求。",
      "why_correct": "A选项使用DynamoDB的点时恢复(PITR)功能是最佳选择。PITR提供了一种简单的方法，可以在过去35天内的任何时间点恢复表，满足了快速恢复的需求，并且操作开销最小。",
      "why_wrong": "B选项使用AWS Backup备份整个表，恢复速度不如PITR。C选项使用Lambda定时备份，需要额外的运维工作。D选项使用数据流，需要额外的开发和管理工作，且恢复速度不如PITR。"
    },
    "related_terms": [
      "Amazon EC2",
      "DynamoDB",
      "点时恢复",
      "AWS Backup",
      "Lambda",
      "流",
      "Amazon S3"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 769,
    "topic": "",
    "question_cn": "一个公司拥有一个应用程序，用来将文件上传到一个Amazon S3桶。一旦上传文件将被处理以提取元数据，这需要不到5秒钟。上传的数量和频率从每小时几个文件到同时上传数百个文件不等。该公司已经请解决方案设计师设计一个符合这些要求的成本效益高的架构。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "配置Amazon S3 API，AWS CloudTrail路径以记录S3 API调用。使用Lambda程序处理文件。",
      "B": "在S3桶中配置一个对象创建的事件通知，以调用Lambda函数来处理文件。",
      "C": "配置Amazon Kinesis Data Streams以处理和发送数据到Amazon S3。调用一个Lambda函数来处理文件。",
      "D": "配置一个Amazon Simple Notification Service(SNS)主题来处理上传到Amazon S3的文件。调用一个Lambda函数来处理文件。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Event Notifications",
      "Lambda"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，S3事件通知结合Lambda函数是最简单、最经济高效的解决方案，适用于触发式处理S3对象上传事件。 Kinesis Data Streams 更加复杂，适用于流数据的处理，不适合此处。",
      "why_correct": "B选项使用S3事件通知和Lambda函数。当文件上传到S3桶时，S3事件通知触发Lambda函数，可以高效、自动地处理文件。这种方案简单易用，成本较低，非常适合这个场景。",
      "why_wrong": "A选项使用CloudTrail记录S3 API调用，需要额外的处理逻辑，不如直接使用S3事件通知。C选项使用Kinesis Data Streams，对于简单的文件处理来说，过于复杂。D选项使用SNS，SNS用于发布订阅，需要额外的配置，不如S3事件通知直接。"
    },
    "related_terms": [
      "Amazon S3",
      "AWS CloudTrail",
      "Lambda",
      "S3",
      "事件通知",
      "Kinesis Data Streams",
      "SNS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 770,
    "topic": "",
    "question_cn": "一个公司的应用程序部署在Amazon EC2实例中，并在事件驱动的体系结构中使用Lambda函数。该公司使用非生产开发环境在不同的AWS账户测试新的特性之前，该公司部署的特性到生产。生产实例显示出由于客户在不同的时区中的经常使用，公司只在工作日的办公时间使用非生产实例。公司周末不使用非生产实例。该公司希望优化成本以运行它的应用程序。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "对生产实例使用按需实例。只在周末使用非生产实例专用主机。",
      "B": "为生产实例和非生产实例使用保留的实例。在不使用时关闭非生产实例。",
      "C": "对生产实例使用计算节约计划。非生产实例按需使用实例。在不使用时关闭非生产实例。",
      "D": "使用生产实例专用主机。对非生产实例使用实例节约计划。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Compute Savings Plans",
      "Reserved Instances"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，计算节约计划(Compute Savings Plans)可以为EC2实例提供灵活的定价，并对按需实例提供折扣。在非生产环境中使用按需实例，可以根据需要启动和停止实例，降低成本。",
      "why_correct": "C选项使用计算节约计划(Compute Savings Plans)来优化生产实例的成本，并使用按需实例来运行非生产实例。计算节约计划对持续运行的生产实例可以提供折扣，而对仅在工作日使用的非生产实例使用按需实例，可以最大限度地降低成本。",
      "why_wrong": "A选项对生产环境使用按需实例，成本较高。B选项为生产和非生产环境使用保留实例，如果非生产环境实例在周末关闭，则不能充分利用保留实例。D选项使用专用主机，成本比计算节约计划更高。"
    },
    "related_terms": [
      "Amazon EC2",
      "Lambda",
      "按需实例",
      "专用主机",
      "保留的实例",
      "计算节约计划",
      "实例节约计划"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 771,
    "topic": "",
    "question_cn": "一家公司将数据存储在内部的甲骨文关系数据库中。该公司需要将数据提供在Amazon Aurora后的分析。该公司使用一个站点到站点的VPN连接以连接其内部网络到AWS。公司必须捕捉源数据库在迁移到Aurora后的期间发生的更改。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用AWS Schema Conversion Tool(AWS SCT)来将甲骨文架构转换为Aurora后的架构。使用AWS Database Migration Service(AWS DMS) 来迁移数据。",
      "B": "使用AWS DMS将数据迁移到一个Amazon S3桶。通过使用Aurora MySQL扩展将数据导入到后Aurora。",
      "C": "使用AWS Schema Conversion Tool(AWS SCT) 来将甲骨文架构转换为Aurora后的架构。使用AWS Database Migration Service(AWS DMS) 迁移现有数据并复制正在进行的更改。",
      "D": "使用Snowball设备将数据迁移到Amazon S3桶。通过使用Aurora MySQL扩展将数据导入到后Aurora。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DMS",
      "AWS SCT",
      "Oracle to Aurora MySQL Migration"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，AWS DMS结合AWS SCT可以实现从Oracle到Aurora的数据库迁移，包括架构转换和持续的数据复制，以捕获源数据库的更改。",
      "why_correct": "C选项使用AWS DMS和AWS SCT。AWS SCT可以将Oracle数据库架构转换为Aurora MySQL架构。AWS DMS可以迁移数据，并持续复制更改。这种方案能够满足数据迁移、架构转换和持续数据同步的需求。",
      "why_wrong": "A选项缺少持续数据同步的能力。B选项没有提及架构转换，也没有持续数据同步。D选项使用Snowball，适用于大规模数据迁移，但是缺少持续数据同步，并且不适合频繁的数据更新。"
    },
    "related_terms": [
      "甲骨文",
      "Amazon Aurora",
      "AWS SCT",
      "AWS DMS",
      "Amazon S3",
      "Aurora MySQL",
      "VPN",
      "Snowball"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 772,
    "topic": "",
    "question_cn": "一家公司用Docker容器构建了一个应用程序，需要在AWS云中运行该应用程序。公司希望使用托管服务来托管应用程序。该解决方案必须根据各个集装箱服务的需求适当地扩展和扩展。解决方案也不应导致额外的业务管理费用或基础设施管理。哪些解决方案能满足这些要求？(选二)",
    "options_cn": {
      "A": "使用Amazon Elastic Container Service(Amazon ECS)与AWS Fargate。",
      "B": "使用Amazon Elastic Kubernetes Service(Amazon EKS)与AWS Fargate。",
      "C": "提供一个Amazon API Gateway API。将API连接到AWS Lambda来运行容器。",
      "D": "使用Amazon Elastic Container Service(Amazon ECS)与Amazon EC2工人节点。",
      "E": "使用Amazon Elastic Kubernetes Service(Amazon EKS)与Amazon EC2工人节点。"
    },
    "vote_percentage": "67%",
    "tags": [
      "ECS Fargate",
      "EKS Fargate"
    ],
    "explanation": {
      "analysis": "正确答案：AC。使用ECS Fargate和Lambda可以实现容器的托管、自动伸缩，并且无需管理底层基础设施，减少了运维开销。EKS Fargate可以实现容器化应用的部署，但选项提供的方案并不完整。 使用EC2 worker nodes需要运维。",
      "why_correct": "A: 使用ECS Fargate，完全托管的容器服务，无需管理底层基础设施，满足了自动伸缩和减少运维开销的要求。 C: 使用API Gateway和Lambda，可以运行容器，并提供API接口，满足了自动伸缩和减少运维开销的要求。",
      "why_wrong": "B: EKS Fargate虽然也提供了容器服务，但是选项中并未完全呈现。 D、E: 使用EC2 worker nodes需要运维。"
    },
    "related_terms": [
      "Docker",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon EKS",
      "Amazon EC2",
      "Amazon API Gateway",
      "AWS Lambda"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 773,
    "topic": "",
    "question_cn": "一家电子商务公司正在进行一次季节性的在线销售。该公司在Amazon EC2实例上的网站覆盖多个可用性区域。该公司希望其网站能够管理销售过程中突然增加的流量。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个大到足以处理高峰流量负载的自动缩放组。停止一半的Amazon EC2实例。配置自动缩放组以便在流量增加时使用停止的实例进行缩放。",
      "B": "为网站创建一个自动缩放组。设置自动缩放组的最小尺寸以便它能够处理高流量而无需扩展。",
      "C": "使用Amazon CloudFront和Amazon ElastiCache动态内容与一个自动标度组设置的起源。配置自动缩放组的实例以填充CloudFront和ElastiCache。在缓存完全填充后进行扩展。",
      "D": "配置一个自动缩放组以便随着流量的增加而扩展。创建一个启动模板以从预先配置的Amazon机器映像开始新的实例。"
    },
    "vote_percentage": "80%",
    "tags": [
      "EC2 Auto Scaling",
      "Launch Template"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，创建自动缩放组结合启动模板是最有效的方案，可以根据流量动态扩展EC2实例，满足处理突增流量的需求。",
      "why_correct": "D选项使用自动缩放组结合启动模板，可以根据流量的增加自动启动新的EC2实例，满足了快速扩展的需求，启动模板可以确保新实例配置一致。并且能处理高流量负载。",
      "why_wrong": "A选项停止实例并使用停止的实例缩放，不能立即响应流量的增加。B选项设置固定大小的自动缩放组，无法应对流量峰值。C选项使用CloudFront和ElastiCache，适用于内容缓存，不直接解决服务器扩容问题。"
    },
    "related_terms": [
      "Amazon EC2",
      "自动缩放组",
      "CloudFront",
      "ElastiCache",
      "启动模板"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 774,
    "topic": "",
    "question_cn": "解决方案架构师必须为公司的合规策略提供自动化解决方案，该策略声明安全组不能包含允许0.0.0.0/0的SSH规则。如果有任何违规行为，需要通知公司。需要尽快找到解决办法。解决方案架构师应该如何用最少的操作开销来满足这些需求？",
    "options_cn": {
      "A": "编写一个AWS Lambda脚本，该脚本监视向0.0.0.0/0地址开放的安全组，并在每次找到一个地址时创建一个Amazon SNS通知。",
      "B": "启用受限制的SSH配置管理规则，并在创建不符合规则时生成Amazon SNS通知。",
      "C": "创建一个具有IAM权限的角色，允许全局打开安全组和网络ACLs。创建一个Amazon SNS主题以便每次用户承担这个角色时生成通知。",
      "D": "配置一个服务控制策略(SCP)，防止非管理用户创建或编辑安全组。当用户请求需要管理员权限的规则时，在票务系统中创建通知。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Group",
      "AWS Config",
      "SNS"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是，AWS Config规则可以自动检测安全组是否违反了安全组的规则，并触发SNS通知。",
      "why_correct": "B选项启用AWS Config规则，当创建不符合规则的安全组时，触发SNS通知。AWS Config可以自动监控和评估安全组配置，当发现0.0.0.0/0规则时，触发警报，符合安全合规要求，操作简单。",
      "why_wrong": "A选项使用Lambda脚本轮询检查安全组，增加了运维成本，并且无法实时响应。C选项创建IAM角色，虽然可以限制权限，但没有解决自动检测和通知的问题。D选项使用SCP，虽然可以阻止不合规操作，但无法检测和通知现有的违规行为。"
    },
    "related_terms": [
      "SSH",
      "安全组",
      "AWS Lambda",
      "Amazon SNS",
      "受限制的SSH配置管理",
      "SCP",
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 775,
    "topic": "",
    "question_cn": "一个公司已经将一个应用程序部署到一个AWS账户中。该应用程序由运行在Lambda和Amazon Elastic Kubernetes Service(Amazon EKS)上的微服务组成。一个单独的团队支持每个微服务。该公司有多个AWS账户，并希望为每个团队提供自己的微服务账户。解决方案架构师需要设计一个解决方案，它将在HTTPS(443)端口上提供服务到服务的通信。解决方案还必须为服务发现提供一个服务注册表。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个VPC检查VPC。在检查上部署AWS网络防火墙。将检查连接到一个新的过境网关上。从VPC到VPC的路线。应用防HTTPS防火墙规则只允许HTTPS通信。",
      "B": "创建一个服务网格网络。将微服务与服务网格联系起来。为每个服务定义HTTPS监听器。注册微服务计算资源作为目标。识别VPC，VPC需要与服务进行通信的VPC。将这些VPC与服务网格联系起来。",
      "C": "为每个微服务创建一个网络负载均衡器(NLB)，其中包括一个HTTPS监听器和目标组。为每个微服务创建一个私人VPC，并在VPC中创建一个VPC链接端点服务。在每个VPC中创建一个需要使用该微服务的接口端点。",
      "D": "创建包含微服务的VPC之间的窥视连接。为每个需要连接到客户端的服务创建一个前缀列表。创建路由表将流量路由到相应的VPC。创建安全组只允许HTTPS通信。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Service Mesh",
      "VPC Peering",
      "NLB"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，服务网格提供了服务间通信的解决方案，可以满足HTTPS通信和注册服务的要求，并且简化了微服务的管理。",
      "why_correct": "B选项创建一个服务网格网络。服务网格能够处理服务之间的通信，并提供服务发现和负载均衡。这个方案可以满足HTTPS通信的需求。简化了微服务管理，满足了题目中的需求。",
      "why_wrong": "A选项，VPC检查VPC和AWS网络防火墙是一种复杂的技术，不能有效解决服务间的通信，也不适合多团队的环境。C选项使用NLB和VPC接口端点，增加了复杂性和成本，不便于服务发现。D选项使用VPC对等连接，需要手动配置，管理复杂。 "
    },
    "related_terms": [
      "Lambda",
      "Amazon EKS",
      "VPC",
      "AWS 网络防火墙",
      "过境网关",
      "HTTPS",
      "服务网格",
      "NLB",
      "VPC 链接端点服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 776,
    "topic": "",
    "question_cn": "一个公司有一个移动游戏，可以读取Amazon RDS数据库实例中的大部分元数据。随着游戏越来越流行，开发人员注意到与游戏元数据负载时间相关的减缓。性能指标表明，简单地扩展数据库不会有帮助。解决方案架构师必须探索所有选项，包括快照、复制和次毫秒响应时间的能力。解决方案架构师应该建议什么来解决这些问题？",
    "options_cn": {
      "A": "带着Aurora复制品迁移数据库到Amazon Aurora。",
      "B": "将数据库迁移到具有全局表的Amazon DynamoDB。",
      "C": "在数据库的前面添加一个Amazon ElastiCache层。",
      "D": "在数据库前面添加一个用于记忆存储层的Amazon ElastiCache。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ElastiCache",
      "RDS performance optimization"
    ],
    "explanation": {
      "analysis": "注意：此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，Amazon ElastiCache可以缓存常用的查询结果，从而减少数据库的负载，从而提高响应时间。",
      "why_correct": "C选项在RDS数据库实例的前面添加Amazon ElastiCache。ElastiCache能够缓存常用数据，从而减轻数据库负载，提高查询速度，满足低延迟的需求。",
      "why_wrong": "A选项迁移到Aurora复制品，只是数据库的冗余和高可用，无法解决性能瓶颈。B选项迁移到DynamoDB，改变了数据库的类型，可能需要修改应用程序代码，并且也无法满足数据库查询性能优化。D选项，重复C选项。"
    },
    "related_terms": [
      "RDS",
      "Aurora",
      "Amazon Aurora",
      "DynamoDB",
      "ElastiCache"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 777,
    "topic": "",
    "question_cn": "一个公司使用美国世界服务组织的多帐户美国服务组织设置。该公司的安全组织单位需要与开发单位共享经批准的Amazon AWS KMS机器图像。使用密钥管理服务加密快照创建了。( ) 哪种解决方案能满足这些要求？ 选二。",
    "options_cn": {
      "A": "将开发团队的 亚马逊资源名称 添加到非苏特派团的发射许可列表中。",
      "B": "添加组织根亚马逊资源名称 到发射许可清单的非苏特派团。",
      "C": ", OU AWS KMS更新密钥策略允许开发团队的 使用用于解密快照的键。",
      "D": "将开发团队的帐户亚马逊资源名称 添加到非苏特派团的发射许可列表中。",
      "E": ", AWS KMS娱乐的是美国卫生局的关键。添加一个关键策略允许组织根亚马逊资源名称 使用键。"
    },
    "vote_percentage": "100%",
    "tags": [
      "KMS",
      "Multi-Account Setup"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BC，但社区共识(投票最高)为AC。社区倾向AC的原因是：需要通过KMS密钥策略授权访问，并且要确保开发团队的账户能访问加密的AMI。选项A和C分别从IAM和KMS策略角度解决了这个问题。",
      "why_correct": "选项A允许授权特定账户访问，选项C通过KMS密钥策略控制访问，两者共同实现了需求。这两个选项是解决问题的关键。",
      "why_wrong": "选项B 仅添加了组织根账户，无法满足特定团队的访问需求。选项D同A，但少了C的关键授权；选项E是错误的，因为该题是关于KMS密钥策略，而不是安全组。"
    },
    "related_terms": [
      "AWS KMS",
      "IAM",
      "快照",
      "亚马逊资源名称"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 778,
    "topic": "",
    "question_cn": "一家数据分析公司有 80 个办公室分布在全球各地。每个办公室拥有 1 至 2 千兆字节的互联网带宽。该公司需要一次性地将大量数据从其办公室迁移到Amazon S3。公司必须在 4 周内完成迁移。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "建立一个新的 10Gbps 直接连接连接到每个办公室 将数据传输到Amazon S3。",
      "B": "使用多个雪球边缘存储器优化设备存储和传输数据到Amazon S3。",
      "C": "使用雪车存储和传输数据到Amazon S3。",
      "D": "建立一个存储网关将数据传输到Amazon S3。"
    },
    "vote_percentage": "88%",
    "tags": [
      "S3 Data Migration",
      "Snowball Edge"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为B。社区倾向B的原因是：对于全球分布的办公室，需要考虑网络带宽的限制。Snowball Edge 提供了数据存储和离线传输的能力，适合这种场景。",
      "why_correct": "选项B：Snowball Edge 提供了数据预处理和离线传输的能力，非常适合带宽有限且需要在限定时间内完成大量数据传输的场景。 多个设备可以加速迁移过程。",
      "why_wrong": "选项A: 直接连接方案需要每个办公室都有高速网络连接，且部署复杂，成本高。选项C：Snowmobile 主要针对PB级数据，对于每个办公室只有几TB数据的场景，成本过高且不灵活。选项D：存储网关适合持续的混合云存储场景，不适合一次性数据迁移。"
    },
    "related_terms": [
      "Amazon S3",
      "雪球边缘存储器",
      "雪车",
      "存储网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 779,
    "topic": "",
    "question_cn": "一个公司有一个Amazon EFS文件系统，其中包含一个参考数据集。该公司在Amazon EC2实例上有需要读取数据集的应用程序。但是应用程序不能更改数据集。公司希望使用IAM访问控制来阻止应用程序修改或删除数据集。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "从EC2实例中以只读模式安装EFS文件系统。",
      "B": "为EFS文件系统创建一个资源策略，该策略拒绝使用弹性文件系统客户端编写附加到EC2实例的角色的操作。",
      "C": "为EFS文件系统创建一个拒绝弹性文件系统客户端编写文件系统上操作的标识策略。",
      "D": "为每个应用程序创建一个EFS访问点。使用可移植操作系统接口文件权限允许对根目录中的文件进行只读访问。"
    },
    "vote_percentage": "60%",
    "tags": [
      "EFS Access Control",
      "IAM Resource Policy"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是：IAM 资源策略提供了更细粒度的控制，可以限制 EC2 实例上应用程序对 EFS 卷的访问权限，确保了只读访问。",
      "why_correct": "选项B：使用IAM 资源策略可以精确地控制应用程序对 EFS 的访问权限，实现只读访问，更符合安全最佳实践。",
      "why_wrong": "选项A：仅在实例级别挂载只读，不够安全和灵活，无法精细控制应用程序的访问权限。选项C：身份策略作用于用户或角色，不适合限制单个文件系统的访问。选项D：访问点可以实现只读访问，但不如资源策略更灵活。"
    },
    "related_terms": [
      "Amazon EFS",
      "Amazon EC2",
      "IAM",
      "EFS",
      "EFS访问点",
      "可移植操作系统接口"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 780,
    "topic": "",
    "question_cn": "一家公司已经聘请了一个外部的供应商在该公司的AWS账户上工作。供应商使用一个自动化的工具，该工具存储在供应商拥有的AWS账户中。卖方无法进入该公司的AWS账户。该公司需要允许供应商进入该公司的AWS账户。哪个解决方案最安全地满足这些要求？",
    "options_cn": {
      "A": "IAM在公司的账户中创建一个角色以授权对供应商角色的访问。将适当的策略附加到供应商所需权限的角色上。",
      "B": "IAM在公司账户中创建一个符合密码复杂性要求的用户。为供应商要求的权限向用户附加适当的策略。",
      "C": "IAM在公司账户中创建一个组。将自动化工具的用户从供应商帐户添加到组中。将适当的策略附加到供应商要求的权限组中。",
      "D": "IAM在公司的账户中创建一个用户它具有允许卖方帐户的权限边界。为供应商要求的权限向用户附加适当的策略。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM",
      "Cross-Account Access"
    ],
    "explanation": {
      "analysis": "核心考点：跨账户访问的最佳实践，使用 IAM 角色来实现权限委派，而非直接创建用户或使用权限边界。",
      "why_correct": "选项A:  使用 IAM 角色允许供应商通过 AssumeRole 方式访问客户账户，符合最小权限原则。供应商的自动化工具可以在自己的账户中担任一个角色，该角色具有访问客户账户中资源的权限。这是最安全、最灵活的解决方案。",
      "why_wrong": "选项B:  创建IAM用户需要创建长期访问密钥，存在安全隐患，并且需要直接管理用户凭证。选项C: 将用户添加到组可以简化策略管理，但仍需要管理用户凭证，不够安全。选项D: 权限边界限制了用户的权限，但仍然需要管理长期密钥，不推荐使用。"
    },
    "related_terms": [
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 781,
    "topic": "",
    "question_cn": "一家公司希望在云中运行其实验工作量。该公司有云支出预算。该公司的首席财务官担心每个部门的云支出责任。首席财务官希望在支出门槛达到预算的60%时收到通知。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用成本分配标签在资源标签所有者。在美国卫生部预算中创建使用预算。当支出超过预算的60%时添加一个报警阈值以接收通知。",
      "B": "使用成本资源管理器预测来确定资源所有者。当支出超过预算的60%时使用成本异常检测来创建报警阈值通知。",
      "C": "使用成本分配标签在资源标签所有者。当支出超过预算的60%时使用支持来创建警报阈值通知。",
      "D": "使用成本资源管理器预测来确定资源所有者。在美国卫生部预算中创建使用预算。当支出超过预算的60%时添加一个报警阈值以接收通知。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Budgets",
      "Cost Allocation Tags"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 AWS Budgets 进行成本监控和告警通知，并结合成本分配标签进行部门级别的成本追踪。",
      "why_correct": "选项A: 使用成本分配标签可以按资源所有者（部门）进行成本细分。然后，创建AWS预算，设置阈值，当达到60%的预算时触发告警通知。",
      "why_wrong": "选项B: 成本异常检测主要用于识别意外的成本变化，而非预算监控。选项C: AWS Support 不能用于设置成本阈值告警。选项D: 成本资源管理器预测用于预测成本，不是设置预算和告警的方式。"
    },
    "related_terms": [
      "成本分配标签",
      "使用预算",
      "报警阈值",
      "成本资源管理器",
      "成本异常检测"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 782,
    "topic": "",
    "question_cn": "一个公司想在AWS上部署一个内部Web应用程序。网站应用程序只能从公司办公室访问。该公司需要从互联网下载网络应用的安全补丁。VPC, AWS VPN Web该公司已经创建了一个并配置了一个网站到现场的连接到该公司的办公室。解决方案架构师必须为应用程序设计一个安全的架构。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将Web应用程序部署到Amazon EC2实例中放在公共应用程序负载平衡器后面的公共子网络中。在公共子网络上附加一个互联网网关。将安全组的入站源设置为0.0.0/0。",
      "B": "将Web应用程序部署到Amazon EC2实例中放在内部应用程序负载平衡器后面的私人子网中。在公共子网络中部署NAT网关。在VPN连接的CIDR块上附加一个互联网网关。将安全组的入站源设置到公司的办公室网络块。",
      "C": "将Web应用程序部署到Amazon EC2实例中的公共子网络中在内部应用程序负载平衡器后面。在私有子网中部署NAT网关。在VPN连接的CIDR块上附加一个互联网网关到VPC。设置安全组的出站目的地。",
      "D": "将Web应用程序部署到Amazon EC2实例中放在公共应用程序负载平衡器后面的私人子网中。在AWS上附加一个互联网网关。将安全组的出站目的地设置为0.0.0/0。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC",
      "NAT Gateway",
      "VPN",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "核心考点:  内部Web应用程序的安全部署，需要通过VPN连接到公司网络，以及通过 NAT 网关访问互联网下载安全补丁。以及安全组的配置。",
      "why_correct": "选项B: 将Web应用程序部署在私有子网中，通过内部负载均衡器访问，确保Web应用不能直接从公网访问。NAT网关允许实例访问互联网下载补丁，VPN连接保证了应用程序和办公室之间的安全通信，安全组的配置也保证了访问的安全性。",
      "why_wrong": "选项A: 将实例放在公共子网中，直接暴露在公网，不安全。安全组配置0.0.0/0意味着允许所有流量进入，极不安全。选项C: NAT网关部署的位置错误，出站目的地设置错误。选项D: 将应用部署在私有子网中，没有互联网访问，无法下载补丁。"
    },
    "related_terms": [
      "VPC",
      "Amazon EC2",
      "应用程序负载平衡器",
      "公共子网络",
      "互联网网关",
      "安全组",
      "NAT网关",
      "AWS VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 783,
    "topic": "",
    "question_cn": "一家公司在运行于Amazon EC2实例的定制应用程序中维护其会计记录。为了开发和维护应用程序数据公司需要将数据迁移到托管AWS的服务中。解决方案必须需要最小的操作支持并提供不可变的、可密码验证的数据更改日志。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "将应用程序的记录复制到Amazon Redshift集群中。",
      "B": "将应用程序的记录复制到Amazon Neptune集群中。",
      "C": "将应用程序的记录复制到Amazon Timestream数据库中。",
      "D": "将应用程序的记录复制到Amazon量子分类账数据库的分类账中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "QLDB",
      "Ledger Database"
    ],
    "explanation": {
      "analysis": "核心考点: 选择合适的数据库，需要满足不可变、可密码验证的数据变更日志的要求。Amazon QLDB 正是为此设计的。",
      "why_correct": "选项D: Amazon QLDB (Quantum Ledger Database) 是一种完全托管的分类账数据库，提供了不可变的、可验证的交易日志，满足题目的所有需求，最适合。",
      "why_wrong": "选项A: Amazon Redshift是数据仓库，不具备不可变日志的功能。选项B: Amazon Neptune 是图数据库，不适合会计记录存储。选项C: Amazon Timestream是时间序列数据库，不适合作为事务账本。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon Redshift",
      "Amazon Neptune",
      "Amazon Timestream",
      "Amazon量子分类账数据库"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 784,
    "topic": "",
    "question_cn": "一个公司的营销数据是从多个来源上传到一个Amazon S3桶。一系列数据准备工作汇总数据以供报告。数据准备工作需要定期并行运行。一些工作需要以后按特定的顺序进行。该公司希望去除作业错误处理、重试逻辑和状态管理的操作开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "一旦数据上传到S3桶中就使用Lambda函数来处理数据。在定期的时间间隔调用其他的Lambda函数。",
      "B": "使用Amazon Athena处理数据。使用Amazon EventBridge调度器调用Athena在一个正常的内部。",
      "C": "使用AWS Glue数据处理数据。使用一个步骤函数状态机来运行数据准备工作。",
      "D": "使用数据管道来处理数据。安排数据管道在午夜处理一次数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Glue",
      "Step Functions"
    ],
    "explanation": {
      "analysis": "核心考点:  利用 AWS Glue 进行数据准备和 ETL，并通过 Step Functions 实现工作流编排，以满足并行、顺序执行、错误处理、重试以及状态管理的需求。",
      "why_correct": "选项C:  AWS Glue 提供了 ETL (提取、转换、加载) 的功能，Step Functions 可以编排多个 Glue 作业，支持并行和顺序执行、错误处理、重试等功能，可以简化作业管理。",
      "why_wrong": "选项A: Lambda 函数适用于简单的处理任务，对于复杂的数据准备工作，操作复杂度较高。选项B: Amazon Athena 适用于查询，不具备数据准备和工作流编排的功能。选项D: 数据管道功能有限，不具备 Glue 和 Step Functions 的灵活性。"
    },
    "related_terms": [
      "Amazon S3",
      "Lambda",
      "Amazon Athena",
      "Amazon EventBridge",
      "AWS Glue",
      "步骤函数"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 785,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个支付处理应用程序，该应用程序在多个可用性区域的私有子网上运行。该应用程序使用多个Lambda函数每天处理数百万个事务。架构必须确保应用程序不处理重复支付。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Lambda收回所有到期付款。发布Amazon S3桶到期付款。配置带有事件通知的S3桶以调用另一个Lambda函数来处理到期付款。",
      "B": "使用Lambda收回所有到期付款。发布对Amazon SQS队列的到期付款。配置另一个Lambda函数以对队列进行轮询并处理到期付款。",
      "C": "使用Lambda收回所有到期付款。发布对Amazon SQS FIFO队列的到期付款。配置另一个Lambda函数以对FIFO队列进行轮询并处理到期付款。",
      "D": "使用Lambda收回所有到期付款。将到期付款存储在Amazon DynamoDB表上。配置 DynamoDB表上的流以调用另一个Lambda函数来处理到期付款。"
    },
    "vote_percentage": "73%",
    "tags": [
      "SQS FIFO",
      "Lambda",
      "Duplicate Processing"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 SQS FIFO 队列保证消息的顺序处理，从而避免重复支付。FIFO (First-In-First-Out) 队列确保了消息按照发送的顺序被处理。",
      "why_correct": "选项C: SQS FIFO 队列确保消息的顺序处理。通过Lambda函数从FIFO队列中读取消息，可以避免重复支付。FIFO队列可以保证顺序，并且只处理一次，完美符合需求。",
      "why_wrong": "选项A: S3 桶事件无法保证消息顺序，可能会导致重复处理。选项B: SQS 标准队列不能保证消息的顺序，可能会导致重复支付。选项D: DynamoDB流不能保证消息的顺序，并且处理逻辑复杂，不推荐。"
    },
    "related_terms": [
      "Lambda",
      "Amazon S3",
      "Amazon SQS",
      "FIFO",
      "Amazon DynamoDB"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 786,
    "topic": "",
    "question_cn": "公司在其内部数据中心运行多个工作负载。该公司的数据中心规模不够快无法满足该公司不断扩大的业务需求。该公司希望收集有关酒店内服务器和工作负载的使用和配置数据以计划向AWS的迁移。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在AWS在美国航空航天系统迁移枢纽中设置家庭航空航天系统区域。使用系统管理器来收集有关现场服务器的数据。",
      "B": "在AWS在美国航空航天系统迁移枢纽中设置家庭航空航天系统区域。使用应用程序发现服务来收集有关酒店内服务器的数据。",
      "C": "使用架构转换工具创建相关模板。使用信任的顾问来收集有关现场服务器的数据。",
      "D": "使用架构转换工具创建相关模板。使用数据库迁移服务来收集有关现场服务器的数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Migration Hub",
      "Application Discovery Service"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 AWS Migration Hub 和 Application Discovery Service (应用程序发现服务) 来收集关于本地服务器和工作负载的信息，为迁移做准备。",
      "why_correct": "选项B:  AWS Migration Hub 提供了一个集中位置来跟踪迁移进度。 应用程序发现服务（Application Discovery Service）可以帮助收集有关本地服务器和工作负载的信息，包括服务器配置和使用情况，为迁移规划提供依据。",
      "why_wrong": "选项A:  系统管理器主要用于管理AWS上的资源，不能直接收集本地服务器的信息。选项C: 架构转换工具和信任的顾问不能收集服务器配置和使用情况的信息。选项D:  数据库迁移服务用于数据库迁移，不适用于一般的服务器信息收集。"
    },
    "related_terms": [
      "AWS",
      "Amazon EC2",
      "AWS",
      "AWS",
      "系统管理器",
      "架构转换工具",
      "数据库迁移服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 787,
    "topic": "",
    "question_cn": "一个公司有一个组织在美国职业安全协会的组织具有所有功能启用。该公司要求所有API调用和登录任何现有或新的AWS账户必须被AWS审计。公司需要有管理的解决方案来防止额外的工作并将成本降至最低。该公司还需要知道任何账户何时不符合安全最佳实践(FSBP)标准。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在组织管理帐户中部署一个控制塔环境。在环境中启用AWS Security Hub和AWS Control Tower 帐户工厂。",
      "B": "在一个专门的组织成员帐户中部署一个控制塔环境。在环境中启用AWS Security Hub和AWS Control Tower 帐户工厂。",
      "C": "利用托管服务加速建立多帐户着陆区。提交一个自助服务提供亚马逊保护在马尔兹。",
      "D": "利用托管服务加速建立多帐户着陆区。提交一个为自助服务提供的美国信息系统安全枢纽在马尔兹。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Control Tower",
      "AWS Security Hub"
    ],
    "explanation": {
      "analysis": "核心考点: 使用AWS Control Tower和Security Hub来实现多账户环境的管理，安全合规审计以及集中化的管理。",
      "why_correct": "选项A: 在管理账户中使用Control Tower可以简化多账户的管理，并且Security Hub能提供安全合规的审计，并报告安全问题。",
      "why_wrong": "选项B: 部署在成员账户不如部署在管理账户好。选项C,D:  这些选项无法实现账户级别的安全审计和合规性。"
    },
    "related_terms": [
      "AWS",
      "AWS",
      "AWS Security Hub",
      "AWS Control Tower"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 788,
    "topic": "",
    "question_cn": "一家公司已经在一个Amazon S3桶中存储了10TB的阿帕奇拼花格式的日志文件。公司偶尔需要使用SQL来分析日志文件。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个Amazon Aurora数据库。通过使用数据库迁移服务将数据从S3桶迁移到极光。向极光数据库发布SQL语句。",
      "B": "创建一个Amazon Redshift集群。使用红移光谱直接在S3桶中的数据上运行SQL语句。",
      "C": "创建一个Glue爬虫从S3桶中存储和检索表元数据。使用Amazon Athena直接在S3桶中的数据上运行SQL语句。",
      "D": "创建一个Amazon EMR集群。使用阿帕奇火花直接在S3桶中的数据上运行SQL语句。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Athena",
      "S3",
      "SQL"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 Amazon Athena 直接查询 S3 桶中的 Parquet 格式的日志文件，无需 ETL 和数据仓库，实现低成本的即时查询。",
      "why_correct": "选项C: 使用 Amazon Athena 可以直接查询 S3 中的数据，无需预先加载，成本低，适合临时查询。Glue爬虫用于创建表的元数据，方便Athena查询。",
      "why_wrong": "选项A: Aurora不是用来分析大量日志数据的。选项B: Redshift 需要将数据导入集群，增加了复杂度和成本。选项D: EMR需要配置和管理，不如 Athena 简单。"
    },
    "related_terms": [
      "Amazon S3",
      "Amazon Aurora",
      "数据库迁移服务",
      "Amazon Redshift",
      "红移光谱",
      "Glue",
      "Amazon Athena",
      "Amazon EMR",
      "阿帕奇火花"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 789,
    "topic": "",
    "question_cn": "一个公司需要一个解决方案来防止云集堆栈部署IAM资源，其中包括一个内联策略或声明中的'*'。解决方案还必须禁止使用公共IP地址部署Amazon EC2实例。该公司在其组织中使用了AWS Control Tower。",
    "options_cn": {
      "A": "使用Control Tower主动控制来阻止使用公共IP地址和高访问率或*的内联策略部署EC2实例。",
      "B": "使用Control Tower检测控件来阻止使用公共IP地址和具有更高访问率或*的内联策略的实例的部署。",
      "C": "使用服务控制策略来阻止EC2实例和IAM资源的操作如果这些操作导致不遵守。"
    },
    "vote_percentage": "64%",
    "tags": [
      "SCP",
      "Control Tower",
      "IAM"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是：使用 Control Tower 的主动控制，可以更好地实施安全策略，并且主动预防违规行为，而不是仅仅检测。",
      "why_correct": "选项A:  使用 Control Tower 的主动控制功能，可以阻止带有特定内联策略或使用公共 IP 地址的 EC2 实例部署，从而主动防止安全风险。",
      "why_wrong": "选项D:  SCP 提供了阻止不合规操作的能力，但无法阻止使用了 `*` 的内联策略。选项B:  Control Tower 的检测控制只能检测违规行为，无法阻止。选项C: 选项和D相同，都是利用SCP进行阻止，但无法阻止使用 `*`的内联策略。"
    },
    "related_terms": [
      "IAM",
      "EC2",
      "AWS Control Tower",
      "服务控制策略"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 790,
    "topic": "",
    "question_cn": "一家公司的Web应用程序最近越来越受欢迎。网络应用程序目前存在于一个公共子网中的一个Amazon EC2实例中。应用无法满足网络流量增加的需求。该公司需要一个解决方案将提供高可用性和可伸缩性以满足用户增加的需求而不改写Web应用程序。哪些步骤组合将满足这些要求？ 选二。",
    "options_cn": {
      "A": "用更大的计算优化实例替换EC2实例。",
      "B": "在私有子网中配置Amazon自动缩放多个可用区域。",
      "C": "配置NAT网关来处理Web请求。",
      "D": "用一个较大的内存优化实例替换EC2实例。",
      "E": "配置公共子网中的应用程序负载平衡器以分配流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "核心考点:  实现Web应用程序的高可用性和可伸缩性，需要使用负载均衡器和自动伸缩。",
      "why_correct": "选项B:  在私有子网中使用自动伸缩可以自动扩展EC2实例，满足流量增长的需求，并且增加了可用性。选项E:  应用程序负载均衡器用于分发流量，提高应用程序的可用性和弹性。",
      "why_wrong": "选项A:  替换实例无法解决高可用性和自动伸缩的问题。选项C: NAT网关用于提供网络地址转换，不是解决高可用性和可伸缩性的方案。选项D: 替换更大的实例可以提供更高的性能，但是不能解决可用性和伸缩性的问题。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon",
      "自动缩放",
      "NAT网关",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 791,
    "topic": "",
    "question_cn": "一个公司有使用环境变量的Lambda功能。该公司不希望其开发人员用纯文本看到环境变量。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将代码部署到Amazon EC2实例而不是使用Lambda函数。",
      "B": "将SSL加密配置到用于存储和加密环境变量的Lambda函数上。",
      "C": "在证书管理器中创建一个证书。配置用于使用该证书对环境变量进行加密的Lambda函数。",
      "D": "创建一个KMS密钥管理服务密钥。启用Lambda函数上的加密助手使用密钥存储和加密环境变量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "KMS",
      "Lambda",
      "Environment Variables"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 KMS (密钥管理服务) 对 Lambda 函数的环境变量进行加密，保护敏感信息，防止明文泄露。",
      "why_correct": "选项D:  KMS 允许加密环境变量，保护敏感信息。通过启用Lambda函数上的加密助手，使用KMS密钥可以安全地存储和加密环境变量。",
      "why_wrong": "选项A:  将代码部署到 EC2 实例，无法保护环境变量。选项B:  SSL 仅用于加密传输中的数据，不适用于加密存储的环境变量。选项C:  证书管理器主要用于 SSL/TLS 证书的管理，不能用于加密环境变量。"
    },
    "related_terms": [
      "Lambda",
      "Amazon EC2",
      "SSL",
      "KMS",
      "KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 792,
    "topic": "",
    "question_cn": "一家分析公司使用亚马逊VPC运行其多层服务。该公司希望使用API向数以百万计的用户提供网络分析服务。用户必须通过使用API身份验证服务来访问 API来验证。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "为用户身份验证配置一个亚马逊密码用户池。实现亚马逊 API网关REST与授权人。",
      "B": "为用户身份验证配置一个亚马逊密码标识池。实现亚马逊 API网关的httpAPI与一个密码授权人。",
      "C": "配置一个拉姆达函数来处理用户身份验证。实现亚马逊 API网关REST与一个兰布达授权人。",
      "D": "配置IAM用户来处理用户身份验证。使用IAM授权人实现亚马逊 API网关。"
    },
    "vote_percentage": "85%",
    "tags": [
      "API Gateway",
      "Cognito"
    ],
    "explanation": {
      "analysis": "此题考察 API 网关和用户认证方案的选择。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是 Cognito 用户池是用于用户认证的成熟服务，与 API 网关集成简单，满足题干需求。",
      "why_correct": "选项A使用 Amazon Cognito 用户池进行身份验证，并使用 API 网关的授权人。这提供了安全且可扩展的解决方案，并且 Cognito 能够处理数百万用户的身份验证需求。",
      "why_wrong": "选项B使用 Cognito 标识池，标识池主要用于授权访问 AWS 资源，而非用户身份验证。选项C使用 Lambda 授权人，增加了复杂性，且维护成本较高。选项D使用 IAM 用户，不适合终端用户身份验证。"
    },
    "related_terms": [
      "VPC",
      "API",
      "API",
      "亚马逊密码用户池",
      "API网关",
      "REST",
      "HTTP API",
      "Lambda",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 793,
    "topic": "",
    "question_cn": "一家公司有一个面向客户的移动应用程序。该应用程序的数据是敏感的必须在休息时加密。该公司使用的是美国卫生局的关键管理 (KMS) 服务。该公司需要一个解决方案防止意外删除KMS密钥。当用户试图删除密钥时，解决方案必须使用亚马逊简单通知服务 (SNS) 向管理员发送电子邮件通知。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个亚马逊事件桥规则当用户试图删除密钥时做出反应。配置该规则取消密钥的任何删除。添加SNS配置规则将其作为事件桥规则的目标。创建一个通知管理员的主题。",
      "B": "创建一个具有自定义逻辑的拉姆达函数以防止密钥删除。当用户试图删除密钥时创建一个亚马逊云表警报。创建一个亚马逊事件桥接规则当执行删除键操作时调用函数。创建一个SNS主题。请配置事件桥规则以发布通知管理员的消息。",
      "C": "创建一个亚马逊事件桥规则当删除密钥操作执行时作出反应。将规则配置为启动一个系统管理器自动化运行记录簿。配置运行簿以取消删除密钥。创建一个SNS主题。请配置事件桥规则以发布通知管理员的消息。",
      "D": "创建一个云径。配置路径将日志传递到一个新的亚马逊云表日志组。为云表日志组创建一个基于公制滤波器的云表警报。在执行删除操作时将警报配置为使用亚马逊信噪比通知管理员。"
    },
    "vote_percentage": "80%",
    "tags": [
      "KMS",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "此题考察KMS密钥保护与通知机制。注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是使用 EventBridge 监听 DeleteKey 操作，并通过 Automation Runbook 撤销删除，并发送通知，实现保护和报警。",
      "why_correct": "选项C使用 EventBridge 监听 KMS 的 DeleteKey 操作，并通过 Automation Runbook 阻止删除，并发送 SNS 通知，提供了最佳的保护和通知机制。",
      "why_wrong": "选项A虽然使用 EventBridge，但无法阻止密钥删除。选项B的Lambda方案增加了复杂性，且维护难度较高。选项D使用 CloudTrail 监控，但无法阻止删除操作，且监控与告警的实现相对复杂。"
    },
    "related_terms": [
      "KMS",
      "SNS",
      "Amazon SNS",
      "KMS",
      "Amazon",
      "亚马逊事件桥规则",
      "Lambda",
      "Amazon 云表警报",
      "云径"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 794,
    "topic": "",
    "question_cn": "一家公司希望分析并生成报告以跟踪其移动应用的使用情况。该应用程序很受欢迎并拥有全球用户群。该公司使用自定义程序来分析应用程序的使用情况。该程序在每个月的最后一周生成多个报告。这个程序需要不到10分钟的时间来完成每个报告。公司很少使用这个程序在每个月的最后一周之外生成报告，因为公司希望在要求报告时最短时间内生成报告。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "通过使用亚马逊 EC2 点播实例运行程序。当请求报告时创建亚马逊事件桥规则启动EC2实例。在每个月的最后一周连续运行EC2实例。",
      "B": "在美国的Lambda运行程序。当请求报告时创建一个亚马逊的事件桥规则来运行一个Lambda函数。",
      "C": "在亚马逊弹性集装箱服务公司运行该程序。当需要报告时安排亚马逊系统运行该程序。",
      "D": "使用亚马逊EC2点实例运行程序。当请求报告时创建一个亚马逊事件规则来启动EC2实例。在每个月的最后一周连续运行EC2实例。"
    },
    "vote_percentage": "60%",
    "tags": [
      "Lambda",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "此题考察根据需求选择计算服务的场景。最佳方案是使用 Lambda，按需运行，符合需求，成本效益高。",
      "why_correct": "选项B使用Lambda函数，可以按需运行，避免了EC2实例的持续运行成本，也符合报告生成时间短的要求。事件桥规则触发Lambda，非常灵活。",
      "why_wrong": "选项A和D使用 EC2，即使使用 Spot 实例，在没有报告时也会产生费用。选项C使用 ECS，增加了运维复杂性，不如 Lambda 简洁。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon",
      "Lambda",
      "亚马逊事件桥规则"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 795,
    "topic": "",
    "question_cn": "一家公司正在设计一个紧密耦合的高性能计算(HPC)环境在 AWS 云。该公司需要包括功能将优化环境的网络和存储。哪些解决方案能够满足这些要求？ 选二。",
    "options_cn": {
      "A": "创建一个加速器在美国世界银行全球加速器。为加速器配置自定义路由。",
      "B": "为光泽文件系统创建一个亚马逊 FSx。配置带有抓取存储的文件系统。",
      "C": "创建一个亚马逊云端分布。将查看器协议策略配置为http和https。",
      "D": "启动亚马逊 EC2实例。在实例上附加弹性织物适配器。",
      "E": "创建一个弹性豆柄部署来管理环境。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Lustre",
      "EC2 Fabric Adapter"
    ],
    "explanation": {
      "analysis": "此题考察 HPC 环境的优化方案，涉及网络和存储。答案是 FSx for Lustre (存储) 和 EC2 的 Elastic Fabric Adapter (网络)。",
      "why_correct": "选项 B (FSx for Lustre) 提供了高性能的共享文件系统，适用于 HPC 工作负载。选项 D (Elastic Fabric Adapter) 提供了低延迟、高吞吐量的网络，优化了 HPC 实例间的通信。",
      "why_wrong": "选项A：Global Accelerator 提升了全球加速性能，但主要针对访问延迟优化，并非 HPC 场景关键。选项C：CloudFront 主要用于内容分发，对 HPC 场景无直接优化作用。选项 E: Elastic Beanstalk 用于应用程序部署和管理，与 HPC 环境优化无关。"
    },
    "related_terms": [
      "HPC",
      "AWS",
      "EC2",
      "全球加速器",
      "亚马逊 FSx",
      "EC2",
      "弹性织物适配器",
      "弹性豆柄"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 796,
    "topic": "",
    "question_cn": "一个公司需要一个解决方案以防止不需要的内容的照片被上传到公司的网络应用程序。解决方案不得涉及培训机器学习模型。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊射手机自动驾驶仪创建并部署一个模型。创建一个当新照片上传时应用程序调用的实时端点。",
      "B": "创建一个使用亚马逊重新定义来检测不需要的内容的拉姆达函数。当新照片被上传时创建一个应用程序调用的Lambda URL函数。",
      "C": "创建一个亚马逊云前功能使用亚马逊理解检测不需要的内容。将该功能与应用程序关联起来。",
      "D": "创建一个使用亚马逊重新识别视频来检测不需要的内容的拉姆达功能。当新照片被上传时创建一个应用程序调用 URL 的拉姆达函数。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Rekognition",
      "Lambda"
    ],
    "explanation": {
      "analysis": "此题考察图像内容检测。要求是不能涉及机器学习模型训练。亚马逊 Rekognition 可以直接检测不当内容，符合要求。",
      "why_correct": "选项B使用 Amazon Rekognition 来检测不当内容，无需训练模型，直接使用Rekognition 的 API。Lambda 函数和 Lambda URL 提供了简便的集成方案。",
      "why_wrong": "选项A: 使用Amazon SageMaker Autopilot 涉及模型训练，不符合要求。选项C: Amazon Comprehend 主要用于自然语言处理，不适合图像内容检测。选项D: Amazon Rekognition Video 仅支持视频，不适用于照片。"
    },
    "related_terms": [
      "Amazon S3",
      "Lambda",
      "Amazon Rekognition",
      "Lambda URL",
      "Amazon Comprehend",
      "Amazon Rekognition",
      "Lambda URL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 797,
    "topic": "",
    "question_cn": "一家公司利用美国在线服务公司运行其电子商务平台。该平台对公司的运营至关重要并且拥有大量的流量和交易量。该公司配置了一个多因素身份验证(MFA)设备以确保其AWS帐户根用户凭证。如果MFA设备丢失，该公司希望确保不会失去对根用户帐户的访问权。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "设置一个备份管理员帐户如果公司失去MFA设备公司可以使用它登录。",
      "B": "为根用户帐户添加多个MFA设备来处理灾难场景。",
      "C": "当公司无法访问根帐户时创建一个新的管理员帐户。",
      "D": "当公司无法访问根帐户时将管理员策略附加到另一个IAM用户。"
    },
    "vote_percentage": "100%",
    "tags": [
      "MFA",
      "Root Account"
    ],
    "explanation": {
      "analysis": "此题考察根用户账户的安全防护措施。最佳实践是为根用户配置多个 MFA 设备，以便在设备丢失时仍能访问账户。",
      "why_correct": "选项B为根用户帐户配置多个MFA设备，可以提供冗余，在设备丢失的情况下，仍能访问根用户帐户。",
      "why_wrong": "选项A创建备份管理员账户并不能解决根用户 MFA 设备丢失的问题。选项C和D会引入安全风险，不推荐用于根用户。"
    },
    "related_terms": [
      "MFA",
      "AWS",
      "IAM"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 798,
    "topic": "",
    "question_cn": "一家社交媒体公司正在为其用户创建一个奖励计划网站。当用户创建和上传视频到网站时，公司会给用户提供点。用户从公司的关联 ID 合作伙伴那里获得礼品或折扣。唯一的标识标识用户。合作伙伴参考这个ID来验证用户获得奖励的资格。合作伙伴希望在公司提供用户点时通过端点接收用户通知。每天都有数百家供应商有兴趣成为附属合作伙伴。该公司希望设计一个架构使网站能够以可扩展的方式快速添加合作伙伴。",
    "options_cn": {
      "A": "创建一个亚马逊时间流数据库以保存一个联系伙伴的列表。实现一个拉姆达函数来读取列表。当公司给用户点时将这个 Lambda ID函数配置为向每个合作伙伴发送用户。",
      "B": "创建一个亚马逊简单通知服务 (SNS) 主题。选择一个端点协议。同意合作伙伴的话题。当公司给用户点时向主题发布用户 ID。",
      "C": "创建一个步骤函数状态机。为每个附属伙伴创建一个任务。当公司给用户点时调用带有用户 ID的状态机作为输入。",
      "D": "在亚马逊运动数据流中创建一个数据流。实现生产者和消费者的应用。在数据流中存储一个关联伙伴列表。当公司给用户点时，发送用户标识。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SNS",
      "Fanout"
    ],
    "explanation": {
      "analysis": "此题考察fanout模式的设计，即一个消息被发送给多个消费者。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是SNS 提供了fanout模式的完美实现，扩展性好，实现简单。",
      "why_correct": "选项B 使用 SNS 主题，允许公司将用户点信息发布到 SNS 主题，然后合作伙伴订阅该主题，从而接收消息，实现 fanout 模式，且易于扩展。",
      "why_wrong": "选项A使用 Timestream 数据库及 Lambda 函数实现fanout，实现复杂，性能可能受限。选项C 使用步骤函数，实现复杂，且扩展性不如 SNS。选项D 使用 Kinesis Data Stream，主要用于数据流处理，不适合这种通知场景。"
    },
    "related_terms": [
      "SNS",
      "Lambda",
      "Amazon SNS",
      "步骤函数",
      "DynamoDB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 799,
    "topic": "",
    "question_cn": "一家公司需要从作为文本文件存储在亚马逊 S3 桶中的食谱记录中提取配料名称。应用程序将使用成分名称来查询亚马逊 DynamoDB 表并确定营养分数。应用程序可以处理非数据记录和错误。公司没有任何拥有机器学习知识的员工来开发这个解决方案。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用S3事件通知来调用Lambda函数。程序的Lambda功能分析对象和提取成分名称使用亚马逊理解。将亚马逊理解输出存储在 DynamoDB表中。",
      "B": "当请求发生时使用亚马逊事件桥牌规则调用Lambda函数。通过使用亚马逊预测来提取成分名对函数进行编程分析。将预测输出存储在 DynamoDB表中。",
      "C": "使用S3事件通知来调用Lambda函数。使用亚马逊波莉创建录音食谱记录。保存音频文件在S3桶。使用(SNS)亚马逊简单通知服务亚马逊 SNS将URL作为邮件发送给员工。指导员工听音频文件计算营养分数 在 DynamoDB桌上存储成分名称。",
      "D": "当弹出请求发生时使用亚马逊事件桥牌规则调用Lambda函数。程序的Lambda功能分析对象和提取成分名称使用亚马逊萨格。在 DynamoDB表中存储来自射手机端点的推理输出。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Textract",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "此题考察从 S3 中提取文本并进行处理。注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是使用 Amazon Comprehend，虽然题目里没说清楚是文档识别，但是其文本分析能力最适合此场景。",
      "why_correct": "选项A 使用 Amazon Comprehend 从 S3 文件中提取文本，符合要求，也无需机器学习知识。使用 S3 事件通知触发 Lambda 函数，将提取的成分存储在 DynamoDB 中。",
      "why_wrong": "选项B 使用 Amazon Forecast，用于预测，不适用于文本提取。选项C使用 Amazon Polly 生成音频，不符合题意。选项D使用 Amazon SageMaker，需要专业的 ML 知识，且没有说明是文档识别。"
    },
    "related_terms": [
      "Amazon S3",
      "Lambda",
      "Amazon DynamoDB",
      "S3",
      "亚马逊理解",
      "亚马逊预测",
      "SNS",
      "亚马逊波莉",
      "DynamoDB",
      "亚马逊萨格"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 800,
    "topic": "",
    "question_cn": "一个公司需要创建一个美国世界银行的Lambda功能，该功能将运行在公司的主要美国世界银行帐户。功能需要访问该公司存储在(EFS) 亚马逊弹性文件系统 AWS 亚马逊 EFS 文件系统中的文件。文件系统位于一个二级账户中。当公司将文件添加到文件系统时，解决方案必须扩展以满足需求。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在主帐户中创建一个新的 EFS 文件系统。使用数据显示器将原始 EFS 文件系统的内容复制到新的 EFS 文件系统中。",
      "B": "在主帐户和次级帐户中的VPC之间创建一个窥视连接。",
      "C": "在具有为文件系统配置的挂载的次级帐户中创建第二个Lambda函数。使用主帐户的Lambda函数调用次级帐户的Lambda函数。",
      "D": "将文件系统的内容移动到一个Lambda层。配置Lambda层的权限允许公司的二级帐户使用Lambda层。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "VPC Peering"
    ],
    "explanation": {
      "analysis": "此题考察跨账户访问 EFS 的方案。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是通过 VPC Peering 实现安全和高效的跨账户访问。",
      "why_correct": "选项B 使用 VPC 对等连接，允许主账户的 Lambda 函数安全地访问二级账户中的 EFS 文件系统，提供最佳性能和安全。",
      "why_wrong": "选项A 涉及数据迁移和复制，增加了复杂性和延迟，且不具备扩展性。选项C 需要跨账户函数调用，增加了复杂性。选项D 通过 Lambda 层访问，不直接解决跨账户访问 EFS 的问题。"
    },
    "related_terms": [
      "Lambda",
      "EFS",
      "VPC",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 801,
    "topic": "",
    "question_cn": "金融公司需要处理高度敏感的数据。该公司将把数据存储在一个亚马逊 S3 桶中。公司需要确保数据在传输和休息时加密。该公司必须管理 AWS 云之外的加密密钥。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "用服务器端加密 (SSE) 对S3桶中的数据进行加密，该加密使用的是一个 AWS KMS密钥管理服务客户管理密钥。",
      "B": "用服务器端加密 (SSE) 对S3桶中的数据进行加密，该加密使用的是一个 AWS KMS管理密钥。",
      "C": "用默认服务器端加密加密S3桶中的数据。",
      "D": "在将数据存储在S3桶之前在公司的数据中心对数据进行加密。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "此题考察S3加密方式。注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，密钥要在AWS云外管理。",
      "why_correct": "选项D 在数据中心加密后上传至 S3 桶，可以满足在公司外部管理加密密钥的要求，并且在传输和存储时都进行了加密，符合安全合规要求。",
      "why_wrong": "选项A 使用 SSE-KMS 加密，但是密钥还是在 AWS KMS 服务中，没有满足在AWS外部管理密钥的要求。选项B 使用 SSE-KMS，密钥也在 AWS KMS 服务中。选项C 使用默认的 SSE，虽然提供了加密，但没有控制密钥。"
    },
    "related_terms": [
      "S3",
      "SSE",
      "AWS KMS",
      "KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 802,
    "topic": "",
    "question_cn": "一家公司想在美国航空公司运行它的支付应用程序。应用程序接收移动设备的付款通知。付款通知在发送进一步处理之前需要基本 的验证。后端处理应用程序运行时间长需要调整计算机和内存。公司不想管理基础设施。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个亚马逊简单队列服务队列。将队列集成到亚马逊 EventBridge 规则中以接收来自移动设备的付款通知。配置规则以验证付款通知并将通知发送到后端应用程序。将后端应用程序部署到亚马逊弹性库伯内特斯服务 (EKS) 亚马逊的任何地方。创建一个独立集群。",
      "B": "创建一个亚马逊 API 网关。将API集成到一个步骤功能状态机以接收来自移动设备的付款通知。调用状态机来验证付款通知并将通知发送到后端应用程序。将后端应用程序部署到亚马逊弹性库伯内特斯服务 (EKS) 亚马逊上。配置带有自管理节点的 EKS 集群。",
      "C": "创建一个亚马逊简单队列服务队列。将队列集成到亚马逊 EventBridge规则中以接收来自移动设备的付款通知。配置规则以验证付款通知并将通知发送到后端应用程序。在亚马逊 EC2 Spot 实例上部署后端应用程序。配置带有默认分配策略的车队。",
      "D": "创建一个亚马逊 API 网关。将API与美国无线电通信系统集成接收来自移动设备的付款通知。调用 Lambda 函数 来验证付款通知并将通知发送到后端应用程序。将后端应用程序部署到亚马逊弹性集装箱服务 (ECS) 亚马逊容器服务上。将亚马逊系统配置为一种 Fargate发射类型。"
    },
    "vote_percentage": "100%",
    "tags": [
      "API Gateway",
      "Lambda",
      "ECS Fargate"
    ],
    "explanation": {
      "analysis": "此题考察无服务器架构下的支付应用设计。注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是：使用 API Gateway 接收请求， Lambda 进行验证， ECS Fargate 运行后端，完全无服务器，运维成本最低。",
      "why_correct": "选项D使用 API Gateway 接收请求，Lambda 函数验证请求，使用 ECS Fargate 运行后端服务，可以实现完全的无服务器架构，减少运维成本，并且使用 Fargate 简化了容器管理。",
      "why_wrong": "选项A和B使用 EKS，需要管理 Kubernetes 集群，增加了复杂性。选项C使用 EC2 Spot 实例，虽然降低了成本，但是需要管理 EC2 实例，并且无法实现完全无服务器。"
    },
    "related_terms": [
      "SQS",
      "EventBridge",
      "EKS",
      "API Gateway",
      "Step Functions",
      "EC2 Spot instances"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 803,
    "topic": "",
    "question_cn": "解决方案架构师正在为公司设计一个用户身份验证解决方案。解决方案必须为从不一致的地理位置、地址或设备登录的用户调用双因素身份验证。解决方案还必须能够扩大规模以容纳数百万用户。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置亚马逊密码用户池进行用户身份验证。基于风险的自适应认证功能与多因素认证 (MFA)。",
      "B": "为用户身份验证配置亚马逊密码标识池。启用多因素认证 (MFA)。",
      "C": "为用户身份验证配置 IAM (IAM) 用户。附加一个策略允许允许管理下的操作。",
      "D": "为用户身份验证配置 AWS 身份中心 单登录 身份验证。将权限集配置为需要多因素身份验证 (MFA)。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cognito",
      "MFA"
    ],
    "explanation": {
      "analysis": "此题考察用户身份验证和 MFA 方案。注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是 Cognito 用户池可以实现自适应 MFA。",
      "why_correct": "选项A 使用 Amazon Cognito 用户池，它提供了基于风险的自适应认证和 MFA 功能，可以根据登录的地理位置、IP地址或设备触发 MFA，满足题干要求，并且具备扩展性。",
      "why_wrong": "选项B 使用 Cognito 标识池，主要用于授权访问 AWS 资源，而非用户身份验证。选项C 使用 IAM 用户进行身份验证，不适合终端用户身份验证。选项D 使用 AWS 身份中心（前身是 SSO），虽然支持 MFA，但自适应 MFA 方面不如 Cognito 灵活。"
    },
    "related_terms": [
      "Amazon Cognito",
      "MFA",
      "IAM",
      "AWS IAM Identity Center"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 804,
    "topic": "",
    "question_cn": "一家公司有一个亚马逊 S3 数据湖。该公司需要一种解决方案将数据从数据湖中转换并每天将数据加载到数据仓库中。数据仓库必须(MPP)具有大规模并行处理功能。然后数据分析员需要通过在数据上使用 SQL 命令来创建和培训机器学习(ML)模型。解决方案必须尽可能使用无服务器的服务。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "运行每天亚马逊 EMR 工作以转换数据和加载数据到亚马逊红移。使用亚马逊红移 创建和培训 ML 模型。",
      "B": "每天运行亚马逊 EMR 工作以转换数据和加载数据到亚马逊 Aurora 无服务器。使用亚马逊奥罗拉语言来创建和培训语言模型。",
      "C": "运行每天的 AWS Glue 工作以转换数据和加载数据到亚马逊红移无服务器。使用亚马逊红移 创建和培训 ML 模型。",
      "D": "运行每天的 AWS Glue 工作以转换数据和加载数据到亚马逊 Athena 表。使用亚马逊雅典娜语言创建和培训语言模型"
    },
    "vote_percentage": "100%",
    "tags": [
      "Glue",
      "Redshift",
      "Machine Learning"
    ],
    "explanation": {
      "analysis": "此题考察数据湖到数据仓库的 ETL 和机器学习解决方案。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，方案使用无服务器的Glue完成 ETL 流程，利用Redshift作为数据仓库，最后用Redshift中的数据创建机器学习模型，完全符合题意。",
      "why_correct": "选项C 使用 AWS Glue 进行数据转换和加载，然后将数据加载到 Amazon Redshift Serverless 中。Redshift 具有 MPP 功能，非常适合数据仓库。在 Redshift 中进行 ML 模型创建和培训，符合题意，同时使用了无服务器的服务。",
      "why_wrong": "选项A 使用 EMR，运维复杂性高，且需要管理集群。选项B 使用 EMR 和 Aurora，Aurora 不适合数据仓库场景。选项D 使用 Athena，Athena 不适合作为数据仓库，而且Athena不用于机器学习模型的创建和训练。"
    },
    "related_terms": [
      "S3",
      "EMR",
      "Redshift",
      "Aurora Serverless",
      "AWS Glue",
      "Athena",
      "ML"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 805,
    "topic": "",
    "question_cn": "一家公司在库伯内特斯的当地数据中心经营集装箱。该公司希望使用亚马逊弹性库伯内特斯服务 (EKS) 和其他 AWS 管理的服务。数据必须留在公司的数据中心的本地，不能存储在任何远程站点或云中以维护合规性。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在公司的数据中心部署本地区域。",
      "B": "在公司的数据中心使用AWS Snowcone。",
      "C": "在公司的数据中心安装一个 AWS Outposts架。",
      "D": "在数据中心安装一个雪球边缘存储节点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Outposts",
      "EKS"
    ],
    "explanation": {
      "analysis": "此题考察在本地数据中心运行 EKS 和 AWS 服务的方案。注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，AWS Outposts 可以将 AWS 服务扩展到本地数据中心，满足需求。",
      "why_correct": "选项C 在公司数据中心安装 AWS Outposts，可以在本地运行 EKS 和其他 AWS 服务，满足数据留在本地的要求。",
      "why_wrong": "选项A 本地区域与题干不符。选项B 虽然 Snowcone 提供了边缘计算的能力，但不能运行 EKS。选项D 雪球边缘存储节点主要用于数据存储和传输，不能运行 EKS。"
    },
    "related_terms": [
      "EKS",
      "AWS Outposts",
      "Snowcone"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 806,
    "topic": "",
    "question_cn": "一家社交媒体公司有收集和处理数据的工作量。工作负载将数据存储在内部的NFS存储中。数据存储无法满足公司不断扩大的业务AWS需求。该公司希望将当前的数据存储迁移到 AWS。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "建立一个 AWS 存储网关卷网关。使用亚马逊 S3生命周期策略将数据转换到适当的存储类。",
      "B": "建立一个 AWS 存储网关亚马逊文件网关。使用亚马逊 S3生命周期策略将数据转换到适当的存储类。",
      "C": "使用亚马逊弹性文件系统 (EFS) -不常访问(IA)标准存储类。激活不常见的访问生命周期策略。",
      "D": "使用亚马逊弹性文件系统(EFS)一个不常见的区域访问 (IA)一个区域存储类。激活不常见的访问生命周期策略。"
    },
    "vote_percentage": "90%",
    "tags": [
      "Storage Gateway",
      "EFS"
    ],
    "explanation": {
      "analysis": "此题考察将本地 NFS 存储迁移到 AWS 的方案。注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，文件网关模拟 NFS，迁移成本低，S3生命周期策略可以进行存储分层。",
      "why_correct": "选项B 使用 AWS 存储网关文件网关，模拟 NFS 接口，使得数据迁移更容易。使用 S3 生命周期策略可以自动将数据分层到合适的存储类，实现成本优化。",
      "why_wrong": "选项A 使用卷网关，不适用于文件共享。选项C 和 D 使用 EFS，不能模拟 NFS 接口，且将数据存储在 EFS 上，而不是 S3，不符合题意。"
    },
    "related_terms": [
      "AWS Storage Gateway",
      "S3",
      "EFS",
      "EFS IA"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 807,
    "topic": "",
    "question_cn": "公司在营销活动期间使用高并发性的Lambda函数来处理消息队列中不断增加的消息。Lambda函数使用密集代码来处理消息。公司希望降低计算成本并为客户保持服务延迟。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "Lambda配置为函数保留的并发性。减少分配给兰布达函数的内存。",
      "B": "Lambda配置为函数保留的并发性。根据计算优化器的建议增加内存。",
      "C": "Lambda配置已配置的相匹配的函数。减少分配给兰布达函数的内存。",
      "D": "Lambda配置已配置的相匹配的函数。根据计算优化器的建议增加内存。"
    },
    "vote_percentage": "69%",
    "tags": [
      "Lambda Concurrency",
      "Lambda Memory Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是，Lambda优化需要同时考虑内存和并发，并且根据计算优化器来调整。",
      "why_correct": "D选项，根据计算优化器的建议增加内存, 并配置相匹配的并发度, 能够同时优化性能和成本, 满足要求。保留并发，同时根据计算优化器调整内存分配，是Lambda函数优化成本的常见做法。",
      "why_wrong": "A、C选项，减少内存可能导致性能下降。B选项，只增加内存，可能导致成本上升。这些选项没有同时优化成本和性能。"
    },
    "related_terms": [
      "Lambda",
      "Lambda 函数保留的并发性"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 808,
    "topic": "",
    "question_cn": "一家公司在Amazon Elastic Container Service上运行其工作负载。需要扫描该任务定义中使用的容器图像以寻找常见的漏洞和暴露。创建的新容器图像也需要扫描。在工作负载变化最少的情况下哪个解决方案能够满足这些需求？",
    "options_cn": {
      "A": "使用Amazon Elastic Container Registry(ECR) 作为私有的图像存储库来存储容器图像。为增强扫描指定推送滤波器上的扫描。",
      "B": "将容器图像存储在一个Amazon S3桶中。使用Amazon Macie扫描图像。使用事件通知来启动 创建对象 放置事件类型的每一个Macie事件的扫描。",
      "C": "将工作负载部署到Amazon Elastic Kubernetes Service (EKS)。使用Amazon Elastic Container Registry(ECR) 作为私人图像存储库。ECR为增强扫描指定推送滤波器上的扫描",
      "D": "将容器图像存储在启用版本控制的Amazon S3桶中。为创建对象配置一个事件通知以调用 Lambda函数。配置Lambda功能启动Amazon Inspector扫描。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECR Image Scanning",
      "Container Security"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，ECR的集成扫描能够无缝地扫描容器镜像，无需复杂的配置，满足题干中'工作负载变化最少'的要求。",
      "why_correct": "A选项，使用ECR的扫描功能，可以在镜像推送到ECR时自动扫描，无需额外配置，满足题干要求",
      "why_wrong": "B选项，使用S3和Macie需要额外的配置和事件触发，增加复杂度。C选项，EKS部署增加了复杂性，与最小化工作负载变化的要求不符。D选项， 使用Lambda和Inspector，需要手动配置，复杂程度高。"
    },
    "related_terms": [
      "Amazon ECR",
      "ECR",
      "Amazon S3",
      "Amazon Macie",
      "Amazon EKS",
      "Lambda",
      "Amazon Inspector"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 809,
    "topic": "",
    "question_cn": "一家公司使用一个批量作业来运行其期末销售流程。该公司需要一个无服务器解决方案当批处理作业成功时将调用第三方HTTP API报告应用程序。报告应用程序有一个使用用户名和密码身份验证的接口。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置一个Amazon EventBridge规则以匹配传入的批处理工作成功的事件。将第三方API配置为带有用户名和密码的EventBridge API目的地。将目的地设置为最终桥规则目标。",
      "B": "配置Amazon EventBridge调度器来匹配传入的批处理作业成功地完成了事件。通过使用用户名和密码来配置一个Lambda函数API来调用第三方。设置Lambda函数作为桥规则的目标。",
      "C": "配置批处理作业来发布工作成功地发布了一个Amazon API网关的事件。在API网关上配置一个代理API集成使用用户名和密码来调用第三方。",
      "D": "配置批处理作业来发布工作成功地发布了一个Amazon API网关的事件。将在API网关上的代理集成Lambda API配置为函数。通过使用用户名和密码来配置函数来调用第三方。"
    },
    "vote_percentage": "61%",
    "tags": [
      "EventBridge",
      "API Gateway"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是，EventBridge 提供了直接集成第三方API的功能，最简洁高效。",
      "why_correct": "A选项，EventBridge 可以直接与HTTP API集成，使用用户名和密码进行身份验证。这简化了流程，减少了复杂性，满足要求。",
      "why_wrong": "B选项，使用Lambda函数调用第三方API，增加了复杂性。C选项，使用API网关，增加了复杂性。D选项，API网关+Lambda，更为复杂。"
    },
    "related_terms": [
      "EventBridge",
      "HTTP API",
      "Lambda",
      "API Gateway"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 810,
    "topic": "",
    "question_cn": "一家公司从供应商那里收集和处理数据。供应商将其数据存储在一个Amazon RDS数据库中，用于在供应商自己的帐户中存储。该公司的VPC没有互联网网关，没有AWS服务直接连接，也没有AWS服务网站到现场的连接。公司需要访问供应商数据库中的数据。哪种解决方案能满足这一要求？",
    "options_cn": {
      "A": "指示供应商注册托管的连接直接连接程序。使用窥视连接公司的VPC和供应商的VPC。",
      "B": "配置公司和供应商之间的客户机VPN连接。使用窥视连接公司的VPC和供应商的VPC。",
      "C": "指示供应商创建一个网络负载均衡器。把网络负载均衡器放在Amazon RDS数据库前面。使用VPC的私人链接，结合VPC和公司的VPC和卖方的VPC。",
      "D": "使用传输网关集成公司的VPC和供应商的VPC。使用窥视连接公司的VPC和供应商的VPC。"
    },
    "vote_percentage": "93%",
    "tags": [
      "VPC Peering",
      "PrivateLink"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是，使用PrivateLink 能够通过私有网络访问 RDS，同时满足安全性要求。",
      "why_correct": "C选项，通过PrivateLink创建一个指向供应商RDS的私有连接，满足了安全性和私有连接的需求。 NLB可以隐藏RDS的私有IP。",
      "why_wrong": "A选项，需要供应商的配合，且配置较为复杂。B选项，VPN连接需要额外的配置和维护。D选项，传输网关，增加了复杂性，且无法直接连接到RDS。"
    },
    "related_terms": [
      "RDS",
      "VPC",
      "Direct Connect",
      "VPN",
      "Network Load Balancer",
      "PrivateLink",
      "Transit Gateway"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 811,
    "topic": "",
    "question_cn": "一家公司希望将Amazon Managed Grafana作为其可视化工具。该公司希望将Amazon RDS数据库中的数据可视化为一个数据源。该公司需要一个安全的解决方案，不会在互联网上公开数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个Amazon Managed Grafana工作区。为RDS数据库创建一个公共端点。将公共端点配置为Amazon Managed Grafana的数据源。",
      "B": "在VPC中创建一个Amazon Managed Grafana工作区。为RDS数据库创建一个私有端点。将私有端点配置为Amazon Managed Grafana的数据源。",
      "C": "创建一个Amazon Managed Grafana工作区。创建一个私人链接端点以建立Amazon Managed Grafana和Amazon RDS之间的连接。建立Amazon RDS作为数据源在Amazon Managed Grafana。",
      "D": "在VPC中创建一个Amazon Managed Grafana工作区。为RDS数据库创建一个公共端点。将公共端点配置为Amazon Managed Grafana的数据源。"
    },
    "vote_percentage": "67%",
    "tags": [
      "Managed Grafana",
      "RDS Private Endpoint"
    ],
    "explanation": {
      "analysis": "使用私有端点确保数据安全,同时保证在VPC内部访问RDS。",
      "why_correct": "B选项，在VPC中创建Grafana工作区，RDS使用私有端点，保证数据在私有网络中传输，满足安全需求。",
      "why_wrong": "A、D选项，使用公共端点，不符合安全要求。C选项，虽然使用Private Link，但没说明Grafana在VPC中。"
    },
    "related_terms": [
      "Amazon Managed Grafana",
      "RDS",
      "VPC",
      "私有端点",
      "PrivateLink"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 812,
    "topic": "",
    "question_cn": "一家公司在Amazon S3上拥有一个数据湖。数据湖从各种数据源中吸收Apache Parquet格式的数据。该公司使用多个转换步骤来准备消化数据。这些步骤包括过滤异常、使数据符合标准日期和时间值以及生成供分析的集合体。该公司必须将转换后的数据存储在数据分析员访问的S3桶中。对于不需要代码的数据转换，公司需要一个预先构建的解决方案。解决方案必须提供数据血统和数据特征分析。公司需要与整个公司的员工分享数据转换步骤。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置一个Glue Studio视觉画布来转换数据。与员工分享转变步骤使用AWS Glue工作。",
      "B": "配置Amazon EMR无服务器来转换数据。通过使用无服务作业与员工共享转换步骤。",
      "C": "配置Glue数据来转换数据。与员工分享转变步骤使用数据库食谱。",
      "D": "为数据创建Amazon Athena表。编写Athena查询来转换数据。与员工共享Athena查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Glue",
      "Data Transformation"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，Glue的视觉化界面和数据血缘追踪可以满足题干要求。",
      "why_correct": "C选项，Glue 可以通过可视化界面进行数据转换，并支持数据血缘追踪，方便与员工分享数据转换步骤，满足题干要求",
      "why_wrong": "A选项，同样是Glue方案，比C多余了AWS Glue工作。B选项，EMR是大数据处理，与题干要求不匹配。D选项，Athena虽然可以查询，但是不具备转换能力。"
    },
    "related_terms": [
      "S3",
      "Glue Studio",
      "AWS Glue",
      "EMR Serverless",
      "Athena"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 813,
    "topic": "",
    "question_cn": "解决方案架构师在多个Amazon EC2实例上运行一个Web应用程序，这些实例位于应用程序负载平衡器后面的单个目标组中。用户可以通过公共网站进入应用程序。解决方案架构师希望允许工程师使用网站的开发版本来访问一个特定的开发实例来测试应用程序的新特性。解决方案架构师希望使用Amazon Route 53路由托管区域使工程师能够访问开发实例。即使开发实例被替换解决方案也必须自动路由到开发实例。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为开发网站创建一个记录，该记录将设置为A记录的值。在Route 53上创建侦听器规则将开发网站的请求转发给包含开发实例的目标组。",
      "B": "用公共IP地址恢复发展实例。为开发网站创建一个记录，该记录对开发实例的公共IP地址具有价值。",
      "C": "为开发网站创建一个记录，该记录将设置为A记录的值。在Route 53上创建监听器规则将开发网站的请求重定向到开发实例的公共地址。",
      "D": "将所有实例置于同一目标群体中。为开发网站创建一个记录。将值设置为A记录。在Route 53上创建一个监听器规则将开发网站的请求转发给目标组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Route 53",
      "ALB"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，通过配置Route 53的A记录和ALB监听器规则，可以方便地将流量导向开发环境，并且方便实例更换。",
      "why_correct": "A选项，通过Route 53 A记录指向ALB，ALB再将流量转发到目标组（包含开发实例），实现流量转发。即使开发实例更换，只要ALB目标组配置正确，则流量会自动转发到新的实例，满足自动路由和开发测试的需求。",
      "why_wrong": "B选项， 使用公共IP，IP地址是变化的，无法满足题目中即使实例被替换也要正常路由到开发实例的要求。C选项， 重定向不能满足测试环境的需求。D选项，没有说明如何让开发环境的实例与生产环境的实例区分开。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "Route 53",
      "A记录"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 814,
    "topic": "",
    "question_cn": "一家公司在公司的数据中心的Kubernetes集群上运行一个容器应用程序。应用程序使用高级消息队列协议(AMQP)与消息队列进行通信。数据中心的扩展速度不足以满足公司不断扩大的业务需求。该公司希望将工作量转移到AWS。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将容器应用程序迁移到Amazon Elastic Container Service中。使用Amazon Simple Queue Service来检索消息。",
      "B": "将容器应用程序迁移到Amazon Elastic Kubernetes Service (EKS)。使用Amazon MQ来检索消息。",
      "C": "使用高度可用的Amazon EC2实例来运行应用程序。使用Amazon MQ来检索消息。",
      "D": "使用Lambda函数运行应用程序。使用Amazon Simple Queue Service来检索消息。"
    },
    "vote_percentage": "93%",
    "tags": [
      "EKS",
      "Amazon MQ"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是，EKS可以作为Kubernetes的替代品，减少代码改动，而Amazon MQ提供AMQP协议支持，无缝迁移现有应用。",
      "why_correct": "B选项，EKS 提供与现有 Kubernetes 相似的环境，降低迁移成本。Amazon MQ 支持 AMQP 协议，允许应用程序继续使用现有的消息队列协议，满足需求。",
      "why_wrong": "A选项，迁移到ECS会改变部署方式。C选项，EC2实例需要运维，不符合最小化运维的要求。D选项，Lambda可能无法满足AMQP的需求。"
    },
    "related_terms": [
      "Amazon EKS",
      "Amazon Elastic Container Service",
      "SQS",
      "Amazon MQ",
      "Lambda"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 815,
    "topic": "",
    "question_cn": "一个在线游戏公司在Amazon EC2实例上拥有它的平台在网络负载平衡器(NLB)的跨多个区域。 可以通过互联网将请求路由到目标。该公司希望通过减少其全球客户群的端到端负载时间来提高客户的游戏体验。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在每个区域创建应用程序负载平衡器来替换现有的NLB。注册现有的EC2实例作为每个区域的目标。",
      "B": "配置Amazon Route 53以便将同样的加权流量路由到每个区域的NLB。",
      "C": "在公司拥有大量客户基础的其他区域创建额外的NLB和EC2实例。",
      "D": "创建AWS Global Accelerator。将现有的NLB配置为目标端点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "NLB"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为D。社区倾向D的原因是，Global Accelerator可以有效降低延迟，提升客户体验。",
      "why_correct": "D选项，使用 Global Accelerator 可以利用 AWS 全球网络，通过就近接入点加速流量，减少延迟，提升用户体验。",
      "why_wrong": "A选项， 只是将 NLB 替换为 ALB, 没有改善延迟。B选项， Route 53 只是DNS，没有加速功能。C选项，增加实例，但没有优化延迟。"
    },
    "related_terms": [
      "EC2",
      "NLB",
      "ALB",
      "Route 53",
      "AWS Global Accelerator"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 816,
    "topic": "",
    "question_cn": "一家公司有一个内部应用程序使用SFTP从多个供应商那里收集财务数据。该公司正在迁移到AWS云。该公司已经创建了一个Amazon S3 API应用程序使用亚马逊S3 API从供应商上传文件。一些供应商在不支持SFTP的遗留应用程序上运行他们的系统。供应商希望继续使用基于SFTP的应用程序来上传数据。该公司希望使用托管服务来满足使用遗留应用程序的供应商的需求。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个AWS Database Migration Service(AWS DMS)实例以复制来自使用遗留应用程序到Amazon S3的供应商存储的数据。向供应商提供访问AWS DMS实例的凭证。",
      "B": "为使用遗留应用程序的供应商创建一个AWS Transfer Family端点。",
      "C": "配置Amazon EC2实例来运行SFTP服务器。指示使用遗留应用程序的供应商使用SFTP服务器上传数据。",
      "D": "为使用遗留应用程序将文件上传到SMB文件共享的供应商配置一个Amazon File Gateway。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Transfer Family",
      "SFTP"
    ],
    "explanation": {
      "analysis": "使用AWS Transfer Family, 可以满足SFTP需求，且是托管服务，运维成本低。",
      "why_correct": "B选项，AWS Transfer Family提供SFTP端点，方便使用SFTP的供应商直接上传数据到S3，满足题干需求，且运维成本低。",
      "why_wrong": "A选项，DMS用于数据库迁移，不适用。C选项， EC2+SFTP 需要自行运维。D选项，File Gateway用于SMB，不符合SFTP的需求。"
    },
    "related_terms": [
      "SFTP",
      "S3",
      "AWS DMS",
      "AWS Transfer Family",
      "Amazon File Gateway",
      "SMB"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 817,
    "topic": "",
    "question_cn": "一个营销团队想为即将到来的多运动项目发起一场运动。该小组有过去五年的新闻报告（PDF）格式。该团队需要一个解决方案以提取对新闻报道内容和感情的深刻见解。解决方案必须使用Amazon提取器来处理新闻报道。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为Amazon Athena提供提取的见解进行分析。将提取的见解和分析存储在Amazon S3桶中。",
      "B": "在Amazon DynamoDB表中存储提取的见解。使用Amazon SageMaker建立一个感情模型。",
      "C": "为Amazon Comprehend的分析提供提取的见解。将分析保存到一个Amazon S3桶。",
      "D": "在Amazon S3桶中存储提取出来的洞见。使用Amazon QuickSight可视化和分析数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Comprehend",
      "PDF Processing"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是，Amazon Comprehend可以提取见解，并且S3桶可以存储，满足题干要求。",
      "why_correct": "C选项，使用 Amazon Comprehend 从PDF提取见解，将分析结果存储在S3桶中，简单高效，满足需求。",
      "why_wrong": "A选项，Athena虽然可以分析，但是需要先提取数据，且不能直接提取情感分析。B选项，DynamoDB和SageMaker超出了需求范围，复杂。D选项，QuickSight无法直接提取见解。"
    },
    "related_terms": [
      "Amazon Athena",
      "S3",
      "Amazon DynamoDB",
      "Amazon SageMaker",
      "Amazon Comprehend",
      "QuickSight"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 818,
    "topic": "",
    "question_cn": "一个公司的应用程序在Amazon EC2实例上运行，这些实例位于多个可用性区域。应用程序需要吸收第三方应用程序的实时数据。该公司需要一种数据摄入解决方案将所摄取的原始数据放在Amazon S3桶中。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建Amazon Kinesis Data Firehose为数据摄入。创建Amazon Kinesis Data Firehose传递流消耗Kinesis数据流。指定S3桶作为交付流的目的地。",
      "B": "在AWS Database Migration Service (AWS DMS)中创建数据库迁移任务。指定EC2实例的复制实例为源端点。指定S3桶为目标端点。设置迁移类型以迁移现有数据并复制正在进行的更改。",
      "C": "在EC2实例上创建和配置AWS DataSync代理。配置DataSync监视任务将数据从EC2实例传输到S3桶。",
      "D": "创建一个直接连接连接到数据摄入应用程序。创建Amazon Kinesis Data Firehose传递流从应用程序中消耗直接放置操作。指定S3桶作为交付流的目的地。"
    },
    "vote_percentage": "60%",
    "tags": [
      "Kinesis Data Firehose",
      "Real-time Data Ingestion"
    ],
    "explanation": {
      "analysis": "Kinesis Data Firehose可以从数据源摄取实时数据，并存储到S3桶中，满足需求。",
      "why_correct": "A选项，使用 Kinesis Data Firehose 接收实时数据，并写入到 S3 桶中，满足数据摄入需求。Kinesis Data Firehose提供了可靠、可扩展的数据摄入方案。",
      "why_wrong": "B选项，AWS DMS主要用于数据库迁移，不适用于实时数据摄取。C选项， DataSync代理主要用于数据同步，不适用于实时数据摄取。D选项，没有说明直接连接的具体实现。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "Kinesis Data Firehose",
      "AWS DMS",
      "DataSync",
      "Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 819,
    "topic": "",
    "question_cn": "一家公司的应用程序正在接收来自多个数据源的数据。数据的规模各不相同，预计会随着时间的推移而增加。目前的最大尺寸是700kb。随着更多数据源的加入，数据量和数据规模继续扩大。该公司决定使用Amazon DynamoDB作为应用程序的主要数据库。解决方案架构师需要识别处理大型数据大小的解决方案。哪个解决方案将以最有效的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个Lambda函数来过滤超过DynamoDB项目大小限制的数据。将较大的数据存储在一个Amazon文档，具有MongoDB兼容性数据库中。",
      "B": "将大型数据作为对象存储在Amazon S3桶中。在DynamoDB表中创建具有指向数据的S3 URL的属性的项。",
      "C": "将所有传入的大数据分割到具有相同分区键的项集合中。在单个操作中使用批写项操作将数据写入DynamoDB表。",
      "D": "创建一个Lambda函数，该函数使用GZIP压缩来压缩写入DynamoDB表的大型对象。"
    },
    "vote_percentage": "100%",
    "tags": [
      "DynamoDB",
      "Large Object Storage"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是，将大型数据存储在S3中，在DynamoDB中存储指向S3的URL，可以规避DynamoDB的限制。",
      "why_correct": "B选项，将大型数据存储在S3中，然后在DynamoDB中存储指向S3对象的URL，规避了DynamoDB的项目大小限制，并保持了灵活性。这个方法最有效，也满足了处理大型数据的需求。",
      "why_wrong": "A选项，使用MongoDB兼容性数据库，增加了复杂性，且与题干不符。C选项，虽然可以分批写入，但还是受限于单个item大小。D选项，压缩可能会增加计算成本，并且没有从根本上解决DynamoDB的大小限制。"
    },
    "related_terms": [
      "DynamoDB",
      "Lambda",
      "S3",
      "MongoDB",
      "GZIP",
      "批写项操作"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 820,
    "topic": "",
    "question_cn": "一家公司正在将遗留的应用程序从一个内部数据中心迁移到AWS。该应用程序依赖于数百个cron作业，这些作业在一天中根据不同的循环时间表运行，1到20分钟。该公司希望找到一个解决方案通过最小的重构在AWS上安排和运行cron作业。解决方案必须支持在未来事件中运行作业。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为cron作业创建一个容器图像。使用Amazon EventBridge调度器创建一个循环的计划。根据AWS CLI的功能运行cron作业任务。",
      "B": "为cron作业创建一个容器图像。在Amazon Elastic Container Service中使用批处理并有调度策略来运行cron作业。",
      "C": "为cron作业创建一个容器图像。使用Amazon EventBridge调度器创建一个循环的计划。在Fargate执行cron工作任务。",
      "D": "为cron作业创建一个容器图像。在AWS步骤函数中创建工作流，该函数使用等待状态在指定时间运行cron作业。使用运行任务动作来运行在Fargate上的cron作业任务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EventBridge Scheduler",
      "Fargate"
    ],
    "explanation": {
      "analysis": "使用EventBridge Scheduler和Fargate可以方便地调度和运行容器化的cron作业。",
      "why_correct": "C选项，利用EventBridge调度器进行定时任务调度，使用Fargate运行容器化的cron作业，简化了运维，满足需求",
      "why_wrong": "A选项，缺少执行环境。B选项，ECS Batch更适合于批处理，不适合cron作业。D选项，步骤函数过于复杂。"
    },
    "related_terms": [
      "cron",
      "EventBridge",
      "AWS CLI",
      "Amazon Elastic Container Service",
      "Fargate",
      "AWS Step Functions"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 821,
    "topic": "",
    "question_cn": "一家公司使用销售队伍。该公司需要装载现有的数据和正在进行的数据变化从销售力量到Amazon Redshift进行分析。该公司不希望数据通过公共互联网传播。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "VPC和VPN连接建立一个从AWS到销售队之间的一个连接。使用Glue数据传输数据。",
      "B": "VPC 和Direct Connect建立一个从AWS到销售力量的直接连接。使用Glue数据传输数据。",
      "C": "在VPC中创建一个与销售力量的Private Link。使用亚马逊程序流来传输数据。",
      "D": "创建窥视连接到销售力。使用亚马逊程序流来传输数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Redshift",
      "PrivateLink"
    ],
    "explanation": {
      "analysis": "使用 PrivateLink 可以通过私有网络连接到Redshift，且Glue可以进行数据传输。",
      "why_correct": "C选项，在 VPC 中创建 PrivateLink 连接到 Redshift，通过安全私有网络进行数据传输，满足不通过公共互联网的需求，用Glue进行数据传输，最简洁高效。",
      "why_wrong": "A选项，VPN连接可以实现安全连接，但相比PrivateLink配置更复杂。B选项，Direct Connect需要物理连接，设置比较复杂。D选项，窥视连接没有提供安全的数据传输通道。"
    },
    "related_terms": [
      "VPC",
      "VPN",
      "AWS",
      "Glue",
      "Direct Connect",
      "Private Link",
      "Amazon程序流"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 822,
    "topic": "",
    "question_cn": "一家公司最近将它的应用程序迁移到了美国世界银行。该应用程序在Amazon EC2实例中运行在多个可用性区域的自动缩放组 (EFS) 中。应用程序将数据存储在Amazon EFS文件系统中，该系统使用标准访问存储。应用程序对公司的文件进行RDS索引。该索引存储在Amazon RDS数据库中。该公司需要优化存储成本的一些应用和服务变化？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "创建一个使用智能层生命周期策略的Amazon S3桶。将所有文件复制到S3桶。更新应用程序以使用Amazon S3存储和检索文 件。",
      "B": "为文件服务器文件共享部署Amazon FSx for Windows。更新应用程序以使用CIFS协议存储和检索文件。",
      "C": "部署Amazon FSx zFS for 开放文件系统共享。更新应用程序以使用新的挂载点来存储和检索文件。",
      "D": "创建一个使用冰川灵活检索Amazon S3桶。将所有文件复制到S3桶。更新应用程序使用Amazon S3存储和检索文件作为标准检索。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle",
      "EFS"
    ],
    "explanation": {
      "analysis": "核心考点是存储成本优化。使用S3智能分层策略是最有效的方法，因为它可以根据访问频率自动将数据迁移到不同的存储层。",
      "why_correct": "选项A使用S3智能分层，可以根据访问模式自动优化存储成本，将不常访问的数据移动到成本较低的存储层。",
      "why_wrong": "选项B、C涉及文件系统，与优化现有数据存储成本无关。选项D使用冰川存储，访问延迟高，不适合频繁访问的文件。"
    },
    "related_terms": [
      "EC2",
      "Multi-AZ",
      "EFS",
      "RDS",
      "Amazon S3",
      "智能层",
      "Amazon FSx for Windows",
      "CIFS",
      "Amazon FSx zFS",
      "冰川灵活检索"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 823,
    "topic": "",
    "question_cn": "一家机器人公司正在为医学手术设计解决方案。这些机器人将使用先进的传感器、摄像头和人工智能算法来感知它们的环境并完成手术。该公司需要一个公共负载平衡器在AWS云中，将确保无缝通信后端服务。负载平衡器必须能够基于查询字符串将流量路由到不同的目标组。流量也必须加密？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "使用网络负载平衡器其证书来自AWS 证书管理器。使用基于查询参数的路由。",
      "B": "使用网关负载平衡器。导入IAM标识和访问管理中的生成证书。将证书附加到负载平衡器上。使用基于路径的路由。",
      "C": "使用一个应用程序负载平衡器和一个由AWS 证书管理器附加的证书。使用基于查询参数的路由。",
      "D": "使用网络负载平衡器。导入IAM标识和访问管理中的生成证书。将证书附加到负载平衡器上。使用基于查询参数的路由。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Application Load Balancer",
      "ACM"
    ],
    "explanation": {
      "analysis": "核心考点是负载均衡器的选择和HTTPS配置。应用程序负载均衡器(ALB)支持基于内容的路由(比如查询字符串)，并能与ACM集成实现SSL/TLS加密。",
      "why_correct": "选项C使用ALB，支持基于查询字符串的路由，且ALB能与ACM集成，简化证书管理。",
      "why_wrong": "选项A使用网络负载均衡器，不支持基于内容的路由。选项B使用网关负载均衡器，不适合此场景。选项D使用网络负载均衡器，且使用了IAM管理证书，操作复杂。"
    },
    "related_terms": [
      "负载平衡器",
      "AWS 证书管理器",
      "IAM",
      "网关负载平衡器",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 824,
    "topic": "",
    "question_cn": "一个公司有一个应用程序运行在一个Amazon EC2实例上。该应用程序使用在同一EC2实例上运行的MySQL数据库。该公司需要一个高可用性和自动可伸缩的解决方案来处理增加的流量？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将应用程序部署到在应用程序负载平衡器后面的自动缩放组中运行的EC2实例。创建一个Amazon Redshift集群该集群具有多个 Mysql 兼容节点。",
      "B": "将应用程序部署到被配置为应用程序负载平衡器后面的目标组的EC2实例。为MySQL集群创建一个具有多个实例的Amazon RDS。",
      "C": "将应用程序部署到在应用程序负载平衡器后面的自动缩放组中运行的EC2实例。为数据库层创建一个Amazon Aurora无服务器的MySQL集群。",
      "D": "将应用程序部署到被配置为应用程序负载平衡器后面的目标组的EC2实例。为使用连接器的雷迪斯集群创建一个Amazon ElastiCache。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "RDS Aurora Serverless"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为C。社区倾向C的原因是使用Aurora Serverless可以提供自动伸缩的MySQL数据库，满足高可用性需求。核心考点是高可用数据库和自动伸缩的实现方案。使用Aurora Serverless可以自动根据负载伸缩数据库容量，结合ALB和EC2 Auto Scaling可以实现完整的解决方案。",
      "why_correct": "选项C使用了Aurora Serverless，它提供了自动伸缩的数据库，满足高可用性和可伸缩性的要求。",
      "why_wrong": "选项A使用了Redshift，它主要用于数据仓库，不适合作为应用程序的MySQL数据库。选项B使用了RDS，但没有说明RDS的多可用区部署，无法满足高可用性需求。选项D使用了ElastiCache，它用于缓存，不能代替数据库。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "自动缩放组",
      "Amazon Redshift",
      "MySQL",
      "Amazon RDS",
      "Amazon Aurora",
      "Amazon ElastiCache"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 825,
    "topic": "",
    "question_cn": "一家公司正计划将数据迁移到Amazon S3桶。数据必须在S3桶内的休息处加密。加密密钥必须每年自动旋转？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "将数据迁移到 S3桶。使用Amazon S3托管密钥的服务器端加密(SSE-S3)。使用SSE-S3加密密钥的内置密钥旋转行为。",
      "B": "创建一个AWS KMS密钥管理服务 客户管理密钥。启动自动键旋转。设置 S3桶的默认加密行为使用客户管理的 KMS 键。将数据 S3迁移到桶。",
      "C": "创建一个AWS KMS 密钥管理服务 客户管理密钥。设置 S3桶的默认加密行为使用客户管理的 KMS 键。将数据迁移到 桶。每年手动旋转 KMS 键。",
      "D": "使用客户密钥材料加密数据。将数据迁移到S3桶。创建一个不含关键材料的 KMS 键。将客户键材料导入 KMS 键。启动自动键旋转"
    },
    "vote_percentage": "60%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是使用 KMS 客户管理密钥，可以实现密钥的自动轮换，满足了题目需求。核心考点是S3加密的实现，以及 KMS 密钥的自动轮换。",
      "why_correct": "选项B使用KMS客户管理密钥，并开启了自动密钥轮换，满足了题目对加密和密钥轮换的需求。",
      "why_wrong": "选项A使用了SSE-S3，没有密钥轮换功能。选项C使用了KMS，但手动轮换密钥，不符合题目的自动轮换要求。选项D的步骤过于复杂，操作开销大，且没有给出正确的密钥使用方法。"
    },
    "related_terms": [
      "Amazon S3",
      "SSE-S3",
      "AWS KMS",
      "KMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 826,
    "topic": "",
    "question_cn": "一家公司正在将应用程序从微软的一个现场活动目录迁移到AWS云服务公司。该公司将应用程序部署在多个AWS账户中。该公司利用AWS Organizations集中管理账目。该公司的安全团队需要一个单一的登录解决方案涉及公司所有的AWS账户。公司必须继续管理在现场活动目录中的用户和群体？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "为微软活动目录在 AWS 目录服务中创建企业版活动目录。将活动目录配置为 IAM标识中心的标识源。",
      "B": "启用AWS信息系统身份识别中心。配置一个双向森林信任关系，通过使用微软主动目录的目录服务将公司的自管理主动目录与IAM标识中心连接起来。",
      "C": "使用AWS目录服务并与公司的自管理活动目录建立双向信任关系。",
      "D": "在Amazon EC2上部署身份提供者。链接作为一个身份源的内部的国内流离失所者在美国信息系统管理局身份中心。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Single Sign-On",
      "AWS Directory Service"
    ],
    "explanation": {
      "analysis": "核心考点是AWS SSO的配置和与现有Active Directory的集成。需要建立信任关系，使用AWS Directory Service，实现集中用户管理和单点登录。",
      "why_correct": "选项B使用AWS SSO，并配置了与本地AD的双向信任关系，满足单点登录需求。",
      "why_wrong": "选项A没有提及信任关系。选项C只提到了AWS Directory Service，没有SSO集成。选项D部署了EC2实例，操作复杂，不是最优解。"
    },
    "related_terms": [
      "AWS",
      "微软活动目录",
      "AWS 目录服务",
      "IAM",
      "AWS Organizations",
      "AWS信息系统身份识别中心",
      "双向森林信任关系",
      "Amazon EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 827,
    "topic": "",
    "question_cn": "一家公司正计划将其应用程序部署在Amazon Aurora PostgreSQL无服务器集群上。应用程序将接收大量的流量。随着应用程序负载的增加，该公司希望优化集群的存储性能？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "配置集群使用Aurora标准存储配置。",
      "B": "将集群存储类型配置为已提供的IOPS。",
      "C": "将集群存储类型配置为通用。",
      "D": "配置集群使用Aurora 优化存储配置。"
    },
    "vote_percentage": "85%",
    "tags": [
      "Aurora Storage Optimization",
      "Aurora PostgreSQL"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为D。社区倾向D的原因是Aurora 优化存储配置专为性能密集型工作负载设计，可以最大限度地提高性能。核心考点是Aurora存储优化配置的选择。",
      "why_correct": "选项D使用Aurora 优化存储配置，能提高性能。",
      "why_wrong": "选项A使用标准存储配置，不能优化性能。选项B配置了IOPS，但不是最优解。选项C通用存储配置，性能不如优化存储配置。"
    },
    "related_terms": [
      "Aurora PostgreSQL",
      "Aurora",
      "IOPS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 828,
    "topic": "",
    "question_cn": "一家在美国金融服务公司运营的金融服务公司设计了安全控制系统以达到行业标准。行业标准包括国家标准和技术研究所和支付卡行业数据安全标准(PCI DSS)。该公司的第三方审计师需要证明设计的控制措施已经实施并正常运作。该公司在一个组织中拥有数百个AWS账户。该公司需要监控各账户控制的现状？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "指定一个账户作为Amazon Inspector委托的管理员账户。从组织管理账户整合检查员与组织，发现和扫描所有的AWS账户的PCIDSS资源。使国家软件技术研究所和的检查行业标准成为可能。",
      "B": "指定一个账户作为Amazon GuardDuty授权的管理员账户。从组织管理账户 在指定的值班管理员账户中使值班员能够保护所有的会员 PCI DSS 账户。为国家软件技术研究所和的 启用保护工业标准。",
      "C": "在组织管理账户中配置一个AWS CloudTrail组织。指定一个账户作为合规账户。在合规性帐户中启用国家软件技术研究所和 的云迹安全标准。",
      "D": "从组织管理账户中指定一个账户作为AWS安全中心授权的管理员账户。在指定的安全中心管理员账户中为PCI DSS所有成员账户启用安全中心。为国家软件技术研究所和数据安全系统启用安全枢纽标准。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Security Hub",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "核心考点是AWS Security Hub和合规性标准。Security Hub可以集中监控和管理多个账户的安全状况，并根据行业标准进行合规性评估。",
      "why_correct": "选项D使用Security Hub，可以集中监控账户安全状况，并进行合规性评估，满足了审计需求。",
      "why_wrong": "选项A使用了Inspector，Inspector主要用于漏洞扫描，不能满足合规性监控需求。选项B使用了GuardDuty，主要用于威胁检测，不是最优解。选项C只使用了CloudTrail，不能进行合规性评估。"
    },
    "related_terms": [
      "Amazon Inspector",
      "PCI DSS",
      "AWS",
      "AWS CloudTrail",
      "Amazon GuardDuty",
      "AWS安全中心"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 829,
    "topic": "",
    "question_cn": "一家公司使用一个Amazon S3桶作为数据湖存储平台。S3桶包含大量数据由多个团队和数百个应用程序随机访问。该公司希望降低S3存储成本并为经常访问的对象提供即时可用性？符合这些要求的最有效的业务解决方案是什么",
    "options_cn": {
      "A": "创建一个生命周期规则将对象转换为智能层存储类。",
      "B": "在Amazon S3冰川储存物体。使用选择提供访问数据的应用程序。",
      "C": "使用S3 存储类分析的数据创建生命周期规则，自动将对象转换为标准-不经常访问存储类。",
      "D": "过渡对象为标准-不经常存取存储类别。当应用程序访问对象时，创建一个 Lambda 函数将对象过渡到标准存储类。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Lifecycle",
      "S3 Intelligent-Tiering"
    ],
    "explanation": {
      "analysis": "核心考点是S3存储类和生命周期策略。使用智能分层(Intelligent-Tiering)可以自动将数据迁移到合适的存储层，降低成本并提供即时可用性。",
      "why_correct": "选项A使用了S3智能分层，可以根据访问频率自动在存储层之间切换。",
      "why_wrong": "选项B使用了S3 Glacier，不适合频繁访问的数据。选项C使用了S3 Standard-IA，需要手动分析，不灵活。选项D手动用Lambda函数切换存储类型，增加了复杂性。"
    },
    "related_terms": [
      "Amazon S3",
      "S3",
      "智能层",
      "Amazon S3冰川",
      "标准-不经常访问",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 830,
    "topic": "",
    "question_cn": "一家公司有10万个用户配置文件和100万个连接的数据集。用户配置文件具有多对多关系的连接。该公司需要一种高效的绩效方式来找到高达五级的相互联系？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "使用Amazon S3桶存储数据集。使用Amazon Athena执行 SQL 连接查询来寻找连接。",
      "B": "使用Amazon Neptune存储数据集的边缘和顶点。查询数据以找到连接。",
      "C": "使用Amazon S3桶存储数据集。使用Amazon QuickSight视觉化的连接。",
      "D": "使用Amazon RDS存储多个表的数据集。执行 SQL连接查询以找到连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Amazon Neptune",
      "Graph Database"
    ],
    "explanation": {
      "analysis": "核心考点是图数据库的选择和使用。对于多对多关系和查找连接，图数据库如Neptune是最佳选择。",
      "why_correct": "选项B使用了Neptune，非常适合处理多对多关系和查找连接。",
      "why_wrong": "选项A使用了Athena和S3，虽然可以查询，但效率不如图数据库。选项C使用了QuickSight，用于数据可视化，不适合查询。选项D使用了RDS，在处理多对多关系和深层连接时效率较低。"
    },
    "related_terms": [
      "Amazon S3",
      "Athena",
      "SQL",
      "Amazon Neptune",
      "Amazon QuickSight",
      "RDS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 831,
    "topic": "",
    "question_cn": "一个公司需要一个安全的连接它的内部环境和AWS。这种连接不需要高带宽，只需处理少量的流量。连接应该很快建立起来？建立这种连接的最具成本效益的方法是什么",
    "options_cn": {
      "A": "使用VPN实现一个客户端。",
      "B": "实现AWS Direct Connect。",
      "C": "在Amazon EC2上设置一个堡垒主机。",
      "D": "实现一个AWS Site-to-Site VPN连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Site-to-Site VPN",
      "Direct Connect"
    ],
    "explanation": {
      "analysis": "核心考点是VPN和Direct Connect的选择。对于低带宽和快速建立连接的需求，Site-to-Site VPN是最经济高效的方案。",
      "why_correct": "选项D使用了Site-to-Site VPN，满足了低带宽、快速建立连接的需求。",
      "why_wrong": "选项A是客户端VPN，不适合内部网络连接。选项B是Direct Connect，带宽高，成本较高，不符合题意。选项C是堡垒机，不是建立连接的方案。"
    },
    "related_terms": [
      "VPN",
      "AWS Direct Connect",
      "Amazon EC2",
      "Site-to-Site VPN"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 832,
    "topic": "",
    "question_cn": "一家公司有一个内部的SFTP文件转移解决方案。该公司正在迁移到AWS云以扩展文件传输解决方案并通过使用Amazon S3来优化成本。该(AD)公司的员工将使用他们的证书在现场的微软活动目录访问新的解决方案。该公司希望保留当前的身份验证和文件访问机制？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "配置一个AWS文件网关。在使用现有活动目录进行身份验证的文件网关上创建S3文件共享。",
      "B": "用Amazon EC2实例配置一个自动缩放组来运行SFTP解决方案。将组配置为将CPU利用率提高到60%。",
      "C": "用SFTP端点创建一个AWS Transfer Family服务器。选择AWS Directory Service选项作为标识提供程序，使用连接器连接现场活动目录。",
      "D": "创建一个AWS Transfer Family端点。将端点配置为使用AWS Directory Service选项作为标识提供程序连接到现有活动目录。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Transfer Family",
      "SFTP"
    ],
    "explanation": {
      "analysis": "核心考点是SFTP解决方案的选择和与Active Directory的集成。AWS Transfer Family提供了SFTP服务，并且支持与AD的集成。",
      "why_correct": "选项C/D使用了AWS Transfer Family，满足了SFTP和AD集成的需求，D选项更好。",
      "why_wrong": "选项A使用了文件网关，但不是最优解。选项B是使用EC2实例搭建SFTP服务，运维复杂。"
    },
    "related_terms": [
      "SFTP",
      "AWS",
      "S3",
      "AWS文件网关",
      "微软活动目录",
      "Amazon EC2",
      "AWS Transfer Family",
      "AWS Directory Service"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 833,
    "topic": "",
    "question_cn": "一家公司正在设计一个事件驱动的订单处理系统。在创建订单之后，每个订单都需要多个验证步骤。一个Lambda函数执行每个验证步骤。每个验证步骤与其他验证步骤无关。单个验证步骤只需要订单事件信息的一个子集。该公司希望确保每个验证步骤的Lambda函数只能访问来自该函数所需要的订单事件的信息。订单处理系统的组件应该松散耦合以适应未来的业务变化？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "为每个验证步骤创建一个Amazon Simple Queue Service队列。创建一个新的 Lambda 函数将订单数据转换为每个验证步骤所需的格式并将消息发布到相应的 SQS队列。订阅每个验证步骤Lambda函数到其相应的小规模服务协议队列",
      "B": "创建一个Amazon Simple Notification Service(SNS)主题。将验证步骤Lambda函数订阅到SNS主题。使用消息体过滤只将所需数据发送到每个订阅的 Lambda 函数。",
      "C": "创建一个Amazon EventBridge事件总线。为每个验证步骤创建一个事件规则。配置输入变压器只向每个目标验证步骤发送所需数据。",
      "D": "创建一个Amazon Simple Queue Service队列。创建一个新的 Lambda 函数以订阅 SQS队列并将订单数据转换为每个验证步骤所需的格式。使用新的 Lambda 函数在单独线程上执行同步调用验证步骤 Lambda 函数。"
    },
    "vote_percentage": "89%",
    "tags": [
      "EventBridge",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点是事件驱动架构和松耦合。EventBridge可以实现事件的路由和转换，且Input Transformer可以实现数据过滤，只传递Lambda函数需要的数据。",
      "why_correct": "选项C使用了EventBridge和输入转换器，可以实现事件路由、数据过滤和松耦合。",
      "why_wrong": "选项A使用SQS和Lambda，需要手动转换数据，且耦合度较高。选项B使用SNS，无法进行数据转换。选项D使用SQS和Lambda，增加了复杂性。"
    },
    "related_terms": [
      "Lambda",
      "Amazon Simple Queue Service",
      "SQS",
      "Amazon Simple Notification Service",
      "SNS",
      "EventBridge"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 834,
    "topic": "",
    "question_cn": "一家公司正在将一个三级应用程序迁移到AWS。应用程序需要一个MySQL数据库。过去应用程序用户在创建新条目时报告应用程序性能差。造成这些性能问题的原因是用户在工作时间从应用程序生成不同的实时报告。AWS？当应用程序移动到AWS时，哪个解决方案将提高其性能",
    "options_cn": {
      "A": "将数据导入具有供给容量的Amazon DynamoDB表。将应用程序重构为报表使用DynamoDB。",
      "B": "在计算优化的Amazon EC2实例上创建数据库。确保计算资源超过现场数据库。",
      "C": "创建一个具有多个读取副本的Amazon Aurora MySQL多数据库集群。将应用程序配置为使用报告的读者端点。",
      "D": "创建一个Amazon Aurora MySQL多数据库集群。将应用程序配置为使用集群的备份实例作为报表的端点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora Read Replicas",
      "MySQL Performance"
    ],
    "explanation": {
      "analysis": "核心考点是数据库性能优化，特别是针对读操作的优化。使用Aurora的只读副本可以分担读负载，提高性能。",
      "why_correct": "选项C使用Aurora多可用区数据库集群并配置了只读副本，可以分担读负载，改善性能。",
      "why_wrong": "选项A使用了DynamoDB，不适合关系型数据库。选项B优化了计算资源，但没有针对读性能优化。选项D使用了备份实例作为报告端点，可能会影响备份，且不是最优解。"
    },
    "related_terms": [
      "MySQL",
      "DynamoDB",
      "Amazon DynamoDB",
      "EC2",
      "Amazon Aurora MySQL",
      "Aurora MySQL",
      "读取副本"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 835,
    "topic": "",
    "question_cn": "一家公司正在通过使用AWS Direct Connect将一个安全的内部网络扩展到AWS云端。房地内的网络没有直接互联网接入。一个运行在内部网络上的应用程序需要使用一个Amazon S3桶？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "创建公共虚拟接口。把AWS S3的流量通过公共虚拟接口。",
      "B": "创建VPC和NAT网关。将AWS S3的流量从酒店内网络路由到NAT网关。",
      "C": "创建VPC和AWS S3接口端点。将AWS S3流量从现场网络路由到接口端点。",
      "D": "在内部网络和直接连接之间创建窥视连接。在窥视连接处的VPC通信路线。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "Direct Connect"
    ],
    "explanation": {
      "analysis": "核心考点是使用Direct Connect和私有访问S3。通过VPC接口端点可以实现从内部网络安全地访问S3，且流量不经过Internet。",
      "why_correct": "选项C创建了VPC和S3接口端点，实现了私有访问S3的需求。",
      "why_wrong": "选项A使用了公共虚拟接口，但S3的流量无法通过。选项B使用了NAT网关，需要经过Internet。选项D的解决方案不完整。"
    },
    "related_terms": [
      "AWS Direct Connect",
      "VPC",
      "Amazon S3",
      "NAT网关",
      "S3接口端点",
      "窥视连接"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 836,
    "topic": "",
    "question_cn": "一家公司通过使用Amazon EC2实例的一个自动缩放组为其网站服务。网站不需要数据库。该公司正在扩张，公司的工程团队将网站部署到第二个地区。该公司希望在这两个地区分配流量以适应增长和灾后恢复的目的。解决方案不应该服务于来自网站不健康区域的流量？公司应使用哪些政策或资源来满足这些要求",
    "options_cn": {
      "A": "使用Amazon Route 53的简单路由策略",
      "B": "使用Amazon Route 53的多值答复路由策略",
      "C": "在一个区域的应用程序负载平衡器目标组指定来自两个区域的EC2实例",
      "D": "在一个区域的应用程序负载平衡器目标组指定来自两个区域的EC2实例的IP地址"
    },
    "vote_percentage": "100%",
    "tags": [
      "Route 53",
      "Health Checks"
    ],
    "explanation": {
      "analysis": "核心考点是流量分配和健康检查。使用Route 53的多值答复路由策略并结合健康检查，可以实现跨区域的流量分配，并且避免将流量发送到不健康的区域。",
      "why_correct": "选项B使用了Route 53的多值答复路由策略并结合健康检查，满足了流量分配和健康检查的需求。",
      "why_wrong": "选项A使用了简单路由策略，无法实现跨区域的流量分配。选项C/D在一个区域的ALB配置目标组，无法实现跨区域负载均衡。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "Amazon Route 53"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 837,
    "topic": "",
    "question_cn": "一家公司在Amazon EC2实例上运行其应用程序这些应用程序得到了Amazon EBS的支持。实例运行最新的Amazon Linux版本。当公司员工存储和检索或更大的文件时应用程序正在经历可用性问题。该公司需要一个解决方案不要求公司转移EC2文件之间的实例。这些文件必须在许多实例和多个可用性区之间可用。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "把所有文件转移到一个Amazon S3桶。指示员工从S3桶中获取文件。",
      "B": "对现有EBS卷进行快照。在EC2实例中将快照挂载为EBS卷。指示员工访问实例中的文件。",
      "C": "在所有EC2实例中安装一个Amazon EFS文件系统。指示员工访问实例中的文件。",
      "D": "从EC2实例中创建一个Amazon机器映像。从使用实例存储卷的EC2实例中配置新的EC2实例。指示员工访问实例中的文件。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "EC2"
    ],
    "explanation": {
      "analysis": "核心考点：解决EC2实例之间文件共享和可用性问题。选项C是最佳方案，因为它使用了EFS，提供跨多个可用区的文件共享能力。",
      "why_correct": "EFS提供了一个共享文件系统，可以在多个EC2实例之间共享文件，并具有高可用性和可伸缩性，满足题目要求。",
      "why_wrong": "A: 将文件转移到S3需要修改应用程序，不符合题干中“不要求公司转移EC2文件”的要求；B: EBS快照只提供了备份，不能满足多个实例共享文件的需求；D: 创建AMI创建了新的实例，并没有解决文件共享问题。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EBS",
      "Amazon EFS",
      "Amazon S3",
      "EBS卷",
      "EC2实例",
      "EC2"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 838,
    "topic": "",
    "question_cn": "一家公司在Amazon RDS数据库的支持下在Amazon EC2上运行一个高度敏感的应用程序。合规条例规定所有个人识别信息(PII)加密在休眠。解决方案架构师应该推荐哪种解决方案来满足这个需求而对基础结构的更改最少?",
    "options_cn": {
      "A": "部署AWS证书管理器生成证书。使用证书加密数据库卷。",
      "B": "部署AWS KMS生成加密密钥并使用密钥加密数据库卷。",
      "C": "使用AWS KMS密钥配置SSL加密以加密数据库卷。",
      "D": "配置Amazon EBS加密和Amazon RDS加密与KMS密钥加密实例和数据库卷。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "核心考点：解决RDS数据加密需求，并最小化对现有架构的更改。选项D是最佳方案，因为它同时对EBS和RDS使用KMS进行加密，符合“在休眠状态下加密”的要求。",
      "why_correct": "选项D通过使用KMS密钥加密EBS卷和RDS数据库，满足了合规性要求，并且能够最小化基础设施更改。",
      "why_wrong": "A: 证书加密主要用于TLS/SSL，而非存储数据的加密；B: 使用KMS加密数据库卷，缺少了对EBS的加密；C: SSL加密用于传输过程中，不能满足“休眠加密”的要求。"
    },
    "related_terms": [
      "Amazon RDS",
      "Amazon EC2",
      "AWS",
      "AWS KMS",
      "SSL",
      "Amazon EBS",
      "KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 839,
    "topic": "",
    "question_cn": "一个公司在VPC的私有子网中运行一个Lambda函数。子网有一条通过Amazon NAT进入互联网的默认路径。函数处理输入数据并将输出作为对象保存到Amazon S3上。在尝试上传对象时由于Lambda实例的网络上的流量饱和，因此在尝试上载对象的过程中Lambda函数会暂停。该公司希望在不穿越互联网的情况下访问Amazon S3。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "替换NAT实例为一个托管NAT网关。",
      "B": "将VPC中实例的大小增加到网络优化实例类型。",
      "C": "为Amazon S3提供一个网关端点并相应地对子网的路由表进行编号。",
      "D": "提供一个过境通道。将传输网关附件放置在运行Lambda函数的私有子网中。"
    },
    "vote_percentage": "88%",
    "tags": [
      "VPC Endpoint",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点：优化Lambda函数与S3的通信，避免流量拥堵并减少延迟。选项C是最佳方案，它使用S3网关端点，使得Lambda函数能够直接访问S3，无需通过互联网。",
      "why_correct": "使用S3网关端点，Lambda函数可以直接访问S3，流量不会通过Internet，从而避免了NAT实例的瓶颈，提高了性能和安全性。",
      "why_wrong": "A: 托管NAT网关可以提高可用性，但不能解决流量拥堵问题；B: 增加实例大小不能直接解决访问S3的流量问题；D: 传输网关是针对VPC互联的，在此场景下并非最佳方案。"
    },
    "related_terms": [
      "Lambda",
      "VPC",
      "Amazon NAT",
      "Amazon S3",
      "NAT网关",
      "网关端点",
      "传输网关"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 840,
    "topic": "",
    "question_cn": "世界各地都有记者的一家新闻公司正在美国广播公司主持其广播系统。记者们向广播系统直播。记者们使用手机上的软件通过实时消息传递协议发送实时消息流。解决方案架构师必须设计一个解决方案使记者能够发送最高质量的流。解决方案必须提供回到广播系统的加速的连接。解决方案架构师应该使用什么来满足这些需求?",
    "options_cn": {
      "A": "亚马逊云区",
      "B": "全球加速器",
      "C": "客户虚拟网络",
      "D": "亚马逊 EC2 实例和 弹性 IP 地址"
    },
    "vote_percentage": "100%",
    "tags": [
      "Global Accelerator",
      "Media Streaming"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是: 题目要求加速连接，Global Accelerator正是为加速全球流量设计的服务。而云区不能解决加速问题。",
      "why_correct": "Global Accelerator 提供了加速全球用户访问应用程序的功能，特别适合需要加速全球范围内用户连接到应用程序的场景。",
      "why_wrong": "A: 云区与加速没有直接关系；C: 客户虚拟网络主要用于构建私有网络，与加速无关；D: EC2实例和弹性IP不能提供加速功能。"
    },
    "related_terms": [
      "EC2",
      "全球加速器",
      "弹性 IP 地址"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 841,
    "topic": "",
    "question_cn": "一家公司使用Amazon EC2实例和Amazon EBS运行自己管理的数据库。该公司拥有350个结核数据分布在EBS的所有卷中。公司每天拍摄EBS快照并将快照保存一个月。每日的变化率是EBS卷的5%。由于新规定公司需要将每月快照保存七年。该公司需要改变其备份战略以符合新的条例并确保以最小的行政努力提供数据。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "将EBS快照中的每日快照保存一个月。将每月快照复制到Amazon Glacier深度档案馆保留期为7年。",
      "B": "继续当前EBS快照策略。添加一个新的策略将每月快照移动到Amazon EBS快照存档保留期为7年。",
      "C": "将EBS快照中的每日快照保存一个月。将每月快照保存在标准层中7年。使用增量快照。",
      "D": "将每日快照保存在EBS快照标准层中。使用直接EBS API每个月对EBS卷进行快照。将快照存储在Amazon S3桶中在不常访问的层中长达7年。"
    },
    "vote_percentage": "45%",
    "tags": [
      "EBS Snapshot Archive",
      "Backup Retention"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是: 针对7年数据保存，EBS快照存档是更适合的存储方案。",
      "why_correct": "选项B使用了EBS快照存档，这是专门为长期保存快照设计的，可以满足7年的保留需求，并且管理成本较低。",
      "why_wrong": "A: 将快照复制到Glacier Deep Archive，虽然可以满足长期存储需求，但恢复成本和时间较高，不如快照存档便捷；C: 在标准层保存7年成本过高；D: 使用S3存储快照，管理复杂，且不如EBS快照存档方便。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "EBS快照",
      "Amazon Glacier",
      "EBS快照存档",
      "增量快照",
      "Amazon S3",
      "S3桶",
      "S3",
      "EBS API"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 842,
    "topic": "",
    "question_cn": "一家公司在Amazon EFS文件系统上运行一个存储持久数据的Amazon EC2实例应用程序。该公司需要使用托管AWS的服务解决方案将数据复制到另一个区域。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "使用EFS到EFS备份解决方案将数据复制到另一个区域的EFS文件系统。",
      "B": "运行一个夜间脚本以便将EFS文件系统中的数据复制到一个Amazon S3桶中。在S3桶上允许跨区域复制。",
      "C": "在另一个区域创建VPC。建立跨地区VPC同行。每天晚上运行一个同步系统将数据从原来的区域复制到新的区域。",
      "D": "使用EFS备份创建具有每天使用备份并将其复制到另一个区域的规则的备份计划。将EFS文件系统资源分配给备份计划。"
    },
    "vote_percentage": "71%",
    "tags": [
      "EFS Replication",
      "EFS Backup"
    ],
    "explanation": {
      "analysis": "核心考点：EFS跨区域复制。选项D使用EFS备份功能并配置跨区域复制，是最直接且有效的方法。",
      "why_correct": "选项D利用EFS备份和跨区域复制功能，可以方便地将EFS数据复制到另一个区域，满足了题目的要求，而且配置和管理比较简单。",
      "why_wrong": "A: EFS到EFS备份解决方案通常需要手动配置和管理，不如EFS备份计划方便；B: 将数据复制到S3再进行跨区域复制，增加了复杂性，且涉及额外的存储成本；C: VPC对等和数据同步，对于EFS的跨区域复制来说，过于复杂，且需要手动管理数据同步。"
    },
    "related_terms": [
      "Amazon EFS",
      "EC2",
      "EFS",
      "Amazon S3",
      "跨区域复制",
      "VPC",
      "VPC",
      "VPC同行",
      "EFS备份"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 843,
    "topic": "",
    "question_cn": "一家电子商务公司正在将其公司内部的工作量转移到AWS云端。当前的工作负载包括一个Web应用程序和一个用于存储的微软SQL后端数据库。该公司期望在促销活动中有大量客户。云中的新基础设施必须是高度可用和可伸缩的。用最少的管理费用来满足这些需求的解决方案是什么?",
    "options_cn": {
      "A": "将Web应用程序迁移到两个Amazon EC2实例跨越应用程序负载平衡器后面的两个可用性区域。将数据库迁移到Amazon RDS中的微软SQL服务器并在两个可用性区域中使用读取副本。",
      "B": "将Web应用程序迁移到Amazon EC2实例中该实例在应用程序负载平衡器后面的两个可用性区域中运行于一个自动缩放组。将数据库迁移到两个EC2实例并在不同的区域进行数据库复制。",
      "C": "将Web应用程序迁移到Amazon EC2实例中这些实例在应用程序负载平衡器后面的两个可用性区域中运行。通过多可用区部署将数据库迁移到Amazon RDS。",
      "D": "将Web应用程序迁移到3个Amazon EC2实例跨越应用程序负载平衡器后面的3个可用性区域。在三个可用性区域将数据库迁移到三个EC2实例。"
    },
    "vote_percentage": "88%",
    "tags": [
      "RDS Multi-AZ",
      "EC2 Auto Scaling"
    ],
    "explanation": {
      "analysis": "核心考点：Web应用和数据库的高可用性和可伸缩性。选项C使用RDS多可用区部署，确保数据库的高可用性，结合EC2的自动缩放组，满足了高可用性和可伸缩性的要求，且管理开销最少。",
      "why_correct": "RDS多可用区部署提供了数据库的高可用性，EC2自动伸缩组使得应用程序可以根据负载自动伸缩，满足题目的要求，并且管理上相对简单。",
      "why_wrong": "A: 数据库使用读取副本，不能完全保证高可用性；B: 数据库迁移到EC2，需要手动管理数据库，增加了复杂性；D: 3个EC2实例在三个可用区，管理费用增加，不如使用RDS的多可用区部署。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "可用性区域",
      "RDS",
      "微软SQL",
      "读取副本",
      "自动缩放组",
      "多可用区部署"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 844,
    "topic": "",
    "question_cn": "一家公司有一个内部业务应用程序每天生成数百个文件。这些文件存储在SMB文件共享上需要与应用服务器进行低延迟连接。一个新的公司政策声明所有应用生成的文件必须复制到AWS。已经有一个AWS VPN连接到AWS。应用程序开发团队没有时间进行必要的代码修改以便将应用程序移动到AWS。解决方案架构师应该推荐哪种服务来允许应用程序将文件复制到AWS?",
    "options_cn": {
      "A": "亚马逊弹性文件系统",
      "B": "Windows FSx 用于SMB文件服务器的亚马逊",
      "C": "滚雪球",
      "D": "存储网关"
    },
    "vote_percentage": "50%",
    "tags": [
      "Storage Gateway",
      "File Share Migration"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为B。社区倾向B的原因是: 题目场景是文件服务器，FSx for Windows File Server更适合，且FSx提供了SMB协议的兼容性，易于迁移。",
      "why_correct": "FSx for Windows File Server 提供了SMB协议的兼容性，可以直接将本地SMB文件共享迁移到AWS，且管理方便。",
      "why_wrong": "A: 弹性文件系统主要用于Linux文件系统，不兼容SMB；C: 滚雪球主要用于大量数据的离线迁移，不适用于持续的文件复制场景；D: 存储网关也适用，但 FSx 更直接，更易于迁移。"
    },
    "related_terms": [
      "Amazon EFS",
      "Windows FSx",
      "SMB",
      "滚雪球",
      "存储网关",
      "AWS VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 845,
    "topic": "",
    "question_cn": "一家公司有15名员工。该公司在Amazon DynamoDB上储存员工的开始日期。公司希望在员工工作周年纪念日当天向每位员工发送电子邮件。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "创建一个脚本扫描DynamoDB表并使用Amazon SNS（亚马逊简单通知服务）发送电子邮件给雇员必要时。每天在Amazon EC2实例中使用Cron作业来运行这个脚本。",
      "B": "创建一个脚本扫描DynamoDB表并使用Amazon SQS（亚马逊简单队列服务）在必要时向员工发送电子邮件消息。每天在Amazon EC2实例中使用Cron作业来运行这个脚本。",
      "C": "创建一个Lambda函数扫描DynamoDB表并在必要时使用Amazon SNS向员工发送电子邮件。安排这个Lambda函数每天运行。",
      "D": "创建一个Lambda函数它可以扫描DynamoDB表并在必要时使用Amazon SQS向员工发送电子邮件。安排这个Lambda函数每天运行。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Lambda",
      "SNS"
    ],
    "explanation": {
      "analysis": "核心考点：定时任务和发送邮件。选项C是最佳方案，它使用Lambda函数和SNS发送邮件，并使用EventBridge定时触发，实现自动化，开销较小。",
      "why_correct": "使用Lambda函数和SNS可以实现自动化，无需管理EC2实例，减少了运维成本。Lambda函数通过EventBridge进行定时触发，按需发送邮件，效率高，成本低。",
      "why_wrong": "A: 需要维护EC2实例，运维成本较高；B: SQS用于解耦，在此场景下，SNS更适合直接发送邮件；D: SQS用于解耦，在此场景下，SNS更适合直接发送邮件。"
    },
    "related_terms": [
      "DynamoDB",
      "Amazon SNS",
      "EC2",
      "Cron",
      "Lambda",
      "Amazon SQS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 846,
    "topic": "",
    "question_cn": "一个公司的应用程序运行在Amazon EC2实例在一个弹性负载平衡器负载平衡器后面的一个自动缩放组内。根据该应用程序的历史，该公司预计每年假日期间的流量会激增。解决方案架构师必须设计一个策略以确保自动缩放组主动增加能力以最大限度地减少对应用程序用户的性能影响。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "当CPU利用率超过90%时，创建一个亚马逊云表警报以扩大EC2实例。",
      "B": "创建一个循环计划的动作在预期需求高峰期之前扩展自动扩展组。",
      "C": "在需求高峰期增加自动缩放组中EC2实例的最小和最大数目。",
      "D": "配置亚马逊简单通知服务通知以便在发生自动卡线EC2实例发射事件时发出警报。"
    },
    "vote_percentage": "91%",
    "tags": [
      "Auto Scaling",
      "Scheduled Actions"
    ],
    "explanation": {
      "analysis": "核心考点：自动扩缩容的配置。选项B使用了预定义的计划动作，可以提前进行扩容，以应对预知的流量高峰。",
      "why_correct": "计划操作可以基于已知流量模式提前进行扩容，从而在流量高峰到来之前就准备好足够的资源，减少对应用程序用户的影响。",
      "why_wrong": "A: 反应滞后，可能在高峰期时才触发扩容，用户体验差；C: 仅修改最小和最大实例数，并不能保证在高峰期之前进行扩容；D: 仅发送警报，并不能自动扩容，需要手动干预。"
    },
    "related_terms": [
      "EC2",
      "弹性负载平衡器",
      "自动缩放组",
      "CPU利用率",
      "自动扩展组",
      "亚马逊云表警报",
      "亚马逊简单通知服务"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 847,
    "topic": "",
    "question_cn": "一个公司使用Amazon RDS作为其数据层的后端数据库。公司必须对数据库进行密码轮换。用最少的操作开销来满足这个需求的解决方案是什么?",
    "options_cn": {
      "A": "将密码存储在美国情报系统机密管理器中。允许自动旋转秘密",
      "B": "将密码存储在系统管理器参数存储中 允许对参数进行自动旋转",
      "C": "将密码存储在系统管理器参数存储中。编写一个旋转密码的Lambda函数。",
      "D": "将密码存储在密钥管理服务中。启用自动旋转上的密钥。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Secrets Manager",
      "Password Rotation"
    ],
    "explanation": {
      "analysis": "核心考点：RDS密码轮换。选项A使用Secrets Manager，它原生支持密码自动轮换，最符合题意。",
      "why_correct": "Secrets Manager 提供了密码自动轮换的功能，可以简化密码管理，并满足安全性需求。",
      "why_wrong": "B: Parameter Store不支持密码自动轮换；C: 需要编写Lambda函数，增加了复杂性；D: KMS用于加密密钥，而不是密码轮换。"
    },
    "related_terms": [
      "Amazon RDS",
      "系统管理器参数存储",
      "Lambda",
      "密钥管理服务",
      "KMS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 848,
    "topic": "",
    "question_cn": "一家公司在甲骨文数据库企业版上运行它的应用程序。公司需要将应用程序和数据库迁移到AWS。该公司可以使用自己的许可证 (BYOL) 模型迁移到AWS。应用程序使用第三方数据库功能这些功能需要有特权访问。解决方案架构师必须为数据库迁移设计解决方案。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "使用本地工具将数据库迁移到Amazon RDS。将第三方功能替换为Lambda。",
      "B": "通过使用本地工具将数据库迁移到Amazon RDS的自定义。自定义新的数据库设置以支持第三方功能。",
      "C": "通过使用数据库迁移服务将数据库迁移到Amazon DynamoDB。自定义新的数据库设置以支持第三方功能。",
      "D": "通过使用数据库迁移服务将数据库迁移到Amazon RDS用于后端SQL。重写应用程序代码以删除对第三方特性的依赖。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Database Migration",
      "BYOL"
    ],
    "explanation": {
      "analysis": "核心考点：数据库迁移和BYOL。选项B使用本地工具迁移到RDS，并可以进行自定义以支持第三方功能，满足了BYOL和功能需求。",
      "why_correct": "使用本地工具可以更灵活地迁移数据库，并且可以通过自定义设置来支持第三方功能，满足了BYOL和功能需求。",
      "why_wrong": "A: 将第三方功能替换为Lambda，可能需要大量重构代码，且不一定能完全实现相同的功能；C: 迁移到DynamoDB不合适；D: 重写代码可能导致大量工作量。"
    },
    "related_terms": [
      "Amazon RDS",
      "Lambda",
      "Amazon DynamoDB",
      "数据库迁移服务",
      "SQL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 849,
    "topic": "",
    "question_cn": "一个大型的国际大学已经将其所有的计算服务部署在AWS云中。这些服务包括Amazon EC2、Amazon RDS和Amazon DynamoDB。该大学目前依靠许多定制脚本来备份其基础设施。然而大学希望通过使用AWS本地选项尽可能地集中管理和自动化数据备份。哪种解决方案能满足这些要求?",
    "options_cn": {
      "A": "使用第三方备份软件与存储网关磁带网关虚拟磁带库。",
      "B": "使用AWS Backup来配置和监视正在使用的服务的所有备份。",
      "C": "使用AWS Backup，配置设置生命周期管理以获取日程表上所有数据源的快照。",
      "D": "使用系统管理器状态管理器来管理备份任务的配置和监控。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS Backup",
      "Backup Automation"
    ],
    "explanation": {
      "analysis": "核心考点：备份方案。选项B使用了AWS Backup，可以集中管理各种AWS服务的备份，满足了集中管理和自动化的需求。",
      "why_correct": "AWS Backup 是一个集中式的备份服务，可以自动管理EC2、RDS、DynamoDB等服务的备份，满足了集中管理和自动化的需求。",
      "why_wrong": "A: 使用第三方软件，增加了复杂性，不如AWS Backup方便；C: 生命周期的管理主要针对S3的对象，不如AWS Backup直接；D: System Manager状态管理器并非专门的备份管理工具。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "DynamoDB",
      "存储网关",
      "AWS Backup",
      "AWS Backup",
      "生命周期管理",
      "系统管理器状态管理器",
      "VTL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 850,
    "topic": "",
    "question_cn": "一家公司希望绘制其IT基础设施地图以确定和执行对资源构成安全风险的政策。该公司的安全团队必须能够查询基础设施图中的数据并快速识别安全风险。用最少的操作开销来满足这些需求的解决方案是什么?",
    "options_cn": {
      "A": "使用Amazon RDS SQL存储数据。使用SQL查询数据以识别安全风险。",
      "B": "使用Amazon Neptune存储数据。使用SPARQL来查询数据以识别安全风险。",
      "C": "使用Amazon Redshift存储数据。使用SQL查询数据以识别安全风险。",
      "D": "使用Amazon DynamoDB存储数据。使用PXQL来查询数据以识别安全风险。"
    },
    "vote_percentage": "86%",
    "tags": [
      "Neptune",
      "Graph Database"
    ],
    "explanation": {
      "analysis": "核心考点：基础设施图和安全风险识别。选项B使用Neptune，这是一个图数据库，非常适合存储和查询基础设施图，从而快速识别安全风险。",
      "why_correct": "Neptune是一种图数据库，非常适合存储基础设施关系，方便进行安全风险分析和查询，并且支持SPARQL查询语言。",
      "why_wrong": "A: RDS SQL不是图数据库；C: Redshift用于数据仓库，不适合存储图数据；D: DynamoDB不是图数据库，PXQL也不是标准的查询语言。"
    },
    "related_terms": [
      "Amazon RDS",
      "SQL",
      "Amazon Neptune",
      "SPARQL",
      "Amazon Redshift",
      "Amazon DynamoDB",
      "PXQL"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 851,
    "topic": "",
    "question_cn": "一个大公司希望为开发目的提供其位于全球各地的开发人员单独的、规模有限的、受管理的后格勒格数据库。数据库会很少。开发人员只有在他们正在工作时才需要数据库。哪种解决方案能最有效地满足这些要求?",
    "options_cn": {
      "A": "给予开发人员启动单独的亚马逊Aurora实例的能力。设置一个过程在工作日结束时关闭Aurora实例并在下一个工作日开始时启动Aurora实例。",
      "B": "开发一个服务目录产品为启动亚马逊Aurora实例强制规模限制。当开发人员需要开发数据库时允许他们进入产品的发布。",
      "C": "创建一个亚马逊Aurora无服务集群。开发一个服务目录产品在集群中启动具有默认容量设置的数据库。允许开发人员访问产品。",
      "D": "监控AWS RDS信任的顾问检查闲置的亚马逊RDS数据库。创建一个过程来终止识别的闲置RDS数据库。"
    },
    "vote_percentage": "75%",
    "tags": [
      "Aurora Serverless",
      "Service Catalog"
    ],
    "explanation": {
      "analysis": "核心考点：为开发人员提供按需数据库。选项C使用Aurora Serverless和Service Catalog，提供了按需创建和管理的数据库，满足了需求，并且成本较低。",
      "why_correct": "使用Aurora Serverless可以按需提供数据库，无需预先配置容量，成本较低。结合Service Catalog，开发人员可以自助创建数据库。",
      "why_wrong": "A: 需要手动管理数据库的启动和关闭；B: 仍然需要管理Aurora实例的规模；D: 无法满足开发人员按需创建数据库的需求。"
    },
    "related_terms": [
      "Amazon Aurora",
      "RDS",
      "服务目录",
      "Aurora",
      "AWS RDS",
      "AWS RDS",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 852,
    "topic": "",
    "question_cn": "一家公司正在开发一个网络应用程序为内容管理系统提供服务。内容管理系统运行在Amazon EC2实例后面的一个应用负载平衡器(ALS)。EC2实例在多个可用性区域的自动缩放组中运行。用户经常在内容管理系统中添加和更新文件、博客和其他网站资产。解决方案架构师必须实现一种解决方案，即所有EC2实例都以尽可能少的滞后时间共享最新的网站内容。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "EC2实例ALS，更新自动扩展组生命周期策略中的用户数据以从最近启动的EC2实例中复制网站资产。只在最新的EC2实例中配置对网站资产进行更改。",
      "B": "复制网站资产到Amazon EFS弹性文件系统。将每个EC2实例配置到本地的EFS文件系统。配置网站托管应用程序以引用存储在EFS文件系统中的网站资产。",
      "C": "复制网站资产到一个Amazon S3桶。确保每个EC2实例从S3桶下载网站资产到附加的Amazon EBS卷。每小时运行一次S3同步命令以更新文件。",
      "D": "使用网站资产恢复Amazon EBS快照。在启动新的EC2实例时将快照作为次级EBS卷附加。配置网站托管应用程序以引用存储在次级EBS卷中的网站资产。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EFS",
      "Content Management System"
    ],
    "explanation": {
      "analysis": "此题考察在EC2实例间共享静态内容的方法。最佳方案是使用Amazon EFS共享文件系统，确保所有实例都能访问最新内容。",
      "why_correct": "EFS 提供了一个简单、可扩展且高度可用的文件存储解决方案，非常适合在多个 EC2 实例之间共享网站内容。 选项 B 中，将每个 EC2 实例挂载到 EFS 文件系统，保证了数据同步，且性能较好。",
      "why_wrong": "选项 A: 在实例启动时复制数据，更新延迟较高，同步需要管理；选项 C: S3 同步操作增加了延迟，且EBS作为存储性能相对较差；选项 D: 快照恢复需要时间，不适合快速同步。"
    },
    "related_terms": [
      "Amazon EC2",
      "应用负载平衡器",
      "ALS",
      "EFS",
      "EFS弹性文件系统",
      "Amazon S3",
      "S3",
      "S3同步",
      "Amazon EBS",
      "EBS快照",
      "自动缩放组",
      "EC2",
      "EBS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 853,
    "topic": "",
    "question_cn": "一家公司的Web应用程序由多个Amazon EC2实例组成，这些实例运行在VPC中的应用负载平衡器后面。用于EC2实例的Amazon RDS数据库包含数据。该公司需要有能力自动检测和回应可疑或意外的行为在其美国信息系统环境。该公司已经在其架构中加入了AWS WAF。解决方案架构师接下来应该做什么来防范威胁？",
    "options_cn": {
      "A": "使用Amazon GuardDuty保护任务执行威胁检测。配置Amazon Lambda来过滤GuardDuty的结果并调用一个 Lambda函数来调整AWS WAF规则。",
      "B": "使用AWS Firewall Manager来执行威胁检测。配置Amazon Lambda来过滤Firewall Manager的发现并调用一个 Lambda函数来调整AWS WAF的规则。",
      "C": "使用Amazon Inspector来执行威胁检测并更新VPC ACL规则。创建一个VPC网络以限制对Web应用程序的访问。",
      "D": "使用Amazon Macie来执行威胁检测和更新AWS WAF规则。创建一个VPC网络以限制对Web应用程序的访问。"
    },
    "vote_percentage": "100%",
    "tags": [
      "GuardDuty",
      "WAF"
    ],
    "explanation": {
      "analysis": "此题考察如何结合GuardDuty 和 WAF 防御 Web 应用程序。最佳实践是使用 GuardDuty 进行威胁检测，并结合 Lambda 和 WAF 实现自动响应。",
      "why_correct": "选项A:  使用 GuardDuty 进行威胁检测， GuardDuty 检测到威胁后可以触发Lambda 函数，用于更新 AWS WAF 规则，从而对威胁进行响应和缓解。 这个方案自动化程度高。",
      "why_wrong": "选项 B：使用 Firewall Manager 检测，虽然也能实现，但不如GuardDuty专业；选项 C：Inspector 和 VPC ACL 侧重于安全评估和访问控制，无法自动响应威胁；选项 D：Macie 侧重于数据安全，与题干不符。"
    },
    "related_terms": [
      "Web应用程序",
      "EC2",
      "VPC",
      "应用负载平衡器",
      "Amazon RDS",
      "AWS WAF",
      "Amazon GuardDuty",
      "Amazon Lambda",
      "AWS WAF",
      "AWS Firewall Manager",
      "VPC ACL",
      "Amazon Inspector",
      "Amazon Macie",
      "VPC"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 854,
    "topic": "",
    "question_cn": "一家公司正计划运行一组连接到Amazon Aurora数据库的Amazon EC2实例。该公司已经建立了一个CloudFormation模板用于部署EC2实例和Aurora数据库集群。公司希望允许实例以安全的方式对数据库进行身份验证。公司不想维护静态数据库凭证。用最少的工作来满足这些要求的解决方案是什么？",
    "options_cn": {
      "A": "创建具有用户名和密码的数据库用户。在CloudFormation模板中添加数据库用户名和密码的参数。在启动实例时将参数传递给EC2实例。",
      "B": "创建具有用户名和密码的数据库用户。在AWS Systems Manager Parameter Store中存储用户名和密码。配置EC2实例以从Parameter Store中检索数据库凭据。",
      "C": "配置数据库集群以使用IAM数据库身份验证。创建一个数据库用户来使用IAM身份验证。将一个IAM角色与EC2实例关联起来，允许实例上的应用程序访问数据库。",
      "D": "配置数据库集群以便与IAM用户使用IAM数据库身份验证。创建一个数据库用户，其名称与IAM用户相匹配。将IAM用户与EC2实例关联起来，允许实例上的应用程序访问数据库。"
    },
    "vote_percentage": "100%",
    "tags": [
      "IAM Database Authentication",
      "EC2 Aurora"
    ],
    "explanation": {
      "analysis": "此题考察使用 IAM 数据库身份验证，以便 EC2 实例安全地访问 Aurora 数据库。 这是最安全的方案，因为它避免了静态凭证。",
      "why_correct": "选项 C: 使用 IAM 数据库身份验证，避免了在实例中存储凭据，提高安全性；通过IAM角色将权限赋予EC2实例，更加安全和灵活。",
      "why_wrong": "选项 A: 使用用户名密码，不安全；选项 B: 使用 Parameter Store，安全性稍好，但不如 IAM 数据库身份验证；选项 D: 方案可行，但比选项 C 复杂，并且依赖于 IAM 用户，而不是角色。"
    },
    "related_terms": [
      "Amazon Aurora",
      "EC2",
      "CloudFormation",
      "IAM",
      "IAM数据库身份验证",
      "AWS Systems Manager Parameter Store"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 855,
    "topic": "",
    "question_cn": "一家公司希望将其Amazon CloudFront分布配置为使用SSL/TLS证书。公司不希望使用默认域名的发行。相反，该公司希望使用不同的域名发行。哪个解决方案将在不增加任何费用的情况下部署证书？",
    "options_cn": {
      "A": "请求Amazon ACM从美国东部 (弗吉尼亚北部) 地区的证书管理器颁发私人证书。",
      "B": "请求Amazon ACM从美国西部 (俄勒冈) 地区的证书管理器颁发私人证书。",
      "C": "请求Amazon ACM从美国东部 (弗吉尼亚北部) 地区的证书经理签发公共证书。",
      "D": "请求Amazon ACM从美国西部 (俄勒冈) 地区的证书经理发放公共证书。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ACM",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为A，但社区共识(投票最高)为C。社区倾向C的原因是使用 ACM 签发公共证书，并且绑定到CloudFront，不产生额外费用。这是最符合题意的。",
      "why_correct": "选项 C:  使用 ACM 签发公共证书，可以免费获得证书。并且，CloudFront 可以使用 ACM 颁发的证书，满足题目的需求。",
      "why_wrong": "选项 A: ACM 签发私人证书需要付费；选项 B: ACM 签发私人证书需要付费；选项 D:虽然为公共证书，但地点不对。"
    },
    "related_terms": [
      "CloudFront",
      "SSL/TLS",
      "ACM"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 856,
    "topic": "",
    "question_cn": "一个公司创建操作数据并将数据存储在一个Amazon S3桶中。为了公司的年度审计，外部顾问需要访问存储在S3桶中的年度报告。外部顾问需要在7天内查阅报告。公司必须实施一个解决方案，允许外部顾问只访问报告。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个新的S3桶，它被配置为主机公共静态网站。将操作数据迁移到新的S3桶。与外部顾问分享网站的网址。",
      "B": "允许公众进入S3桶7天。当外部顾问完成审计时，删除对S3桶的访问。",
      "C": "创建一个新的IAM用户，它可以访问S3桶中的报表。提供外部顾问的访问密钥。七天后撤销访问密钥。",
      "D": "生成一个预先签名的URL，它具有对S3桶上报表位置的所需访问权限。与外部顾问共享预先签名的URL。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3",
      "Pre-signed URL"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地提供对S3桶中特定文件的临时访问。 预签名 URL 提供了最灵活和安全的解决方案。",
      "why_correct": "选项 D:  使用预签名 URL，可以为外部顾问提供对特定文件的限时访问。  这种方法是最安全的，因为它没有授予对整个桶的访问权限。可以精确地控制访问的资源和时间。",
      "why_wrong": "选项 A:  开放桶的访问，不安全，并且不能限制访问的文件；选项 B:  开放桶的访问，不安全，开放访问权限大于访问一个文件；选项 C: 创建 IAM 用户，安全性相对较好，但是还需要管理 IAM 用户的凭证。不如预签名 URL 简单。"
    },
    "related_terms": [
      "Amazon S3",
      "S3桶",
      "IAM",
      "预先签名的URL"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 857,
    "topic": "",
    "question_cn": "一家公司计划在Amazon EC2实例上运行高性能计算(HPC)工作负载。工作负载需要低延迟的网络性能和具有紧密耦合的节点到节点通信的高网络吞吐量。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将EC2实例配置为集群放置组的一部分。",
      "B": "启动带有专用实例租赁的EC2实例。",
      "C": "启动EC2实例作为竞价实例。",
      "D": "在启动EC2实例时配置随需应变能力保留。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2",
      "HPC"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为A。社区倾向A的原因是集群放置组可以实现低延迟的网络性能。",
      "why_correct": "选项 A: 将EC2实例配置为集群放置组的一部分，可以实现低延迟的网络性能，并提供紧密的节点间通信，这对于 HPC 工作负载至关重要。",
      "why_wrong": "选项 B: 专用实例虽然提供了隔离，但并不能直接改善网络性能；选项 C: 竞价实例，成本较低，但可用性不稳定，不适合 HPC；选项 D:  随需应变能力保留，主要用于保障实例的可用性，与网络性能关系不大。"
    },
    "related_terms": [
      "EC2",
      "HPC",
      "EC2",
      "集群放置组",
      "专用实例",
      "竞价实例",
      "随需应变能力"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 858,
    "topic": "",
    "question_cn": "一家公司拥有主数据中心和二级数据中心，这些数据中心相距500英里(807.7公里)，并与高速光缆连接。该公司需要一个高度可用和安全、的网络连接其数据中心和一个在AWS上的任务关键工作量。解决方案架构师必须选择提供最大弹性的连接解决方案。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "从主数据中心直接连接到两个单独设备上的两个直接连接点。",
      "B": "从每一个主数据中心和二级数据中心直接连接到同一设备上的一个直接连接位置。",
      "C": "从每个主数据中心和二级数据中心直接连接到两个直接连接点在两个独立的设备上。",
      "D": "从每个主数据中心和二级数据中心直接连接到两个独立设备上的一个直接连接点。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Direct Connect",
      "High Availability"
    ],
    "explanation": {
      "analysis": "此题考察如何设计高可用性的Direct Connect连接。 关键在于冗余，以避免单点故障。",
      "why_correct": "选项 C:  从每个主数据中心和二级数据中心连接到两个不同的Direct Connect位置，并且这些连接位于两个独立的设备上。 这种双重冗余提供了最高的可用性，因为即使一个连接或设备发生故障，流量仍然可以通过另一个连接保持通畅。",
      "why_wrong": "选项 A: 从主数据中心直接连接到两个单独设备上的两个直接连接点，主数据中心如果出现问题，则不可用;选项 B:  存在单点故障；选项 D:  不完全冗余。"
    },
    "related_terms": [
      "直接连接",
      "AWS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 859,
    "topic": "",
    "question_cn": "一家公司为甲骨文点播数据库实例运行了几个使用率高的Amazon RDS。数据库实例运行在成员帐户中，是在一个组织的AWS世界卫生组织。AWS公司的财务团队可以访问本组织的管理账户和成员账户。财务团队希望通过使用信任的顾问来找到优化成本的方法。哪些步骤组合将满足这些要求？(选择两个)",
    "options_cn": {
      "A": "使用管理帐户中受信任的顾问建议。",
      "B": "在RDS数据库实例正在运行的成员帐户中使用受信任的顾问建议。",
      "C": "回顾受信任的顾问检查Amazon RDS保留实例优化。",
      "D": "回顾受信任的顾问检查Amazon RDS闲置的db实例。",
      "E": "回顾受信任的顾问检查计算优化。用计算优化器交叉检查结果。"
    },
    "vote_percentage": "62%",
    "tags": [
      "RDS Cost Optimization",
      "Trusted Advisor"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BC，但社区共识(投票最高)为AC。社区倾向AC的原因是，结合Trusted Advisor，检查管理账户和RDS 保留实例优化，可以更全面的优化成本。",
      "why_correct": "选项 A: 使用管理账户的 Trusted Advisor 建议，可以帮助识别组织层面的成本优化机会；选项 C: 审查保留实例的建议，可以帮助节省 RDS 数据库的成本，这是成本优化的重要方面。",
      "why_wrong": "选项 B: 在成员账户中使用 Trusted Advisor，可以获得成员账户的成本建议，但是不够全面；选项 D: RDS 闲置 db 实例的检查，可以节省成本，但不是最佳选择；选项 E: 计算优化，不如 RDS 优化更直接。"
    },
    "related_terms": [
      "RDS",
      "Amazon RDS",
      "受信任的顾问",
      "RDS",
      "计算优化器"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 860,
    "topic": "",
    "question_cn": "解决方案架构师正在创建一个应用程序。该应用程序将在一个VPC中的多个可用性区域的私有子网上运行Amazon EC2实例。EC2实例将经常访问包含机密信息的大型文件。这些文件存储在Amazon S3桶中进行处理。解决方案架构师必须优化网络架构以最小化数据传输成本。解决方案架构师应该做什么来满足这些需求？",
    "options_cn": {
      "A": "在VPC中为Amazon S3创建网关端点。在专用子网的路由表中添加网关端点的条目。",
      "B": "在公共子网中创建单个NAT网关。在私有子网的路由表中添加指向NAT网关的默认路由。",
      "C": "在为私有子网的路由表的VPC中为Amazon S3创建一个接口端点。为接口端点添加一个条目。",
      "D": "为公共子网络中的每个可用区域创建一个NAT网关。在私有子网的每个路由表中添加指向同一可用性区域中的NAT网关的默认路由。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 VPC Endpoint",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是，使用网关端点访问S3可以避免产生数据传输费用。",
      "why_correct": "选项 A:  使用 VPC 网关端点访问 S3，数据传输不会产生额外费用。这是在 VPC 中访问 S3 的最低成本方法。",
      "why_wrong": "选项 B:  使用 NAT 网关，会产生数据处理费用；选项 C: 接口端点会产生费用，并且费用相对较高；选项 D:  为每个可用区创建NAT网关，会产生更多的成本，并且每个NAT网关也会产生费用。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "S3",
      "S3桶",
      "Amazon S3",
      "VPC",
      "NAT网关",
      "接口端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 861,
    "topic": "",
    "question_cn": "一家公司希望将其内部的MySQL数据库迁移到AWS。数据库接受来自面向客户的应用程序的定期导入，这导致大量的写入操作。该公司担心流量可能会在应用程序中造成性能问题。解决方案架构师应该如何设计基于AWS的架构？",
    "options_cn": {
      "A": "为MySQL RDS实例提供了一个具有配置的SSD存储器的Amazon RDS。监视器使用Amazon CloudWatch编写操作指标。如有必要，调整已备好的ISPS好的。",
      "B": "为MySQL RDS实例提供一个具有通用SSD存储的Amazon RDS。将一个Amazon ElastiCache集群放在RDS实例的前面。将应用程序配置为查询ElastiCache。",
      "C": "提供一个具有内存优化实例类型的Amazon文档，具有MongoDB兼容性RDS实例。监控Amazon CloudWatch与性能相关的问题。必要时更改实例类。",
      "D": "提供一个具有通用性能模式的Amazon EFS弹性文件系统。监控Amazon的CloudWatch系统以发现瓶颈。如有必要，更改为提供的吞吐量性能模式。"
    },
    "vote_percentage": "85%",
    "tags": [
      "RDS",
      "MySQL"
    ],
    "explanation": {
      "analysis": "此题考察如何优化 RDS MySQL 数据库的性能，特别是应对大量写入操作。 选项A提供了最优的方案：使用 RDS，配备SSD存储，并使用CloudWatch监控性能，根据需要调整存储配置。",
      "why_correct": "选项 A: 使用 RDS 并且配置 SSD 存储，可以提供更好的性能，特别是针对写入密集型工作负载。  CloudWatch 可以帮助监控性能，并根据需要进行调整。",
      "why_wrong": "选项 B: ElastiCache 可以用于缓存读操作，但对写操作的优化有限； 选项 C: MongoDB 兼容的实例不适合 MySQL 迁移； 选项 D: EFS 方案不适用于 MySQL 数据库，并且通用性能模式的性能较低。"
    },
    "related_terms": [
      "MySQL",
      "Amazon RDS",
      "SSD",
      "Amazon CloudWatch",
      "Amazon ElastiCache",
      "MongoDB",
      "Amazon EFS"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 862,
    "topic": "",
    "question_cn": "一个公司运行一个应用程序在AWS云中生成敏感的档案数据文件。公司想重新设计应用程序的数据存储。该公司希望对数据文件进行加密，并确保第三方在数据被加密并发送到S3之前无法访问数据。该公司已经创建了一个Amazon S3桶。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将S3桶配置为使用Amazon S3管理加密密钥的客户端加密。将应用程序配置为使用S3桶存储档案文件。",
      "B": "配置S3桶使用AWS KMS (SSE-KMS)密钥使用服务器端加密。将应用程序配置为使用S3桶存储档案文件。",
      "C": "配置S3桶使用AWS KMS (SSE-KMS)键使用双层服务器端加密。将应用程序配置为使用S3桶存储档案文件。",
      "D": "配置应用程序使用存储在AWS KMS中的密钥使用客户端加密。配置应用程序将档案文件存储在S3桶中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "Client-Side Encryption"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地存储敏感数据到 S3。 为了确保数据在发送到 S3 之前无法被第三方访问，需要使用客户端加密。",
      "why_correct": "选项 D:  使用客户端加密，数据在传输到 S3 之前就已经被加密。 应用程序使用存储在 AWS KMS 中的密钥，确保了只有授权用户才能解密数据。",
      "why_wrong": "选项 A:  S3 管理的密钥，虽然可以提供加密，但是数据加密还是在S3端完成的，不符合需求；选项 B 和 C:  服务器端加密，虽然提供了 S3 的加密，但数据在存储到 S3 之前未加密，不符合需求。"
    },
    "related_terms": [
      "S3",
      "Amazon S3",
      "AWS KMS",
      "SSE-KMS",
      "客户端加密"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 863,
    "topic": "",
    "question_cn": "一家公司使用Amazon RDS为其数据库层设置默认备份设置。公司需要每天对数据库进行备份以满足监管要求。公司必须保留备份30天。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "每天编写一个Lambda函数来创建一个快照。",
      "B": "修改RDS数据库为自动备份保留30天。",
      "C": "使用AWS Systems Manager维护窗口修改备份保留期。",
      "D": "每天使用AWS CLI创建一个手动快照。修改RDS备份保留期。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Backup",
      "Retention Period"
    ],
    "explanation": {
      "analysis": "此题考察如何配置 RDS 自动备份和保留策略。 最简单的方案是直接配置 RDS 自动备份的保留期。",
      "why_correct": "选项 B:  直接修改 RDS 数据库的自动备份保留期，即可满足要求，开销最小。",
      "why_wrong": "选项 A: 使用 Lambda 函数创建快照，实现起来更复杂，开销更大；选项 C: 通过 Systems Manager 维护窗口修改备份保留期，也可以实现，但不是最佳实践；选项 D: 使用 AWS CLI 创建手动快照，会增加管理工作量，不能自动实现备份。"
    },
    "related_terms": [
      "Amazon RDS",
      "Lambda",
      "快照",
      "AWS Systems Manager",
      "AWS CLI"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 864,
    "topic": "",
    "question_cn": "一家公司在AWS上运行其应用程序，使用Amazon Aurora数据库集群作为其数据库。在多个用户访问和读取数据的高峰使用时间，监控系统显示写入查询的数据库性能下降。该公司希望提高应用程序的可伸缩性以满足高峰使用需求。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个第二个 Aurora DB 集群。配置一个副本作业将用户的数据复制到新数据库中。更新应用程序以使用第二个数据库读取数据。",
      "B": "创建一个Amazon DynamoDB Accelerator (DAX)集群在现有的Aurora数据库集群前面。更新应用程序使用DAX集群进行只读查询。直接将数据写入Aurora数据库集群。",
      "C": "在现有的Aurora DB集群中创建一个Aurora读取副本。更新应用程序以使用只读查询的副本端点并使用集群端点编写查询。",
      "D": "创建一个Amazon Redshift集群。将用户数据复制到Redshift集群。更新应用程序以连接到Redshift集群并在Redshift集群上执行只读查询。"
    },
    "vote_percentage": "80%",
    "tags": [
      "Aurora",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "此题考察如何提高 Aurora 数据库的读取性能。使用 Aurora 读取副本是最直接和最有效的方法。",
      "why_correct": "选项 C:  使用 Aurora 读取副本可以提高读取性能。  应用程序可以从读取副本读取数据，从而减轻主数据库集群的负载。",
      "why_wrong": "选项 A:  创建新的集群，数据同步的延迟较大；选项 B: DAX 是 DynamoDB 的缓存，不适用于 Aurora；选项 D:  Redshift 是数据仓库，与题干不符。"
    },
    "related_terms": [
      "Amazon Aurora",
      "Aurora DB",
      "Amazon DynamoDB Accelerator (DAX)",
      "Aurora读取副本",
      "Amazon Redshift"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 865,
    "topic": "",
    "question_cn": "一家公司的近实时流媒体应用程序正在运行。当数据被吸收时，一个作业在数据上运行，需要30分钟才能完成。由于大量输入的数据，工作量经常出现高延迟。解决方案架构师需要设计一个可伸缩和无服务器的解决方案来提高性能。解决方案架构师应该采取哪些步骤组合？(选择两个)",
    "options_cn": {
      "A": "使用Amazon Kinesis Data Firehose吸收数据。",
      "B": "使用AWS Lambda步骤函数来处理数据。",
      "C": "使用AWS Database Migration Service(AWS DMS)来吸收数据。",
      "D": "在自动缩放组中使用Amazon EC2实例来处理数据。",
      "E": "使用与Amazon Elastic Container Service(ECS)处理数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Kinesis Data Firehose",
      "Step Functions"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为AB，但社区共识(投票最高)为AE。社区倾向AE的原因是，使用 Kinesis Data Firehose 吸收数据，结合 ECS 处理数据。是更加无服务器的方式。",
      "why_correct": "选项 A:  Kinesis Data Firehose 简化了将数据流式传输到各种目的地（例如 S3）的过程。  选项 E:  使用 ECS，可以托管容器化的数据处理作业，提供可伸缩性和弹性。",
      "why_wrong": "选项 B: 步骤函数适用于管理协调多个 Lambda 函数，但处理作业时间过长，并且不是无服务器的，并且不如 ECS 灵活；选项 C: AWS DMS 适用于数据库迁移，而不是流处理，并且成本高；选项 D: 使用 EC2 实例，需要管理，不符合无服务器的要求。"
    },
    "related_terms": [
      "Amazon Kinesis Data Firehose",
      "AWS Lambda",
      "AWS Database Migration Service(AWS DMS)",
      "Amazon EC2",
      "Amazon Elastic Container Service(ECS)"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 866,
    "topic": "",
    "question_cn": "在一个VPC中，一个公司在多个Amazon EC2实例上运行一个Web应用程序。应用程序需要将敏感数据写入一个Amazon S3桶。数据不能通过公共互联网发送。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为Amazon S3创建VPC网关端点。在路由表中创建到端点的路由。",
      "B": "创建一个内部网络负载平衡器将S3桶作为目标。",
      "C": "将S3桶部署到VPC中，在VPC路由表中创建一个路由到桶。",
      "D": "在VPC和S3区域端点之间创建一个AWS Direct Connect连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察如何在VPC中安全地访问 S3 桶。 最优的解决方案是使用 VPC 终端节点。",
      "why_correct": "选项 A:  使用 VPC 网关端点，可以在 VPC 内部安全地访问 S3 桶，而无需通过公共互联网传输数据。 通过在路由表中添加相应的路由，可以确保流量通过 VPC 端点。",
      "why_wrong": "选项 B:  网络负载均衡器不能用于指向 S3；选项 C: 将 S3 桶部署到 VPC 不可行；选项 D: Direct Connect 是为连接数据中心和 AWS 设置的，不适用于此场景。"
    },
    "related_terms": [
      "VPC",
      "Amazon EC2",
      "Amazon S3",
      "VPC网关端点",
      "S3桶",
      "AWS Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 867,
    "topic": "",
    "question_cn": "一家公司在Amazon EC2实例中运行其生产工作负载并拥有Amazon EBS卷的数量。解决方案架构师需要分析当前EBS卷成本并建议优化。这些建议需要包括估计的每月储蓄机会。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon EBS报告生成卷优化建议。",
      "B": "使用AWS System Manager报告来确定卷优化建议。",
      "C": "使用Amazon CloudWatch度量报告确定卷优化建议。",
      "D": "使用计算优化器生成优化的卷建议。"
    },
    "vote_percentage": null,
    "tags": [
      "EBS Optimization",
      "AWS Compute Optimizer"
    ],
    "explanation": {
      "analysis": "核心考点: 评估EBS卷成本并优化。答案D (使用计算优化器) 提供了直接的成本优化建议。",
      "why_correct": "AWS Compute Optimizer可以分析资源利用率并提供优化建议，包括EBS卷的成本和性能优化。",
      "why_wrong": "选项A,B,C 均不能直接提供卷优化建议，而是报告功能或监控功能。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EBS",
      "Amazon EBS报告",
      "AWS System Manager",
      "Amazon CloudWatch"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 868,
    "topic": "",
    "question_cn": "一家全球性的公司在AWS S3上运行它的工作负载。该公司的应用程序使用Amazon S3桶跨区域的敏感数据存储和分析。公司每天用多个S3桶存储数百万件物品。该公司希望识别所有未启用版本的S3桶。哪种解决方案能满足这些要求？",
    "options_cn": {
      "B": "使用Amazon S3存储透镜来识别所有S3桶这些桶没有跨区域的可转换功能。",
      "C": "为S3桶启用IAM访问分析器以识别所有未跨区域启用的S3桶。",
      "D": "创建一个多区域接入点以识别所有未跨区域启用的S3桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Versioning",
      "S3 Storage Lens"
    ],
    "explanation": {
      "analysis": "核心考点: 检测S3桶版本控制是否启用。答案B (使用S3存储透镜) 提供了S3桶版本控制的识别功能。",
      "why_correct": "S3 Storage Lens 能够分析 S3 存储桶的使用情况，包括版本控制状态，从而帮助识别未启用版本控制的存储桶。",
      "why_wrong": "选项C,D 不直接解决检测未启用版本控制的桶。"
    },
    "related_terms": [
      "AWS S3",
      "S3",
      "Amazon S3",
      "S3存储透镜",
      "IAM",
      "S3桶",
      "跨区域",
      "多区域接入点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 869,
    "topic": "",
    "question_cn": "一家公司希望增强其电子商务订单处理应用程序，该应用程序部署在美国航空公司。在不可预测的流量高峰期间，应用程序必须精确地处理每一次订单而不影响客户体验。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个Amazon Simple Queue Service (SQS) FIFO队列。把所有的订单都放在SQS队列中。配置一个 Lambda函数作为目标来处理订单。",
      "B": "创建一个Amazon Simple Notification Service(SNS)标准主题。发布所有的订单到SNS标准主题。将应用程序配置为SNS通知目标。",
      "C": "通过使用Amazon程序流创建一个流。把命令发送到流。配置一个 Lambda函数作为目标来处理订单。",
      "D": "在应用程序中配置X-Ray来跟踪订单请求。将应用程序配置为通过从Amazon CloudWatch中提取订单来处理订单。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS FIFO",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点: 确保订单处理的顺序性和可靠性。答案A (SQS FIFO) 满足严格的顺序要求。",
      "why_correct": "SQS FIFO 队列保证消息按发送顺序处理，这对于需要精确订单处理的应用至关重要。Lambda 函数可以异步处理队列中的消息。",
      "why_wrong": "选项B,C 无法保证订单处理的顺序；选项D 侧重于跟踪，而非处理。"
    },
    "related_terms": [
      "Amazon Simple Queue Service (SQS)",
      "SQS",
      "Lambda",
      "Amazon Simple Notification Service(SNS)",
      "SNS",
      "X-Ray",
      "Amazon CloudWatch"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 870,
    "topic": "",
    "question_cn": "一个公司有两个AWS账户：生产和开发。公司需要将开发账户中的代码更改推到生产账户。在Alpha阶段，开发团队中只有两个高级开发人员需要访问生产账户。在测试阶段，更多的开发人员将需要访问权限来执行测试。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "通过在每个账户中使用IAM管理控制台创建两个策略文档。将策略分配给需要访问的开发人员。",
      "B": "在开发账户中创建一个IAM角色。授权角色访问生产帐户。允许开发人员承担这个角色。",
      "C": "在生产账户中创建一个IAM角色。定义指定开发账户的信托策略。允许开发人员承担这个角色。",
      "D": "在生产账户中创建一个IAM组。在指定生产账户的信任策略中添加组作为主体。将开发人员添加到组中。"
    },
    "vote_percentage": "55%",
    "tags": [
      "IAM Roles",
      "Cross-Account Access"
    ],
    "explanation": {
      "analysis": "核心考点: 跨账户访问权限管理。答案C (IAM角色+信任策略) 是最佳实践。",
      "why_correct": "在生产账户中创建IAM角色，定义信任策略，允许开发账户中的IAM角色担任该角色，是最安全的跨账户访问方式。这样可以明确控制哪些账户可以访问生产资源。",
      "why_wrong": "选项A 策略分配给用户，不灵活；选项B 从开发账户授权生产账户角色，不符合安全最佳实践；选项D 使用组不具备跨账户访问能力。"
    },
    "related_terms": [
      "AWS",
      "IAM",
      "IAM",
      "IAM角色",
      "IAM组",
      "AWS组织",
      "服务控制策略"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 871,
    "topic": "",
    "question_cn": "一家公司希望限制对其Web应用程序内容的访问。该公司需要通过使用在AWS上可用的授权技术来保护内容。该公司还希望实现无服务器架构用于具有低登录延迟的授权和认证。解决方案必须与Web应用程序集成并在全球范围内为内容服务。该应用程序目前的用户基础较小但该公司预计该应用程序的用户基础将增加。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置Amazon Cognito进行身份验证。实现Lambda@Edge授权。配置Amazon CloudFront服务于全球网络应用程序。",
      "B": "配置微软活动目录的目录服务以进行身份验证。实现许可许可。使用一个应用程序负载平衡器为Web应用程序提供全局服务。",
      "C": "配置Amazon Cognito进行身份验证。实现许可许可。使用Amazon S3 Transfer Acceleration为网络应用程序提供全球服务。",
      "D": "配置微软活动目录的目录服务以进行身份验证。实现Lambda@Edge授权。使用弹性豆茎服务于全球的应用程序。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Cognito",
      "Lambda@Edge",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "核心考点: 安全的Web内容访问控制。答案A (Cognito + Lambda@Edge + CloudFront) 提供了最佳的无服务器解决方案。",
      "why_correct": "Amazon Cognito 提供身份验证服务，Lambda@Edge 用于授权，CloudFront 提供全球内容分发，结合起来实现安全、低延迟的内容访问。",
      "why_wrong": "选项B,D 使用目录服务不适合无服务器架构。选项C 使用Transfer Acceleration 优化S3传输，而非内容访问控制。"
    },
    "related_terms": [
      "Amazon Cognito",
      "Lambda@Edge",
      "Amazon CloudFront",
      "微软活动目录",
      "Amazon S3 Transfer Acceleration",
      "弹性豆茎"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 872,
    "topic": "",
    "question_cn": "开发团队在其开发、阶段和生产环境中使用多个AWS账户。团队成员已经推出了大型Amazon EC2实例，这些实例没有得到充分利用。解决方案架构师必须防止在所有账户中启动大型实例。解决方案架构师如何用最少的操作开销来满足这个需求？",
    "options_cn": {
      "A": "更新IAM策略拒绝启动大型EC2实例。将这些策略应用于所有用户。",
      "B": "定义资源访问管理器中的资源防止启动大型EC2实例。",
      "C": "在每个账户中创建一个IAM角色拒绝启动大型EC2实例。允许开发者组访问这个角色。",
      "D": "用默认策略在管理账户中的AWS组织中创建一个组织。创建一个拒绝启动大EC2实例的服务控制策略并将其应用到AWS账户中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SCP",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "核心考点: 限制EC2实例的启动，以控制成本。答案D (SCP) 提供了最有效的解决方案。",
      "why_correct": "服务控制策略 (SCP) 允许您在AWS组织级别上集中控制资源的使用，最有效地阻止了大型EC2实例的启动。",
      "why_wrong": "选项A,C需要在每个账户中单独配置IAM策略，操作复杂。选项B没有相关的功能。"
    },
    "related_terms": [
      "Amazon EC2",
      "IAM",
      "EC2",
      "IAM策略",
      "资源访问管理器",
      "AWS组织",
      "EC2"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 873,
    "topic": "",
    "question_cn": "一家公司已经将数百台内部虚拟机(VMS)迁移到Amazon EC2实例。这些实例运行了一个多样的操作系统版本和几个Linux发行版。该公司希望有一个解决方案将库存和更新的操作系统自动化。公司还需要每个案例的共同弱点的摘要以定期每月审查。解决方案架构师应该建议什么来满足这些需求？",
    "options_cn": {
      "A": "建立AWS Systems Manager补丁管理器来管理所有EC2实例。配置安全枢纽以生成每月报告。",
      "B": "建立AWS Systems Manager补丁管理器来管理所有EC2实例。部署Amazon Inspector并配置每月报告。",
      "C": "设置屏蔽高级并配置每月报告。部署配置在EC2实例上实现补丁安装自动化。",
      "D": "在帐户中设置Amazon保护职责以监控所有EC2实例。部署配置在EC2实例上实现补丁安装自动化。"
    },
    "vote_percentage": "88%",
    "tags": [
      "AWS Systems Manager",
      "Amazon Inspector"
    ],
    "explanation": {
      "analysis": "核心考点: 自动化补丁管理和漏洞评估。官方答案与社区投票不一致。注意: 此题官方答案为A，但社区共识(投票最高)为B。社区倾向B的原因是...Amazon Inspector提供了漏洞评估功能。",
      "why_correct": "使用AWS Systems Manager Patch Manager可以自动化补丁安装。结合Amazon Inspector可以提供漏洞评估和安全报告。",
      "why_wrong": "选项A 使用了安全枢纽，但安全枢纽不提供漏洞评估；选项C,D 缺少漏洞评估功能。"
    },
    "related_terms": [
      "Amazon EC2",
      "AWS Systems Manager",
      "Amazon Inspector",
      "EC2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 874,
    "topic": "",
    "question_cn": "一家公司将其应用程序存储在AWS云中。该应用程序在Amazon EC2实例运行在弹性负载平衡器(ELB)负载平衡器后面的一个自动缩放组中。该应用程序连接到一个Amazon DynamoDB表。为了实现灾难恢复的目的，该公司希望确保该应用程序能够从另一个区域获得停机时间最少。哪种解决方案能在最短的停机时间内满足这些要求？",
    "options_cn": {
      "A": "创建一个自动缩放组和一个ELB。将DynamoDB表配置为全局表。配置DNS故障转移以指向新的区域的ELB。",
      "B": "创建一个CloudFormation组模板以创建EC2实例、ELBs 和DynamoDB表以便在必要时启动。配置DNS故障转移以指向新的区域的ELB。",
      "C": "创建一个CloudFormation组模板以创建EC2实例和在必要时将要启动的ELB。将DynamoDB表配置为全局表。配置DNS故障转移以指向新的区域的ELB。",
      "D": "创建一个自动缩放组和一个ELB。将DynamoDB表配置为全局表。创建一个Amazon CloudWatch表警报评估期为10分钟以调用一个Lambda函数更新Amazon Route 53指向DR区域的ELB。"
    },
    "vote_percentage": "85%",
    "tags": [
      "DynamoDB Global Tables",
      "DNS Failover",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "核心考点: 跨区域灾难恢复。答案A (全局表+DNS故障转移) 提供了最佳的灾难恢复方案。",
      "why_correct": "配置DynamoDB全局表实现数据同步。使用DNS故障转移可以在发生故障时快速将流量切换到备用区域，从而实现最小停机时间。",
      "why_wrong": "选项B 和 C 使用 CloudFormation，但是启动时间较长，无法保证最短停机时间。选项D使用CloudWatch Alarm和Lambda 更新Route53记录，比DNS故障转移更复杂，延迟更高。"
    },
    "related_terms": [
      "Amazon EC2",
      "弹性负载平衡器(ELB)",
      "ELB",
      "自动缩放组",
      "Amazon DynamoDB",
      "DynamoDB",
      "CloudFormation",
      "Amazon CloudWatch",
      "Lambda",
      "Amazon Route 53"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 875,
    "topic": "",
    "question_cn": "一个公司在一个私人子网中运行一个在Amazon EC2实例上的应用程序。应用程序需要在Amazon S3桶中存储和检索数据。根据监管规定，数据不得在公共互联网上传播。解决方案架构师应该做什么才能最经济有效地满足这些需求？",
    "options_cn": {
      "A": "部署一个NAT网关来访问S3桶。",
      "B": "部署存储网关以访问S3桶。",
      "C": "部署一个S3接口端点来访问S3桶。",
      "D": "部署一个S3网关端点来访问S3桶。"
    },
    "vote_percentage": "85%",
    "tags": [
      "S3 Gateway Endpoint",
      "VPC"
    ],
    "explanation": {
      "analysis": "核心考点: 从私有子网安全访问S3。答案D (S3网关端点) 提供了最经济高效的解决方案。",
      "why_correct": "S3网关端点允许从VPC内的私有子网访问S3，而无需经过公共互联网，并且不收取数据处理费用，成本低。",
      "why_wrong": "选项A: NAT网关增加了成本和复杂性；选项B: 存储网关用于混合云场景；选项C: 接口端点成本较高。"
    },
    "related_terms": [
      "Amazon EC2",
      "Amazon S3",
      "NAT网关",
      "存储网关",
      "S3接口端点",
      "S3网关端点"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 876,
    "topic": "",
    "question_cn": "一个公司在Amazon EC2实例上拥有一个在单一可用性区域运行的应用程序。该应用程序可以通过开放系统互联模型的传输层访问。该公司需要应用架构具有高可用性。哪些步骤组合将最符合这些要求？ (选二)",
    "options_cn": {
      "A": "在不同的可用性区域中配置新的EC2实例。使用Amazon Route 53将交通路线通到所有实例。",
      "B": "在EC2实例前配置网络负载平衡器。",
      "C": "将网络负载平衡器配置到实例中。将一个应用程序负载平衡器配置为HTTP和HTTPS流量到实例。",
      "D": "为EC2实例创建一个自动缩放组。将自动缩放组配置为使用多个可用性区域。配置自动缩放组来运行实例上的应用程序健康检查。",
      "E": "创建一个Amazon CloudWatch报警器。将警报配置为重新启动向停止状态过渡的EC2实例。"
    },
    "vote_percentage": "100%",
    "tags": [
      "High Availability",
      "Auto Scaling",
      "Load Balancing",
      "Route 53"
    ],
    "explanation": {
      "analysis": "核心考点: 提高EC2应用程序的可用性。官方答案与社区投票不一致。注意: 此题官方答案为C和D，但社区共识(投票最高)为B和D。社区倾向BD的原因是...选项BD结合了负载均衡器和自动伸缩组，是高可用性的核心。",
      "why_correct": "选项B 在EC2实例前配置网络负载均衡器，提供高可用性。选项D 创建一个自动缩放组，跨多个可用区部署实例，并进行健康检查，实现弹性与高可用。",
      "why_wrong": "选项A，Route 53只是将流量分发，本身不提供高可用。选项C，同时使用NLB和ALB有些多余，且ALB更适合于HTTP/HTTPS场景。选项E，CloudWatch报警器只能用于重启实例，而无法保证可用性。"
    },
    "related_terms": [
      "Amazon EC2",
      "Route 53",
      "网络负载平衡器",
      "应用程序负载平衡器",
      "自动缩放组",
      "Amazon CloudWatch"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 877,
    "topic": "",
    "question_cn": "一家公司使用Amazon S3来主持其静态网站。公司想在网页上添加一个联系表格。该联系人表单将有动态服务器端组件供用户输入其姓名、电子邮件地址、电话号码和用户信息。该公司预计每月不到100次现场访问。当客户填写表格时，联系人必须通过电子邮件通知公司。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在Amazon弹性集装箱服务中接受动态接触形式。建立Amazon Simple Email Service (SES)亚马逊连接到第三方电子邮件提供商。",
      "B": "创建一个Amazon API网关端点，该端点从Lambda函数返回联系表单。在API网关上配置另一个Lambda函数以将消息发布到Amazon Simple Notification Service(SNS)亚马逊主题。",
      "C": "网站的主机是通过使用增强静态内容和动态内容的主机。使用服务器端脚本来构建联系表单。配置Amazon Simple Queue Service(SQS)亚马逊小规模服务组来向公司传递消息。",
      "D": "将网站从Amazon S3迁移到运行Windows Server的Amazon EC2实例。使用互联网信息服务(IIS)作为Web服务器的网页主机。使用客户端脚本来构建联系表单。将表单与亚马逊工作邮件集成。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Static Website",
      "API Gateway",
      "Lambda",
      "SNS"
    ],
    "explanation": {
      "analysis": "核心考点: 静态网站增加动态联系表单。答案B (API Gateway + Lambda + SNS) 提供了无服务器的最佳解决方案。",
      "why_correct": "API Gateway 接受表单提交，触发 Lambda 函数，通过 SNS 发送通知，实现无服务器、低成本且易于维护的解决方案。",
      "why_wrong": "选项A 使用ECS和SES，增加复杂度，不适用于低流量。选项C使用SQS，对于邮件通知不是最佳选择。选项D 将网站迁移到EC2，增加了运维成本，并且不符合最佳实践。"
    },
    "related_terms": [
      "Amazon S3",
      "Amazon弹性集装箱服务",
      "Amazon Simple Email Service (SES)",
      "Amazon API网关",
      "Lambda",
      "Amazon Simple Notification Service(SNS)",
      "SNS",
      "Amazon SQS",
      "SQS",
      "Amazon EC2",
      "Windows Server",
      "IIS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 878,
    "topic": "",
    "question_cn": "一家公司为其业务部门在美国AWS服务社的组织中创建专门的AWS账户。最近向业务单元帐户的根用户发送了一个重要的通知，而不是指定帐户所有者。该公司希望确保所有未来的通知能够根据账单、操作或安全性的通知类别发送给不同的员工。哪个解决方案最安全地满足这些要求？",
    "options_cn": {
      "A": "配置每个AWS帐户使用公司管理的单一电子邮件地址。确保所有帐户所有者都能进入电子邮件帐户接收通知。为每个AWS帐户配置其他联系人并为账单小组、安全小组和每个业务单位的业务小组配置相应的分发名单。",
      "B": "为公司管理的每个业务单元配置每个AWS帐户使用不同的电子邮件发送列表。用管理员电子邮件地址配置每个分发列表可以AWS响应警报。为每个AWS帐户配置其他联系人并为账单小组、安全小组和每个业务单位的业务小组配置相应的分发名单。",
      "C": "配置每个AWS帐户根用户的电子邮件地址为每个公司管理的电子邮件地址，每个业务单位有一个人。为每个AWS帐户配置其他联系人并为账单小组、安全小组和每个业务单位的业务小组配置相应的分发名单。",
      "D": "配置每个AWS帐户根用户使用转到中央邮箱的电子邮件别名。为每个帐户配置备用联系人为账单小组、安全小组和操作小组使用单个业务管理的电子邮件分发列表。"
    },
    "vote_percentage": "54%",
    "tags": [
      "AWS Account Contact Information",
      "Notifications"
    ],
    "explanation": {
      "analysis": "核心考点: 配置AWS账户通知。官方答案与社区投票不一致。注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是...D选项提供了更集中、可控的通知管理方式。",
      "why_correct": "选项D使用电子邮件别名和分发列表，可以更有效地管理通知，减少根用户直接接收通知的情况，并提供通知管理的集中化。",
      "why_wrong": "选项A, B, C 都依赖于账户根用户的电子邮件地址或者单独的邮件地址，不利于管理。"
    },
    "related_terms": [
      "AWS",
      "AWS",
      "AWS帐户"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 879,
    "topic": "",
    "question_cn": "一家公司在AWS EC2上运行电子商务应用程序。Amazon EC2实例处理购买并将购买细节存储在一个Amazon Aurora后行数据库集群中。在使用高峰期客户正在经历应用程序超时。解决方案架构师需要重新架构应用程序以便应用程序可以扩展以满足高峰使用需求。哪些行动组合最符合这些要求？ (选二)",
    "options_cn": {
      "A": "配置一个新EC2实例的自动缩放组以重试采购直到处理完成。通过使用Amazon RDS代理更新应用程序来连接到数据库集群。",
      "B": "将应用程序配置为使用在极光后行数据库集群前面的Amazon弹性集群。",
      "C": "更新应用程序将采购请求发送到Amazon Simple Queue Service (SQS)亚马逊队列。配置一个新的EC2实例的自动缩放组该实例读取自SQS队列。",
      "D": "配置一个Lambda函数以重试购票直到处理完成。",
      "E": "配置一个Amazon API网关具有使用计划的休息 。"
    },
    "vote_percentage": "80%",
    "tags": [
      "Auto Scaling",
      "SQS",
      "RDS Proxy"
    ],
    "explanation": {
      "analysis": "核心考点: 应用程序在高负载下的可扩展性和可靠性。答案A和C提供了最佳的解决方案，结合了自动伸缩和异步处理。",
      "why_correct": "选项A:  使用Auto Scaling和RDS Proxy提高数据库连接性能，增强弹性。 选项C： 使用 SQS 异步处理订单请求，解耦应用程序并提高可靠性。  ",
      "why_wrong": "选项B，Elastic Cache是缓存，不能直接解决高负载下的问题；选项D，Lambda函数可能无法处理高峰负载；选项E，API Gateway主要用于API的管理和安全，不能直接解决高负载下的问题。"
    },
    "related_terms": [
      "AWS EC2",
      "Amazon EC2",
      "Amazon Aurora",
      "Aurora",
      "Amazon RDS",
      "SQS",
      "Lambda",
      "API网关"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 880,
    "topic": "",
    "question_cn": "一个使用美国职业教育协会的公司在30个不同的AWS账户中运行150个应用程序。该公司使用了成本和使用报告在AWS S3管理账户中创建了一个新的报告。该报告被交付到一个Amazon S3桶并在数据收集帐户中复制到一个桶。该公司的高层领导希望查看一个定制仪表板从本月初开始每天提供NAT网关成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "共享一个Amazon QuickSight仪表板其中包括请求的表可视化。配置QuickSight以使用数据同步查询新报表。",
      "B": "共享一个Amazon QuickSight仪表板其中包括请求的表可视化。配置QuickSight使用Amazon Athena查询新报告。",
      "C": "共享一个Amazon CloudWatch仪表板其中包括请求的表可视化。将CloudWatch配置为使用数据监视器来查询新报表。",
      "D": "共享一个Amazon CloudWatch仪表板其中包括请求的表可视化。配置CloudWatch使用Amazon Athena查询新报告。"
    },
    "vote_percentage": "100%",
    "tags": [
      "QuickSight",
      "Athena",
      "Cost Reporting"
    ],
    "explanation": {
      "analysis": "核心考点: 创建定制的成本分析仪表板。答案B (QuickSight + Athena) 提供了最佳的解决方案。",
      "why_correct": "QuickSight 允许创建仪表盘，Athena 可以用来查询S3上的数据，从而创建自定义的成本分析报告。",
      "why_wrong": "CloudWatch 主要用于监控和报警，不适合构建定制的成本分析仪表板。 数据同步功能不如 Athena 灵活。"
    },
    "related_terms": [
      "AWS",
      "AWS S3",
      "Amazon S3",
      "Amazon QuickSight",
      "Amazon Athena",
      "Amazon CloudWatch",
      "NAT网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 881,
    "topic": "",
    "question_cn": "一家公司在Amazon S3网站上提供了一个高流量静态网站，该网站的Amazon CloudFront分布为默认TTL0秒。该公司希望实现缓存以提高网站的性能。不过该公司还希望确保在部署后的几分钟内不会提供陈旧的内容。为了满足这些需求解决方案架构师应该实现哪些缓存方法组合？ (选二)",
    "options_cn": {
      "A": "将CloudFront默认TTL设置为2分钟。",
      "B": "在S3桶上设置默认的TTL 2分钟。",
      "C": "在Amazon S3的对象中添加一个Cache-Control专用指令。",
      "D": "创建一个Lambda@Edge函数以添加一个过期的标题到 HTTP 响应。将该函数配置为在查看器响应上运行。",
      "E": "在Amazon S3的对象中添加Cache-Control:max-age指令。在部署时创建CloudFront无效以清除任何从边缘缓存更改的文件。"
    },
    "vote_percentage": "47%",
    "tags": [
      "CloudFront",
      "Caching",
      "Cache-Control"
    ],
    "explanation": {
      "analysis": "核心考点: 提高网站性能，同时确保内容的及时更新。答案A和E (调整CloudFront TTL + Cache-Control + CloudFront Invalidations) 提供了最佳的缓存策略。",
      "why_correct": "选项A：设置CloudFront的默认TTL，控制缓存时间。选项E：使用Cache-Control: max-age指令控制对象缓存时长，部署时进行CloudFront失效处理，保证内容的及时更新和性能提升。",
      "why_wrong": "选项B在S3上设置TTL，影响小。选项C只适用于特定对象。选项D仅通过Lambda设置过期标头，不够灵活且没有对缓存进行失效。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "TTL",
      "Lambda@Edge",
      "Cache-Control",
      "HTTP"
    ],
    "best_answer": [
      "A",
      "E"
    ],
    "official_answer": [
      "A",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 882,
    "topic": "",
    "question_cn": "一家公司通过使用亚马逊EC2实例和Lambda功能运行其应用程序。EC2实例运行在VPC的私有子网中。对于应用程序的工作，Lambda函数需要对EC2实例的直接网络访问。该应用程序将运行一年。在一年期间应用程序使用的Lambda功能的数量将增加。公司必须降低所有应用资源的成本？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "为EC2购买实例储蓄计划。连接到包含EC2实例的私有子网。",
      "B": "为EC2和Lambda购买实例储蓄计划。在EC2实例运行的同一VPC中将Lambda函数连接到新的公共子网络。",
      "C": "购买一个计算储蓄计划。连接到包含EC2实例的私有子网。",
      "D": "购买一个计算储蓄计划。保持兰布达功能在兰布达服务。"
    },
    "vote_percentage": "63%",
    "tags": [
      "EC2 Savings Plans",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点是成本优化和Lambda访问EC2。 购买计算储蓄计划能够覆盖EC2和Lambda的计算成本。 注意：选项D的措辞有误，但可以理解为保留Lambda在Lambda服务。",
      "why_correct": "计算储蓄计划能覆盖EC2和Lambda的计算成本，是最优选择。",
      "why_wrong": "A 仅涵盖EC2，B 在公共子网中连接Lambda，增加了安全风险。 D 表达有误，且没有明确说明成本优化。"
    },
    "related_terms": [
      "EC2",
      "Lambda",
      "VPC",
      "EC2 实例储蓄计划",
      "计算储蓄计划"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 883,
    "topic": "",
    "question_cn": "一家公司已经在美国航空航天公司上部署了一个多帐户战略使用AWS控制塔。该公司已经向每个开发商提供了单独AWS账户。该公司希望实施控制措施以限制开发商所承担的资源成本？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "指示每个开发人员用一个标签标记他们的所有资源。标签上有一个关键的成本中心和一个开发人员名称的值。使用所需标签的AWS Config规则检查标签。创建一个Lambda函数来终止没有标记的资源。配置成本资源管理器向每个开发人员发送每日报表以监控他们的支出。",
      "B": "使用AWS Budgets为每个开发者帐户建立预算。建立实际和预测值的预算。提示当开发人员超过或预期超过分配的预算时通知他们。使用AWS IAM Budgets行动对开发者的角色应用否认策略以防止在指定预算完成时启动额外资源。",
      "C": "使用AWS Cost Explorer监控和报告每个开发人员帐户的成本。配置成本资源管理器向每个开发人员发送每日报表以监控他 们的支出。使用成本异常检测来检测异常支出并提供警报。",
      "D": "使用AWS Service Catalog允许开发人员在有限的成本范围内启动资源。在每个帐户中创建Lambda函数在每个工作日结束时停止运行资源。在每个工作日开始时配置Lambda函数以恢复资源。"
    },
    "vote_percentage": "75%",
    "tags": [
      "AWS Budgets",
      "Cost Allocation Tags"
    ],
    "explanation": {
      "analysis": "核心考点是成本控制。 通过AWS Budgets设置预算，并配置IAM策略在预算超标时阻止资源创建，是最有效率且最直接的方案。",
      "why_correct": "AWS Budgets提供了精确的预算控制，并在超标时提供警报和自动限制资源创建的能力。",
      "why_wrong": "A 标签策略需要手动标记资源，实现起来有难度。C 仅提供监控，没有实际的控制功能。D Service Catalog限制了开发人员的资源使用范围，但无法提供实时的预算控制。"
    },
    "related_terms": [
      "AWS Control Tower",
      "AWS账户",
      "AWS Config",
      "Lambda",
      "AWS Budgets",
      "AWS IAM",
      "AWS Cost Explorer",
      "AWS Service Catalog"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 884,
    "topic": "",
    "question_cn": "一个Web (ALB) 解决方案架构师正在设计一个三层应用程序。该体系结构包括一个面向互联网的应用程序负载平衡器和EC2实例上托管的Web层。EC2实例位于私有子网络中。具有业务逻辑的应用程序层在私有子网中的EC2实例上运行。数据库层由在私有子网中运行在EC2 SQL实例上的微软服务器组成。安保是公司的高度优先事项？解决方案架构师应该使用哪些安全组配置组合？选三。",
    "options_cn": {
      "A": "配置Web层的安全组以允许从ALB的安全组中输入HTTPS流量。",
      "B": "配置Web层的安全组使出站HTTPS流量达到0.0.0/0。",
      "C": "为数据库层配置安全组以允许从应用程序层的安全组输入微软服务器流量。",
      "D": "为数据库层配置安全组以允许出站HTTPS流量和微软服务器流量到Web层的安全组。",
      "E": "配置应用程序层的安全组以允许来自Web层安全组的入站HTTPS流量。",
      "F": "配置应用程序层的安全组以允许出站HTTPS流量和微软服务器流量到Web层的安全组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Groups",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "核心考点是安全组配置。 选A, C, E 实现了最小权限原则，确保了必要的流量流动，并且限制了不必要的访问，符合安全最佳实践。",
      "why_correct": "A、C、E 允许特定流量通过，最大限度地减少了攻击面。B允许所有出站流量，不安全。D允许数据库层出站到Web层，不合理。F 与 E 重复，但安全模型不够严谨。",
      "why_wrong": "B 允许所有出站流量，不符合最小权限原则。D 允许数据库层出站流量到Web层，不合理。F 与 E 重复, 整体不够安全。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "HTTPS",
      "Web层",
      "SQL"
    ],
    "best_answer": [
      "A",
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 885,
    "topic": "",
    "question_cn": "一家公司发布了新版本的生产应用程序。该公司的工作量使用亚马逊EC2、AWS Lambda、AWS Fargate和亚马逊SageMaker。由于使用情况稳定该公司希望对工作量进行成本优化。该公司希望用最少的储蓄计划覆盖大多数服务？哪些储蓄计划将满足这些要求？选二。",
    "options_cn": {
      "A": "为亚马逊EC2和SageMaker购买实例储蓄计划。",
      "B": "为亚马逊EC2、Lambda和SageMaker购买一个计算储蓄计划。",
      "C": "购买一个SageMaker储蓄计划。",
      "D": "为Lambda、Fargate和亚马逊EC2购买一个计算储蓄计划。",
      "E": "为亚马逊EC2和Fargate购买实例储蓄计划。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Compute Savings Plans",
      "EC2 Savings Plans"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为BD，但社区共识(投票最高)为CD。社区倾向CD的原因是，覆盖的范围更广，能最大限度降低成本。CD侧重于SageMaker和Lambda的成本优化。",
      "why_correct": "C 购买一个SageMaker储蓄计划直接优化SageMaker成本。D 计算储蓄计划可以覆盖Lambda, Fargate 和EC2，进一步优化成本。",
      "why_wrong": "A 仅覆盖EC2，范围较小。B 覆盖范围不如CD。E 仅覆盖EC2和Fargate，范围较小。"
    },
    "related_terms": [
      "EC2",
      "AWS Lambda",
      "AWS Fargate",
      "SageMaker",
      "实例储蓄计划",
      "计算储蓄计划"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 886,
    "topic": "",
    "question_cn": "一家公司使用微软的SQL Server数据库。公司的应用程序连接到数据库中。该公司希望迁移到Amazon Aurora后的数据库并对应用程序代码进行最小的更改？哪些步骤组合将满足这些要求？选二。",
    "options_cn": {
      "A": "使用AWS SCT(Schema Conversion Tool)来重写应用程序中的SQL查询。",
      "B": "允许在Aurora后上运行来自应用程序的SQL查询。",
      "C": "使用AWS SCT(Schema Conversion Tool)和AWS DMS(Database Migration Service)迁移数据库架构和数据。",
      "D": "使用亚马逊RDS代理将应用程序连接到Aurora后。",
      "E": "使用AWS DMS(Database Migration Service)来重写应用程序中的SQL查询。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DMS",
      "AWS SCT"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为CD，但社区共识(投票最高)为BC。社区倾向BC的原因是，简化了数据库迁移的步骤，确保了应用代码的兼容性。",
      "why_correct": "B Aurora兼容SQL Server, 最小化代码改动。C 使用AWS SCT和AWS DMS来迁移数据库架构和数据。",
      "why_wrong": "A 修改SQL查询，修改代码，不符合最小改动要求。 D  RDS代理对Aurora的连接优化，但是不是必要的步骤。E 重写SQL查询，需要修改代码，不符合最小改动要求。"
    },
    "related_terms": [
      "SQL Server",
      "Aurora",
      "AWS SCT",
      "AWS DMS",
      "RDS代理"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 887,
    "topic": "",
    "question_cn": "一家公司计划将一个应用程序重新主机到Amazon EC2实例，该应用程序使用Amazon EBS作为附加存储器。解决方案架构师必须设计一个解决方案以确保所有新创建的Amazon EBS卷默认加密。解决方案还必须防止创建未加密的EBS卷？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "配置EC2账户属性以始终加密新的EBS卷。",
      "B": "使用AWS KMS配置AWS。配置加密卷标识符。应用默认的密钥管理服务密钥。",
      "C": "配置AWS System Manager以创建EBS卷的加密副本。重新配置EC2实例以使用加密卷。",
      "D": "在AWS KMS中创建客户管理密钥。在公司迁移工作负载时配置迁移枢纽以使用密钥。"
    },
    "vote_percentage": "67%",
    "tags": [
      "EBS Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "核心考点：EBS卷的默认加密。 通过配置账户属性，可以确保所有新创建的EBS卷默认加密，并防止创建未加密卷。",
      "why_correct": "配置EC2账户属性以始终加密新的EBS卷，这是最直接、最简洁的方式。",
      "why_wrong": "B 需要手动配置，增加了复杂性。C 需要复制EBS卷，增加成本和复杂度。D 与默认加密无关。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "KMS",
      "AWS KMS",
      "AWS System Manager",
      "加密",
      "密钥"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 888,
    "topic": "",
    "question_cn": "一家电子商务公司希望从公司网站上收集用户点击流数据进行实时分析。网站全天经历着流量模式的波动。该公司需要一个可伸缩的解决方案能够适应不同层次的流量？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "使用Amazon Kinesis Data Streams中按需模式的数据流来捕捉点击流数据。使用AWS Kinesis Data Analytics处理实时数据。",
      "B": "使用Amazon Kinesis Data Firehose捕捉点击流数据。使用Glue实时处理数据。",
      "C": "使用Amazon Kinesis Video Streams捕捉点击流数据。使用Glue实时处理数据。",
      "D": "使用亚马逊托管服务的Apache Kafka，以前称为Amazon Kinesis Data Analytics来捕捉点击流数据。使用AWS Kinesis Data Analytics处理实时数据。"
    },
    "vote_percentage": "88%",
    "tags": [
      "Kinesis Data Streams",
      "Kinesis Data Analytics"
    ],
    "explanation": {
      "analysis": "核心考点是实时数据处理。 Kinesis Data Streams 结合 Kinesis Data Analytics 提供了高吞吐量、可伸缩的解决方案，用于处理实时点击流数据。",
      "why_correct": "Kinesis Data Streams 专为实时数据流设计，Kinesis Data Analytics 提供实时处理能力，满足需求。",
      "why_wrong": "B Kinesis Data Firehose 用于数据加载，不是实时处理。C Kinesis Video Streams用于视频流，不适用。D Kinesis Data Analytics 已经包含了Kafka。"
    },
    "related_terms": [
      "Kinesis Data Streams",
      "Kinesis Data Analytics",
      "Kinesis Data Firehose",
      "Glue",
      "Kinesis Video Streams",
      "Apache Kafka"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 889,
    "topic": "",
    "question_cn": "一家全球性的公司在S3上运行它的工作量。该公司的应用程序使用Amazon S3桶跨区域的敏感数据存储和分析。公司每天用多个S3桶存储数百万件物品。该公司希望识别所有未启用版本的S3桶？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "设置一个CloudTrail事件，它有一个规则来识别所有的S3桶，这些桶在区域之间不被启用。",
      "B": "使用Amazon S3 存储透镜来识别所有S3桶，这些桶没有跨区域的可转换功能。",
      "C": "为S3启用IAM访问分析器以识别所有未跨区域启用的S3桶。",
      "D": "创建一个多区域接入点以识别所有未跨区域启用的S3桶。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Versioning",
      "S3 Storage Lens"
    ],
    "explanation": {
      "analysis": "核心考点是S3版本控制和监控。 S3 存储透镜可以用于识别未启用版本控制的S3桶，从而满足需求。",
      "why_correct": "S3 存储透镜可以分析桶配置，包括版本控制状态，并生成报告。",
      "why_wrong": "A CloudTrail 不是用来检测S3桶的版本控制状态。C IAM 访问分析器与S3版本控制无关。 D 多区域接入点与版本控制无关。"
    },
    "related_terms": [
      "S3",
      "CloudTrail",
      "S3存储桶",
      "S3 存储透镜",
      "IAM访问分析器",
      "多区域接入点"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 890,
    "topic": "",
    "question_cn": "一个公司需要优化其Amazon S3存储成本的应用程序生成许多无法重新创建的文件。每个文件大约为5MB，存储在Amazon S3标准存储中。在删除文件之前公司必须存储这些文件4年。必须立即访问这些文件。这些文件在对象创建的前30天经常被访问，但在前30天之后很少被访问？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "创建一个生命周期策略以便在对象创建30天后将文件转移到S3 Glacier即时检索。在对象创建4年后删除文件",
      "B": "创建一个生命周期策略以便在对象创建后30天将文件移动到S3-IA(S3-不经常访问)一个区域。在对象创建4年后删除文件",
      "C": "创建一个生命周期策略以便在对象创建30天后将文件转移到S3标准不经常访问(S3-I)。在对象创建4年后删除文件",
      "D": "创建一个生命周期策略以便在对象创建30天后将文件转移到S3标准不经常访问(S3-I)。在物体创建4年后将文件转移到S3 Glacier的灵活检索。"
    },
    "vote_percentage": "50%",
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为D，但社区共识(投票最高)为C。社区倾向C的原因是，最大化成本效益，满足文件访问的需求。S3 Standard-IA可以满足前30天高频率访问需求，4年后删除文件符合要求。",
      "why_correct": "C  S3 Standard-IA (不经常访问) 存储类，适用于访问频率较低的文件。30天后移动到Standard-IA，并4年后删除，是成本和性能的平衡。",
      "why_wrong": "A S3 Glacier即时检索的访问延迟较高，不适用于需要立即访问的文件。B S3-IA 不支持区域存储。D  将文件移动到 Glacier 灵活检索，成本较高且访问延迟增加，没有必要。"
    },
    "related_terms": [
      "S3",
      "S3 Glacier",
      "S3-IA",
      "生命周期策略"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 891,
    "topic": "",
    "question_cn": "一个公司运行它的关键存储应用程序在AWS云。该应用程序使用Amazon S3在两个区域。该公司希望该应用程序能够将远程用户数据发送到最近的S3桶中没有公共网络阻塞。该公司还希望该应用程序能够在Amazon管理的管理层最少的情况下失败？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在这两个区域之间进行主动设计。将应用程序配置为使用最接近用户的区域端点。",
      "B": "使用多区域接入点的主动被动配置。为每个区域创建一个全球端点。",
      "C": "将用户数据发送到最接近用户的区域S3端点。配置一个跨帐户复制规则以保持S3桶同步。",
      "D": "建立Amazon S3多区域接入点使用具有单一全局端点的活动主动配置。配置跨区域复制。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Multi-Region Access Points",
      "S3 Replication"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，多区域接入点提供全球访问，并且可以配置跨区域复制以实现高可用性。",
      "why_correct": "D  多区域接入点可以提供一个全局端点，自动将用户请求路由到最近的桶，并结合跨区域复制，提供了高可用性和低延迟。",
      "why_wrong": "A 需要应用程序的特殊配置。 B 使用主动被动模式，不能最大限度地利用资源。C 依赖于复制，在数据同步方面存在延迟。"
    },
    "related_terms": [
      "S3",
      "S3桶",
      "多区域接入点",
      "跨区域复制"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 892,
    "topic": "",
    "question_cn": "一家公司正在将一个数据中心从其所在地迁移到AWS。该公司拥有多个遗留应用程序，这些应用程序在单个虚拟服务器上托管。不能更改应用程序的设计。EC2 每个独立的虚拟服务器当前都作为自己的EC2实例运行。解决方案架构师需要确保应用程序在迁移到AWS之后是可靠的和容错的。这些应用程序将在亚马逊EC2实例上运行？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "创建一个自动缩放组，它至少有一个EC2实例和一个应用程序负载平衡器。为每个应用程序实例创建一个亚马逊机器映像。在自动缩放组中请使用该系统创建EC2实例。在自动缩放组前配置一个应用程序负载平衡器。",
      "B": "使用AWS Backup创建每个应用程序的EC2实例的每小时备份。将备份存储在亚马逊S3中的单独可用性区域中。配置一个灾难恢复过程以从每个应用程序的最新备份中恢复其EC2实例。",
      "C": "为每个应用程序实例创建一个亚马逊机器映像。启动两个新的EC2实例。将每个EC2实例放在一个单独的可用性区域中。配置一个具有EC2实例作为目标的网络负载平衡器。",
      "D": "使用AWS Migration Hub重构空间迁移每个应用程序从EC2实例。将每个应用程序的功能分解为单个组件。每一个应用程序都在亚马逊弹性集装箱服务(CCS)，亚马逊ECS上并具有一种AWS Fargate发射类型。"
    },
    "vote_percentage": "50%",
    "tags": [
      "EC2 Auto Scaling",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为C，但社区共识(投票最高)为A。社区倾向A的原因是， A使用自动伸缩组和负载均衡器，提供了高可用性，同时能根据负载情况动态扩展，满足容错和可靠性需求。",
      "why_correct": "A 自动伸缩组提供高可用性和动态扩展能力。应用程序负载均衡器将流量分发到健康实例。 AMI 提供了快速恢复。",
      "why_wrong": "B 基于备份的恢复，恢复时间较长。C 缺少自动伸缩。 D 涉及应用程序重构，不符合题干中“不能更改应用程序的设计”的要求。"
    },
    "related_terms": [
      "EC2",
      "ALB",
      "自动缩放组",
      "亚马逊机器映像",
      "AWS Backup",
      "NLB",
      "AWS Migration Hub"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 893,
    "topic": "",
    "question_cn": "公司希望通过为每个工作负载创建一个AWS账户来隔离其工作负载。该公司需要一个解决方案为工作负载集中管理网络组件。解决方案还必须创建具有自动安全控制护栏的账户？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "使用AWS Control Tower来部署账户。创建一个具有专用子网和公共子网的网络VPC账户。使用资源访问管理器与工作负载账户共享子网。",
      "B": "使用AWS Organizations来部署账户。创建一个具有专用子网和公共子网的网络VPC账户。使用资源访问管理器与工作负载帐 户共享子网。",
      "C": "使用AWS Control Tower来部署账户。在每个工作负载帐户中部署一个VPC。配置每一个VPC通过一个检查VPC通过一个过境网关附件。",
      "D": "使用AWS Organizations来部署账户。在每个工作负载帐户中部署一个VPC。配置每一个VPC通过一个检查VPC通过一个过境网关附件。"
    },
    "vote_percentage": "67%",
    "tags": [
      "AWS Control Tower",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "核心考点：账户隔离和集中网络管理。AWS Control Tower提供了创建和管理多个AWS账户的框架，并能实现自动的安全控制和网络配置。",
      "why_correct": "AWS Control Tower简化了多账户环境的管理，并提供合规性护栏，减少了管理开销。选项提供了网络VPC的配置，满足集中管理网络的需求。",
      "why_wrong": "B 使用Organizations，但没有安全控制和合规性护栏。 C，D在每个账户部署VPC增加了复杂度。"
    },
    "related_terms": [
      "AWS Control Tower",
      "AWS Organizations",
      "VPC",
      "资源访问管理器",
      "过境网关"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 894,
    "topic": "",
    "question_cn": "一个公司在一个应用负载平衡器(ALB)背后的亚马逊EC2实例上拥有一个网站。网站提供静态内容。网站流量正在增加。该公司希望最大限度地降低网站托管成本？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "把网站移到一个亚马逊S3桶。为S3桶配置亚马逊云区分布。",
      "B": "把网站移到一个亚马逊S3桶。为S3桶配置一个亚马逊弹性集群。",
      "C": "将网站移到Amazon CloudFront。配置一个ALB来解析到CloudFront网站。",
      "D": "将网站移到Amazon CloudFront。配置EC2实例来缓存网站。"
    },
    "vote_percentage": "78%",
    "tags": [
      "S3",
      "CloudFront"
    ],
    "explanation": {
      "analysis": "核心考点是成本优化和静态内容托管。 使用S3托管静态内容，结合CloudFront进行CDN加速，可以有效降低成本。",
      "why_correct": "A 使用S3和CloudFront是最经济、高效的方案，CloudFront提供全球CDN加速，降低延迟。",
      "why_wrong": "B 使用弹性集群不适合静态网站托管。C ALB不支持静态网站。D EC2实例用于缓存，没有利用S3的成本优势。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "S3",
      "CloudFront",
      "亚马逊弹性集群"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 895,
    "topic": "",
    "question_cn": "一个公司正在为一个媒体应用程序实现共享存储解决方案，该应用程序由该公司在AWS上主机。公司需要能够使用SMB客户端访问存储数据？用最少的管理费用来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "创建一个AWS存储网关卷网关。创建一个使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享。",
      "B": "创建一个AWS存储网关磁带网关。配置磁带使用亚马逊S3。连接应用服务器到磁带网关。",
      "C": "创建一个亚马逊EC2 Windows实例。在实例中安装和配置文件共享角色。将应用程序服务器连接到文件共享。",
      "D": "为FSx for Windows文件服务器文件系统创建一个亚马逊FSx。将应用程序服务器连接到文件系统。"
    },
    "vote_percentage": "100%",
    "tags": [
      "FSx for Windows File Server",
      "SMB"
    ],
    "explanation": {
      "analysis": "核心考点： SMB共享存储。FSx for Windows File Server 专为 Windows 环境设计，提供对 SMB 协议的支持，并且是完全托管的。",
      "why_correct": "D  FSx for Windows File Server 提供原生的 SMB 共享，易于管理。",
      "why_wrong": "A 卷网关更适合于本地存储与云存储的混合场景。B 磁带网关用于备份和归档，不适用于共享存储。C  需要手动管理 Windows 实例，增加了管理成本。"
    },
    "related_terms": [
      "AWS存储网关",
      "SMB",
      "卷网关",
      "磁带网关",
      "FSx for Windows",
      "文件服务器"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 896,
    "topic": "",
    "question_cn": "一家公司正在设计其生产应用程序的灾难恢复策略。该应用程序由位于美国东1号地区亚马逊极光集群的MySQL数据库支持。该公司已选择美国西部地区为其博士区。公司的目标恢复点目标是5分钟，目标恢复时间目标是20分钟。该公司希望最小化配置更改？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "在美国西部创建一个极光读取副本，其规模类似于生产应用程序的MySQL集群编写实例。",
      "B": "将极光集群转换为极光全球数据库。配置托管故障转移。",
      "C": "在美国西部创建一个具有跨区域复制的新极光集群。",
      "D": "在美国西部创建一个新的极光集群。使用AWS DMS数据库迁移服务来同步两个集群。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Aurora Global Database",
      "Disaster Recovery"
    ],
    "explanation": {
      "analysis": "核心考点是数据库灾难恢复。 转换成 Aurora Global Database，并配置托管故障转移，能够满足低RTO和RPO的需求，且配置改动最小。",
      "why_correct": "B  Aurora Global Database 提供了跨区域的灾难恢复能力，可以实现快速的故障转移，满足RTO和RPO要求。",
      "why_wrong": "A 读取副本无法满足灾备的RTO和RPO要求。C 新建跨区域复制集群需要初始化，恢复时间长，且配置复杂。D DMS用于迁移，恢复时间不确定。"
    },
    "related_terms": [
      "Aurora",
      "MySQL",
      "MySQL集群",
      "极光读取副本",
      "极光全球数据库",
      "AWS DMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 897,
    "topic": "",
    "question_cn": "一家公司每周在工作周的第一天之前就进行一项重要的数据分析工作。这项工作需要至少 2 小时才能完成分析。这项工作是有规模的，不能容忍干扰。该公司需要一个解决方案来在美国航空公司运作这项工作。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为这项工作创建一个容器。在亚马逊弹性容器服务集群中通过使用亚马逊视频桥调度器将工作安排为作为 法盖特任务运行。",
      "B": "配置工作运行在一个 Lambda 函数。创建一个在亚马逊 EventBridge 计划的规则调用 Lambda 函数。",
      "C": "在 Linux EC2 实例上配置一个 CLONTAB 条目来运行分析。配置运行亚马逊 点实例的自动缩放组。",
      "D": "配置一个 数据化任务来运行作业。配置一个 表达式来按计划运行任务。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS Fargate",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "此题考察在 AWS 上调度大规模任务的方案。选项 A 使用 ECS Fargate 运行容器化任务，符合要求。其他选项或成本过高，或不支持大规模并发。",
      "why_correct": "A 选项使用 ECS Fargate 运行容器化任务，可以满足大规模计算的需求，并且 Fargate 提供了无服务器的计算能力，不需要管理服务器，符合题目中的无干扰要求。",
      "why_wrong": "B 选项使用 Lambda 函数，可能因为计算时间限制或函数超时导致失败。C 选项使用 EC2 和 cron，需要手动管理 EC2 实例，维护成本高。D 选项 Cron 表达式运行任务的方式不如 A 选项的 Fargate 更具弹性。"
    },
    "related_terms": [
      "弹性容器服务",
      "Fargate",
      "Lambda",
      "EventBridge",
      "EC2",
      "CLONTAB",
      "点实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 898,
    "topic": "",
    "question_cn": "一家公司在云中运行工作负载。该公司希望集中收集安全数据以评估整个公司的安全性并改进工作量保护。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在 AWS 湖组中配置一个数据湖。使用 Glue 爬虫吸收安全数据到数据湖。",
      "B": "配置一个 Lambda 函数来收集安全数据。CSV 格式。上传数据到一个 S3 桶。",
      "C": "配置亚马逊安全湖中的数据湖来收集安全数据。上传数据到一个 S3 桶。",
      "D": "配置 RDS 数据库迁移服务 复制实例将安全数据加载到亚马逊 集群中。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Security Lake",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察利用 AWS 安全湖进行安全数据收集的方案。C 选项直接使用安全湖，是最佳选择。其他选项的方案需要更多的手动配置，或不符合题意。",
      "why_correct": "C 选项直接使用 AWS Security Lake，这是专门用于集中收集安全数据的服务，满足题目的需求，并且最简单。",
      "why_wrong": "A 选项需要手动配置 Glue 和数据湖，比 C 选项复杂。B 选项需要自己编写 Lambda 函数和数据格式，开发成本高。D 选项使用 DMS，不适用与收集安全数据。"
    },
    "related_terms": [
      "AWS 湖组",
      "Glue",
      "Lambda",
      "CSV",
      "S3",
      "亚马逊安全湖",
      "RDS",
      "DMS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 899,
    "topic": "",
    "question_cn": "一家公司正在将五个内部应用程序迁移到云中的 VPC 中。每一个应用程序目前都部署在单独的虚拟网络中应该同样部署在云 VPC 中。应用程序需要到达共享服务。所有的应用程序必须能够相互交流，如果迁移成功该公司将对多个申请重复迁移过程。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在应用程序 和共享服务 之间部署 VPN 隧道。将子网中的应用程序 之间的路由添加到共享服务。",
      "B": "部署 查看应用程序 和共享服务 之间的连接。通过窥视连接将子网中的应用程序 之间的路由添加到共享服务 VPC。",
      "C": "部署应用程序 和共享服务 路由之间的 直接连接从其子网中的应用程序 路由到共享服务 和应用程序  VPC。将共享服务 子网的路由添加到 应用程序中。",
      "D": "部署一个连接过境网关和应用程序 和共享服务 的过境网关。在子网中的应用程序 和应用程序 之间通过中转 VPC 网关向共享服务 添加路由。"
    },
    "vote_percentage": "88%",
    "tags": [
      "Transit Gateway",
      "VPC"
    ],
    "explanation": {
      "analysis": "此题考察多个 VPC 互连的方案。D 选项使用 Transit Gateway 是最佳选择，可以简化网络管理。其他选项实现复杂，不便于扩展。",
      "why_correct": "D 选项使用 Transit Gateway，Transit Gateway 简化了 VPC 之间的连接，易于管理和扩展，满足题目的需求。",
      "why_wrong": "A 选项使用 VPN，管理复杂，不便于扩展。B 选项和 C 选项连接方式复杂。"
    },
    "related_terms": [
      "VPC",
      "VPN 隧道",
      "Direct Connect",
      "过境网关"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 900,
    "topic": "",
    "question_cn": "一家公司希望使用亚马逊弹性集装箱服务 亚马逊 在混合环境中运行其内部应用程序。该应用程序目前在现场的容器上运行。该公司需要一个单一的容器解决方案可以在内部、混合或云环境中进行扩展。该公司必须在云中运行新的应用程序容器并且必 HTTP 须使用负载平衡器来处理 流量。哪些行动组合将满足这些要求？选二。",
    "options_cn": {
      "A": "为云应用程序容器建立一个使用 法盖特发射类型的 集群。在任何外部发射类型使用亚马逊系统用于现场应用程序容器。",
      "B": "为云计算服务建立一个应用负载平衡器。",
      "C": "为云计算服务建立网络负载平衡器。",
      "D": "建立一个使用美国航空航天系统法盖特发射类型的集群。对云应用程序容器和内部应用程序容器使用法尔盖特。",
      "E": "为云应用程序容器建立一个使用亚马逊  发射类型的 集群。在任何地方使用亚马逊的应用程序容器使用 法盖特发射类 型。"
    },
    "vote_percentage": "100%",
    "tags": [
      "ECS Fargate",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "此题考察在 ECS 中使用 Fargate 和 ALB 的组合方案。A 和 B 选项满足题意。",
      "why_correct": "A 选项使用 Fargate 启动类型运行容器，这是无服务器的，满足在云中运行的要求。B 选项使用 Application Load Balancer（ALB），可以满足HTTP 流量的负载均衡需求。",
      "why_wrong": "C 选项使用 Network Load Balancer，不适用于HTTP流量。D 选项试图在内部环境中使用 Fargate，不符合混合云的定义，因为 Fargate 是无服务器的，仅适用于云环境。E 选项描述有误， Fargate 启动类型并没有亚马逊 的选项。"
    },
    "related_terms": [
      "ECS",
      "Fargate",
      "ALB",
      "负载平衡器"
    ],
    "best_answer": [
      "A",
      "B"
    ],
    "official_answer": [
      "A",
      "B"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 901,
    "topic": "",
    "question_cn": "一家公司正在将其工作量转移到美国航空服务公司。该公司在运行在 服务器实例的内部关系数据库中有敏感和关键的数据。该公司希望使用 云来提高安全性减少数据库的运行开销。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到亚马逊 EC2 实例。使用 KMS 密钥管理服务 管理密钥进行加密。",
      "B": "将数据库迁移到多个  RDS 亚马逊 的 服务器数据库实例。使用 KMS 密钥管理服务 管理密钥进行加密。",
      "C": "将数据迁移到 S3 桶。使用亚马逊马西确保数据安全。",
      "D": "将数据库迁移到亚马逊 DynamoDB 表。使用亚马逊云观察日志来确保数据安全。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS",
      "KMS"
    ],
    "explanation": {
      "analysis": "此题考察数据库迁移到 AWS 上的最佳实践。B 选项使用 RDS 和 KMS，安全性好，运维成本低。",
      "why_correct": "B 选项使用 RDS 服务，RDS 提供了托管的数据库服务，减少了数据库的维护工作量，同时使用 KMS 进行密钥加密，提高了安全性，是最优解。",
      "why_wrong": "A 选项将数据库迁移到 EC2，需要自己管理数据库，运维复杂。C 选项将数据库迁移到 S3，不符合关系数据库的需求。D 选项使用 DynamoDB，不适用于传统关系型数据库。"
    },
    "related_terms": [
      "EC2",
      "KMS",
      "RDS",
      "DynamoDB",
      "S3",
      "马西",
      "CloudWatch"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 902,
    "topic": "",
    "question_cn": "一家公司想将一个应用程序迁移到美国航空信息系统。该公司希望增加该应用程序目前的可用性。该公司希望在应用程序的架构中使用  AWS。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个自动缩放组其中包含多个亚马逊 EC2 实例这些实例在两个可用性区域中承载应用程序。配置应用程序负载平衡器 (ALS), 并将自动缩放组设置为目标。连接一个  到行。",
      "B": "创建一个集群放置组其中包含多个托管应用程序的亚马逊 EC2 实例。配置应用程序负载平衡器并将 实例设置为目标。连接  一个 到安置组。",
      "C": "创建两个亚马逊 EC2 实例这些实例在两个可用性区域上承载应用程序。将 实例配置为应用程序负载平衡器 的目标。连  接一个  到 行。",
      "D": "创建一个自动缩放组其中包含多个亚马逊 EC2 实例这些实例在两个可用性区域中承载应用程序。配置应用程序负载平衡 (ALS),  器 并将自动缩放组设置为目标。将 连接到自动缩放组。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Auto Scaling",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "此题考察如何提高应用程序的可用性。A 选项使用 Auto Scaling 和 ALB，实现高可用性。",
      "why_correct": "A 选项使用 Auto Scaling 组和 Application Load Balancer，在两个可用区部署多个 EC2 实例，提供了高可用性和弹性。",
      "why_wrong": "B 选项使用集群放置组，可能会影响可用性，放置组并非提高可用性的主要手段。C 选项手动创建两个实例，无法自动扩展。D 选项语句不完整。"
    },
    "related_terms": [
      "AWS",
      "EC2",
      "可用性区域",
      "自动缩放组",
      "负载平衡器",
      "ALS",
      "实例",
      "安置组"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 903,
    "topic": "",
    "question_cn": "一家公司在亚马逊 S3 桶中管理一个数据湖，许多应用程序都可以访问。 桶包含每个应用程序的唯一前缀。该公司希望将每个应用程 序限制在其特定前缀上并对每个前缀下的对象进行颗粒控制。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为每个应用程序创建专用的 S3 接入点和接入点策略。",
      "B": "为桶中的每个对象设置 S3 ACL 权限。",
      "C": "为每个应用程序将 S3 桶中的对象复制到新的 S3 桶中。用前缀创建复制规则。",
      "D": "为每个应用程序将 S3 桶中的对象复制到新的 S3 桶中。为每个应用程序创建专用的 访问点。"
    },
    "vote_percentage": "78%",
    "tags": [
      "S3 Access Points",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察 S3 权限管理。A 选项使用 S3 Access Points 是最简洁的方案，也是推荐的最佳实践。",
      "why_correct": "A 选项使用 S3 Access Points，可以针对每个应用创建独立的访问点，并设置不同的策略，控制访问权限。",
      "why_wrong": "B 选项使用 ACL，管理复杂，不推荐。C 选项和 D 选项复制 S3 桶，增加了存储成本和管理负担。"
    },
    "related_terms": [
      "S3",
      "接入点",
      "S3 ACL",
      "访问点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 904,
    "topic": "",
    "question_cn": "一家公司有一个应用程序，客户可以用它将图片上传到亚马逊 S3 桶中。每天晚上公司都会推出亚马逊 点播车队处理当天收到的 2, 512mb 所有图像。每个图像的处理需要 2 分钟需要 512MB 的内存。 解决方案架构师需要在图像上传时更改应用程序来处理图像。 哪些变化最符合这些要求？",
    "options_cn": {
      "A": "使用 S3 事件通知将带有图像细节的消息写入亚马逊简单队列服务队列 亚马逊小规模服务队列 。配置一个 Lambda 函数来读 取队列中的消息并处理图像。",
      "B": "使用 S3 事件通知将带有图像细节的消息写入亚马逊简单队列服务队列 亚马逊小规模服务队列 。配置 保留实例来读取队列 中的消息并处理图像。",
      "C": "使用 S3 事件通知将带有图像细节的消息发布到亚马逊简单通知服务 亚马逊 主题中。在亚马逊弹性容器服务中配置一个容 器实例以订阅主题并处理图像。",
      "D": "使用 S3 事件通知将带有图像细节的消息发布到亚马逊简单通知服务 亚马逊 主题中。配置一个 弹性豆柄应用程序来 订阅主题并处理图像。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Event Notifications",
      "Lambda",
      "SQS"
    ],
    "explanation": {
      "analysis": "此题考察 S3 触发事件的处理方案。A 选项使用 S3 事件通知触发 SQS 队列，再由 Lambda 处理，符合无服务器架构，扩展性好，是最优解。",
      "why_correct": "A 选项使用 S3 事件通知触发 SQS 队列，可以异步处理图像，不会影响上传流程。 Lambda 函数负责从队列中读取消息并处理图像，无服务器架构，扩展性好。",
      "why_wrong": "B 选项使用保留实例，成本高，而且不灵活。C 选项使用 SNS 和 ECS，增加了复杂性。D 选项使用 SNS 和 Elastic Beanstalk，不够灵活，不推荐。"
    },
    "related_terms": [
      "S3",
      "EC2",
      "Lambda",
      "SQS",
      "简单队列服务",
      "弹性容器服务",
      "SNS",
      "简单通知服务",
      "弹性豆柄应用程序"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 905,
    "topic": "",
    "question_cn": "一家公司希望改进其混合应用程序的可用性和性能。该应用程序包括基于状态的 工作负载在亚马逊 EC2 实例中在不同的 区域， 和无状态的基于 UDP 的工作负载在房地中。解决方案架构师应该采取哪些行动组合来提高可用性和性能？选二。",
    "options_cn": {
      "A": "创建一个加速器使用美国世界银行全球加速器。添加负载平衡器作为端点。",
      "B": "创建一个亚马逊云前分布源使用亚马逊线路 53 后路由到路由请求负载平衡器。",
      "C": "配置每个区域的两个应用程序负载平衡器。第一条路径将是 端点第二条路径将是现场端点。",
      "D": "配置每个区域的网络负载平衡器以解决 端点。在每个路由到内部端点的区域中配置网络负载平衡器。",
      "E": "配置每个区域的网络负载平衡器以解决 端点。在路由到内部端点的每个区域配置应用程序负载平衡器。"
    },
    "vote_percentage": null,
    "tags": [
      "Global Accelerator",
      "NLB"
    ],
    "explanation": {
      "analysis": "此题考察混合云环境下的可用性和性能优化。A 和 D 选项提供最佳实践。",
      "why_correct": "A 选项使用 Global Accelerator 优化性能。D 选项使用 NLB 解决 UDP 端点。这俩结合，可以实现负载均衡和性能优化。",
      "why_wrong": "B 选项使用 CloudFront，只适用于静态内容。C 和 E 选项不完整。"
    },
    "related_terms": [
      "EC2",
      "全球加速器",
      "负载平衡器",
      "线路 53",
      "云前分布",
      "应用程序负载平衡器",
      "网络负载平衡器"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 906,
    "topic": "",
    "question_cn": "一家公司在亚马逊 EC2 实例和亚马逊弹性块存储 EBS 上运行一个自管理的微软 SQL 服务器。每日快照的 EBS 卷。 EBS， 最近公司所有 快照都是在运行删除所有过期 快照的快照清理脚本时意外删除的。解决方案架构师需要更新体系结构以防止数据丢失而不必无限期地保留 EBS 快照。用最小的开发努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "更改用户的 IAM 策略以拒绝 EBS 快照删除。",
      "B": "每天完成快照后将 EBS 快照复制到另一个 区域。",
      "C": "在回收站中创建 7 天 快照保留规则并对所有快照应用该规则。",
      "D": "复制 EBS 快照到亚马逊 S3 标准不常访问 标准 。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM",
      "EBS Snapshots"
    ],
    "explanation": {
      "analysis": "此题考察如何防止 EBS 快照被误删除。A 选项通过 IAM 策略阻止误删除，是最简单有效的方案。",
      "why_correct": "A 选项通过 IAM 策略阻止用户删除快照，有效地防止误操作，并且实现简单。",
      "why_wrong": "B 选项复制到另一个区域，可以防止区域故障，但不能防止误删除。C 选项需要开发，并且 7 天的保留策略可能无法满足需求。D 选项将快照复制到 S3 不常用访问，成本高，且不能防止删除。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "快照",
      "IAM",
      "区域",
      "S3",
      "标准不常访问"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 907,
    "topic": "",
    "question_cn": "一个公司希望在测试环境中使用 云图栈。该公司在亚马逊 S3 的桶中存储云图模板以阻止公众访问。该公司希望根据特定的用户 S3 请求授予对 桶中模板的云形成访问权以创建测试环境。解决方案必须遵循安全最佳做法。 哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为亚马逊 S3 创建网关 VPC 端点。将云格式堆栈配置为使用 S3 对象 URL 。",
      "B": "创建一个具有 S3 桶作为目标的亚马逊 API RESTAPI 网关 。将云格式堆栈配置为使用 API 网关 URL 。",
      "C": "为模板对象创建一个预先签名的 URL 。将云格式堆栈配置为使用预先签名的 URL 。",
      "D": "允许公众访问 S3 桶中的模板对象。在创建测试环境后阻塞公共访问"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Pre-signed URLs",
      "CloudFormation"
    ],
    "explanation": {
      "analysis": "此题考察安全访问 S3 中的 CloudFormation 模板。C 选项使用预签名 URL，符合安全最佳实践。",
      "why_correct": "C 选项使用预签名 URL，可以根据用户的请求，生成临时的访问 URL，满足了根据用户请求动态授权访问的要求，并且是最安全的做法。",
      "why_wrong": "A 选项使用 VPC 端点，无法解决访问控制的问题。B 选项使用 API 网关，增加了复杂性。D 选项直接开放 S3 桶的公共访问，不符合安全最佳实践。"
    },
    "related_terms": [
      "S3",
      "云图栈",
      "VPC",
      "API",
      "API 网关",
      "预先签名的 URL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 908,
    "topic": "",
    "question_cn": "一个公司有在一个组织中运行的应用程序。该公司外包业务支持的应用程序。公司需要在不损害安全的情况下为外部支持工程师提供通道。外部支持工程师需要访问 管理控制台。外部支持工程师还需要操作系统访问该公司车队的 EC2 实例这些实例在私人子网 Linux 中运行亚马逊 。 哪个解决方案最安全地满足这些要求？",
    "options_cn": {
      "A": "确认在所有实例上安装了 系统管理代理 SSM 代理 。分配一个具有连接到系统管理器所需策略的实例概要文件 使用 身份识别中心提供外部支持工程师控制台访问。使用系统管理器会话管理器来分配所需的权限。",
      "B": "确认在所有实例上安装了 系统管理代理 SSM 代理 。分配一个具有连接到系统管理器所需策略的实例概要文件 使用系统管理器会话管理器向外部支持工程师提供每个 帐户中的本地 用户凭证以便进行控制台访问。",
      "C": "确认所有实例都有一个安全组只允许从外部支持工程师的源 IP 地址范围访问 。在每个  帐户中提供本地 用户凭证给外部 SSH 支持工程师以便访问控制台。提供每个外部支持工程师一个 密钥对登录到应用程序实例。",
      "D": "在公共子网中创建一个堡垒主机。建立堡垒主机安全组只允许从外部工程师的 地址范围访问。确保所有实例都有一个 SSH SSH iam 允许从堡垒主机访问 的安全组。提供每个外部支持工程师一个 密钥对登录到应用程序实例。向工程师提供本地帐户 用户 , 凭证以便访问控制台。"
    },
    "vote_percentage": null,
    "tags": [
      "SSM Session Manager",
      "IAM",
      "EC2"
    ],
    "explanation": {
      "analysis": "此题考察安全地访问 EC2 实例的方案。A 选项使用 SSM Session Manager，是最安全的解决方案，并且不需要开放 SSH 端口。",
      "why_correct": "A 选项使用 SSM Session Manager，可以安全地访问 EC2 实例，并且无需打开 SSH 端口。使用 IAM 角色进行身份验证，安全可靠。",
      "why_wrong": "B 选项不安全，不建议给用户提供账号密码进行控制台访问。C 选项和 D 选项使用 SSH 和密钥对，需要开放 SSH 端口，安全风险较高。"
    },
    "related_terms": [
      "EC2",
      "SSM",
      "身份识别中心",
      "系统管理器",
      "IAM",
      "Linux",
      "安全组",
      "SSH",
      "密钥对",
      "堡垒主机",
      "公共子网"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 909,
    "topic": "",
    "question_cn": "一家公司使用亚马逊 RDS 来运行其在美东 1 号地区的应用程序。该公司还使用机器学习 模型根据近实时报告预测年度收入。这些 RDS 报告是通过使用相同的 数据库生成的。数据库性能在工作时间会减缓。公司需要改进数据库性能。 哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个跨区域读副本。配置从读取副本生成的报表。",
      "B": "启动后  RDS 的多 AZ 数据库实例部署。配置从备用数据库生成的报表。",
      "C": "使用 数据迁移服务 来逻辑地将数据复制到一个新的数据库中。配置要从新数据库生成的报表。",
      "D": "在美国东 1 号创建一个读副本。配置从读取副本生成的报表。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Read Replicas",
      "Performance Optimization"
    ],
    "explanation": {
      "analysis": "此题考察数据库性能优化方案。D 选项使用同区域的读副本，提高性能。",
      "why_correct": "D 选项在美国东 1 号地区创建一个读副本，用于生成报表，可以减轻主数据库的负载，提高性能。",
      "why_wrong": "A 选项创建跨区域读副本，延迟较高。B 选项使用多 AZ 部署，主要用于提高可用性，不能提升性能。C 选项使用 DMS 复制数据库，实现复杂。"
    },
    "related_terms": [
      "RDS",
      "读副本",
      "多AZ",
      "数据库实例",
      "数据迁移服务"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 910,
    "topic": "",
    "question_cn": "一家公司在云中拥有其多层的、公共的 Web 应用程序。网络应用程序运行在亚马逊 EC2 实例上，其数据库运行在亚马逊 RDS 上。该 Web 应用程序预计在即将到来的周末假期期间销售额将大幅增长。解决方案架构师需要构建一个解决方案来分析 应用程序的粒度不超过 2 分钟的性能。 解决方案架构师应该做什么来满足这个需求？",
    "options_cn": {
      "A": "把亚马逊云表日志送到亚马逊红移。使用亚马逊统计学进行进一步分析。",
      "B": "EC2 能够对所有 实例进行详细监测。使用亚马逊云表指标执行进一步的分析。",
      "C": "创建一个 Lambda 函数从亚马逊云表日志中获取  日志。使用亚马逊云表指标执行进一步的分析。",
      "D": "将 日志发送到亚马逊 S3  。使用亚马逊红移从  S3 桶获取日志处理原始数据以进一步分析亚马逊快视。"
    },
    "vote_percentage": null,
    "tags": [
      "CloudWatch",
      "EC2 Monitoring"
    ],
    "explanation": {
      "analysis": "此题考察应用程序性能监控。B 选项使用 CloudWatch 详细监控，满足 2 分钟粒度的要求。",
      "why_correct": "B 选项使用 CloudWatch 详细监控可以实现 1 分钟的粒度，满足题目的需求。",
      "why_wrong": "A 和 D 选项，通过 Redshift 分析 CloudWatch 日志，时延较大，不满足 2 分钟的粒度要求。C 选项使用 Lambda 处理 CloudWatch 日志，增加了复杂性，并非最佳实践。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "应用程序",
      "云表日志",
      "红移",
      "统计学",
      "云表指标",
      "Lambda",
      "S3",
      "亚马逊快视"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 911,
    "topic": "",
    "question_cn": "一家公司运行一个存储和共享照片的应用程序。用户将照片上传到亚马逊 S3 桶。每天用户上传大约 150 张照片。该公司希望设计一  个解决方案创建每个新照片的缩略图并将缩略图存储在第二个 S3 桶中。 哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在长期运行的亚马逊 EMR 集群中每分钟配置一个亚马逊 EventBridge 计划规则来调用脚本。配置脚本为没有缩略图的照片生成缩略 S3 图。配置脚本将缩略图上传到第二个 桶。",
      "B": "配置一个亚马逊 EventBridge 计划规则以便每分钟调用一个内存优化的亚马逊 EC2 实例上的脚本。配置脚本为没有缩略图的照片生成 S3 缩略图。配置脚本将缩略图上传到第二个 桶。",
      "C": "每次用户将新照片上传到应用程序时配置一个 S3 事件通知来调用 Lambda 函数。配置 Lambda 函数以生成缩略图并将缩略图上 S3 传到第二个 桶。",
      "D": "每次用户向应用程序上传新照片时配置 S3 存储透镜以调用 Lambda 函数。配置 Lambda 函数以生成缩略图并将缩略图上传 S3 到第二个 桶。"
    },
    "vote_percentage": null,
    "tags": [
      "Lambda",
      "S3 Event Notifications"
    ],
    "explanation": {
      "analysis": "此题考察 S3 上传图片后生成缩略图的方案。C 选项使用 Lambda 函数响应 S3 事件，是最优解。",
      "why_correct": "C 选项使用 S3 事件通知触发 Lambda 函数，当有新的图片上传到 S3 时，自动触发 Lambda 生成缩略图，并将缩略图保存到另外一个 S3 桶中，符合无服务器的架构，扩展性和成本都较好。",
      "why_wrong": "A 选项和 B 选项使用定时任务，不能实时触发，并且需要维护 EMR 或 EC2 实例，不推荐。D 选项使用 S3 存储透镜，不适用于触发事件处理。"
    },
    "related_terms": [
      "S3",
      "EventBridge",
      "EC2",
      "Lambda"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 912,
    "topic": "",
    "question_cn": "一家公司使用亚马逊S3桶在亚马逊冰川深度档案存储类中存储了数百万个跨多个前缀的对象。该公司需要删除所有超过3年的数据，但必须保留的数据子集除外。该公司已经确定了必须保留的数据并希望实现无服务器解决方案。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用S3清单列出所有对象。使用EC2创建一个脚本，该脚本在亚马逊EC2实例上运行，删除清单列表中的对象。",
      "B": "使用S3批处理删除3年以上的对象，但必须保留的数据除外。",
      "C": "提供一个Glue爬虫来查询超过3年的对象。保存旧对象的清单文件。创建一个脚本来删除清单中的对象。",
      "D": "启用S3库存。创建一个Lambda函数来过滤和删除对象。通过使用库存报告调用S3批处理操作的Lambda函数来删除对象。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Lifecycle",
      "S3 Batch Operations"
    ],
    "explanation": {
      "analysis": "此题考察S3生命周期管理和S3批量操作。官方答案为D，社区共识一致。通过S3库存和Lambda函数的结合，可以实现对S3对象的筛选和删除，满足无服务器和保留数据的需求。",
      "why_correct": "选项D结合了S3库存、Lambda函数和S3批处理操作，能够实现对特定对象的删除，同时保留需要保留的数据。这是最佳解决方案，因为它提供了最大的灵活性，能够精确控制哪些对象被删除，哪些对象被保留。",
      "why_wrong": "选项A使用EC2实例运行脚本，需要管理EC2实例，增加了运维复杂度。选项B使用S3批处理，但无法排除需要保留的数据。选项C使用Glue爬虫和脚本，增加了复杂性，且效率较低。"
    },
    "related_terms": [
      "S3",
      "冰川",
      "EC2",
      "Glue",
      "Lambda",
      "S3 批处理"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 913,
    "topic": "",
    "question_cn": "一家公司正在建立一个应用程序。该应用程序使用多个Lambda函数从一个亚马逊S3桶中检索敏感数据进行处理。公司必须确保Lambda只有授权的功能才能访问数据。解决办法必须符合最小特权原则。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "通过一个共享的IAM角色授予所有Lambda函数访问所有S3桶。",
      "B": "为Lambda函数配置要在VPC中运行的Lambda函数。配置一个桶策略以授予基于Lambda函数的VPC端点地址的访问。",
      "C": "为每一个Lambda函数创建单独的IAM角色。将IAM角色访问到S3桶。分配每个IAM角色作为相应的Lambda函数的执行角色。",
      "D": "配置一个桶策略授予基于其Lambda函数的ARN的Lambda函数的访问权。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM Roles",
      "S3 Bucket Policy"
    ],
    "explanation": {
      "analysis": "此题考察IAM角色和S3桶策略。官方答案和社区共识一致，为C。最佳实践是为每个Lambda函数创建单独的IAM角色，并授予其访问S3桶的最小权限，遵循最小权限原则。",
      "why_correct": "选项C遵循最小权限原则，为每个Lambda函数创建单独的IAM角色，并仅授予其访问S3桶的必要权限，从而提高了安全性。这是最佳实践。",
      "why_wrong": "选项A使用共享角色，违反了最小权限原则。选项B使用VPC端点地址，虽然可行，但不如IAM角色直接。选项D使用Lambda函数的ARN，虽然可行，但不如IAM角色更灵活，更易于管理。"
    },
    "related_terms": [
      "S3",
      "Lambda",
      "IAM",
      "VPC",
      "ARN"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 914,
    "topic": "",
    "question_cn": "一家公司开发了一个非生产应用程序，该应用程序由公司每个业务单位的多种微服务组成。一个开发团队维护所有的微服务。Web前端使用Java、mysql后端，其中包含应用程序逻辑。该架构还使用了一个数据库，该公司在亚马逊EC2实例上拥有该数据库。该公司需要确保该应用程序的安全性和可在全球范围内使用。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用Amazon API Gateway和AWS Lambda来主机静态的网页端。通过使用亚马逊API网关将微服务重构为使用Lambda的功能。将EC2数据库迁移到Amazon RDS。保留实例。",
      "B": "使用Amazon S3和AWS Lambda来主机静态的网页端。通过使用亚马逊API网关将微服务重构为使用Lambda的功能。为了mysql，将数据库迁移到Amazon RDS。",
      "C": "使用Amazon S3和AWS Lambda来主机静态的网页端。重构微服务使用位于网络负载平衡器后面的目标组中的Lambda函数。为了mysql，将数据库迁移到Amazon RDS。",
      "D": "使用Amazon S3来主机静态网页正面。重构微服务使用位于应用程序负载平衡器后面的目标组中的Lambda函数。将mysql EC2数据库迁移到Amazon RDS。保留实例。"
    },
    "vote_percentage": null,
    "tags": [
      "Serverless Architecture",
      "Amazon RDS"
    ],
    "explanation": {
      "analysis": "此题考察Web应用程序的现代化改造。官方答案和社区共识一致，为B。 最佳解决方案是使用S3托管静态内容，使用Lambda函数构建微服务，并使用RDS托管数据库，实现高可用性和全球访问。",
      "why_correct": "选项B使用了S3托管静态内容，Lambda函数构建微服务，以及RDS托管数据库。这是一种现代化的、可扩展的、高可用性的架构，可以满足安全性和全球可访问性的需求。这是最经济实惠的方案。",
      "why_wrong": "选项A使用了API Gateway，API Gateway适用于对外暴露API，对于内部微服务来说，API Gateway不是必须的。 选项C和D的选项有使用网络负载平衡器（NLB）和应用负载平衡器（ALB）的差异，但使用NLB的成本比ALB略高。"
    },
    "related_terms": [
      "EC2",
      "API Gateway",
      "AWS Lambda",
      "S3",
      "RDS",
      "Java",
      "mysql",
      "保留实例",
      "网络负载平衡器",
      "应用程序负载平衡器",
      "mysql"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 915,
    "topic": "",
    "question_cn": "一家电子游戏公司正在向全球用户部署一个新的游戏应用程序。该公司需要一种能够提供几乎实时的玩家评估和排名的解决方案。解决方案架构师必须设计解决方案以提供对数据的快速访问。如果公司重新启动应用程序解决方案还必须确保数据在磁盘上持续存在。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "以亚马逊S3桶作为起源配置亚马逊云端分布。将玩家数据存储在S3桶中。",
      "B": "在多个AWS区域创建亚马逊EC2实例。在EC2实例上存储玩家数据。将具有地理定位记录的亚马逊Route 53线路配置为直接用户访问EC2最近的实例。",
      "C": "为雷迪斯除尘器部署一个亚马逊弹性飞机。将玩家数据存储在弹性集群中。",
      "D": "部署一个亚马逊弹力用于记忆粉。将玩家数据存储在弹性集群中。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon ElastiCache",
      "Redis"
    ],
    "explanation": {
      "analysis": "此题考察实时数据处理和持久化。官方答案和社区共识一致，为C。使用ElastiCache for Redis可以提供快速的读写性能，满足实时需求，同时Redis的持久化功能可以保证数据的持续存在。",
      "why_correct": "选项C使用ElastiCache for Redis，提供了快速的读写性能，满足实时玩家评估和排名的需求。Redis的持久化机制确保了数据的持续存在。这是最佳解决方案，因为它提供了快速的性能和数据持久性。",
      "why_wrong": "选项A使用S3，S3不适合需要低延迟的实时数据访问。选项B使用EC2，需要管理EC2实例，增加了运维复杂度。选项D是选项C的错误说法， ElastiCache 并没有弹力用于记忆粉。"
    },
    "related_terms": [
      "S3",
      "云端分布",
      "EC2",
      "Route 53",
      "雷迪斯",
      "弹性飞机",
      "弹性集群",
      "弹力用于记忆粉"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 916,
    "topic": "",
    "question_cn": "一家公司正在设计一种基于AWS的应用程序，用于处理敏感数据。应用程序存储和处理多个客户的财务数据。为了满足合规要求，每个客户的数据必须使用安全的、集中的密钥管理解决方案在休息时单独加密。该公司希望使用密钥管理服务（AWS KMS）来实现加密。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为每个客户生成唯一的加密密钥。把钥匙放在一个亚马逊S3桶里。启用服务器端加密。",
      "B": "在AWS环境中部署硬件安全设备，安全存储客户提供的加密密钥。将安全设备与KMS集成以加密应用程序中的敏感数据。",
      "C": "创建一个单独的KMS键以加密整个应用程序的所有敏感数据。",
      "D": "为每个客户的数据创建单独的KMS键，这些数据具有颗粒访问控制和启用日志记录功能。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS KMS",
      "Encryption at Rest"
    ],
    "explanation": {
      "analysis": "此题考察AWS KMS的应用。官方答案和社区共识一致，为A。使用KMS为每个客户生成唯一的加密密钥，结合S3的服务器端加密，可以满足安全和合规性要求。",
      "why_correct": "选项A使用了KMS为每个客户生成唯一的加密密钥，并将密钥存储在S3中，同时启用S3的服务器端加密。这满足了安全性和合规性要求，并且操作开销最小。 这是最简洁、最有效的解决方案。",
      "why_wrong": "选项B涉及硬件安全设备，增加了复杂性和成本。选项C使用单个密钥，这不符合为每个客户单独加密的要求。选项D描述了KMS的使用场景，虽然可行，但增加了不必要的复杂性。"
    },
    "related_terms": [
      "KMS",
      "S3",
      "IAM"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 917,
    "topic": "",
    "question_cn": "一家公司需要设计一个有弹性的Web应用程序来处理客户订单。应用程序必须在不影响客户体验或失去客户订单的情况下自动处理Web流量和应用程序使用量的增加。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用NAT网关管理网络流量。使用亚马逊自动缩放组接收、处理和存储经过处理的客户订单。使用一个Lambda函数来捕获和存储未处理的订单。",
      "B": "使用网络负载平衡器（NLB）来管理网络流量。使用一个应用程序负载平衡器接收来自亚马逊Redshift的客户订单。使用多AZ部署来存储未处理和处理的客户订单。",
      "C": "使用网关负载平衡器来管理流量。使用亚马逊弹性集装箱服务接收和处理客户订单。使用SQS获取和存储未处理的订单。使用亚马逊DynamoDB存储处理客户订单。",
      "D": "使用应用程序负载平衡器管理Web流量。使用亚马逊自动缩放组接收和处理客户订单。使用亚马逊简单队列服务来存储未经处理的订单。使用亚马逊RDS与多AZ部署存储处理客户订单。"
    },
    "vote_percentage": null,
    "tags": [
      "Application Load Balancer",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考察应用程序的弹性设计。官方答案为D，但社区共识略有差异，倾向于D。最佳实践是使用ALB、Auto Scaling、SQS和RDS，满足弹性、可用性和数据持久性的需求。",
      "why_correct": "选项D使用ALB管理流量，自动缩放组处理负载，SQS存储未处理订单，RDS存储处理的客户订单，并使用多AZ部署提高可用性。这种组合提供了弹性和可用性，可以满足业务需求。",
      "why_wrong": "选项A使用NAT网关，不适合处理大规模流量。选项B和C使用了Redshift和ECS，并不完全符合题目的要求。"
    },
    "related_terms": [
      "NAT 网关",
      "自动缩放组",
      "Lambda",
      "NLB",
      "应用程序负载平衡器",
      "Redshift",
      "多AZ",
      "网关负载平衡器",
      "弹性集装箱服务",
      "SQS",
      "DynamoDB",
      "RDS",
      "多AZ"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 918,
    "topic": "",
    "question_cn": "一家公司正在使用AWS数据监视器将数百万个文件从一个内部系统迁移到S3。这些文件的平均尺寸是10KB。该公司希望使用亚马逊S3进行文件存储。在迁移后的第一年，文件将被访问一次或两次，必须立即提供。一年后，档案必须归档至少七年。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "使用归档工具将文件分组为大型对象。使用数据化方法迁移对象。在S3 Glacier即时检索中存储对象第一年。使用生命周期配置将文件转换到S3 Glacier深度档案库，保存期为7年。",
      "B": "使用归档工具将文件分组为大型对象。将对象复制到S3标准不经常访问（S3-IA）。使用生命周期配置将文件转换为S3 Glacier即时检索后保留期为7年。",
      "C": "配置S3 Glacier即时检索文件的目标存储类。使用生命周期策略将文件转换为S3 Glacier的灵活检索后保留期为7年。",
      "D": "配置数据展示任务将文件转移到S3标准不经常访问（S3-IA）。使用生命周期配置将文件在保留期为7年的一年后转换为S3深度归档。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Lifecycle Policies",
      "S3 Storage Classes"
    ],
    "explanation": {
      "analysis": "此题考察S3存储类和生命周期策略。官方答案为B，社区共识倾向于B。 使用S3-IA满足第一年的访问需求，然后转换为Glacier满足长期归档需求。",
      "why_correct": "选项B首先将文件存储在S3标准不经常访问（S3-IA）存储类中，以满足第一年可能需要少量访问的需求， 并在之后转换为 Glacier 即时检索。这是一种经济高效的解决方案，兼顾了访问频率和存储成本，符合题目的要求。",
      "why_wrong": "选项A将文件直接存储在Glacier中，这不符合第一年需要即时访问的要求。选项C和D的选项虽然符合归档要求，但未能充分利用S3-IA的优势，成本较高。"
    },
    "related_terms": [
      "S3",
      "Glacier",
      "S3-IA",
      "生命周期配置",
      "深度档案库",
      "数据化",
      "S3标准不经常访问"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 919,
    "topic": "",
    "question_cn": "一家公司最近对其内部的甲骨文数据库工作负载进行了提升和转移，以运行在亚马逊内存优化的EC2实例上。EC2实例使用1TB的SSD（I1）EBS卷，该卷有64,000IPS。迁移后的数据库存储性能比现场数据库的性能慢。哪种解决方案能提高存储性能？",
    "options_cn": {
      "A": "添加更多已预置的IOPS EBS卷。使用OS命令创建一个逻辑卷管理条条。",
      "B": "将已提供的IOPS EBS卷增加到多达64000 iPS。",
      "C": "将已提供的IOPS EBS卷增加到2TB。",
      "D": "将EC2实例更改为存储优化实例类型。不要改变已提供的IOPS EBS卷。"
    },
    "vote_percentage": null,
    "tags": [
      "EBS Volume Optimization",
      "IOPS"
    ],
    "explanation": {
      "analysis": "此题考察EBS卷的性能优化。官方答案和社区共识一致，为A。通过增加EBS卷，构建逻辑卷，可以提高存储性能。",
      "why_correct": "选项A通过添加更多EBS卷，创建逻辑卷管理条带，可以增加整体的IOPS和吞吐量，提高数据库存储性能，满足了数据库性能提升的需求。",
      "why_wrong": "选项B和C无法通过增加IOPS来大幅提升性能。选项D切换实例类型，可能无法解决现有的IOPS瓶颈，并且还需要停机维护。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "IOPS",
      "SSD",
      "逻辑卷管理"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 920,
    "topic": "",
    "question_cn": "一家公司正在从一个在亚马逊EC2上托管的网络应用程序的整体架构迁移到一个无服务器的微服务架构。该公司希望使用支持事件驱动的松散耦合架构的服务。该公司希望使用发布-订阅模式。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置一个亚马逊API网关以调用一个Lambda函数，该函数将事件发布到亚马逊简单队列服务（SQS）队列。配置一个或多个订阅者来读取来自SQS队列的事件。",
      "B": "配置一个亚马逊API网关以调用一个Lambda函数，该函数将事件发布到亚马逊简单通知服务（SNS）主题。配置一个或多个订阅者来接收来自SNS主题的事件。",
      "C": "配置一个亚马逊API网关的网络接口，以写入到一个数据流中的亚马逊Kinesis数据流中并增强出借。配置一个或多个订阅者接收数据流中的事件。",
      "D": "配置一个亚马逊API网关以调用一个Lambda函数，该函数将事件发布到亚马逊简单通知服务（SNS）主题。配置一个或多个订阅者接收来自主题的事件。"
    },
    "vote_percentage": null,
    "tags": [
      "SNS",
      "Lambda"
    ],
    "explanation": {
      "analysis": "此题考察发布-订阅模式。官方答案和社区共识一致，为B。SNS非常适合发布-订阅模式，Lambda可以作为中间层处理事件，实现松散耦合的架构。",
      "why_correct": "选项B使用了SNS和Lambda函数，实现了发布-订阅模式。API Gateway触发Lambda函数，Lambda函数将事件发布到SNS主题，订阅者接收来自SNS主题的事件，满足了题目的要求。 这是最佳实践，因为它提供了松散耦合和可扩展性。",
      "why_wrong": "选项A使用了SQS，SQS更适合消息队列，而不是发布-订阅模式。选项C使用了Kinesis，Kinesis更适合流数据处理。选项D与B类似，但重复了答案。"
    },
    "related_terms": [
      "API网关",
      "Lambda",
      "SQS",
      "SNS",
      "Kinesis"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 921,
    "topic": "",
    "question_cn": "一家公司最近将一个完整的应用程序迁移到亚马逊EC2实例和亚马逊RDS。该应用程序具有紧密耦合的模块。应用程序的现有设计使EC2应用程序能够只在一个RDS实例上运行。该公司已经注意到在使用高峰时期EC2实例的CPU利用率很高。高CPU利用率与亚马逊RDS的读请求性能下降相关。该公司希望降低CPU利用率，提高读请求性能。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "将EC2实例调整为具有更多CPU容量的实例类型。配置一个最小和最大尺寸为1的自动缩放组。为读请求配置一个读副本。",
      "B": "将EC2实例调整为具有更多CPU容量的实例类型。配置一个最小和最大尺寸为1的自动缩放组。添加读取副本并将所有读写流量重定向到副本。",
      "C": "配置一个最小尺寸1和最大尺寸2的自动缩放组。将数据库实例调整为具有更多CPU容量的实例类型。",
      "D": "将EC2实例调整为具有更多CPU容量的实例类型。配置一个最小和最大尺寸为1的自动缩放组。将数据库实例调整为具有更多CPU容量的实例类型。"
    },
    "vote_percentage": null,
    "tags": [
      "Read Replicas",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考察RDS的读性能优化。官方答案和社区共识一致，为B。通过添加只读副本和负载均衡，可以分担读请求的压力，提高性能。",
      "why_correct": "选项B通过添加RDS读副本，将读写流量分流，可以提高读性能。同时通过调整EC2实例和自动伸缩，可以增加CPU容量，提高应用程序的整体性能。这是最佳实践，可以解决CPU利用率高和读请求性能下降的问题。",
      "why_wrong": "选项A没有将读写流量分流，读副本只是为了提高可用性。选项C没有涉及到EC2实例，并不能解决CPU利用率高的问题。选项D并没有将读写流量分流。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "CPU",
      "读请求",
      "自动缩放组",
      "Read Replica"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 922,
    "topic": "",
    "question_cn": "一家公司需要授权一个开发团队访问该公司的AWS资源。公司必须对资源保持高度的安全性。该公司需要一个访问控制解决方案，将防止未经授权访问敏感数据。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用IAM，将每个开发团队成员的用户凭证与团队其他成员共享，以简化访问管理并简化开发工作流程。",
      "B": "使用IAM根据最小权限原则定义具有细粒度权限的IAM角色。为每个开发人员分配一个IAM角色。",
      "C": "创建IAM访问密钥授予对AWS资源的编程访问。只允许开发人员使用访问密钥通过AWS API调用与AWS资源交互。",
      "D": "创建一个科尼托用户池。通过使用用户池授予开发人员访问AWS资源的权限。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM",
      "Least Privilege"
    ],
    "explanation": {
      "analysis": "此题考察IAM权限管理。官方答案和社区共识一致，为B。最佳实践是使用IAM角色，并遵循最小权限原则，确保安全。",
      "why_correct": "选项B使用了IAM角色，并根据最小权限原则定义具有细粒度权限的角色。为每个开发人员分配一个角色。这符合安全最佳实践，并防止未经授权访问敏感数据。",
      "why_wrong": "选项A共享用户凭证，存在安全风险。选项C使用访问密钥，不如角色更安全。选项D使用了Cognito用户池，虽然也可以实现访问控制，但不如IAM角色更灵活。"
    },
    "related_terms": [
      "IAM",
      "IAM角色",
      "最小权限原则",
      "IAM访问密钥",
      "AWS API",
      "Cognito 用户池"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 923,
    "topic": "",
    "question_cn": "一家公司在亚马逊EC2实例上拥有一个单一的Web应用程序。应用程序用户最近在特定时间报告了性能差。对亚马逊云表指标的分析表明，在性能差的时期CPU利用率是100%。该公司希望解决这个性能问题并提高应用程序的可用性。哪些步骤组合将最符合这些要求？选二。",
    "options_cn": {
      "A": "使用AWS计算优化器获得一个实例类型垂直扩展的推荐。",
      "B": "从EC2服务器上创建一个亚马逊机器映像。请在一个新的发射模板中引用该自动识别系统。",
      "C": "创建一个自动缩放组和应用程序负载平衡器来垂直缩放。",
      "D": "使用AWS计算优化器获得一个实例类型水平扩展的推荐。",
      "E": "创建一个自动缩放组和一个应用程序负载平衡器水平缩放。"
    },
    "vote_percentage": null,
    "tags": [
      "Auto Scaling",
      "Load Balancing"
    ],
    "explanation": {
      "analysis": "此题考察应用程序性能优化和可用性提升。官方答案和社区共识一致，为BE。通过自动缩放和负载均衡，可以实现水平扩展，提高可用性，解决性能问题。",
      "why_correct": "选项B和E结合使用，创建 AMI，使用自动缩放组和应用程序负载均衡器进行水平扩展。这可以解决CPU利用率高的问题，并提高应用程序的可用性。这是最佳解决方案。",
      "why_wrong": "选项A使用计算优化器进行垂直扩展，只能解决部分问题，且无法提高可用性。选项C也属于垂直扩展，和A的原理一样。"
    },
    "related_terms": [
      "EC2",
      "Web应用程序",
      "CPU",
      "AWS计算优化器",
      "自动缩放组",
      "应用程序负载平衡器",
      "Amazon机器映像"
    ],
    "best_answer": [
      "B",
      "E"
    ],
    "official_answer": [
      "B",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 924,
    "topic": "",
    "question_cn": "一家公司运行其所有的业务应用程序在AWS云。该公司利用AWS组织的组织来管理多个AWS账户。解决方案架构师需要审查授予IAM用户的所有权限，以确定哪些IAM用户拥有比要求更多的权限。用最少的管理费用来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用网络访问分析器来审查公司AWS账户中的所有访问权限。",
      "B": "当IAM用户在AWS账户中创建或修改资源时创建一个云表警报。",
      "C": "使用IAM访问分析器审查公司的所有资源和账户。",
      "D": "使用亚马逊检查员发现现有IAM政策中的漏洞。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM Access Analyzer",
      "AWS Organizations"
    ],
    "explanation": {
      "analysis": "此题考察IAM权限审计。官方答案和社区共识一致，为C。IAM访问分析器是专门用于审核IAM权限的工具，可以快速发现权限过大的用户。",
      "why_correct": "选项C使用IAM访问分析器审查公司的所有资源和帐户。IAM访问分析器是专门用于分析IAM权限的工具，可以帮助发现权限过大的用户，符合最小管理成本和安全要求。",
      "why_wrong": "选项A使用网络访问分析器，侧重于网络安全，不适合IAM权限审计。选项B创建云表警报，仅在资源创建或修改时触发，无法全面审计现有权限。选项D使用亚马逊检查员发现现有政策中的漏洞，检查员无法完全替代IAM访问分析器。"
    },
    "related_terms": [
      "IAM",
      "IAM用户",
      "IAM访问分析器",
      "AWS账户",
      "IAM策略",
      "AWS组织",
      "网络访问分析器",
      "云表",
      "亚马逊检查员"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 925,
    "topic": "",
    "question_cn": "一家公司需要实施一项新的数据保存政策以遵守监管。作为该策略的一部分，存储在亚马逊S3桶中的敏感文档必须在一段固定时间内受到保护不被删除或修改。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "启动S3对象锁定所需对象并启用治理模式。",
      "B": "启动S3对象锁定所需对象并启用依从性模式。",
      "C": "在S3桶上启用版本控制。设置一个生命周期策略以便在指定的时间段后删除对象。",
      "D": "配置一个生命周期策略将对象转换为S3 Glacier的灵活检索以保持停留时间。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Object Lock",
      "Compliance"
    ],
    "explanation": {
      "analysis": "此题考察S3对象锁定。官方答案和社区共识一致，为B。 启用S3对象锁定并使用合规性模式，可以防止对象被删除或修改，满足法规遵从性的需求。",
      "why_correct": "选项B，启用S3对象锁定并设置依从性模式，可以确保对象在指定的时间内无法被删除或覆盖。这满足了法规遵从性，因为对象在设定的保留期内是不可变的。",
      "why_wrong": "选项A启用治理模式，在特定条件下可以绕过保护，不符合法规。选项C使用版本控制和生命周期策略来删除对象，无法保证对象在保留期内不被删除或修改。选项D将对象转换为Glacier，虽然可以存储，但无法保证对象在保留期内不被修改。"
    },
    "related_terms": [
      "S3",
      "S3对象锁定",
      "治理模式",
      "依从性模式",
      "版本控制",
      "生命周期策略",
      "S3 Glacier"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 926,
    "topic": "",
    "question_cn": "一家公司在容器上运行面向客户的Web应用程序。工作负载使用亚马逊弹性集装箱服务（Amazon ECS）在AWS Fargate上。Web应用程序是资源密集型的。Web应用程序需要每周7天、每天24小时为客户提供。该公司预计该应用程序将经历短时间的高流量。工作量必须很大。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "与Fargate配置一个供应商。使用第三方工具进行负载测试。在亚马逊的云表中正确调整Fargate任务。",
      "B": "配置一个具有法尔盖特稳定状态和法尔盖特点为突发交通。",
      "C": "配置一个具有Fargate现场稳定状态和Fargate突发交通能力供应商。",
      "D": "与Fargate配置一个供应商。使用计算优化器来正确调整Fargate任务。"
    },
    "vote_percentage": null,
    "tags": [
      "Fargate",
      "ECS"
    ],
    "explanation": {
      "analysis": "此题考察Fargate的配置。官方答案和社区共识一致，为C。为了满足高流量和弹性需求，配置具有稳定状态和突发能力的Fargate任务。",
      "why_correct": "选项C配置了具有Fargate稳定状态和Fargate突发交通能力。Fargate可以自动扩展以满足流量峰值，并保证Web应用程序的可用性。这是最好的解决方案，可以满足大规模和高可用性的需求。",
      "why_wrong": "选项A 侧重于测试，而不是实际配置。选项B只有突发能力，不能保证稳定运行。选项D同样只是调整，无法满足业务需求。"
    },
    "related_terms": [
      "Amazon ECS",
      "AWS Fargate",
      "Web应用程序",
      "负载测试",
      "Fargate",
      "计算优化器"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 927,
    "topic": "",
    "question_cn": "一家公司正在建立一个应用程序在 AWS云。该应用程序在应用程序负载平衡器后面的Amazon EC2实例中托管。该公司使用Amazon Route 53 DNS 作为DDOS攻击的防护。该公司需要有管理的解决方案积极主动的参与以发现针对DDOS攻击。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置AWS Shield。配置检测攻击的配置管理规则。",
      "B": "创建一个网站提供检测和防止DDOS攻击的规则。将网络与AWS WAF联系起来。",
      "C": "将访问日志存储在一个Amazon S3桶中。配置Amazon Shield Advanced功能以检测和采取针对DDOS攻击的自动预防行动。",
      "D": "订阅AWS Shield Advanced。在Route 53上配置托管区域。添加资源作为受保护资源。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Shield Advanced",
      "Route 53"
    ],
    "explanation": {
      "analysis": "此题考查如何防御DDOS攻击。使用AWS Shield Advanced结合Route 53可以提供增强的防护。",
      "why_correct": "AWS Shield Advanced提供了针对DDOS攻击的增强保护，并且可以与Route 53集成，保护应用程序。",
      "why_wrong": "选项A和B侧重于配置AWS WAF，虽然也有一定的防护作用，但不如Shield Advanced全面。选项C缺少对Route 53的集成。"
    },
    "related_terms": [
      "EC2",
      "应用程序负载平衡器",
      "Amazon Route 53",
      "DDOS攻击",
      "AWS Shield",
      "AWS WAF",
      "Amazon S3",
      "AWS Shield Advanced",
      "Route 53",
      "托管区域"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 928,
    "topic": "",
    "question_cn": "一家公司在VPC中拥有一个视频流媒体应用程序。该公司使用一个网络负载平衡器来处理用于实时数据处理的TCP通信。有人未经授权试图访问该应用程序。该公司希望以最小的架构更改来提高应用程序的安全性以防止未经授权的尝试访问应用程序。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在北草坪会议大楼直接实施一系列的AWS WAF规则以过滤未经授权的流量。",
      "B": "恢复北草坪会议大楼的安全组只允许可信的IP地址。",
      "C": "部署第二个北草坪会议大楼与现有的北草坪会议大楼平行配置有一个严格的IP地址允许列表。",
      "D": "使用AWS Shield Advanced提供增强的保护并防止未经授权的访问尝试。"
    },
    "vote_percentage": null,
    "tags": [
      "Security Groups",
      "Network Load Balancer"
    ],
    "explanation": {
      "analysis": "此题考查如何通过最小的架构更改来提高应用程序的安全性。修改安全组是最直接的方法。",
      "why_correct": "修改安全组是最直接且最不影响现有架构的措施，可以快速限制未经授权的访问。",
      "why_wrong": "选项A涉及AWS WAF，需要更多的配置和管理工作。选项C需要部署额外的资源。选项D涉及AWS Shield Advanced，虽然能提供更全面的保护，但对于最小架构更改来说过于复杂。"
    },
    "related_terms": [
      "VPC",
      "网络负载平衡器",
      "TCP",
      "AWS WAF",
      "IP地址",
      "AWS Shield Advanced"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 929,
    "topic": "",
    "question_cn": "一家医疗保健公司正在开发一个 Lambda 功能，该功能发布关于加密的Amazon Simple Notification Service主题的通知。通知含有受保护的健康信息。SRS主题使用AWS Key Management Service (AWS KMS)客户管理密钥进行加密。公司必须确保该应用程序拥有必要的权限以便安全地将消息发布到SRS主题。哪些步骤组合将满足这些要求（选三）？",
    "options_cn": {
      "A": "为SRS主题创建一个资源策略，该策略允许Lambda函数向主题发布消息。",
      "B": "使用服务器端加密的AWS KMS (SSE-KMS)密钥用于处理SRS主题而不是客户管理的密钥。",
      "C": "为AWS KMS创建加密密钥的资源策略，该加密密钥使用具有必要的权限。",
      "D": "在SRS主题的资源策略中指定Lambda函数的亚马逊资源名称(ARN)。",
      "E": "通过使用Amazon API Gateway资源策略将一个Amazon API Gateway与SRS主题相关联以控制对该主题的访问。",
      "F": "配置具有使用AWS KMS中的客户管理密钥所必需的权限的Lambda执行角色。"
    },
    "vote_percentage": null,
    "tags": [
      "SNS Encryption",
      "KMS",
      "Lambda Permissions"
    ],
    "explanation": {
      "analysis": "此题考察SNS消息加密和Lambda权限。需要确保Lambda有权限发布消息到SNS主题，并使用KMS密钥进行加密。",
      "why_correct": "选项A、D、F 涵盖了Lambda函数向SNS主题发布消息所需的权限，以及加密密钥的设置和Lambda的执行角色配置。选项C是不正确的，应该为KMS密钥创建策略。选项B是错误的，不建议用SSE-KMS,SSE-KMS是对服务端的加密, 不涉及权限的问题。",
      "why_wrong": "选项B、E 无法正确实现目标。B 使用服务器端加密无法满足需求，E使用了API网关，会增加复杂性。"
    },
    "related_terms": [
      "Lambda",
      "Amazon Simple Notification Service",
      "AWS Key Management Service",
      "SRS",
      "SSE-KMS",
      "Amazon API Gateway",
      "Lambda执行角色",
      "亚马逊资源名称"
    ],
    "best_answer": [
      "A",
      "D",
      "F"
    ],
    "official_answer": [
      "A",
      "D",
      "F"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 930,
    "topic": "",
    "question_cn": "公司有员工门户网站。员工登录到门户网站查看工资单细节。该公司正在开发一种新的系统使员工能够上传扫描文件要求报销。该公司运行了一个程序从文档中提取基于文本的数据并将提取的信息附加到每个员工的报销身份证中进行处理。员工门户网站要求100%的正常运行时间。文档提取程序每天都很少按需运行。该公司希望建立一个可扩展的、成本效益高的新系统，该系统只需对现有门户网站进行最低限度的修改。公司不想做任何代码更改。用最少的执行努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在门户网站的自动缩放组中运行Amazon EC2点播实例。使用Lambda函数运行文档提取程序。当员工上传新的报销文档时调用Lambda函数。",
      "B": "在门户网站的自动缩放组中运行Amazon EC2点实例。在点实例上运行文档提取程序。当员工上传新的报销文档时启动文档提取程序实例",
      "C": "购买一个节省计划来运行门户网站和文档提取程序，在一个自动缩放组中运行门户网站和文档提取程序。",
      "D": "创建一个Amazon S3桶来主持门户网站。为现有功能使用Amazon API Gateway和一个Lambda函数。使用Lambda函数运行文档提取程序。当调用与新文档上传相关联的API时，调用Lambda函数。"
    },
    "vote_percentage": null,
    "tags": [
      "EC2 Auto Scaling",
      "Lambda",
      "S3"
    ],
    "explanation": {
      "analysis": "本题考察如何构建一个可扩展、成本效益高且对现有系统影响最小的解决方案。Lambda函数和EC2结合是最好的方案。",
      "why_correct": "选项A 使用 EC2 和 Lambda 满足了按需运行文档提取程序的需求，并且可以与现有门户网站集成。使用点播实例有助于控制成本，Lambda 的serverless特性有助于实现弹性伸缩。",
      "why_wrong": "选项B 使用点实例，如果实例中断，会影响可用性。选项C不涉及文档提取程序的运行，且无法满足按需运行的需求。选项D使用S3托管门户网站，需要进行代码更改，不符合要求。"
    },
    "related_terms": [
      "Amazon EC2",
      "Lambda",
      "Amazon S3",
      "Amazon API Gateway",
      "自动缩放组",
      "点播实例",
      "点实例",
      "节省计划"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 931,
    "topic": "",
    "question_cn": "一家媒体公司在美国东部地区有一个多帐户的AWS环境。该公司在一个发布性能指标的生产账户中有一个Amazon Simple Notification Service(SNS)Amazon主题。该公司在管理员帐户中有一个Lambda函数来处理和分析日志数据。在报告重要度量时，必须由来自生产帐户中的SNS主题的消息调用管理员帐户中的Lambda函数。哪些步骤组合将满足这些要求（选二）？",
    "options_cn": {
      "A": "创建一个IAM资源策略，用于创建允许Amazon SNS调用该函数的Lambda函数。",
      "B": "在管理员帐户中实现Amazon Simple Queue Service(SQS)队列以从生产帐户中的SNS主题中缓冲消息。配置SQS队列以调用Lambda函数。",
      "C": "为SNS主题创建一个IAM策略，该策略允许Lambda函数订阅该主题。",
      "D": "在生产帐户中使用一个Amazon EventBridge规则来捕捉SNS主题通知。将该EventBridge规则配置为将通知转发到管理员帐户中Lambda的Lambda函数。",
      "E": "将性能指标存储在生产帐户中的Amazon S3桶中。使用Amazon Athena从管理员帐户分析指标。"
    },
    "vote_percentage": null,
    "tags": [
      "SNS",
      "Lambda Permissions",
      "EventBridge"
    ],
    "explanation": {
      "analysis": "此题考查如何从其他账户的SNS主题触发Lambda函数。可以使用IAM策略和EventBridge实现。",
      "why_correct": "选项A：创建IAM资源策略允许SNS调用Lambda。选项C：创建SNS主题策略允许Lambda函数订阅。这两个策略都满足了跨账户访问的权限设置。 A 和 C 可以通过 SNS 和 Lambda 的资源策略实现权限。",
      "why_wrong": "选项B 使用 SQS 增加了复杂性，并非必须。 选项D 使用 EventBridge 也可以实现，但是不如AC简洁。 选项E，存储在S3,无法直接触发Lambda函数。"
    },
    "related_terms": [
      "Amazon Simple Notification Service",
      "SNS",
      "Lambda",
      "IAM",
      "Amazon Simple Queue Service",
      "SQS",
      "Amazon EventBridge",
      "Amazon S3",
      "Amazon Athena"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 932,
    "topic": "",
    "question_cn": "一家公司正在将一个应用程序从网站内的位置迁移到Amazon Elastic Kubernetes Service(Amazon EKS)。公司必须使用自定义子网的Pod是在VPC的。公司需要确保这些吊舱能够在Pod的VPC中安全地进行通信。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "配置EKS传输网关直接管理Amazon EKS中的吊舱的定制子网配置。",
      "B": "创建一个从公司内部IP地址范围到EKS吊舱的直接连接。",
      "C": "使用Amazon VPC CNI插件为Kubernetes。定义EKS集群中的自定义子网供扩展器使用。",
      "D": "实施一个Kubernetes网络策略，该策略具有反亲缘性规则以限制Pod的放置到特定的节点中，这些节点是自定义的子网。"
    },
    "vote_percentage": null,
    "tags": [
      "EKS",
      "VPC CNI",
      "Kubernetes Networking"
    ],
    "explanation": {
      "analysis": "此题考察如何在EKS中使用自定义子网。使用VPC CNI是最常见和最佳实践。",
      "why_correct": "使用Amazon VPC CNI插件，可以为 Kubernetes 集群配置自定义子网，并使Pod能够安全地在 VPC 中进行通信，满足了题目的要求。",
      "why_wrong": "选项A 使用了传输网关，不适用于配置EKS吊舱的定制子网。选项B 创建直接连接，不是一个标准的 EKS 解决方案。选项D，Kubernetes网络策略可以限制 Pod 的放置，但这不是最直接的解决方案，而且需要额外的配置。"
    },
    "related_terms": [
      "Amazon Elastic Kubernetes Service",
      "Amazon EKS",
      "VPC",
      "Pod",
      "VPC CNI",
      "Kubernetes",
      "传输网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 933,
    "topic": "",
    "question_cn": "一家公司拥有一个电子商务应用程序，该应用程序将所有数据存储在一个Amazon RDS实例中用于由完全管理的MySQL数据库实例。公司需要降低单一失败点的风险。用最少的执行努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "修改RDS数据库实例以使用多可用区部署。在下一个维护窗口中应用更改。",
      "B": "将当前数据库迁移到一个新的Amazon RDS多可用区部署。使用具有异质迁移策略的AWS Database Migration Service(AWS DMS)将当前的数据库实例迁移到数据库表。",
      "C": "在多可用区部署中创建一个新的RDS数据库实例。从最近的快照中手动还原现有的RDS数据库实例中的数据。",
      "D": "在Amazon EC2自动缩放组中配置具有最小3个组大小的数据库实例。使用Amazon Route 53简单路由分发请求到所有数据库实例。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Multi-AZ",
      "High Availability"
    ],
    "explanation": {
      "analysis": "此题考察如何提高RDS的可用性。使用多可用区部署是最佳实践。",
      "why_correct": "通过将RDS实例配置为多可用区部署，可以在发生故障时自动故障转移到备用实例，从而最大限度地减少停机时间。只需对现有实例进行少量更改，是最简单的解决方案。",
      "why_wrong": "选项B和C都需要创建新的RDS实例或使用DMS，增加了复杂性。选项D涉及使用 EC2 和 Route 53，并不能解决RDS的单点故障问题，而且增加了管理成本。"
    },
    "related_terms": [
      "Amazon RDS",
      "MySQL",
      "多可用区",
      "AWS Database Migration Service",
      "AWS DMS",
      "快照",
      "Amazon EC2",
      "Amazon Route 53"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 934,
    "topic": "",
    "question_cn": "公司拥有多个微软SMB文件服务器和Linux NFS文件服务器，用于在内部环境中共享文件。作为该公司迁移计划的一部分，该公司希望将文件服务器整合到AWS云中。该公司需要一个托管的存储服务支持NFS和SMB访问。解决方案必须能够在协议之间共享。解决方案必须在可用区域级别具有冗余。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用Amazon FSx for Windows File Server进行存储。配置多协议访问。",
      "B": "创建两个Amazon EC2实例。在SMB文件服务器访问中使用一个EC2实例，在NFS文件服务器访问中使用一个实例。",
      "C": "使用Amazon FSx for SMB网络应用于NFS访问。使用Amazon FSx for NFS对SMB访问的光泽。",
      "D": "使用Amazon S3存储。通过Amazon File Gateway访问Amazon S3。"
    },
    "vote_percentage": null,
    "tags": [
      "FSx for Windows File Server",
      "SMB",
      "NFS"
    ],
    "explanation": {
      "analysis": "此题考查如何提供一个同时支持SMB和NFS协议的文件共享服务。FSx for Windows File Server可以满足需求。",
      "why_correct": "Amazon FSx for Windows File Server 能够同时支持 SMB 和 NFS 协议，满足了协议共享的需求，并且在可用区级别具有冗余。",
      "why_wrong": "选项 B 涉及 EC2 实例，增加了管理复杂性，并且无法在协议之间共享。选项 C 无法提供在协议之间共享功能。选项D使用了Amazon S3和File Gateway，不直接支持SMB和NFS协议。"
    },
    "related_terms": [
      "SMB",
      "NFS",
      "Amazon FSx for Windows File Server",
      "Amazon FSx for SMB",
      "Amazon FSx for NFS",
      "Amazon S3",
      "Amazon File Gateway"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 935,
    "topic": "",
    "question_cn": "一个软件公司需要升级一个关键的Web应用程序。该应用程序目前运行在一个Amazon EC2实例，该公司在一个公共子网中主机。实例运行一个MySQL数据库。应用程序的DNS记录发布在Amazon Route 53区域。解决方案架构师必须重新配置应用程序使其具有可伸缩性和高度可用性。解决方案架构师还必须减少MySQL数据库的读延迟。哪些解决方案能够满足这些要求（选二）？",
    "options_cn": {
      "A": "启动第二个 EC2实例在第二个AWS可用区。使用路由故障转移路由策略将流量重定向到第二个EC2实例。",
      "B": "创建和配置一个自动缩放组以在多个可用性区启动私有EC2实例。将实例添加到新应用程序负载平衡器后面的目标组。",
      "C": "将数据库迁移到Amazon Aurora的MySQL集群。在单独的可用性区域中创建主数据库实例和读者数据库实例。",
      "D": "创建并配置一个自动缩放组以在多个可用区启动私有EC2实例。将实例添加到新应用程序负载平衡器后面的目标组。",
      "E": "将数据库迁移到一个具有跨区域读取副本的Amazon Aurora MySQL集群。"
    },
    "vote_percentage": "100%",
    "tags": [
      "EC2 Auto Scaling",
      "Application Load Balancer",
      "Aurora",
      "Read Replicas"
    ],
    "explanation": {
      "analysis": "此题考查如何提高Web应用程序的可伸缩性、可用性和降低数据库读延迟。Aurora和Auto Scaling是关键。",
      "why_correct": "选项D和E：D创建自动缩放组和应用程序负载平衡器，提高应用程序的可伸缩性和可用性。E将MySQL数据库迁移到具有跨区域读取副本的Amazon Aurora MySQL集群，降低读延迟。Aurora读取副本解决读延迟问题，D 解决可用性和伸缩性问题。",
      "why_wrong": "选项A:  第二个 EC2 实例使用故障转移路由策略，只能提高有限的可用性。B: 创建自动伸缩组和负载均衡器，提升可用性，但是不能提升数据库的读性能。 C：将MySQL数据库迁移到Amazon Aurora，但是没有读取副本，数据库的读延迟没有改善。"
    },
    "related_terms": [
      "EC2",
      "MySQL",
      "DNS",
      "Amazon Route 53",
      "Amazon Aurora",
      "跨区域读取副本",
      "应用程序负载平衡器"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 936,
    "topic": "",
    "question_cn": "一家公司运行着成千上万的Lambda函数。该公司需要一个解决方案以安全地存储敏感的信息，所有Lambda函数使用。解决方案还必须管理敏感信息的自动旋转。哪些步骤组合将以最少的操作开销满足这些要求（选二）？",
    "options_cn": {
      "A": "通过使用Lambda@Edge来检索和创建敏感信息创建HTTP安全标题。",
      "B": "创建一个检索敏感信息的Lambda层。",
      "C": "将敏感信息存储在AWS Secrets Manager中。",
      "D": "将敏感信息存储在系统管理器参数存储中。",
      "E": "创建一个消费者使用专用吞吐量来检索敏感信息并创建环境变量。"
    },
    "vote_percentage": null,
    "tags": [
      "Secrets Manager",
      "Parameter Store",
      "Lambda Layers"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地存储和管理 Lambda 函数的敏感信息。AWS Secrets Manager是最佳选择。",
      "why_correct": "选项C 和 D：Secrets Manager 提供了安全存储和自动旋转秘密的功能。系统管理器参数存储也可用于存储敏感信息，并可以与 Lambda 函数集成。",
      "why_wrong": "选项A: 使用Lambda@Edge创建HTTP安全标题，与存储敏感信息无关。选项B: 创建Lambda层可以存储共享代码，但不能实现自动旋转。选项E 使用专用吞吐量，增加了复杂性。"
    },
    "related_terms": [
      "Lambda",
      "AWS Secrets Manager",
      "Lambda@Edge",
      "HTTP",
      "Lambda层",
      "系统管理器参数存储"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 937,
    "topic": "",
    "question_cn": "一个公司有一个内部应用程序在一个自动缩放组中运行在Amazon EC2实例上。对EC2实例进行了优化计算并使用了Amazon Elastic Block Storage (EBS) Amazon EBS卷。该公司希望确定跨EC2实例、自动缩放组和 EBS 卷的成本优化。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "创建一个新的AWS Cost and Usage Report。搜索报告中的EC2实例、自动缩放组和 EBS卷的成本建议。",
      "B": "创建新的Amazon CloudWatch账单提示。检查EC2实例、自动缩放组和 EBS卷的提示状态。",
      "C": "为EC2实例、自动缩放组和EBS卷配置AWS Compute Optimizer。",
      "D": "配置AWS 计算器以计算EC2实例的成本建议。创建一个新的AWS Cost and Usage Report。在报告中搜索自动缩放组和 EBS卷的成本建议。"
    },
    "vote_percentage": null,
    "tags": [
      "Compute Optimizer",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "此题考查如何跨EC2实例、自动缩放组和EBS卷进行成本优化。AWS Compute Optimizer是最佳工具。",
      "why_correct": "AWS Compute Optimizer 能够分析 EC2 实例、自动缩放组和 EBS 卷的使用情况，并提供成本优化建议。",
      "why_wrong": "选项A 使用Cost and Usage Report 可以提供成本信息，但是没有给出明确的成本优化建议。选项B使用CloudWatch账单提示，没有提供成本优化的建议。选项D结合了计算器和Cost and Usage Report,不如Compute Optimizer直接。"
    },
    "related_terms": [
      "EC2",
      "Amazon Elastic Block Storage",
      "EBS",
      "AWS Cost and Usage Report",
      "EC2实例",
      "自动缩放组",
      "EBS卷",
      "AWS Compute Optimizer",
      "AWS 计算器",
      "CloudWatch",
      "账单提示"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 938,
    "topic": "",
    "question_cn": "一家公司正在运行一个跨多个Amazon EC2实例的媒体商店，分布在一个VPC中的多个可用性区域。该公司希望有一个高性能的解决方案，在所有EC2实例之间共享数据，并更愿意将数据保留在VPC中。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "创建一个Amazon S3桶并从每个实例的应用程序调用服务。",
      "B": "创建一个Amazon S3桶并配置所有实例将其作为已安装的卷访问。",
      "C": "配置Amazon Elastic Block Store (EBS) Amazon EBS卷并在所有实例中安装。",
      "D": "配置一个Amazon Elastic File System (EFS) Amazon EFS文件系统并在所有实例中安装它。"
    },
    "vote_percentage": null,
    "tags": [
      "EFS",
      "Shared Storage"
    ],
    "explanation": {
      "analysis": "此题考察如何在多个EC2实例之间共享数据，并且数据保留在VPC中。Amazon EFS是最佳选择。",
      "why_correct": "Amazon EFS 提供了在多个 EC2 实例之间共享数据的解决方案，并且数据保留在 VPC 中，满足了高性能的需求。",
      "why_wrong": "选项A和B：使用 S3 在实例之间共享数据，性能较差，且S3不是一个文件系统，需要额外的处理。选项C：EBS卷只能挂载到一个 EC2 实例，无法在多个实例之间共享数据。"
    },
    "related_terms": [
      "EC2",
      "VPC",
      "Amazon S3",
      "Amazon Elastic Block Store",
      "EBS",
      "Amazon Elastic File System",
      "EFS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 939,
    "topic": "",
    "question_cn": "一个公司使用Amazon RDS作为MySQL实例。为了做好年终处理的准备，该公司添加了一个只读副本以容纳来自该公司报告工具的额外CPU读查询。读取副本的使用率为60%，基本实例的使用率为60%。在年底活动完成后，读取副本的使用率为25%。基本实例的使用率仍然是恒定的。该公司希望正确调整数据库并为未来的增长提供足够的性能。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "删除读取副本，不要更改主实例。",
      "B": "将读取副本调整为较小的实例尺寸，不要对主要实例进行更改。",
      "C": "将读取副本调整为更大的实例尺寸，将主实例调整为更小的实例尺寸。",
      "D": "删除读取副本，将主实例调整为更大实例的大小。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Read Replicas",
      "Database Optimization"
    ],
    "explanation": {
      "analysis": "此题考察如何根据负载变化调整 RDS 数据库。由于只读副本负载降低，调整其大小是正确的选择。",
      "why_correct": "读取副本的负载已经降低，将其调整为较小的实例尺寸，可以降低成本并满足需求。",
      "why_wrong": "选项A: 删除读取副本可能会影响报告工具的性能。选项C: 将主实例调整为更小是错误的，因为它仍然保持负载。选项D: 删除读取副本并调整主实例，不必要地改变了主实例的配置。"
    },
    "related_terms": [
      "Amazon RDS",
      "MySQL",
      "只读副本",
      "CPU",
      "基本实例"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 940,
    "topic": "",
    "question_cn": "一家公司正在将其数据库迁移到Amazon RDS以获取PostgreSQL。该公司正在将其应用程序迁移到Amazon EC2实例。该公司希望为长期工作量优化成本。哪种解决方案能最有效地满足这一要求？",
    "options_cn": {
      "A": "使用Amazon RDS的按需实例来处理PostgreSQL工作负载。购买一个一年的计算储蓄计划在EC2实例没有预先选择。",
      "B": "为Amazon RDS的PostgreSQL工作负载保留了一年期的没有预付选项的采购实例。购买一个为期一年的EC2实例储蓄计划并且没有EC2实例的前期选项。",
      "C": "为Amazon RDS预订一个一年期的实例并为PostgreSQL工作负载提供部分提前选项。购买一个为期一年的EC2实例节约计划并为EC2实例提供部分预付选项。",
      "D": "为Amazon RDS预订一个三年期的实例，所有的前期选项都用于PostgreSQL工作负载。购买一个三年的EC2实例储蓄计划并为EC2实例提供所有的预付选项。"
    },
    "vote_percentage": "100%",
    "tags": [
      "RDS Reserved Instances",
      "EC2 Savings Plans",
      "Cost Optimization"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为D。社区倾向D的原因是，预留实例和储蓄计划搭配三年期更划算。此题考查如何优化RDS和EC2的成本。使用预留实例和节省计划组合可以最大化成本优化。",
      "why_correct": "使用三年期的预留实例和EC2节省计划，并选择所有预付选项，可以最大程度地降低长期成本。",
      "why_wrong": "选项A：使用按需实例，无法最大化节省成本。选项B 和 C: 一年期的预留实例和储蓄计划，虽然可以节省成本，但不如三年期更划算。"
    },
    "related_terms": [
      "Amazon RDS",
      "PostgreSQL",
      "EC2",
      "按需实例",
      "计算储蓄计划",
      "预留实例"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 941,
    "topic": "",
    "question_cn": "一家公司正在使用Amazon Elastic Kubernetes Service集群。该公司必须确保在EKS集群中的服务帐户能够通过使用服务帐户角色(IRSA)安全而细粒度地访问特定的IAM资源。哪些解决方案能够满足这些要求（选二）？",
    "options_cn": {
      "A": "创建一个IAM策略定义所需权限直接将该策略附加到EKS节点的IAM角色。",
      "B": "在EKS集群内实施Kubernetes网络策略以防止服务账户访问特定的服务。",
      "C": "修改EKS集群的IAM角色，使其包括对每个服务帐户的权限。确保 IAM角色和Kubernetes角色之间的一对一映射。",
      "D": "定义一个包含必要权限的IAM角色。用IAM角色的亚马逊资源名称(ARN)注释Kubernetes服务帐户。",
      "E": "在服务帐户的IAM角色和开放式连接身份提供者之间建立信任关系。"
    },
    "vote_percentage": null,
    "tags": [
      "IRSA",
      "IAM Roles",
      "EKS"
    ],
    "explanation": {
      "analysis": "此题考查如何使用IRSA(IAM Roles for Service Accounts)安全地访问IAM资源。IRSA是最佳实践。",
      "why_correct": "选项D和E 提供了 IRSA 的正确配置方法。 选项D: 定义 IAM 角色，用ARN注释Kubernetes服务账户，实现授权。选项E: 在服务帐户的IAM角色和OIDC之间建立信任关系， 建立信任关系。这两个选项都符合 IRSA 的最佳实践。",
      "why_wrong": "选项A: 将 IAM 策略直接附加到 EKS 节点的 IAM 角色，不安全。选项B: Kubernetes网络策略是控制 pod 之间流量的, 不能解决访问 IAM 资源的问题。选项C: 这种方法不正确，也不推荐。创建 IAM 角色应该以服务账号为基础。"
    },
    "related_terms": [
      "EKS",
      "IAM",
      "IRSA",
      "Kubernetes",
      "IAM",
      "ARN",
      "OpenID"
    ],
    "best_answer": [
      "D",
      "E"
    ],
    "official_answer": [
      "D",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 942,
    "topic": "",
    "question_cn": "一家公司定期将机密数据上传到亚马逊S3桶进行分析。公司的安全策略要求对象必须在休息时加密。公司必须每年自动旋转加密密钥。该公司必须能够追踪关键旋转使用美国航空航天系统。公司还必须降低加密密钥的成本？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "(SSE-C) 使用用户提供密钥的服务器端加密",
      "B": "S3 (SSE-3) 使用亚马逊托管密钥的服务器端加密",
      "C": "AWSKMS (SSE-KMS) 使用服务器端加密的密钥",
      "D": "AWSKMS 使用客户管理的密钥的服务器端加密"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 KMS (SSE-KMS) 进行 S3 对象加密，并结合客户管理的密钥实现自动密钥轮换和审计。 答案D满足了需求。",
      "why_correct": "选项 D 提供了使用 KMS (SSE-KMS) 加密，客户管理密钥允许自动轮换，符合安全策略。KMS 也提供了密钥轮换的审计日志。 客户管理密钥可以降低成本，因为您控制密钥的生命周期和轮换。 这是解决问题的最有效解决方案。",
      "why_wrong": "A 选项使用客户提供的密钥 (SSE-C)，不提供密钥轮换功能。B 选项使用 AWS 托管密钥，无法实现密钥轮换。C 选项使用 KMS 加密，但未指定客户管理密钥，因此无法满足自动密钥轮换的需求。"
    },
    "related_terms": [
      "S3",
      "SSE-C",
      "AWS KMS",
      "SSE-KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 943,
    "topic": "",
    "question_cn": "一家公司已经将好几种应用程序迁移到了美国航空信息系统。公司想知道这些应用程序的成本细目。该公司希望收到一份包含这些信息的定期报告。？哪种解决方案能最有效地满足这些要求",
    "options_cn": {
      "A": "aws使用CSV 预算下载过去个月的数据。文件。查找所需信息。",
      "B": "RDS SQL将成本和使用报告加载到亚马逊数据库实例中。运行查询以获取所需信息。",
      "C": "aws用一个费用键和一个应用程序名称的值标记所有的资源。激活成本分配标记。利用成本资源来获得所需的信息。",
      "D": "aws用一个费用键和一个应用程序名称的值标记所有的资源。使用账单和成本管理控制台下载过去个月的账单。查找所需信息。"
    },
    "vote_percentage": null,
    "tags": [
      "Cost Allocation Tags",
      "AWS Cost Explorer"
    ],
    "explanation": {
      "analysis": "核心考点: 使用成本分配标签 (Cost Allocation Tags) 和 AWS Cost Explorer 来追踪和分析应用程序的成本。 答案 C 正确，因为其利用了成本分配标签来细分成本。",
      "why_correct": "C 选项使用成本分配标签来标记资源，然后通过 Cost Explorer  或账单报告来分析成本。 这是 AWS 推荐的做法，简单有效。 成本分配标签是一种有效的方式，可以按应用程序或其他自定义维度来跟踪成本。",
      "why_wrong": "A 选项通过 CSV 下载预算数据，手动操作，不够自动化。B 选项将成本报告加载到 RDS 实例，增加了运维复杂性，且查询数据效率低。D 选项使用账单和成本管理控制台下载过去几个月的账单，没有使用成本分配标签，不方便分析。"
    },
    "related_terms": [
      "CSV",
      "RDS",
      "AWS",
      "AWS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 944,
    "topic": "",
    "question_cn": "一家电子商务公司正准备在AWS上部署一个网络应用程序以确保为客户提供持续的服务。该体系结构包括该公司在Amazon EC2实例上 Web 应用程序、亚马逊RDS中的关系数据库以及该公司在亚马逊S3上存储的静态资产。该公司希望为该应用程序设计一个健壮且有弹性的架构。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "EC2 RDS S3 在一个可用性区域中部署亚马逊实例。在同一可用性区域部署数据库实例。使用具有版本控制功能的亚马逊存储静态资产。",
      "B": "EC2 AZRDS 在多个可用性区的自动缩放组中部署亚马逊实例。部署一个多数据库实例。使用亚马逊云前分配静态资产。",
      "C": "EC2 AZ RDS EC2 在一个可用性区域中部署亚马逊实例。为交叉冗余在第二可用性区部署数据库实例。直接从实例服务静态资产。",
      "D": "使用Lambda函数为应用程序服务。在数据库中使用亚马逊极光无服务器。在亚马逊弹性文件系统 亚马逊 中存储静态资产一个不常见的区域访问一个区域。"
    },
    "vote_percentage": null,
    "tags": [
      "High Availability",
      "Multi-AZ Deployment"
    ],
    "explanation": {
      "analysis": "核心考点: 构建高可用性的Web应用程序，使用多可用区部署和自动伸缩组。答案B正确",
      "why_correct": "B 选项在多个可用区部署 EC2 实例（自动伸缩组）和数据库实例（多 AZ RDS），实现高可用性。 使用CloudFront加速静态内容分发,提升性能和可用性。",
      "why_wrong": "A 选项仅在一个可用区部署，不具备高可用性。C 选项中在第二个可用区部署数据库实例，但 Web 应用和数据库之间的跨区域访问会导致延迟增加。D 选项使用了 Lambda 和 Aurora 无服务器，但 EFS的部署方式不合理，并且涉及多个技术，实现复杂性较高。 此外, 静态资产存储在EFS，EFS不适合存储静态资源。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "S3",
      "AZ",
      "Lambda",
      "Aurora Serverless",
      "EFS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 945,
    "topic": "",
    "question_cn": "一家电子商务公司在多个账户中运行几个内部应用程序。该公司利用美国职业介绍所的组织管理其美国职业介绍所的帐户。该公司网络账户中的安全设备必须检查帐户中应用程序之间的交互。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在网络帐户中部署一个网络负载平衡器 将流量发送到安全设备。配置应用程序帐户通过在应用程序帐户中 使用接口提供端点将流量发送到 。",
      "B": "在应用帐户中部署应用程序负载平衡器将流量直接发送到安全设备。",
      "C": "在网络帐户中部署网关负载平衡器将流量发送到安全设备。通过在应用程序帐户中使用一个接口配置应用程序帐户将 GW 流量发送到 局。",
      "D": "在应用程序帐户中部署接口端点将流量直接发送到安全设备。"
    },
    "vote_percentage": null,
    "tags": [
      "VPC",
      "Gateway Load Balancer"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 Gateway Load Balancer (GWLB) 和 VPC 接口端点，实现跨账户的网络流量检查。 答案 C 正确。 注意: 此题官方答案为 D，但社区共识(投票最高)为C。社区倾向C的原因是 GWLB 更加灵活和安全，提供了流量检查的能力。",
      "why_correct": "C 选项在网络账户中使用 GWLB 将流量发送到安全设备，提供了更强的安全性和灵活性。通过接口端点，应用程序账户中的应用程序可以将流量路由到 GWLB，确保流量经过安全设备检查。 GWLB 能够将流量发送到多个安全设备，以实现高可用性和扩展性。",
      "why_wrong": "A 选项使用网络负载均衡器，这并非最佳方案，且接口方式不明确。B 选项应用程序负载均衡器不适合检查跨账户流量。 D 选项使用接口端点，缺少安全设备，不能满足流量检查的需求。"
    },
    "related_terms": [
      "网络负载均衡器",
      "VPC",
      "接口端点",
      "网关负载均衡器",
      "GW",
      "接口端点"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 946,
    "topic": "",
    "question_cn": "一家公司在一个包含六个极光复制品的亚马逊奥罗拉集群上运行其生产工作量。该公司希望其一个部门的近实时报告查询能够自动分布在三个极光复制品上。这三个副本有一个不同的计算和内存规格与其他的数据库集群。？哪种解决方案符合这些要求",
    "options_cn": {
      "A": "为工作负载创建并使用自定义端点",
      "B": "创建一个三个节点集群克隆并使用读者端点",
      "C": "为选定的三个节点使用任何实例端点",
      "D": "使用读者端点自动分发只读工作负载"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon Aurora",
      "Custom Endpoints"
    ],
    "explanation": {
      "analysis": "核心考点: Aurora 自定义端点（Custom Endpoints）允许将特定工作负载定向到具有特定配置的副本。答案 A 正确。",
      "why_correct": "A 选项允许创建自定义端点，可以配置这些端点指向具有不同计算和内存规格的 Aurora 副本，满足了将特定工作负载定向到特定副本的需求。",
      "why_wrong": "B 选项复制整个集群，资源消耗较大，且无法满足指定特定实例的要求。C 选项使用实例端点，无法控制工作负载的路由。D 选项使用只读端点，无法满足自定义需求。"
    },
    "related_terms": [
      "Aurora",
      "读者端点"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 947,
    "topic": "",
    "question_cn": "一家公司在其内部数据中心的服务器上运行节点功能。数据中心将数据存储在一个后数据库中。公司在服务器上的环境变量中存储连接字符串中的凭证。该公司希望将其应用程序迁移到AWS并将诺德应用程序服务器替换为Lambda。该公司还希望迁移RDS到亚马逊以获取后并且确保数据库凭证得到安全的管理。？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "在系统管理器参数存储中将数据库凭据作为参数存储配置参数存储以每 天自动旋转一次秘密。从参数中检索凭证",
      "B": "将数据库凭证作为一个秘密存储在美国信息系统保密管理器中。将机密管理器配置为每 天自动旋转证书。更新 函数 以从秘密中检索凭证。",
      "C": "将数据库凭证存储为加密的 环境变量。编写一个自定义的兰布达函数来旋转凭证。安排每 天运行一次兰布达功能。",
      "D": "将数据库凭据存储为密钥管理服务中的一个键。为键配置自动旋转。从 键中重新获取凭证。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Secrets Manager",
      "Lambda",
      "RDS"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 AWS Secrets Manager 存储和管理数据库凭证，并利用其自动轮换功能。答案 B 正确。",
      "why_correct": "B 选项使用 AWS Secrets Manager 存储数据库凭证，提供了安全性和自动轮换功能。Lambda 函数可以从 Secrets Manager 中检索凭证，减少了手动维护的开销。这是 AWS 推荐的最佳实践，能够安全、高效地管理凭证。",
      "why_wrong": "A 选项使用 Systems Manager Parameter Store 存储凭证，不具备自动轮换功能。C 选项使用加密的环境变量，需要编写自定义轮换逻辑，增加了复杂性。D 选项使用 KMS 存储凭证，KMS 本身不适合存储数据库凭证，并且需要更多的配置才能实现。"
    },
    "related_terms": [
      "Lambda",
      "RDS",
      "参数存储",
      "秘密管理器",
      "KMS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 948,
    "topic": "",
    "question_cn": "一家公司希望复制现有的和正在进行的数据变化从内部的甲骨文数据库到亚马逊RDS的甲骨文。每天复制的数据量各不相同。该公司希望使用数据库迁移服务进行数据复制。解决方案必须只分配复制实例所需的容量。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "用多部署配置复制实例以跨多个可用性区提供实例。",
      "B": "创建一个 无服务器复制任务以分析和复制数据同时提供所需的容量。",
      "C": "使用亚马逊自动缩放以根据数据量大小大小的复制实例大小上下。",
      "D": "通过使用亚马逊弹性容器服务提供 法盖特发射类型的复制能力分析和复制数据同时提供所需的容量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "AWS DMS",
      "Serverless"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 DMS 无服务器复制任务，根据数据量自动伸缩，实现按需分配容量。 答案 B 正确。",
      "why_correct": "B 选项使用 DMS 无服务器复制任务，DMS 会自动管理复制实例的容量，无需手动配置，能满足按需分配容量的要求。",
      "why_wrong": "A 选项采用多AZ部署，虽然提高了可用性，但无法实现容量的自动伸缩。C 选项使用自动缩放，增加了复杂性，不便于管理。D 选项采用 ECS Fargate，引入了额外的复杂度，不适用 DMS 复制任务。"
    },
    "related_terms": [
      "RDS",
      "DMS",
      "Auto Scaling",
      "Serverless",
      "Fargate"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 949,
    "topic": "",
    "question_cn": "一个公司有一个多层网络应用程序。应用程序的内部服务组件部署在亚马逊EC2实例上。内部服务组件需要访问作为服务，API的第三方软件这些 SaaS是在上托管的。该公司需要提供从应用程序的内部服务到第三方SaaS应用程序的安全和私人连接。该公司需要确保最小限度的公共互联网曝光。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "实现一个与第三方提供者的安全连接。",
      "B": "部署 传输网关来管理和路由应用程序的和第三方提供者之间的流量。",
      "C": "配置 私人链接只允许来自的出站流量而不允许第三方提供商建立。",
      "D": "使用 私人链接创建应用程序的 和第三方提供者之间的私有连接。"
    },
    "vote_percentage": "100%",
    "tags": [
      "PrivateLink",
      "VPC"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 AWS PrivateLink 为 EC2 上的应用程序提供与第三方 SaaS 应用程序之间的私有连接。 答案 D 正确",
      "why_correct": "D 选项使用 PrivateLink 实现了应用程序和第三方 SaaS 之间的私有连接，确保流量不经过公网，安全性更高。 PrivateLink 提供了私密、安全且无需暴露应用程序到公网的连接方式。",
      "why_wrong": "A 选项依赖于第三方，无法保证安全性。 B 选项使用传输网关，增加了复杂性。 C 选项 PrivateLink 的方向描述不正确，无法实现私密连接。"
    },
    "related_terms": [
      "VPC",
      "SaaS",
      "私有链接",
      "传输网关",
      "私有链接"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 950,
    "topic": "",
    "question_cn": "解决方案架构师需要连接公司的企业网络到其VPC 以允许在现场访问其资源。解决方案必须在网络层和会话层提供企业网络和VPC之间的所有通信的加密。该解决方案还必须提供安全控制以防止美国广播公司和内部系统之间的无限制访问。？哪种解决方案符合这些要求",
    "options_cn": {
      "A": "配置 直接连接到 。配置路由表以允许和拒绝在之间和在所需的场所之间的流量。",
      "B": "创建一个 策略只允许从一组定义的企业 地址访问管理控制台。通过使用 策略和角色限制基于工作责任的用户访问。",
      "C": "配置 站点到站点的以连接到配置路由表条目将从内部的流量导向到 配置实例安全组和网络 只允许来自内部的所需流量。",
      "D": "配置 传输网关连接到 。配置路由表条目以将从内部的流量导向。配置实例安全组和网络只允许来自内部的所需流量。"
    },
    "vote_percentage": "100%",
    "tags": [
      "Site-to-Site VPN",
      "VPC",
      "Security Groups"
    ],
    "explanation": {
      "analysis": "核心考点: 使用站点到站点 VPN (Site-to-Site VPN) 实现企业网络到 VPC 的安全连接，并且配置安全组和网络ACL进行访问控制。 答案 C 正确。 注意: 此题官方答案为 D，但社区共识(投票最高)为C。社区倾向C的原因是，题目描述更符合Site-to-Site VPN而非TGW",
      "why_correct": "C 选项配置站点到站点的 VPN，在网络层提供加密。配置路由表、安全组和 NACL 提供了安全控制，可以限制企业网络和 VPC 之间的访问。",
      "why_wrong": "A 选项配置直接连接，没有提供加密。B 选项重点在于 IAM 控制台访问权限，与题目要求不符。D 选项使用传输网关连接，虽然能实现连接，但是没有说明安全组配置。"
    },
    "related_terms": [
      "Direct Connect",
      "VPC",
      "IAM",
      "Direct Connect",
      "Transit Gateway",
      "VPC",
      "Direct Connect",
      "Transit Gateway",
      "VPC"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 951,
    "topic": "",
    "question_cn": "一个公司有一个带有嵌入式凭证的定制应用程序它可以从亚马逊RDS中的数据库中为 集群检索信息。公司需要以最小的编程 RDS mysql 努力使应用程序更加安全。该公司已经在上为应用程序用户为数据库创建了凭证。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将证书保存在密钥管理服务中。用创建键。配置应用程序以从加载数据库凭据。启用自动旋转键",
      "B": "将凭证存储在加密的本地存储中。配置应用程序从本地存储中加载数据库凭据。建立一个全权证书轮换时间表创建一个克里 欧工作。",
      "C": "把证书存放在美国情报局的秘密经理。配置应用程序从秘密管理器加载数据库凭据。建立一个全权证书轮换时间表创建一个 为机密管理员的函数。",
      "D": "将凭证存储在系统管理器参数存储中将应用程序配置为从参数存储加载数据库凭据 通过使用参数存储在数据库RDS中的中设置全权证书旋转时间表。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Secrets Manager",
      "RDS"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 Secrets Manager 存储和管理数据库凭据，并结合其自动轮换功能。答案 C 正确",
      "why_correct": "C 选项使用 AWS Secrets Manager 存储数据库凭据，可以实现安全存储和自动轮换功能，降低了维护开销。 Lambda 函数可以自动轮换证书。 这是 AWS 推荐的最佳实践，能够安全、高效地管理凭证。",
      "why_wrong": "A 选项使用 KMS 存储凭证，不适合存储数据库凭证，实现复杂。B 选项将凭证存储在加密的本地存储，增加了运维复杂度，并且没有自动轮换功能。 D 选项使用 SSM Parameter Store 存储凭证，无法提供自动轮换功能。"
    },
    "related_terms": [
      "RDS",
      "KMS",
      "IAM",
      "秘密管理器",
      "RDS",
      "参数存储",
      "RDS",
      "RDS"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 952,
    "topic": "",
    "question_cn": "一家公司希望将其应用转移到无服务解决方案。无服务器解决方案需要使用SQL分析现有数据和新数据。该公司将数据存储在一个S3亚马逊桶中。数据必须在休息时加密并复制到不同的区域。？用最少的操作开销来满足这些需求的解决方案是什么",
    "options_cn": {
      "A": "创建一个新的桶该桶使用多区域密钥进行服务器端加密。配置跨区域复制。将数据加载到新的桶中。使用亚马逊雅典娜查询数据。",
      "B": "创建一个新的桶使用亚马逊托管密钥的服务器端加密。配置跨区域复制。将数据加载到新的桶中。使用亚RDS马逊查询数据。",
      "C": "在现有的桶上配置跨区域复制。使用亚马逊托管密钥的服务器端加密。使用亚马逊雅典娜查询数据。",
      "D": "在现有的桶上配置跨区域复制。使用服务器端加密与多区域密钥。使用亚马逊查询数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "S3 Cross-Region Replication",
      "Amazon Athena"
    ],
    "explanation": {
      "analysis": "核心考点:  在 S3 中配置加密和跨区域复制，并使用 Athena 进行无服务器数据分析。 答案 A 正确。",
      "why_correct": "A 选项使用多区域密钥 (用于跨区域复制,CRR), 实现了加密和跨区域复制，并且使用 Athena 进行数据分析，符合题目要求。 Athena 是一个无服务器查询服务，可以直接查询 S3 数据。",
      "why_wrong": "B 选项使用 AWS 托管密钥，不方便管理，并且需要新建桶。 C 选项使用 AWS 托管密钥，并且缺少S3跨区域复制。 D 选项使用多区域密钥，但是缺少 S3 跨区域复制。"
    },
    "related_terms": [
      "S3",
      "Athena",
      "SSE-C",
      "Multi-Region keys",
      "KMS",
      "跨区域复制",
      "跨区域复制",
      "Athena",
      "雅典娜"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 953,
    "topic": "",
    "question_cn": "一家公司有一个有成千上万用户的网络应用程序。应用程序使用6个用户上传的图像生成 AI 图像。用户可以每8-10个小时下载一次人 AI工智能图片。该公司还有一个高级用户选项使用户能够随时下载生成的AI图像。该公司使用用户上传的图像运行人工智能模型培训每年两次。公司需要一个存储方案来存储图像？哪种存储方案最符合这些要求",
    "options_cn": {
      "A": "移动上传到亚马逊冰川深度档案。将高级用户生成的人工智能图像移动到标准。将非优质用户生成的人工智能图像移至S3 (S3 -Ia) 标准 标准 。",
      "B": "将上传到亚马逊冰川深度档案的图像移到冰川的灵活检索。",
      "C": "将上传到亚马逊 的图片移动到一个不常见的区域的一个区域。将高级用户生成的人工智能图像移动到标准。将非优质用户生成的人工智能图像移至S3 (S3 -Ia) 标准 标准 。",
      "D": "将上传到亚马逊的图片移动到一个不常见的区域的一个区域。移动所有生成的人工智能图像到 冰川灵活检索。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Storage Classes",
      "Lifecycle Policies"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 S3 存储类别和生命周期策略来优化存储成本。 答案 A 正确。",
      "why_correct": "A 选项 将上传的图像存储在 S3 标准存储类。对于AI图像，高级用户生成的图像移动到 S3 标准存储类，非优质用户生成的图像移至 S3 IA（不频繁访问） 存储类。生命周期策略可以自动管理存储类的转换。对于不经常访问的数据（每年两次），可以归档到 Glacier Deep Archive。",
      "why_wrong": "B 选项将所有图像移到 Glacier Deep Archive，检索成本高，不适合需要频繁访问的图像。 C 选项将上传的图像移动到 S3 不频繁访问存储类，不适用于高级用户。 D 选项将上传的图像移动到 S3 不频繁访问存储类，并且移动所有生成的AI图像到 Glacier Flexible Retrieval，成本较高，不适合经常访问的AI图像。"
    },
    "related_terms": [
      "S3",
      "Glacier Deep Archive",
      "S3-IA",
      "Glacier Flexible Retrieval",
      "S3-IA",
      "Glacier Flexible Retrieval"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 954,
    "topic": "",
    "question_cn": "一家公司正在开发机器学习模型。该公司正在开发作为独立微型服务的模型。微服务在启动时从亚马逊S3获取大约1GB的模型数据并将数据加载到内存中。用户通过异步API访问ML模型。用户可以发送请求或批请求。该公司向数百名用户提供了ML模型。模型的使用模式不规则，有些模型已经有几天或几周不用了。其他的模型一次收到成千上万的请 求。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "将API的请求引导到网络负载平衡器。将模型部署为的功能北草坪会议大楼将调用这些功能。根据北草坪会议大楼接收到的流量使用自动缩放来扩展兰姆达功能。",
      "B": "将API的请求引导到应用程序负载平衡器。将模型部署为将调用的亚马逊弹性容器服务。使用自动缩放来根据接收到的通信量来扩展集群实例。",
      "C": "将来自的请求引导到一个亚马逊简单队列服务队列中。将模型作为拉姆达函数来部署而该函数将由事件调用。 LMAB VCPS 使用自动缩放来增加基于小规模服务协议队列大小的 函数的数量。",
      "D": "将来自的请求引导到一个亚马逊简单队列服务队列中。将模型部署为从队列中读取的亚马逊弹性容器服务。使用自，动缩放的亚马逊系统以规模为基础的集群容量和服务的数量。"
    },
    "vote_percentage": null,
    "tags": [
      "SQS",
      "ECS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 SQS 将 API 请求排队，并使用 ECS 和 Auto Scaling 处理请求，实现异步处理和弹性伸缩。 答案 D 正确",
      "why_correct": "D 选项使用 SQS 将 API 请求排队，解耦了请求的接收和处理。使用 ECS 部署模型作为容器，并使用自动伸缩来根据队列中的消息数量进行伸缩，符合异步处理和弹性伸缩的需求。这种方式能有效地处理不规则的流量，并降低成本。",
      "why_wrong": "A 选项使用 NLB 引导流量，不能提供异步处理和弹性伸缩。B 选项使用 ALB，也不提供异步处理。C 选项使用 SQS 和 Lambda，但是性能和成本并不占优势。"
    },
    "related_terms": [
      "API Gateway",
      "Lambda",
      "EC2",
      "Auto Scaling",
      "Simple Queue Service",
      "Lambda",
      "Auto Scaling",
      "Simple Queue Service",
      "EC2",
      "Auto Scaling"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 955,
    "topic": "",
    "question_cn": "一个公司在亚马逊EC2实例上运行一个Web应用程序在应用程序负载平衡器后面的一个自动缩放组中。应用程序将数据存储在亚马逊奥罗拉集群中。该公司需要创建一个灾难恢复解决方案。博士溶液的可接受恢复时间最多为30分钟。当主要的基础设施是健康的时解决方案不 需要支持客户使用。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "在第二个区域部署具有和自动缩放组的基础设施。将自动缩放组的期望容量和最大容量设置为最小值。将奥罗拉的 集群转换为奥罗拉全球数据库。配置亚马逊线路 用于具有端点的主动无源故障转移。",
      "B": "在第二个区域部署基础设施并更新自动缩放组以包括第二个区域的实例。使用亚马逊路由配置活动主动故障转。将奥罗拉的集群转换为奥罗拉全球数据库。",
      "C": "通过使用 备份备份奥罗拉集群数据。在第二个区域中部署基础设施。更新自动缩放组以包含来自第二区域EC2的 实例。使用亚马逊路由配置活动主动故障转移。在第二个区域创建一个数据库集群从备份中恢复数据。",
      "D": "使用备份来备份基础设施配置。使用备份在第二个区域创建所需的基础设施。设置自动缩放组所需容量为零使用亚马逊号路由来配置主动被动故障转移。将奥罗拉的集群转换为奥罗拉全球数据库。"
    },
    "vote_percentage": null,
    "tags": [
      "Multi-region deployment",
      "Aurora Global Database",
      "Route 53"
    ],
    "explanation": {
      "analysis": "核心考点: 使用 Aurora Global Database 实现跨区域的灾难恢复，并结合Route 53 实现 DNS 故障转移，达到RTO小于30分钟的目标。 答案 A 正确。",
      "why_correct": "A 选项在第二个区域部署了基础设施，并且将 Aurora 数据库配置为 Aurora Global Database，实现了快速的数据库故障转移。将自动缩放组的期望容量设置为 0，可以节省成本。使用 Route 53 配置故障转移，实现 DNS 级别的故障转移。 结合这些技术，RTO能满足要求。",
      "why_wrong": "B 选项将 aurora 集群转换为Aurora Global Database,但是没有在主区域构建Web应用程序，不满足高可用需求。C 选项依赖于备份和恢复，无法达到30分钟 RTO 的要求。 D 选项没有在主区域构建Web应用程序,而且依赖备份，不满足RTO的要求。"
    },
    "related_terms": [
      "EC2",
      "Application Load Balancer",
      "Auto Scaling",
      "Aurora",
      "RDS",
      "DR",
      "Aurora Global Database",
      "Route 53",
      "备份",
      "EC2",
      "Route 53",
      "Aurora Global Database",
      "备份",
      "DR",
      "Route 53",
      "Aurora Global Database"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 956,
    "topic": "",
    "question_cn": "一家公司正在将其数据处理应用程序迁移到 云。应用程序处理几个不能中断的短期批量作业。在每个批处理作业完成后生成数据。这些数据可访问30天保留2年。该公司希望尽可能降低在云中运行应用程序的成本。？哪种解决方案能满足这些要求",
    "options_cn": {
      "A": "迁移数据处理应用到亚马逊点实例。数据存储在亚马逊标准。立即将数据转移到亚马逊冰川。三十天后恢复。设置过期删除 年后的数据。",
      "B": "将数据处理应用程序迁移到亚马逊 随需应变的实例。数据存储在亚马逊冰川即时检索。天后将数据移到冰川深度档案馆。设置过期删除年后的数据。",
      "C": "部署亚马逊 点实例运行批处理作业。数据存储在亚马逊标准。天后将数据转移到亚马逊冰川的灵活检索。设置过期删除 年后的数据。",
      "D": "部署亚马逊 按需实例运行批处理任务。数据存储在亚马逊标准。天后将数据移至亚马逊冰川深度档案库。设置过期删除年后的数据。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Storage Classes",
      "Spot Instances",
      "Lifecycle Policies"
    ],
    "explanation": {
      "analysis": "核心考点:  使用 Spot 实例运行批处理作业，并使用 S3 存储类别和生命周期策略来优化存储成本。 答案 C 正确",
      "why_correct": "C 选项使用 Spot 实例运行批处理作业，可以最大程度地降低计算成本。将数据存储在 S3 标准存储类中。30天后，数据转换为 Glacier Flexible Retrieval。生命周期策略可以自动管理存储类的转换。对于不经常访问的数据（2年后），可以删除。",
      "why_wrong": "A 选项使用Spot实例，但是数据立即转移到冰川，会增加检索成本。B 选项使用按需实例，增加了计算成本。 此外，B 使用 Glacier Instant Retrieval，数据检索成本高。 D 选项使用按需实例，并且 使用 Glacier Deep Archive，检索成本高。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "Glacier",
      "S3",
      "Glacier Deep Archive",
      "EC2",
      "Glacier",
      "Glacier Deep Archive"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 957,
    "topic": "",
    "question_cn": "一个公司需要设计一个混合网络架构。该公司的工作量目前存储在云和内部数据中心。工作负载需要个位延迟才能进行通信。该公司使用了一个美国交通系统中转网关过境网关连接多个VPC。哪些步骤组合将最符合这些要求？选二。",
    "options_cn": {
      "A": "在每个VPC上建立一个站点到站点的VPN连接。",
      "B": "联系一个直接连接网关与连接到的过境网关。",
      "C": "建立一个站点到站点的VPN连接到直接连接网关。",
      "D": "建立一个直接连接连接。创建一个直接连接网关的传输虚拟接口。",
      "E": "VPCs连接的站点现场连接到连接到的过境网关。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Direct Connect",
      "Transit Gateway"
    ],
    "explanation": {
      "analysis": "核心考点是混合云架构的设计，需要考虑低延迟和VPC互联。答案BD提供了通过Direct Connect和Transit Gateway实现混合云连接的方案。",
      "why_correct": "选项B和D结合使用 Direct Connect 和 Transit Gateway，可以提供低延迟的连接，满足题干对混合云和个位数延迟的要求。",
      "why_wrong": "选项A使用站点到站点 VPN，相比 Direct Connect 延迟更高。选项C的连接方式不完整。选项E描述不清，不符合题意。"
    },
    "related_terms": [
      "VPN",
      "Direct Connect",
      "Transit Gateway",
      "Direct Connect"
    ],
    "best_answer": [
      "B",
      "D"
    ],
    "official_answer": [
      "B",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 958,
    "topic": "",
    "question_cn": "一家全球性的电子商务公司在RDS上运行其重要的工作量。工作负载使用亚马逊RDS来处理为多AZ部署而配置的后备实例。客户在公司经历数据库故障时报告了应用程序超时。公司需要一个弹性解决方案来减少故障转移时间。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个亚马逊RDS代理。将代理分配给实例。",
      "B": "为实例创建一个读副本。将读流量移动到读副本。",
      "C": "监控CPU负载以识别超时。",
      "D": "采取常规的自动快照。将自动快照复制到多个区域。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon RDS Proxy",
      "RDS High Availability"
    ],
    "explanation": {
      "analysis": "核心考点是 RDS 的高可用性和减少故障转移时间。答案A是使用RDS代理，可以自动处理数据库故障转移。",
      "why_correct": "选项A 使用 RDS 代理，可以缓存数据库连接，提高数据库连接效率，并在数据库故障时自动切换到备用实例，减少故障转移时间。",
      "why_wrong": "选项B 创建读副本，主要用于提升读取性能，不能直接减少故障转移时间。选项C只是监控，无法解决故障转移问题。选项D是数据备份策略，不是快速故障转移的方案。"
    },
    "related_terms": [
      "RDS",
      "Multi-AZ",
      "RDS Proxy",
      "Read Replica",
      "CPU",
      "快照"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 959,
    "topic": "",
    "question_cn": "一个公司有多个亚马逊RDS数据库实例运行在一个开发账户。所有的实例都有标记来标识它们是开发资源。公司只需要在工作时间内按计划运行开发数据库实例。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个亚马逊云表警报以识别需要停止的实例。创建一个Lambda函数来启动和停止实例。",
      "B": "创建一个信任的顾问报告来识别要启动和停止的实例。创建一个Lambda函数来启动和停止实例。",
      "C": "创建系统管理器国家管理器协会以启动和停止实例。",
      "D": "创建一个亚马逊事件桥规则调用Lambda函数来启动和停止实例。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon EventBridge",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点是自动化 RDS 数据库实例的启停。答案D 使用 EventBridge 触发 Lambda 函数，是最简洁、自动化的方式。",
      "why_correct": "选项D 使用 EventBridge 结合 Lambda，可以实现数据库实例的定时启停，自动化程度高，操作开销小，并且通过标签进行资源标识，可以更灵活地控制。",
      "why_wrong": "选项A 需要配置 CloudWatch 告警，过于复杂。选项B 使用 Trusted Advisor 报告，不适用于自动操作。选项C 使用 Systems Manager State Manager，虽然可以实现，但是没有 EventBridge 方便。"
    },
    "related_terms": [
      "CloudWatch",
      "Lambda",
      "顾问",
      "Lambda",
      "系统管理器",
      "事件桥",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 960,
    "topic": "",
    "question_cn": "一家消费者调查公司已经从一个特定的地理区域收集了数年的数据。该公司将这些数据存储在一个亚马逊S3桶中的区域。该公司已开始在一个新的地理区域与一家营销公司分享这一数据。该公司已经批准了该公司的账户进入S3桶。当市场营销公司从S3桶中索取数据时，公司希望最大限度地降低数据传输成本。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在公司的S3桶上配置请求者支付的功能。",
      "B": "配置S3跨区域复制(CRR)从公司的S3桶到销售公司的S3桶。",
      "C": "配置AWS资源访问管理器与营销公司账户共享桶。",
      "D": "配置公司的S3桶使用智能层同步桶到营销公司的S3桶。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Cross-Region Replication",
      "S3 Requestor Pays"
    ],
    "explanation": {
      "analysis": "核心考点是优化S3的数据传输成本。答案B使用了跨区域复制，将数据复制到目标区域，降低了营销公司的数据访问成本。",
      "why_correct": "选项B 使用 S3 跨区域复制(CRR)，将数据复制到营销公司所在的区域，降低了营销公司读取数据的成本，并且复制之后营销公司就可以直接访问数据，不需要再从源桶读取。",
      "why_wrong": "选项A 配置请求者付费，由请求者承担数据传输费用，不是降低总体的成本。选项C 使用 RAM 共享桶，可以共享桶，但是数据还是在源桶中。选项D 使用 S3 智能分层，适用于存储成本优化，不是针对传输成本优化。"
    },
    "related_terms": [
      "S3",
      "请求者付费",
      "CRR",
      "AWS RAM",
      "S3",
      "智能层"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 961,
    "topic": "",
    "question_cn": "一家公司利用美国世界贸易协会主持其公开的电子商务网站。该网站使用了一个美国世界服务社全球加速器从互联网流量。全局加速器将流量转发给一个应用负载均衡器，这是一个自动缩放组的切入点。该公司最近在网站上发现了一起DDoS攻击事件。公司需要一个解决方案来缓解未来的攻击。用最少的执行努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用基于费率的规则为全球加速器加速器配置一个AWS WAF的网络，以阻止流量。",
      "B": "通过更新网络ACL配置Lambda函数来读取指标来阻止攻击",
      "C": "利用基于费率的规则在AWS WAF上配置一个ALB来阻止流量",
      "D": "在全球加速器加速器前配置亚马逊云端分布"
    },
    "vote_percentage": null,
    "tags": [
      "AWS WAF",
      "Global Accelerator"
    ],
    "explanation": {
      "analysis": "核心考点是保护网站免受 DDoS 攻击，并且考虑最少的执行工作。答案A 是在Global Accelerator中配置AWS WAF，直接拦截恶意流量。",
      "why_correct": "选项A 在 Global Accelerator 上配置 AWS WAF，可以利用 WAF 的规则（包括基于速率的规则）来阻止恶意流量，有效地减轻 DDoS 攻击，而且部署简单。",
      "why_wrong": "选项B 使用 ACL 和 Lambda 函数，实现复杂，配置工作量大，响应不够及时。选项C 虽然使用了 WAF，但 WAF 保护的是 ALB，而不是 Global Accelerator。 选项 D 配置 CloudFront，CloudFront 主要用于内容分发和缓存，不能直接缓解 DDoS 攻击。"
    },
    "related_terms": [
      "AWS WAF",
      "Global Accelerator",
      "DDoS",
      "ALB",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 962,
    "topic": "",
    "question_cn": "一个公司使用亚马逊 DynamoDB 表来存储公司从设备接收到的数据。DynamoDB支持面向客户的网站以显示客户设备上的最新活动。该公司将表配置为写入和读取提供的吞吐量。该公司希望每天计算客户设备数据的性能指标。解决方案必须对表中已提供的读写容量产生最小的影响。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊 Athena查询与亚马逊 Athena DynamoDB连接器计算性能指标的一个经常性的计划。",
      "B": "使用 Glue 工作与 Glue DynamoDB导出连接器计算性能指标的一个经常性的计划。",
      "C": "使用亚马逊 Redshift复制命令计算性能指标在一个重复的时间表。",
      "D": "使用亚马逊 EMR 作业与阿帕奇蜂巢外部表计算性能指标的一个经常性的时间表。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon Athena",
      "DynamoDB"
    ],
    "explanation": {
      "analysis": "核心考点是计算 DynamoDB 数据的性能指标，并且最小化对 DynamoDB 读写容量的影响。答案A 使用 Athena 直接查询 DynamoDB，无需额外的 ETL 过程。",
      "why_correct": "选项A 使用 Athena，可以通过 Athena 的 DynamoDB 连接器直接查询 DynamoDB 数据，不需要额外的 ETL 过程，对 DynamoDB 的读写容量影响最小，也方便使用 SQL 进行分析。",
      "why_wrong": "选项B 需要使用 Glue 进行 ETL，过程比较复杂。选项C 使用 Redshift，需要将 DynamoDB 数据导入 Redshift，延迟高，操作复杂。选项D 使用 EMR 和 Hive，配置复杂，而且会占用额外的资源。"
    },
    "related_terms": [
      "DynamoDB",
      "Athena",
      "Glue",
      "Redshift",
      "EMR",
      "Apache Hive"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 963,
    "topic": "",
    "question_cn": "一个解决方案架构师正在为一个新的无状态应用程序设计云架构。该应用程序将部署在EC2上。解决方案架构师为该应用程序创建了一个亚马逊机器映像和启动模板。根据需要处理的作业数量，应用程序必须并行运行，同时根据需要添加和删除应用程序亚马逊EC2实例。应用程序必须是松散耦合的。作业项必须长期存储。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "创建一个亚马逊简单通知服务(SNS)亚马逊主题以发送需要处理的作业。使用带有扩展策略集的启动模板创建一个自动扩展组，以根据CPU使用情况添加和删除EC2实例。",
      "B": "创建一个亚马逊简单队列服务(SQS)队列以保存需要处理的作业。通过使用带有扩展策略集的启动模板来根据网络使用情况添加和删除EC2实例创建一个自动扩展组。",
      "C": "创建一个亚马逊简单队列服务(SQS)队列以保存需要处理的作业。通过使用带有扩展策略集的启动模板创建一个自动扩展组，以根据SQS队列中的项目数量添加和删除EC2实例。",
      "D": "创建一个亚马逊简单通知服务(SNS)亚马逊主题以发送需要处理的作业。通过使用带有扩展策略集的发布模板创建一个自动扩展组，以根据发布到SNS主题的消息数量添加和删除EC2实例。"
    },
    "vote_percentage": null,
    "tags": [
      "SQS",
      "EC2 Auto Scaling"
    ],
    "explanation": {
      "analysis": "核心考点是设计无状态应用程序的架构，实现作业队列和自动伸缩。答案C使用SQS存储作业，并根据队列中的消息数量进行自动伸缩。",
      "why_correct": "选项C 使用 SQS 队列存储需要处理的作业，保证了作业的持久化和解耦。 Auto Scaling 组根据 SQS 队列中消息的数量来动态调整 EC2 实例的数量，实现自动伸缩，满足了题目中的所有要求。",
      "why_wrong": "选项A 使用 SNS，主要用于发布订阅消息，不适合作为作业队列。 选项B 使用网络使用情况进行 Auto Scaling，与题目中作业数量的依赖不匹配。选项D 使用SNS，无法保证作业的可靠性和持久性，也不适合作为作业队列。"
    },
    "related_terms": [
      "EC2",
      "SNS",
      "Auto Scaling",
      "SQS",
      "EC2实例"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 964,
    "topic": "",
    "question_cn": "一家全球电子商务公司使用的是单一的架构。该公司需要一个解决方案来管理不断增加的产品数据量。解决方案必须是可伸缩的并具有模块化的服务体系结构。该公司需要维护其结构化的数据库模式。该公司还需要一个存储解决方案来存储产品数据和产品图像。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "在自动缩放组中使用亚马逊 EC2实例部署容器化应用程序。使用应用程序负载均衡器分配流量。使用亚马逊 RDS 数据库实例存储产品数据和产品图像。",
      "B": "使用 Lambda函数管理现有的单片应用程序。使用亚马逊 DynamoDB存储产品数据和产品图像。使用亚马逊 SNS来进行事件驱动的Lambda函数之间的通信。",
      "C": "使用亚马逊弹性库伯内特斯服务(EKS)与亚马逊EFS部署部署一个集装箱化的应用程序。使用亚马逊 Aurora 集群存储产品数据。使用步骤函数来管理工作流。将产品图像保存在亚马逊冰川深度档案中。",
      "D": "使用亚马逊弹性集装箱服务(ECS)与Fargate部署一个集装箱化的应用程序。使用具有多AZ部署的亚马逊RDS存储产品数据。将产品图像存储在亚马逊S3桶中。"
    },
    "vote_percentage": null,
    "tags": [
      "ECS",
      "RDS",
      "S3"
    ],
    "explanation": {
      "analysis": "核心考点是构建可扩展的电商平台。答案D 提供了基于 ECS Fargate 的容器化部署，使用 RDS 存储结构化数据，S3 存储图像，是合适的方案。",
      "why_correct": "选项D 使用 ECS 和 Fargate，可以实现容器化部署，简化运维。使用 RDS 可以存储结构化的产品数据，使用 S3 存储产品图像，满足可扩展性和模块化的需求。",
      "why_wrong": "选项A 在 EC2 上部署容器，需要运维服务器。选项B 使用 DynamoDB，不适合结构化数据库。选项C 使用冰川深度归档产品图片，访问延迟太高，使用EFS，存储成本高。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "Lambda",
      "DynamoDB",
      "SNS",
      "EKS",
      "EFS",
      "Aurora",
      "Step Functions",
      "ECS",
      "Fargate",
      "S3",
      "Multi-AZ",
      "Glacier"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 965,
    "topic": "",
    "question_cn": "一家公司正在将应用程序从本地环境迁移到AWS。该应用程序将敏感数据存储在Amazon S3中。公司必须在将数据存储在Amazon S3之前对数据进行加密。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用客户管理密钥使用客户端加密加密数据。",
      "B": "使用服务器端加密的数据加密与AWS KMS密钥(SSE-KMS)。",
      "C": "使用用户提供的密钥使用服务器端加密对数据进行加密(SSE-C)。",
      "D": "使用亚马逊管理密钥使用客户端加密加密数据。"
    },
    "vote_percentage": "100%",
    "tags": [
      "S3 Encryption",
      "KMS"
    ],
    "explanation": {
      "analysis": "注意: 此题官方答案为B，但社区共识(投票最高)为A。社区倾向A的原因是 客户端加密，数据在传输到S3之前就被加密，安全性更高。",
      "why_correct": "选项A 使用客户端加密，可以确保数据在到达 S3 之前就被加密，安全性最高。客户管理密钥可以更好地控制密钥的生命周期。是最安全的解决方案。",
      "why_wrong": "选项B 使用 SSE-KMS，由 AWS 管理密钥，而不是客户管理，安全性不如选项A。 选项C 使用 SSE-C，需要客户提供加密密钥，管理复杂。 选项D 描述不清晰，不完整。"
    },
    "related_terms": [
      "S3",
      "KMS",
      "SSE-KMS",
      "SSE-C",
      "客户端加密"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 966,
    "topic": "",
    "question_cn": "一个公司希望创建一个亚马逊 EMR 集群，多个团队将使用它。该公司希望确保每个团队的大数据负载只能访问每个团队需要与之交互的 AWS 服务。该公司不希望工作负载能够访问集群的基础EC2实例上的实例元数据服务版本2(IMDSv2)。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "为团队需要的每个AWS服务配置接口VPC端点。使用所需的接口VPC端点提交大数据工作负载。",
      "B": "创建EMR运行时角色。将集群配置为使用运行时角色。使用运行时角色提交大数据工作负载。",
      "C": "创建具有每个团队所需权限的EC2实例配置文件。使用实例配置文件提交大数据工作负载。",
      "D": "创建一个安全配置，该配置具有设置为错误的启用应用程序二甲胺选项。使用安全性配置提交大数据工作负载。"
    },
    "vote_percentage": null,
    "tags": [
      "EMR",
      "IAM Roles"
    ],
    "explanation": {
      "analysis": "核心考点是 EMR 集群的权限管理和安全性。答案 B 使用 EMR 运行时角色，可以限制访问权限并避免访问 IMDSv2。",
      "why_correct": "选项 B 通过使用 EMR 运行时角色，可以限制 EMR 集群的访问权限。 运行时角色可以附加 IAM policy, 限制 EMR 集群访问 AWS 服务，并且可以禁用 IMDSv2 的访问。",
      "why_wrong": "选项A 配置 VPC 接口终端节点，主要用于私有访问，与限制权限没有直接关系。选项C 使用 EC2 实例配置文件，可以授权访问AWS服务，但是没有限制IMDSv2的功能。 选项D 使用安全配置，主要是配置加密和数据处理，与权限控制和访问 IMDSv2 无关。"
    },
    "related_terms": [
      "EMR",
      "EC2",
      "VPC 端点",
      "IMDSv2"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 967,
    "topic": "",
    "question_cn": "解决方案架构师正在设计一个应用程序帮助用户填写和提交注册表。解决方案架构师计划使用两级架构，包括应用程序服务器层和工作人员层。申请需要快速处理提交的表格。应用程序需要精确地处理每个表单一次。解决方案必须确保没有数据丢失。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "在应用程序服务器层和工作层层之间使用亚马逊简单队列服务(SQS)FIFO队列来存储和转发表单数据。",
      "B": "在应用程序服务器层和工作层层之间使用亚马逊API网关API来存储和转发表单数据。",
      "C": "在应用程序服务器层和工作人员层之间使用亚马逊简单队列服务标准队列来存储和转发表单数据。",
      "D": "使用一个步骤函数工作流。在应用程序服务器层和存储和转发表单数据的工作层之间创建同步工作流。"
    },
    "vote_percentage": "100%",
    "tags": [
      "SQS FIFO",
      "Event-driven architecture"
    ],
    "explanation": {
      "analysis": "核心考点是设计一个应用程序来处理用户提交的表单，并保证数据的可靠性和顺序。答案 A 使用 SQS FIFO 队列，可以满足这些需求。",
      "why_correct": "选项 A 使用 SQS FIFO 队列可以保证消息的顺序，并且每个消息只会被处理一次，满足精确处理每个表单一次的需求，避免了数据丢失。",
      "why_wrong": "选项 B 使用 API 网关，无法保证数据处理的可靠性。选项 C 使用 SQS 标准队列，不保证消息的顺序，可能会导致问题。 选项 D 使用 Step Functions 创建同步工作流，无法保证消息的顺序和可靠性，相对复杂。"
    },
    "related_terms": [
      "SQS",
      "FIFO",
      "API Gateway",
      "Step Functions"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 968,
    "topic": "",
    "question_cn": "一家金融公司利用一个内部搜索应用程序来收集来自不同生产商的流媒体数据。该应用程序为搜索和可视化功能提供实时更新。该公司正计划迁移到 AWS，并希望使用本地解决方案。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "使用亚马逊EC2实例来摄取和处理数据流到亚马逊S3桶存储。使用亚马逊 Athena搜索数据。使用亚马逊管理格拉法纳创建可视化。",
      "B": "使用亚马逊 EMR 来吸收和处理数据流到亚马逊 Redshift 存储。使用亚马逊 Redshift Spectrum 搜索数据。使用亚马逊快速视觉创建可视化。",
      "C": "使用亚马逊弹性库伯内特斯服务(EKS)吸收和处理数据流到亚马逊 DynamoDB存储。使用亚马逊云表创建图形仪表板来搜索和可视化数据。",
      "D": "使用亚马逊运动数据流来摄取和处理数据流到亚马逊开放搜索服务。使用开放搜索服务来搜索数据。使用亚马逊快速视觉创建可视化。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon OpenSearch Service",
      "Kinesis Data Streams"
    ],
    "explanation": {
      "analysis": "核心考点是使用 AWS 服务构建一个实时搜索和可视化解决方案。答案 D 提供了最佳的组合，使用 Kinesis Data Streams 摄取数据，OpenSearch Service 进行搜索，QuickSight 进行可视化。",
      "why_correct": "选项 D 使用 Kinesis Data Streams 摄取数据流，OpenSearch Service 提供强大的搜索功能，且支持实时更新，QuickSight 用于创建可视化，完全满足需求，并且是云原生解决方案。",
      "why_wrong": "选项 A 使用 EC2 和 S3，架构复杂，Athena不擅长实时搜索。选项 B 使用 EMR 和 Redshift，配置复杂，而且 Redshift 不适合实时搜索。 选项 C 使用 EKS 和 DynamoDB，DynamoDB 不擅长搜索，且不适用于创建图形仪表板。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "Athena",
      "Grafana",
      "EMR",
      "Redshift",
      "Redshift Spectrum",
      "QuickSight",
      "EKS",
      "DynamoDB",
      "CloudWatch",
      "OpenSearch",
      "Data Streams"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 969,
    "topic": "",
    "question_cn": "一家公司目前运行的一个内部应用程序是在 Linux 机器上使用的。该应用程序资源密集，直接为客户服务。公司想把这个应用程序现代化。该公司希望在容器上运行这个应用程序并基于亚马逊云表指标进行规模化。该公司还希望减少用于运营维护活动的时间。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用容器将应用程序容器化。使用一个 CloudFormation 模板将应用程序部署到 Fargate的亚马逊弹性容器服务上。",
      "B": "使用容器将应用程序容器化。在亚马逊 EC2实例中使用 CloudFormation 模板将应用程序部署到亚马逊弹性容器服务中。",
      "C": "使用应用程序运行程序来整合应用程序。使用应用程序运行器将应用程序部署到 Fargate的亚马逊弹性容器服务中。",
      "D": "使用应用程序运行程序来整合应用程序。使用应用程序运行器将应用程序部署到亚马逊EC2实例上的亚马逊弹性库伯内特斯服务(EKS)亚马逊。"
    },
    "vote_percentage": null,
    "tags": [
      "ECS Fargate",
      "Containerization"
    ],
    "explanation": {
      "analysis": "核心考点是应用程序的现代化和容器化，并且减少运维开销。答案 A 使用 ECS Fargate 可以满足这些要求。",
      "why_correct": "选项A 使用 ECS 和 Fargate，可以实现容器化部署，简化运维，并且可以基于 CloudWatch 指标进行自动伸缩，减少了运维工作量，符合题意。",
      "why_wrong": "选项B 在 EC2 上部署容器，需要运维 EC2 实例。选项C 使用 Application Runner，不是最佳实践，可能缺少灵活性。 选项D 使用 EKS 和 Application Runner，需要运维 Kubernetes 集群，增加了运维负担。"
    },
    "related_terms": [
      "Fargate",
      "ECS",
      "CloudFormation",
      "CloudWatch"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 970,
    "topic": "",
    "question_cn": "一个公司正在设计一个新的内部网络应用程序在 AWS 云。新的应用程序必须安全地从AWS托管的服务中检索和存储多个员工用户名和密码。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "将员工凭证存储在系统管理器参数存储中。使用 CloudWatch 和批处理分泌值从参数存储中检索用户名和密码。",
      "B": "将员工证书保存在AWS机密经理处。使用 CloudWatch和批处理分泌值从机密管理器检索用户名和密码。",
      "C": "将员工凭证存储在系统管理器参数存储中。使用 CloudWatch和批处理分泌值从参数存储中检索用户名和密码。",
      "D": "将员工证书保存在AWS机密经理处。使用Lambda函数和批处理分泌值从机密管理器检索用户名和密码。"
    },
    "vote_percentage": null,
    "tags": [
      "Secrets Manager",
      "Lambda"
    ],
    "explanation": {
      "analysis": "核心考点是安全地存储和检索员工凭证。答案 D 使用 Secrets Manager 和 Lambda 函数，是最安全且操作开销最小的方案。",
      "why_correct": "选项D 将敏感的员工凭证存储在 AWS Secrets Manager 中，通过 Lambda 函数来检索，可以确保凭证的安全性和访问控制，操作开销较小，是最佳实践。",
      "why_wrong": "选项A 将凭证存储在系统管理器参数存储中，安全性不如 Secrets Manager。选项B 使用 CloudWatch，CloudWatch 主要用于监控，不能用于检索秘密信息。 选项C 与选项A一样，安全性不足。"
    },
    "related_terms": [
      "System Manager Parameter Store",
      "CloudWatch",
      "Secrets Manager",
      "Lambda"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 971,
    "topic": "",
    "question_cn": "位于东北地区的一家公司拥有数以千计的前哨服务器。该公司已经在世界各地的偏远地区部署了这些服务器。所有服务器都定期下载由 100 个文件组成的新软件版本。在所有服务器运行新的软件版本之前存在显著的延迟。公司必须减少新软件版本的部署延迟。用最少的操作开销来满足这个需求的解决方案是什么？",
    "options_cn": {
      "A": "创建一个亚马逊S3桶在阿普东北。建立一个亚马逊云端分布在东北，其中包括一个禁用缓存策略。将S3桶配置为原产地。使用签名网址下载软件。",
      "B": "创建一个亚马逊S3桶在阿普东北。在美国东地区创建第二个S3桶。在桶中配置复制。建立了亚马逊云端分布使用东北，作为主要起源，美国东作为次要来源。使用签名网址下载软件。",
      "C": "创建一个亚马逊S3桶在阿普东北。配置亚马逊传输加速度。使用传输加速端点下载软件。",
      "D": "创建一个亚马逊S3桶在阿普东北。建立亚马逊云区分布。将S3桶配置为原产地。使用签名网址下载软件。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon CloudFront",
      "S3 Transfer Acceleration"
    ],
    "explanation": {
      "analysis": "核心考点是优化软件部署的延迟，降低下载时间。答案 D 使用 CloudFront，通过 CDN 加速文件分发，最有效。",
      "why_correct": "选项 D 使用 CloudFront，可以利用 CDN 的优势，将软件文件缓存到全球边缘站点，减少下载延迟。使用签名 URL 可以确保访问安全。",
      "why_wrong": "选项A 在 CloudFront 中禁用缓存策略，无法加速。选项B 使用 S3 桶复制，部署架构复杂。选项C 使用 S3 传输加速，仅适用于单个S3桶的数据传输加速，对于大规模部署效果有限，并且不能减少延迟。CloudFront 是更好的选择。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "传输加速",
      "签名网址"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 972,
    "topic": "",
    "question_cn": "一家公司目前通过使用微软的服务器运行一个内部股票交易应用程序。该公司希望将应用程序迁移到云中。该公司需要设计一个高可用性的解决方案提供低延迟访问以在多个可用性区域之间阻塞存储。用最少的执行努力来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "配置Windows服务器集群，该集群跨越Amazon EC2实例上的两个可用性区域。在两个集群节点上安装应用程序。使用Amazon FSx作为两个集群节点之间的共享存储Windows文件服务器。",
      "B": "配置Windows服务器集群，该集群跨越Amazon EC2实例上的两个可用性区域。在两个集群节点上安装应用程序。使用Amazon EBS SSD(GP3) EBS卷作为连接到EC2实例的存储。建立应用程序级别的复制以同步数据从一个可用性区域的EBS卷到第二个可用性区域的另一个EBS卷。",
      "C": "将应用程序部署在Amazon EC2实例中的两个可用性区域。在备用模式下将一个EC2实例配置为活动实例和第二个EC2实例。使用 FSX (ISCSI) 一个Amazon 网络应用程序通过使用因特网小型计算机系统接口协议访问数据。",
      "D": "将应用程序部署在Amazon EC2实例中的两个可用性区域。在备用模式下将一个EC2实例配置为活动实例和第二个EC2实例。使用Amazon EBS卷作为连接到EC2实例的存储器。建立Amazon级复制以便在第二个可用性区中将数据从一个有效性区域中的碘卷同步到另一个有效性区域中的碘卷。"
    },
    "vote_percentage": null,
    "tags": [
      "EC2",
      "FSx"
    ],
    "explanation": {
      "analysis": "此题考察在AWS上部署高可用性Windows应用程序的存储方案。最佳答案是使用Amazon FSx for Windows File Server，提供跨可用区的文件共享存储。",
      "why_correct": "Amazon FSx for Windows File Server 专为Windows环境设计，提供高性能、高可用性的共享文件存储，并且支持多AZ部署，满足高可用和低延迟的需求。与EBS相比，FSx更易于配置共享存储。",
      "why_wrong": "选项B使用EBS，需要应用程序级别的数据同步和复制，增加了复杂度和运维负担。选项C虽然使用了FSx，但配置不完整，描述不清。选项D在描述EBS的复制方案时不够明确。"
    },
    "related_terms": [
      "EC2",
      "FSx",
      "EBS",
      "Multi-AZ",
      "iSCSI"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 973,
    "topic": "",
    "question_cn": "一家公司正在设计一个具有互联网界面应用负载平衡器的应用程序。该应用程序需要从公共互联网上接收HTTPS Web流量。必须只将HTTPS流量发送到在Amazon EC2实例上的443端口上的应用服务器上。ALB必须在端口8443的HTTPS上对应用服务器进行健康检查。哪些配置组合的安全组是与ALB关联将满足这些要求？选三。",
    "options_cn": {
      "A": "允许从443端口的HTTPS入站流量。",
      "B": "允许所有出港交通量达到443。",
      "C": "允许HTTPS出站流量进入443端口的应用程序实例。",
      "D": "允许从应用程序实例为端口443输入流量。",
      "E": "允许HTTPS出站流量到应用程序实例以便在8443端口上进行健康检查。",
      "F": "允许从应用程序实例进入的流量进行端口8443的健康检查。"
    },
    "vote_percentage": null,
    "tags": [
      "Security Group",
      "ALB"
    ],
    "explanation": {
      "analysis": "此题考查ALB安全组的配置，需要考虑入站、出站流量以及健康检查端口。正确答案是A、C、E。",
      "why_correct": "选项A: 允许来自互联网的HTTPS流量进入ALB的443端口。选项C: 允许ALB将HTTPS流量发送到EC2实例的443端口。选项E: 允许ALB对EC2实例的8443端口进行健康检查。",
      "why_wrong": "选项B允许所有出站流量，过于宽松。选项D允许从应用程序实例输入流量，描述不清晰。选项F配置了健康检查，但方向不对。"
    },
    "related_terms": [
      "ALB",
      "HTTPS",
      "EC2",
      "HTTPS",
      "安全组"
    ],
    "best_answer": [
      "A",
      "C",
      "E"
    ],
    "official_answer": [
      "A",
      "C",
      "E"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 974,
    "topic": "",
    "question_cn": "一个公司在S3上主持一个应用程序。该应用程序赋予用户上传照片和存储在Amazon S3桶照片的能力。该公司希望使用Amazon CloudFront和定制域名上传照片文件到S3桶在欧盟西部地区。哪种解决方案能满足这些要求？选二。",
    "options_cn": {
      "A": "使用证书管理器在美国东1号区域创建公共证书。在云端使用证书。",
      "B": "使用 AWS 证书管理器 (ACM) 在eu-west-1中创建公共证书。在CloudFront中使用证书。",
      "C": "配置Amazon S3以允许从CloudFront上传。配置S3 Transfer Acceleration。",
      "D": "配置Amazon S3 允许上传来自云前原产地访问控制。",
      "E": "配置Amazon S3 允许从云端上传。配置一个Amazon 网站端点。"
    },
    "vote_percentage": "50%",
    "tags": [
      "CloudFront",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考查CloudFront和S3的配置，特别是使用自定义域名和安全上传。正确答案是B和D。",
      "why_correct": "选项B: 在eu-west-1区域创建ACM证书，并在CloudFront中使用，满足使用自定义域名的需求。选项D: 配置S3允许来自CloudFront的上传，确保文件可以上传到S3桶。",
      "why_wrong": "选项A: 在美国东1创建证书，区域不匹配。选项C: 配置S3 Transfer Acceleration，与题目需求不匹配。选项E: 配置网站端点，与CloudFront的使用冲突。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "ACM",
      "S3 Transfer Acceleration",
      "S3 桶"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 975,
    "topic": "",
    "question_cn": "一家天气预报公司连续收集各种传感器的温度读数。一个现有的数据摄取过程收集读数和聚合成更大的阿帕奇拼带文件读数。然后，该流程使用KMS（CSE-KMS）和S3，流程使用KMS管理的密钥使用客户端加密对文件进行加密。最后流程将这些文件写入一个Amazon S3桶，每个日历日都有单独的前缀。该公司希望对数据进行偶尔的SQL查询以获取特定日历日的移动平均值样本。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "配置Amazon Athena来读取加密文件。直接在Amazon S3中运行对数据的SQL查询。",
      "B": "使用Amazon S3 Select直接在Amazon S3中运行对数据的SQL查询。",
      "C": "配置Amazon Redshift读取加密文件。使用Redshift Spectrum和Redshift查询编辑器直接在Amazon S3中运行对数据的SQL查询。",
      "D": "配置Amazon EMR来读取加密文件。直接在Amazon S3中使用阿帕奇斯帕克斯运行对数据的SQL查询。"
    },
    "vote_percentage": null,
    "tags": [
      "Athena",
      "S3",
      "KMS"
    ],
    "explanation": {
      "analysis": "此题考察对加密S3数据进行查询的最佳方式。最佳答案是使用Amazon Athena。",
      "why_correct": "Athena可以直接查询S3上的加密数据，无需预先解密，并且Athena非常适合临时查询。使用KMS管理密钥，保证了数据的安全性。",
      "why_wrong": "选项B，S3 Select无法直接处理CSE-KMS加密数据。选项C，Redshift Spectrum虽然可以查询S3数据，但是增加了复杂度和成本。选项D，EMR适用于大规模数据处理，对于偶尔的查询来说，成本过高。"
    },
    "related_terms": [
      "S3",
      "KMS",
      "SSE-KMS",
      "Athena",
      "S3 Select",
      "Redshift",
      "Redshift Spectrum",
      "EMR",
      "Apache Spark"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 976,
    "topic": "",
    "question_cn": "一家公司正在实施一个新的应用程序。该公司将在多个区域的多个可用性区域内运行多个Amazon EC2实例的应用程序。该应用程序将通过互联网提供。用户将访问来自世界各地的应用程序。该公司希望确保每个访问应用程序的用户都被发送到最接近用户位置的EC2实例中。哪种解决方案能满足这些要求？",
    "options_cn": {
      "A": "实施Amazon Route 53地理定位路由策略。使用一个面向互联网的应用程序负载平衡器将流量分布到同一区域内的所有可用区域。",
      "B": "实施Amazon Route 53地理邻近路由政策。使用一个面向互联网的网络负载平衡器将流量分布到同一区域内的所有可用区域。",
      "C": "实施Amazon Route 53多值响应路由策略。使用一个面向互联网的应用程序负载平衡器将流量分布到同一区域内的所有可用区域。",
      "D": "执行Amazon Route 53加权路由政策。使用一个面向互联网的网络负载平衡器将流量分布到同一区域内的所有可用区域。"
    },
    "vote_percentage": null,
    "tags": [
      "Route 53",
      "Geo-proximity routing"
    ],
    "explanation": {
      "analysis": "此题考察如何基于用户地理位置将流量路由到最近的EC2实例。最佳答案是使用Route 53的地理邻近路由策略和网络负载均衡器。",
      "why_correct": "Route 53的地理邻近路由策略，可以根据用户的地理位置，将流量路由到最近的EC2实例。网络负载均衡器（NLB）能更好地支持这种场景，而且NLB支持静态IP，更容易配置。",
      "why_wrong": "选项A使用了应用程序负载均衡器（ALB），不适合地理位置路由。选项C多值响应路由策略，不适用于根据地理位置进行路由。选项D加权路由策略，不能根据用户地理位置进行路由。"
    },
    "related_terms": [
      "Route 53",
      "EC2",
      "ALB",
      "地理位置路由",
      "地理邻近路由",
      "多值响应路由",
      "加权路由"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 977,
    "topic": "",
    "question_cn": "一家金融服务公司计划在EC2上推出一个新的应用程序来处理敏感的金融交易。该公司将在Amazon EC2实例中部署应用程序。该公司将使用Amazon RDS作为数据库。该公司的安全政策要求数据必须在休息和运输过程中加密。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "通过使用AWS KMS管理的密钥为Amazon RDS配置静态加密。为传输中的加密配置ACM证书。",
      "B": "通过使用AWS KMS管理的密钥为Amazon RDS配置静态加密。为传输中的加密配置IPSEC隧道。",
      "C": "在对Amazon RDS进行数据存储之前实施第三方应用级数据加密。为传输中的加密配置ACM证书。",
      "D": "通过使用AWS KMS管理的密钥为Amazon RDS配置静态加密。配置VPN连接以启用专用连接在传输中加密数据。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Encryption",
      "KMS",
      "SSL/TLS"
    ],
    "explanation": {
      "analysis": "此题考察保护RDS数据安全性的最佳实践。最佳答案是使用KMS管理的密钥进行静态加密，并通过SSL/TLS实现传输加密。",
      "why_correct": "选项A: 使用KMS加密RDS数据，并在传输过程中使用SSL/TLS加密，满足了静态和传输加密的要求，并且使用ACM证书，易于管理。",
      "why_wrong": "选项B: 使用IPSEC隧道，增加了配置的复杂性。选项C: 使用第三方应用级加密，增加了开发和运维的复杂性。选项D: 配置VPN连接，增加了复杂性。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "KMS",
      "ACM",
      "IPSEC",
      "VPN"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 978,
    "topic": "",
    "question_cn": "一家公司正在将其内部的甲骨文数据库迁移到Amazon RDS的数据库。该公司需要保存数据90天以满足监管要求。公司还必须能够将数据库恢复到一个特定的时间点最多14天。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "创建Amazon RDS自动备份。保留期定为90天。",
      "B": "每天创建一个Amazon RDS手动快照。删除超过90天的手动快照。",
      "C": "使用Amazon Aurora克隆功能为甲骨文创建一个点时恢复。删除超过90天的克隆。",
      "D": "创建一个备份计划有一个90天的保留期使用AWS Backup。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Backup",
      "Point-in-time recovery"
    ],
    "explanation": {
      "analysis": "此题考察RDS备份和恢复的配置。最佳答案是使用RDS自动备份并配置90天的保留期。",
      "why_correct": "RDS自动备份可以满足备份和恢复的需求，通过配置90天的保留期，满足了监管要求。手动快照需要手动管理，增加运维成本。",
      "why_wrong": "选项B: 需要手动删除备份，增加工作量。选项C: Aurora克隆不适用于甲骨文数据库。选项D: 使用AWS Backup增加了额外的复杂性。"
    },
    "related_terms": [
      "RDS",
      "Aurora",
      "AWS Backup",
      "自动备份",
      "手动快照"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 979,
    "topic": "",
    "question_cn": "一个公司正在开发一个新的应用程序，它使用一个关系数据库来存储用户数据和应用程序配置。该公司预计该应用程序的用户将稳步增长。该公司预计数据库的使用量将是可变的而且阅读量很大偶尔也会写。该公司希望成本最优化数据库解决方案。该公司希望使用一个管理的数据库解决方案以提供必要的性能。哪种解决方案能最有效地满足这些要求？",
    "options_cn": {
      "A": "在Amazon RDS上部署数据库。使用已提供的存储以确保读写操作的一致性能。",
      "B": "在Amazon Aurora上部署数据库，无服务器根据实际使用情况自动扩展数据库容量以适应工作量。",
      "C": "在Amazon DynamoDB上部署数据库。使用随需应变的容量模式自动调整吞吐量以适应工作量。",
      "D": "在Amazon RDS上部署数据库。使用磁存储和读取副本以适应工作负载。"
    },
    "vote_percentage": null,
    "tags": [
      "Aurora Serverless",
      "RDS"
    ],
    "explanation": {
      "analysis": "此题考察数据库选型，以及如何根据工作负载特点进行优化。最佳答案是使用Aurora Serverless。",
      "why_correct": "Aurora Serverless可以根据实际使用情况自动扩展数据库容量，满足可变的工作负载需求，并且成本优化。Aurora性能良好，适合读写混合负载。",
      "why_wrong": "选项A: RDS不能自动缩放。选项C: DynamoDB适用于NoSQL工作负载，不适用于关系型数据库，同时无法满足数据库的要求。选项D: 使用磁存储性能较差，不能满足大读写量，读取副本虽然可以改善读取性能，但不能解决自动扩展的问题。"
    },
    "related_terms": [
      "RDS",
      "Aurora",
      "DynamoDB",
      "RDS",
      "读取副本"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 980,
    "topic": "",
    "question_cn": "一个公司在VPC中的几个Amazon EC2实例上拥有它的应用程序。该公司为每个客户创建了一个专用的Amazon S3桶以便在Amazon S3中存储相关信息。该公司希望确保运行在EC2实例上的应用程序能够安全地访问属于该公司帐户的S3桶。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "为Amazon S3创建一个连接到VPC的网关端点。更新EC2实例配置文件策略只提供对应用程序需要的特定桶的访问。",
      "B": "在公共子网中创建一个NAT网关并与一个只允许访问Amazon S3的安全组一起。更新路由表以使用NAT网关。",
      "C": "为Amazon S3创建一个网关端点该端点附属于使用拒绝操作和下列条件键对EC2实例配置文件策略进行日期。",
      "D": "在公共子网中创建一个NAT网关。更新路径表以使用NAT网关。为所有桶指定桶策略并附有拒绝操作和以下条件键。"
    },
    "vote_percentage": null,
    "tags": [
      "VPC Endpoint",
      "IAM"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地让EC2实例访问S3。最佳答案是使用VPC端点并结合IAM策略。",
      "why_correct": "使用S3 VPC网关端点，可以让EC2实例通过VPC内部访问S3，避免了流量经过公共互联网。通过更新EC2实例的IAM角色策略，限制对特定S3桶的访问，从而实现最小权限原则，保障数据安全。",
      "why_wrong": "选项B和D使用了NAT网关，虽然可以访问S3，但增加了复杂性和成本，且流量需要经过公网，不安全。选项C的描述不完整，策略设置不清晰。"
    },
    "related_terms": [
      "VPC",
      "EC2",
      "S3",
      "VPC 网关端点",
      "NAT 网关",
      "EC2 实例配置文件",
      "桶策略"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 981,
    "topic": "",
    "question_cn": "一家公司正在建立一个基于云计算的应用程序它将处理敏感的客户数据。应用程序在数据库中使用Amazon RDS，在对象存储中使用Amazon S3，AWS Lambda在无服务器处理中调用Amazon SQS的事件通知。该公司使用美国信息管理局身份中心来管理用户凭证。开发、测试和操作团队需要对Amazon RDS和Amazon S3进行安全访问同时确保敏感客户数据的保密性。解决办法必须符合最小特权原则。用最少的操作开销来满足这些需求的解决方案是什么？",
    "options_cn": {
      "A": "使用最少权限的IAM角色授予所有团队访问权限。为每个团队分配IAM角色使用定制IAM策略定义基于团队职责的Amazon RDS和S3对象访问的特定权限。",
      "B": "启用具有标识中心目录的IAM标识中心。创建和配置具有对Amazon RDS和Amazon S3的颗粒访问权限集。将所有团队分配给具有特定权限集访问权限的组。",
      "C": "在所有基于角色权限的团队中为每个成员创建单独的用户。根据用户的需求为每个用户分配具有IAM和IAM访问预定义策略的IAM角色。实现IAM访问分析器定期认证评估。",
      "D": "使用AWS组织为每个团队创建单独的帐户。以最少的特权实现跨帐户IAM角色。根据团队的作用和职责授予RDS和S3访问的特定权限。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM",
      "RDS",
      "S3",
      "IAM Identity Center"
    ],
    "explanation": {
      "analysis": "此题考察如何在多团队环境中安全地访问RDS和S3，同时遵守最小权限原则。最佳答案是使用IAM Identity Center和IAM权限组。",
      "why_correct": "选项B: 使用IAM Identity Center集中管理用户身份和权限，创建具有对RDS和S3细粒度访问权限的权限集，并将团队分配到不同的权限组，满足了最小权限原则，降低了管理复杂性。",
      "why_wrong": "选项A:  缺少集中身份管理，不易维护。选项C: 为每个成员创建用户，管理成本太高，不便于管理。选项D: 使用多个账户，增加了复杂性，不符合题目中“最少操作开销”的要求。"
    },
    "related_terms": [
      "RDS",
      "S3",
      "Lambda",
      "SQS",
      "IAM",
      "IAM Identity Center",
      "IAM角色",
      "IAM策略",
      "IAM访问分析器",
      "AWS组织",
      "IAM角色",
      "最小特权"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 982,
    "topic": "",
    "question_cn": "一家公司有一个包含敏感数据文件的Amazon S3存储桶。该公司有一个在本地数据中心的虚拟机上运行的应用程序。该公司目前使用AWS IAM Identity Center。应用程序需要临时访问S3存储桶中的文件。该公司希望授予应用程序对S3存储桶中的文件的安全访问权限。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "创建S3存储桶策略，允许从公司本地数据中心的公共IP地址范围访问存储桶。",
      "B": "使用IAM Roles Anywhere在IAM Identity Center中获取授予S3存储桶访问权限的安全凭证。使用AWS CLI配置虚拟机以代入该角色。",
      "C": "在虚拟机上安装AWS CLI。使用有权访问存储桶的IAM用户的访问密钥配置AWS CLI。",
      "D": "创建授予存储桶访问权限的IAM用户和策略。将IAM用户的访问密钥和密钥存储在AWS Secrets Manager中。配置应用程序以在启动时检索访问密钥和秘密密钥。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM Roles Anywhere",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地让本地应用程序访问S3，并考虑了临时凭证的需求。最佳答案是使用IAM Roles Anywhere。",
      "why_correct": "IAM Roles Anywhere允许在AWS外部的应用程序，使用IAM角色进行身份验证，获取临时凭证访问AWS资源。通过这种方式，本地应用程序可以安全地访问S3存储桶，无需存储长期凭证。",
      "why_wrong": "选项A: 使用IP地址范围，不安全且不易维护。选项C:  使用IAM用户访问密钥，安全性较差，不推荐。选项D: 将密钥存储在AWS Secrets Manager中，虽然安全性有所提高，但仍需管理IAM用户，相对复杂。"
    },
    "related_terms": [
      "S3",
      "IAM Identity Center",
      "IAM Roles Anywhere",
      "AWS CLI",
      "IAM用户",
      "IAM策略",
      "AWS Secrets Manager"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 983,
    "topic": "",
    "question_cn": "一家公司在其本地数据中心托管其核心网络服务，包括目录服务和DNS。数据中心使用AWS Direct Connect (DX)连接到AWS云。计划增加更多AWS账户，这些账户将需要快速、经济高效且一致地访问这些网络服务。解决方案架构师应该实施什么来以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在每个新帐户中创建DX连接。将网络流量路由到本地服务器。",
      "B": "在VPC中为所有所需服务配置VPC终端节点。将网络流量路由到本地服务器。",
      "C": "在每个新帐户和VPC之间创建VPN连接，将网络流量路由到本地服务器。",
      "D": "在账户之间配置AWS Transit Gateway。将DX分配给中转网关，并将网络流量路由到本地服务器。"
    },
    "vote_percentage": null,
    "tags": [
      "Direct Connect",
      "Transit Gateway"
    ],
    "explanation": {
      "analysis": "此题考查跨多个AWS账户共享本地网络服务的最佳方式。最佳答案是使用AWS Transit Gateway。",
      "why_correct": "Transit Gateway可以作为中心枢纽，连接VPC和本地数据中心。通过Direct Connect连接到Transit Gateway后，所有AWS账户都可以通过Transit Gateway访问本地网络服务。减少了每个账户的配置和管理工作量，提高了效率。",
      "why_wrong": "选项A:  需要在每个新账户中创建DX连接，增加了管理工作量。选项B:  VPC终端节点不适用于本地数据中心的服务。选项C:  使用VPN连接，增加了配置复杂性，并且性能不如Direct Connect。"
    },
    "related_terms": [
      "AWS Direct Connect",
      "VPC",
      "VPC终端节点",
      "VPN",
      "AWS Transit Gateway",
      "DX"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 984,
    "topic": "",
    "question_cn": "一家公司在跨多个可用区的一个AWS区域托管其主要公共Web应用程序。该应用程序使用Amazon EC2 Auto Scaling组和应用程序负载均衡器(ALB)。开发团队需要成本优化的计算解决方案，以提高公司向全球数百万客户提供动态内容的能力。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "创建Amazon CloudFront ALB分配。将现有ALB配置为源。",
      "B": "使用Amazon Route 53根据每个客户的地理位置向EC2实例和ALB提供流量。",
      "C": "创建启用公共读取访问的Amazon S3存储桶。将Web应用程序迁移到S3存储桶。配置用于网站托管的S3存储桶。",
      "D": "使用AWS Direct Connect将内容从Web应用程序直接提供到每个客户的位置。"
    },
    "vote_percentage": null,
    "tags": [
      "CloudFront",
      "ALB"
    ],
    "explanation": {
      "analysis": "此题考察如何优化Web应用程序的性能，面向全球客户提供内容。最佳答案是使用CloudFront。",
      "why_correct": "CloudFront是一个内容分发网络（CDN），可以缓存Web应用程序的内容，并将其分发到全球各地的边缘站点，加速内容交付。将ALB作为源，保证了负载均衡和高可用性。",
      "why_wrong": "选项B: Route 53可以进行流量管理，但不能优化内容分发。选项C: 将应用程序迁移到S3静态网站托管，无法满足动态内容的需求。选项D: 使用Direct Connect，无法覆盖全球用户，且成本高昂。"
    },
    "related_terms": [
      "EC2",
      "CloudFront",
      "ALB",
      "Amazon Route 53",
      "S3",
      "AWS Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 985,
    "topic": "",
    "question_cn": "一家公司将用户数据存储在Amazon S3中。数据在工作时间高峰时段持续使用。访问模式各不相同，有些数据一次几个月都不使用。解决方案架构师必须选择一种经济高效的解决方案，在保持高可用性的同时保持最高水平的耐用性。哪种存储解决方案可以满足这些要求？",
    "options_cn": {
      "A": "Amazon S3标准",
      "B": "Amazon S3 智能分层",
      "C": "Amazon S3 Glacier深度存档",
      "D": "Amazon S3 - S3 -IA 一区 不频繁访问（ 一区 ）"
    },
    "vote_percentage": null,
    "tags": [
      "S3 Storage Class"
    ],
    "explanation": {
      "analysis": "此题考察如何根据访问模式优化S3存储成本。最佳答案是使用S3智能分层。",
      "why_correct": "S3智能分层可以自动将对象在标准、不频繁访问（IA）和归档访问之间移动，根据访问频率自动调整，可以平衡成本和性能。对于访问模式不固定的数据，最适合。",
      "why_wrong": "选项A: 标准存储成本较高。选项C: Glacier深度存档适合长期不常访问的归档数据，不适合频繁访问的数据。选项D: 一区IA，虽然成本较低，但是没有高可用性。"
    },
    "related_terms": [
      "S3",
      "S3标准",
      "S3 智能分层",
      "S3 Glacier深度存档",
      "S3 - S3 -IA 一区",
      "IA 一区"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 986,
    "topic": "",
    "question_cn": "一家公司正在测试在Amazon EC2 Linux实例上运行的应用程序。单个500 GB Amazon Elastic Block Store (Amazon EBS)通用 (gp2)卷附加到EC2实例。该公司将在Auto Scaling组中的多个EC2实例上部署该应用程序。所有实例都需要访问存储在EBS卷中的数据。该公司需要一个高度可用且具有弹性的解决方案，并且不会对应用程序代码进行重大更改。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "配置使用NFS服务器软件的EC2实例。将单个500 GB gp2 EBS卷附加到实例。",
      "B": "预置Amazon FSx for Windows File ServerSMB文件系统。将文件系统配置为单个可用区内的文件存储。",
      "C": "为EC2实例配置两个250 GB IOPS SSD EBS卷。",
      "D": "预置Amazon Elastic File System (Amazon EFS)文件系统。配置文件系统以使用通用性能模式。"
    },
    "vote_percentage": null,
    "tags": [
      "EFS",
      "EC2",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考查在EC2 Auto Scaling环境下共享存储的最佳方案。最佳答案是使用Amazon EFS。",
      "why_correct": "EFS是一个可扩展的、共享的文件系统，可以被多个EC2实例同时访问，非常适合于Auto Scaling场景，而且无需对应用程序代码进行修改。EFS能满足高可用性和弹性的要求。",
      "why_wrong": "选项A:  使用NFS共享存储，需要配置NFS服务器，增加了复杂性，并且会成为单点故障。选项B: FSx for Windows File Server仅适用于Windows环境，且仅在单个可用区内，不满足高可用性需求。选项C: 使用EBS卷，无法满足共享存储的需求。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "gp2",
      "Auto Scaling",
      "NFS",
      "FSx for Windows File Server",
      "SMB",
      "EFS",
      "IOPS",
      "SSD"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 987,
    "topic": "",
    "question_cn": "一家公司最近为其客户推出了一款新应用程序。该应用程序在跨两个可用区的多个EC2实例上运行。最终用户使用TCP与应用程序进行通信。应用程序必须具有高可用性，并且必须随着用户数量的增加而自动扩展。哪种步骤组合能够最经济有效地满足这些要求？ （选择两个。）",
    "options_cn": {
      "A": "在EC2实例前面添加网络负载均衡器。",
      "B": "为EC2实例配置Auto Scaling组。",
      "C": "在EC2实例前面添加一个应用程序负载均衡器。",
      "D": "为应用程序手动添加更多EC2实例。",
      "E": "在EC2实例前面添加网关负载均衡器。"
    },
    "vote_percentage": null,
    "tags": [
      "EC2 Auto Scaling",
      "Application Load Balancer"
    ],
    "explanation": {
      "analysis": "此题考察EC2应用程序的高可用性和自动伸缩的实现方案。答案组合是利用负载均衡器和Auto Scaling组实现.",
      "why_correct": "选项A和C均提供了负载均衡功能，其中应用程序负载均衡器更适合HTTP/HTTPS流量，网络负载均衡器提供更低延迟；选项B使用Auto Scaling实现自动伸缩。选择这两个选项可以确保高可用性、自动扩展和负载均衡。",
      "why_wrong": "选项D手动添加实例，不具备自动伸缩能力；选项E网关负载均衡器用于VPN和Direct Connect等场景，不适合此应用场景。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling",
      "TCP",
      "网络负载均衡器",
      "应用程序负载均衡器",
      "网关负载均衡器"
    ],
    "best_answer": [
      "B",
      "C"
    ],
    "official_answer": [
      "B",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 988,
    "topic": "",
    "question_cn": "一家公司正在为使用AWS云的新移动应用程序设计架构。该公司使用AWS Organizations中的组织单位(OU)来管理其账户。该公司Amazon EC2 IAM希望通过使用敏感和不敏感的值来标记实例的数据敏感度。身份不得删除标签或创建没有标签的实例。哪种步骤组合可以满足这些要求？ （选择两个。）",
    "options_cn": {
      "A": "在组织中，创建一个新的标签策略，指定数据敏感度标签键和所需的值。强制执行EC2实例的标签值。将标签策略附加到适当的OU。",
      "B": "(SCP)在组织中，创建一个新的服务控制策略(SCP)，指定数据敏感度标签键和所需的标签值。强制执行EC2实例的标签值。将OU连接到适当的SCP。",
      "C": "创建标签策略，在未指定标签键时拒绝运行实例。创建另一个标签策略以防止身份删除标签。将标签策略附加到适当的OU。",
      "D": "(SCP)创建服务控制策略(SCP)，以在未指定标签密钥时拒绝创建实例。创建另一个SCP以防止身份删除标签。将SCP连接到适当的OU。",
      "E": "创建规则以检查EC2实例是否使用数据敏感度标签和指定值。配置Lambda函数以在发现不合规资源时删除资 源。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Organizations",
      "Tag Policies",
      "Service Control Policies (SCP)"
    ],
    "explanation": {
      "analysis": "此题考察如何通过AWS Organizations和IAM策略来强制执行标签规范。答案组合是使用标签策略和SCP实现.",
      "why_correct": "选项A和D。选项A使用标签策略强制执行标签，选项D使用SCP强制标签，并防止删除和创建无标签的资源。这满足了题目要求。",
      "why_wrong": "选项B的SCP设置不完全，选项C缺少SCP的限制，选项E方案使用Lambda函数进行清理，实现复杂且无法从根本上防止违规。"
    },
    "related_terms": [
      "EC2",
      "AWS Organizations",
      "OU",
      "IAM",
      "SCP",
      "Lambda",
      "EC2实例"
    ],
    "best_answer": [
      "A",
      "D"
    ],
    "official_answer": [
      "A",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 989,
    "topic": "",
    "question_cn": "一家公司在AWS RDS for PostgreSQL上运行数据库工作负载，RDS是该公司客户门户的后端。该公司在RDS上运行多可用区数据库集群。公司需要实施30天的备份保留政策。该公司目前拥有自动备份和手动备份。该公司希望维护这两种类型的30天以内的现有RDS备份。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用AWS Backup将RDS备份保留策略配置为30天以进行自动备份。手动删除超过30天的手动备份。",
      "B": "禁用RDS自动备份。删除超过30天的自动备份和手动备份。将RDS备份保留策略配置为30天以进行自动备份。",
      "C": "将RDS备份保留策略配置为30天以进行自动备份。手动删除超过30天的手动备份。",
      "D": "禁用RDS自动备份。使用AWS CloudFormation自动删除超过30天的自动备份和手动备份。将RDS备份保留策略配置为30天以进行自动备份。"
    },
    "vote_percentage": null,
    "tags": [
      "RDS Backup",
      "AWS Backup"
    ],
    "explanation": {
      "analysis": "此题考察RDS备份保留策略的配置，以及手动备份的清理。答案是设置自动备份保留策略，并手动删除超过保留期的备份。",
      "why_correct": "选项C是最佳实践，通过配置RDS的自动备份保留策略，并手动删除超过保留期的手动备份，以满足30天备份保留策略的要求。这种方法既满足了备份需求，又控制了成本。",
      "why_wrong": "选项A使用AWS Backup，增加了额外的服务成本，并且对于RDS的自动备份策略，没有必要使用AWS Backup。选项B禁用了RDS的自动备份，不符合备份保留的要求。选项D CloudFormation用于清理备份，增加了复杂性，不具备成本效益。"
    },
    "related_terms": [
      "RDS",
      "PostgreSQL",
      "RDS",
      "多可用区",
      "AWS Backup",
      "RDS",
      "CloudFormation"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 990,
    "topic": "",
    "question_cn": "一家公司正计划将旧应用程序迁移到AWS。该应用程序当前使用NFS与本地存储解决方案通信以存储应用程序数据。为此，不能修改应用程序以使用除NFS之外的任何其他通信协议。解决方案架构师应建议在迁移后使用哪种存储解决方案？",
    "options_cn": {
      "A": "AWS数据同步",
      "B": "Amazon EBS（亚马逊弹性块存储）",
      "C": "Amazon EFS（弹性文件系统）",
      "D": "Amazon EMR（Amazon EMRFS）文件系统"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon EFS",
      "NFS"
    ],
    "explanation": {
      "analysis": "此题考察文件系统迁移的存储解决方案。答案是使用Amazon EFS，因为其支持NFS协议。",
      "why_correct": "Amazon EFS支持NFS协议，因此可以满足应用程序对NFS协议的需求，且易于迁移。",
      "why_wrong": "AWS数据同步用于数据迁移，并非存储解决方案；Amazon EBS是块存储，不支持NFS；Amazon EMRFS是用于EMR的，不适用于通用文件存储。"
    },
    "related_terms": [
      "NFS",
      "AWS",
      "EBS",
      "EFS",
      "EMR"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 991,
    "topic": "",
    "question_cn": "一家公司使用GPS跟踪器记录数千只海龟的迁徙模式。追踪器每5分钟检查一次，看看海龟移动的距离是否超过100码（91.4米）。如果海龟移动了，它的跟踪器会将新坐标发送到在一个区域的多个可用区中的三个EC2实例上运行的应用程序。最近，Web应用程序在处理大量跟踪器数据时不堪重负。数据丢失，无法重播事件。解决方案架构师必须防止此问题再次发生，并且需要一个运营开销最少的解决方案。解决方案架构师应该怎样做才能满足这些要求？",
    "options_cn": {
      "A": "创建Amazon S3存储桶来存储数据。配置应用程序以扫描存储桶中的新数据进行处理。",
      "B": "创建Amazon API Gateway终端节点来处理传输的位置坐标。使用Lambda函数同时处理每个项目。",
      "C": "创建Amazon Simple Queue Service (Amazon SQS)队列来存储传入数据。配置应用程序以轮询新消息以进行处理。",
      "D": "创建Amazon DynamoDB表来存储传输的位置坐标。配置应用程序以查询表以获取要处理的新数据。使用TTL来删除已经处理过的数据。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon SQS",
      "Scalability"
    ],
    "explanation": {
      "analysis": "此题考察如何构建高吞吐量的消息队列处理方案。答案是使用SQS，解耦生产者和消费者。",
      "why_correct": "使用SQS作为消息队列，可以解耦追踪器数据生产者和EC2实例中的消费者。SQS可以处理高吞吐量，并支持弹性伸缩。EC2实例可以从队列中读取数据，并在需要时增加实例数量以处理增加的数据量。可以防止数据丢失，并满足运营开销最小的要求。",
      "why_wrong": "S3用于存储，不适用于流式数据；API Gateway和Lambda方案用于API调用，无法支持高并发； DynamoDB没有消息队列功能，无法解决吞吐量问题，且TTL的删除不及时可能导致数据丢失。"
    },
    "related_terms": [
      "EC2",
      "S3",
      "API Gateway",
      "Lambda",
      "SQS",
      "DynamoDB",
      "TTL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 992,
    "topic": "",
    "question_cn": "公司的软件开发团队需要RDS多可用区集群。集群将充当本地部署的桌面客户端的后端。桌面客户端需要直接连接到RDS集群。公司必须让开发团队能够在团队在办公室时使用客户端连接到集群。哪种解决方案最安全地提供所需的连接？",
    "options_cn": {
      "A": "创建一个VPC和两个公有子网。在公有子网中创建RDS集群。将RDS与公司办公室中的客户网关结合使用。",
      "B": "创建一个VPC和两个私有子网。在私有子网中创建RDS集群。将RDS与公司办公室中的客户网关结合使用。",
      "C": "创建一个VPC和两个私有子网。在私有子网中创建RDS集群。使用安全组允许公司办公范围访问集群。",
      "D": "创建一个VPC和两个公有子网。在公有子网中创建RDS集群。为每个开发者创建一个集群用户。使用安全组允许用户访问集群。"
    },
    "vote_percentage": null,
    "tags": [
      "VPC",
      "RDS",
      "VPN"
    ],
    "explanation": {
      "analysis": "此题考察如何在私有子网中创建RDS集群，并使用VPN进行安全连接。答案是使用VPN连接到私有子网中的RDS集群。",
      "why_correct": "选项B在私有子网中创建RDS集群，并且通过VPN连接到公司的客户网关。这种方式是最安全的，因为数据传输通过加密的VPN连接，RDS集群无法从公共互联网直接访问。",
      "why_wrong": "选项A在公有子网中创建RDS，存在安全风险。选项C和D使用安全组，虽然可以限制访问，但不如VPN安全。"
    },
    "related_terms": [
      "RDS",
      "VPC",
      "安全组"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 993,
    "topic": "",
    "question_cn": "解决方案架构师正在创建一个应用程序来处理大量数据的批处理。输入数据将保存在S3中，输出数据将存储在不同的S3存储桶中。为了进行处理，应用程序将通过网络在多个EC2实例之间传输数据。解决方案架构师应该如何降低总体数据传输成本？",
    "options_cn": {
      "A": "将所有EC2实例放入Auto Scaling组中。",
      "B": "将所有EC2实例放置在同一区域中。",
      "C": "将所有EC2实例放置在同一可用区中。",
      "D": "将所有EC2实例放置在多个可用区的私有子网中。"
    },
    "vote_percentage": null,
    "tags": [
      "EC2",
      "Data Transfer",
      "Availability Zone"
    ],
    "explanation": {
      "analysis": "此题考察如何优化EC2实例间的数据传输成本。答案是将实例放置在同一个可用区中。",
      "why_correct": "将所有EC2实例放置在同一可用区中，减少了跨可用区的数据传输，从而降低了成本。AWS在同一可用区内的数据传输是免费的。",
      "why_wrong": "Auto Scaling组与数据传输成本无关；将所有实例放置在同一区域，并不能保证在同一可用区；将实例放置在多个可用区的私有子网中，会增加跨可用区的数据传输成本。"
    },
    "related_terms": [
      "EC2",
      "Auto Scaling"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 994,
    "topic": "",
    "question_cn": "一家公司托管一个多层Web应用程序，该应用程序使用Amazon Aurora MySQL数据库集群进行存储。应用程序层托管在14个EC2实例上。该公司的安全准则要求对数据库凭证进行加密并每天轮换一次。解决方案架构师应该如何做才能以最少的操作工作满足此要求？",
    "options_cn": {
      "A": "使用AWS Key Management Service (AWS KMS)创建新的KMS加密密钥。使用AWS Secrets Manager创建一个使用KMS密钥和适当凭证的新的Aurora密钥。将密钥与数据库集群关联。配置1天的自定义轮换期。",
      "B": "在AWS Systems Manager Parameter Store SecureString中创建两个参数：一个用于作为字符串参数的用户名，另一个使用AWS Key Management Service (AWS KMS)作为密码。为密码参数选择KMS加密，并将这些参数加载到应用程序层中。实施每1天轮换一次密码的Lambda函数。",
      "C": "将包含凭证的文件存储在加密的Amazon Elastic File System (Amazon EFS)文件系统中。在应用层的所有EC2实例中挂载EFS文件系统。限制对文件系统上的文件的访问，以便应用程序可以读取该文件，并且只有超级用户可以修改该文件。实现一个AWS Lambda函数，该函数每1天在Aurora中轮换一次密钥并将新凭证写入文件。",
      "D": "将包含凭证的文件存储在应用程序用来加载凭证的加密的Amazon S3存储桶中。定期将文件下载到应用程序，以确保使用正确的凭据。实施一个AWS Lambda函数，该函数每1天轮换一次凭证，并将这些S3凭证上传到存储桶中的文件。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Secrets Manager",
      "KMS",
      "Aurora",
      "Secrets Rotation"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地管理数据库凭据，并实现每天轮换的需求。答案是使用AWS Secrets Manager。",
      "why_correct": "选项A是最优方案。AWS Secrets Manager设计用于安全地存储和管理秘密，例如数据库凭据。它可以与KMS集成进行加密，并支持密钥轮换。将Aurora数据库与Secrets Manager关联，并配置1天的轮换周期，可以满足安全要求，并减少操作工作量。",
      "why_wrong": "选项B使用Parameter Store，无法完全满足密钥安全存储和轮换的需求。选项C使用EFS存储凭据，管理复杂且不如Secrets Manager安全。选项D使用S3，安全性和维护不如Secrets Manager。"
    },
    "related_terms": [
      "RDS",
      "Aurora MySQL",
      "EC2",
      "AWS KMS",
      "Secrets Manager",
      "KMS",
      "EFS",
      "Systems Manager Parameter Store SecureString",
      "Lambda"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 995,
    "topic": "",
    "question_cn": "一家流媒体公司正在重建其基础设施，以满足用户日常消费的视频内容日益增长的需求。该公司需要处理20TB大小的视频以阻止视频中的某些内容。视频处理最多可能需要60分钟。该公司需要一种能够根据需求扩展并保持成本效益的解决方案。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "使用AWS Lambda函数处理视频。将视频元数据存储在Amazon DynamoDB中。将视频内容存储在S3智能分层中。",
      "B": "使用Amazon Elastic Container Service (Amazon ECS)和AWS Fargate实施微服务来处理视频。将视频元数据存储在Amazon Aurora中。将视频内容存储在S3智能分层中。",
      "C": "使用应用程序负载均衡器(ALB)后面的Auto Scaling组中的Amazon EC2实例来处理视频。将视频内容存储在S3 Standard中。使用Amazon Simple Queue Service (Amazon SQS)进行排队并解耦处理任务。",
      "D": "在Amazon EC2上的Amazon Elastic Kubernetes Service (Amazon EKS)上部署容器化视频处理应用程序。将视频元数据存储在Amazon RDS中。将视频内容存储在S3 Glacier Deep Archive的单个可用区中。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Fargate",
      "Amazon ECS",
      "S3 Intelligent-Tiering"
    ],
    "explanation": {
      "analysis": "此题考察视频处理的解决方案，要求可伸缩性和成本效益。答案是使用ECS和Fargate。",
      "why_correct": "选项B使用ECS和AWS Fargate，Fargate是无服务器计算引擎，可以根据需求自动扩展。将视频内容存储在S3智能分层中可以根据访问频率自动调整存储层，优化成本。Aurora用于存储元数据，提供了高可用性和可扩展性。",
      "why_wrong": "选项A，Lambda对于长时间运行的任务不合适，而且可能因为时间限制而导致失败。选项C，使用EC2实例，运维复杂且成本较高。选项D，EKS运维复杂，Glacier Deep Archive不适合经常访问的视频内容。"
    },
    "related_terms": [
      "Lambda",
      "DynamoDB",
      "S3智能分层",
      "ECS",
      "Fargate",
      "Aurora",
      "ALB",
      "EC2",
      "SQS",
      "EKS"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 996,
    "topic": "",
    "question_cn": "一家公司在Kubernetes集群上运行本地应用程序。该公司最近增加了数百万新客户。该公司现有的本地基础设施无法处理大量新客户。该公司需要将本地应用程序迁移到AWS云上。该公司将迁移到Amazon Elastic Kubernetes Service (Amazon EKS)集群。该公司不想管理EKS上新架构的底层计算基础设施。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用EKS自我管理的节点来提供计算能力。将应用程序部署到新的EKS集群。",
      "B": "使用EKS受管节点组提供计算能力。将应用程序部署到新的EKS集群。",
      "C": "使用AWS Fargate提供计算容量。创建Fargate配置文件。使用Fargate配置文件部署应用程序。",
      "D": "将受管节点组与Karpenter一起使用来提供计算容量。将应用程序部署到新的EKS集群。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon EKS",
      "AWS Fargate",
      "Kubernetes"
    ],
    "explanation": {
      "analysis": "此题考察EKS的部署方式。答案是使用Fargate，减少运营开销。",
      "why_correct": "使用AWS Fargate可以完全托管 Kubernetes 容器运行环境。 解决方案架构师无需管理底层计算基础设施，包括 EC2 实例、操作系统和容器编排。 这种方法最大限度地减少了运营开销，并允许更专注于应用程序开发和部署。",
      "why_wrong": "选项A和B使用了EKS的受管节点组，需要运维。选项D中Karpenter虽然是自动伸缩工具，但仍需要管理节点。"
    },
    "related_terms": [
      "Kubernetes",
      "EKS",
      "Fargate",
      "EKS",
      "Karpenter"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 997,
    "topic": "",
    "question_cn": "一家公司正在推出一款新应用程序，该应用程序需要结构化数据库来存储用户配置文件、应用程序设置和事务数据。数据库必须能够随着应用程序流量进行扩展，并且必须提供备份。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用开源软件在Amazon EC2 Spot实例上部署自管理数据库。使用Spot实例来优化成本。配置自动备份到S3。",
      "B": "使用Amazon RDS。对具有通用SSD存储的数据库使用按需容量模式。配置自动备份，保留期为7天。",
      "C": "使用Amazon Aurora Serverless作为数据库。使用无服务器容量扩展。配置自动备份到S3。",
      "D": "在Amazon EC2实例上部署自我管理的NoSQL数据库。使用预留实例来优化成本。将自动备份直接配置到S3灵活检索。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon Aurora Serverless",
      "RDS Backup"
    ],
    "explanation": {
      "analysis": "此题考察数据库的选型，要求弹性伸缩和成本效益。答案是Aurora Serverless。",
      "why_correct": "选项C使用Amazon Aurora Serverless，提供了自动伸缩和自动备份到S3的功能。Aurora Serverless按照使用量计费，具有成本效益。备份自动进行，满足了备份要求。",
      "why_wrong": "选项A，EC2自管理数据库运维成本高，Spot实例不稳定。选项B，RDS按需模式，成本较高，且不具备自动弹性伸缩的能力。选项D，NoSQL数据库和S3灵活检索，不如Aurora Serverless方便，运维也较复杂。"
    },
    "related_terms": [
      "EC2",
      "RDS",
      "Aurora Serverless",
      "S3",
      "EC2",
      "NoSQL"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 998,
    "topic": "",
    "question_cn": "一家公司在AWS Web上运行其旧版Web应用程序。Web应用程序服务器在公有子网中的Amazon EC2实例上运行。Web应用程序服务器从客户收集图像并将图像文件存储在本地连接的Amazon Elastic Block Store (Amazon EBS)卷中。图像文件每天晚上上传到Amazon S3存储桶进行备份。解决方案架构师发现图像文件正在通过公共终端节点上传到Amazon S3。解决方案架构师需要确保流向Amazon S3的流量不使用公共终端节点。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "为S3存储桶创建一个具有必要权限的VPC网关终端节点。配置子网路由表以使用网关终端节点。",
      "B": "将S3存储桶移至VPC内。配置子网路由表以通过私有IP地址访问S3存储桶。",
      "C": "为VPC内的EC2实例创建S3访问点。将Web应用程序配置为使用S3访问点上传。",
      "D": "在具有EC2实例的VPC和Amazon S3之间配置AWS Direct Connect连接，以提供专用网络路径。"
    },
    "vote_percentage": null,
    "tags": [
      "VPC Endpoint",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察如何确保EC2实例与S3之间的流量不通过公网传输。答案是使用VPC网关终端节点。",
      "why_correct": "选项A，为S3存储桶创建VPC网关终端节点，可以使EC2实例通过VPC内部的私有连接访问S3，避免了公网流量，并保证了数据的安全性。",
      "why_wrong": "选项B,将S3存储桶移至VPC内，无法实现，S3桶本身并不在VPC内。选项C，S3访问点可以简化访问，但并不能解决通过公网的问题。选项D，AWS Direct Connect提供了私有网络连接，成本较高，且不适用于此简单场景。"
    },
    "related_terms": [
      "EC2",
      "EBS",
      "S3",
      "VPC",
      "S3访问点",
      "AWS Direct Connect"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 999,
    "topic": "",
    "question_cn": "一家公司正在AWS上创建电子商务网站的原型。该网站由应用程序负载均衡器、用于Web服务器的EC2实例Auto Scaling组以及使用单可用区配置运行的Amazon RDS for MySQL数据库实例组成。MySQL数据库实例在搜索产品目录时网站响应缓慢。产品目录是数据库中公司不经常更新的一组表。解决方案架构师确定，当进行产品目录搜索时，数据库实例上的CPU利用率很高。解决方案架构师应该建议什么来提高产品目录搜索期间网站的性能？",
    "options_cn": {
      "A": "将产品目录迁移到Amazon Redshift数据库。使用COPY命令加载产品目录表。",
      "B": "实施Amazon ElastiCache for Redis集群来缓存产品目录。使用延迟加载来填充缓存。",
      "C": "向Auto Scaling组添加额外的扩展策略，以便在数据库响应缓慢时启动额外的EC2实例。",
      "D": "开启数据库实例的多可用区配置。配置EC2实例以限制发送到数据库的产品目录查询。"
    },
    "vote_percentage": null,
    "tags": [
      "ElastiCache for Redis",
      "Caching"
    ],
    "explanation": {
      "analysis": "此题考察如何优化网站的产品目录搜索性能。答案是使用ElastiCache for Redis缓存。",
      "why_correct": "选项B，通过使用Amazon ElastiCache for Redis缓存产品目录，可以显著提高搜索性能。Redis是一种内存中的数据存储，速度非常快。延迟加载可以确保缓存仅在需要时才填充，避免不必要的开销。",
      "why_wrong": "选项A，Redshift适用于数据仓库，不适合网站的产品目录搜索。选项C，扩展EC2实例，无法解决数据库的负载问题，且增加了成本。选项D，开启多可用区配置，无法解决数据库负载问题，并且增加了成本，并且限制查询会影响功能。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "Auto Scaling",
      "RDS",
      "MySQL",
      "ElastiCache for Redis",
      "ElastiCache",
      "Redshift"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1000,
    "topic": "",
    "question_cn": "一家公司目前在本地块存储系统中存储了5 TB的数据。该公司当前的存储解决方案为额外数据提供的空间有限。该公司在本地运行的应用程序必须能够以低延迟检索经常访问的数据。该公司需要基于云的存储解决方案。哪种解决方案能够以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "使用Amazon S3文件网关。将文件网关与本地应用程序集成，以使用S3文件系统存储和直接检索文件。",
      "B": "使用AWS Storage Gateway iSCSI卷网关并将缓存卷作为iSCSI目标。",
      "C": "使用AWS Storage Gateway iSCSI卷网关并将存储卷作为iSCSI目标。",
      "D": "使用AWS Storage Gateway磁带网关。将磁带网关与本地应用程序集成以在S3中存储虚拟磁带。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Storage Gateway",
      "iSCSI",
      "File Gateway",
      "Volume Gateway"
    ],
    "explanation": {
      "analysis": "此题考察Storage Gateway的选择。答案是使用iSCSI卷网关，并配置缓存卷。",
      "why_correct": "选项B，使用iSCSI卷网关，可以作为块存储来使用，并配置缓存卷。缓存卷可以缓存常用的数据，提供低延迟的访问，满足经常访问数据的需求。这种解决方案的运营效率高，因为管理的是块存储，与本地存储的使用模式类似。",
      "why_wrong": "选项A，文件网关提供了文件接口，不如块存储效率高。选项C，使用存储卷，本地存储空间可能不够。选项D，磁带网关用于归档，不适用于经常访问的数据。"
    },
    "related_terms": [
      "S3",
      "S3 文件网关",
      "Storage Gateway",
      "iSCSI",
      "磁带网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1001,
    "topic": "",
    "question_cn": "一家公司经营送餐服务。由于最近的增长，该公司的订单处理系统在高峰流量时段遇到了扩展问题。当前架构包括Auto Scaling组中的Amazon EC2实例，用于从应用程序收集订单。Auto Scaling组中的第二组EC2实例履行订单。订单收集过程发生得很快，但订单履行过程可能需要更长的时间。数据不得因缩放事件而丢失。解决方案架构师必须确保订单收集流程和订单履行流程都能在高峰流量时段充分扩展。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "使用Amazon CloudWatch监控两个Auto Scaling组中每个实例的CPUUtilization指标。配置每个Auto Scaling组的最小容量以满足其峰值工作负载值。",
      "B": "使用Amazon CloudWatch监控两个Auto Scaling组中每个实例的CPUUtilization指标。配置CloudWatch警报以调用Simple Notification Service (Amazon SNS)主题，从而根据需要创建其他Auto Scaling组。",
      "C": "预置两个Amazon Simple Queue Service (Amazon SQS)队列。使用一个队列进行订单收集。使用第二个队列来履行订单。配置EC2实例以轮询其各自的队列。根据队列发送的通知扩展Auto Scaling组。",
      "D": "预置两个Amazon Simple Queue Service (Amazon SQS)队列。使用一个队列进行订单收集。使用第二个队列来履行订单。配置EC2实例以轮询其各自的队列。根据每个队列中的消息数量扩展Auto Scaling组。"
    },
    "vote_percentage": null,
    "tags": [
      "Amazon SQS",
      "Auto Scaling"
    ],
    "explanation": {
      "analysis": "此题考察如何构建异步，可扩展的订单处理系统。答案是使用SQS队列，并根据队列中的消息数量进行Auto Scaling。",
      "why_correct": "选项D，通过使用SQS队列，可以解耦订单收集和订单履行流程。使用两个队列，一个用于收集订单，一个用于履行订单。EC2实例轮询各自的队列，并根据队列中的消息数量自动扩展EC2实例组。 这保证了可扩展性，并防止数据丢失。",
      "why_wrong": "选项A，只配置最小容量，无法根据负载自动扩展。选项B，使用SNS，扩展方式不够灵活。选项C，根据SQS发送的通知扩展，实现过于复杂，且效果不如直接监控队列长度。"
    },
    "related_terms": [
      "Auto Scaling",
      "EC2",
      "CloudWatch",
      "CPUUtilization",
      "CloudWatch",
      "SNS",
      "SQS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1002,
    "topic": "",
    "question_cn": "一家在线游戏公司正在将用户数据存储迁移到Amazon DynamoDB，以支持公司不断增长的用户群。当前架构包括DynamoDB表，其中包含用户个人资料、成就和游戏内交易。该公司需要设计一个强大、持续可用且有弹性的DynamoDB架构，以维持用户的无缝游戏体验。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在单个区域中创建DynamoDB表。使用按需容量模式。使用全局表跨多个区域复制数据。",
      "B": "使用DynamoDB Accelerator (DAX) 缓存经常访问的数据。在单个区域中部署表并启用自动扩展。手动配置跨区域复制到其他区域。",
      "C": "在多个区域中创建DynamoDB表。使用按需容量模式。使用流在区域之间进行跨区域复制。",
      "D": "使用DynamoDB全局表进行自动多区域复制。在多个AWS区域中部署表。使用预置容量模式。启用自动扩展。"
    },
    "vote_percentage": null,
    "tags": [
      "DynamoDB Global Tables",
      "DynamoDB Capacity Modes"
    ],
    "explanation": {
      "analysis": "此题考察DynamoDB全局表的使用场景和成本效益。 社区共识认为选项D最佳，因为它提供了跨区域复制，并且支持预置容量模式和自动扩展，满足了高可用性和弹性的需求。 选项C使用流进行区域间复制，不如全局表方便；选项B，手动配置跨区域复制较为复杂；选项A，未提供多区域复制能力。",
      "why_correct": "选项D使用全局表进行自动多区域复制，简化了跨区域数据复制的配置。预置容量模式可以更好地控制成本，自动扩展可以根据负载变化调整容量，满足了游戏公司对高可用性和弹性的要求。",
      "why_wrong": "选项A在单个区域创建表，不满足多区域高可用性的要求。选项B手动配置跨区域复制，增加了运维复杂性，且未完全利用DynamoDB的特性。选项C使用流进行区域间复制，不如全局表方便，而且按需容量模式可能导致成本不可预测。"
    },
    "related_terms": [
      "DynamoDB",
      "DynamoDB",
      "按需容量模式",
      "全局表",
      "DAX",
      "自动扩展",
      "跨区域复制",
      "DynamoDB",
      "预置容量模式",
      "自动扩展"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1003,
    "topic": "",
    "question_cn": "一家公司在本地运行其媒体渲染应用程序。该公司希望降低存储成本，并将所有数据转移到Amazon S3。本地渲染应用程序需要低延迟地访问存储。该公司需要为该应用程序设计一个存储解决方案。存储解决方案必须保持所需的应用程序性能。哪种存储解决方案能够以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用Mountpoint for Amazon S3访问Amazon S3中本地应用程序的数据。",
      "B": "配置Amazon S3 文件网关以为本地应用程序提供存储。",
      "C": "将数据从Amazon S3复制到Amazon FSx for Windows File Server。配置文件网关以为本地应用程序提供存储。",
      "D": "配置本地文件服务器。使用S3 API连接到Amazon S3存储。配置应用程序以从本地文件服务器访问存储。"
    },
    "vote_percentage": null,
    "tags": [
      "S3 File Gateway",
      "S3 Mountpoint"
    ],
    "explanation": {
      "analysis": "此题考察如何通过低延迟的方式访问S3数据。 社区共识认为选项B最佳，S3 文件网关是为本地应用程序提供低延迟访问S3数据的理想选择。",
      "why_correct": "选项B，Amazon S3 文件网关通过缓存经常访问的数据，可以为本地应用程序提供低延迟的访问，同时降低存储成本。",
      "why_wrong": "选项A，Mountpoint for Amazon S3虽然可以访问S3数据，但可能不如文件网关那么适合本地应用程序。选项C，将数据复制到FSx for Windows File Server，增加了复杂性和成本。选项D，通过API访问S3，延迟较高，不适合低延迟需求。"
    },
    "related_terms": [
      "S3",
      "Mountpoint for Amazon S3",
      "S3",
      "文件网关",
      "Amazon FSx for Windows File Server",
      "S3 API"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1004,
    "topic": "",
    "question_cn": "一家公司在us-east-1区域托管其企业资源规划系统。该系统在Amazon EC2实例上运行。客户使用实例上托管的公共ERP API与系统交换信息。国际客户报告其数据中心的响应时间缓慢。哪种解决方案能够最具成本效益地缩短国际客户的响应时间？",
    "options_cn": {
      "A": "创建具有公共虚拟接口(VIF)的AWS Direct Connect连接，以提供从每个客户的数据中心到us-east-1的连接。使用Connect API ERP API网关将客户请求路由到系统。",
      "B": "在Amazon CloudFront前面设置API分配。配置CachingOptimized托管缓存策略以提高缓存效率。",
      "C": "设置AWS Global Accelerator API。为必要的端口配置侦听器。为适当的区域配置终端节点组以分配流量。在组中为us-east-1创建端点。",
      "D": "使用AWS VPN API，在区域和客户网络之间建立专用站点到站点VPN隧道。通过VPN连接将流量路由到us-east-1。"
    },
    "vote_percentage": null,
    "tags": [
      "CloudFront",
      "Global Accelerator"
    ],
    "explanation": {
      "analysis": "此题考察如何通过CDN加速全球客户的访问速度。 社区共识认为选项B是最佳方案，使用CloudFront可以缓存API响应，从而降低延迟。",
      "why_correct": "选项B，CloudFront作为内容分发网络，可以缓存API响应，缩短国际客户的响应时间，提高用户体验。",
      "why_wrong": "选项A，Direct Connect主要用于建立本地数据中心和AWS之间的连接，不能直接改善全球访问的延迟。选项C，Global Accelerator也用于加速应用程序的访问，但相比CloudFront，部署和配置相对复杂。选项D，VPN主要用于建立安全连接，不能直接提高访问速度。"
    },
    "related_terms": [
      "AWS Direct Connect",
      "us-east-1",
      "VIF",
      "Connect API",
      "ERP API",
      "CloudFront",
      "CachingOptimized",
      "AWS Global Accelerator",
      "VPN",
      "VPN"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1005,
    "topic": "",
    "question_cn": "一家公司通过在其网站上进行的调查来跟踪客户满意度。有时每小时都会有数千名客户接受调查。调查结果目前通过电子邮件发送给公司，以便公司员工可以手动查看结果并评估客户情绪。该公司希望实现客户调查流程的自动化。必须提供过去12个月的调查结果。哪种解决方案能够以最具可扩展性的方式满足这些要求？",
    "options_cn": {
      "A": "使用Amazon API Gateway将调查结果数据发送到连接到Amazon SQS队列的终端节点。创建一个AWS Lambda函数来轮询SQS队列，调用Amazon Comprehend进行情绪分析，并将结果保存到Amazon DynamoDB表。将所有记录的TTL设置为未来365天。",
      "B": "将调查结果数据发送到在Amazon EC2实例上运行的API。配置API以将调查结果存储为Amazon DynamoDB表中的新记录，调用Amazon Comprehend进行情绪分析，并将结果保存在第二个DynamoDB表中。将所有记录的TTL设置为未来365天。",
      "C": "将调查结果数据写入一个Amazon S3存储桶。使用S3 Event Notifications调用一个AWS Lambda函数来读取数据并调用Amazon Rekognition进行情绪分析。将情绪分析结果存储在第二个S3存储桶中。对每个存储桶使用S3生命周期策略，在365天后过期对象。",
      "D": "使用Amazon API Gateway将调查结果数据发送到连接到Amazon SQS队列的终端节点。配置SQS队列以调用AWS Lambda函数，该函数调用Amazon Lex进行情绪分析并将结果保存到Amazon DynamoDB表。将所有记录的TTL设置为未来365天。"
    },
    "vote_percentage": null,
    "tags": [
      "SQS",
      "Lambda",
      "DynamoDB",
      "Comprehend"
    ],
    "explanation": {
      "analysis": "此题考察自动化处理客户调查结果的解决方案。 社区共识认为选项A是最佳，它结合了API Gateway、SQS、Lambda、Comprehend和DynamoDB，实现了高度可扩展的自动化流程。",
      "why_correct": "选项A，使用API Gateway接收调查数据，将其放入SQS队列，Lambda函数从队列中消费数据，调用Comprehend进行情绪分析，并将结果存储在DynamoDB中。这种架构具有良好的可扩展性，能够处理大量的调查数据。TTL设置为365天，满足了存储12个月数据的要求。",
      "why_wrong": "选项B，在EC2实例上运行API，扩展性不如基于Lambda的解决方案。选项C，使用Rekognition进行情绪分析可能不适用，且存储结果在另一个S3桶，不太合理。选项D，使用Lex进行情绪分析不合适。"
    },
    "related_terms": [
      "API Gateway",
      "SQS",
      "Lambda",
      "Amazon Comprehend",
      "DynamoDB",
      "TTL",
      "EC2",
      "DynamoDB",
      "Amazon Comprehend",
      "S3",
      "S3 Event Notifications",
      "Lambda",
      "Amazon Comprehend"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1006,
    "topic": "",
    "question_cn": "一家公司使用AWS Systems Manager对Amazon EC2实例进行日常管理和修补。EC2实例位于应用程序负载均衡器(ALB)后面的IP地址类型目标组中。新的安全协议要求公司在补丁期间从服务中删除EC2实例。当公司尝试在下一个补丁期间遵循安全协议时，公司会在补丁窗口期间收到错误。哪种解决方案组合可以解决这些错误？ （选择两个。）",
    "options_cn": {
      "A": "将目标组的目标类型从IP地址类型更改为实例类型。",
      "B": "继续使用现有的Systems Manager文档而不进行任何更改，因为它已经过优化，可以处理ALB后面的IP地址类型目标组中的EC2实例。",
      "C": "实施AWS Systems Manager自动化文档来管理修补过程。",
      "D": "使用Systems Manager维护窗口自动从服务中删除实例以修补实例。",
      "E": "配置Systems Manager状态管理器以从服务中删除ALB实例并管理修补计划。使用运行状况检查重新路由流量。"
    },
    "vote_percentage": null,
    "tags": [
      "Systems Manager",
      "ALB",
      "Patching"
    ],
    "explanation": {
      "analysis": "此题考察如何解决ALB后端的EC2实例补丁问题。 社区共识认为选项C和D是最佳组合，使用Systems Manager的自动化文档和维护窗口，可以安全地进行实例的补丁操作。",
      "why_correct": "选项C，使用Systems Manager自动化文档来管理修补过程，可以实现补丁的自动化。选项D，使用维护窗口自动从服务中删除实例以修补实例，可以确保在补丁期间实例不会接收到流量，避免出现错误。",
      "why_wrong": "选项A，将目标类型更改为实例类型，可以解决问题，但是需要修改配置，会影响现有服务的正常运行。选项B，现有的Systems Manager文档可能不支持ALB后面的IP地址类型目标组中的实例的补丁，因为补丁过程中IP地址可能发生变化。选项E，状态管理器并不能有效解决问题，并且使用健康检查不能完全保证补丁期间的流量安全。"
    },
    "related_terms": [
      "Systems Manager",
      "EC2",
      "ALB",
      "Systems Manager",
      "Systems Manager",
      "ALB",
      "Systems Manager",
      "ALB"
    ],
    "best_answer": [
      "C",
      "D"
    ],
    "official_answer": [
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 1007,
    "topic": "",
    "question_cn": "一家医疗公司希望对来自多个客户的大量临床试验数据进行转换。公司必须从包含客户数据的关系数据库中提取数据。然后该公司将使用一系列复杂的规则来转换数据。转换完成后，该公司会将数据加载到Amazon S3。在公司将数据存储在Amazon S3中之前，所有数据都必须在处理时进行加密。所有数据都必须使用客户特定的密钥进行加密。哪种解决方案能够以最少的运营工作量满足这些要求？",
    "options_cn": {
      "A": "为每位客户创建一个AWS Glue作业。将安全配置附加到每个作业，该作业使用服务器端加密(SSE-S3)和托管密钥来加密数据。",
      "B": "为每个客户创建一个Amazon EMR集群。将安全配置附加到每个集群，该集群使用客户端加密和自定义客户端根密钥(Custom)来加密数据。",
      "C": "为每位客户创建一个AWS Glue作业。将安全配置附加到每个作业，该作业使用客户端加密和AWS KMS托管密钥来加密数据。",
      "D": "为每位客户创建一个Amazon EMR集群。将安全配置附加到每个集群，该集群使用带有AWS KMS密钥的服务器端加密(SSE-KMS)来加密数据。"
    },
    "vote_percentage": null,
    "tags": [
      "Glue",
      "EMR",
      "KMS",
      "SSE-KMS",
      "CSE-KMS"
    ],
    "explanation": {
      "analysis": "此题考察对S3数据加密的选择。 社区共识认为选项D是最优解，使用了EMR和SSE-KMS，满足了数据加密需求，并具有较少的运营工作量。",
      "why_correct": "选项D，使用EMR集群进行数据转换，并使用SSE-KMS进行服务器端加密，通过KMS管理客户特定的密钥，满足了数据加密的需求。相对于选项B而言，客户端加密需要管理密钥，增加了复杂性。选项A使用了SSE-S3和托管密钥，不能满足使用客户特定密钥进行加密的需求。选项C使用了客户端加密(CSE-KMS)，增加了密钥管理的复杂性。",
      "why_wrong": "选项A使用SSE-S3，不满足使用客户特定密钥的需求。选项B使用了客户端加密，密钥管理复杂。选项C使用了客户端加密，密钥管理复杂。"
    },
    "related_terms": [
      "AWS Glue",
      "SSE-S3",
      "EMR",
      "客户端加密",
      "AWS KMS",
      "SSE-KMS",
      "AWS Glue",
      "SSE-S3",
      "KMS"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1008,
    "topic": "",
    "question_cn": "一家公司在单个Amazon EC2按需实例上托管网站分析应用程序。该分析应用程序具有高度弹性，并且设计为在无状态模式下运行。该公司注意到该应用程序在繁忙时间显示出性能下降的迹象，并出现5xx错误。公司需要使应用程序无缝扩展。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "创建Web应用程序的Amazon EC2系统映像(AMI)。使用AMI启动第二个按需实例。使用应用程序负载均衡器在两个EC2实例之间分配负载。",
      "B": "创建Web应用程序的Amazon EC2系统映像(AMI)。使用AMI启动第二个按需实例。使用Amazon Route 53加权路由在两个EC2实例之间分配负载。",
      "C": "创建AWS Lambda函数来停止EC2实例并更改实例类型。创建Amazon CloudWatch警报以在CPU利用率超过75%时调用Lambda函数。",
      "D": "创建Web应用程序的Amazon EC2系统映像(AMI)。将启动模板应用于Auto Scaling。创建包含启动模板的Auto Scaling组。配置启动模板使用Spot队列。将应用程序负载均衡器附加到Auto Scaling组。"
    },
    "vote_percentage": null,
    "tags": [
      "Auto Scaling",
      "Load Balancing",
      "Spot Instances"
    ],
    "explanation": {
      "analysis": "此题考察EC2实例的自动伸缩方案。 社区共识认为选项D是最具成本效益的解决方案，它结合了Auto Scaling、应用程序负载均衡器和Spot实例，满足了应用程序的弹性需求。",
      "why_correct": "选项D使用Auto Scaling组和启动模板，可以根据需求自动增加或减少EC2实例的数量。使用Spot实例可以降低成本，ALB可以实现负载均衡。这种组合提供了高度的弹性和成本效益。",
      "why_wrong": "选项A和B，只使用了两个按需实例，无法满足高峰时期的负载需求，且成本较高。选项C，使用Lambda停止EC2实例，并不能实现自动扩展，也无法解决高峰时的问题。"
    },
    "related_terms": [
      "EC2",
      "AMI",
      "ALB",
      "Route 53",
      "Lambda",
      "CloudWatch",
      "CPU",
      "Auto Scaling",
      "Spot",
      "Auto Scaling",
      "ALB"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1009,
    "topic": "",
    "question_cn": "一家公司运行的环境中的数据存储在Amazon S3存储桶中。这些物品全天被频繁访问。该公司对存储在S3存储桶中的数据有严格的AWS Key Management Service (AWS KMS)数据加密要求。该公司目前使用S3进行加密。该公司希望优化与加密对象相关的成本，而不需要额外调用AWS KMS。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "通过Amazon S3托管密钥使用服务器端加密(SSE-S3)。",
      "B": "使用S3存储桶密钥通过AWS KMS密钥对新对象进行服务器端加密(SSE-KMS)。",
      "C": "通过AWS KMS客户管理的密钥使用客户端加密。",
      "D": "使用存储在AWS KMS中的客户提供的密钥(SSE-C)进行服务器端加密。"
    },
    "vote_percentage": null,
    "tags": [
      "SSE-KMS",
      "SSE-S3",
      "KMS",
      "S3 Bucket Keys"
    ],
    "explanation": {
      "analysis": "此题考察S3存储桶加密方式的选择。 社区共识认为选项B是最佳方案，它使用S3存储桶密钥和SSE-KMS，在满足加密需求的同时降低了成本。",
      "why_correct": "选项B，使用S3存储桶密钥，可以减少对KMS API的调用次数，从而降低成本。SSE-KMS使用KMS密钥进行服务器端加密，满足了加密需求。",
      "why_wrong": "选项A，SSE-S3使用S3托管的密钥，虽然简单，但无法满足需要使用KMS密钥的需求。选项C，客户端加密需要在上传数据之前进行加密，增加了复杂性。选项D，SSE-C使用客户提供的密钥，增加了密钥管理的复杂性。"
    },
    "related_terms": [
      "S3",
      "AWS Key Management Service (AWS KMS)",
      "S3",
      "SSE-S3",
      "S3",
      "KMS",
      "SSE-KMS",
      "KMS",
      "SSE-C"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1010,
    "topic": "",
    "question_cn": "一家公司在本地数据中心的虚拟机(VM)上运行多个工作负载。公司正在迅速扩张。本地数据中心无法快速扩展以满足业务需求。该公司希望将工作负载迁移到AWS。迁移具有时间敏感性。该公司希望对非关键工作负载使用直接迁移策略。哪种步骤组合可以满足这些要求？ （选择三项。）",
    "options_cn": {
      "A": "使用AWS Schema Conversion Tool (AWS SCT)收集有关虚拟机的数据。",
      "B": "使用AWS Application Migration Service(AWS Replication Agent)。在虚拟机上安装。",
      "C": "完成虚拟机的初始复制。启动测试实例以在虚拟机上执行验收测试。",
      "D": "停止虚拟机上的所有操作。启动切换实例。",
      "E": "使用AWS App2Container (A2C)收集有关虚拟机的数据。",
      "F": "使用AWS Database Migration Service (AWS DMS)迁移虚拟机。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Application Migration Service",
      "Migration"
    ],
    "explanation": {
      "analysis": "此题考察使用AWS Application Migration Service(MGN)进行VM迁移的步骤。 社区共识认为选项B、C和D是最佳组合，这些步骤描述了使用MGN迁移VM的关键流程。",
      "why_correct": "选项B，使用AWS Application Migration Service是直接迁移的关键步骤。在虚拟机上安装replication agent。 选项C，启动测试实例进行测试，验证迁移的正确性。 选项D，停止虚拟机并启动切换实例，完成迁移。 组合起来是一个完整的直接迁移方案。",
      "why_wrong": "选项A，AWS SCT主要用于数据库架构转换，不适用于虚拟机迁移。选项E，AWS App2Container(A2C)用于将应用程序容器化，不适用于直接迁移VM。 选项F，AWS DMS用于数据库迁移，不适用于虚拟机迁移。"
    },
    "related_terms": [
      "AWS Schema Conversion Tool (AWS SCT)",
      "AWS Application Migration Service(AWS Replication Agent)",
      "AWS Database Migration Service (AWS DMS)",
      "AWS App2Container (A2C)",
      "AWS DMS"
    ],
    "best_answer": [
      "B",
      "C",
      "D"
    ],
    "official_answer": [
      "B",
      "C",
      "D"
    ],
    "is_multiple": true,
    "answer_count": 3
  },
  {
    "id": 1011,
    "topic": "",
    "question_cn": "一家公司在私有子网中托管应用程序。该公司已经将该应用程序与Amazon Cognito集成。该公司使用用户池对用户进行身份验证。该公司需要修改应用程序，以便应用程序可以将用户文档安全地存储在Amazon S3存储桶中。哪种步骤组合可以安全地将Amazon S3与应用程序集成？ （选择两个。）",
    "options_cn": {
      "A": "创建Amazon Cognito身份池，以便在用户成功登录时为用户生成安全的访问令牌。",
      "B": "当用户成功登录时，使用现有的Amazon Cognito用户池为用户生成访问令牌。",
      "C": "在公司托管应用程序的同一VPC中创建S3 VPC终端节点。",
      "D": "在公司托管应用程序的VPC中创建NAT网关。向S3存储桶分配策略以拒绝任何不是从NAT网关发起的请求。",
      "E": "将策略附加到S3存储桶，仅允许从用户的IP地址进行访问。"
    },
    "vote_percentage": null,
    "tags": [
      "Cognito",
      "S3",
      "VPC Endpoint"
    ],
    "explanation": {
      "analysis": "此题考察如何安全地将应用程序与Cognito和S3集成。 社区共识认为选项A和C是最佳组合，使用身份池获取访问令牌，并使用VPC终端节点，保证安全访问。",
      "why_correct": "选项A，创建身份池生成安全访问令牌，授权用户访问S3。选项C，在VPC中创建S3 VPC终端节点，保证应用程序在私有子网中安全地访问S3，避免流量通过Internet。",
      "why_wrong": "选项B，用户池生成访问令牌，不能直接用于S3访问。 选项D，使用NAT网关，流量依然需要通过NAT网关，不如VPC终端节点安全。 选项E，仅允许从用户IP地址访问，不适用于所有情况，安全性低。"
    },
    "related_terms": [
      "S3",
      "Cognito",
      "S3",
      "Cognito",
      "S3 VPC",
      "VPC",
      "NAT网关"
    ],
    "best_answer": [
      "A",
      "C"
    ],
    "official_answer": [
      "A",
      "C"
    ],
    "is_multiple": true,
    "answer_count": 2
  },
  {
    "id": 1012,
    "topic": "",
    "question_cn": "一家公司有一个三层Web应用程序来处理客户的订单。Web层由应用程序负载均衡器(ALB)后面的Amazon EC2实例组成。处理层由Amazon Simple Queue Service (Amazon SQS)实例组成。存储层使用Amazon DynamoDB。EC2实例处理Web层和处理层的解耦。在高峰时段，一些用户报告订单处理延迟和大厅。该公司注意到，在这些延迟期间，EC2实例的CPU使用率为100%，并且SQS队列已满。高峰时间是可变且不可预测的。 公司需要提高应用程序的性能。哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "使用Amazon EC2 Auto Scaling的计划扩展在高峰使用时间期间横向扩展处理层实例。使用CPU利用率指标来确定何时进行扩展。",
      "B": "在DynamoDB后端层之前使用Amazon ElastiCache for Redis。使用目标利用率作为衡量标准来确定何时进行扩展。",
      "C": "添加Amazon CloudFront Web分配以缓存Web层的响应。使用延迟作为衡量标准来确定何时进行扩展。",
      "D": "使用Amazon EC2 Auto Scaling ApproximateNumberOfMessages属性来确定何时进行缩放。"
    },
    "vote_percentage": null,
    "tags": [
      "Auto Scaling",
      "SQS",
      "EC2",
      "ApproximateNumberOfMessages"
    ],
    "explanation": {
      "analysis": "此题考察如何提高应用程序的性能。 社区共识认为选项D是最佳方案，它利用了SQS队列消息数量来触发Auto Scaling的伸缩，解决了SQS队列满的问题。",
      "why_correct": "选项D使用Amazon EC2 Auto Scaling并使用SQS队列的ApproximateNumberOfMessages属性来确定何时进行缩放，可以根据SQS队列中的消息数量自动扩展处理层实例，从而提高应用程序的性能。",
      "why_wrong": "选项A，计划扩展无法很好地应对不可预测的高峰时段。选项B，ElastiCache for Redis用于缓存，不能解决SQS队列满的问题。选项C，CloudFront缓存Web层响应，对于解决SQS队列满的问题没有直接帮助。"
    },
    "related_terms": [
      "ALB",
      "EC2",
      "SQS",
      "DynamoDB",
      "EC2",
      "CPU",
      "SQS",
      "EC2 Auto Scaling",
      "CPU",
      "ElastiCache for Redis",
      "CloudFront",
      "ApproximateNumber"
    ],
    "best_answer": [
      "D"
    ],
    "official_answer": [
      "D"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1013,
    "topic": "",
    "question_cn": "公司的生产环境由周一至周六持续运行的Amazon EC2按需实例组成。这些实例在周日只能运行12小时，并且不能容忍中断。该公司希望优化生产环境的成本。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "为周日仅运行12小时的EC2实例购买计划预留实例。为周一至周六持续运行的EC2实例购买标准预留实例。",
      "B": "为周日仅运行12小时的EC2实例购买可转换预留实例。为周一至周六持续运行的EC2实例购买标准预留实例。",
      "C": "对周日仅运行12小时的EC2实例使用EC2 Spot实例。为周一至周六持续运行的EC2实例购买标准预留实例。",
      "D": "对周日仅运行12小时的EC2实例使用EC2 Spot实例。为周一至周六持续运行的EC2实例购买可转换预留实例。"
    },
    "vote_percentage": null,
    "tags": [
      "Reserved Instances",
      "Spot Instances",
      "Savings Plans"
    ],
    "explanation": {
      "analysis": "此题考察如何优化EC2实例的成本。 社区共识认为选项A是最具成本效益的，它使用了预留实例的计划功能，最大限度地降低了成本。",
      "why_correct": "选项A，对于周一到周六持续运行的EC2实例，使用标准预留实例可以获得较高的折扣。对于周日仅运行12小时的EC2实例，使用计划预留实例，可以根据特定的使用时长来优化成本。",
      "why_wrong": "选项B，可转换预留实例的折扣低于标准预留实例。选项C，Spot实例可能会因为中断而导致服务不可用，不满足不能容忍中断的要求。选项D，Spot实例价格波动大，不确定性高，且可转换预留实例的折扣低于标准预留实例。"
    },
    "related_terms": [
      "EC2",
      "EC2",
      "预留实例",
      "预留实例",
      "可转换预留实例",
      "标准预留实例",
      "EC2 Spot",
      "预留实例",
      "EC2 Spot",
      "可转换预留实例"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1014,
    "topic": "",
    "question_cn": "一家数字图像处理公司希望将其本地整体应用程序迁移到AWS云。作为处理工作流程的一部分，该公司处理数千张图像并生成大型文件。该公司需要一个解决方案来管理不断增长的图像处理作业。该解决方案还必须减少图像处理工作流程中的手动任务。该公司不想管理解决方案的底层基础设施。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将Amazon Elastic Container Service (Amazon ECS)与Amazon EC2 Spot实例结合使用来处理图像。配置Amazon Simple Queue Service (Amazon SQS)以编排工作流程。将处理后的文件存储在Amazon Elastic File System (Amazon EFS)中。",
      "B": "使用AWS Batch作业处理图像。使用AWS Step Functions编排工作流程。将处理后的文件存储在Amazon S3存储桶中。",
      "C": "使用AWS Lambda函数和Amazon EC2 Spot实例来处理图像。将处理后的文件存储在Amazon FSx for Windows File System中。",
      "D": "部署一组Amazon EC2实例来处理图像。使用AWS Step Functions编排工作流程。将处理后的文件存储在Amazon Elastic Block Store (Amazon EBS)卷中。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Batch",
      "Step Functions",
      "S3"
    ],
    "explanation": {
      "analysis": "此题考察图像处理工作流程的解决方案。 社区共识认为选项B是最佳方案，它结合了AWS Batch和Step Functions，并使用S3存储处理后的文件，无需管理底层基础设施。",
      "why_correct": "选项B，AWS Batch可以管理计算任务，AWS Step Functions可以编排工作流程，S3用于存储处理后的文件。这种组合无需管理底层基础设施，符合题目的要求，运营开销最少。",
      "why_wrong": "选项A，使用ECS和EFS增加了基础设施的管理复杂性。选项C，使用Lambda和Spot实例可能导致性能问题。选项D，直接部署EC2实例增加了运维工作量，并且使用了EBS，管理复杂。"
    },
    "related_terms": [
      "EC2",
      "Amazon SQS",
      "Amazon EFS",
      "AWS Batch",
      "AWS Step Functions",
      "S3",
      "AWS Lambda",
      "Amazon FSx for Windows File System"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1015,
    "topic": "",
    "question_cn": "一家公司的图像托管网站使世界各地的用户能够从其移动设备上传、查看和下载图像。该公司目前在Amazon S3存储桶中托管静态网站。由于网站越来越受欢迎，网站的性能有所下降。用户在上传和下载图像时报告了延迟问题。 公司必须提高网站的性能。哪种解决方案能够以最少的实施工作满足这些要求？",
    "options_cn": {
      "A": "为S3存储桶配置Amazon CloudFront分配以提高下载性能。启用S3传输加速以提高上传性能。",
      "B": "在多个AWS区域中配置适当大小的Amazon EC2实例。将应用程序迁移到EC2实例。使用应用程序负载均衡器在EC2实例之间平均分配网站流量。配置AWS Global Accelerator以低延迟满足全球需求。",
      "C": "配置使用S3存储桶作为源的Amazon CloudFront分配以提高下载性能。配置应用程序使用CloudFront上传图片，以提高上传性能。在多个AWS区域中创建S3存储桶。配置桶的复制规则，根据用户的位置复制用户的数据。将下载重定向到最接近每个用户S3位置的S3存储桶。",
      "D": "为S3存储桶配置AWS Global Accelerator以提高网络性能。为应用程序创建一个端点以使用Global Accelerator而不是S3存储桶。"
    },
    "vote_percentage": null,
    "tags": [
      "CloudFront",
      "S3 Transfer Acceleration",
      "Global Accelerator"
    ],
    "explanation": {
      "analysis": "此题考察如何提高图片托管网站的性能。 社区共识认为选项A是最佳方案，使用了CloudFront和S3传输加速，实现了上传和下载的加速，且实施工作量最少。",
      "why_correct": "选项A，使用CloudFront加速下载，并启用S3传输加速加速上传，可以有效地提高网站的性能，且实施工作量最少。",
      "why_wrong": "选项B，在EC2实例上部署应用程序，增加了管理复杂性。选项C，在多个区域创建S3桶并复制数据，增加了复杂性和成本。选项D，Global Accelerator可能不如CloudFront更适合静态内容的加速。"
    },
    "related_terms": [
      "S3",
      "CloudFront",
      "S3",
      "S3 Transfer Acceleration",
      "EC2",
      "ALB",
      "AWS Global Accelerator",
      "S3",
      "CloudFront",
      "CloudFront",
      "S3",
      "AWS Global Accelerator",
      "Global Accelerator"
    ],
    "best_answer": [
      "A"
    ],
    "official_answer": [
      "A"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1016,
    "topic": "",
    "question_cn": "一家公司在VPC中应用程序负载均衡器(ALB)后面的私有子网中运行应用程序。VPC具有NAT网关和Internet网关。应用程序调用Amazon S3 API来存储对象。根据公司的安全政策，来自应用程序的流量不得通过互联网传输。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "配置Amazon S3接口端点。创建允许出站流量流向S3的安全组。",
      "B": "配置S3 VPC网关端点。更新路由表以使用终端节点。",
      "C": "配置存储桶策略以允许来自分配给NAT网关的弹性IP地址的流量。",
      "D": "在部署旧应用程序的同一子网中创建第二个NAT网关。更新路由表以使用第二个NAT网关。"
    },
    "vote_percentage": null,
    "tags": [
      "VPC Endpoint",
      "S3",
      "NAT Gateway"
    ],
    "explanation": {
      "analysis": "此题考察如何在VPC中安全地访问S3。 社区共识认为选项B是最佳方案，使用S3 VPC网关端点，避免了流量经过Internet。",
      "why_correct": "选项B，配置S3 VPC网关端点，允许应用程序通过VPC直接访问S3，流量不会经过Internet，满足安全要求。更新路由表以使用终端节点，确保流量路由正确。",
      "why_wrong": "选项A，接口端点增加了成本，并且不如网关端点简单。选项C，使用NAT网关，流量依然需要通过NAT网关，不如VPC终端节点安全。选项D，创建第二个NAT网关，没有必要，而且增加了复杂性。"
    },
    "related_terms": [
      "ALB",
      "VPC",
      "NAT网关",
      "S3",
      "S3",
      "S3",
      "S3 VPC",
      "NAT网关"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1017,
    "topic": "",
    "question_cn": "一家公司有一个在Amazon EC2实例上的Amazon Elastic Kubernetes Service (Amazon EKS)集群上运行的应用程序。该应用程序具有使用Amazon DynamoDB和Amazon S3的数据服务。公司必须确保UI只能访问Amazon S3，并且数据服务的EKS Pod只能访问Amazon DynamoDB。该公司使用AWS Identity and Access Management (IAM)。 哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "使用所需权限为Amazon S3和Amazon DynamoDB访问创建单独的IAM策略。将两个IAM策略附加到EC2实例配置文件。使用基于角色的访问控制(RBAC)来控制各个EKS Pod对Amazon S3或Amazon DynamoDB的访问。",
      "B": "为具有所需权限的Amazon S3和Amazon DynamoDB访问创建单独的IAM策略。将IAM策略直接附加到数据服务的EKS Pod和UI的EKS Pod。",
      "C": "为UI和数据服务创建单独的服务帐户以承担IAM角色。将AmazonS3FullAccess策略附加到UI服务帐户，并将AmazonDynamoDBFullAccess策略附加到数据服务账户。",
      "D": "为UI和数据服务创建单独的服务帐户以承担IAM角色。使用服务帐户的IAM角色提供对用于EKS Pod的Amazon S3和用于数据服务的Amazon DynamoDB的访问。"
    },
    "vote_percentage": null,
    "tags": [
      "IAM Roles for Service Accounts (IRSA)",
      "EKS IAM Permissions"
    ],
    "explanation": {
      "analysis": "此题考察EKS集群中IAM权限的配置。选项C通过为UI和数据服务创建单独的服务账户，并分别附加AmazonS3FullAccess和AmazonDynamoDBFullAccess策略，满足了题目对权限隔离的需求。",
      "why_correct": "选项C通过创建服务账户并附加特定于服务的策略，实现了最小权限原则，确保了UI和数据服务只能访问其所需资源，符合安全最佳实践。",
      "why_wrong": "选项A:  将IAM策略附加到EC2实例配置文件过于宽泛，无法实现精细的权限控制；选项B: 将IAM策略直接附加到Pod会增加管理复杂性；选项D: 缺少对UI和数据服务正确权限的定义，无法满足题目要求。"
    },
    "related_terms": [
      "EKS",
      "DynamoDB",
      "S3",
      "IAM",
      "S3",
      "DynamoDB",
      "IAM",
      "IAM",
      "EC2",
      "EKS",
      "DynamoDB",
      "IAM",
      "IAM",
      "EKS",
      "IAM",
      "UI",
      "服务帐户",
      "IAM",
      "S3",
      "服务帐户"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1018,
    "topic": "",
    "question_cn": "AWS公司需要让分布在全球的开发团队以符合安全策略的方式安全地访问公司的AWS资源。该公司当前使用本地Active Directory进行内部身份验证。该公司使用AWS Organizations管理支持多个项目的多个AWS账户。该公司需要一个解决方案来与现有基础设施集成，以提供集中的身份管理和访问控制。 哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "设置AWS Directory Service以在AWS上创建托管的Microsoft Active Directory。与本地Active Directory建立信任关系。使用分配给Active Directory组的IAM记录来访问公司AWS账户内的资源。",
      "B": "为每个开发人员创建一个IAM用户。根据每个用户对每个项目的参与情况，手动管理每个IAM用户的权限。实施多重身份验证(MFA)作为额外的安全层。",
      "C": "使用AD Connector中的AWS Directory Service连接到本地Active Directory。将AD Connector与AWS IAM Identity Center集成。配置权限集以授予每个Active Directory组对特定AWS账户和资源的访问权限。",
      "D": "使用Amazon Cognito部署身份联合解决方案。将身份联合解决方案与本地Active Directory集成。使用Amazon Cognito为开发人员提供访问令牌以访问AWS账户和资源。"
    },
    "vote_percentage": null,
    "tags": [
      "AWS Directory Service",
      "IAM Identity Center"
    ],
    "explanation": {
      "analysis": "此题考察如何通过AWS服务与本地Active Directory集成，实现集中身份管理和访问控制。选项C使用AD Connector连接到本地Active Directory，并与IAM Identity Center集成，提供了最简洁的方案。",
      "why_correct": "选项C利用AD Connector连接到现有的Active Directory，并与IAM Identity Center集成。IAM Identity Center提供了集中管理用户、组和权限的平台，减少了运营开销，简化了管理流程。",
      "why_wrong": "选项A：创建托管的Microsoft Active Directory会增加复杂性。选项B: 手动管理IAM用户和权限难以扩展，且容易出错。选项D: Amazon Cognito适用于用户身份管理，但在此场景下不如IAM Identity Center。"
    },
    "related_terms": [
      "AWS",
      "AWS Organizations",
      "AWS",
      "AWS Directory Service",
      "Active Directory",
      "IAM",
      "Active Directory",
      "MFA",
      "AD Connector",
      "AWS Directory Service",
      "IAM Identity Center",
      "Active Directory"
    ],
    "best_answer": [
      "C"
    ],
    "official_answer": [
      "C"
    ],
    "is_multiple": false,
    "answer_count": 1
  },
  {
    "id": 1019,
    "topic": "",
    "question_cn": "一家公司正在云中开发应用程序。应用程序的HTTP API包含在Amazon API Gateway中发布的关键信息。必须只能从属于公司IP内部网络的一组有限的可信地址访问关键信息。 哪种解决方案可以满足这些要求？",
    "options_cn": {
      "A": "设置API Gateway私有集成以限制对一组预定义IP地址的访问。",
      "B": "为API创建资源策略，拒绝访问任何未明确允许的IP地址。",
      "C": "直接将API部署在私有子网中。创建网络ACL。设置规则以允许来自特定IP地址的流量。",
      "D": "修改附加到API Gateway的安全组，以仅允许来自受信任IP地址的入站流量。"
    },
    "vote_percentage": null,
    "tags": [
      "API Gateway Resource Policy",
      "IP Address Restriction"
    ],
    "explanation": {
      "analysis": "此题考察如何限制对API Gateway API的访问。选项B通过使用资源策略，明确拒绝所有未被允许的IP地址，实现了最安全的访问控制。",
      "why_correct": "选项B通过使用API Gateway资源策略，可以细粒度地控制对API的访问，明确拒绝来自未授权IP地址的请求，符合安全最佳实践。",
      "why_wrong": "选项A:  私有集成主要用于与VPC中的资源交互，而不是IP地址限制。选项C: 使用网络ACL可以实现IP地址限制，但增加了复杂性，且效率不如资源策略。选项D: 安全组主要用于控制EC2实例的访问，不适用于API Gateway。"
    },
    "related_terms": [
      "API Gateway",
      "API",
      "API Gateway",
      "IP"
    ],
    "best_answer": [
      "B"
    ],
    "official_answer": [
      "B"
    ],
    "is_multiple": false,
    "answer_count": 1
  }
]