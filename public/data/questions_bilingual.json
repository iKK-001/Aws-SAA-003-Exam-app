[
  {
    "id": 1,
    "topic": "1",
    "question_en": "A company collects data for temperature, humidity, and atmospheric pressure in cities across multiple continents. The average volume of data that the company collects from each site daily is 500 GB. Each site has a high-speed Internet connection. The company wants to aggregate the data from all these global sites as quickly as possible in a single Amazon S3 bucket. The solution must minimize operational complexity. Which solution meets these requirements?",
    "options_en": {
      "A": "Turn on S3 Transfer Acceleration on the destination S3 bucket. Use multipart uploads to directly upload site data to the destination S3 bucket.",
      "B": "Upload the data from each site to an S3 bucket in the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket. Then remove the data from the origin S3 bucket.",
      "C": "Schedule AWS Snowball Edge Storage Optimized device jobs daily to transfer data from each site to the closest Region. Use S3 Cross- Region Replication to copy objects to the destination S3 bucket.",
      "D": "Upload the data from each site to an Amazon EC2 instance in the closest Region. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. At regular intervals, take an EBS snapshot and copy it to the Region that contains the destination S3 bucket. Restore the EBS volume in that Region."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一家公司收集了全球多个大陆城市的气温、湿度和大气压力数据。该公司每天从每个站点收集的平均数据量为 500 GB。每个站点都有高速互联网连接。该公司希望尽快将来自所有这些全球站点的数据聚合到单个 Amazon S3 存储桶中。解决方案必须最大限度地减少运营复杂性。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "在目标 S3 存储桶上打开 S3 Transfer Acceleration。使用 multipart uploads 将站点数据直接上传到目标 S3 存储桶。",
      "B": "将每个站点的数据上传到最近区域的 S3 存储桶。使用 S3 跨区域复制将对象复制到目标 S3 存储桶。然后从源 S3 存储桶中删除数据。",
      "C": "每天安排 AWS Snowball Edge 存储优化设备作业，将每个站点的数据传输到最近的区域。使用 S3 跨区域复制将对象复制到目标 S3 存储桶。",
      "D": "将每个站点的数据上传到最近区域的 Amazon EC2 实例。将数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。定期间隔拍摄 EBS 快照并将其复制到包含目标 S3 存储桶的区域。在该区域恢复 EBS 卷。"
    }
  },
  {
    "id": 2,
    "topic": "1",
    "question_en": "A company needs the ability to analyze the log files of its proprietary application. The logs are stored in JSON format in an Amazon S3 bucket. Queries will be simple and will run on-demand. A solutions architect needs to perform the analysis with minimal changes to the existing architecture. What should the solutions architect do to meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Use Amazon Redshift to load all the content into one place and run the SQL queries as needed.",
      "B": "Use Amazon CloudWatch Logs to store the logs. Run SQL queries as needed from the Amazon CloudWatch console.",
      "C": "Use Amazon Athena directly with Amazon S3 to run the queries as needed.",
      "D": "Use AWS Glue to catalog the logs. Use a transient Apache Spark cluster on Amazon EMR to run the SQL queries as needed."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要分析其专有应用程序的日志文件。 日志以 JSON 格式存储在 Amazon S3 存储桶中。 查询将很简单，并将按需运行。 解决方案架构师需要以最少的现有架构更改来执行分析。 解决方案架构师应该怎么做才能以最少的运营开销来满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Redshift 将所有内容加载到一个位置，并根据需要运行 SQL 查询。",
      "B": "使用 Amazon CloudWatch Logs 存储日志。 从 Amazon CloudWatch 控制台根据需要运行 SQL 查询。",
      "C": "直接将 Amazon Athena 与 Amazon S3 结合使用，以根据需要运行查询。",
      "D": "使用 AWS Glue 编目日志。 使用 Amazon EMR 上的瞬时 Apache Spark 集群，以根据需要运行 SQL 查询。"
    }
  },
  {
    "id": 3,
    "topic": "1",
    "question_en": "A company uses AWS Organizations to manage multiple AWS accounts for different departments. The management account has an Amazon S3 bucket that contains project reports. The company wants to limit access to this S3 bucket to only users of accounts within the organization in AWS Organizations. Which solution meets these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Add the aws PrincipalOrgID global condition key with a reference to the organization ID to the S3 bucket policy.",
      "B": "Create an organizational unit (OU) for each department. Add the aws:PrincipalOrgPaths global condition key to the S3 bucket policy.",
      "C": "Use AWS CloudTrail to monitor the CreateAccount, InviteAccountToOrganization, LeaveOrganization, and RemoveAccountFromOrganization events. Update the S3 bucket policy accordingly.",
      "D": "Tag each user that needs access to the S3 bucket. Add the aws:PrincipalTag global condition key to the S3 bucket policy."
    },
    "correct_answer": "A",
    "vote_percentage": "97%",
    "question_cn": "一家公司使用 AWS Organizations 为不同部门管理多个 AWS 账户。管理账户有一个 Amazon S3 存储桶，其中包含项目报告。该公司希望将对该 S3 存储桶的访问权限限制为 AWS Organizations 中组织内的账户用户。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将 `aws:PrincipalOrgID` 全局条件键与对组织 ID 的引用添加到 S3 存储桶策略中。",
      "B": "为每个部门创建一个组织单元 (OU)。将 `aws:PrincipalOrgPaths` 全局条件键添加到 S3 存储桶策略中。",
      "C": "使用 AWS CloudTrail 监控 `CreateAccount`、`InviteAccountToOrganization`、`LeaveOrganization` 和 `RemoveAccountFromOrganization` 事件。相应地更新 S3 存储桶策略。",
      "D": "标记每个需要访问 S3 存储桶的用户。将 `aws:PrincipalTag` 全局条件键添加到 S3 存储桶策略中。"
    }
  },
  {
    "id": 4,
    "topic": "1",
    "question_en": "An application runs on an Amazon EC2 instance in a VPC. The application processes logs that are stored in an Amazon S3 bucket. The EC2 instance needs to access the S3 bucket without connectivity to the internet. Which solution will provide private network connectivity to Amazon S3?",
    "options_en": {
      "A": "Create a gateway VPC endpoint to the S3 bucket.",
      "B": "Stream the logs to Amazon CloudWatch Logs. Export the logs to the S3 bucket.",
      "C": "Create an instance profile on Amazon EC2 to allow S3 access.",
      "D": "Create an Amazon API Gateway API with a private link to access the S3 endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一个应用程序在 VPC 中的 Amazon EC2 实例上运行。该应用程序处理存储在 Amazon S3 存储桶中的日志。EC2 实例需要在没有互联网连接的情况下访问 S3 存储桶。哪种解决方案将提供到 Amazon S3 的私有网络连接？",
    "options_cn": {
      "A": "创建到 S3 存储桶的网关 VPC endpoint。",
      "B": "将日志流式传输到 Amazon CloudWatch Logs。将日志导出到 S3 存储桶。",
      "C": "在 Amazon EC2 上创建实例配置文件以允许访问 S3。",
      "D": "创建一个 Amazon API Gateway API，该 API 具有一个私有链接来访问 S3 endpoint。"
    }
  },
  {
    "id": 5,
    "topic": "1",
    "question_en": "A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time. What should a solutions architect propose to ensure users see all of their documents at once?",
    "options_en": {
      "A": "Copy the data so both EBS volumes contain all the documents",
      "B": "Configure the Application Load Balancer to direct a user to the server with the documents",
      "C": "Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS",
      "D": "Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server"
    },
    "correct_answer": "C",
    "vote_percentage": "98%",
    "question_cn": "一家公司使用单个 Amazon EC2 实例在 AWS 上托管一个 Web 应用程序，该实例将用户上传的文档存储在 Amazon EBS 卷中。为了提高可扩展性和可用性，该公司复制了架构，并在另一个可用区中创建了第二个 EC2 实例和 EBS 卷，并将两者置于一个 Application Load Balancer 之后。完成此更改后，用户报告说，每次刷新网站时，他们只能看到文档的一个子集，但永远无法同时看到所有文档。解决方案架构师应该提出什么建议来确保用户一次看到他们的所有文档？",
    "options_cn": {
      "A": "复制数据，使两个 EBS 卷都包含所有文档",
      "B": "配置 Application Load Balancer，将用户定向到包含文档的服务器",
      "C": "将数据从两个 EBS 卷复制到 Amazon EFS。修改应用程序以将新文档保存到 Amazon EFS",
      "D": "配置 Application Load Balancer 将请求发送到两台服务器。从正确的服务器返回每个文档"
    }
  },
  {
    "id": 6,
    "topic": "1",
    "question_en": "A company uses NFS to store large video files in on-premises network attached storage. Each video file ranges in size from 1 MB to 500 GB. The total storage is 70 TB and is no longer growing. The company decides to migrate the video files to Amazon S3. The company must migrate the video files as soon as possible while using the least possible network bandwidth. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an S3 bucket. Create an IAM role that has permissions to write to the S3 bucket. Use the AWS CLI to copy all files locally to the S3 bucket.",
      "B": "Create an AWS Snowball Edge job. Receive a Snowball Edge device on premises. Use the Snowball Edge client to transfer data to the device. Return the device so that AWS can import the data into Amazon S3.",
      "C": "Deploy an S3 File Gateway on premises. Create a public service endpoint to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway.",
      "D": "Set up an AWS Direct Connect connection between the on-premises network and AWS. Deploy an S3 File Gateway on premises. Create a public virtual interface (VIF) to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway."
    },
    "correct_answer": "C",
    "vote_percentage": "86%",
    "question_cn": "一家公司使用 NFS 在本地网络附加存储中存储大型视频文件。每个视频文件的大小范围为 1 MB 到 500 GB。总存储量为 70 TB，并且不再增长。该公司决定将视频文件迁移到 Amazon S3。该公司必须尽快迁移视频文件，同时使用最少的网络带宽。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建 S3 存储桶。创建一个具有写入 S3 存储桶权限的 IAM 角色。使用 AWS CLI 将所有文件本地复制到 S3 存储桶。",
      "B": "创建一个 AWS Snowball Edge 作业。在本地接收 Snowball Edge 设备。使用 Snowball Edge 客户端将数据传输到该设备。返回该设备，以便 AWS 可以将数据导入 Amazon S3。",
      "C": "在本地部署一个 S3 文件网关。创建公共服务终端节点以连接到 S3 文件网关。创建一个 S3 存储桶。在 S3 文件网关上创建一个新的 NFS 文件共享。将新的文件共享指向 S3 存储桶。将数据从现有的 NFS 文件共享传输到 S3 文件网关。",
      "D": "在本地网络和 AWS 之间设置 AWS Direct Connect 连接。在本地部署一个 S3 文件网关。创建公共虚拟接口 (VIF) 以连接到 S3 文件网关。创建一个 S3 存储桶。在 S3 文件网关上创建一个新的 NFS 文件共享。将新的文件共享指向 S3 存储桶。将数据从现有的 NFS 文件共享传输到 S3 文件网关。"
    }
  },
  {
    "id": 7,
    "topic": "1",
    "question_en": "A company has an application that ingests incoming messages. Dozens of other applications and microservices then quickly consume these messages. The number of messages varies drastically and sometimes increases suddenly to 100,000 each second. The company wants to decouple the solution and increase scalability. Which solution meets these requirements?",
    "options_en": {
      "A": "Persist the messages to Amazon Kinesis Data Analytics. Configure the consumer applications to read and process the messages.",
      "B": "Deploy the ingestion application on Amazon EC2 instances in an Auto Scaling group to scale the number of EC2 instances based on CPU metrics.",
      "C": "Write the messages to Amazon Kinesis Data Streams with a single shard. Use an AWS Lambda function to preprocess messages and store them in Amazon DynamoDB. Configure the consumer applications to read from DynamoDB to process the messages.",
      "D": "Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SOS) subscriptions. Configure the consumer applications to process the messages from the queues."
    },
    "correct_answer": "A",
    "vote_percentage": "83%",
    "question_cn": "一家公司有一个摄取传入消息的应用程序。 随后，数十个其他应用程序和微服务会快速使用这些消息。消息数量变化很大，有时会突然增加到每秒 100,000 条。该公司希望解耦该解决方案并提高可扩展性。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将消息持久化到 Amazon Kinesis Data Analytics。配置消费者应用程序来读取和处理这些消息。",
      "B": "在 Auto Scaling 组中的 Amazon EC2 实例上部署摄取应用程序，以根据 CPU 指标扩展 EC2 实例的数量。",
      "C": "将消息写入具有单个分片的 Amazon Kinesis Data Streams。 使用 AWS Lambda 函数预处理消息并将其存储在 Amazon DynamoDB 中。 配置消费者应用程序从 DynamoDB 读取以处理消息。",
      "D": "将消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题，并带有多个 Amazon Simple Queue Service (Amazon SQS) 订阅。 配置消费者应用程序从队列中处理消息。"
    }
  },
  {
    "id": 8,
    "topic": "1",
    "question_en": "A company is migrating a distributed application to AWS. The application serves variable workloads. The legacy platform consists of a primary server that coordinates jobs across multiple compute nodes. The company wants to modernize the application with a solution that maximizes resiliency and scalability. How should a solutions architect design the architecture to meet these requirements?",
    "options_en": {
      "A": "Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling to use scheduled scaling.",
      "B": "Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling based on the size of the queue.",
      "C": "Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure AWS CloudTrail as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the primary server.",
      "D": "Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure Amazon EventBridge (Amazon CloudWatch Events) as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the compute nodes."
    },
    "correct_answer": "C",
    "vote_percentage": "93%",
    "question_cn": "一家公司正在将分布式应用程序迁移到 AWS。该应用程序处理可变的工作负载。传统平台由一个主服务器组成，该服务器协调多个计算节点上的作业。该公司希望使用能够最大程度提高弹性和可扩展性的解决方案来现代化应用程序。解决方案架构师应如何设计架构以满足这些要求？",
    "options_cn": {
      "A": "将 Amazon Simple Queue Service (Amazon SQS) 队列配置为作业的目的地。使用 Amazon EC2 实例实现计算节点，这些实例在 Auto Scaling 组中进行管理。配置 EC2 Auto Scaling 以使用计划扩展。",
      "B": "将 Amazon Simple Queue Service (Amazon SQS) 队列配置为作业的目的地。使用 Amazon EC2 实例实现计算节点，这些实例在 Auto Scaling 组中进行管理。根据队列的大小配置 EC2 Auto Scaling。",
      "C": "使用 Amazon EC2 实例实现主服务器和计算节点，这些实例在 Auto Scaling 组中进行管理。将 AWS CloudTrail 配置为作业的目的地。根据主服务器上的负载配置 EC2 Auto Scaling。",
      "D": "使用 Amazon EC2 实例实现主服务器和计算节点，这些实例在 Auto Scaling 组中进行管理。将 Amazon EventBridge (Amazon CloudWatch Events) 配置为作业的目的地。根据计算节点上的负载配置 EC2 Auto Scaling。"
    }
  },
  {
    "id": 9,
    "topic": "1",
    "question_en": "A company is running an SMB file server in its data center. The file server stores large files that are accessed frequently for the first few days after the files are created. After 7 days the files are rarely accessed. The total data size is increasing and is close to the company's total storage capacity. A solutions architect must increase the company's available storage space without losing low-latency access to the most recently accessed files. The solutions architect must also provide file lifecycle management to avoid future storage issues. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.",
      "B": "Create an Amazon S3 File Gateway to extend the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.",
      "C": "Create an Amazon FSx for Windows File Server file system to extend the company's storage space.",
      "D": "Install a utility on each user's computer to access Amazon S3. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days."
    },
    "correct_answer": "D",
    "vote_percentage": "83%",
    "question_cn": "一家公司在其数据中心运行 SMB 文件服务器。该文件服务器存储大文件，这些文件在创建后的头几天会被频繁访问。7 天后，文件很少被访问。总数据大小正在增加，并且接近公司的总存储容量。一位解决方案架构师必须增加公司可用的存储空间，同时又不失去对最近访问文件的低延迟访问。解决方案架构师还必须提供文件生命周期管理，以避免未来的存储问题。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 将超过 7 天的数据从 SMB 文件服务器复制到 AWS。",
      "B": "创建一个 Amazon S3 File Gateway 来扩展公司的存储空间。创建 S3 生命周期策略，在 7 天后将数据转换为 S3 Glacier Deep Archive。",
      "C": "创建一个 Amazon FSx for Windows File Server 文件系统来扩展公司的存储空间。",
      "D": "在每个用户的计算机上安装一个实用程序以访问 Amazon S3。创建 S3 生命周期策略，在 7 天后将数据转换为 S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 10,
    "topic": "1",
    "question_en": "A company is building an ecommerce web application on AWS. The application sends information about new orders to an Amazon API Gateway REST API to process. The company wants to ensure that orders are processed in the order that they are received. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an API Gateway integration to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when the application receives an order. Subscribe an AWS Lambda function to the topic to perform processing.",
      "B": "Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) FIFO queue when the application receives an order. Configure the SQS FIFO queue to invoke an AWS Lambda function for processing.",
      "C": "Use an API Gateway authorizer to block any requests while the application processes an order.",
      "D": "Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) standard queue when the application receives an order. Configure the SQS standard queue to invoke an AWS Lambda function for processing."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一家公司正在 AWS 上构建一个电子商务 Web 应用程序。该应用程序将有关新订单的信息发送到 Amazon API Gateway REST API 进行处理。该公司希望确保订单按照接收顺序进行处理。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 API Gateway 集成将消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题，当应用程序收到订单时。将 AWS Lambda 函数订阅到该主题以执行处理。",
      "B": "使用 API Gateway 集成将消息发送到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列，当应用程序收到订单时。配置 SQS FIFO 队列以调用 AWS Lambda 函数进行处理。",
      "C": "使用 API Gateway 授权程序阻止任何请求，同时应用程序处理订单。",
      "D": "使用 API Gateway 集成将消息发送到 Amazon Simple Queue Service (Amazon SQS) 标准队列，当应用程序收到订单时。配置 SQS 标准队列以调用 AWS Lambda 函数进行处理。"
    }
  },
  {
    "id": 11,
    "topic": "1",
    "question_en": "A company has an application that runs on Amazon EC2 instances and uses an Amazon Aurora database. The EC2 instances connect to the database by using user names and passwords that are stored locally in a file. The company wants to minimize the operational overhead of credential management. What should a solutions architect do to accomplish this goal?",
    "options_en": {
      "A": "Use AWS Secrets Manager. Turn on automatic rotation.",
      "B": "Use AWS Systems Manager Parameter Store. Turn on automatic rotation.",
      "C": "Create an Amazon S3 bucket to store objects that are encrypted with an AWS Key Management Service (AWS KMS) encryption key. Migrate the credential file to the S3 bucket. Point the application to the S3 bucket.",
      "D": "Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume for each EC2 instance. Attach the new EBS volume to each EC2 instance. Migrate the credential file to the new EBS volume. Point the application to the new EBS volume."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司有一个在 Amazon EC2 实例上运行并使用 Amazon Aurora 数据库的应用程序。 EC2 实例通过使用本地存储在文件中的用户名和密码来连接到数据库。该公司希望最大限度地减少凭据管理的运营开销。解决方案架构师应该怎么做才能实现此目标？",
    "options_cn": {
      "A": "使用 AWS Secrets Manager。 打开自动轮换。",
      "B": "使用 AWS Systems Manager Parameter Store。 打开自动轮换。",
      "C": "创建一个 Amazon S3 存储桶来存储使用 AWS Key Management Service (AWS KMS) 加密密钥加密的对象。 将凭据文件迁移到 S3 存储桶。 将应用程序指向 S3 存储桶。",
      "D": "为每个 EC2 实例创建一个加密的 Amazon Elastic Block Store (Amazon EBS) 卷。 将新的 EBS 卷附加到每个 EC2 实例。 将凭据文件迁移到新的 EBS 卷。 将应用程序指向新的 EBS 卷。"
    }
  },
  {
    "id": 12,
    "topic": "1",
    "question_en": "A global company hosts its web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The web application has static data and dynamic data. The company stores its static data in an Amazon S3 bucket. The company wants to improve performance and reduce latency for the static data and dynamic data. The company is using its own domain name registered with Amazon Route 53. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins. Configure Route 53 to route trafic to the CloudFront distribution.",
      "B": "Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint Configure Route 53 to route trafic to the CloudFront distribution.",
      "C": "Create an Amazon CloudFront distribution that has the S3 bucket as an origin. Create an AWS Global Accelerator standard accelerator that has the ALB and the CloudFront distribution as endpoints. Create a custom domain name that points to the accelerator DNS name. Use the custom domain name as an endpoint for the web application.",
      "D": "Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint. Create two domain names. Point one domain name to the CloudFront DNS name for dynamic content. Point the other domain name to the accelerator DNS name for static content. Use the domain names as endpoints for the web application."
    },
    "correct_answer": "C",
    "vote_percentage": "80%",
    "question_cn": "一家全球公司将其 Web 应用程序托管在 Application Load Balancer (ALB) 后的 Amazon EC2 实例上。该 Web 应用程序包含静态数据和动态数据。该公司将其静态数据存储在 Amazon S3 存储桶中。该公司希望提高静态数据和动态数据的性能并减少延迟。该公司正在使用其在 Amazon Route 53 中注册的自己的域名。解决方案架构师应采取什么措施来满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon CloudFront 分发，该分发将 S3 存储桶和 ALB 作为源。配置 Route 53 以将流量路由到 CloudFront 分发。",
      "B": "创建一个 Amazon CloudFront 分发，该分发将 ALB 作为源。创建一个 AWS Global Accelerator 标准加速器，该加速器将 S3 存储桶作为端点。配置 Route 53 以将流量路由到 CloudFront 分发。",
      "C": "创建一个 Amazon CloudFront 分发，该分发将 S3 存储桶作为源。创建一个 AWS Global Accelerator 标准加速器，该加速器将 ALB 和 CloudFront 分发作为端点。创建一个指向加速器 DNS 域名的自定义域名。使用自定义域名作为 Web 应用程序的端点。",
      "D": "创建一个 Amazon CloudFront 分发，该分发将 ALB 作为源。创建一个 AWS Global Accelerator 标准加速器，该加速器将 S3 存储桶作为端点。创建两个域名。将一个域名指向 CloudFront DNS 域名，用于动态内容。将另一个域名指向加速器 DNS 域名，用于静态内容。使用这些域名作为 Web 应用程序的端点。"
    }
  },
  {
    "id": 13,
    "topic": "1",
    "question_en": "A company performs monthly maintenance on its AWS infrastructure. During these maintenance activities, the company needs to rotate the credentials for its Amazon RDS for MySQL databases across multiple AWS Regions. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the credentials as secrets in AWS Secrets Manager. Use multi-Region secret replication for the required Regions. Configure Secrets Manager to rotate the secrets on a schedule.",
      "B": "Store the credentials as secrets in AWS Systems Manager by creating a secure string parameter. Use multi-Region secret replication for the required Regions. Configure Systems Manager to rotate the secrets on a schedule.",
      "C": "Store the credentials in an Amazon S3 bucket that has server-side encryption (SSE) enabled. Use Amazon EventBridge (Amazon CloudWatch Events) to invoke an AWS Lambda function to rotate the credentials.",
      "D": "Encrypt the credentials as secrets by using AWS Key Management Service (AWS KMS) multi-Region customer managed keys. Store the secrets in an Amazon DynamoDB global table. Use an AWS Lambda function to retrieve the secrets from DynamoDB. Use the RDS API to rotate the secrets."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司每月对其 AWS 基础设施进行维护。在这些维护活动期间，该公司需要轮换其跨多个 AWS 区域的 Amazon RDS for MySQL 数据库的凭证。哪种解决方案将以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "将凭证作为秘密存储在 AWS Secrets Manager 中。对所需区域使用多区域秘密复制。配置 Secrets Manager 以按计划轮换秘密。",
      "B": "通过创建安全字符串参数，将凭证作为秘密存储在 AWS Systems Manager 中。对所需区域使用多区域秘密复制。配置 Systems Manager 以按计划轮换秘密。",
      "C": "将凭证存储在已启用服务器端加密 (SSE) 的 Amazon S3 存储桶中。使用 Amazon EventBridge (Amazon CloudWatch Events) 调用 AWS Lambda 函数来轮换凭证。",
      "D": "使用 AWS Key Management Service (AWS KMS) 多区域客户托管密钥将凭证加密为秘密。将秘密存储在 Amazon DynamoDB 全局表中。使用 AWS Lambda 函数从 DynamoDB 检索秘密。使用 RDS API 轮换秘密。"
    }
  },
  {
    "id": 14,
    "topic": "1",
    "question_en": "A company runs an ecommerce application on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales based on CPU utilization metrics. The ecommerce application stores the transaction data in a MySQL 8.0 database that is hosted on a large EC2 instance. The database's performance degrades quickly as application load increases. The application handles more read requests than write transactions. The company wants a solution that will automatically scale the database to meet the demand of unpredictable read workloads while maintaining high availability. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Redshift with a single node for leader and compute functionality.",
      "B": "Use Amazon RDS with a Single-AZ deployment Configure Amazon RDS to add reader instances in a different Availability Zone.",
      "C": "Use Amazon Aurora with a Multi-AZ deployment. Configure Aurora Auto Scaling with Aurora Replicas.",
      "D": "Use Amazon ElastiCache for Memcached with EC2 Spot Instances."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其Application Load Balancer后面的Amazon EC2实例上运行电子商务应用程序。这些实例在跨多个可用区的Amazon EC2 Auto Scaling组中运行。Auto Scaling组根据CPU利用率指标进行扩展。电子商务应用程序将事务数据存储在大型EC2实例上托管的MySQL 8.0数据库中。随着应用程序负载的增加，数据库的性能会迅速下降。该应用程序处理的读取请求多于写入事务。该公司希望找到一种解决方案，该方案将自动扩展数据库以满足不可预测的读取工作负载的需求，同时保持高可用性。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用具有单个节点作为领导者和计算功能的Amazon Redshift。",
      "B": "使用单可用区部署的Amazon RDS。配置Amazon RDS以在不同的可用区中添加读取器实例。",
      "C": "使用多可用区部署的Amazon Aurora。使用Aurora Replicas配置Aurora Auto Scaling。",
      "D": "使用带有EC2 Spot实例的Amazon ElastiCache for Memcached。"
    }
  },
  {
    "id": 15,
    "topic": "1",
    "question_en": "A company recently migrated to AWS and wants to implement a solution to protect the trafic that fiows in and out of the production VPC. The company had an inspection server in its on-premises data center. The inspection server performed specific operations such as trafic fiow inspection and trafic filtering. The company wants to have the same functionalities in the AWS Cloud. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon GuardDuty for trafic inspection and trafic filtering in the production VPC.",
      "B": "Use Trafic Mirroring to mirror trafic from the production VPC for trafic inspection and filtering.",
      "C": "Use AWS Network Firewall to create the required rules for trafic inspection and trafic filtering for the production VPC.",
      "D": "Use AWS Firewall Manager to create the required rules for trafic inspection and trafic filtering for the production VPC."
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "一家公司最近迁移到 AWS，并希望实施一个解决方案来保护进出生产 VPC 的流量。该公司在其本地数据中心有一个检查服务器。该检查服务器执行特定操作，例如流量流检查和流量过滤。该公司希望在 AWS 云中拥有相同的功能。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon GuardDuty 进行生产 VPC 中的流量检查和流量过滤。",
      "B": "使用 Trafic Mirroring 镜像生产 VPC 中的流量以进行流量检查和过滤。",
      "C": "使用 AWS Network Firewall 为生产 VPC 创建所需的流量检查和流量过滤规则。",
      "D": "使用 AWS Firewall Manager 为生产 VPC 创建所需的流量检查和流量过滤规则。"
    }
  },
  {
    "id": 16,
    "topic": "1",
    "question_en": "A company hosts a data lake on AWS. The data lake consists of data in Amazon S3 and Amazon RDS for PostgreSQL. The company needs a reporting solution that provides data visualization and includes all the data sources within the data lake. Only the company's management team should have full access to all the visualizations. The rest of the company should have only limited access. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate IAM roles.",
      "B": "Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups.",
      "C": "Create an AWS Glue table and crawler for the data in Amazon S3. Create an AWS Glue extract, transform, and load (ETL) job to produce reports. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports.",
      "D": "Create an AWS Glue table and crawler for the data in Amazon S3. Use Amazon Athena Federated Query to access data within Amazon RDS for PostgreSQL. Generate reports by using Amazon Athena. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports."
    },
    "correct_answer": "D",
    "vote_percentage": "83%",
    "question_cn": "一家公司在 AWS 上托管数据湖。数据湖包含 Amazon S3 和 Amazon RDS for PostgreSQL 中的数据。该公司需要一个报告解决方案，该解决方案提供数据可视化，并包含数据湖内的所有数据源。只有公司的管理团队才应该完全访问所有可视化内容。公司的其余人员应该只有有限的访问权限。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以可视化数据。与适当的 IAM 角色共享仪表板。",
      "B": "在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以可视化数据。与适当的用户和组共享仪表板。",
      "C": "为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。创建 AWS Glue 提取、转换和加载 (ETL) 作业以生成报告。将报告发布到 Amazon S3。使用 S3 存储桶策略限制对报告的访问。",
      "D": "为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。使用 Amazon Athena Federated Query 访问 Amazon RDS for PostgreSQL 中的数据。使用 Amazon Athena 生成报告。将报告发布到 Amazon S3。使用 S3 存储桶策略限制对报告的访问。"
    }
  },
  {
    "id": 17,
    "topic": "1",
    "question_en": "A company is implementing a new business application. The application runs on two Amazon EC2 instances and uses an Amazon S3 bucket for document storage. A solutions architect needs to ensure that the EC2 instances can access the S3 bucket. What should the solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Create an IAM role that grants access to the S3 bucket. Attach the role to the EC2 instances.",
      "B": "Create an IAM policy that grants access to the S3 bucket. Attach the policy to the EC2 instances.",
      "C": "Create an IAM group that grants access to the S3 bucket. Attach the group to the EC2 instances.",
      "D": "Create an IAM user that grants access to the S3 bucket. Attach the user account to the EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "99%",
    "question_cn": "一家公司正在实施一个新的业务应用程序。该应用程序在两个 Amazon EC2 实例上运行，并使用 Amazon S3 存储桶进行文档存储。解决方案架构师需要确保 EC2 实例可以访问 S3 存储桶。 解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "创建一个 IAM 角色，授予对 S3 存储桶的访问权限。将该角色附加到 EC2 实例。",
      "B": "创建一个 IAM 策略，授予对 S3 存储桶的访问权限。将该策略附加到 EC2 实例。",
      "C": "创建一个 IAM 组，授予对 S3 存储桶的访问权限。将该组附加到 EC2 实例。",
      "D": "创建一个 IAM 用户，授予对 S3 存储桶的访问权限。将该用户帐户附加到 EC2 实例。"
    }
  },
  {
    "id": 18,
    "topic": "1",
    "question_en": "An application development team is designing a microservice that will convert large images to smaller, compressed images. When a user uploads an image through the web interface, the microservice should store the image in an Amazon S3 bucket, process and compress the image with an AWS Lambda function, and store the image in its compressed form in a different S3 bucket. A solutions architect needs to design a solution that uses durable, stateless components to process the images automatically. Which combination of actions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure the S3 bucket to send a notification to the SQS queue when an image is uploaded to the S3 bucket.",
      "B": "Configure the Lambda function to use the Amazon Simple Queue Service (Amazon SQS) queue as the invocation source. When the SQS message is successfully processed, delete the message in the queue.",
      "C": "Configure the Lambda function to monitor the S3 bucket for new uploads. When an uploaded image is detected, write the file name to a text file in memory and use the text file to keep track of the images that were processed.",
      "D": "Launch an Amazon EC2 instance to monitor an Amazon Simple Queue Service (Amazon SQS) queu",
      "E": "When items are added to the queue, log the file name in a text file on the EC2 instance and invoke the Lambda function. E. Configure an Amazon EventBridge (Amazon CloudWatch Events) event to monitor the S3 bucket. When an image is uploaded, send an alert to an Amazon ample Notification Service (Amazon SNS) topic with the application owner's email address for further processing."
    },
    "correct_answer": "A",
    "vote_percentage": "99%",
    "question_cn": "一个应用程序开发团队正在设计一个微服务，该微服务会将大图像转换为较小的压缩图像。当用户通过 Web 界面上传图像时，该微服务应将图像存储在 Amazon S3 存储桶中，使用 AWS Lambda 函数处理和压缩图像，并将压缩形式的图像存储在另一个 S3 存储桶中。一个解决方案架构师需要设计一个使用持久、无状态组件自动处理图像的解决方案。哪种操作组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。配置 S3 存储桶，以便在将图像上传到 S3 存储桶时，将通知发送到 SQS 队列。",
      "B": "配置 Lambda 函数，使用 Amazon Simple Queue Service (Amazon SQS) 队列作为调用源。当 SQS 消息成功处理后，删除队列中的消息。",
      "C": "配置 Lambda 函数以监视 S3 存储桶中的新上传。当检测到已上传的图像时，将文件名写入内存中的文本文件，并使用该文本文件跟踪已处理的图像。",
      "D": "启动一个 Amazon EC2 实例来监视 Amazon Simple Queue Service (Amazon SQS) 队列。当项目添加到队列时，在 EC2 实例上的文本文件中记录文件名并调用 Lambda 函数。",
      "E": "配置一个 Amazon EventBridge (Amazon CloudWatch Events) 事件来监视 S3 存储桶。当上传图像时，将警报发送到 Amazon 简单通知服务 (Amazon SNS) 主题，其中包含应用程序所有者的电子邮件地址，以便进一步处理。"
    }
  },
  {
    "id": 19,
    "topic": "1",
    "question_en": "A company has a three-tier web application that is deployed on AWS. The web servers are deployed in a public subnet in a VPC. The application servers and database servers are deployed in private subnets in the same VPC. The company has deployed a third-party virtual firewall appliance from AWS Marketplace in an inspection VPC. The appliance is configured with an IP interface that can accept IP packets. A solutions architect needs to integrate the web application with the appliance to inspect all trafic to the application before the trafic reaches the web server. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a Network Load Balancer in the public subnet of the application's VPC to route the trafic to the appliance for packet inspection.",
      "B": "Create an Application Load Balancer in the public subnet of the application's VPC to route the trafic to the appliance for packet inspection.",
      "C": "Deploy a transit gateway in the inspection VPConfigure route tables to route the incoming packets through the transit gateway.",
      "D": "Deploy a Gateway Load Balancer in the inspection VPC. Create a Gateway Load Balancer endpoint to receive the incoming packets and forward the packets to the appliance."
    },
    "correct_answer": "B",
    "vote_percentage": "82%",
    "question_cn": "一家公司在其 AWS 上部署了一个三层 Web 应用程序。Web 服务器部署在 VPC 的公共子网中。应用程序服务器和数据库服务器部署在同一 VPC 中的私有子网中。该公司从 AWS Marketplace 部署了第三方虚拟防火墙设备，该设备位于一个检查 VPC 中。该设备配置了一个可以接受 IP 数据包的 IP 接口。一个解决方案架构师需要将 Web 应用程序与该设备集成，以便在流量到达 Web 服务器之前检查所有应用程序流量。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "在应用程序的 VPC 的公共子网中创建一个 Network Load Balancer，将流量路由到设备进行数据包检查。",
      "B": "在应用程序的 VPC 的公共子网中创建一个 Application Load Balancer，将流量路由到设备进行数据包检查。",
      "C": "在检查 VPC 中部署一个转接网关。配置路由表以通过转接网关路由传入数据包。",
      "D": "在检查 VPC 中部署一个 Gateway Load Balancer。创建一个 Gateway Load Balancer 端点来接收传入数据包，并将数据包转发到该设备。"
    }
  },
  {
    "id": 20,
    "topic": "1",
    "question_en": "A company wants to improve its ability to clone large amounts of production data into a test environment in the same AWS Region. The data is stored in Amazon EC2 instances on Amazon Elastic Block Store (Amazon EBS) volumes. Modifications to the cloned data must not affect the production environment. The software that accesses this data requires consistently high I/O performance. A solutions architect needs to minimize the time that is required to clone the production data into the test environment. Which solution will meet these requirements?",
    "options_en": {
      "A": "Take EBS snapshots of the production EBS volumes. Restore the snapshots onto EC2 instance store volumes in the test environment.",
      "B": "Configure the production EBS volumes to use the EBS Multi-Attach feature. Take EBS snapshots of the production EBS volumes. Attach the production EBS volumes to the EC2 instances in the test environment.",
      "C": "Take EBS snapshots of the production EBS volumes. Create and initialize new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment before restoring the volumes from the production EBS snapshots.",
      "D": "Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment."
    },
    "correct_answer": "D",
    "vote_percentage": "93%",
    "question_cn": "一家公司希望提高其将大量生产数据克隆到相同 AWS 区域中的测试环境中的能力。数据存储在 Amazon EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷上。对克隆数据的修改不得影响生产环境。访问此数据的软件需要始终如一的高 I/O 性能。 一位解决方案架构师需要最大限度地减少将生产数据克隆到测试环境所需的时间。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "拍摄生产 EBS 卷的 EBS 快照。 将快照恢复到测试环境中的 EC2 实例存储卷上。",
      "B": "配置生产 EBS 卷以使用 EBS Multi-Attach 功能。 拍摄生产 EBS 卷的 EBS 快照。 将生产 EBS 卷附加到测试环境中的 EC2 实例。",
      "C": "拍摄生产 EBS 卷的 EBS 快照。 创建并初始化新的 EBS 卷。 在从生产 EBS 快照恢复卷之前，将新的 EBS 卷附加到测试环境中的 EC2 实例。",
      "D": "拍摄生产 EBS 卷的 EBS 快照。 在 EBS 快照上打开 EBS 快速快照恢复功能。 将快照恢复到新的 EBS 卷中。 将新的 EBS 卷附加到测试环境中的 EC2 实例。"
    }
  },
  {
    "id": 21,
    "topic": "1",
    "question_en": "An ecommerce company wants to launch a one-deal-a-day website on AWS. Each day will feature exactly one product on sale for a period of 24 hours. The company wants to be able to handle millions of requests each hour with millisecond latency during peak hours. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3.",
      "B": "Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website trafic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL.",
      "C": "Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in trafic. Store the data in Amazon RDS for MySQL.",
      "D": "Use an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司希望在 AWS 上推出一个每日特价网站。每天将有一个产品在 24 小时内促销。该公司希望能够处理每小时数百万个请求，并在高峰时具有毫秒级延迟。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 在不同的 S3 存储桶中托管完整的网站。添加 Amazon CloudFront 发行版。将 S3 存储桶设置为发行版的源。将订单数据存储在 Amazon S3 中。",
      "B": "将完整的网站部署在运行于多个可用区中的 Auto Scaling 组中的 Amazon EC2 实例上。添加 Application Load Balancer (ALB) 来分发网站流量。为后端 API 添加另一个 ALB。将数据存储在 Amazon RDS for MySQL 中。",
      "C": "将完整的应用程序迁移到在容器中运行。在 Amazon Elastic Kubernetes Service (Amazon EKS) 上托管容器。使用 Kubernetes Cluster Autoscaler 来增加和减少 pod 的数量以处理流量突发。将数据存储在 Amazon RDS for MySQL 中。",
      "D": "使用 Amazon S3 存储桶托管网站的静态内容。部署 Amazon CloudFront 发行版。将 S3 存储桶设置为源。使用 Amazon API Gateway 和 AWS Lambda 函数作为后端 API。将数据存储在 Amazon DynamoDB 中。"
    }
  },
  {
    "id": 22,
    "topic": "1",
    "question_en": "A solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone. Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files. Which storage option meets these requirements?",
    "options_en": {
      "A": "S3 Standard",
      "B": "S3 Intelligent-Tiering",
      "C": "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "D": "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在使用 Amazon S3 来设计新的数字媒体应用程序的存储架构。媒体文件必须能够应对可用区 (Availability Zone) 的丢失。某些文件会被频繁访问，而其他文件则以不可预测的模式很少被访问。解决方案架构师必须最大限度地降低存储和检索媒体文件的成本。哪种存储选项满足这些要求？",
    "options_cn": {
      "A": "S3 标准",
      "B": "S3 智能分层",
      "C": "S3 标准-不频繁访问 (S3 Standard-IA)",
      "D": "S3 单区-不频繁访问 (S3 One Zone-IA)"
    }
  },
  {
    "id": 23,
    "topic": "1",
    "question_en": "A company is storing backup files by using Amazon S3 Standard storage. The files are accessed frequently for 1 month. However, the files are not accessed after 1 month. The company must keep the files indefinitely. Which storage solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure S3 Intelligent-Tiering to automatically migrate objects.",
      "B": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Glacier Deep Archive after 1 month.",
      "C": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) after 1 month.",
      "D": "Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 month."
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在使用 Amazon S3 标准存储来存储备份文件。这些文件在一个月内会被频繁访问。然而，在一个月后，这些文件将不再被访问。该公司必须无限期地保留这些文件。哪种存储解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置 S3 Intelligent-Tiering 以自动迁移对象。",
      "B": "创建一个 S3 生命周期配置，将对象从 S3 标准存储转换为 S3 Glacier Deep Archive，时间为 1 个月后。",
      "C": "创建一个 S3 生命周期配置，将对象从 S3 标准存储转换为 S3 标准 - 不频繁访问 (S3 Standard-IA)，时间为 1 个月后。",
      "D": "创建一个 S3 生命周期配置，将对象从 S3 标准存储转换为 S3 单区 - 不频繁访问 (S3 One Zone-IA)，时间为 1 个月后。"
    }
  },
  {
    "id": 24,
    "topic": "1",
    "question_en": "A company observes an increase in Amazon EC2 costs in its most recent bill. The billing team notices unwanted vertical scaling of instance types for a couple of EC2 instances. A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in-depth analysis to identify the root cause of the vertical scaling. How should the solutions architect generate the information with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Budgets to create a budget report and compare EC2 costs based on instance types.",
      "B": "Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.",
      "C": "Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the last 2 months.",
      "D": "Use AWS Cost and Usage Reports to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight with Amazon S3 as a source to generate an interactive graph based on instance types."
    },
    "correct_answer": "C",
    "vote_percentage": "64%",
    "question_cn": "一家公司在其最新的账单中观察到 Amazon EC2 成本有所增加。计费团队注意到几个 EC2 实例的实例类型出现了不必要的垂直扩展。一位解决方案架构师需要创建一个图表，比较过去 2 个月的 EC2 成本，并进行深入分析以确定垂直扩展的根本原因。解决方案架构师应该如何以最少的运营开销生成信息？",
    "options_cn": {
      "A": "使用 AWS Budgets 创建预算报告，并根据实例类型比较 EC2 成本。",
      "B": "使用 Cost Explorer 的细粒度过滤功能，根据实例类型对 EC2 成本进行深入分析。",
      "C": "使用 AWS Billing and Cost Management 仪表板上的图表，比较过去 2 个月的基于实例类型的 EC2 成本。",
      "D": "使用 AWS Cost and Usage Reports 创建报告并将其发送到 Amazon S3 存储桶。 使用 Amazon QuickSight 并将 Amazon S3 用作源，根据实例类型生成交互式图表。"
    }
  },
  {
    "id": 25,
    "topic": "1",
    "question_en": "A company is designing an application. The application uses an AWS Lambda function to receive information through Amazon API Gateway and to store the information in an Amazon Aurora PostgreSQL database. During the proof-of-concept stage, the company has to increase the Lambda quotas significantly to handle the high volumes of data that the company needs to load into the database. A solutions architect must recommend a new design to improve scalability and minimize the configuration effort. Which solution will meet these requirements?",
    "options_en": {
      "A": "Refactor the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances. Connect the database by using native Java Database Connectivity (JDBC) drivers.",
      "B": "Change the platform from Aurora to Amazon DynamoDProvision a DynamoDB Accelerator (DAX) cluster. Use the DAX client SDK to point the existing DynamoDB API calls at the DAX cluster.",
      "C": "Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using Amazon Simple Notification Service (Amazon SNS).",
      "D": "Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue."
    },
    "correct_answer": "D",
    "vote_percentage": "99%",
    "question_cn": "一家公司正在设计一个应用程序。该应用程序使用一个 AWS Lambda 函数通过 Amazon API Gateway 接收信息，并将信息存储在 Amazon Aurora PostgreSQL 数据库中。在概念验证阶段，该公司必须大幅增加 Lambda 配额，以处理公司需要加载到数据库中的大量数据。一位解决方案架构师必须推荐一种新设计，以提高可扩展性并最大限度地减少配置工作量。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 Lambda 函数代码重构为在 Amazon EC2 实例上运行的 Apache Tomcat 代码。使用原生 Java Database Connectivity (JDBC) 驱动程序连接数据库。",
      "B": "将平台从 Aurora 更改为 Amazon DynamoDB。预置一个 DynamoDB Accelerator (DAX) 集群。使用 DAX 客户端 SDK 将现有的 DynamoDB API 调用指向 DAX 集群。",
      "C": "设置两个 Lambda 函数。配置一个函数来接收信息。配置另一个函数将信息加载到数据库中。使用 Amazon Simple Notification Service (Amazon SNS) 集成 Lambda 函数。",
      "D": "设置两个 Lambda 函数。配置一个函数来接收信息。配置另一个函数将信息加载到数据库中。使用 Amazon Simple Queue Service (Amazon SQS) 队列集成 Lambda 函数。"
    }
  },
  {
    "id": 26,
    "topic": "1",
    "question_en": "A company needs to review its AWS Cloud deployment to ensure that its Amazon S3 buckets do not have unauthorized configuration changes. What should a solutions architect do to accomplish this goal?",
    "options_en": {
      "A": "Turn on AWS Config with the appropriate rules.",
      "B": "Turn on AWS Trusted Advisor with the appropriate checks.",
      "C": "Turn on Amazon Inspector with the appropriate assessment template.",
      "D": "Turn on Amazon S3 server access logging. Configure Amazon EventBridge (Amazon Cloud Watch Events)."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一家公司需要审查其 AWS 云部署，以确保其 Amazon S3 存储桶没有未经授权的配置更改。解决方案架构师应该怎么做才能实现此目标？",
    "options_cn": {
      "A": "使用适当的规则打开 AWS Config。",
      "B": "使用适当的检查打开 AWS Trusted Advisor。",
      "C": "使用适当的评估模板打开 Amazon Inspector。",
      "D": "打开 Amazon S3 服务器访问日志记录。配置 Amazon EventBridge (Amazon CloudWatch Events)。"
    }
  },
  {
    "id": 27,
    "topic": "1",
    "question_en": "A company is launching a new application and will display application metrics on an Amazon CloudWatch dashboard. The company's product manager needs to access this dashboard periodically. The product manager does not have an AWS account. A solutions architect must provide access to the product manager by following the principle of least privilege. Which solution will meet these requirements?",
    "options_en": {
      "A": "Share the dashboard from the CloudWatch console. Enter the product manager's email address, and complete the sharing steps. Provide a shareable link for the dashboard to the product manager.",
      "B": "Create an IAM user specifically for the product manager. Attach the CloudWatchReadOnlyAccess AWS managed policy to the user. Share the new login credentials with the product manager. Share the browser URL of the correct dashboard with the product manager.",
      "C": "Create an IAM user for the company's employees. Attach the ViewOnlyAccess AWS managed policy to the IAM user. Share the new login credentials with the product manager. Ask the product manager to navigate to the CloudWatch console and locate the dashboard by name in the Dashboards section.",
      "D": "Deploy a bastion server in a public subnet. When the product manager requires access to the dashboard, start the server and share the RDP credentials. On the bastion server, ensure that the browser is configured to open the dashboard URL with cached AWS credentials that have appropriate permissions to view the dashboard."
    },
    "correct_answer": "B",
    "vote_percentage": "74%",
    "question_cn": "一家公司正在启动一个新应用程序，并将应用程序指标显示在 Amazon CloudWatch 仪表板上。该公司的产品经理需要定期间隔访问此仪表板。产品经理没有 AWS 账户。一个解决方案架构师必须通过遵循最小权限原则来向产品经理提供访问权限。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "从 CloudWatch 控制台共享仪表板。输入产品经理的电子邮件地址，并完成共享步骤。为产品经理提供仪表板的可共享链接。",
      "B": "专门为产品经理创建一个 IAM 用户。将 CloudWatchReadOnlyAccess AWS 托管策略附加到该用户。与产品经理共享新的登录凭据。与产品经理共享正确仪表板的浏览器 URL。",
      "C": "为公司的员工创建一个 IAM 用户。将 ViewOnlyAccess AWS 托管策略附加到 IAM 用户。与产品经理共享新的登录凭据。要求产品经理导航到 CloudWatch 控制台，并在“仪表板”部分按名称找到仪表板。",
      "D": "在公共子网中部署一个堡垒服务器。当产品经理需要访问仪表板时，启动服务器并共享 RDP 凭据。在堡垒服务器上，确保浏览器配置为使用具有查看仪表板的适当权限的缓存 AWS 凭据打开仪表板 URL。"
    }
  },
  {
    "id": 28,
    "topic": "1",
    "question_en": "A company is migrating applications to AWS. The applications are deployed in different accounts. The company manages the accounts centrally by using AWS Organizations. The company's security team needs a single sign-on (SSO) solution across all the company's accounts. The company must continue managing the users and groups in its on-premises self-managed Microsoft Active Directory. Which solution will meet these requirements?",
    "options_en": {
      "A": "Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a one-way forest trust or a one-way domain trust to connect the company's self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory.",
      "B": "Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a two-way forest trust to connect the company's self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory.",
      "C": "Use AWS Directory Service. Create a two-way trust relationship with the company's self-managed Microsoft Active Directory.",
      "D": "Deploy an identity provider (IdP) on premises. Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司正在将应用程序迁移到 AWS。这些应用程序部署在不同的账户中。该公司使用 AWS Organizations 集中管理这些账户。该公司的安全团队需要在所有公司的账户中使用单点登录 (SSO) 解决方案。该公司必须继续在其本地自管理的 Microsoft Active Directory 中管理用户和组。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "从 AWS SSO 控制台启用 AWS Single Sign-On (AWS SSO)。通过使用 AWS Directory Service for Microsoft Active Directory，创建一个单向林信任或单向域信任来连接公司的自管理 Microsoft Active Directory 与 AWS SSO。",
      "B": "从 AWS SSO 控制台启用 AWS Single Sign-On (AWS SSO)。通过使用 AWS Directory Service for Microsoft Active Directory，创建一个双向林信任来连接公司的自管理 Microsoft Active Directory 与 AWS SSO。",
      "C": "使用 AWS Directory Service。创建与公司自管理 Microsoft Active Directory 的双向信任关系。",
      "D": "在本地部署一个身份提供者 (IdP)。从 AWS SSO 控制台启用 AWS Single Sign-On (AWS SSO)。"
    }
  },
  {
    "id": 29,
    "topic": "1",
    "question_en": "A company provides a Voice over Internet Protocol (VoIP) service that uses UDP connections. The service consists of Amazon EC2 instances that run in an Auto Scaling group. The company has deployments across multiple AWS Regions. The company needs to route users to the Region with the lowest latency. The company also needs automated failover between Regions. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Use the NLB as an AWS Global Accelerator endpoint in each Region.",
      "B": "Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Use the ALB as an AWS Global Accelerator endpoint in each Region.",
      "C": "Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 latency record that points to aliases for each NLB. Create an Amazon CloudFront distribution that uses the latency record as an origin.",
      "D": "Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 weighted record that points to aliases for each ALB. Deploy an Amazon CloudFront distribution that uses the weighted record as an origin."
    },
    "correct_answer": "C",
    "vote_percentage": "78%",
    "question_cn": "一家公司提供使用 UDP 连接的互联网语音协议 (VoIP) 服务。该服务由在 Auto Scaling 组中运行的 Amazon EC2 实例组成。该公司在多个 AWS 区域中都有部署。该公司需要将用户路由到延迟最低的区域。该公司还需要区域之间的自动化故障转移。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "部署一个 Network Load Balancer (NLB) 和一个相关的目标组。将目标组与 Auto Scaling 组关联。在每个区域中使用 NLB 作为 AWS Global Accelerator 终端节点。",
      "B": "部署一个 Application Load Balancer (ALB) 和一个相关的目标组。将目标组与 Auto Scaling 组关联。在每个区域中使用 ALB 作为 AWS Global Accelerator 终端节点。",
      "C": "部署一个 Network Load Balancer (NLB) 和一个相关的目标组。将目标组与 Auto Scaling 组关联。创建 Amazon Route 53 延迟记录，该记录指向每个 NLB 的别名。创建一个 Amazon CloudFront 分发，该分发使用延迟记录作为源。",
      "D": "部署一个 Application Load Balancer (ALB) 和一个相关的目标组。将目标组与 Auto Scaling 组关联。创建 Amazon Route 53 加权记录，该记录指向每个 ALB 的别名。部署一个 Amazon CloudFront 分发，该分发使用加权记录作为源。"
    }
  },
  {
    "id": 30,
    "topic": "1",
    "question_en": "A development team runs monthly resource-intensive tests on its general purpose Amazon RDS for MySQL DB instance with Performance Insights enabled. The testing lasts for 48 hours once a month and is the only process that uses the database. The team wants to reduce the cost of running the tests without reducing the compute and memory attributes of the DB instance. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Stop the DB instance when tests are completed. Restart the DB instance when required.",
      "B": "Use an Auto Scaling policy with the DB instance to automatically scale when tests are completed.",
      "C": "Create a snapshot when tests are completed. Terminate the DB instance and restore the snapshot when required.",
      "D": "Modify the DB instance to a low-capacity instance when tests are completed. Modify the DB instance again when required."
    },
    "correct_answer": "C",
    "vote_percentage": "76%",
    "question_cn": "一个开发团队在其通用 Amazon RDS for MySQL 数据库实例上运行每月资源密集型测试，并启用了 Performance Insights。测试每月持续 48 小时，并且是唯一使用该数据库的进程。该团队希望降低运行测试的成本，而不会降低数据库实例的计算和内存属性。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "在测试完成后停止数据库实例。在需要时重新启动数据库实例。",
      "B": "使用带有数据库实例的 Auto Scaling 策略，以便在测试完成后自动扩展。",
      "C": "在测试完成后创建快照。终止数据库实例，并在需要时还原快照。",
      "D": "在测试完成后将数据库实例修改为低容量实例。在需要时再次修改数据库实例。"
    }
  },
  {
    "id": 31,
    "topic": "1",
    "question_en": "A company that hosts its web application on AWS wants to ensure all Amazon EC2 instances. Amazon RDS DB instances. and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check. What should a solutions architect do to accomplish this?",
    "options_en": {
      "A": "Use AWS Config rules to define and detect resources that are not properly tagged.",
      "B": "Use Cost Explorer to display resources that are not properly tagged. Tag those resources manually.",
      "C": "Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.",
      "D": "Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一家公司在 AWS 上托管其 Web 应用程序，希望确保所有 Amazon EC2 实例、Amazon RDS 数据库实例和 Amazon Redshift 集群都配置了标签。该公司希望尽量减少配置和操作此检查的工作量。解决方案架构师应该怎么做才能实现此目的？",
    "options_cn": {
      "A": "使用 AWS Config 规则定义和检测未正确标记的资源。",
      "B": "使用 Cost Explorer 显示未正确标记的资源。手动标记这些资源。",
      "C": "编写 API 调用来检查所有资源是否正确分配了标签。定期在 EC2 实例上运行代码。",
      "D": "编写 API 调用来检查所有资源是否正确分配了标签。通过 Amazon CloudWatch 安排一个 AWS Lambda 函数来定期间隔运行代码。"
    }
  },
  {
    "id": 32,
    "topic": "1",
    "question_en": "A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images. Which method is the MOST cost-effective for hosting the website?",
    "options_en": {
      "A": "Containerize the website and host it in AWS Fargate.",
      "B": "Create an Amazon S3 bucket and host the website there.",
      "C": "Deploy a web server on an Amazon EC2 instance to host the website.",
      "D": "Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个开发团队需要托管一个网站，该网站将被其他团队访问。网站内容包括 HTML、CSS、客户端 JavaScript 和图像。哪种方法对于托管网站来说最具成本效益？",
    "options_cn": {
      "A": "将网站容器化并在 AWS Fargate 中托管。",
      "B": "创建一个 Amazon S3 存储桶并在其中托管网站。",
      "C": "在 Amazon EC2 实例上部署一个 Web 服务器来托管网站。",
      "D": "配置一个 Application Load Balancer，其目标是使用 Express.js 框架的 AWS Lambda。"
    }
  },
  {
    "id": 33,
    "topic": "1",
    "question_en": "A company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications.",
      "B": "Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.",
      "C": "Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.",
      "D": "Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3."
    },
    "correct_answer": "C",
    "vote_percentage": "86%",
    "question_cn": "一家公司在 AWS 上运行一个在线市场 Web 应用程序。该应用程序在高峰时为数十万用户提供服务。该公司需要一个可扩展的近实时解决方案，以与几个其他内部应用程序共享数百万笔金融交易的详细信息。交易也需要被处理以移除敏感数据，然后再存储在文档数据库中，以实现低延迟检索。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "将交易数据存储到 Amazon DynamoDB 中。在 DynamoDB 中设置一个规则，以便在每次写入时从每笔交易中删除敏感数据。使用 DynamoDB Streams 与其他应用程序共享交易数据。",
      "B": "将交易数据流式传输到 Amazon Kinesis Data Firehose 中，以将数据存储在 Amazon DynamoDB 和 Amazon S3 中。使用 AWS Lambda 集成 Kinesis Data Firehose 来删除敏感数据。其他应用程序可以消费存储在 Amazon S3 中的数据。",
      "C": "将交易数据流式传输到 Amazon Kinesis Data Streams 中。使用 AWS Lambda 集成来从每笔交易中删除敏感数据，然后将交易数据存储在 Amazon DynamoDB 中。其他应用程序可以从 Kinesis 数据流中消费交易数据。",
      "D": "将批处理的交易数据作为文件存储在 Amazon S3 中。使用 AWS Lambda 处理每个文件并删除敏感数据，然后再更新 Amazon S3 中的文件。Lambda 函数随后将数据存储在 Amazon DynamoDB 中。其他应用程序可以消费存储在 Amazon S3 中的交易文件。"
    }
  },
  {
    "id": 34,
    "topic": "1",
    "question_en": "A company hosts its multi-tier applications on AWS. For compliance, governance, auditing, and security, the company must track configuration changes on its AWS resources and record a history of API calls made to these resources. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use AWS CloudTrail to track configuration changes and AWS Config to record API calls.",
      "B": "Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.",
      "C": "Use AWS Config to track configuration changes and Amazon CloudWatch to record API calls.",
      "D": "Use AWS CloudTrail to track configuration changes and Amazon CloudWatch to record API calls."
    },
    "correct_answer": "B",
    "vote_percentage": "99%",
    "question_cn": "一家公司在 AWS 上托管其多层应用程序。为了合规性、管理、审计和安全性，该公司必须跟踪其 AWS 资源上的配置更改，并记录对这些资源进行的 API 调用的历史记录。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS CloudTrail 跟踪配置更改，使用 AWS Config 记录 API 调用。",
      "B": "使用 AWS Config 跟踪配置更改，使用 AWS CloudTrail 记录 API 调用。",
      "C": "使用 AWS Config 跟踪配置更改，使用 Amazon CloudWatch 记录 API 调用。",
      "D": "使用 AWS CloudTrail 跟踪配置更改，使用 Amazon CloudWatch 记录 API 调用。"
    }
  },
  {
    "id": 35,
    "topic": "1",
    "question_en": "A company is preparing to launch a public-facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third-party service is used for the DNS. The company's solutions architect must recommend a solution to detect and protect against large-scale DDoS attacks. Which solution meets these requirements?",
    "options_en": {
      "A": "Enable Amazon GuardDuty on the account.",
      "B": "Enable Amazon Inspector on the EC2 instances.",
      "C": "Enable AWS Shield and assign Amazon Route 53 to it.",
      "D": "Enable AWS Shield Advanced and assign the ELB to it."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正准备在 AWS 云中发布面向公众的 Web 应用程序。该架构由 VPC 内的 Amazon EC2 实例组成，这些实例位于 Elastic Load Balancer (ELB) 之后。第三方服务用于 DNS。公司的解决方案架构师必须推荐一种解决方案来检测并防御大规模 DDoS 攻击。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "在账户上启用 Amazon GuardDuty。",
      "B": "在 EC2 实例上启用 Amazon Inspector。",
      "C": "启用 AWS Shield 并为其分配 Amazon Route 53。",
      "D": "启用 AWS Shield Advanced 并为其分配 ELB。"
    }
  },
  {
    "id": 36,
    "topic": "1",
    "question_en": "A company is building an application in the AWS Cloud. The application will store data in Amazon S3 buckets in two AWS Regions. The company must use an AWS Key Management Service (AWS KMS) customer managed key to encrypt all data that is stored in the S3 buckets. The data in both S3 buckets must be encrypted and decrypted with the same KMS key. The data and the key must be stored in each of the two Regions. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
      "B": "Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption.",
      "C": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.",
      "D": "Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets."
    },
    "correct_answer": "C",
    "vote_percentage": "56%",
    "question_cn": "一家公司正在 AWS 云中构建应用程序。该应用程序将数据存储在两个 AWS 区域的 Amazon S3 存储桶中。该公司必须使用 AWS Key Management Service (AWS KMS) 客户托管密钥来加密存储在 S3 存储桶中的所有数据。两个 S3 存储桶中的数据都必须使用相同的 KMS 密钥进行加密和解密。数据和密钥必须存储在这两个区域中的每一个区域。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在每个区域创建一个 S3 存储桶。配置 S3 存储桶以使用带 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。",
      "B": "创建客户托管的多区域 KMS 密钥。在每个区域创建一个 S3 存储桶。配置 S3 存储桶之间的复制。配置应用程序以使用具有客户端加密的 KMS 密钥。",
      "C": "在每个区域创建一个客户托管的 KMS 密钥和一个 S3 存储桶。配置 S3 存储桶以使用带 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。",
      "D": "在每个区域创建一个客户托管的 KMS 密钥和一个 S3 存储桶。配置 S3 存储桶以使用带 AWS KMS 密钥 (SSE-KMS) 的服务器端加密。配置 S3 存储桶之间的复制。"
    }
  },
  {
    "id": 37,
    "topic": "1",
    "question_en": "A company recently launched a variety of new workloads on Amazon EC2 instances in its AWS account. The company needs to create a strategy to access and administer the instances remotely and securely. The company needs to implement a repeatable process that works with native AWS services and follows the AWS Well-Architected Framework. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use the EC2 serial console to directly access the terminal interface of each instance for administration.",
      "B": "Attach the appropriate IAM role to each existing instance and new instance. Use AWS Systems Manager Session Manager to establish a remote SSH session.",
      "C": "Create an administrative SSH key pair. Load the public key into each EC2 instance. Deploy a bastion host in a public subnet to provide a tunnel for administration of each instance.",
      "D": "Establish an AWS Site-to-Site VPN connection. Instruct administrators to use their local on-premises machines to connect directly to the instances by using SSH keys across the VPN tunnel."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司最近在其 AWS 账户中的 Amazon EC2 实例上启动了各种新的工作负载。该公司需要创建一个策略来远程、安全地访问和管理这些实例。该公司需要实施一个可重复的过程，该过程使用原生的 AWS 服务并遵循 AWS 良好的架构框架。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 EC2 串行控制台直接访问每个实例的终端接口以进行管理。",
      "B": "将适当的 IAM 角色附加到每个现有实例和新实例。使用 AWS Systems Manager Session Manager 建立远程 SSH 会话。",
      "C": "创建一个管理 SSH 密钥对。将公钥加载到每个 EC2 实例中。在公共子网中部署一个堡垒主机，为每个实例的管理提供一个隧道。",
      "D": "建立 AWS Site-to-Site VPN 连接。指示管理员使用其本地的本地机器通过 VPN 隧道使用 SSH 密钥直接连接到实例。"
    }
  },
  {
    "id": 38,
    "topic": "1",
    "question_en": "A company is hosting a static website on Amazon S3 and is using Amazon Route 53 for DNS. The website is experiencing increased demand from around the world. The company must decrease latency for users who access the website. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Replicate the S3 bucket that contains the website to all AWS Regions. Add Route 53 geolocation routing entries.",
      "B": "Provision accelerators in AWS Global Accelerator. Associate the supplied IP addresses with the S3 bucket. Edit the Route 53 entries to point to the IP addresses of the accelerators.",
      "C": "Add an Amazon CloudFront distribution in front of the S3 bucket. Edit the Route 53 entries to point to the CloudFront distribution.",
      "D": "Enable S3 Transfer Acceleration on the bucket. Edit the Route 53 entries to point to the new endpoint."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Amazon S3 上托管静态网站，并使用 Amazon Route 53 进行 DNS。该网站正经历来自世界各地日益增长的需求。公司必须减少用户访问网站的延迟。哪种解决方案以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将包含网站的 S3 存储桶复制到所有 AWS 区域。添加 Route 53 地理位置路由条目。",
      "B": "在 AWS Global Accelerator 中配置加速器。将提供的 IP 地址与 S3 存储桶关联。编辑 Route 53 条目以指向加速器的 IP 地址。",
      "C": "在 S3 存储桶前面添加一个 Amazon CloudFront 分发。编辑 Route 53 条目以指向 CloudFront 分发。",
      "D": "在存储桶上启用 S3 Transfer Acceleration。编辑 Route 53 条目以指向新的终端节点。"
    }
  },
  {
    "id": 39,
    "topic": "1",
    "question_en": "A company maintains a searchable repository of items on its website. The data is stored in an Amazon RDS for MySQL database table that contains more than 10 million rows. The database has 2 TB of General Purpose SSD storage. There are millions of updates against this data every day through the company's website. The company has noticed that some insert operations are taking 10 seconds or longer. The company has determined that the database storage performance is the problem. Which solution addresses this performance issue?",
    "options_en": {
      "A": "Change the storage type to Provisioned IOPS SSD.",
      "B": "Change the DB instance to a memory optimized instance class.",
      "C": "Change the DB instance to a burstable performance instance class.",
      "D": "Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司在其网站上维护一个可搜索的物品存储库。数据存储在 Amazon RDS for MySQL 数据库表中，该表包含超过 1000 万行。数据库具有 2 TB 的通用 SSD 存储。每天通过公司的网站对这些数据进行数百万次更新。该公司注意到一些插入操作需要 10 秒或更长时间。该公司已确定数据库存储性能是问题所在。哪个解决方案解决了此性能问题？",
    "options_cn": {
      "A": "将存储类型更改为预置 IOPS SSD。",
      "B": "将数据库实例更改为内存优化实例类。",
      "C": "将数据库实例更改为可突增性能实例类。",
      "D": "使用 MySQL 本机异步复制启用多可用区 RDS 读副本。"
    }
  },
  {
    "id": 40,
    "topic": "1",
    "question_en": "A company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis. The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days. What is the MOST operationally eficient solution that meets these requirements?",
    "options_en": {
      "A": "Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.",
      "B": "Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.",
      "C": "Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster. Set up the Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days.",
      "D": "Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司拥有数千个边缘设备，这些设备每天总共生成 1 TB 的状态警报。每个警报大约 2 KB 大小。一位解决方案架构师需要实施一个解决方案来摄取和存储警报以供将来分析。该公司需要一个高可用性解决方案。但是，该公司需要最大限度地降低成本，并且不想管理额外的基础设施。此外，该公司希望保留 14 天的数据以供立即分析，并归档任何超过 14 天的数据。哪种解决方案在运营上最有效，能够满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Kinesis Data Firehose 传输流来摄取警报。配置 Kinesis Data Firehose 流将警报传输到 Amazon S3 存储桶。设置一个 S3 生命周期配置，在 14 天后将数据转换为 Amazon S3 Glacier。",
      "B": "跨两个可用区启动 Amazon EC2 实例，并将它们置于 Application Load Balancer (ALB) 后面以摄取警报。在 EC2 实例上创建一个脚本，该脚本会将警报存储在 Amazon S3 存储桶中。设置一个 S3 生命周期配置，在 14 天后将数据转换为 Amazon S3 Glacier。",
      "C": "创建一个 Amazon Kinesis Data Firehose 传输流来摄取警报。配置 Kinesis Data Firehose 流将警报传输到 Amazon OpenSearch Service（Amazon Elasticsearch Service）集群。设置 Amazon OpenSearch Service（Amazon Elasticsearch Service）集群，每天拍摄手动快照，并从集群中删除超过 14 天的数据。",
      "D": "创建一个 Amazon Simple Queue Service (Amazon SQS) 标准队列来摄取警报，并将消息保留期设置为 14 天。配置使用者轮询 SQS 队列，检查消息的年龄，并根据需要分析消息数据。如果消息已满 14 天，使用者应将消息复制到 Amazon S3 存储桶，然后从 SQS 队列中删除该消息。"
    }
  },
  {
    "id": 41,
    "topic": "1",
    "question_en": "A company's application integrates with multiple software-as-a-service (SaaS) sources for data collection. The company runs Amazon EC2 instances to receive the data and to upload the data to an Amazon S3 bucket for analysis. The same EC2 instance that receives and uploads the data also sends a notification to the user when an upload is complete. The company has noticed slow application performance and wants to improve the performance as much as possible. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Auto Scaling group so that EC2 instances can scale out. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.",
      "B": "Create an Amazon AppFlow fiow to transfer data between each SaaS source and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for each SaaS source to send output data. Configure the S3 bucket as the rule's target. Create a second EventBridge (Cloud Watch Events) rule to send events when the upload to the S3 bucket is complete. Configure an Amazon Simple Notification Service (Amazon SNS) topic as the second rule's target.",
      "D": "Create a Docker container to use instead of an EC2 instance. Host the containerized application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon CloudWatch Container Insights to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete."
    },
    "correct_answer": "B",
    "vote_percentage": "68%",
    "question_cn": "一家公司的应用程序与多个软件即服务 (SaaS) 源集成，用于数据收集。该公司运行 Amazon EC2 实例来接收数据并将数据上传到 Amazon S3 存储桶以进行分析。接收和上传数据的同一 EC2 实例也会在上传完成后向用户发送通知。该公司注意到应用程序性能缓慢，并希望尽可能提高性能。哪种解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Auto Scaling 组，以便 EC2 实例可以横向扩展。配置 S3 事件通知，以便在上传到 S3 存储桶完成后，将事件发送到 Amazon Simple Notification Service (Amazon SNS) 主题。",
      "B": "创建一个 Amazon AppFlow 流，用于在每个 SaaS 源和 S3 存储桶之间传输数据。配置 S3 事件通知，以便在上传到 S3 存储桶完成后，将事件发送到 Amazon Simple Notification Service (Amazon SNS) 主题。",
      "C": "为每个 SaaS 源创建一个 Amazon EventBridge (Amazon CloudWatch Events) 规则，以发送输出数据。将 S3 存储桶配置为该规则的目标。创建第二个 EventBridge (CloudWatch Events) 规则，以便在上传到 S3 存储桶完成后发送事件。将 Amazon Simple Notification Service (Amazon SNS) 主题配置为第二个规则的目标。",
      "D": "创建一个 Docker 容器来代替 EC2 实例。在 Amazon Elastic Container Service (Amazon ECS) 上托管容器化应用程序。配置 Amazon CloudWatch Container Insights，以便在上传到 S3 存储桶完成后，将事件发送到 Amazon Simple Notification Service (Amazon SNS) 主题。"
    }
  },
  {
    "id": 42,
    "topic": "1",
    "question_en": "A company runs a highly available image-processing application on Amazon EC2 instances in a single VPC. The EC2 instances run inside several subnets across multiple Availability Zones. The EC2 instances do not communicate with each other. However, the EC2 instances download images from Amazon S3 and upload images to Amazon S3 through a single NAT gateway. The company is concerned about data transfer charges. What is the MOST cost-effective way for the company to avoid Regional data transfer charges?",
    "options_en": {
      "A": "Launch the NAT gateway in each Availability Zone.",
      "B": "Replace the NAT gateway with a NAT instance.",
      "C": "Deploy a gateway VPC endpoint for Amazon S3.",
      "D": "Provision an EC2 Dedicated Host to run the EC2 instances."
    },
    "correct_answer": "C",
    "vote_percentage": "99%",
    "question_cn": "一家公司在单个 VPC 中的 Amazon EC2 实例上运行一个高可用性图像处理应用程序。 EC2 实例在多个可用区中的几个子网内运行。 EC2 实例之间不相互通信。 但是，EC2 实例通过单个 NAT 网关从 Amazon S3 下载图像并将图像上传到 Amazon S3。该公司担心数据传输费用。该公司避免区域数据传输费用的最具成本效益的方法是什么？",
    "options_cn": {
      "A": "在每个可用区启动 NAT 网关。",
      "B": "用 NAT 实例替换 NAT 网关。",
      "C": "为 Amazon S3 部署一个网关 VPC endpoint。",
      "D": "预置一个 EC2 专用主机以运行 EC2 实例。"
    }
  },
  {
    "id": 43,
    "topic": "1",
    "question_en": "A company has an on-premises application that generates a large amount of time-sensitive data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long-term solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity for internal users. Which solution meets these requirements?",
    "options_en": {
      "A": "Establish AWS VPN connections and proxy all trafic through a VPC gateway endpoint.",
      "B": "Establish a new AWS Direct Connect connection and direct backup trafic through this new connection.",
      "C": "Order daily AWS Snowball devices. Load the data onto the Snowball devices and return the devices to AWS each day.",
      "D": "Submit a support ticket through the AWS Management Console. Request the removal of S3 service limits from the account."
    },
    "correct_answer": "B",
    "vote_percentage": "99%",
    "question_cn": "一家公司有一个本地应用程序，该应用程序会生成大量时间敏感的数据，这些数据会被备份到 Amazon S3。应用程序不断增长，用户抱怨互联网带宽限制。一个解决方案架构师需要设计一个长期解决方案，该方案既能及时备份到 Amazon S3，又能最大限度地减少对内部用户互联网连接的影响。以下哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "建立 AWS VPN 连接，并通过 VPC 网关终端节点代理所有流量。",
      "B": "建立一个新的 AWS Direct Connect 连接，并将备份流量定向到这个新连接。",
      "C": "每天订购 AWS Snowball 设备。将数据加载到 Snowball 设备上，然后每天将设备返回到 AWS。",
      "D": "通过 AWS Management Console 提交支持工单。请求从账户中删除 S3 服务限制。"
    }
  },
  {
    "id": 44,
    "topic": "1",
    "question_en": "A company has an Amazon S3 bucket that contains critical data. The company must protect the data from accidental deletion. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Enable versioning on the S3 bucket.",
      "B": "Enable MFA Delete on the S3 bucket.",
      "C": "Create a bucket policy on the S3 bucket.",
      "D": "Enable default encryption on the S3 bucket",
      "E": "Create a lifecycle policy for the objects in the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "98%",
    "question_cn": "一家公司有一个包含关键数据的 Amazon S3 存储桶。该公司必须保护数据免受意外删除。 解决方案架构师应该采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 S3 存储桶上启用版本控制。",
      "B": "在 S3 存储桶上启用 MFA Delete。",
      "C": "在 S3 存储桶上创建存储桶策略。",
      "D": "在 S3 存储桶上启用默认加密。",
      "E": "为 S3 存储桶中的对象创建生命周期策略。"
    }
  },
  {
    "id": 45,
    "topic": "1",
    "question_en": "A company has a data ingestion workfiow that consists of the following: • An Amazon Simple Notification Service (Amazon SNS) topic for notifications about new data deliveries • An AWS Lambda function to process the data and record metadata The company observes that the ingestion workfiow fails occasionally because of network connectivity issues. When such a failure occurs, the Lambda function does not ingest the corresponding data unless the company manually reruns the job. Which combination of actions should a solutions architect take to ensure that the Lambda function ingests all data in the future? (Choose two.)",
    "options_en": {
      "A": "Deploy the Lambda function in multiple Availability Zones.",
      "B": "Create an Amazon Simple Queue Service (Amazon SQS) queue, and subscribe it to the SNS topic.",
      "C": "Increase the CPU and memory that are allocated to the Lambda function.",
      "D": "Increase provisioned throughput for the Lambda function",
      "E": "Modify the Lambda function to read from an Amazon Simple Queue Service (Amazon SQS) queue."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司有一个数据摄取工作流，包括： • 用于关于新数据交付通知的 Amazon Simple Notification Service (Amazon SNS) 主题 • 用于处理数据和记录元数据的 AWS Lambda 函数。该公司观察到，由于网络连接问题，摄取工作流偶尔会失败。当发生此类故障时，除非公司手动重新运行该作业，否则 Lambda 函数不会摄取相应的数据。解决方案架构师应该采取哪些组合操作来确保 Lambda 函数将来摄取所有数据？（选择两个。）",
    "options_cn": {
      "A": "将 Lambda 函数部署在多个可用区。",
      "B": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列，并将其订阅到 SNS 主题。",
      "C": "增加分配给 Lambda 函数的 CPU 和内存。",
      "D": "增加 Lambda 函数的预置吞吐量。",
      "E": "修改 Lambda 函数以从 Amazon Simple Queue Service (Amazon SQS) 队列读取。"
    }
  },
  {
    "id": 46,
    "topic": "1",
    "question_en": "A company has an application that provides marketing services to stores. The services are based on previous purchases by store customers. The stores upload transaction data to the company through SFTP, and the data is processed and analyzed to generate new marketing offers. Some of the files can exceed 200 GB in size. Recently, the company discovered that some of the stores have uploaded files that contain personally identifiable information (PII) that should not have been included. The company wants administrators to be alerted if PII is shared again. The company also wants to automate remediation. What should a solutions architect do to meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Use an Amazon S3 bucket as a secure transfer point. Use Amazon Inspector to scan the objects in the bucket. If objects contain PII, trigger an S3 Lifecycle policy to remove the objects that contain PII.",
      "B": "Use an Amazon S3 bucket as a secure transfer point. Use Amazon Macie to scan the objects in the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.",
      "C": "Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII.",
      "D": "Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Email Service (Amazon SES) to trigger a notification to the administrators and trigger an S3 Lifecycle policy to remove the meats that contain PII."
    },
    "correct_answer": "B",
    "vote_percentage": "60%",
    "question_cn": "一家公司有一个为商店提供营销服务的应用程序。这些服务基于商店客户之前的购买情况。商店通过 SFTP 将交易数据上传到该公司，然后处理和分析这些数据以生成新的营销优惠。某些文件的大小可能超过 200 GB。最近，该公司发现一些商店上传的文件包含不应包含的个人身份信息 (PII)。该公司希望在再次共享 PII 时提醒管理员。该公司还希望自动化补救措施。解决方案架构师应该怎么做才能以最少的开发工作量满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 存储桶作为安全传输点。使用 Amazon Inspector 扫描存储桶中的对象。如果对象包含 PII，则触发 S3 生命周期策略以删除包含 PII 的对象。",
      "B": "使用 Amazon S3 存储桶作为安全传输点。使用 Amazon Macie 扫描存储桶中的对象。如果对象包含 PII，请使用 Amazon Simple Notification Service (Amazon SNS) 向管理员发送通知，以删除包含 PII 的对象。",
      "C": "在 AWS Lambda 函数中实现自定义扫描算法。当对象加载到存储桶中时触发该函数。如果对象包含 PII，请使用 Amazon Simple Notification Service (Amazon SNS) 向管理员发送通知，以删除包含 PII 的对象。",
      "D": "在 AWS Lambda 函数中实现自定义扫描算法。当对象加载到存储桶中时触发该函数。如果对象包含 PII，请使用 Amazon Simple Email Service (Amazon SES) 向管理员发送通知，并触发 S3 生命周期策略以删除包含 PII 的对象。"
    }
  },
  {
    "id": 47,
    "topic": "1",
    "question_en": "A company needs guaranteed Amazon EC2 capacity in three specific Availability Zones in a specific AWS Region for an upcoming event that will last 1 week. What should the company do to guarantee the EC2 capacity?",
    "options_en": {
      "A": "Purchase Reserved Instances that specify the Region needed.",
      "B": "Create an On-Demand Capacity Reservation that specifies the Region needed.",
      "C": "Purchase Reserved Instances that specify the Region and three Availability Zones needed.",
      "D": "Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要在特定 AWS 区域的三个特定可用区中保证 Amazon EC2 的容量，用于即将举行的一周活动。该公司应该怎么做才能保证 EC2 容量？",
    "options_cn": {
      "A": "购买指定所需区域的预留实例。",
      "B": "创建指定所需区域的按需容量预留。",
      "C": "购买指定所需区域和三个可用区的预留实例。",
      "D": "创建指定所需区域和三个可用区的按需容量预留。"
    }
  },
  {
    "id": 48,
    "topic": "1",
    "question_en": "A company's website uses an Amazon EC2 instance store for its catalog of items. The company wants to make sure that the catalog is highly available and that the catalog is stored in a durable location. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Move the catalog to Amazon ElastiCache for Redis.",
      "B": "Deploy a larger EC2 instance with a larger instance store.",
      "C": "Move the catalog from the instance store to Amazon S3 Glacier Deep Archive.",
      "D": "Move the catalog to an Amazon Elastic File System (Amazon EFS) file system."
    },
    "correct_answer": "A",
    "vote_percentage": "92%",
    "question_cn": "一家公司的网站使用 Amazon EC2 实例存储来存储其商品目录。该公司希望确保目录具有高可用性，并且目录存储在持久的位置。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将目录移动到 Amazon ElastiCache for Redis。",
      "B": "部署一个更大的 EC2 实例，并使用更大的实例存储。",
      "C": "将目录从实例存储移动到 Amazon S3 Glacier Deep Archive。",
      "D": "将目录移动到 Amazon Elastic File System (Amazon EFS) 文件系统。"
    }
  },
  {
    "id": 49,
    "topic": "1",
    "question_en": "A company stores call transcript files on a monthly basis. Users access the files randomly within 1 year of the call, but users access the files infrequently after 1 year. The company wants to optimize its solution by giving users the ability to query and retrieve files that are less than 1- year-old as quickly as possible. A delay in retrieving older files is acceptable. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store individual files with tags in Amazon S3 Glacier Instant Retrieval. Query the tags to retrieve the files from S3 Glacier Instant Retrieval.",
      "B": "Store individual files in Amazon S3 Intelligent-Tiering. Use S3 Lifecycle policies to move the files to S3 Glacier Flexible Retrieval after 1 year. Query and retrieve the files that are in Amazon S3 by using Amazon Athena. Query and retrieve the files that are in S3 Glacier by using S3 Glacier Select.",
      "C": "Store individual files with tags in Amazon S3 Standard storage. Store search metadata for each archive in Amazon S3 Standard storage. Use S3 Lifecycle policies to move the files to S3 Glacier Instant Retrieval after 1 year. Query and retrieve the files by searching for metadata from Amazon S3.",
      "D": "Store individual files in Amazon S3 Standard storage. Use S3 Lifecycle policies to move the files to S3 Glacier Deep Archive after 1 year. Store search metadata in Amazon RDS. Query the files from Amazon RDS. Retrieve the files from S3 Glacier Deep Archive."
    },
    "correct_answer": "C",
    "vote_percentage": "69%",
    "question_cn": "一家公司按月存储通话记录文件。用户在通话后 1 年内随机访问这些文件，但 1 年后用户很少访问这些文件。该公司希望通过为用户提供尽可能快速地查询和检索不到 1 年的文件来优化其解决方案。检索较旧文件时的延迟是可以接受的。哪种解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将单个文件及其标签存储在 Amazon S3 Glacier Instant Retrieval 中。查询标签以从 S3 Glacier Instant Retrieval 检索文件。",
      "B": "将单个文件存储在 Amazon S3 Intelligent-Tiering 中。使用 S3 生命周期策略在 1 年后将文件移动到 S3 Glacier Flexible Retrieval。使用 Amazon Athena 查询和检索 Amazon S3 中的文件。使用 S3 Glacier Select 查询和检索 S3 Glacier 中的文件。",
      "C": "将单个文件及其标签存储在 Amazon S3 Standard 存储中。将每个存档的搜索元数据存储在 Amazon S3 Standard 存储中。使用 S3 生命周期策略在 1 年后将文件移动到 S3 Glacier Instant Retrieval。通过搜索来自 Amazon S3 的元数据来查询和检索文件。",
      "D": "将单个文件存储在 Amazon S3 Standard 存储中。使用 S3 生命周期策略在 1 年后将文件移动到 S3 Glacier Deep Archive。将搜索元数据存储在 Amazon RDS 中。从 Amazon RDS 查询文件。从 S3 Glacier Deep Archive 检索文件。"
    }
  },
  {
    "id": 50,
    "topic": "1",
    "question_en": "A company has a production workload that runs on 1,000 Amazon EC2 Linux instances. The workload is powered by third-party software. The company needs to patch the third-party software on all EC2 instances as quickly as possible to remediate a critical security vulnerability. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an AWS Lambda function to apply the patch to all EC2 instances.",
      "B": "Configure AWS Systems Manager Patch Manager to apply the patch to all EC2 instances.",
      "C": "Schedule an AWS Systems Manager maintenance window to apply the patch to all EC2 instances.",
      "D": "Use AWS Systems Manager Run Command to run a custom command that applies the patch to all EC2 instances."
    },
    "correct_answer": "D",
    "vote_percentage": "73%",
    "question_cn": "一家公司有一个在 1,000 个 Amazon EC2 Linux 实例上运行的生产工作负载。该工作负载由第三方软件提供支持。该公司需要尽快修补所有 EC2 实例上的第三方软件，以修复关键的安全漏洞。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，将补丁应用于所有 EC2 实例。",
      "B": "配置 AWS Systems Manager Patch Manager 以将补丁应用于所有 EC2 实例。",
      "C": "安排一个 AWS Systems Manager 维护时段，将补丁应用于所有 EC2 实例。",
      "D": "使用 AWS Systems Manager Run Command 运行一个自定义命令，该命令应用补丁到所有 EC2 实例。"
    }
  },
  {
    "id": 51,
    "topic": "1",
    "question_en": "A company is developing an application that provides order shipping statistics for retrieval by a REST API. The company wants to extract the shipping statistics, organize the data into an easy-to-read HTML format, and send the report to several email addresses at the same time every morning. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Configure the application to send the data to Amazon Kinesis Data Firehose.",
      "B": "Use Amazon Simple Email Service (Amazon SES) to format the data and to send the report by email.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Glue job to query the application's API for the data.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Lambda function to query the application's API for the data",
      "E": "Store the application data in Amazon S3. Create an Amazon Simple Notification Service (Amazon SNS) topic as an S3 event destination to send the report by email."
    },
    "correct_answer": "D",
    "vote_percentage": "69%",
    "question_cn": "一家公司正在开发一个应用程序，该应用程序提供订单发货统计数据，以供 REST API 检索。该公司希望提取发货统计数据，将数据组织成易于阅读的 HTML 格式，并在每天早上同一时间将报告发送到多个电子邮件地址。 解决方案架构师应采取哪些组合步骤来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "配置应用程序将数据发送到 Amazon Kinesis Data Firehose。",
      "B": "使用 Amazon Simple Email Service (Amazon SES) 格式化数据并通过电子邮件发送报告。",
      "C": "创建一个 Amazon EventBridge (Amazon CloudWatch Events) 定时事件，该事件调用 AWS Glue 作业以查询应用程序的 API 获取数据。",
      "D": "创建一个 Amazon EventBridge (Amazon CloudWatch Events) 定时事件，该事件调用 AWS Lambda 函数以查询应用程序的 API 获取数据。",
      "E": "将应用程序数据存储在 Amazon S3 中。 创建一个 Amazon Simple Notification Service (Amazon SNS) 主题作为 S3 事件目的地，通过电子邮件发送报告。"
    }
  },
  {
    "id": 52,
    "topic": "1",
    "question_en": "A company wants to migrate its on-premises application to AWS. The application produces output files that vary in size from tens of gigabytes to hundreds of terabytes. The application data must be stored in a standard file system structure. The company wants a solution that scales automatically. is highly available, and requires minimum operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the application to run as containers on Amazon Elastic Container Service (Amazon ECS). Use Amazon S3 for storage.",
      "B": "Migrate the application to run as containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Block Store (Amazon EBS) for storage.",
      "C": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic File System (Amazon EFS) for storage.",
      "D": "Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic Block Store (Amazon EBS) for storage."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将其本地应用程序迁移到 AWS。该应用程序生成的输出文件大小从数十 GB 到数百 TB 不等。应用程序数据必须存储在标准文件系统结构中。该公司希望找到一个可以自动扩展、高度可用且运营开销最少的解决方案。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将应用程序迁移为在 Amazon Elastic Container Service (Amazon ECS) 上以容器形式运行。使用 Amazon S3 进行存储。",
      "B": "将应用程序迁移为在 Amazon Elastic Kubernetes Service (Amazon EKS) 上以容器形式运行。使用 Amazon Elastic Block Store (Amazon EBS) 进行存储。",
      "C": "将应用程序迁移到 Multi-AZ Auto Scaling 组中的 Amazon EC2 实例。使用 Amazon Elastic File System (Amazon EFS) 进行存储。",
      "D": "将应用程序迁移到 Multi-AZ Auto Scaling 组中的 Amazon EC2 实例。使用 Amazon Elastic Block Store (Amazon EBS) 进行存储。"
    }
  },
  {
    "id": 53,
    "topic": "1",
    "question_en": "A company needs to store its accounting records in Amazon S3. The records must be immediately accessible for 1 year and then must be archived for an additional 9 years. No one at the company, including administrative users and root users, can be able to delete the records during the entire 10-year period. The records must be stored with maximum resiliency. Which solution will meet these requirements?",
    "options_en": {
      "A": "Store the records in S3 Glacier for the entire 10-year period. Use an access control policy to deny deletion of the records for a period of 10 years.",
      "B": "Store the records by using S3 Intelligent-Tiering. Use an IAM policy to deny deletion of the records. After 10 years, change the IAM policy to allow deletion.",
      "C": "Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 Glacier Deep Archive after 1 year. Use S3 Object Lock in compliance mode for a period of 10 years.",
      "D": "Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 year. Use S3 Object Lock in governance mode for a period of 10 years."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要将会计记录存储在 Amazon S3 中。这些记录必须可立即访问 1 年，然后必须存档 9 年。在整个 10 年期间，公司内没有人，包括管理用户和根用户，都能够删除这些记录。这些记录必须以最大的弹性进行存储。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将记录在 S3 Glacier 中存储整个 10 年。使用访问控制策略来拒绝在 10 年内删除记录。",
      "B": "使用 S3 Intelligent-Tiering 存储记录。使用 IAM 策略来拒绝删除记录。10 年后，更改 IAM 策略以允许删除。",
      "C": "使用 S3 生命周期策略在 1 年后将记录从 S3 Standard 转换为 S3 Glacier Deep Archive。在合规模式下使用 S3 Object Lock 锁定 10 年。",
      "D": "使用 S3 生命周期策略在 1 年后将记录从 S3 Standard 转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)。在管理模式下使用 S3 Object Lock 锁定 10 年。"
    }
  },
  {
    "id": 54,
    "topic": "1",
    "question_en": "A company runs multiple Windows workloads on AWS. The company's employees use Windows file shares that are hosted on two Amazon EC2 instances. The file shares synchronize data between themselves and maintain duplicate copies. The company wants a highly available and durable storage solution that preserves how users currently access the files. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Migrate all the data to Amazon S3. Set up IAM authentication for users to access files.",
      "B": "Set up an Amazon S3 File Gateway. Mount the S3 File Gateway on the existing EC2 instances.",
      "C": "Extend the file share environment to Amazon FSx for Windows File Server with a Multi-AZ configuration. Migrate all the data to FSx for Windows File Server.",
      "D": "Extend the file share environment to Amazon Elastic File System (Amazon EFS) with a Multi-AZ configuration. Migrate all the data to Amazon EFS."
    },
    "correct_answer": "C",
    "vote_percentage": "98%",
    "question_cn": "一家公司在 AWS 上运行多个 Windows 工作负载。 公司的员工使用托管在两个 Amazon EC2 实例上的 Windows 文件共享。 文件共享在它们之间同步数据并维护重复的副本。 公司希望获得一个高可用性和持久的存储解决方案，以保留用户当前访问文件的方式。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将所有数据迁移到 Amazon S3。 设置 IAM 身份验证，供用户访问文件。",
      "B": "设置一个 Amazon S3 File Gateway。 将 S3 File Gateway 挂载在现有的 EC2 实例上。",
      "C": "将文件共享环境扩展到具有 Multi-AZ 配置的 Amazon FSx for Windows File Server。 将所有数据迁移到 FSx for Windows File Server。",
      "D": "将文件共享环境扩展到具有 Multi-AZ 配置的 Amazon Elastic File System (Amazon EFS)。 将所有数据迁移到 Amazon EFS。"
    }
  },
  {
    "id": 55,
    "topic": "1",
    "question_en": "A solutions architect is developing a VPC architecture that includes multiple subnets. The architecture will host applications that use Amazon EC2 instances and Amazon RDS DB instances. The architecture consists of six subnets in two Availability Zones. Each Availability Zone includes a public subnet, a private subnet, and a dedicated subnet for databases. Only EC2 instances that run in the private subnets can have access to the RDS databases. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a new route table that excludes the route to the public subnets' CIDR blocks. Associate the route table with the database subnets.",
      "B": "Create a security group that denies inbound trafic from the security group that is assigned to instances in the public subnets. Attach the security group to the DB instances.",
      "C": "Create a security group that allows inbound trafic from the security group that is assigned to instances in the private subnets. Attach the security group to the DB instances.",
      "D": "Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在开发包含多个子网的 VPC 架构。该架构将托管使用 Amazon EC2 实例和 Amazon RDS 数据库实例的应用程序。该架构由两个可用区中的六个子网组成。每个可用区包含一个公有子网、一个私有子网和一个用于数据库的专用子网。只有在私有子网中运行的 EC2 实例才能访问 RDS 数据库。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个新的路由表，该路由表排除到公有子网 CIDR 块的路由。将该路由表与数据库子网关联。",
      "B": "创建一个安全组，该安全组拒绝来自分配给公有子网中实例的安全组的入站流量。将安全组附加到数据库实例。",
      "C": "创建一个安全组，该安全组允许来自分配给私有子网中实例的安全组的入站流量。将安全组附加到数据库实例。",
      "D": "在公有子网和私有子网之间创建一个新的对等连接。在私有子网和数据库子网之间创建不同的对等连接。"
    }
  },
  {
    "id": 56,
    "topic": "1",
    "question_en": "A company has registered its domain name with Amazon Route 53. The company uses Amazon API Gateway in the ca-central-1 Region as a public interface for its backend microservice APIs. Third-party services consume the APIs securely. The company wants to design its API Gateway URL with the company's domain name and corresponding certificate so that the third-party services can use HTTPS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create stage variables in API Gateway with Name=\"Endpoint-URL\" and Value=\"Company Domain Name\" to overwrite the default URL. Import the public certificate associated with the company's domain name into AWS Certificate Manager (ACM).",
      "B": "Create Route 53 DNS records with the company's domain name. Point the alias record to the Regional API Gateway stage endpoint. Import the public certificate associated with the company's domain name into AWS Certificate Manager (ACM) in the us-east-1 Region.",
      "C": "Create a Regional API Gateway endpoint. Associate the API Gateway endpoint with the company's domain name. Import the public certificate associated with the company's domain name into AWS Certificate Manager (ACM) in the same Region. Attach the certificate to the API Gateway endpoint. Configure Route 53 to route trafic to the API Gateway endpoint.",
      "D": "Create a Regional API Gateway endpoint. Associate the API Gateway endpoint with the company's domain name. Import the public certificate associated with the company's domain name into AWS Certificate Manager (ACM) in the us-east-1 Region. Attach the certificate to the API Gateway APIs. Create Route 53 DNS records with the company's domain name. Point an A record to the company's domain name."
    },
    "correct_answer": "D",
    "vote_percentage": "94%",
    "question_cn": "一家公司已使用 Amazon Route 53 注册了其域名。该公司在其位于 ca-central-1 区域的 Amazon API Gateway 中用作其后端微服务 API 的公共接口。第三方服务安全地使用这些 API。该公司希望使用公司的域名及其相应的证书来设计其 API Gateway URL，以便第三方服务可以使用 HTTPS。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 API Gateway 中创建阶段变量，名称为“Endpoint-URL”，值为“公司域名”以覆盖默认 URL。将与公司域名关联的公共证书导入 AWS Certificate Manager (ACM)。",
      "B": "创建 Route 53 DNS 记录，使用公司的域名。将别名记录指向区域 API Gateway 阶段端点。将与公司域名关联的公共证书导入位于 us-east-1 区域的 AWS Certificate Manager (ACM)。",
      "C": "创建区域 API Gateway 端点。将 API Gateway 端点与公司的域名关联。将与公司域名关联的公共证书导入同一区域的 AWS Certificate Manager (ACM)。将证书附加到 API Gateway 端点。配置 Route 53 将流量路由到 API Gateway 端点。",
      "D": "创建区域 API Gateway 端点。将 API Gateway 端点与公司的域名关联。将与公司域名关联的公共证书导入位于 us-east-1 区域的 AWS Certificate Manager (ACM)。将证书附加到 API Gateway API。创建 Route 53 DNS 记录，使用公司的域名。将 A 记录指向公司的域名。"
    }
  },
  {
    "id": 57,
    "topic": "1",
    "question_en": "A company is running a popular social media website. The website gives users the ability to upload images to share with other users. The company wants to make sure that the images do not contain inappropriate content. The company needs a solution that minimizes development effort. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use Amazon Comprehend to detect inappropriate content. Use human review for low-confidence predictions.",
      "B": "Use Amazon Rekognition to detect inappropriate content. Use human review for low-confidence predictions.",
      "C": "Use Amazon SageMaker to detect inappropriate content. Use ground truth to label low-confidence predictions.",
      "D": "Use AWS Fargate to deploy a custom machine learning model to detect inappropriate content. Use ground truth to label low-confidence predictions."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在运营一个流行的社交媒体网站。该网站允许用户上传图片与其他人分享。该公司希望确保图片不包含不当内容。该公司需要一个最大限度减少开发工作量的解决方案。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Comprehend 检测不当内容。对低置信度的预测进行人工审核。",
      "B": "使用 Amazon Rekognition 检测不当内容。对低置信度的预测进行人工审核。",
      "C": "使用 Amazon SageMaker 检测不当内容。使用 ground truth 标记低置信度的预测。",
      "D": "使用 AWS Fargate 部署一个自定义机器学习模型来检测不当内容。使用 ground truth 标记低置信度的预测。"
    }
  },
  {
    "id": 58,
    "topic": "1",
    "question_en": "A company wants to run its critical applications in containers to meet requirements for scalability and availability. The company prefers to focus on maintenance of the critical applications. The company does not want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workload. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use Amazon EC2 instances, and install Docker on the instances.",
      "B": "Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes.",
      "C": "Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.",
      "D": "Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)-optimized Amazon Machine Image (AMI)."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在容器中运行其关键应用程序，以满足可扩展性和可用性的要求。该公司倾向于专注于关键应用程序的维护。该公司不想负责配置和管理运行容器化工作负载的底层基础设施。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EC2 实例，并在这些实例上安装 Docker。",
      "B": "在 Amazon EC2 worker 节点上使用 Amazon Elastic Container Service (Amazon ECS)。",
      "C": "使用 AWS Fargate 上的 Amazon Elastic Container Service (Amazon ECS)。",
      "D": "使用来自 Amazon Elastic Container Service (Amazon ECS) 优化 Amazon Machine Image (AMI) 的 Amazon EC2 实例。"
    }
  },
  {
    "id": 59,
    "topic": "1",
    "question_en": "A company hosts more than 300 global websites and applications. The company requires a platform to analyze more than 30 TB of clickstream data each day. What should a solutions architect do to transmit and process the clickstream data?",
    "options_en": {
      "A": "Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics.",
      "B": "Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis.",
      "C": "Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket. run an AWS Lambda function to process the data for analysis.",
      "D": "Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis."
    },
    "correct_answer": "D",
    "vote_percentage": "90%",
    "question_cn": "一家公司托管了 300 多个全球网站和应用程序。该公司需要一个平台来每天分析超过 30 TB 的点击流数据。解决方案架构师应该怎么做才能传输和处理点击流数据？",
    "options_cn": {
      "A": "设计一个 AWS Data Pipeline 以将数据归档到 Amazon S3 存储桶，并使用数据运行 Amazon EMR 集群以生成分析结果。",
      "B": "创建一个 Amazon EC2 实例的 Auto Scaling 组来处理数据，并将其发送到 Amazon S3 数据湖，供 Amazon Redshift 用于分析。",
      "C": "将数据缓存在 Amazon CloudFront 中。将数据存储在 Amazon S3 存储桶中。当对象添加到 S3 存储桶时，运行一个 AWS Lambda 函数来处理数据以进行分析。",
      "D": "从 Amazon Kinesis Data Streams 收集数据。使用 Amazon Kinesis Data Firehose 将数据传输到 Amazon S3 数据湖。将数据加载到 Amazon Redshift 中进行分析。"
    }
  },
  {
    "id": 60,
    "topic": "1",
    "question_en": "A company has a website hosted on AWS. The website is behind an Application Load Balancer (ALB) that is configured to handle HTTP and HTTPS separately. The company wants to forward all requests to the website so that the requests will use HTTPS. What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Update the ALB's network ACL to accept only HTTPS trafic.",
      "B": "Create a rule that replaces the HTTP in the URL with HTTPS.",
      "C": "Create a listener rule on the ALB to redirect HTTP trafic to HTTPS.",
      "D": "Replace the ALB with a Network Load Balancer configured to use Server Name Indication (SNI)."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上托管了一个网站。该网站位于 Application Load Balancer (ALB) 后面，该 ALB 配置为单独处理 HTTP 和 HTTPS。该公司希望将所有请求转发到该网站，以便请求使用 HTTPS。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "更新 ALB 的网络 ACL，仅接受 HTTPS 流量。",
      "B": "创建一个规则，将 URL 中的 HTTP 替换为 HTTPS。",
      "C": "在 ALB 上创建一个侦听器规则，将 HTTP 流量重定向到 HTTPS。",
      "D": "将 ALB 替换为配置为使用服务器名称指示 (SNI) 的 Network Load Balancer。"
    }
  },
  {
    "id": 61,
    "topic": "1",
    "question_en": "A company is developing a two-tier web application on AWS. The company's developers have deployed the application on an Amazon EC2 instance that connects directly to a backend Amazon RDS database. The company must not hardcode database credentials in the application. The company must also implement a solution to automatically rotate the database credentials on a regular basis. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the database credentials in the instance metadata. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and instance metadata at the same time.",
      "B": "Store the database credentials in a configuration file in an encrypted Amazon S3 bucket. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and the credentials in the configuration file at the same time. Use S3 Versioning to ensure the ability to fall back to previous values.",
      "C": "Store the database credentials as a secret in AWS Secrets Manager. Turn on automatic rotation for the secret. Attach the required permission to the EC2 role to grant access to the secret.",
      "D": "Store the database credentials as encrypted parameters in AWS Systems Manager Parameter Store. Turn on automatic rotation for the encrypted parameters. Attach the required permission to the EC2 role to grant access to the encrypted parameters."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上开发一个两层 Web 应用程序。公司的开发人员已将应用程序部署在连接到后端 Amazon RDS 数据库的 Amazon EC2 实例上。公司不得在应用程序中硬编码数据库凭证。公司还必须实施一个解决方案，以定期间隔自动轮换数据库凭证。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将数据库凭证存储在实例元数据中。使用 Amazon EventBridge (Amazon CloudWatch Events) 规则运行一个预定的 AWS Lambda 函数，该函数同时更新 RDS 凭证和实例元数据。",
      "B": "将数据库凭证存储在加密的 Amazon S3 存储桶中的配置文件中。使用 Amazon EventBridge (Amazon CloudWatch Events) 规则运行一个预定的 AWS Lambda 函数，该函数同时更新 RDS 凭证和配置文件中的凭证。使用 S3 版本控制以确保能够回退到先前的值。",
      "C": "将数据库凭证作为密钥存储在 AWS Secrets Manager 中。打开密钥的自动轮换功能。将所需权限附加到 EC2 角色以授予对密钥的访问权限。",
      "D": "将数据库凭证作为加密参数存储在 AWS Systems Manager Parameter Store 中。打开加密参数的自动轮换功能。将所需权限附加到 EC2 角色以授予对加密参数的访问权限。"
    }
  },
  {
    "id": 62,
    "topic": "1",
    "question_en": "A company is deploying a new public web application to AWS. The application will run behind an Application Load Balancer (ALB). The application needs to be encrypted at the edge with an SSL/TLS certificate that is issued by an external certificate authority (CA). The certificate must be rotated each year before the certificate expires. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate.",
      "B": "Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Import the key material from the certificate. Apply the certificate to the ALUse the managed renewal feature to automatically rotate the certificate.",
      "C": "Use AWS Certificate Manager (ACM) Private Certificate Authority to issue an SSL/TLS certificate from the root CA. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate.",
      "D": "Use AWS Certificate Manager (ACM) to import an SSL/TLS certificate. Apply the certificate to the ALB. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification when the certificate is nearing expiration. Rotate the certificate manually."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司正在将新的公共 Web 应用程序部署到 AWS。该应用程序将在 Application Load Balancer (ALB) 后面运行。该应用程序需要在边缘使用由外部证书颁发机构 (CA) 颁发的 SSL/TLS 证书进行加密。该证书必须在证书过期之前每年轮换一次。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Certificate Manager (ACM) 颁发 SSL/TLS 证书。将该证书应用于 ALB。使用托管续订功能自动轮换证书。",
      "B": "使用 AWS Certificate Manager (ACM) 颁发 SSL/TLS 证书。从证书导入密钥材料。将该证书应用于 ALB。使用托管续订功能自动轮换证书。",
      "C": "使用 AWS Certificate Manager (ACM) 私有证书颁发机构从根 CA 颁发 SSL/TLS 证书。将该证书应用于 ALB。使用托管续订功能自动轮换证书。",
      "D": "使用 AWS Certificate Manager (ACM) 导入 SSL/TLS 证书。将该证书应用于 ALB。使用 Amazon EventBridge (Amazon CloudWatch Events) 在证书即将到期时发送通知。手动轮换证书。"
    }
  },
  {
    "id": 63,
    "topic": "1",
    "question_en": "A company runs its infrastructure on AWS and has a registered base of 700,000 users for its document management application. The company intends to create a product that converts large .pdf files to .jpg image files. The .pdf files average 5 MB in size. The company needs to store the original files and the converted files. A solutions architect must design a scalable solution to accommodate demand that will grow rapidly over time. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Save the .pdf files to Amazon S3. Configure an S3 PUT event to invoke an AWS Lambda function to convert the files to .jpg format and store them back in Amazon S3.",
      "B": "Save the .pdf files to Amazon DynamoDUse the DynamoDB Streams feature to invoke an AWS Lambda function to convert the files to .jpg format and store them back in DynamoDB.",
      "C": "Upload the .pdf files to an AWS Elastic Beanstalk application that includes Amazon EC2 instances, Amazon Elastic Block Store (Amazon EBS) storage, and an Auto Scaling group. Use a program in the EC2 instances to convert the files to .jpg format. Save the .pdf files and the .jpg files in the EBS store.",
      "D": "Upload the .pdf files to an AWS Elastic Beanstalk application that includes Amazon EC2 instances, Amazon Elastic File System (Amazon EFS) storage, and an Auto Scaling group. Use a program in the EC2 instances to convert the file to .jpg format. Save the .pdf files and the .jpg files in the EBS store."
    },
    "correct_answer": "A",
    "vote_percentage": "99%",
    "question_cn": "一家公司在 AWS 上运行其基础设施，并为其文档管理应用程序注册了 700,000 个用户。该公司计划创建一个将大型 .pdf 文件转换为 .jpg 图像文件的产品。 .pdf 文件平均大小为 5 MB。该公司需要存储原始文件和转换后的文件。解决方案架构师必须设计一个可扩展的解决方案，以适应会随着时间推移而快速增长的需求。哪个解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "将 .pdf 文件保存到 Amazon S3。配置一个 S3 PUT 事件来调用一个 AWS Lambda 函数，以将文件转换为 .jpg 格式，并将它们存储回 Amazon S3。",
      "B": "将 .pdf 文件保存到 Amazon DynamoDB。使用 DynamoDB Streams 功能来调用一个 AWS Lambda 函数，以将文件转换为 .jpg 格式，并将它们存储回 DynamoDB。",
      "C": "将 .pdf 文件上传到包含 Amazon EC2 实例、Amazon Elastic Block Store (Amazon EBS) 存储和一个 Auto Scaling 组的 AWS Elastic Beanstalk 应用程序。在 EC2 实例中使用一个程序将文件转换为 .jpg 格式。将 .pdf 文件和 .jpg 文件保存在 EBS 存储中。",
      "D": "将 .pdf 文件上传到包含 Amazon EC2 实例、Amazon Elastic File System (Amazon EFS) 存储和一个 Auto Scaling 组的 AWS Elastic Beanstalk 应用程序。在 EC2 实例中使用一个程序将文件转换为 .jpg 格式。将 .pdf 文件和 .jpg 文件保存在 EBS 存储中。"
    }
  },
  {
    "id": 64,
    "topic": "1",
    "question_en": "A company has more than 5 TB of file data on Windows file servers that run on premises. Users and applications interact with the data each day. The company is moving its Windows workloads to AWS. As the company continues this process, the company requires access to AWS and on- premises file storage with minimum latency. The company needs a solution that minimizes operational overhead and requires no significant changes to the existing file access patterns. The company uses an AWS Site-to-Site VPN connection for connectivity to AWS. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Deploy and configure Amazon FSx for Windows File Server on AWS. Move the on-premises file data to FSx for Windows File Server. Reconfigure the workloads to use FSx for Windows File Server on AWS.",
      "B": "Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to the S3 File Gateway. Reconfigure the on-premises workloads and the cloud workloads to use the S3 File Gateway.",
      "C": "Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to Amazon S3. Reconfigure the workloads to use either Amazon S3 directly or the S3 File Gateway. depending on each workload's location.",
      "D": "Deploy and configure Amazon FSx for Windows File Server on AWS. Deploy and configure an Amazon FSx File Gateway on premises. Move the on-premises file data to the FSx File Gateway. Configure the cloud workloads to use FSx for Windows File Server on AWS. Configure the on-premises workloads to use the FSx File Gateway."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司在本地运行的 Windows 文件服务器上拥有超过 5 TB 的文件数据。用户和应用程序每天都与这些数据交互。该公司正在将其 Windows 工作负载迁移到 AWS。随着该公司继续此过程，该公司需要以最小延迟访问 AWS 和本地文件存储。该公司需要一个最大限度地减少运营开销且不需要对其现有文件访问模式进行重大更改的解决方案。该公司使用 AWS Site-to-Site VPN 连接到 AWS。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在 AWS 上部署和配置 Amazon FSx for Windows File Server。将本地文件数据移动到 FSx for Windows File Server。重新配置工作负载以使用 AWS 上的 FSx for Windows File Server。",
      "B": "在本地部署和配置 Amazon S3 File Gateway。将本地文件数据移动到 S3 File Gateway。重新配置本地工作负载和云工作负载以使用 S3 File Gateway。",
      "C": "在本地部署和配置 Amazon S3 File Gateway。将本地文件数据移动到 Amazon S3。重新配置工作负载以根据每个工作负载的位置直接使用 Amazon S3 或 S3 File Gateway。",
      "D": "在 AWS 上部署和配置 Amazon FSx for Windows File Server。在本地部署和配置 Amazon FSx File Gateway。将本地文件数据移动到 FSx File Gateway。配置云工作负载以使用 AWS 上的 FSx for Windows File Server。配置本地工作负载以使用 FSx File Gateway。"
    }
  },
  {
    "id": 65,
    "topic": "1",
    "question_en": "A hospital recently deployed a RESTful API with Amazon API Gateway and AWS Lambda. The hospital uses API Gateway and Lambda to upload reports that are in PDF format and JPEG format. The hospital needs to modify the Lambda code to identify protected health information (PHI) in the reports. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use existing Python libraries to extract the text from the reports and to identify the PHI from the extracted text.",
      "B": "Use Amazon Textract to extract the text from the reports. Use Amazon SageMaker to identify the PHI from the extracted text.",
      "C": "Use Amazon Textract to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text.",
      "D": "Use Amazon Rekognition to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家医院最近使用 Amazon API Gateway 和 AWS Lambda 部署了一个 RESTful API。医院使用 API Gateway 和 Lambda 上传 PDF 和 JPEG 格式的报告。医院需要修改 Lambda 代码以识别报告中的受保护健康信息 (PHI)。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用现有的 Python 库从报告中提取文本，并从提取的文本中识别 PHI。",
      "B": "使用 Amazon Textract 从报告中提取文本。使用 Amazon SageMaker 从提取的文本中识别 PHI。",
      "C": "使用 Amazon Textract 从报告中提取文本。使用 Amazon Comprehend Medical 从提取的文本中识别 PHI。",
      "D": "使用 Amazon Rekognition 从报告中提取文本。使用 Amazon Comprehend Medical 从提取的文本中识别 PHI。"
    }
  },
  {
    "id": 66,
    "topic": "1",
    "question_en": "A company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days. Which storage solution is MOST cost-effective?",
    "options_en": {
      "A": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation.",
      "B": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation.",
      "C": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.",
      "D": "Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation."
    },
    "correct_answer": "C",
    "vote_percentage": "66%",
    "question_cn": "一家公司有一个应用程序，该应用程序会生成大量文件，每个文件大约 5 MB 大小。这些文件存储在 Amazon S3 中。公司策略要求这些文件在删除之前需要存储 4 年。由于这些文件包含不易再现的关键业务数据，因此始终需要即时访问。文件在创建后的前 30 天内会经常被访问，但在前 30 天后很少被访问。哪种存储解决方案最具成本效益？",
    "options_cn": {
      "A": "创建一个 S3 存储桶生命周期策略，将文件从 S3 Standard 转移到 S3 Glacier，从对象创建后 30 天开始。在对象创建 4 年后删除这些文件。",
      "B": "创建一个 S3 存储桶生命周期策略，将文件从 S3 Standard 转移到 S3 One Zone-Infrequent Access (S3 One Zone-IA)，从对象创建后 30 天开始。在对象创建 4 年后删除这些文件。",
      "C": "创建一个 S3 存储桶生命周期策略，将文件从 S3 Standard 转移到 S3 Standard-Infrequent Access (S3 Standard-IA)，从对象创建后 30 天开始。在对象创建 4 年后删除这些文件。",
      "D": "创建一个 S3 存储桶生命周期策略，将文件从 S3 Standard 转移到 S3 Standard-Infrequent Access (S3 Standard-IA)，从对象创建后 30 天开始。在对象创建 4 年后将文件转移到 S3 Glacier。"
    }
  },
  {
    "id": 67,
    "topic": "1",
    "question_en": "A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue, writes to an Amazon RDS table, and deletes the message from the queue. Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages. What should a solutions architect do to ensure messages are being processed once only?",
    "options_en": {
      "A": "Use the CreateQueue API call to create a new queue.",
      "B": "Use the AddPermission API call to add appropriate permissions.",
      "C": "Use the ReceiveMessage API call to set an appropriate wait time.",
      "D": "Use the ChangeMessageVisibility API call to increase the visibility timeout."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在多个 Amazon EC2 实例上托管一个应用程序。该应用程序处理来自 Amazon SQS 队列的消息，写入 Amazon RDS 表，并从队列中删除消息。RDS 表中偶尔会发现重复的记录。SQS 队列不包含任何重复的消息。解决方案架构师应采取什么措施来确保消息仅被处理一次？",
    "options_cn": {
      "A": "使用 CreateQueue API 调用创建一个新队列。",
      "B": "使用 AddPermission API 调用添加适当的权限。",
      "C": "使用 ReceiveMessage API 调用设置适当的等待时间。",
      "D": "使用 ChangeMessageVisibility API 调用来增加可见性超时。"
    }
  },
  {
    "id": 68,
    "topic": "1",
    "question_en": "A solutions architect is designing a new hybrid architecture to extend a company's on-premises infrastructure to AWS. The company requires a highly available connection with consistent low latency to an AWS Region. The company needs to minimize costs and is willing to accept slower trafic if the primary connection fails. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Provision an AWS Direct Connect connection to a Region. Provision a VPN connection as a backup if the primary Direct Connect connection fails.",
      "B": "Provision a VPN tunnel connection to a Region for private connectivity. Provision a second VPN tunnel for private connectivity and as a backup if the primary VPN connection fails.",
      "C": "Provision an AWS Direct Connect connection to a Region. Provision a second Direct Connect connection to the same Region as a backup if the primary Direct Connect connection fails.",
      "D": "Provision an AWS Direct Connect connection to a Region. Use the Direct Connect failover attribute from the AWS CLI to automatically create a backup connection if the primary Direct Connect connection fails."
    },
    "correct_answer": "A",
    "vote_percentage": "94%",
    "question_cn": "一位解决方案架构师正在设计一个新的混合架构，以将一家公司的本地基础设施扩展到 AWS。该公司需要一个高可用性、具有一致低延迟的连接到 AWS 区域。该公司需要最大限度地降低成本，并且如果主连接失败，愿意接受较慢的流量。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "预置一个 AWS Direct Connect 连接到某个区域。如果主 Direct Connect 连接失败，则预置一个 VPN 连接作为备份。",
      "B": "预置一个 VPN 隧道连接到某个区域以进行私有连接。预置第二个 VPN 隧道以进行私有连接，并作为备份，以防主 VPN 连接失败。",
      "C": "预置一个 AWS Direct Connect 连接到某个区域。如果主 Direct Connect 连接失败，则预置第二个 Direct Connect 连接到同一区域作为备份。",
      "D": "预置一个 AWS Direct Connect 连接到某个区域。使用来自 AWS CLI 的 Direct Connect 故障转移属性，如果主 Direct Connect 连接失败，则自动创建一个备份连接。"
    }
  },
  {
    "id": 69,
    "topic": "1",
    "question_en": "A company is running a business-critical web application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances are in an Auto Scaling group. The application uses an Amazon Aurora PostgreSQL database that is deployed in a single Availability Zone. The company wants the application to be highly available with minimum downtime and minimum loss of data. Which solution will meet these requirements with the LEAST operational effort?",
    "options_en": {
      "A": "Place the EC2 instances in different AWS Regions. Use Amazon Route 53 health checks to redirect trafic. Use Aurora PostgreSQL Cross- Region Replication.",
      "B": "Configure the Auto Scaling group to use multiple Availability Zones. Configure the database as Multi-AZ. Configure an Amazon RDS Proxy instance for the database.",
      "C": "Configure the Auto Scaling group to use one Availability Zone. Generate hourly snapshots of the database. Recover the database from the snapshots in the event of a failure.",
      "D": "Configure the Auto Scaling group to use multiple AWS Regions. Write the data from the application to Amazon S3. Use S3 Event Notifications to launch an AWS Lambda function to write the data to the database."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司在其Application Load Balancer后面的Amazon EC2实例上运行着一项关键业务Web应用程序。 EC2实例位于一个Auto Scaling组中。该应用程序使用部署在单个可用区中的Amazon Aurora PostgreSQL数据库。公司希望该应用程序具有高可用性，且停机时间最短，数据丢失最少。哪个解决方案将以最少的运营工作量满足这些要求？",
    "options_cn": {
      "A": "将EC2实例放置在不同的AWS区域。使用Amazon Route 53健康检查来重定向流量。使用Aurora PostgreSQL 跨区域复制。",
      "B": "配置Auto Scaling组以使用多个可用区。将数据库配置为Multi-AZ。为数据库配置Amazon RDS Proxy实例。",
      "C": "配置Auto Scaling组以使用一个可用区。每小时拍摄数据库快照。在发生故障时从快照恢复数据库。",
      "D": "配置Auto Scaling组以使用多个AWS区域。将应用程序中的数据写入Amazon S3。使用S3事件通知来启动一个AWS Lambda函数，将数据写入数据库。"
    }
  },
  {
    "id": 70,
    "topic": "1",
    "question_en": "A company's HTTP application is behind a Network Load Balancer (NLB). The NLB's target group is configured to use an Amazon EC2 Auto Scaling group with multiple EC2 instances that run the web service. The company notices that the NLB is not detecting HTTP errors for the application. These errors require a manual restart of the EC2 instances that run the web service. The company needs to improve the application's availability without writing custom scripts or code. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Enable HTTP health checks on the NLB, supplying the URL of the company's application.",
      "B": "Add a cron job to the EC2 instances to check the local application's logs once each minute. If HTTP errors are detected. the application will restart.",
      "C": "Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company's application. Configure an Auto Scaling action to replace unhealthy instances.",
      "D": "Create an Amazon Cloud Watch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state."
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家公司的 HTTP 应用程序位于 Network Load Balancer (NLB) 之后。NLB 的目标组被配置为使用 Amazon EC2 Auto Scaling 组，该组具有多个运行 Web 服务的 EC2 实例。该公司注意到 NLB 未检测到应用程序的 HTTP 错误。这些错误需要手动重启运行 Web 服务的 EC2 实例。该公司需要提高应用程序的可用性，而无需编写自定义脚本或代码。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在 NLB 上启用 HTTP 运行状况检查，提供公司应用程序的 URL。",
      "B": "在 EC2 实例中添加一个 cron 作业，每分钟检查一次本地应用程序的日志。如果检测到 HTTP 错误，应用程序将重新启动。",
      "C": "用 Application Load Balancer 替换 NLB。通过提供公司应用程序的 URL 来启用 HTTP 运行状况检查。配置 Auto Scaling 操作以替换运行状况不佳的实例。",
      "D": "创建一个 Amazon CloudWatch 警报，该警报监控 NLB 的 UnhealthyHostCount 指标。配置 Auto Scaling 操作，以便在警报处于 ALARM 状态时替换运行状况不佳的实例。"
    }
  },
  {
    "id": 71,
    "topic": "1",
    "question_en": "A company runs a shopping application that uses Amazon DynamoDB to store customer information. In case of data corruption, a solutions architect needs to design a solution that meets a recovery point objective (RPO) of 15 minutes and a recovery time objective (RTO) of 1 hour. What should the solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Configure DynamoDB global tables. For RPO recovery, point the application to a different AWS Region.",
      "B": "Configure DynamoDB point-in-time recovery. For RPO recovery, restore to the desired point in time.",
      "C": "Export the DynamoDB data to Amazon S3 Glacier on a daily basis. For RPO recovery, import the data from S3 Glacier to DynamoDB.",
      "D": "Schedule Amazon Elastic Block Store (Amazon EBS) snapshots for the DynamoDB table every 15 minutes. For RPO recovery, restore the DynamoDB table by using the EBS snapshot."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司运行一个使用 Amazon DynamoDB 存储客户信息的购物应用程序。如果发生数据损坏，解决方案架构师需要设计一个解决方案，以满足 15 分钟的恢复点目标 (RPO) 和 1 小时的恢复时间目标 (RTO)。 解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "配置 DynamoDB 全局表。对于 RPO 恢复，将应用程序指向不同的 AWS 区域。",
      "B": "配置 DynamoDB 的时间点恢复。对于 RPO 恢复，恢复到所需的时间点。",
      "C": "每天将 DynamoDB 数据导出到 Amazon S3 Glacier。对于 RPO 恢复，从 S3 Glacier 将数据导入到 DynamoDB。",
      "D": "每 15 分钟为 DynamoDB 表安排 Amazon Elastic Block Store (Amazon EBS) 快照。对于 RPO 恢复，使用 EBS 快照恢复 DynamoDB 表。"
    }
  },
  {
    "id": 72,
    "topic": "1",
    "question_en": "A company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region. A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs. How can the solutions architect meet this requirement?",
    "options_en": {
      "A": "Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it.",
      "B": "Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets.",
      "C": "Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets.",
      "D": "Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司运行一个照片处理应用程序，该应用程序需要经常从位于同一 AWS 区域的 Amazon S3 存储桶上传和下载图片。 解决方案架构师注意到数据传输费用增加，需要实施一个解决方案来降低这些成本。 解决方案架构师如何满足此要求？",
    "options_cn": {
      "A": "将 Amazon API Gateway 部署到公有子网中，并调整路由表以通过它路由 S3 调用。",
      "B": "在公有子网中部署一个 NAT Gateway，并附加一个允许访问 S3 存储桶的终端节点策略。",
      "C": "将应用程序部署到公有子网中，并允许其通过互联网网关路由以访问 S3 存储桶。",
      "D": "将 S3 VPC 网关终端节点部署到 VPC 中，并附加一个允许访问 S3 存储桶的终端节点策略。"
    }
  },
  {
    "id": 73,
    "topic": "1",
    "question_en": "A company recently launched Linux-based application instances on Amazon EC2 in a private subnet and launched a Linux-based bastion host on an Amazon EC2 instance in a public subnet of a VPC. A solutions architect needs to connect from the on-premises network, through the company's internet connection, to the bastion host, and to the application servers. The solutions architect must make sure that the security groups of all the EC2 instances will allow that access. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Replace the current security group of the bastion host with one that only allows inbound access from the application instances.",
      "B": "Replace the current security group of the bastion host with one that only allows inbound access from the internal IP range for the company.",
      "C": "Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.",
      "D": "Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host",
      "E": "Replace the current security group of the application instances with one that allows inbound SSH access from only the public IP address of the bastion host."
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家公司最近在 VPC 的私有子网中的 Amazon EC2 上启动了基于 Linux 的应用程序实例，并在 VPC 的公有子网中的 Amazon EC2 实例上启动了基于 Linux 的堡垒主机。 解决方案架构师需要通过公司的互联网连接从本地网络连接到堡垒主机和应用程序服务器。 解决方案架构师必须确保所有 EC2 实例的安全组将允许该访问。 解决方案架构师应采取哪些步骤组合以满足这些要求？ （选择两个。）",
    "options_cn": {
      "A": "将堡垒主机的当前安全组替换为仅允许从应用程序实例进行入站访问的安全组。",
      "B": "将堡垒主机的当前安全组替换为仅允许来自公司内部 IP 范围的入站访问的安全组。",
      "C": "将堡垒主机的当前安全组替换为仅允许来自公司外部 IP 范围的入站访问的安全组。",
      "D": "将应用程序实例的当前安全组替换为仅允许来自堡垒主机的私有 IP 地址的入站 SSH 访问的安全组。",
      "E": "将应用程序实例的当前安全组替换为仅允许来自堡垒主机的公共 IP 地址的入站 SSH 访问的安全组。"
    }
  },
  {
    "id": 74,
    "topic": "1",
    "question_en": "A solutions architect is designing a two-tier web application. The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company. How should security groups be configured in this situation? (Choose two.)",
    "options_en": {
      "A": "Configure the security group for the web tier to allow inbound trafic on port 443 from 0.0.0.0/0.",
      "B": "Configure the security group for the web tier to allow outbound trafic on port 443 from 0.0.0.0/0.",
      "C": "Configure the security group for the database tier to allow inbound trafic on port 1433 from the security group for the web tier.",
      "D": "Configure the security group for the database tier to allow outbound trafic on ports 443 and 1433 to the security group for the web tier",
      "E": "Configure the security group for the database tier to allow inbound trafic on ports 443 and 1433 from the security group for the web tier."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一位解决方案架构师正在设计一个两层 Web 应用程序。该应用程序包含一个在公有子网中的 Amazon EC2 上托管的面向公众的 Web 层。数据库层包含在私有子网中的 Amazon EC2 上运行的 Microsoft SQL Server。安全性是该公司的首要任务。在这种情况下，应该如何配置安全组？（选择两个。）",
    "options_cn": {
      "A": "配置 Web 层的安全组，允许来自 0.0.0.0/0 的端口 443 的入站流量。",
      "B": "配置 Web 层的安全组，允许来自 0.0.0.0/0 的端口 443 的出站流量。",
      "C": "配置数据库层的安全组，允许来自 Web 层安全组的端口 1433 的入站流量。",
      "D": "配置数据库层的安全组，允许到 Web 层安全组的端口 443 和 1433 的出站流量。",
      "E": "配置数据库层的安全组，允许来自 Web 层安全组的端口 443 和 1433 的入站流量。"
    }
  },
  {
    "id": 75,
    "topic": "1",
    "question_en": "A company wants to move a multi-tiered application from on premises to the AWS Cloud to improve the application's performance. The application consists of application tiers that communicate with each other by way of RESTful services. Transactions are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application. Which solution meets these requirements and is the MOST operationally eficient?",
    "options_en": {
      "A": "Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.",
      "B": "Use Amazon CloudWatch metrics to analyze the application performance history to determine the servers' peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.",
      "C": "Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.",
      "D": "Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected."
    },
    "correct_answer": "A",
    "vote_percentage": "81%",
    "question_cn": "一家公司希望将多层应用程序从本地环境迁移到 AWS 云，以提高应用程序的性能。该应用程序包含通过 RESTful 服务相互通信的应用程序层。当某一层过载时，事务将被丢弃。解决方案架构师必须设计一个解决方案来解决这些问题并实现应用程序现代化。哪种解决方案满足这些要求，并且运营效率最高？",
    "options_cn": {
      "A": "使用 Amazon API Gateway 并将事务定向到 AWS Lambda 函数作为应用程序层。使用 Amazon Simple Queue Service (Amazon SQS) 作为应用程序服务之间的通信层。",
      "B": "使用 Amazon CloudWatch 指标来分析应用程序性能历史记录，以确定服务器在性能故障期间的峰值利用率。增加应用程序服务器的 Amazon EC2 实例的大小以满足峰值需求。",
      "C": "使用 Amazon Simple Notification Service (Amazon SNS) 来处理在 Auto Scaling 组中运行在 Amazon EC2 上的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控 SNS 队列长度，并根据需要进行扩展和缩减。",
      "D": "使用 Amazon Simple Queue Service (Amazon SQS) 来处理在 Auto Scaling 组中运行在 Amazon EC2 上的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控 SQS 队列长度，并在检测到通信故障时进行扩展。"
    }
  },
  {
    "id": 76,
    "topic": "1",
    "question_en": "A company receives 10 TB of instrumentation data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on-premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near-real-time analytics. A secure transfer is important because the data is considered sensitive. Which solution offers the MOST reliable data transfer?",
    "options_en": {
      "A": "AWS DataSync over public internet",
      "B": "AWS DataSync over AWS Direct Connect",
      "C": "AWS Database Migration Service (AWS DMS) over public internet",
      "D": "AWS Database Migration Service (AWS DMS) over AWS Direct Connect"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司每天从位于单个工厂的几台机器接收 10 TB 的仪器数据。数据由存储在工厂内本地数据中心存储区域网络 (SAN) 上的 JSON 文件组成。该公司希望将此数据发送到 Amazon S3，以便能够被提供关键近实时分析的几个其他系统访问。由于数据被认为是敏感的，因此安全传输非常重要。哪种解决方案提供最可靠的数据传输？",
    "options_cn": {
      "A": "通过公共互联网使用 AWS DataSync",
      "B": "通过 AWS Direct Connect 使用 AWS DataSync",
      "C": "通过公共互联网使用 AWS Database Migration Service (AWS DMS)",
      "D": "通过 AWS Direct Connect 使用 AWS Database Migration Service (AWS DMS)"
    }
  },
  {
    "id": 77,
    "topic": "1",
    "question_en": "A company needs to configure a real-time data ingestion architecture for its application. The company needs an API, a process that transforms data as the data is streamed, and a storage solution for the data. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Deploy an Amazon EC2 instance to host an API that sends data to an Amazon Kinesis data stream. Create an Amazon Kinesis Data Firehose delivery stream that uses the Kinesis data stream as a data source. Use AWS Lambda functions to transform the data. Use the Kinesis Data Firehose delivery stream to send the data to Amazon S3.",
      "B": "Deploy an Amazon EC2 instance to host an API that sends data to AWS Glue. Stop source/destination checking on the EC2 instance. Use AWS Glue to transform the data and to send the data to Amazon S3.",
      "C": "Configure an Amazon API Gateway API to send data to an Amazon Kinesis data stream. Create an Amazon Kinesis Data Firehose delivery stream that uses the Kinesis data stream as a data source. Use AWS Lambda functions to transform the data. Use the Kinesis Data Firehose delivery stream to send the data to Amazon S3.",
      "D": "Configure an Amazon API Gateway API to send data to AWS Glue. Use AWS Lambda functions to transform the data. Use AWS Glue to send the data to Amazon S3."
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一家公司需要为其应用程序配置一个实时数据摄取架构。该公司需要一个 API、一个在数据流传输时转换数据的流程以及一个用于存储数据的解决方案。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "部署一个 Amazon EC2 实例来托管一个 API，该 API 将数据发送到 Amazon Kinesis 数据流。创建一个 Amazon Kinesis Data Firehose 交付流，该交付流使用 Kinesis 数据流作为数据源。使用 AWS Lambda 函数转换数据。使用 Kinesis Data Firehose 交付流将数据发送到 Amazon S3。",
      "B": "部署一个 Amazon EC2 实例来托管一个 API，该 API 将数据发送到 AWS Glue。停止在 EC2 实例上进行 源/目标 检查。使用 AWS Glue 转换数据，并将数据发送到 Amazon S3。",
      "C": "配置一个 Amazon API Gateway API，将数据发送到 Amazon Kinesis 数据流。创建一个 Amazon Kinesis Data Firehose 交付流，该交付流使用 Kinesis 数据流作为数据源。使用 AWS Lambda 函数转换数据。使用 Kinesis Data Firehose 交付流将数据发送到 Amazon S3。",
      "D": "配置一个 Amazon API Gateway API，将数据发送到 AWS Glue。使用 AWS Lambda 函数转换数据。使用 AWS Glue 将数据发送到 Amazon S3。"
    }
  },
  {
    "id": 78,
    "topic": "1",
    "question_en": "A company needs to keep user transaction data in an Amazon DynamoDB table. The company must retain the data for 7 years. What is the MOST operationally eficient solution that meets these requirements?",
    "options_en": {
      "A": "Use DynamoDB point-in-time recovery to back up the table continuously.",
      "B": "Use AWS Backup to create backup schedules and retention policies for the table.",
      "C": "Create an on-demand backup of the table by using the DynamoDB console. Store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to invoke an AWS Lambda function. Configure the Lambda function to back up the table and to store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要在 Amazon DynamoDB 表中保留用户交易数据。该公司必须将数据保留 7 年。哪个解决方案在运营上效率最高，并且满足这些要求？",
    "options_cn": {
      "A": "使用 DynamoDB 的时间点恢复功能持续备份表。",
      "B": "使用 AWS Backup 为表创建备份计划和保留策略。",
      "C": "使用 DynamoDB 控制台创建表的按需备份。将备份存储在 Amazon S3 存储桶中。为 S3 存储桶设置 S3 生命周期配置。",
      "D": "创建一个 Amazon EventBridge（Amazon CloudWatch Events）规则来调用一个 AWS Lambda 函数。配置 Lambda 函数以备份表并将备份存储在 Amazon S3 存储桶中。为 S3 存储桶设置 S3 生命周期配置。"
    }
  },
  {
    "id": 79,
    "topic": "1",
    "question_en": "A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write trafic will often be unpredictable. When trafic spikes occur, they will happen very quickly. What should a solutions architect recommend?",
    "options_en": {
      "A": "Create a DynamoDB table in on-demand capacity mode.",
      "B": "Create a DynamoDB table with a global secondary index.",
      "C": "Create a DynamoDB table with provisioned capacity and auto scaling.",
      "D": "Create a DynamoDB table in provisioned capacity mode, and configure it as a global table."
    },
    "correct_answer": "A",
    "vote_percentage": "79%",
    "question_cn": "一家公司计划使用 Amazon DynamoDB 表进行数据存储。该公司关注成本优化。该表在大多数早晨都不会被使用。在晚上，读写流量通常是不可预测的。当流量高峰出现时，它们会很快发生。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "在按需容量模式下创建 DynamoDB 表。",
      "B": "创建带有全局二级索引的 DynamoDB 表。",
      "C": "创建具有预置容量和自动伸缩的 DynamoDB 表。",
      "D": "在预置容量模式下创建 DynamoDB 表，并将其配置为全局表。"
    }
  },
  {
    "id": 80,
    "topic": "1",
    "question_en": "A company recently signed a contract with an AWS Managed Service Provider (MSP) Partner for help with an application migration initiative. A solutions architect needs ta share an Amazon Machine Image (AMI) from an existing AWS account with the MSP Partner's AWS account. The AMI is backed by Amazon Elastic Block Store (Amazon EBS) and uses an AWS Key Management Service (AWS KMS) customer managed key to encrypt EBS volume snapshots. What is the MOST secure way for the solutions architect to share the AMI with the MSP Partner's AWS account?",
    "options_en": {
      "A": "Make the encrypted AMI and snapshots publicly available. Modify the key policy to allow the MSP Partner's AWS account to use the key.",
      "B": "Modify the launchPermission property of the AMI. Share the AMI with the MSP Partner's AWS account only. Modify the key policy to allow the MSP Partner's AWS account to use the key.",
      "C": "Modify the launchPermission property of the AMI. Share the AMI with the MSP Partner's AWS account only. Modify the key policy to trust a new KMS key that is owned by the MSP Partner for encryption.",
      "D": "Export the AMI from the source account to an Amazon S3 bucket in the MSP Partner's AWS account, Encrypt the S3 bucket with a new KMS key that is owned by the MSP Partner. Copy and launch the AMI in the MSP Partner's AWS account."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一家公司最近与一家 AWS 托管服务提供商 (MSP) 合作伙伴签订了合同，以帮助进行应用程序迁移计划。一位解决方案架构师需要与 MSP 合作伙伴的 AWS 账户共享来自现有 AWS 账户的 Amazon Machine Image (AMI)。AMI 由 Amazon Elastic Block Store (Amazon EBS) 支持，并使用 AWS Key Management Service (AWS KMS) 客户托管密钥来加密 EBS 卷快照。解决方案架构师与 MSP 合作伙伴的 AWS 账户共享 AMI 的最安全方法是什么？",
    "options_cn": {
      "A": "将加密的 AMI 和快照公开。修改密钥策略以允许 MSP 合作伙伴的 AWS 账户使用该密钥。",
      "B": "修改 AMI 的 launchPermission 属性。仅与 MSP 合作伙伴的 AWS 账户共享 AMI。修改密钥策略以允许 MSP 合作伙伴的 AWS 账户使用该密钥。",
      "C": "修改 AMI 的 launchPermission 属性。仅与 MSP 合作伙伴的 AWS 账户共享 AMI。修改密钥策略以信任由 MSP 合作伙伴拥有的新 KMS 密钥进行加密。",
      "D": "将 AMI 从 源账户 导出到 MSP 合作伙伴的 AWS 账户中的 Amazon S3 存储桶，使用由 MSP 合作伙伴拥有的新 KMS 密钥加密 S3 存储桶。在 MSP 合作伙伴的 AWS 账户中复制并启动 AMI。"
    }
  },
  {
    "id": 81,
    "topic": "1",
    "question_en": "A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored. Which design should the solutions architect use?",
    "options_en": {
      "A": "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.",
      "B": "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.",
      "C": "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.",
      "D": "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在为在 AWS 上部署的新应用程序设计云架构。该流程应并行运行，并根据要处理的作业数量按需添加和删除应用程序节点。处理器应用程序是无状态的。解决方案架构师必须确保应用程序是松散耦合的，并且作业项被持久存储。解决方案架构师应该使用哪种设计？",
    "options_cn": {
      "A": "创建一个 Amazon SNS 主题来发送需要处理的作业。创建一个包含处理器应用程序的 Amazon 机器映像 (AMI)。创建一个使用 AMI 的启动配置。创建一个使用启动配置的 Auto Scaling 组。将 Auto Scaling 组的缩放策略设置为根据 CPU 使用率添加和删除节点。",
      "B": "创建一个 Amazon SQS 队列来保存需要处理的作业。创建一个包含处理器应用程序的 Amazon 机器映像 (AMI)。创建一个使用 AMI 的启动配置。创建一个使用启动配置的 Auto Scaling 组。将 Auto Scaling 组的缩放策略设置为根据网络使用情况添加和删除节点。",
      "C": "创建一个 Amazon SQS 队列来保存需要处理的作业。创建一个包含处理器应用程序的 Amazon 机器映像 (AMI)。创建一个使用 AMI 的启动模板。创建一个使用启动模板的 Auto Scaling 组。将 Auto Scaling 组的缩放策略设置为根据 SQS 队列中的项目数量添加和删除节点。",
      "D": "创建一个 Amazon SNS 主题来发送需要处理的作业。创建一个包含处理器应用程序的 Amazon 机器映像 (AMI)。创建一个使用 AMI 的启动模板。创建一个使用启动模板的 Auto Scaling 组。将 Auto Scaling 组的缩放策略设置为根据发布到 SNS 主题的消息数量添加和删除节点。"
    }
  },
  {
    "id": 82,
    "topic": "1",
    "question_en": "A company hosts its web applications in the AWS Cloud. The company configures Elastic Load Balancers to use certificates that are imported into AWS Certificate Manager (ACM). The company's security team must be notified 30 days before the expiration of each certificate. What should a solutions architect recommend to meet this requirement?",
    "options_en": {
      "A": "Add a rule in ACM to publish a custom message to an Amazon Simple Notification Service (Amazon SNS) topic every day, beginning 30 days before any certificate will expire.",
      "B": "Create an AWS Config rule that checks for certificates that will expire within 30 days. Configure Amazon EventBridge (Amazon CloudWatch Events) to invoke a custom alert by way of Amazon Simple Notification Service (Amazon SNS) when AWS Config reports a noncompliant resource.",
      "C": "Use AWS Trusted Advisor to check for certificates that will expire within 30 days. Create an Amazon CloudWatch alarm that is based on Trusted Advisor metrics for check status changes. Configure the alarm to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS).",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect any certificates that will expire within 30 days. Configure the rule to invoke an AWS Lambda function. Configure the Lambda function to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS)."
    },
    "correct_answer": "D",
    "vote_percentage": "52%",
    "question_cn": "一家公司在 AWS 云中托管其 Web 应用程序。该公司配置 Elastic Load Balancer 以使用导入到 AWS Certificate Manager (ACM) 中的证书。该公司的安全团队必须在每个证书到期前 30 天收到通知。解决方案架构师应推荐什么来满足此要求？",
    "options_cn": {
      "A": "在 ACM 中添加一个规则，每天将自定义消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题，从任何证书到期前 30 天开始。",
      "B": "创建一个 AWS Config 规则，检查将在 30 天内到期的证书。配置 Amazon EventBridge (Amazon CloudWatch Events) 通过 Amazon Simple Notification Service (Amazon SNS) 调用自定义警报，当 AWS Config 报告不合规资源时。",
      "C": "使用 AWS Trusted Advisor 检查将在 30 天内到期的证书。创建一个 Amazon CloudWatch 警报，该警报基于 Trusted Advisor 的检查状态更改指标。配置警报以通过 Amazon Simple Notification Service (Amazon SNS) 发送自定义警报。",
      "D": "创建一个 Amazon EventBridge (Amazon CloudWatch Events) 规则，以检测将在 30 天内到期的任何证书。配置该规则以调用一个 AWS Lambda 函数。配置 Lambda 函数以通过 Amazon Simple Notification Service (Amazon SNS) 发送自定义警报。"
    }
  },
  {
    "id": 83,
    "topic": "1",
    "question_en": "A company's dynamic website is hosted using on-premises servers in the United States. The company is launching its product in Europe, and it wants to optimize site loading times for new European users. The site's backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed. What should the solutions architect recommend?",
    "options_en": {
      "A": "Launch an Amazon EC2 instance in us-east-1 and migrate the site to it.",
      "B": "Move the website to Amazon S3. Use Cross-Region Replication between Regions.",
      "C": "Use Amazon CloudFront with a custom origin pointing to the on-premises servers.",
      "D": "Use an Amazon Route 53 geoproximity routing policy pointing to on-premises servers."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的动态网站使用位于美国的本地服务器进行托管。该公司将在欧洲推出其产品，并希望优化新欧洲用户的站点加载时间。该站点的后端必须保留在美国。该产品将在几天内推出，并且需要一个即时解决方案。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "在 us-east-1 启动一个 Amazon EC2 实例并将站点迁移到它。",
      "B": "将网站移至 Amazon S3。使用跨区域复制 between Regions。",
      "C": "使用 Amazon CloudFront，其自定义源指向本地服务器。",
      "D": "使用 Amazon Route 53 地理位置路由策略，指向本地服务器。"
    }
  },
  {
    "id": 84,
    "topic": "1",
    "question_en": "A company wants to reduce the cost of its existing three-tier web architecture. The web, application, and database servers are running on Amazon EC2 instances for the development, test, and production environments. The EC2 instances average 30% CPU utilization during peak hours and 10% CPU utilization during non-peak hours. The production EC2 instances run 24 hours a day. The development and test EC2 instances run for at least 8 hours each day. The company plans to implement automation to stop the development and test EC2 instances when they are not in use. Which EC2 instance purchasing solution will meet the company's requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use Spot Instances for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances.",
      "B": "Use Reserved Instances for the production EC2 instances. Use On-Demand Instances for the development and test EC2 instances.",
      "C": "Use Spot blocks for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances.",
      "D": "Use On-Demand Instances for the production EC2 instances. Use Spot blocks for the development and test EC2 instances."
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一家公司希望降低其现有三层 Web 架构的成本。 Web、应用程序和数据库服务器在 Amazon EC2 实例上运行，用于开发、测试和生产环境。 EC2 实例在高峰时段的平均 CPU 利用率为 30%，在非高峰时段的 CPU 利用率为 10%。 生产 EC2 实例每天运行 24 小时。 开发和测试 EC2 实例每天至少运行 8 小时。 该公司计划实施自动化，以便在不使用时停止开发和测试 EC2 实例。 哪种 EC2 实例购买解决方案最符合公司的要求，并且最具成本效益？",
    "options_cn": {
      "A": "对生产 EC2 实例使用 Spot 实例。 对开发和测试 EC2 实例使用预留实例。",
      "B": "对生产 EC2 实例使用预留实例。 对开发和测试 EC2 实例使用按需实例。",
      "C": "对生产 EC2 实例使用 Spot 块。 对开发和测试 EC2 实例使用预留实例。",
      "D": "对生产 EC2 实例使用按需实例。 对开发和测试 EC2 实例使用 Spot 块。"
    }
  },
  {
    "id": 85,
    "topic": "1",
    "question_en": "A company has a production web application in which users upload documents through a web interface or a mobile app. According to a new regulatory requirement. new documents cannot be modified or deleted after they are stored. What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Store the uploaded documents in an Amazon S3 bucket with S3 Versioning and S3 Object Lock enabled.",
      "B": "Store the uploaded documents in an Amazon S3 bucket. Configure an S3 Lifecycle policy to archive the documents periodically.",
      "C": "Store the uploaded documents in an Amazon S3 bucket with S3 Versioning enabled. Configure an ACL to restrict all access to read-only.",
      "D": "Store the uploaded documents on an Amazon Elastic File System (Amazon EFS) volume. Access the data by mounting the volume in read-only mode."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个生产型 Web 应用程序，用户可以通过 Web 界面或移动应用程序上传文档。根据一项新的监管要求，新文档在存储后不能被修改或删除。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "将上传的文档存储在启用了 S3 版本控制和 S3 对象锁定的 Amazon S3 存储桶中。",
      "B": "将上传的文档存储在 Amazon S3 存储桶中。配置 S3 生命周期策略以定期间隔归档文档。",
      "C": "将上传的文档存储在启用了 S3 版本控制的 Amazon S3 存储桶中。配置 ACL 以将所有访问权限限制为只读。",
      "D": "将上传的文档存储在 Amazon Elastic File System (Amazon EFS) 卷上。通过以只读模式挂载该卷来访问数据。"
    }
  },
  {
    "id": 86,
    "topic": "1",
    "question_en": "A company has several web servers that need to frequently access a common Amazon RDS MySQL Multi-AZ DB instance. The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently. Which solution meets these requirements?",
    "options_en": {
      "A": "Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager.",
      "B": "Store the database user credentials in AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter.",
      "C": "Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database.",
      "D": "Store the database user credentials in files encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有多个 Web 服务器，需要频繁访问一个公共 Amazon RDS MySQL 多可用区数据库实例。该公司希望 Web 服务器能够安全地连接到数据库，同时满足定期轮换用户凭证的安全要求。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "将数据库用户凭证存储在 AWS Secrets Manager 中。授予必要的 IAM 权限，以允许 Web 服务器访问 AWS Secrets Manager。",
      "B": "将数据库用户凭证存储在 AWS Systems Manager OpsCenter 中。授予必要的 IAM 权限，以允许 Web 服务器访问 OpsCenter。",
      "C": "将数据库用户凭证存储在安全的 Amazon S3 存储桶中。授予必要的 IAM 权限，以允许 Web 服务器检索凭证并访问数据库。",
      "D": "将数据库用户凭证存储在用 AWS Key Management Service (AWS KMS) 加密的 Web 服务器文件系统中。Web 服务器应该能够解密文件并访问数据库。"
    }
  },
  {
    "id": 87,
    "topic": "1",
    "question_en": "A company hosts an application on AWS Lambda functions that are invoked by an Amazon API Gateway API. The Lambda functions save customer data to an Amazon Aurora MySQL database. Whenever the company upgrades the database, the Lambda functions fail to establish database connections until the upgrade is complete. The result is that customer data is not recorded for some of the event. A solutions architect needs to design a solution that stores customer data that is created during database upgrades. Which solution will meet these requirements?",
    "options_en": {
      "A": "Provision an Amazon RDS proxy to sit between the Lambda functions and the database. Configure the Lambda functions to connect to the RDS proxy.",
      "B": "Increase the run time of the Lambda functions to the maximum. Create a retry mechanism in the code that stores the customer data in the database.",
      "C": "Persist the customer data to Lambda local storage. Configure new Lambda functions to scan the local storage to save the customer data to the database.",
      "D": "Store the customer data in an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Create a new Lambda function that polls the queue and stores the customer data in the database."
    },
    "correct_answer": "A",
    "vote_percentage": "61%",
    "question_cn": "一家公司在其由 Amazon API Gateway API 调用的 AWS Lambda 函数上托管一个应用程序。Lambda 函数将客户数据保存到 Amazon Aurora MySQL 数据库。每当公司升级数据库时，Lambda 函数都会在升级完成之前无法建立数据库连接。结果是，某些事件的客户数据未被记录。一位解决方案架构师需要设计一个解决方案来存储在数据库升级期间创建的客户数据。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置一个 Amazon RDS 代理，位于 Lambda 函数和数据库之间。配置 Lambda 函数连接到 RDS 代理。",
      "B": "将 Lambda 函数的运行时增加到最大。在代码中创建一个重试机制，将客户数据存储在数据库中。",
      "C": "将客户数据持久保存到 Lambda 本地存储。配置新的 Lambda 函数来扫描本地存储，以便将客户数据保存到数据库。",
      "D": "将客户数据存储在 Amazon Simple Queue Service (Amazon SQS) FIFO 队列中。创建一个新的 Lambda 函数来轮询队列并将客户数据存储在数据库中。"
    }
  },
  {
    "id": 88,
    "topic": "1",
    "question_en": "A survey company has gathered data for several years from areas in the United States. The company hosts the data in an Amazon S3 bucket that is 3 TB in size and growing. The company has started to share the data with a European marketing firm that has S3 buckets. The company wants to ensure that its data transfer costs remain as low as possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the Requester Pays feature on the company's S3 bucket.",
      "B": "Configure S3 Cross-Region Replication from the company's S3 bucket to one of the marketing firm's S3 buckets.",
      "C": "Configure cross-account access for the marketing firm so that the marketing firm has access to the company's S3 bucket.",
      "D": "Configure the company's S3 bucket to use S3 Intelligent-Tiering. Sync the S3 bucket to one of the marketing firm's S3 buckets."
    },
    "correct_answer": "B",
    "vote_percentage": "46%",
    "question_cn": "一家调查公司收集了美国多个地区多年来的数据。该公司将数据托管在大小为 3 TB 且不断增长的 Amazon S3 存储桶中。该公司已开始与拥有 S3 存储桶的欧洲营销公司共享数据。该公司希望确保其数据传输成本保持在尽可能低的水平。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在公司的 S3 存储桶上配置 Requester Pays 功能。",
      "B": "配置 S3 跨区域复制，将数据从公司的 S3 存储桶复制到营销公司的其中一个 S3 存储桶。",
      "C": "为营销公司配置跨账户访问权限，以便营销公司可以访问公司的 S3 存储桶。",
      "D": "将公司的 S3 存储桶配置为使用 S3 Intelligent-Tiering。将 S3 存储桶同步到营销公司的其中一个 S3 存储桶。"
    }
  },
  {
    "id": 89,
    "topic": "1",
    "question_en": "A company uses Amazon S3 to store its confidential audit documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution. What should a solutions architect do to secure the audit documents?",
    "options_en": {
      "A": "Enable the versioning and MFA Delete features on the S3 bucket.",
      "B": "Enable multi-factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.",
      "C": "Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.",
      "D": "Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon S3 存储其机密的审计文档。 S3 存储桶使用存储桶策略，根据最小权限原则限制对审计团队 IAM 用户凭证的访问。 公司经理担心 S3 存储桶中文件的意外删除，并希望获得更安全的解决方案。 解决方案架构师应该怎么做来保护审计文档？",
    "options_cn": {
      "A": "在 S3 存储桶上打开版本控制和 MFA 删除功能。",
      "B": "在每个审计团队 IAM 用户帐户的 IAM 用户凭证上打开多因素身份验证 (MFA)。",
      "C": "为审计团队的 IAM 用户帐户添加一个 S3 生命周期策略，以在审计日期期间拒绝 s3:DeleteObject 操作。",
      "D": "使用 AWS Key Management Service (AWS KMS) 加密 S3 存储桶，并限制审计团队 IAM 用户帐户访问 KMS 密钥。"
    }
  },
  {
    "id": 90,
    "topic": "1",
    "question_en": "A company is using a SQL database to store movie data that is publicly accessible. The database runs on an Amazon RDS Single-AZ DB instance. A script runs queries at random intervals each day to record the number of new movies that have been added to the database. The script must report a final total during business hours. The company's development team notices that the database performance is inadequate for development tasks when the script is running. A solutions architect must recommend a solution to resolve this issue. Which solution will meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Modify the DB instance to be a Multi-AZ deployment.",
      "B": "Create a read replica of the database. Configure the script to query only the read replica.",
      "C": "Instruct the development team to manually export the entries in the database at the end of each day.",
      "D": "Use Amazon ElastiCache to cache the common queries that the script runs against the database."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司正在使用 SQL 数据库来存储可公开访问的电影数据。该数据库运行在 Amazon RDS 单可用区数据库实例上。一个脚本每天以随机间隔运行查询，以记录已添加到数据库中的新电影的数量。该脚本必须在工作时间内报告最终总数。该公司的开发团队注意到，当脚本运行时，数据库性能对于开发任务来说是不够的。解决方案架构师必须推荐一个解决方案来解决这个问题。哪种解决方案将以最少的运营开销满足此要求？",
    "options_cn": {
      "A": "将数据库实例修改为多可用区部署。",
      "B": "创建数据库的只读副本。配置脚本仅查询只读副本。",
      "C": "指示开发团队在每天结束时手动导出数据库中的条目。",
      "D": "使用 Amazon ElastiCache 缓存脚本对数据库运行的常见查询。"
    }
  },
  {
    "id": 91,
    "topic": "1",
    "question_en": "A company has applications that run on Amazon EC2 instances in a VPC. One of the applications needs to call the Amazon S3 API to store and read objects. According to the company's security regulations, no trafic from the applications is allowed to travel across the internet. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an S3 gateway endpoint.",
      "B": "Create an S3 bucket in a private subnet.",
      "C": "Create an S3 bucket in the same AWS Region as the EC2 instances.",
      "D": "Configure a NAT gateway in the same subnet as the EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有在 VPC 中的 Amazon EC2 实例上运行的应用程序。其中一个应用程序需要调用 Amazon S3 API 来存储和读取对象。根据公司的安全规定，应用程序的流量不允许通过互联网传输。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置一个 S3 网关 VPC endpoint。",
      "B": "在私有子网中创建一个 S3 存储桶。",
      "C": "在与 EC2 实例相同的 AWS 区域中创建一个 S3 存储桶。",
      "D": "在与 EC2 实例相同的子网中配置一个 NAT Gateway。"
    }
  },
  {
    "id": 92,
    "topic": "1",
    "question_en": "A company is storing sensitive user information in an Amazon S3 bucket. The company wants to provide secure access to this bucket from the application tier running on Amazon EC2 instances inside a VPC. Which combination of steps should a solutions architect take to accomplish this? (Choose two.)",
    "options_en": {
      "A": "Configure a VPC gateway endpoint for Amazon S3 within the VPC.",
      "B": "Create a bucket policy to make the objects in the S3 bucket public.",
      "C": "Create a bucket policy that limits access to only the application tier running in the VPC.",
      "D": "Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instanc",
      "E": "E. Create a NAT instance and have the EC2 instances use the NAT instance to access the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家公司正在将敏感的用户信息存储在 Amazon S3 存储桶中。该公司希望从在 VPC 内的 Amazon EC2 实例上运行的应用层安全地访问此存储桶。 解决方案架构师应采取哪些步骤的组合来实现此目的？（选择两个。）",
    "options_cn": {
      "A": "在 VPC 内为 Amazon S3 配置一个 VPC gateway endpoint。",
      "B": "创建一个桶策略，使 S3 存储桶中的对象公开。",
      "C": "创建一个桶策略，将访问限制为仅在 VPC 中运行的应用层。",
      "D": "创建一个带有 S3 访问策略的 IAM 用户，并将 IAM 凭证复制到 EC2 实例。",
      "E": "创建一个 NAT 实例，并让 EC2 实例使用 NAT 实例来访问 S3 存储桶。"
    }
  },
  {
    "id": 93,
    "topic": "1",
    "question_en": "A company runs an on-premises application that is powered by a MySQL database. The company is migrating the application to AWS to increase the application's elasticity and availability. The current architecture shows heavy read activity on the database during times of normal operation. Every 4 hours, the company's development team pulls a full export of the production database to populate a database in the staging environment. During this period, users experience unacceptable application latency. The development team is unable to use the staging environment until the procedure completes. A solutions architect must recommend replacement architecture that alleviates the application latency issue. The replacement architecture also must give the development team the ability to continue using the staging environment without delay. Which solution meets these requirements?",
    "options_en": {
      "A": "Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility.",
      "B": "Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on- demand.",
      "C": "Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Use the standby instance for the staging database.",
      "D": "Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility."
    },
    "correct_answer": "B",
    "vote_percentage": "91%",
    "question_cn": "一家公司运行一个由 MySQL 数据库支持的本地应用程序。该公司正在将应用程序迁移到 AWS 以提高应用程序的弹性和可用性。当前架构显示在正常运行期间数据库上有大量的读取活动。每 4 小时，公司的开发团队都会提取生产数据库的完整导出，以填充登台环境中的数据库。在此期间，用户会遇到不可接受的应用程序延迟。在过程完成之前，开发团队无法使用登台环境。一个解决方案架构师必须推荐一个能够缓解应用程序延迟问题的替代架构。替代架构还必须使开发团队能够继续使用登台环境而不会延迟。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Aurora MySQL 和 Multi-AZ Aurora 副本进行生产。通过实施使用 mysqldump 实用程序的备份和恢复过程来填充登台数据库。",
      "B": "使用 Amazon Aurora MySQL 和 Multi-AZ Aurora 副本进行生产。使用数据库克隆按需创建登台数据库。",
      "C": "使用 Amazon RDS for MySQL 和 Multi-AZ 部署以及用于生产的读取副本。使用备用实例作为登台数据库。",
      "D": "使用 Amazon RDS for MySQL 和 Multi-AZ 部署以及用于生产的读取副本。通过实施使用 mysqldump 实用程序的备份和恢复过程来填充登台数据库。"
    }
  },
  {
    "id": 94,
    "topic": "1",
    "question_en": "A company is designing an application where users upload small files into Amazon S3. After a user uploads a file, the file requires one-time simple processing to transform the data and save the data in JSON format for later analysis. Each file must be processed as quickly as possible after it is uploaded. Demand will vary. On some days, users will upload a high number of files. On other days, users will upload a few files or no files. Which solution meets these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure Amazon EMR to read text files from Amazon S3. Run processing scripts to transform the data. Store the resulting JSON file in an Amazon Aurora DB cluster.",
      "B": "Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use Amazon EC2 instances to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB.",
      "C": "Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB.",
      "D": "Configure Amazon EventBridge (Amazon CloudWatch Events) to send an event to Amazon Kinesis Data Streams when a new file is uploaded. Use an AWS Lambda function to consume the event from the stream and process the data. Store the resulting JSON file in an Amazon Aurora DB cluster."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在设计一个应用程序，用户将小文件上传到 Amazon S3。在用户上传文件后，该文件需要一次性简单处理以转换数据，并将数据保存为 JSON 格式，以供以后分析。每个文件必须在上传后尽快处理。需求量会有所不同。在某些日子，用户将上传大量文件。在其他日子，用户将上传少量文件或不上传任何文件。哪个解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon EMR 从 Amazon S3 读取文本文件。运行处理脚本以转换数据。将生成的 JSON 文件存储在 Amazon Aurora 数据库集群中。",
      "B": "配置 Amazon S3 向 Amazon Simple Queue Service (Amazon SQS) 队列发送事件通知。使用 Amazon EC2 实例从队列中读取并处理数据。将生成的 JSON 文件存储在 Amazon DynamoDB 中。",
      "C": "配置 Amazon S3 向 Amazon Simple Queue Service (Amazon SQS) 队列发送事件通知。使用 AWS Lambda 函数从队列中读取并处理数据。将生成的 JSON 文件存储在 Amazon DynamoDB 中。",
      "D": "配置 Amazon EventBridge (Amazon CloudWatch Events) 在上传新文件时向 Amazon Kinesis Data Streams 发送事件。使用 AWS Lambda 函数从流中消费事件并处理数据。将生成的 JSON 文件存储在 Amazon Aurora 数据库集群中。"
    }
  },
  {
    "id": 95,
    "topic": "1",
    "question_en": "An application allows users at a company's headquarters to access product data. The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read trafic from write trafic. A solutions architect needs to optimize the application's performance quickly. What should the solutions architect recommend?",
    "options_en": {
      "A": "Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone.",
      "B": "Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone.",
      "C": "Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.",
      "D": "Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database."
    },
    "correct_answer": "D",
    "vote_percentage": "98%",
    "question_cn": "一个应用程序允许公司总部的用户访问产品数据。产品数据存储在 Amazon RDS MySQL 数据库实例中。运维团队隔离了一个应用程序性能变慢的问题，并希望将读取流量与写入流量分开。一个解决方案架构师需要快速优化应用程序的性能。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "将现有数据库更改为多可用区部署。从主可用区提供读取请求。",
      "B": "将现有数据库更改为多可用区部署。从辅助可用区提供读取请求。",
      "C": "为数据库创建只读副本。将只读副本配置为具有源数据库一半的计算和存储资源。",
      "D": "为数据库创建只读副本。将只读副本配置为与源数据库相同的计算和存储资源。"
    }
  },
  {
    "id": 96,
    "topic": "1",
    "question_en": "An Amazon EC2 administrator created the following policy associated with an IAM group containing several users: What is the effect of this policy?",
    "options_en": {
      "A": "Users can terminate an EC2 instance in any AWS Region except us-east-1.",
      "B": "Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region.",
      "C": "Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.",
      "D": "Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254."
    },
    "correct_answer": "C",
    "vote_percentage": "70%",
    "question_cn": "一位 Amazon EC2 管理员创建了以下与包含多个用户的 IAM 组关联的策略：此策略的效果是什么？",
    "options_cn": {
      "A": "用户可以终止任何 AWS 区域中的 EC2 实例，除了 us-east-1。",
      "B": "用户可以在 us-east-1 区域中终止 IP 地址为 10.100.100.1 的 EC2 实例。",
      "C": "当用户的 源 IP 为 10.100.100.254 时，用户可以在 us-east-1 区域中终止 EC2 实例。",
      "D": "当用户的 源 IP 为 10.100.100.254 时，用户无法在 us-east-1 区域中终止 EC2 实例。"
    }
  },
  {
    "id": 97,
    "topic": "1",
    "question_en": "A company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control. Which solution will satisfy these requirements?",
    "options_en": {
      "A": "Configure Amazon EFS storage and set the Active Directory domain for authentication.",
      "B": "Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones.",
      "C": "Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume.",
      "D": "Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在本地运行大型 Microsoft SharePoint 部署，需要 Microsoft Windows 共享文件存储。该公司希望将此工作负载迁移到 AWS Cloud，并正在考虑各种存储选项。存储解决方案必须高度可用并与 Active Directory 集成以进行访问控制。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon EFS 存储并为身份验证设置 Active Directory 域。",
      "B": "在两个可用区内的 AWS Storage Gateway 文件网关上创建 SMB 文件共享。",
      "C": "创建一个 Amazon S3 存储桶，并配置 Microsoft Windows Server 将其挂载为卷。",
      "D": "在 AWS 上创建一个 Amazon FSx for Windows File Server 文件系统，并为身份验证设置 Active Directory 域。"
    }
  },
  {
    "id": 98,
    "topic": "1",
    "question_en": "An image-processing company has a web application that users use to upload images. The application uploads the images into an Amazon S3 bucket. The company has set up S3 event notifications to publish the object creation events to an Amazon Simple Queue Service (Amazon SQS) standard queue. The SQS queue serves as the event source for an AWS Lambda function that processes the images and sends the results to users through email. Users report that they are receiving multiple email messages for every uploaded image. A solutions architect determines that SQS messages are invoking the Lambda function more than once, resulting in multiple email messages. What should the solutions architect do to resolve this issue with the LEAST operational overhead?",
    "options_en": {
      "A": "Set up long polling in the SQS queue by increasing the ReceiveMessage wait time to 30 seconds.",
      "B": "Change the SQS standard queue to an SQS FIFO queue. Use the message deduplication ID to discard duplicate messages.",
      "C": "Increase the visibility timeout in the SQS queue to a value that is greater than the total of the function timeout and the batch window timeout.",
      "D": "Modify the Lambda function to delete each message from the SQS queue immediately after the message is read before processing."
    },
    "correct_answer": "A",
    "vote_percentage": "81%",
    "question_cn": "一家图像处理公司有一个用户用于上传图像的 Web 应用程序。 该应用程序将图像上传到 Amazon S3 存储桶中。该公司设置了 S3 事件通知，将对象创建事件发布到 Amazon Simple Queue Service (Amazon SQS) 标准队列。 SQS 队列充当 AWS Lambda 函数的事件源，该函数处理图像并通过电子邮件将结果发送给用户。用户报告说，他们为每个上传的图像都收到了多封电子邮件。一位解决方案架构师确定 SQS 消息多次调用 Lambda 函数，导致多封电子邮件。 解决方案架构师应该怎么做才能以最少的运营开销解决此问题？",
    "options_cn": {
      "A": "通过将 ReceiveMessage 等待时间增加到 30 秒，在 SQS 队列中设置长轮询。",
      "B": "将 SQS 标准队列更改为 SQS FIFO 队列。使用消息去重 ID 来丢弃重复的消息。",
      "C": "将 SQS 队列中的可见性超时增加到大于函数超时和批处理窗口超时总和的值。",
      "D": "修改 Lambda 函数，以便在处理之前从 SQS 队列中读取消息后立即删除每条消息。"
    }
  },
  {
    "id": 99,
    "topic": "1",
    "question_en": "A company is implementing a shared storage solution for a gaming application that is hosted in an on-premises data center. The company needs the ability to use Lustre clients to access data. The solution must be fully managed. Which solution meets these requirements?",
    "options_en": {
      "A": "Create an AWS Storage Gateway file gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
      "B": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
      "C": "Create an Amazon Elastic File System (Amazon EFS) file system, and configure it to support Lustre. Attach the file system to the origin server. Connect the application server to the file system.",
      "D": "Create an Amazon FSx for Lustre file system. Attach the file system to the origin server. Connect the application server to the file system."
    },
    "correct_answer": "D",
    "vote_percentage": "94%",
    "question_cn": "一家公司正在为其托管在本地数据中心的视频游戏应用程序实施共享存储解决方案。该公司需要使用Lustre客户端访问数据的能力。该解决方案必须是完全托管的。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Storage Gateway 文件网关。创建使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享。",
      "B": "创建一个 Amazon EC2 Windows 实例。在该实例上安装并配置 Windows 文件共享角色。将应用程序服务器连接到文件共享。",
      "C": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统，并将其配置为支持Lustre。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。",
      "D": "创建一个 Amazon FSx for Lustre 文件系统。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。"
    }
  },
  {
    "id": 100,
    "topic": "1",
    "question_en": "A company's containerized application runs on an Amazon EC2 instance. The application needs to download security certificates before it can communicate with other business applications. The company wants a highly secure solution to encrypt and decrypt the certificates in near real time. The solution also needs to store data in highly available storage after the data is encrypted. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create AWS Secrets Manager secrets for encrypted certificates. Manually update the certificates as needed. Control access to the data by using fine-grained IAM access.",
      "B": "Create an AWS Lambda function that uses the Python cryptography library to receive and perform encryption operations. Store the function in an Amazon S3 bucket.",
      "C": "Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon S3.",
      "D": "Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon Elastic Block Store (Amazon EBS) volumes."
    },
    "correct_answer": "D",
    "vote_percentage": "79%",
    "question_cn": "一家公司的容器化应用程序在 Amazon EC2 实例上运行。该应用程序需要先下载安全证书，然后才能与其他业务应用程序通信。该公司希望使用高度安全的解决方案，以近乎实时的速度对证书进行加密和解密。该解决方案还需要在数据加密后将数据存储在具有高可用性的存储中。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "为加密证书创建 AWS Secrets Manager 密钥。根据需要手动更新证书。通过使用细粒度的 IAM 访问控制对数据的访问。",
      "B": "创建一个使用 Python 加密库接收和执行加密操作的 AWS Lambda 函数。将该函数存储在 Amazon S3 存储桶中。",
      "C": "创建一个 AWS Key Management Service (AWS KMS) 客户托管密钥。允许 EC2 角色使用 KMS 密钥进行加密操作。将加密数据存储在 Amazon S3 上。",
      "D": "创建一个 AWS Key Management Service (AWS KMS) 客户托管密钥。允许 EC2 角色使用 KMS 密钥进行加密操作。将加密数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷上。"
    }
  },
  {
    "id": 101,
    "topic": "1",
    "question_en": "A solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates. What should the solutions architect do to enable Internet access for the private subnets?",
    "options_en": {
      "A": "Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC trafic to the NAT gateway in its AZ.",
      "B": "Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC trafic to the NAT instance in its AZ.",
      "C": "Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC trafic to the private internet gateway.",
      "D": "Create an egress-only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non- VPC trafic to the egress-only Internet gateway."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一位解决方案架构师正在设计一个包含公有子网和私有子网的 VPC。VPC 和子网使用 IPv4 CIDR 块。为了实现高可用性，在三个可用区（AZ）的每个可用区中都有一个公有子网和一个私有子网。一个互联网网关用于为公有子网提供互联网访问。私有子网需要访问互联网以允许 Amazon EC2 实例下载软件更新。解决方案架构师应该怎么做才能为私有子网启用互联网访问？",
    "options_cn": {
      "A": "创建三个 NAT 网关，每个可用区中的每个公有子网一个。为每个可用区创建一个私有路由表，将非 VPC 流量转发到其可用区中的 NAT 网关。",
      "B": "创建三个 NAT 实例，每个可用区中的每个私有子网一个。为每个可用区创建一个私有路由表，将非 VPC 流量转发到其可用区中的 NAT 实例。",
      "C": "在其中一个私有子网上创建一个第二个互联网网关。更新私有子网的路由表，将非 VPC 流量转发到私有互联网网关。",
      "D": "在其中一个公有子网上创建一个仅限出口的互联网网关。更新私有子网的路由表，将非 VPC 流量转发到仅限出口的互联网网关。"
    }
  },
  {
    "id": 102,
    "topic": "1",
    "question_en": "A company wants to migrate an on-premises data center to AWS. The data center hosts an SFTP server that stores its data on an NFS-based file system. The server holds 200 GB of data that needs to be transferred. The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system. Which combination of steps should a solutions architect take to automate this task? (Choose two.)",
    "options_en": {
      "A": "Launch the EC2 instance into the same Availability Zone as the EFS file system.",
      "B": "Install an AWS DataSync agent in the on-premises data center.",
      "C": "Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data.",
      "D": "Manually use an operating system copy command to push the data to the EC2 instanc",
      "E": "E. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server."
    },
    "correct_answer": "A",
    "vote_percentage": "40%",
    "question_cn": "一家公司希望将本地数据中心迁移到 AWS。 数据中心托管一个 SFTP 服务器，该服务器将其数据存储在基于 NFS 的文件系统上。 服务器包含 200 GB 的数据需要传输。 服务器必须托管在 Amazon EC2 实例上，该实例使用 Amazon Elastic File System (Amazon EFS) 文件系统。 解决方案架构师应采取哪些步骤组合来自动化此任务？（选择两项。）",
    "options_cn": {
      "A": "将 EC2 实例启动到与 EFS 文件系统相同的可用区。",
      "B": "在本地数据中心安装一个 AWS DataSync 代理。",
      "C": "在 EC2 实例上创建一个辅助 Amazon Elastic Block Store (Amazon EBS) 卷以存储数据。",
      "D": "手动使用操作系统复制命令将数据推送到 EC2 实例。",
      "E": "使用 AWS DataSync 为本地 SFTP 服务器创建合适的地址配置。"
    }
  },
  {
    "id": 103,
    "topic": "1",
    "question_en": "A company has an AWS Glue extract, transform, and load (ETL) job that runs every day at the same time. The job processes XML data that is in an Amazon S3 bucket. New data is added to the S3 bucket every day. A solutions architect notices that AWS Glue is processing all the data during each run. What should the solutions architect do to prevent AWS Glue from reprocessing old data?",
    "options_en": {
      "A": "Edit the job to use job bookmarks.",
      "B": "Edit the job to delete data after the data is processed.",
      "C": "Edit the job by setting the NumberOfWorkers field to 1.",
      "D": "Use a FindMatches machine learning (ML) transform."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个 AWS Glue extract, transform, and load (ETL) 作业，该作业每天在同一时间运行。该作业处理 Amazon S3 存储桶中的 XML 数据。新数据每天添加到 S3 存储桶。一位解决方案架构师注意到 AWS Glue 每次运行时都在处理所有数据。解决方案架构师应该怎么做才能防止 AWS Glue 重新处理旧数据？",
    "options_cn": {
      "A": "编辑作业以使用作业书签。",
      "B": "编辑作业以在处理完数据后删除数据。",
      "C": "通过将 NumberOfWorkers 字段设置为 1 来编辑作业。",
      "D": "使用 FindMatches 机器学习 (ML) 转换。"
    }
  },
  {
    "id": 104,
    "topic": "1",
    "question_en": "A solutions architect must design a highly available infrastructure for a website. The website is powered by Windows web servers that run on Amazon EC2 instances. The solutions architect must implement a solution that can mitigate a large-scale DDoS attack that originates from thousands of IP addresses. Downtime is not acceptable for the website. Which actions should the solutions architect take to protect the website from such an attack? (Choose two.)",
    "options_en": {
      "A": "Use AWS Shield Advanced to stop the DDoS attack.",
      "B": "Configure Amazon GuardDuty to automatically block the attackers.",
      "C": "Configure the website to use Amazon CloudFront for both static and dynamic content.",
      "D": "Use an AWS Lambda function to automatically add attacker IP addresses to VPC network ACLs",
      "E": "Use EC2 Spot Instances in an Auto Scaling group with a target tracking scaling policy that is set to 80% CPU utilization."
    },
    "correct_answer": "A",
    "vote_percentage": "87%",
    "question_cn": "一位解决方案架构师必须为网站设计一个高可用性基础设施。该网站由在 Amazon EC2 实例上运行的 Windows Web 服务器提供支持。解决方案架构师必须实施一个可以缓解源自数千个 IP 地址的大规模 DDoS 攻击的解决方案。该网站的停机时间是不可接受的。 解决方案架构师应该采取哪些措施来保护网站免受此类攻击？（选择两项。）",
    "options_cn": {
      "A": "使用 AWS Shield Advanced 来阻止 DDoS 攻击。",
      "B": "配置 Amazon GuardDuty 以自动阻止攻击者。",
      "C": "将网站配置为使用 Amazon CloudFront 来提供静态和动态内容。",
      "D": "使用 AWS Lambda 函数自动将攻击者的 IP 地址添加到 VPC 网络 ACL 中。",
      "E": "在具有目标跟踪扩展策略的 Auto Scaling 组中使用 EC2 Spot 实例，该策略设置为 80% 的 CPU 利用率。"
    }
  },
  {
    "id": 105,
    "topic": "1",
    "question_en": "A company is preparing to deploy a new serverless workload. A solutions architect must use the principle of least privilege to configure permissions that will be used to run an AWS Lambda function. An Amazon EventBridge (Amazon CloudWatch Events) rule will invoke the function. Which solution meets these requirements?",
    "options_en": {
      "A": "Add an execution role to the function with lambda:InvokeFunction as the action and * as the principal.",
      "B": "Add an execution role to the function with lambda:InvokeFunction as the action and Service: lambda.amazonaws.com as the principal.",
      "C": "Add a resource-based policy to the function with lambda:* as the action and Service: events.amazonaws.com as the principal.",
      "D": "Add a resource-based policy to the function with lambda:InvokeFunction as the action and Service: events.amazonaws.com as the principal."
    },
    "correct_answer": "D",
    "vote_percentage": "97%",
    "question_cn": "一家公司正准备部署新的无服务器工作负载。一位解决方案架构师必须使用最小权限原则来配置将用于运行 AWS Lambda 函数的权限。Amazon EventBridge (Amazon CloudWatch Events) 规则将调用该函数。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "为函数添加一个执行角色，其操作为 lambda:InvokeFunction，主体为 *。",
      "B": "为函数添加一个执行角色，其操作为 lambda:InvokeFunction，主体为 Service: lambda.amazonaws.com。",
      "C": "为函数添加一个基于资源的策略，其操作为 lambda:*，主体为 Service: events.amazonaws.com。",
      "D": "为函数添加一个基于资源的策略，其操作为 lambda:InvokeFunction，主体为 Service: events.amazonaws.com。"
    }
  },
  {
    "id": 106,
    "topic": "1",
    "question_en": "A company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest. Encryption key usage must be logged for auditing purposes. Keys must be rotated every year. Which solution meets these requirements and is the MOST operationally eficient?",
    "options_en": {
      "A": "Server-side encryption with customer-provided keys (SSE-C)",
      "B": "Server-side encryption with Amazon S3 managed keys (SSE-S3)",
      "C": "Server-side encryption with AWS KMS keys (SSE-KMS) with manual rotation",
      "D": "Server-side encryption with AWS KMS keys (SSE-KMS) with automatic rotation"
    },
    "correct_answer": "D",
    "vote_percentage": "93%",
    "question_cn": "一家公司正准备在 Amazon S3 中存储机密数据。出于合规性原因，静态数据必须加密。必须记录密钥使用情况以进行审计。密钥必须每年轮换一次。哪个解决方案满足这些要求并且操作效率最高？",
    "options_cn": {
      "A": "使用客户提供的密钥的服务器端加密 (SSE-C)",
      "B": "使用 Amazon S3 托管密钥的服务器端加密 (SSE-S3)",
      "C": "使用 AWS KMS 密钥的服务器端加密 (SSE-KMS)，手动轮换",
      "D": "使用 AWS KMS 密钥的服务器端加密 (SSE-KMS)，自动轮换"
    }
  },
  {
    "id": 107,
    "topic": "1",
    "question_en": "A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants to use these data points in its existing analytics platform. A solutions architect must determine the most viable multi-tier option to support this architecture. The data points must be accessible from the REST API. Which action meets these requirements for storing and retrieving location data?",
    "options_en": {
      "A": "Use Amazon Athena with Amazon S3.",
      "B": "Use Amazon API Gateway with AWS Lambda.",
      "C": "Use Amazon QuickSight with Amazon Redshift.",
      "D": "Use Amazon API Gateway with Amazon Kinesis Data Analytics."
    },
    "correct_answer": "D",
    "vote_percentage": "50%",
    "question_cn": "一家自行车共享公司正在开发一个多层架构，以在运营高峰时跟踪其自行车的 GPS 位置。该公司希望在其现有的分析平台中使用这些数据点。解决方案架构师必须确定最可行的多层选项以支持此架构。这些数据点必须可以通过 REST API 访问。哪个操作满足存储和检索位置数据的这些要求？",
    "options_cn": {
      "A": "使用 Amazon Athena 和 Amazon S3。",
      "B": "使用 Amazon API Gateway 和 AWS Lambda。",
      "C": "使用 Amazon QuickSight 和 Amazon Redshift。",
      "D": "使用 Amazon API Gateway 和 Amazon Kinesis Data Analytics。"
    }
  },
  {
    "id": 108,
    "topic": "1",
    "question_en": "A company has an automobile sales website that stores its listings in a database on Amazon RDS. When an automobile is sold, the listing needs to be removed from the website and the data must be sent to multiple target systems. Which design should a solutions architect recommend?",
    "options_en": {
      "A": "Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.",
      "B": "Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.",
      "C": "Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.",
      "D": "Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets."
    },
    "correct_answer": "C",
    "vote_percentage": "63%",
    "question_cn": "一家公司有一个汽车销售网站，该网站将其列表存储在 Amazon RDS 上的数据库中。 当汽车售出时，该列表需要从网站上删除，并且数据必须发送到多个目标系统。 解决方案架构师应推荐哪种设计？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，当 Amazon RDS 上的数据库更新时触发，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) 队列，供目标系统使用。",
      "B": "创建一个 AWS Lambda 函数，当 Amazon RDS 上的数据库更新时触发，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列，供目标系统使用。",
      "C": "订阅 RDS 事件通知，并将 Amazon Simple Queue Service (Amazon SQS) 队列扇出到多个 Amazon Simple Notification Service (Amazon SNS) 主题。 使用 AWS Lambda 函数更新目标系统。",
      "D": "订阅 RDS 事件通知，并将 Amazon Simple Notification Service (Amazon SNS) 主题扇出到多个 Amazon Simple Queue Service (Amazon SQS) 队列。 使用 AWS Lambda 函数更新目标系统。"
    }
  },
  {
    "id": 109,
    "topic": "1",
    "question_en": "A company needs to store data in Amazon S3 and must prevent the data from being changed. The company wants new objects that are uploaded to Amazon S3 to remain unchangeable for a nonspecific amount of time until the company decides to modify the objects. Only specific users in the company's AWS account can have the ability 10 delete the objects. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an S3 Glacier vault. Apply a write-once, read-many (WORM) vault lock policy to the objects.",
      "B": "Create an S3 bucket with S3 Object Lock enabled. Enable versioning. Set a retention period of 100 years. Use governance mode as the S3 bucket’s default retention mode for new objects.",
      "C": "Create an S3 bucket. Use AWS CloudTrail to track any S3 API events that modify the objects. Upon notification, restore the modified objects from any backup versions that the company has.",
      "D": "Create an S3 bucket with S3 Object Lock enabled. Enable versioning. Add a legal hold to the objects. Add the s3:PutObjectLegalHold permission to the IAM policies of users who need to delete the objects."
    },
    "correct_answer": "D",
    "vote_percentage": "76%",
    "question_cn": "一家公司需要在 Amazon S3 中存储数据，并且必须防止数据被更改。该公司希望上传到 Amazon S3 的新对象在公司决定修改这些对象之前，保持不可更改的时间，时间长短不确定。只有公司 AWS 账户中的特定用户才能删除这些对象。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 S3 Glacier 保险库。对这些对象应用一次写入多次读取（WORM）保险库锁定策略。",
      "B": "创建一个启用了 S3 对象锁定的 S3 存储桶。启用版本控制。设置 100 年的保留期。将治理模式用作 S3 存储桶中新对象的默认保留模式。",
      "C": "创建一个 S3 存储桶。使用 AWS CloudTrail 跟踪修改这些对象的任何 S3 API 事件。收到通知后，从公司拥有的任何备份版本恢复修改后的对象。",
      "D": "创建一个启用了 S3 对象锁定的 S3 存储桶。启用版本控制。为这些对象添加法律保留。将 s3:PutObjectLegalHold 权限添加到需要删除对象的用户的 IAM 策略中。"
    }
  },
  {
    "id": 110,
    "topic": "1",
    "question_en": "A social media company allows users to upload images to its website. The website runs on Amazon EC2 instances. During upload requests, the website resizes the images to a standard size and stores the resized images in Amazon S3. Users are experiencing slow upload requests to the website. The company needs to reduce coupling within the application and improve website performance. A solutions architect must design the most operationally eficient process for image uploads. Which combination of actions should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Configure the application to upload images to S3 Glacier.",
      "B": "Configure the web server to upload the original images to Amazon S3.",
      "C": "Configure the application to upload images directly from each user's browser to Amazon S3 through the use of a presigned URL",
      "D": "Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the imag",
      "E": "E. Create an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function on a schedule to resize uploaded images."
    },
    "correct_answer": "B",
    "vote_percentage": "52%",
    "question_cn": "一家社交媒体公司允许用户向其网站上传图片。该网站运行在 Amazon EC2 实例上。在上传请求期间，网站将图片调整为标准尺寸，并将调整后的图片存储在 Amazon S3 中。用户遇到上传请求到网站的速度变慢的问题。该公司需要减少应用程序内的耦合并提高网站性能。一个解决方案架构师必须设计最高效的图像上传流程。解决方案架构师应该采取哪些操作组合来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "配置应用程序将图片上传到 S3 Glacier。",
      "B": "配置 Web 服务器将原始图片上传到 Amazon S3。",
      "C": "配置应用程序使用预签名 URL，直接从每个用户的浏览器将图片上传到 Amazon S3。",
      "D": "配置 S3 事件通知，以便在上传图片时调用 AWS Lambda 函数。使用该函数调整图片大小。",
      "E": "创建一个 Amazon EventBridge（Amazon CloudWatch Events）规则，该规则在定期间隔调用 AWS Lambda 函数以调整上传的图片大小。"
    }
  },
  {
    "id": 111,
    "topic": "1",
    "question_en": "A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity. Which architecture offers the HIGHEST availability?",
    "options_en": {
      "A": "Add a second ActiveMQ server to another Availability Zone. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
      "B": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.",
      "C": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled.",
      "D": "Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled."
    },
    "correct_answer": "D",
    "vote_percentage": "98%",
    "question_cn": "一家公司最近将消息处理系统迁移到了 AWS。该系统接收消息到运行在 Amazon EC2 实例上的 ActiveMQ 队列中。消息由运行在 Amazon EC2 上的消费者应用程序处理。消费者应用程序处理消息并将结果写入运行在 Amazon EC2 上的 MySQL 数据库。公司希望此应用程序具有高可用性，且运营复杂性较低。哪种架构提供最高的可用性？",
    "options_cn": {
      "A": "在另一个可用区添加第二个 ActiveMQ 服务器。在另一个可用区添加一个额外的消费者 EC2 实例。将 MySQL 数据库复制到另一个可用区。",
      "B": "使用 Amazon MQ，在两个可用区配置主动/备用代理。在另一个可用区添加一个额外的消费者 EC2 实例。将 MySQL 数据库复制到另一个可用区。",
      "C": "使用 Amazon MQ，在两个可用区配置主动/备用代理。在另一个可用区添加一个额外的消费者 EC2 实例。使用启用了多可用区的 Amazon RDS for MySQL。",
      "D": "使用 Amazon MQ，在两个可用区配置主动/备用代理。为跨两个可用区的消费者 EC2 实例添加一个 Auto Scaling 组。使用启用了多可用区的 Amazon RDS for MySQL。"
    }
  },
  {
    "id": 112,
    "topic": "1",
    "question_en": "A company hosts a containerized web application on a fieet of on-premises servers that process incoming requests. The number of requests is growing quickly. The on-premises servers cannot handle the increased number of requests. The company wants to move the application to AWS with minimum code changes and minimum development effort. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Fargate on Amazon Elastic Container Service (Amazon ECS) to run the containerized web application with Service Auto Scaling. Use an Application Load Balancer to distribute the incoming requests.",
      "B": "Use two Amazon EC2 instances to host the containerized web application. Use an Application Load Balancer to distribute the incoming requests.",
      "C": "Use AWS Lambda with a new code that uses one of the supported languages. Create multiple Lambda functions to support the load. Use Amazon API Gateway as an entry point to the Lambda functions.",
      "D": "Use a high performance computing (HPC) solution such as AWS ParallelCluster to establish an HPC cluster that can process the incoming requests at the appropriate scale."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其本地服务器集群上托管一个容器化的 Web 应用程序，该应用程序会处理传入的请求。请求数量正在快速增长。本地服务器无法处理增加的请求数量。该公司希望以最少的代码更改和最少的开发工作量将该应用程序迁移到 AWS。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Fargate on Amazon Elastic Container Service (Amazon ECS) 运行容器化的 Web 应用程序，并使用 Service Auto Scaling。使用 Application Load Balancer (ALB) 分发传入的请求。",
      "B": "使用两个 Amazon EC2 实例来托管容器化的 Web 应用程序。使用 Application Load Balancer (ALB) 分发传入的请求。",
      "C": "使用 AWS Lambda 和使用其中一种支持语言编写的新代码。创建多个 Lambda 函数以支持负载。使用 Amazon API Gateway 作为 Lambda 函数的入口点。",
      "D": "使用高性能计算 (HPC) 解决方案（例如 AWS ParallelCluster）来建立一个 HPC 集群，该集群可以按适当的规模处理传入的请求。"
    }
  },
  {
    "id": 113,
    "topic": "1",
    "question_en": "A company uses 50 TB of data for reporting. The company wants to move this data from on premises to AWS. A custom application in the company’s data center runs a weekly data transformation job. The company plans to pause the application until the data transfer is complete and needs to begin the transfer process as soon as possible. The data center does not have any available network bandwidth for additional workloads. A solutions architect must transfer the data and must configure the transformation job to continue to run in the AWS Cloud. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS DataSync to move the data. Create a custom transformation job by using AWS Glue.",
      "B": "Order an AWS Snowcone device to move the data. Deploy the transformation application to the device.",
      "C": "Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue.",
      "D": "Order an AWS Snowball Edge Storage Optimized device that includes Amazon EC2 compute. Copy the data to the device. Create a new EC2 instance on AWS to run the transformation application."
    },
    "correct_answer": "C",
    "vote_percentage": "71%",
    "question_cn": "一家公司使用 50 TB 的数据进行报告。该公司希望将这些数据从本地迁移到 AWS。该公司数据中心的一个自定义应用程序每周运行一次数据转换作业。该公司计划暂停该应用程序，直到数据传输完成，并且需要尽快开始传输过程。数据中心没有任何可用于额外工作负载的网络带宽。解决方案架构师必须传输数据，并且必须配置转换作业以继续在 AWS 云中运行。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 移动数据。使用 AWS Glue 创建一个自定义转换作业。",
      "B": "订购 AWS Snowcone 设备来移动数据。将转换应用程序部署到该设备。",
      "C": "订购 AWS Snowball Edge 存储优化设备。将数据复制到该设备。使用 AWS Glue 创建一个自定义转换作业。",
      "D": "订购一个包含 Amazon EC2 计算的 AWS Snowball Edge 存储优化设备。将数据复制到该设备。在 AWS 上创建一个新的 EC2 实例以运行转换应用程序。"
    }
  },
  {
    "id": 114,
    "topic": "1",
    "question_en": "A company has created an image analysis application in which users can upload photos and add photo frames to their images. The users upload images and metadata to indicate which photo frames they want to add to their images. The application uses a single Amazon EC2 instance and Amazon DynamoDB to store the metadata. The application is becoming more popular, and the number of users is increasing. The company expects the number of concurrent users to vary significantly depending on the time of day and day of week. The company must ensure that the application can scale to meet the needs of the growing user base. Which solution meats these requirements?",
    "options_en": {
      "A": "Use AWS Lambda to process the photos. Store the photos and metadata in DynamoDB.",
      "B": "Use Amazon Kinesis Data Firehose to process the photos and to store the photos and metadata.",
      "C": "Use AWS Lambda to process the photos. Store the photos in Amazon S3. Retain DynamoDB to store the metadata.",
      "D": "Increase the number of EC2 instances to three. Use Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volumes to store the photos and metadata."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司创建了一个图像分析应用程序，用户可以上传照片并向其图像添加相框。用户上传图像和元数据，以指示他们想要添加到图像中的相框。该应用程序使用单个 Amazon EC2 实例和 Amazon DynamoDB 来存储元数据。该应用程序变得越来越受欢迎，用户数量也在增加。该公司预计并发用户数量会因一天中的时间和一周中的日期而异。该公司必须确保该应用程序可以扩展以满足不断增长的用户群的需求。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS Lambda 处理照片。将照片和元数据存储在 DynamoDB 中。",
      "B": "使用 Amazon Kinesis Data Firehose 处理照片，并存储照片和元数据。",
      "C": "使用 AWS Lambda 处理照片。将照片存储在 Amazon S3 中。保留 DynamoDB 来存储元数据。",
      "D": "将 EC2 实例的数量增加到三个。使用预置 IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) 卷来存储照片和元数据。"
    }
  },
  {
    "id": 115,
    "topic": "1",
    "question_en": "A medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access. A new requirement mandates that the network trafic for file transfers take a private route and not be sent over the internet. Which change to the network architecture should a solutions architect recommend to meet this requirement?",
    "options_en": {
      "A": "Create a NAT gateway. Configure the route table for the public subnets to send trafic to Amazon S3 through the NAT gateway.",
      "B": "Configure the security group for the EC2 instances to restrict outbound trafic so that only trafic to the S3 prefix list is permitted.",
      "C": "Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets.",
      "D": "Remove the internet gateway from the VPC. Set up an AWS Direct Connect connection, and route trafic to Amazon S3 over the Direct Connect connection."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家医疗记录公司正在 Amazon EC2 实例上托管一个应用程序。该应用程序处理存储在 Amazon S3 上的客户数据文件。EC2 实例托管在公共子网中。EC2 实例通过互联网访问 Amazon S3，但它们不需要任何其他网络访问。一项新要求规定，文件传输的网络流量必须采取专用路由，而不是通过互联网发送。解决方案架构师应该推荐对网络架构进行哪些更改来满足此要求？",
    "options_cn": {
      "A": "创建一个 NAT Gateway。配置公共子网的路由表，以通过 NAT Gateway 将流量发送到 Amazon S3。",
      "B": "配置 EC2 实例的安全组，以限制出站流量，以便仅允许到 S3 前缀列表的流量。",
      "C": "将 EC2 实例移动到私有子网。为 Amazon S3 创建一个 VPC endpoint，并将该 endpoint 链接到私有子网的路由表。",
      "D": "从 VPC 中删除 internet gateway。设置 AWS Direct Connect 连接，并通过 Direct Connect 连接将流量路由到 Amazon S3。"
    }
  },
  {
    "id": 116,
    "topic": "1",
    "question_en": "A company uses a popular content management system (CMS) for its corporate website. However, the required patching and maintenance are burdensome. The company is redesigning its website and wants anew solution. The website will be updated four times a year and does not need to have any dynamic content available. The solution must provide high scalability and enhanced security. Which combination of changes will meet these requirements with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Configure Amazon CloudFront in front of the website to use HTTPS functionality.",
      "B": "Deploy an AWS WAF web ACL in front of the website to provide HTTPS functionality.",
      "C": "Create and deploy an AWS Lambda function to manage and serve the website content.",
      "D": "Create the new website and an Amazon S3 bucket. Deploy the website on the S3 bucket with static website hosting enabled",
      "E": "Create the new website. Deploy the website by using an Auto Scaling group of Amazon EC2 instances behind an Application Load Balancer."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司为其企业网站使用流行的内容管理系统（CMS）。然而，所需的补丁和维护工作非常繁重。该公司正在重新设计其网站，并希望采用新的解决方案。该网站每年将更新四次，并且不需要任何动态内容。该解决方案必须提供高可扩展性和增强的安全性。哪两种变更组合将以最少的运营开销满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在网站前面配置 Amazon CloudFront 以使用 HTTPS 功能。",
      "B": "在网站前面部署 AWS WAF Web ACL 以提供 HTTPS 功能。",
      "C": "创建并部署一个 AWS Lambda 函数来管理和提供网站内容。",
      "D": "创建新网站和一个 Amazon S3 存储桶。将网站部署在 S3 存储桶上，并启用静态网站托管。",
      "E": "创建新网站。通过使用 Application Load Balancer 后面的 Amazon EC2 实例的 Auto Scaling 组来部署网站。"
    }
  },
  {
    "id": 117,
    "topic": "1",
    "question_en": "A company stores its application logs in an Amazon CloudWatch Logs log group. A new policy requires the company to store all application logs in Amazon OpenSearch Service (Amazon Elasticsearch Service) in near-real time. Which solution will meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure a CloudWatch Logs subscription to stream the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).",
      "B": "Create an AWS Lambda function. Use the log group to invoke the function to write the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service).",
      "C": "Create an Amazon Kinesis Data Firehose delivery stream. Configure the log group as the delivery streams sources. Configure Amazon OpenSearch Service (Amazon Elasticsearch Service) as the delivery stream's destination.",
      "D": "Install and configure Amazon Kinesis Agent on each application server to deliver the logs to Amazon Kinesis Data Streams. Configure Kinesis Data Streams to deliver the logs to Amazon OpenSearch Service (Amazon Elasticsearch Service)."
    },
    "correct_answer": "C",
    "vote_percentage": "69%",
    "question_cn": "一家公司将其应用程序日志存储在 Amazon CloudWatch Logs 日志组中。一项新策略要求该公司近乎实时地将所有应用程序日志存储在 Amazon OpenSearch Service (Amazon Elasticsearch Service) 中。哪种解决方案以最少的运营开销满足此要求？",
    "options_cn": {
      "A": "配置 CloudWatch Logs 订阅，将日志流式传输到 Amazon OpenSearch Service (Amazon Elasticsearch Service)。",
      "B": "创建 AWS Lambda 函数。使用日志组调用该函数，将日志写入 Amazon OpenSearch Service (Amazon Elasticsearch Service)。",
      "C": "创建 Amazon Kinesis Data Firehose 交付流。将日志组配置为交付流的源。将 Amazon OpenSearch Service (Amazon Elasticsearch Service) 配置为交付流的目的地。",
      "D": "在每个应用程序服务器上安装并配置 Amazon Kinesis Agent，以便将日志传递到 Amazon Kinesis Data Streams。配置 Kinesis Data Streams 以将日志传递到 Amazon OpenSearch Service (Amazon Elasticsearch Service)。"
    }
  },
  {
    "id": 118,
    "topic": "1",
    "question_en": "A company is building a web-based application running on Amazon EC2 instances in multiple Availability Zones. The web application will provide access to a repository of text documents totaling about 900 TB in size. The company anticipates that the web application will experience periods of high demand. A solutions architect must ensure that the storage component for the text documents can scale to meet the demand of the application at all times. The company is concerned about the overall cost of the solution. Which storage solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Amazon Elastic Block Store (Amazon EBS)",
      "B": "Amazon Elastic File System (Amazon EFS)",
      "C": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "D": "Amazon S3"
    },
    "correct_answer": "D",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在构建一个基于网络的应用程序，该应用程序在多个可用区中的 Amazon EC2 实例上运行。该 Web 应用程序将提供对大约 900 TB 文本文档存储库的访问。该公司预计 Web 应用程序将经历高需求时期。解决方案架构师必须确保文本文档的存储组件可以扩展以始终满足应用程序的需求。该公司关心解决方案的总体成本。哪种存储解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "Amazon Elastic Block Store (Amazon EBS)",
      "B": "Amazon Elastic File System (Amazon EFS)",
      "C": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "D": "Amazon S3"
    }
  },
  {
    "id": 119,
    "topic": "1",
    "question_en": "A global company is using Amazon API Gateway to design REST APIs for its loyalty club users in the us-east-1 Region and the ap-southeast-2 Region. A solutions architect must design a solution to protect these API Gateway managed REST APIs across multiple accounts from SQL injection and cross-site scripting attacks. Which solution will meet these requirements with the LEAST amount of administrative effort?",
    "options_en": {
      "A": "Set up AWS WAF in both Regions. Associate Regional web ACLs with an API stage.",
      "B": "Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules.",
      "C": "Set up AWS Shield in bath Regions. Associate Regional web ACLs with an API stage.",
      "D": "Set up AWS Shield in one of the Regions. Associate Regional web ACLs with an API stage."
    },
    "correct_answer": "A",
    "vote_percentage": "69%",
    "question_cn": "一家全球公司正在使用 Amazon API Gateway 为其位于 us-east-1 区域和 ap-southeast-2 区域的忠诚俱乐部用户设计 REST API。 解决方案架构师必须设计一个解决方案，以保护这些 API Gateway 管理的 REST API 跨多个账户免受 SQL 注入和跨站点脚本攻击。 哪种解决方案将以最少的管理工作量满足这些要求？",
    "options_cn": {
      "A": "在两个区域设置 AWS WAF。 将区域 Web ACL 与 API 阶段关联。",
      "B": "在两个区域设置 AWS Firewall Manager。 集中配置 AWS WAF 规则。",
      "C": "在两个区域设置 AWS Shield。 将区域 Web ACL 与 API 阶段关联。",
      "D": "在一个区域设置 AWS Shield。 将区域 Web ACL 与 API 阶段关联。"
    }
  },
  {
    "id": 120,
    "topic": "1",
    "question_en": "A company has implemented a self-managed DNS solution on three Amazon EC2 instances behind a Network Load Balancer (NLB) in the us- west-2 Region. Most of the company's users are located in the United States and Europe. The company wants to improve the performance and availability of the solution. The company launches and configures three EC2 instances in the eu-west-1 Region and adds the EC2 instances as targets for a new NLB. Which solution can the company use to route trafic to all the EC2 instances?",
    "options_en": {
      "A": "Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin.",
      "B": "Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups.",
      "C": "Attach Elastic IP addresses to the six EC2 instances. Create an Amazon Route 53 geolocation routing policy to route requests to one of the six EC2 instances. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution's origin.",
      "D": "Replace the two NLBs with two Application Load Balancers (ALBs). Create an Amazon Route 53 latency routing policy to route requests to one of the two ALBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin."
    },
    "correct_answer": "A",
    "vote_percentage": "75%",
    "question_cn": "一家公司在 us-west-2 区域的三个 Amazon EC2 实例上实现了自管理的 DNS 解决方案，这些实例位于一个 Network Load Balancer (NLB) 之后。该公司的大部分用户位于美国和欧洲。该公司希望提高解决方案的性能和可用性。该公司在 eu-west-1 区域启动并配置了三个 EC2 实例，并将这些 EC2 实例添加为新 NLB 的目标。该公司可以使用哪种解决方案来将流量路由到所有 EC2 实例？",
    "options_cn": {
      "A": "创建 Amazon Route 53 地理位置路由策略，将请求路由到两个 NLB 之一。创建 Amazon CloudFront 分配。使用 Route 53 记录作为分配的源。",
      "B": "在 AWS Global Accelerator 中创建标准加速器。在 us-west-2 和 eu-west-1 中创建终端节点组。将两个 NLB 添加为终端节点组的终端节点。",
      "C": "将弹性 IP 地址附加到六个 EC2 实例。创建 Amazon Route 53 地理位置路由策略，将请求路由到六个 EC2 实例之一。创建 Amazon CloudFront 分配。使用 Route 53 记录作为分配的源。",
      "D": "用两个 Application Load Balancer (ALB) 替换两个 NLB。创建 Amazon Route 53 延迟路由策略，将请求路由到两个 ALB 之一。创建 Amazon CloudFront 分配。使用 Route 53 记录作为分配的源。"
    }
  },
  {
    "id": 121,
    "topic": "1",
    "question_en": "A company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi-AZ deployment. Daily database snapshots are taken from this instance. What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward?",
    "options_en": {
      "A": "Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.",
      "B": "Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots to it. Enable encryption on the DB instance.",
      "C": "Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS) Restore encrypted snapshot to an existing DB instance.",
      "D": "Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS)."
    },
    "correct_answer": "A",
    "vote_percentage": "83%",
    "question_cn": "一家公司正在 AWS 上运行在线事务处理 (OLTP) 工作负载。此工作负载使用位于 Multi-AZ 部署中的未加密 Amazon RDS 数据库实例。每天从该实例拍摄数据库快照。解决方案架构师应采取什么措施来确保数据库和快照在未来始终被加密？",
    "options_cn": {
      "A": "加密最新数据库快照的副本。通过恢复加密的快照来替换现有的数据库实例。",
      "B": "创建一个新的加密 Amazon Elastic Block Store (Amazon EBS) 卷，并将快照复制到其中。在数据库实例上启用加密。",
      "C": "复制快照并使用 AWS Key Management Service (AWS KMS) 启用加密。将加密的快照恢复到现有的数据库实例。",
      "D": "将快照复制到使用带有 AWS Key Management Service (AWS KMS) 托管密钥的服务器端加密 (SSE-KMS) 加密的 Amazon S3 存储桶。"
    }
  },
  {
    "id": 122,
    "topic": "1",
    "question_en": "A company wants to build a scalable key management infrastructure to support developers who need to encrypt data in their applications. What should a solutions architect do to reduce the operational burden?",
    "options_en": {
      "A": "Use multi-factor authentication (MFA) to protect the encryption keys.",
      "B": "Use AWS Key Management Service (AWS KMS) to protect the encryption keys.",
      "C": "Use AWS Certificate Manager (ACM) to create, store, and assign the encryption keys.",
      "D": "Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望构建可扩展的密钥管理基础设施，以支持需要在其应用程序中加密数据的开发人员。解决方案架构师应该怎么做以减少运营负担？",
    "options_cn": {
      "A": "使用多因素身份验证 (MFA) 来保护加密密钥。",
      "B": "使用 AWS Key Management Service (AWS KMS) 来保护加密密钥。",
      "C": "使用 AWS Certificate Manager (ACM) 来创建、存储和分配加密密钥。",
      "D": "使用 IAM 策略来限制有权访问权限的用户范围，以保护加密密钥。"
    }
  },
  {
    "id": 123,
    "topic": "1",
    "question_en": "A company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination. There has been an increase in trafic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit. What should a solutions architect do to increase the application's performance?",
    "options_en": {
      "A": "Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.",
      "B": "Create an Amazon S3 bucket Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.",
      "C": "Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.",
      "D": "Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM."
    },
    "correct_answer": "D",
    "vote_percentage": "96%",
    "question_cn": "一家公司在其两个 Amazon EC2 实例上托管动态 Web 应用程序。该公司拥有自己的 SSL 证书，该证书位于每个实例上以执行 SSL 终止。最近流量有所增加，运营团队确定 SSL 加密和解密导致 Web 服务器的计算能力达到其最大限制。解决方案架构师应该怎么做来提高应用程序的性能？",
    "options_cn": {
      "A": "使用 AWS Certificate Manager (ACM) 创建一个新的 SSL 证书。将 ACM 证书安装在每个实例上。",
      "B": "创建一个 Amazon S3 存储桶。将 SSL 证书迁移到 S3 存储桶。配置 EC2 实例以引用该存储桶进行 SSL 终止。",
      "C": "创建另一个 EC2 实例作为代理服务器。将 SSL 证书迁移到新实例，并将其配置为将连接定向到现有的 EC2 实例。",
      "D": "将 SSL 证书导入 AWS Certificate Manager (ACM)。创建一个 Application Load Balancer (ALB)，其中包含一个使用来自 ACM 的 SSL 证书的 HTTPS 侦听器。"
    }
  },
  {
    "id": 124,
    "topic": "1",
    "question_en": "A company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete. The company has asked a solutions architect to design a scalable and cost-effective solution that meets the requirements of the job. What should the solutions architect recommend?",
    "options_en": {
      "A": "Implement EC2 Spot Instances.",
      "B": "Purchase EC2 Reserved Instances.",
      "C": "Implement EC2 On-Demand Instances.",
      "D": "Implement the processing on AWS Lambda."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司有一个高度动态的批处理作业，该作业使用许多 Amazon EC2 实例来完成。该作业本质上是无状态的，可以在任何给定时间启动和停止，没有任何负面影响，并且通常需要 60 分钟以上才能完成。该公司要求解决方案架构师设计一个可扩展且经济高效的解决方案，以满足该作业的要求。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "实施 EC2 Spot Instances。",
      "B": "购买 EC2 Reserved Instances。",
      "C": "实施 EC2 On-Demand Instances。",
      "D": "在 AWS Lambda 上实施处理。"
    }
  },
  {
    "id": 125,
    "topic": "1",
    "question_en": "A company runs its two-tier ecommerce website on AWS. The web tier consists of a load balancer that sends trafic to Amazon EC2 instances. The database tier uses an Amazon RDS DB instance. The EC2 instances and the RDS DB instance should not be exposed to the public internet. The EC2 instances require internet access to complete payment processing of orders through a third-party web service. The application must be highly available. Which combination of configuration options will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.",
      "B": "Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.",
      "C": "Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi-AZ DB instance in private subnets.",
      "D": "Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets."
    },
    "correct_answer": "C",
    "vote_percentage": "61%",
    "question_cn": "一家公司在 AWS 上运行其两层电商网站。Web 层由一个负载均衡器组成，该负载均衡器将流量发送到 Amazon EC2 实例。数据库层使用 Amazon RDS 数据库实例。EC2 实例和 RDS 数据库实例不应暴露给公共互联网。EC2 实例需要互联网访问权限，才能通过第三方 Web 服务完成订单的支付处理。该应用程序必须具有高可用性。哪种配置选项组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Auto Scaling 组在私有子网中启动 EC2 实例。在私有子网中部署 RDS 多可用区数据库实例。",
      "B": "使用两个私有子网和两个跨两个可用区的 NAT Gateway 配置一个 VPC。在私有子网中部署 Application Load Balancer。",
      "C": "使用 Auto Scaling 组在跨两个可用区的公共子网中启动 EC2 实例。在私有子网中部署 RDS 多可用区数据库实例。",
      "D": "配置一个 VPC，其中包含两个公共子网、两个私有子网和两个跨两个可用区的 NAT Gateway。在公共子网中部署 Application Load Balancer。"
    }
  },
  {
    "id": 126,
    "topic": "1",
    "question_en": "A solutions architect needs to implement a solution to reduce a company's storage costs. All the company's data is in the Amazon S3 Standard storage class. The company must keep all data for at least 25 years. Data from the most recent 2 years must be highly available and immediately retrievable. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive immediately.",
      "B": "Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 2 years.",
      "C": "Use S3 Intelligent-Tiering. Activate the archiving option to ensure that data is archived in S3 Glacier Deep Archive.",
      "D": "Set up an S3 Lifecycle policy to transition objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately and to S3 Glacier Deep Archive after 2 years."
    },
    "correct_answer": "B",
    "vote_percentage": "79%",
    "question_cn": "一位解决方案架构师需要实施一个解决方案来降低公司的存储成本。该公司所有的数据都在 Amazon S3 标准存储类中。该公司必须将所有数据保留至少 25 年。最近 2 年的数据必须具有高可用性，并且可以立即检索。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置 S3 生命周期策略，立即将对象转换为 S3 Glacier Deep Archive。",
      "B": "设置 S3 生命周期策略，在 2 年后将对象转换为 S3 Glacier Deep Archive。",
      "C": "使用 S3 Intelligent-Tiering。 激活归档选项以确保数据归档在 S3 Glacier Deep Archive 中。",
      "D": "设置 S3 生命周期策略，立即将对象转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)，并在 2 年后转换为 S3 Glacier Deep Archive。"
    }
  },
  {
    "id": 127,
    "topic": "1",
    "question_en": "A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore. Which set of services should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage",
      "B": "Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage",
      "C": "Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage",
      "D": "Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage"
    },
    "correct_answer": "A",
    "vote_percentage": "62%",
    "question_cn": "一家媒体公司正在评估将其系统迁移到 AWS 云的可能性。该公司需要至少 10 TB 的存储空间，以便为视频处理提供最高的 I/O 性能，300 TB 的非常耐用的存储空间来存储媒体内容，以及 900 TB 的存储空间以满足不再使用的存档媒体的需求。解决方案架构师应该推荐哪一组服务来满足这些需求？",
    "options_cn": {
      "A": "使用 Amazon EBS 以获得最高性能，Amazon S3 用于耐用数据存储，以及 Amazon S3 Glacier 用于存档存储",
      "B": "使用 Amazon EBS 以获得最高性能，Amazon EFS 用于耐用数据存储，以及 Amazon S3 Glacier 用于存档存储",
      "C": "使用 Amazon EC2 实例存储以获得最高性能，Amazon EFS 用于耐用数据存储，以及 Amazon S3 用于存档存储",
      "D": "使用 Amazon EC2 实例存储以获得最高性能，Amazon S3 用于耐用数据存储，以及 Amazon S3 Glacier 用于存档存储"
    }
  },
  {
    "id": 128,
    "topic": "1",
    "question_en": "A company wants to run applications in containers in the AWS Cloud. These applications are stateless and can tolerate disruptions within the underlying infrastructure. The company needs a solution that minimizes cost and operational overhead. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use Spot Instances in an Amazon EC2 Auto Scaling group to run the application containers.",
      "B": "Use Spot Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.",
      "C": "Use On-Demand Instances in an Amazon EC2 Auto Scaling group to run the application containers.",
      "D": "Use On-Demand Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group."
    },
    "correct_answer": "A",
    "vote_percentage": "72%",
    "question_cn": "一家公司希望在 AWS 云中运行容器化应用程序。这些应用程序是无状态的，并且可以容忍底层基础设施中的中断。该公司需要一个能够最大限度地降低成本和运营开销的解决方案。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在 Amazon EC2 Auto Scaling 组中使用 Spot Instances 来运行应用程序容器。",
      "B": "在 Amazon Elastic Kubernetes Service (Amazon EKS) 托管节点组中使用 Spot Instances。",
      "C": "在 Amazon EC2 Auto Scaling 组中使用 On-Demand Instances 来运行应用程序容器。",
      "D": "在 Amazon Elastic Kubernetes Service (Amazon EKS) 托管节点组中使用 On-Demand Instances。"
    }
  },
  {
    "id": 129,
    "topic": "1",
    "question_en": "A company is running a multi-tier web application on premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company's growth. A solutions architect must improve the application's infrastructure. Which combination of actions should the solutions architect take to accomplish this? (Choose two.)",
    "options_en": {
      "A": "Migrate the PostgreSQL database to Amazon Aurora.",
      "B": "Migrate the web application to be hosted on Amazon EC2 instances.",
      "C": "Set up an Amazon CloudFront distribution for the web application content.",
      "D": "Set up Amazon ElastiCache between the web application and the PostgreSQL databas",
      "E": "E. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS)."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在其本地部署上运行一个多层 Web 应用程序。该 Web 应用程序已容器化，并在连接到包含用户记录的 PostgreSQL 数据库的多个 Linux 主机上运行。维护基础设施和容量规划的运营开销限制了公司的发展。一位解决方案架构师必须改进应用程序的基础设施。解决方案架构师应采取哪些组合的操作来完成此任务？（选择两个。）",
    "options_cn": {
      "A": "将 PostgreSQL 数据库迁移到 Amazon Aurora。",
      "B": "将 Web 应用程序迁移到托管在 Amazon EC2 实例上。",
      "C": "为 Web 应用程序内容设置 Amazon CloudFront 分发。",
      "D": "在 Web 应用程序和 PostgreSQL 数据库之间设置 Amazon ElastiCache。",
      "E": "将 Web 应用程序迁移到使用 Amazon Elastic Container Service (Amazon ECS) 托管在 AWS Fargate 上。"
    }
  },
  {
    "id": 130,
    "topic": "1",
    "question_en": "An application runs on Amazon EC2 instances across multiple Availability Zonas. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%. What should a solutions architect do to maintain the desired performance across all instances in the group?",
    "options_en": {
      "A": "Use a simple scaling policy to dynamically scale the Auto Scaling group.",
      "B": "Use a target tracking policy to dynamically scale the Auto Scaling group.",
      "C": "Use an AWS Lambda function ta update the desired Auto Scaling group capacity.",
      "D": "Use scheduled scaling actions to scale up and scale down the Auto Scaling group."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个应用程序在多个可用区运行在 Amazon EC2 实例上。这些实例在 Application Load Balancer 后面的 Amazon EC2 Auto Scaling 组中运行。当 EC2 实例的 CPU 利用率接近或达到 40% 时，该应用程序的性能最佳。解决方案架构师应该怎么做才能在组中的所有实例上保持所需的性能？",
    "options_cn": {
      "A": "使用简单的伸缩策略动态伸缩 Auto Scaling 组。",
      "B": "使用目标跟踪策略动态伸缩 Auto Scaling 组。",
      "C": "使用 AWS Lambda 函数来更新所需的 Auto Scaling 组容量。",
      "D": "使用预定的伸缩操作来伸缩和缩减 Auto Scaling 组。"
    }
  },
  {
    "id": 131,
    "topic": "1",
    "question_en": "A company is developing a file-sharing application that will use an Amazon S3 bucket for storage. The company wants to serve all the files through an Amazon CloudFront distribution. The company does not want the files to be accessible through direct navigation to the S3 URL. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Write individual policies for each S3 bucket to grant read permission for only CloudFront access.",
      "B": "Create an IAM user. Grant the user read permission to objects in the S3 bucket. Assign the user to CloudFront.",
      "C": "Write an S3 bucket policy that assigns the CloudFront distribution ID as the Principal and assigns the target S3 bucket as the Amazon Resource Name (ARN).",
      "D": "Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在开发一个文件共享应用程序，该应用程序将使用 Amazon S3 存储桶进行存储。该公司希望通过 Amazon CloudFront 分发来提供所有文件。该公司不希望通过直接导航到 S3 URL 来访问这些文件。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "为每个 S3 存储桶编写单独的策略，仅授予 CloudFront 访问权限的读取权限。",
      "B": "创建一个 IAM 用户。 授予该用户对 S3 存储桶中对象的读取权限。 将该用户分配给 CloudFront。",
      "C": "编写一个 S3 存储桶策略，将 CloudFront 分发 ID 分配为主体，并将目标 S3 存储桶分配为 Amazon 资源名称 (ARN)。",
      "D": "创建源访问身份 (OAI)。 将 OAI 分配给 CloudFront 分发。 配置 S3 存储桶权限，以便只有 OAI 具有读取权限。"
    }
  },
  {
    "id": 132,
    "topic": "1",
    "question_en": "A company’s website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company’s website demands globally. The solution should be cost-effective, limit the provisioning of infrastructure resources, and provide the fastest possible response time. Which combination should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Amazon CloudFront and Amazon S3",
      "B": "AWS Lambda and Amazon DynamoDB",
      "C": "Application Load Balancer with Amazon EC2 Auto Scaling",
      "D": "Amazon Route 53 with internal Application Load Balancers"
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一家公司的网站为用户提供可下载的历史性能报告。该网站需要一个解决方案，以扩展来满足公司网站的全球需求。该解决方案应具有成本效益，限制基础设施资源的配置，并提供最快的响应时间。解决方案架构师应该推荐哪种组合来满足这些要求？",
    "options_cn": {
      "A": "Amazon CloudFront 和 Amazon S3",
      "B": "AWS Lambda 和 Amazon DynamoDB",
      "C": "带有 Amazon EC2 Auto Scaling 的 Application Load Balancer",
      "D": "带有内部 Application Load Balancers 的 Amazon Route 53"
    }
  },
  {
    "id": 133,
    "topic": "1",
    "question_en": "A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region.",
      "B": "Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region.",
      "C": "Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.",
      "D": "Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone."
    },
    "correct_answer": "D",
    "vote_percentage": "49%",
    "question_cn": "一家公司在其本地运行 Oracle 数据库。作为公司迁移到 AWS 的一部分，该公司希望将数据库升级到最新的可用版本。该公司还希望为数据库设置灾难恢复 (DR)。该公司需要最大限度地减少正常运营和 DR 设置的运营开销。该公司还需要保持对数据库底层操作系统的访问。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 Oracle 数据库迁移到 Amazon EC2 实例。设置数据库复制到不同的 AWS 区域。",
      "B": "将 Oracle 数据库迁移到 Amazon RDS for Oracle。激活跨区域自动备份以将快照复制到另一个 AWS 区域。",
      "C": "将 Oracle 数据库迁移到 Amazon RDS Custom for Oracle。在另一个 AWS 区域中为数据库创建一个只读副本。",
      "D": "将 Oracle 数据库迁移到 Amazon RDS for Oracle。在另一个可用区中创建一个备用数据库。"
    }
  },
  {
    "id": 134,
    "topic": "1",
    "question_en": "A company wants to move its application to a serverless solution. The serverless solution needs to analyze existing and new data by using SL. The company stores the data in an Amazon S3 bucket. The data requires encryption and must be replicated to a different AWS Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region kays (SSE-KMS). Use Amazon Athena to query the data.",
      "B": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data.",
      "C": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon Athena to query the data.",
      "D": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon RDS to query the data."
    },
    "correct_answer": "A",
    "vote_percentage": "52%",
    "question_cn": "一家公司希望将其应用程序迁移到无服务器解决方案。该无服务器解决方案需要使用 SQL 分析现有和新数据。该公司将数据存储在 Amazon S3 存储桶中。数据需要加密，并且必须复制到不同的 AWS 区域。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域的 S3 存储桶。使用 AWS KMS 多区域密钥 (SSE-KMS) 进行服务器端加密。使用 Amazon Athena 查询数据。",
      "B": "创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域的 S3 存储桶。使用 AWS KMS 多区域密钥 (SSE-KMS) 进行服务器端加密。使用 Amazon RDS 查询数据。",
      "C": "将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域的 S3 存储桶。使用 Amazon S3 托管加密密钥 (SSE-S3) 进行服务器端加密。使用 Amazon Athena 查询数据。",
      "D": "将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域的 S3 存储桶。使用 Amazon S3 托管加密密钥 (SSE-S3) 进行服务器端加密。使用 Amazon RDS 查询数据。"
    }
  },
  {
    "id": 135,
    "topic": "1",
    "question_en": "A company runs workloads on AWS. The company needs to connect to a service from an external provider. The service is hosted in the provider's VPC. According to the company’s security team, the connectivity must be private and must be restricted to the target service. The connection must be initiated only from the company’s VPC. Which solution will mast these requirements?",
    "options_en": {
      "A": "Create a VPC peering connection between the company's VPC and the provider's VPC. Update the route table to connect to the target service.",
      "B": "Ask the provider to create a virtual private gateway in its VPC. Use AWS PrivateLink to connect to the target service.",
      "C": "Create a NAT gateway in a public subnet of the company’s VPUpdate the route table to connect to the target service.",
      "D": "Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行工作负载。该公司需要从外部提供商连接到一项服务。该服务托管在提供商的 VPC 中。根据公司的安全团队的要求，连接必须是私有的，并且必须限制为目标服务。连接必须仅从公司的 VPC 启动。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在公司 VPC 和提供商的 VPC 之间创建 VPC 对等连接。更新路由表以连接到目标服务。",
      "B": "要求提供商在其 VPC 中创建一个虚拟专用网关。使用 AWS PrivateLink 连接到目标服务。",
      "C": "在公司 VPC 的一个公共子网中创建 NAT 网关。更新路由表以连接到目标服务。",
      "D": "要求提供商为目标服务创建 VPC 终端节点。使用 AWS PrivateLink 连接到目标服务。"
    }
  },
  {
    "id": 136,
    "topic": "1",
    "question_en": "A company is migrating its on-premises PostgreSQL database to Amazon Aurora PostgreSQL. The on-premises database must remain online and accessible during the migration. The Aurora database must remain synchronized with the on-premises database. Which combination of actions must a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an ongoing replication task.",
      "B": "Create a database backup of the on-premises database.",
      "C": "Create an AWS Database Migration Service (AWS DMS) replication server.",
      "D": "Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT)",
      "E": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization."
    },
    "correct_answer": "C",
    "vote_percentage": "91%",
    "question_cn": "一家公司正在将其本地 PostgreSQL 数据库迁移到 Amazon Aurora PostgreSQL。在迁移期间，本地数据库必须保持在线状态并可访问。Aurora 数据库必须与本地数据库保持同步。解决方案架构师必须采取哪些组合操作来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "创建一个持续的复制任务。",
      "B": "创建本地数据库的数据库备份。",
      "C": "创建 AWS Database Migration Service (AWS DMS) 复制服务器。",
      "D": "使用 AWS Schema Conversion Tool (AWS SCT) 转换数据库模式。",
      "E": "创建 Amazon EventBridge (Amazon CloudWatch Events) 规则来监控数据库同步。"
    }
  },
  {
    "id": 137,
    "topic": "1",
    "question_en": "A company uses AWS Organizations to create dedicated AWS accounts for each business unit to manage each business unit's account independently upon request. The root email recipient missed a notification that was sent to the root user email address of one account. The company wants to ensure that all future notifications are not missed. Future notifications must be limited to account administrators. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the company’s email server to forward notification email messages that are sent to the AWS account root user email address to all users in the organization.",
      "B": "Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.",
      "C": "Configure all AWS account root user email messages to be sent to one administrator who is responsible for monitoring alerts and forwarding those alerts to the appropriate groups.",
      "D": "Configure all existing AWS accounts and all newly created accounts to use the same root user email address. Configure AWS account alternate contacts in the AWS Organizations console or programmatically."
    },
    "correct_answer": "D",
    "vote_percentage": "89%",
    "question_cn": "一家公司使用 AWS Organizations 为每个业务部门创建专用的 AWS 账户，以根据请求独立管理每个业务部门的账户。根电子邮件收件人错过了发送到其中一个账户的根用户电子邮件地址的通知。该公司希望确保将来不会错过所有通知。未来的通知必须仅限于账户管理员。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将公司的电子邮件服务器配置为将发送到 AWS 账户根用户电子邮件地址的通知电子邮件消息转发给组织中的所有用户。",
      "B": "将所有 AWS 账户根用户电子邮件地址配置为发送给可以响应警报的少数管理员的通讯组列表。在 AWS Organizations 控制台或通过编程方式配置 AWS 账户备用联系人。",
      "C": "配置所有 AWS 账户根用户电子邮件消息以发送给负责监控警报并将这些警报转发给相应组的一个管理员。",
      "D": "配置所有现有 AWS 账户和所有新创建的账户以使用相同的根用户电子邮件地址。在 AWS Organizations 控制台或通过编程方式配置 AWS 账户备用联系人。"
    }
  },
  {
    "id": 138,
    "topic": "1",
    "question_en": "A company runs its ecommerce application on AWS. Every new order is published as a massage in a RabbitMQ queue that runs on an Amazon EC2 instance in a single Availability Zone. These messages are processed by a different application that runs on a separate EC2 instance. This application stores the details in a PostgreSQL database on another EC2 instance. All the EC2 instances are in the same Availability Zone. The company needs to redesign its architecture to provide the highest availability with the least operational overhead. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Create another Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database.",
      "B": "Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.",
      "C": "Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.",
      "D": "Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Create a third Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行其电子商务应用程序。每个新订单都会作为消息发布到在单个可用区中的 Amazon EC2 实例上运行的 RabbitMQ 队列中。这些消息由在另一个 EC2 实例上运行的不同应用程序处理。此应用程序将详细信息存储在另一个 EC2 实例上的 PostgreSQL 数据库中。所有 EC2 实例都在同一可用区中。该公司需要重新设计其架构，以提供最高的可用性，同时将运营开销降至最低。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将队列迁移到 Amazon MQ 上的一对冗余（活动/备用）RabbitMQ 实例。为托管应用程序的 EC2 实例创建一个多可用区 Auto Scaling 组。为托管 PostgreSQL 数据库的 EC2 实例创建另一个多可用区 Auto Scaling 组。",
      "B": "将队列迁移到 Amazon MQ 上的一对冗余（活动/备用）RabbitMQ 实例。为托管应用程序的 EC2 实例创建一个多可用区 Auto Scaling 组。将数据库迁移到在 PostgreSQL 的 Amazon RDS 的多可用区部署上运行。",
      "C": "为托管 RabbitMQ 队列的 EC2 实例创建一个多可用区 Auto Scaling 组。为托管应用程序的 EC2 实例创建另一个多可用区 Auto Scaling 组。将数据库迁移到在 PostgreSQL 的 Amazon RDS 的多可用区部署上运行。",
      "D": "为托管 RabbitMQ 队列的 EC2 实例创建一个多可用区 Auto Scaling 组。为托管应用程序的 EC2 实例创建另一个多可用区 Auto Scaling 组。为托管 PostgreSQL 数据库的 EC2 实例创建第三个多可用区 Auto Scaling 组"
    }
  },
  {
    "id": 139,
    "topic": "1",
    "question_en": "A reporting team receives files each day in an Amazon S3 bucket. The reporting team manually reviews and copies the files from this initial S3 bucket to an analysis S3 bucket each day at the same time to use with Amazon QuickSight. Additional teams are starting to send more files in larger sizes to the initial S3 bucket. The reporting team wants to move the files automatically analysis S3 bucket as the files enter the initial S3 bucket. The reporting team also wants to use AWS Lambda functions to run pattern-matching code on the copied data. In addition, the reporting team wants to send the data files to a pipeline in Amazon SageMaker Pipelines. What should a solutions architect do to meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a Lambda function to copy the files to the analysis S3 bucket. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.",
      "B": "Create a Lambda function to copy the files to the analysis S3 bucket. Configure the analysis S3 bucket to send event notifications to Amazon EventBridge (Amazon CloudWatch Events). Configure an ObjectCreated rule in EventBridge (CloudWatch Events). Configure Lambda and SageMaker Pipelines as targets for the rule.",
      "C": "Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.",
      "D": "Configure S3 replication between the S3 buckets. Configure the analysis S3 bucket to send event notifications to Amazon EventBridge (Amazon CloudWatch Events). Configure an ObjectCreated rule in EventBridge (CloudWatch Events). Configure Lambda and SageMaker Pipelines as targets for the rule."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一个报告团队每天都会在一个 Amazon S3 存储桶中收到文件。报告团队每天都会在同一时间手动审查并将文件从这个初始 S3 存储桶复制到分析 S3 存储桶，以便与 Amazon QuickSight 一起使用。其他团队开始将更多更大体积的文件发送到初始 S3 存储桶。报告团队希望在文件进入初始 S3 存储桶时，自动将文件移动到分析 S3 存储桶。报告团队还希望使用 AWS Lambda 函数对复制的数据运行模式匹配代码。此外，报告团队希望将数据文件发送到 Amazon SageMaker Pipelines 中的管道。解决方案架构师应该怎么做，以最少的运营开销来满足这些要求？",
    "options_cn": {
      "A": "创建一个 Lambda 函数将文件复制到分析 S3 存储桶。为分析 S3 存储桶创建 S3 事件通知。将 Lambda 和 SageMaker Pipelines 配置为事件通知的目的地。将 s3:ObjectCreated:Put 配置为事件类型。",
      "B": "创建一个 Lambda 函数将文件复制到分析 S3 存储桶。将分析 S3 存储桶配置为将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatch Events) 中配置一个 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为该规则的目标。",
      "C": "在 S3 存储桶之间配置 S3 复制。为分析 S3 存储桶创建 S3 事件通知。将 Lambda 和 SageMaker Pipelines 配置为事件通知的目的地。将 s3:ObjectCreated:Put 配置为事件类型。",
      "D": "在 S3 存储桶之间配置 S3 复制。将分析 S3 存储桶配置为将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatch Events) 中配置一个 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为该规则的目标。"
    }
  },
  {
    "id": 140,
    "topic": "1",
    "question_en": "A solutions architect needs to help a company optimize the cost of running an application on AWS. The application will use Amazon EC2 instances, AWS Fargate, and AWS Lambda for compute within the architecture. The EC2 instances will run the data ingestion layer of the application. EC2 usage will be sporadic and unpredictable. Workloads that run on EC2 instances can be interrupted at any time. The application front end will run on Fargate, and Lambda will serve the API layer. The front-end utilization and API layer utilization will be predictable over the course of the next year. Which combination of purchasing options will provide the MOST cost-effective solution for hosting this application? (Choose two.)",
    "options_en": {
      "A": "Use Spot Instances for the data ingestion layer",
      "B": "Use On-Demand Instances for the data ingestion layer",
      "C": "Purchase a 1-year Compute Savings Plan for the front end and API layer.",
      "D": "Purchase 1-year All Upfront Reserved instances for the data ingestion layer",
      "E": "Purchase a 1-year EC2 instance Savings Plan for the front end and API layer."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要帮助一家公司优化在 AWS 上运行应用程序的成本。该应用程序将在其架构中使用 Amazon EC2 实例、AWS Fargate 和 AWS Lambda 进行计算。 EC2 实例将运行应用程序的数据摄取层。 EC2 的使用将是零星且不可预测的。在 EC2 实例上运行的工作负载可以随时中断。应用程序前端将在 Fargate 上运行，而 Lambda 将服务于 API 层。 在接下来的一年里，前端利用率和 API 层利用率将是可预测的。哪种购买选项的组合将为托管此应用程序提供最具成本效益的解决方案？（选择两个。）",
    "options_cn": {
      "A": "对数据摄取层使用 Spot 实例",
      "B": "对数据摄取层使用按需实例",
      "C": "为前端和 API 层购买 1 年期计算节省计划。",
      "D": "为数据摄取层购买 1 年期预留实例（全部预付）。",
      "E": "为前端和 API 层购买 1 年期 EC2 实例节省计划。"
    }
  },
  {
    "id": 141,
    "topic": "1",
    "question_en": "A company runs a web-based portal that provides users with global breaking news, local alerts, and weather updates. The portal delivers each user a personalized view by using mixture of static and dynamic content. Content is served over HTTPS through an API server running on an Amazon EC2 instance behind an Application Load Balancer (ALB). The company wants the portal to provide this content to its users across the world as quickly as possible. How should a solutions architect design the application to ensure the LEAST amount of latency for all users?",
    "options_en": {
      "A": "Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve all static and dynamic content by specifying the ALB as an origin.",
      "B": "Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.",
      "C": "Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve the static content. Serve the dynamic content directly from the ALB.",
      "D": "Deploy the application stack in two AWS Regions. Use an Amazon Route 53 geolocation routing policy to serve all content from the ALB in the closest Region."
    },
    "correct_answer": "B",
    "vote_percentage": "70%",
    "question_cn": "一家公司运营一个基于网络的门户网站，为用户提供全球突发新闻、本地警报和天气更新。该门户网站通过使用静态和动态内容的混合为每个用户提供个性化视图。内容通过 HTTPS 在运行在 Application Load Balancer (ALB) 后的 Amazon EC2 实例上的 API 服务器上提供。该公司希望该门户网站能够尽快向全球用户提供此内容。解决方案架构师应如何设计应用程序，以确保所有用户的延迟时间最短？",
    "options_cn": {
      "A": "将应用程序堆栈部署在单个 AWS 区域中。使用 Amazon CloudFront 通过指定 ALB 作为源来提供所有静态和动态内容。",
      "B": "将应用程序堆栈部署在两个 AWS 区域中。使用 Amazon Route 53 延迟路由策略从最近的区域中的 ALB 提供所有内容。",
      "C": "将应用程序堆栈部署在单个 AWS 区域中。使用 Amazon CloudFront 提供静态内容。直接从 ALB 提供动态内容。",
      "D": "将应用程序堆栈部署在两个 AWS 区域中。使用 Amazon Route 53 地理位置路由策略从最近的区域中的 ALB 提供所有内容。"
    }
  },
  {
    "id": 142,
    "topic": "1",
    "question_en": "A gaming company is designing a highly available architecture. The application runs on a modified Linux kernel and supports only UDP-based trafic. The company needs the front-end tier to provide the best possible user experience. That tier must have low latency, route trafic to the nearest edge location, and provide static IP addresses for entry into the application endpoints. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.",
      "B": "Configure Amazon CloudFront to forward requests to a Network Load Balancer. Use AWS Lambda for the application in an AWS Application Auto Scaling group.",
      "C": "Configure AWS Global Accelerator to forward requests to a Network Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.",
      "D": "Configure Amazon API Gateway to forward requests to an Application Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家游戏公司正在设计一个高可用性架构。该应用程序运行在经过修改的 Linux 内核上，并且仅支持基于 UDP 的流量。该公司需要前端层提供最佳的用户体验。该层必须具有低延迟，将流量路由到最近的边缘位置，并为进入应用程序终端节点的入口提供静态 IP 地址。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Route 53 以将请求转发到 Application Load Balancer。在 AWS Application Auto Scaling 中使用 AWS Lambda 作为应用程序。",
      "B": "配置 Amazon CloudFront 以将请求转发到 Network Load Balancer。在 AWS Application Auto Scaling 组中使用 AWS Lambda 作为应用程序。",
      "C": "配置 AWS Global Accelerator 以将请求转发到 Network Load Balancer。在 EC2 Auto Scaling 组中使用 Amazon EC2 实例作为应用程序。",
      "D": "配置 Amazon API Gateway 以将请求转发到 Application Load Balancer。在 EC2 Auto Scaling 组中使用 Amazon EC2 实例作为应用程序。"
    }
  },
  {
    "id": 143,
    "topic": "1",
    "question_en": "A company wants to migrate its existing on-premises monolithic application to AWS. The company wants to keep as much of the front-end code and the backend code as possible. However, the company wants to break the application into smaller applications. A different team will manage each application. The company needs a highly scalable solution that minimizes operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Host the application on AWS Lambda. Integrate the application with Amazon API Gateway.",
      "B": "Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda.",
      "C": "Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets.",
      "D": "Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target."
    },
    "correct_answer": "D",
    "vote_percentage": "74%",
    "question_cn": "一家公司希望将其现有的本地单体应用程序迁移到 AWS。该公司希望尽可能保留前端代码和后端代码。但是，该公司希望将应用程序分解成更小的应用程序。不同的团队将管理每个应用程序。该公司需要一个高度可扩展的解决方案，以最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Lambda 上托管应用程序。将应用程序与 Amazon API Gateway 集成。",
      "B": "使用 AWS Amplify 托管应用程序。将应用程序连接到与 AWS Lambda 集成的 Amazon API Gateway API。",
      "C": "在 Amazon EC2 实例上托管应用程序。设置一个 Application Load Balancer，并将 Auto Scaling 组中的 EC2 实例作为目标。",
      "D": "在 Amazon Elastic Container Service (Amazon ECS) 上托管应用程序。设置一个 Application Load Balancer，并将 Amazon ECS 作为目标。"
    }
  },
  {
    "id": 144,
    "topic": "1",
    "question_en": "A company recently started using Amazon Aurora as the data store for its global ecommerce application. When large reports are run, developers report that the ecommerce application is performing poorly. After reviewing metrics in Amazon CloudWatch, a solutions architect finds that the ReadIOPS and CPUUtilizalion metrics are spiking when monthly reports run. What is the MOST cost-effective solution?",
    "options_en": {
      "A": "Migrate the monthly reporting to Amazon Redshift.",
      "B": "Migrate the monthly reporting to an Aurora Replica.",
      "C": "Migrate the Aurora database to a larger instance class.",
      "D": "Increase the Provisioned IOPS on the Aurora instance."
    },
    "correct_answer": "B",
    "vote_percentage": "98%",
    "question_cn": "一家公司最近开始使用 Amazon Aurora 作为其全球电子商务应用程序的数据存储。 当运行大型报告时，开发人员报告说电子商务应用程序的性能很差。 在审查 Amazon CloudWatch 中的指标后，解决方案架构师发现，在每月报告运行时，ReadIOPS 和 CPUUtilizalion 指标会飙升。 哪种解决方案最具成本效益？",
    "options_cn": {
      "A": "将每月报告迁移到 Amazon Redshift。",
      "B": "将每月报告迁移到 Aurora 副本。",
      "C": "将 Aurora 数据库迁移到更大的实例类型。",
      "D": "增加 Aurora 实例上的预置 IOPS。"
    }
  },
  {
    "id": 145,
    "topic": "1",
    "question_en": "A company hosts a website analytics application on a single Amazon EC2 On-Demand Instance. The analytics software is written in PHP and uses a MySQL database. The analytics software, the web server that provides PHP, and the database server are all hosted on the EC2 instance. The application is showing signs of performance degradation during busy times and is presenting 5xx errors. The company needs to make the application scale seamlessly. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load to each EC2 instance.",
      "B": "Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances.",
      "C": "Migrate the database to an Amazon Aurora MySQL DB instance. Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization surpasses 75%.",
      "D": "Migrate the database to an Amazon Aurora MySQL DB instance. Create an AMI of the web application. Apply the AMI to a launch template. Create an Auto Scaling group with the launch template Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group."
    },
    "correct_answer": "D",
    "vote_percentage": "75%",
    "question_cn": "一家公司在单个 Amazon EC2 按需实例上托管一个网站分析应用程序。分析软件用 PHP 编写，并使用 MySQL 数据库。分析软件、提供 PHP 的 Web 服务器以及数据库服务器都托管在 EC2 实例上。该应用程序在繁忙时段表现出性能下降的迹象，并出现 5xx 错误。该公司需要使应用程序无缝扩展。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。使用该 AMI 启动第二个 EC2 按需实例。使用 Application Load Balancer 将负载分配到每个 EC2 实例。",
      "B": "将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。使用该 AMI 启动第二个 EC2 按需实例。使用 Amazon Route 53 加权路由将负载分配到两个 EC2 实例。",
      "C": "将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建一个 AWS Lambda 函数来停止 EC2 实例并更改实例类型。创建一个 Amazon CloudWatch 警报，以便在 CPU 利用率超过 75% 时调用 Lambda 函数。",
      "D": "将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建 Web 应用程序的 AMI。将 AMI 应用于启动模板。使用启动模板创建一个 Auto Scaling 组。配置启动模板以使用 Spot Fleet。将 Application Load Balancer 附加到 Auto Scaling 组。"
    }
  },
  {
    "id": 146,
    "topic": "1",
    "question_en": "A company runs a stateless web application in production on a group of Amazon EC2 On-Demand Instances behind an Application Load Balancer. The application experiences heavy usage during an 8-hour period each business day. Application usage is moderate and steady overnight. Application usage is low during weekends. The company wants to minimize its EC2 costs without affecting the availability of the application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Spot Instances for the entire workload.",
      "B": "Use Reserved Instances for the baseline level of usage. Use Spot instances for any additional capacity that the application needs.",
      "C": "Use On-Demand Instances for the baseline level of usage. Use Spot Instances for any additional capacity that the application needs.",
      "D": "Use Dedicated Instances for the baseline level of usage. Use On-Demand Instances for any additional capacity that the application needs."
    },
    "correct_answer": "B",
    "vote_percentage": "64%",
    "question_cn": "一家公司在 Application Load Balancer 后的一组 Amazon EC2 按需实例上运行生产中的无状态 Web 应用程序。该应用程序在每个工作日的 8 小时内经历高负载。应用程序在夜间的负载适中且稳定。应用程序在周末的负载较低。该公司希望在不影响应用程序可用性的情况下，最大限度地降低其 EC2 成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "对整个工作负载使用 Spot 实例。",
      "B": "对基线使用量使用预留实例。对应用程序需要的任何额外容量使用 Spot 实例。",
      "C": "对基线使用量使用按需实例。对应用程序需要的任何额外容量使用 Spot 实例。",
      "D": "对基线使用量使用专用实例。对应用程序需要的任何额外容量使用按需实例。"
    }
  },
  {
    "id": 147,
    "topic": "1",
    "question_en": "A company needs to retain application log files for a critical application for 10 years. The application team regularly accesses logs from the past month for troubleshooting, but logs older than 1 month are rarely accessed. The application generates more than 10 TB of logs per month. Which storage option meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store the logs in Amazon S3. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.",
      "B": "Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.",
      "C": "Store the logs in Amazon CloudWatch Logs. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.",
      "D": "Store the logs in Amazon CloudWatch Logs. Use Amazon S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要保留一个关键应用程序的应用程序日志文件 10 年。应用程序团队会定期访问上个月的日志以进行故障排除，但很少访问超过 1 个月的日志。该应用程序每月生成超过 10 TB 的日志。哪个存储选项最经济高效地满足这些要求？",
    "options_cn": {
      "A": "将日志存储在 Amazon S3 中。使用 AWS Backup 将超过 1 个月的日志移动到 S3 Glacier Deep Archive。",
      "B": "将日志存储在 Amazon S3 中。使用 S3 生命周期策略将超过 1 个月的日志移动到 S3 Glacier Deep Archive。",
      "C": "将日志存储在 Amazon CloudWatch Logs 中。使用 AWS Backup 将超过 1 个月的日志移动到 S3 Glacier Deep Archive。",
      "D": "将日志存储在 Amazon CloudWatch Logs 中。使用 Amazon S3 生命周期策略将超过 1 个月的日志移动到 S3 Glacier Deep Archive。"
    }
  },
  {
    "id": 148,
    "topic": "1",
    "question_en": "A company has a data ingestion workfiow that includes the following components: An Amazon Simple Notification Service (Amazon SNS) topic that receives notifications about new data deliveries An AWS Lambda function that processes and stores the data The ingestion workfiow occasionally fails because of network connectivity issues. When failure occurs, the corresponding data is not ingested unless the company manually reruns the job. What should a solutions architect do to ensure that all notifications are eventually processed?",
    "options_en": {
      "A": "Configure the Lambda function for deployment across multiple Availability Zones.",
      "B": "Modify the Lambda function's configuration to increase the CPU and memory allocations for the function.",
      "C": "Configure the SNS topic’s retry strategy to increase both the number of retries and the wait time between retries.",
      "D": "Configure an Amazon Simple Queue Service (Amazon SQS) queue as the on-failure destination. Modify the Lambda function to process messages in the queue."
    },
    "correct_answer": "D",
    "vote_percentage": "88%",
    "question_cn": "一家公司有一个数据摄取工作流程，其中包括以下组件：一个 Amazon Simple Notification Service (Amazon SNS) 主题，用于接收关于新数据交付的通知；一个 AWS Lambda 函数，用于处理和存储数据。摄取工作流程偶尔会因为网络连接问题而失败。当失败发生时，除非公司手动重新运行作业，否则相应的数据不会被摄取。解决方案架构师应该怎么做才能确保所有通知最终都被处理？",
    "options_cn": {
      "A": "为 Lambda 函数配置跨多个可用区的部署。",
      "B": "修改 Lambda 函数的配置以增加该函数的 CPU 和内存分配。",
      "C": "配置 SNS 主题的重试策略，以增加重试次数和重试之间的等待时间。",
      "D": "将一个 Amazon Simple Queue Service (Amazon SQS) 队列配置为失败目标。修改 Lambda 函数以处理队列中的消息。"
    }
  },
  {
    "id": 149,
    "topic": "1",
    "question_en": "A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing. The company wants to implement a solution that minimizes operational overhead. How should a solutions architect accomplish this?",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.",
      "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber.",
      "C": "Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently.",
      "D": "Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一项生成事件数据的服务。该公司希望使用 AWS 在接收到事件数据时对其进行处理。数据的写入顺序必须在整个处理过程中保持不变。该公司希望实施一个最大限度地减少运营开销的解决方案。解决方案架构师应如何实现此目的？",
    "options_cn": {
      "A": "创建一个 Amazon Simple Queue Service (Amazon SQS) FIFO 队列来保存消息。设置一个 AWS Lambda 函数来处理来自队列的消息。",
      "B": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，以传递包含要处理的有效载荷的通知。将一个 AWS Lambda 函数配置为订阅者。",
      "C": "创建一个 Amazon Simple Queue Service (Amazon SQS) 标准队列来保存消息。设置一个 AWS Lambda 函数来独立处理来自队列的消息。",
      "D": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，以传递包含要处理的有效载荷的通知。将一个 Amazon Simple Queue Service (Amazon SQS) 队列配置为订阅者。"
    }
  },
  {
    "id": 150,
    "topic": "1",
    "question_en": "A company is migrating an application from on-premises servers to Amazon EC2 instances. As part of the migration design requirements, a solutions architect must implement infrastructure metric alarms. The company does not need to take action if CPU utilization increases to more than 50% for a short burst of time. However, if the CPU utilization increases to more than 50% and read IOPS on the disk are high at the same time, the company needs to act as soon as possible. The solutions architect also must reduce false alarms. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create Amazon CloudWatch composite alarms where possible.",
      "B": "Create Amazon CloudWatch dashboards to visualize the metrics and react to issues quickly.",
      "C": "Create Amazon CloudWatch Synthetics canaries to monitor the application and raise an alarm.",
      "D": "Create single Amazon CloudWatch metric alarms with multiple metric thresholds where possible."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其应用程序从本地服务器迁移到 Amazon EC2 实例。作为迁移设计要求的一部分，解决方案架构师必须实施基础设施指标警报。如果 CPU 利用率在短时间内增加到 50% 以上，该公司不需要采取行动。但是，如果 CPU 利用率增加到 50% 以上，并且磁盘上的读取 IOPS 很高，则该公司需要尽快采取行动。解决方案架构师还必须减少误报。解决方案架构师应如何做才能满足这些要求？",
    "options_cn": {
      "A": "尽可能创建 Amazon CloudWatch 复合警报。",
      "B": "创建 Amazon CloudWatch 仪表板以可视化指标并快速响应问题。",
      "C": "创建 Amazon CloudWatch Synthetics canaries 来监控应用程序并发出警报。",
      "D": "尽可能创建具有多个指标阈值的单个 Amazon CloudWatch 指标警报。"
    }
  },
  {
    "id": 151,
    "topic": "1",
    "question_en": "A company wants to migrate its on-premises data center to AWS. According to the company's compliance requirements, the company can use only the ap-northeast-3 Region. Company administrators are not permitted to connect VPCs to the internet. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap- northeast-3.",
      "B": "Use rules in AWS WAF to prevent internet access. Deny access to all AWS Regions except ap-northeast-3 in the AWS account settings.",
      "C": "Use AWS Organizations to configure service control policies (SCPS) that prevent VPCs from gaining internet access. Deny access to all AWS Regions except ap-northeast-3.",
      "D": "Create an outbound rule for the network ACL in each VPC to deny all trafic from 0.0.0.0/0. Create an IAM policy for each user to prevent the use of any AWS Region other than ap-northeast-3",
      "E": "Use AWS Config to activate managed rules to detect and alert for internet gateways and to detect and alert for new resources deployed outside of ap-northeast-3."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司希望将其本地数据中心迁移到 AWS。根据公司的合规性要求，该公司只能使用 ap-northeast-3 区域。公司管理员不允许将 VPC 连接到互联网。哪些解决方案将满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "使用 AWS Control Tower 实施数据驻留防护栏，以拒绝互联网访问，并拒绝访问除 ap-northeast-3 之外的所有 AWS 区域。",
      "B": "使用 AWS WAF 中的规则来阻止互联网访问。在 AWS 账户设置中拒绝访问除 ap-northeast-3 之外的所有 AWS 区域。",
      "C": "使用 AWS Organizations 配置服务控制策略 (SCPS)，以防止 VPC 获得互联网访问权限。拒绝访问除 ap-northeast-3 之外的所有 AWS 区域。",
      "D": "为每个 VPC 中的网络 ACL 创建一个出站规则，以拒绝来自 0.0.0.0/0 的所有流量。为每个用户创建一个 IAM 策略，以防止使用 ap-northeast-3 之外的任何 AWS 区域。",
      "E": "使用 AWS Config 激活托管规则，以检测并警报互联网网关，并检测并警报在 ap-northeast-3 之外部署的新资源。"
    }
  },
  {
    "id": 152,
    "topic": "1",
    "question_en": "A company uses a three-tier web application to provide training to new employees. The application is accessed for only 12 hours every day. The company is using an Amazon RDS for MySQL DB instance to store information and wants to minimize costs. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Configure an IAM policy for AWS Systems Manager Session Manager. Create an IAM role for the policy. Update the trust relationship of the role. Set up automatic start and stop for the DB instance.",
      "B": "Create an Amazon ElastiCache for Redis cache cluster that gives users the ability to access the data from the cache when the DB instance is stopped. Invalidate the cache after the DB instance is started.",
      "C": "Launch an Amazon EC2 instance. Create an IAM role that grants access to Amazon RDS. Attach the role to the EC2 instance. Configure a cron job to start and stop the EC2 instance on the desired schedule.",
      "D": "Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules."
    },
    "correct_answer": "D",
    "vote_percentage": "80%",
    "question_cn": "一家公司使用三层 Web 应用程序为新员工提供培训。该应用程序每天仅访问 12 小时。该公司正在使用 Amazon RDS for MySQL DB 实例来存储信息，并希望最大限度地降低成本。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "为 AWS Systems Manager Session Manager 配置一个 IAM 策略。为该策略创建一个 IAM 角色。更新该角色的信任关系。设置 DB 实例的自动启动和停止。",
      "B": "创建一个 Amazon ElastiCache for Redis 缓存集群，使用户能够在 DB 实例停止时从缓存中访问数据。在 DB 实例启动后使缓存失效。",
      "C": "启动一个 Amazon EC2 实例。创建一个 IAM 角色，授予对 Amazon RDS 的访问权限。将该角色附加到 EC2 实例。配置一个 cron 作业，以在所需的时间表上启动和停止 EC2 实例。",
      "D": "创建 AWS Lambda 函数来启动和停止 DB 实例。创建 Amazon EventBridge (Amazon CloudWatch Events) 计划规则来调用 Lambda 函数。将 Lambda 函数配置为规则的事件目标。"
    }
  },
  {
    "id": 153,
    "topic": "1",
    "question_en": "A company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 128 KB in size. The company has millions of files, but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users. Which action should the company take to meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure S3 Standard-Infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects.",
      "B": "Move the files to S3 Intelligent-Tiering and configure it to move objects to a less expensive storage tier after 90 days.",
      "C": "Configure S3 inventory to manage objects and move them to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days.",
      "D": "Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days."
    },
    "correct_answer": "D",
    "vote_percentage": "64%",
    "question_cn": "一家公司销售由流行歌曲片段创建的铃声。包含铃声的文件存储在 Amazon S3 Standard 中，并且大小至少为 128 KB。该公司拥有数百万个文件，但 90 天以上的铃声下载频率较低。该公司需要在节省存储成本的同时，使其用户可以随时访问最常访问的文件。该公司应采取哪项措施以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "为对象的初始存储层配置 S3 Standard-Infrequent Access (S3 Standard-IA) 存储。",
      "B": "将文件移动到 S3 Intelligent-Tiering，并将其配置为在 90 天后将对象移动到更便宜的存储层。",
      "C": "配置 S3 inventory 来管理对象，并在 90 天后将它们移动到 S3 Standard-Infrequent Access (S3 Standard-1A)。",
      "D": "实施一个 S3 生命周期策略，该策略在 90 天后将对象从 S3 Standard 移动到 S3 Standard-Infrequent Access (S3 Standard-1A)。"
    }
  },
  {
    "id": 154,
    "topic": "1",
    "question_en": "A company needs to save the results from a medical trial to an Amazon S3 repository. The repository must allow a few scientists to add new files and must restrict all other users to read-only access. No users can have the ability to modify or delete any files in the repository. The company must keep every file in the repository for a minimum of 1 year after its creation date. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use S3 Object Lock in governance mode with a legal hold of 1 year.",
      "B": "Use S3 Object Lock in compliance mode with a retention period of 365 days.",
      "C": "Use an IAM role to restrict all users from deleting or changing objects in the S3 bucket. Use an S3 bucket policy to only allow the IAM role.",
      "D": "Configure the S3 bucket to invoke an AWS Lambda function every time an object is added. Configure the function to track the hash of the saved object so that modified objects can be marked accordingly."
    },
    "correct_answer": "B",
    "vote_percentage": "91%",
    "question_cn": "一家公司需要将医疗试验的结果保存到 Amazon S3 存储库中。该存储库必须允许少数科学家添加新文件，并且必须将所有其他用户的访问权限限制为只读。任何用户都不能修改或删除存储库中的任何文件。公司必须将存储库中的每个文件保留至少 1 年的创建日期。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 S3 Object Lock 的治理模式，保留期为 1 年。",
      "B": "使用 S3 Object Lock 的合规模式，保留期为 365 天。",
      "C": "使用 IAM 角色来限制所有用户删除或更改 S3 存储桶中的对象。使用 S3 存储桶策略仅允许 IAM 角色。",
      "D": "配置 S3 存储桶，以便每次添加对象时调用 AWS Lambda 函数。配置该函数以跟踪已保存对象的哈希值，以便可以相应地标记已修改的对象。"
    }
  },
  {
    "id": 155,
    "topic": "1",
    "question_en": "A large media company hosts a web application on AWS. The company wants to start caching confidential media files so that users around the world will have reliable access to the files. The content is stored in Amazon S3 buckets. The company must deliver the content quickly, regardless of where the requests originate geographically. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS DataSync to connect the S3 buckets to the web application.",
      "B": "Deploy AWS Global Accelerator to connect the S3 buckets to the web application.",
      "C": "Deploy Amazon CloudFront to connect the S3 buckets to CloudFront edge servers.",
      "D": "Use Amazon Simple Queue Service (Amazon SQS) to connect the S3 buckets to the web application."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家大型媒体公司在 AWS 上托管一个 Web 应用程序。该公司希望开始缓存机密的媒体文件，以便世界各地的用户能够可靠地访问这些文件。内容存储在 Amazon S3 存储桶中。无论请求来自何处，该公司都必须快速交付内容。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 将 S3 存储桶连接到 Web 应用程序。",
      "B": "部署 AWS Global Accelerator 将 S3 存储桶连接到 Web 应用程序。",
      "C": "部署 Amazon CloudFront 将 S3 存储桶连接到 CloudFront 边缘服务器。",
      "D": "使用 Amazon Simple Queue Service (Amazon SQS) 将 S3 存储桶连接到 Web 应用程序。"
    }
  },
  {
    "id": 156,
    "topic": "1",
    "question_en": "A company produces batch data that comes from different databases. The company also produces live stream data from network sensors and application APIs. The company needs to consolidate all the data into one place for business analytics. The company needs to process the incoming data and then stage the data in different Amazon S3 buckets. Teams will later run one-time queries and import the data into a business intelligence tool to show key performance indicators (KPIs). Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.",
      "B": "Use Amazon Kinesis Data Analytics for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.",
      "C": "Create custom AWS Lambda functions to move the individual records from the databases to an Amazon Redshift cluster.",
      "D": "Use an AWS Glue extract, transform, and load (ETL) job to convert the data into JSON format. Load the data into multiple Amazon OpenSearch Service (Amazon Elasticsearch Service) clusters",
      "E": "Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司生成来自不同数据库的批量数据。该公司还生成来自网络传感器和应用程序 API 的实时流数据。公司需要将所有数据整合到一个地方进行商业分析。公司需要处理传入的数据，然后将数据分阶段存储在不同的 Amazon S3 存储桶中。团队稍后将运行一次性查询，并将数据导入到商业智能工具中以显示关键绩效指标 (KPI)。哪种步骤组合将以最少的运营开销满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Amazon Athena 进行一次性查询。使用 Amazon QuickSight 创建 KPI 的仪表板。",
      "B": "使用 Amazon Kinesis Data Analytics 进行一次性查询。使用 Amazon QuickSight 创建 KPI 的仪表板。",
      "C": "创建自定义 AWS Lambda 函数以将单个记录从数据库移动到 Amazon Redshift 集群。",
      "D": "使用 AWS Glue extract, transform, and load (ETL) 作业将数据转换为 JSON 格式。将数据加载到多个 Amazon OpenSearch Service (Amazon Elasticsearch Service) 集群。",
      "E": "使用 AWS Lake Formation 中的蓝图来识别可以摄取到数据湖中的数据。使用 AWS Glue 爬取源，提取数据，并将数据以 Apache Parquet 格式加载到 Amazon S3 中。"
    }
  },
  {
    "id": 157,
    "topic": "1",
    "question_en": "A company stores data in an Amazon Aurora PostgreSQL DB cluster. The company must store all the data for 5 years and must delete all the data after 5 years. The company also must indefinitely keep audit logs of actions that are performed within the database. Currently, the company has automated backups configured for Aurora. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Take a manual snapshot of the DB cluster.",
      "B": "Create a lifecycle policy for the automated backups.",
      "C": "Configure automated backup retention for 5 years.",
      "D": "Configure an Amazon CloudWatch Logs export for the DB cluster",
      "E": "Use AWS Backup to take the backups and to keep the backups for 5 years."
    },
    "correct_answer": "B",
    "vote_percentage": "18%",
    "question_cn": "一家公司将数据存储在 Amazon Aurora PostgreSQL 数据库集群中。该公司必须将所有数据存储 5 年，并在 5 年后删除所有数据。该公司还必须无限期地保留数据库内执行操作的审计日志。目前，该公司已为 Aurora 配置了自动备份。解决方案架构师应采取哪些步骤组合来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "拍摄数据库集群的手动快照。",
      "B": "为自动备份创建生命周期策略。",
      "C": "配置自动备份保留 5 年。",
      "D": "为数据库集群配置 Amazon CloudWatch Logs 导出。",
      "E": "使用 AWS Backup 进行备份，并将备份保留 5 年。"
    }
  },
  {
    "id": 158,
    "topic": "1",
    "question_en": "A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience. Which service will improve the performance of both the real-time and on-demand streaming?",
    "options_en": {
      "A": "Amazon CloudFront",
      "B": "AWS Global Accelerator",
      "C": "Amazon Route 53",
      "D": "Amazon S3 Transfer Acceleration"
    },
    "correct_answer": "A",
    "vote_percentage": "66%",
    "question_cn": "一位解决方案架构师正在为即将到来的音乐活动优化一个网站。表演视频将进行实时流式传输，然后可供点播。预计此次活动将吸引全球在线观众。哪个服务将提高实时和点播流的性能？",
    "options_cn": {
      "A": "Amazon CloudFront",
      "B": "AWS Global Accelerator",
      "C": "Amazon Route 53",
      "D": "Amazon S3 Transfer Acceleration"
    }
  },
  {
    "id": 159,
    "topic": "1",
    "question_en": "A company is running a publicly accessible serverless application that uses Amazon API Gateway and AWS Lambda. The application’s trafic recently spiked due to fraudulent requests from botnets. Which steps should a solutions architect take to block requests from unauthorized users? (Choose two.)",
    "options_en": {
      "A": "Create a usage plan with an API key that is shared with genuine users only.",
      "B": "Integrate logic within the Lambda function to ignore the requests from fraudulent IP addresses.",
      "C": "Implement an AWS WAF rule to target malicious requests and trigger actions to filter them out.",
      "D": "Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint",
      "E": "Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call."
    },
    "correct_answer": "C",
    "vote_percentage": "67%",
    "question_cn": "一家公司正在运行一个使用 Amazon API Gateway 和 AWS Lambda 的公开可访问的无服务器应用程序。 由于来自僵尸网络的欺诈性请求，该应用程序的流量最近激增。 解决方案架构师应采取哪些步骤来阻止来自未经授权用户的请求？（选择两项。）",
    "options_cn": {
      "A": "创建一个带有 API 密钥的使用计划，该密钥仅与真实用户共享。",
      "B": "在 Lambda 函数中集成逻辑以忽略来自欺诈性 IP 地址的请求。",
      "C": "实施 AWS WAF 规则以定位恶意请求并触发操作以过滤它们。",
      "D": "将现有的公共 API 转换为私有 API。更新 DNS 记录以将用户重定向到新的 API 终端节点。",
      "E": "为每个尝试访问 API 的用户创建一个 IAM 角色。用户在进行 API 调用时将担任该角色。"
    }
  },
  {
    "id": 160,
    "topic": "1",
    "question_en": "An ecommerce company hosts its analytics application in the AWS Cloud. The application generates about 300 MB of data each month. The data is stored in JSON format. The company is evaluating a disaster recovery solution to back up the data. The data must be accessible in milliseconds if it is needed, and the data must be kept for 30 days. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "B": "Amazon S3 Glacier",
      "C": "Amazon S3 Standard",
      "D": "Amazon RDS for PostgreSQL"
    },
    "correct_answer": "C",
    "vote_percentage": "89%",
    "question_cn": "一家电子商务公司在 AWS 云中托管其分析应用程序。该应用程序每个月生成大约 300 MB 的数据。数据以 JSON 格式存储。该公司正在评估灾难恢复解决方案以备份数据。如果需要，必须在毫秒内访问数据，并且必须将数据保留 30 天。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "B": "Amazon S3 Glacier",
      "C": "Amazon S3 Standard",
      "D": "Amazon RDS for PostgreSQL"
    }
  },
  {
    "id": 161,
    "topic": "1",
    "question_en": "A company has a small Python application that processes JSON documents and outputs the results to an on-premises SQL database. The application runs thousands of times each day. The company wants to move the application to the AWS Cloud. The company needs a highly available solution that maximizes scalability and minimizes operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Place the JSON documents in an Amazon S3 bucket. Run the Python code on multiple Amazon EC2 instances to process the documents. Store the results in an Amazon Aurora DB cluster.",
      "B": "Place the JSON documents in an Amazon S3 bucket. Create an AWS Lambda function that runs the Python code to process the documents as they arrive in the S3 bucket. Store the results in an Amazon Aurora DB cluster.",
      "C": "Place the JSON documents in an Amazon Elastic Block Store (Amazon EBS) volume. Use the EBS Multi-Attach feature to attach the volume to multiple Amazon EC2 instances. Run the Python code on the EC2 instances to process the documents. Store the results on an Amazon RDS DB instance.",
      "D": "Place the JSON documents in an Amazon Simple Queue Service (Amazon SQS) queue as messages. Deploy the Python code as a container on an Amazon Elastic Container Service (Amazon ECS) cluster that is configured with the Amazon EC2 launch type. Use the container to process the SQS messages. Store the results on an Amazon RDS DB instance."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司有一个小型 Python 应用程序，该应用程序处理 JSON 文档并将结果输出到本地 SQL 数据库。该应用程序每天运行数千次。该公司希望将该应用程序迁移到 AWS 云。该公司需要一个高可用性解决方案，该解决方案可最大限度地提高可扩展性并最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 JSON 文档放置在 Amazon S3 存储桶中。在多个 Amazon EC2 实例上运行 Python 代码以处理文档。将结果存储在 Amazon Aurora 数据库集群中。",
      "B": "将 JSON 文档放置在 Amazon S3 存储桶中。创建一个 AWS Lambda 函数，该函数运行 Python 代码以在 JSON 文档到达 S3 存储桶时对其进行处理。将结果存储在 Amazon Aurora 数据库集群中。",
      "C": "将 JSON 文档放置在 Amazon Elastic Block Store (Amazon EBS) 卷中。使用 EBS 多重附加功能将卷附加到多个 Amazon EC2 实例。在 EC2 实例上运行 Python 代码以处理文档。将结果存储在 Amazon RDS 数据库实例上。",
      "D": "将 JSON 文档作为消息放置在 Amazon Simple Queue Service (Amazon SQS) 队列中。将 Python 代码作为容器部署在配置了 Amazon EC2 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群上。使用容器处理 SQS 消息。将结果存储在 Amazon RDS 数据库实例上。"
    }
  },
  {
    "id": 162,
    "topic": "1",
    "question_en": "A company wants to use high performance computing (HPC) infrastructure on AWS for financial risk modeling. The company’s HPC workloads run on Linux. Each HPC workfiow runs on hundreds of Amazon EC2 Spot Instances, is short-lived, and generates thousands of output files that are ultimately stored in persistent storage for analytics and long-term future use. The company seeks a cloud storage solution that permits the copying of on-premises data to long-term persistent storage to make data available for processing by all EC2 instances. The solution should also be a high performance file system that is integrated with persistent storage to read and write datasets and output files. Which combination of AWS services meets these requirements?",
    "options_en": {
      "A": "Amazon FSx for Lustre integrated with Amazon S3",
      "B": "Amazon FSx for Windows File Server integrated with Amazon S3",
      "C": "Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)",
      "D": "Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在 AWS 上使用高性能计算 (HPC) 基础设施进行金融风险建模。该公司的 HPC 工作负载运行在 Linux 上。每个 HPC 工作流程都在数百个 Amazon EC2 Spot 实例上运行，生命周期很短，并生成数千个输出文件，这些文件最终存储在持久性存储中，用于分析和长期未来使用。该公司寻求一种云存储解决方案，该解决方案允许将本地数据复制到长期持久性存储中，以便所有 EC2 实例都可以处理数据。该解决方案还应该是一个高性能文件系统，该文件系统与持久性存储集成，用于读取和写入数据集和输出文件。哪种 AWS 服务组合符合这些要求？",
    "options_cn": {
      "A": "Amazon FSx for Lustre 与 Amazon S3 集成",
      "B": "Amazon FSx for Windows File Server 与 Amazon S3 集成",
      "C": "Amazon S3 Glacier 与 Amazon Elastic Block Store (Amazon EBS) 集成",
      "D": "带有 VPC endpoint 的 Amazon S3 存储桶与 Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) 卷集成"
    }
  },
  {
    "id": 163,
    "topic": "1",
    "question_en": "A company is building a containerized application on premises and decides to move the application to AWS. The application will have thousands of users soon after it is deployed. The company is unsure how to manage the deployment of containers at scale. The company needs to deploy the containerized application in a highly available architecture that minimizes operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service (Amazon ECS) cluster with the AWS Fargate launch type to run the containers. Use target tracking to scale automatically based on demand.",
      "B": "Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service (Amazon ECS) cluster with the Amazon EC2 launch type to run the containers. Use target tracking to scale automatically based on demand.",
      "C": "Store container images in a repository that runs on an Amazon EC2 instance. Run the containers on EC2 instances that are spread across multiple Availability Zones. Monitor the average CPU utilization in Amazon CloudWatch. Launch new EC2 instances as needed.",
      "D": "Create an Amazon EC2 Amazon Machine Image (AMI) that contains the container image. Launch EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon CloudWatch alarm to scale out EC2 instances when the average CPU utilization threshold is breached."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在本地构建一个容器化应用程序，并决定将该应用程序迁移到 AWS。该应用程序在部署后不久将拥有数千名用户。该公司不确定如何大规模管理容器的部署。该公司需要在高可用性架构中部署容器化应用程序，以最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将容器镜像存储在 Amazon Elastic Container Registry (Amazon ECR) 存储库中。使用带有 AWS Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群来运行容器。使用目标跟踪根据需求自动扩展。",
      "B": "将容器镜像存储在 Amazon Elastic Container Registry (Amazon ECR) 存储库中。使用带有 Amazon EC2 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群来运行容器。使用目标跟踪根据需求自动扩展。",
      "C": "将容器镜像存储在运行于 Amazon EC2 实例上的存储库中。在分布于多个可用区的 EC2 实例上运行容器。在 Amazon CloudWatch 中监控平均 CPU 利用率。根据需要启动新的 EC2 实例。",
      "D": "创建一个包含容器镜像的 Amazon EC2 Amazon Machine Image (AMI)。在跨多个可用区的 Auto Scaling 组中启动 EC2 实例。使用 Amazon CloudWatch 警报在超过平均 CPU 利用率阈值时扩展 EC2 实例。"
    }
  },
  {
    "id": 164,
    "topic": "1",
    "question_en": "A company has two applications: a sender application that sends messages with payloads to be processed and a processing application intended to receive the messages with payloads. The company wants to implement an AWS service to handle messages between the two applications. The sender application can send about 1,000 messages each hour. The messages may take up to 2 days to be processed: If the messages fail to process, they must be retained so that they do not impact the processing of any remaining messages. Which solution meets these requirements and is the MOST operationally eficient?",
    "options_en": {
      "A": "Set up an Amazon EC2 instance running a Redis database. Configure both applications to use the instance. Store, process, and delete the messages, respectively.",
      "B": "Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the Kinesis Client Library (KCL).",
      "C": "Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead-letter queue to collect the messages that failed to process.",
      "D": "Subscribe the processing application to an Amazon Simple Notification Service (Amazon SNS) topic to receive notifications to process. Integrate the sender application to write to the SNS topic. С"
    },
    "correct_answer": "C",
    "vote_percentage": "90%",
    "question_cn": "一家公司有两个应用程序：一个发送应用程序，用于发送包含待处理负载的消息；一个处理应用程序，用于接收带有负载的消息。该公司希望实施一个 AWS 服务来处理这两个应用程序之间的消息。发送应用程序每小时可以发送大约 1,000 条消息。消息可能需要长达 2 天的时间来处理：如果消息处理失败，则必须保留它们，以免影响剩余消息的处理。哪种解决方案满足这些要求并且在运营上最有效？",
    "options_cn": {
      "A": "设置一个运行 Redis 数据库的 Amazon EC2 实例。将两个应用程序配置为使用该实例。分别存储、处理和删除消息。",
      "B": "使用 Amazon Kinesis 数据流接收来自发送应用程序的消息。将处理应用程序与 Kinesis Client Library (KCL) 集成。",
      "C": "将发送和处理应用程序与 Amazon Simple Queue Service (Amazon SQS) 队列集成。配置一个死信队列来收集处理失败的消息。",
      "D": "将处理应用程序订阅到 Amazon Simple Notification Service (Amazon SNS) 主题，以接收要处理的通知。将发送应用程序集成到 SNS 主题中进行写入。"
    }
  },
  {
    "id": 165,
    "topic": "1",
    "question_en": "A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company’s security policy requires that all website trafic be inspected by AWS WAF. How should the solutions architect comply with these requirements?",
    "options_en": {
      "A": "Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.",
      "B": "Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.",
      "C": "Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.",
      "D": "Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution."
    },
    "correct_answer": "D",
    "vote_percentage": "58%",
    "question_cn": "一个解决方案架构师必须设计一个使用 Amazon CloudFront 和 Amazon S3 源来存储静态网站的解决方案。该公司的安全策略要求所有网站流量都必须由 AWS WAF 检查。解决方案架构师应如何符合这些要求？",
    "options_cn": {
      "A": "配置 S3 存储桶策略，仅接受来自 AWS WAF Amazon 资源名称 (ARN) 的请求。",
      "B": "配置 Amazon CloudFront 在从 S3 源请求内容之前将所有传入请求转发到 AWS WAF。",
      "C": "配置一个安全组，允许 Amazon CloudFront IP 地址仅访问 Amazon S3。将 AWS WAF 与 CloudFront 关联。",
      "D": "配置 Amazon CloudFront 和 Amazon S3 使用源访问身份 (OAI) 来限制对 S3 存储桶的访问。在分发上打开 AWS WAF。"
    }
  },
  {
    "id": 166,
    "topic": "1",
    "question_en": "Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an eficient and effective solution. Which action should the solutions architect take to accomplish this?",
    "options_en": {
      "A": "Generate presigned URLs for the files.",
      "B": "Use cross-Region replication to all Regions.",
      "C": "Use the geoproximity feature of Amazon Route 53.",
      "D": "Use Amazon CloudFront with the S3 bucket as its origin."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "全球活动的组织者希望将每日报告作为静态 HTML 页面发布到线上。预计这些页面将从世界各地的用户那里获得数百万次浏览量。这些文件存储在 Amazon S3 存储桶中。一位解决方案架构师被要求设计一个高效且有效的解决方案。解决方案架构师应采取以下哪项措施来完成此任务？",
    "options_cn": {
      "A": "为文件生成预签名 URL。",
      "B": "使用 跨区域复制 到所有区域。",
      "C": "使用 Amazon Route 53 的地理位置临近功能。",
      "D": "将 Amazon CloudFront 与 S3 存储桶用作其源。"
    }
  },
  {
    "id": 167,
    "topic": "1",
    "question_en": "A company runs a production application on a fieet of Amazon EC2 instances. The application reads the data from an Amazon SQS queue and processes the messages in parallel. The message volume is unpredictable and often has intermittent trafic. This application should continually process messages without any downtime. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use Spot Instances exclusively to handle the maximum capacity required.",
      "B": "Use Reserved Instances exclusively to handle the maximum capacity required.",
      "C": "Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity.",
      "D": "Use Reserved Instances for the baseline capacity and use On-Demand Instances to handle additional capacity."
    },
    "correct_answer": "C",
    "vote_percentage": "53%",
    "question_cn": "一家公司在 Amazon EC2 实例集群上运行生产应用程序。该应用程序从 Amazon SQS 队列读取数据并并行处理消息。消息量不可预测，并且经常出现间歇性流量。此应用程序应持续处理消息，且没有任何停机时间。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "完全使用 Spot 实例来处理所需的最大容量。",
      "B": "完全使用预留实例来处理所需的最大容量。",
      "C": "使用预留实例处理基线容量，并使用 Spot 实例处理额外的容量。",
      "D": "使用预留实例处理基线容量，并使用按需实例处理额外的容量。"
    }
  },
  {
    "id": 168,
    "topic": "1",
    "question_en": "A security team wants to limit access to specific services or actions in all of the team’s AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?",
    "options_en": {
      "A": "Create an ACL to provide access to the services or actions.",
      "B": "Create a security group to allow accounts and attach it to user groups.",
      "C": "Create cross-account roles in each account to deny access to the services or actions.",
      "D": "Create a service control policy in the root organizational unit to deny access to the services or actions."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "安全团队希望限制其所有 AWS 账户中对特定服务或操作的访问。所有账户都属于 AWS Organizations 中的一个大型组织。解决方案必须具有可扩展性，并且必须有一个可以维护权限的单点。解决方案架构师应该怎么做才能实现此目的？",
    "options_cn": {
      "A": "创建 ACL 以提供对服务或操作的访问权限。",
      "B": "创建安全组以允许账户并将其附加到用户组。",
      "C": "在每个账户中创建跨账户角色以拒绝访问服务或操作。",
      "D": "在根组织单元中创建服务控制策略以拒绝访问服务或操作。"
    }
  },
  {
    "id": 169,
    "topic": "1",
    "question_en": "A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load Balancer (ALB). A solutions architect must reduce the risk of DDoS attacks against the application. What should the solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Add an Amazon Inspector agent to the ALB.",
      "B": "Configure Amazon Macie to prevent attacks.",
      "C": "Enable AWS Shield Advanced to prevent attacks.",
      "D": "Configure Amazon GuardDuty to monitor the ALB."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司担心其公共 Web 应用程序的安全，因为最近发生了网络攻击。该应用程序使用一个 Application Load Balancer (ALB)。一位解决方案架构师必须降低针对该应用程序的 DDoS 攻击风险。 解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "将 Amazon Inspector agent 添加到 ALB。",
      "B": "配置 Amazon Macie 以防止攻击。",
      "C": "启用 AWS Shield Advanced 以防止攻击。",
      "D": "配置 Amazon GuardDuty 来监控 ALB。"
    }
  },
  {
    "id": 170,
    "topic": "1",
    "question_en": "A company’s web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only. Which configuration will meet this requirement?",
    "options_en": {
      "A": "Configure the security group for the EC2 instances.",
      "B": "Configure the security group on the Application Load Balancer.",
      "C": "Configure AWS WAF on the Application Load Balancer in a VPC.",
      "D": "Configure the network ACL for the subnet that contains the EC2 instances."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的 Web 应用程序正在 Application Load Balancer 后面的 Amazon EC2 实例上运行。该公司最近更改了其策略，现在要求仅从一个特定国家/地区访问该应用程序。哪种配置将满足此要求？",
    "options_cn": {
      "A": "配置 EC2 实例的安全组。",
      "B": "在 Application Load Balancer 上配置安全组。",
      "C": "在 VPC 中的 Application Load Balancer 上配置 AWS WAF。",
      "D": "配置包含 EC2 实例的子网的网络 ACL。"
    }
  },
  {
    "id": 171,
    "topic": "1",
    "question_en": "A company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a larger number of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is scalable and elastic. What should the solutions architect do to accomplish this?",
    "options_en": {
      "A": "Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made.",
      "B": "Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations.",
      "C": "Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names.",
      "D": "Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and passes the item names to the EC2 instance for tax computations."
    },
    "correct_answer": "D",
    "vote_percentage": "96%",
    "question_cn": "一家公司为其用户提供一个 API，该 API 基于商品价格自动计算税务查询。该公司仅在假日季期间经历了大量查询，导致响应时间变慢。一位解决方案架构师需要设计一个可扩展且弹性的解决方案。该解决方案架构师应该怎么做才能实现此目标？",
    "options_cn": {
      "A": "提供一个托管在 Amazon EC2 实例上的 API。当发出 API 请求时，EC2 实例执行所需的计算。",
      "B": "使用 Amazon API Gateway 设计一个 REST API，该 API 接受商品名称。API Gateway 将商品名称传递给 AWS Lambda 进行税务计算。",
      "C": "创建一个 Application Load Balancer，其后有两个 Amazon EC2 实例。EC2 实例将计算收到的商品名称的税款。",
      "D": "使用 Amazon API Gateway 设计一个 REST API，该 API 连接到托管在 Amazon EC2 实例上的 API。API Gateway 接受并将商品名称传递给 EC2 实例进行税务计算。"
    }
  },
  {
    "id": 172,
    "topic": "1",
    "question_en": "A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should.be protected throughout the entire application stack, and access to the information should be restricted to certain applications. Which action should the solutions architect take?",
    "options_en": {
      "A": "Configure a CloudFront signed URL.",
      "B": "Configure a CloudFront signed cookie.",
      "C": "Configure a CloudFront field-level encryption profile.",
      "D": "Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy."
    },
    "correct_answer": "A",
    "vote_percentage": "77%",
    "question_cn": "一位解决方案架构师正在为应用程序创建新的 Amazon CloudFront 分发。用户提交的一些信息是敏感的。该应用程序使用 HTTPS，但需要另一层安全性。 整个应用程序堆栈都应保护敏感信息，并且应限制对信息的访问，仅限某些应用程序。 解决方案架构师应采取哪项措施？",
    "options_cn": {
      "A": "配置 CloudFront 签名 URL。",
      "B": "配置 CloudFront 签名 cookie。",
      "C": "配置 CloudFront 字段级加密配置文件。",
      "D": "配置 CloudFront，并将源协议策略设置设置为“仅 HTTPS”以实现查看器协议策略。"
    }
  },
  {
    "id": 173,
    "topic": "1",
    "question_en": "A gaming company hosts a browser-based application on AWS. The users of the application consume a large number of videos and images that are stored in Amazon S3. This content is the same for all users. The application has increased in popularity, and millions of users worldwide accessing these media files. The company wants to provide the files to the users while reducing the load on the origin. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Deploy an AWS Global Accelerator accelerator in front of the web servers.",
      "B": "Deploy an Amazon CloudFront web distribution in front of the S3 bucket.",
      "C": "Deploy an Amazon ElastiCache for Redis instance in front of the web servers.",
      "D": "Deploy an Amazon ElastiCache for Memcached instance in front of the web servers."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家游戏公司在 AWS 上托管一个基于浏览器的应用程序。应用程序的用户会消耗大量存储在 Amazon S3 中的视频和图像。这些内容对所有用户都是相同的。该应用程序越来越受欢迎，全球有数百万用户访问这些媒体文件。该公司希望向用户提供文件，同时减少源的负载。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "在 Web 服务器前面部署一个 AWS Global Accelerator 加速器。",
      "B": "在 S3 存储桶前面部署一个 Amazon CloudFront Web 分发。",
      "C": "在 Web 服务器前面部署一个 Amazon ElastiCache for Redis 实例。",
      "D": "在 Web 服务器前面部署一个 Amazon ElastiCache for Memcached 实例。"
    }
  },
  {
    "id": 174,
    "topic": "1",
    "question_en": "A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application. Which architecture should the solutions architect choose that provides high availability?",
    "options_en": {
      "A": "Create an Auto Scaling group that uses three instances across each of two Regions.",
      "B": "Modify the Auto Scaling group to use three instances across each of two Availability Zones.",
      "C": "Create an Auto Scaling template that can be used to quickly create more instances in another Region.",
      "D": "Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance trafic to the web tier."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个多层应用程序，该应用程序在单个可用区中的 Amazon EC2 Auto Scaling 组中运行六个前端 Web 服务器，这些服务器位于 Application Load Balancer (ALB) 之后。解决方案架构师需要修改基础设施以实现高可用性，而无需修改应用程序。解决方案架构师应该选择哪种架构来提供高可用性？",
    "options_cn": {
      "A": "创建一个 Auto Scaling 组，该组在两个区域中的每个区域使用三个实例。",
      "B": "修改 Auto Scaling 组以使用在两个可用区中的每个可用区中使用三个实例。",
      "C": "创建一个 Auto Scaling 模板，该模板可用于在另一个区域中快速创建更多实例。",
      "D": "将 Amazon EC2 实例前面的 ALB 更改为循环配置，以平衡 Web 层流量。"
    }
  },
  {
    "id": 175,
    "topic": "1",
    "question_en": "An ecommerce company has an order-processing application that uses Amazon API Gateway and an AWS Lambda function. The application stores data in an Amazon Aurora PostgreSQL database. During a recent sales event, a sudden surge in customer orders occurred. Some customers experienced timeouts, and the application did not process the orders of those customers. A solutions architect determined that the CPU utilization and memory utilization were high on the database because of a large number of open connections. The solutions architect needs to prevent the timeout errors while making the least possible changes to the application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure provisioned concurrency for the Lambda function. Modify the database to be a global database in multiple AWS Regions.",
      "B": "Use Amazon RDS Proxy to create a proxy for the database. Modify the Lambda function to use the RDS Proxy endpoint instead of the database endpoint.",
      "C": "Create a read replica for the database in a different AWS Region. Use query string parameters in API Gateway to route trafic to the read replica.",
      "D": "Migrate the data from Aurora PostgreSQL to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS). Modify the Lambda function to use the DynamoDB table."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司有一个订单处理应用程序，该应用程序使用 Amazon API Gateway 和一个 AWS Lambda 函数。该应用程序将数据存储在 Amazon Aurora PostgreSQL 数据库中。在最近的一次促销活动中，客户订单突然激增。一些客户遇到了超时，并且该应用程序没有处理这些客户的订单。一位解决方案架构师确定，由于大量打开的连接，数据库的 CPU 利用率和内存利用率很高。解决方案架构师需要防止超时错误，同时对应用程序进行尽可能少的更改。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Lambda 函数配置预置并发。将数据库修改为多个 AWS 区域中的全局数据库。",
      "B": "使用 Amazon RDS Proxy 为数据库创建代理。修改 Lambda 函数以使用 RDS Proxy 终端节点而不是数据库终端节点。",
      "C": "在不同的 AWS 区域中为数据库创建一个只读副本。使用 API Gateway 中的查询字符串参数将流量路由到只读副本。",
      "D": "使用 AWS Database Migration Service (AWS DMS) 将数据从 Aurora PostgreSQL 迁移到 Amazon DynamoDB。修改 Lambda 函数以使用 DynamoDB 表。"
    }
  },
  {
    "id": 176,
    "topic": "1",
    "question_en": "An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the trafic does not leave the AWS network?",
    "options_en": {
      "A": "Use a VPC endpoint for DynamoDB.",
      "B": "Use a NAT gateway in a public subnet.",
      "C": "Use a NAT instance in a private subnet.",
      "D": "Use the internet gateway attached to the VPC."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一个应用程序在私有子网中的 Amazon EC2 实例上运行。该应用程序需要访问 Amazon DynamoDB 表。在确保流量不会离开 AWS 网络的情况下，访问该表的最安全方式是什么？",
    "options_cn": {
      "A": "为 DynamoDB 使用 VPC endpoint。",
      "B": "在公有子网中使用 NAT gateway。",
      "C": "在私有子网中使用 NAT 实例。",
      "D": "使用连接到 VPC 的 internet gateway。"
    }
  },
  {
    "id": 177,
    "topic": "1",
    "question_en": "An entertainment company is using Amazon DynamoDB to store media metadata. The application is read intensive and experiencing delays. The company does not have staff to handle additional operational overhead and needs to improve the performance eficiency of DynamoDB without reconfiguring the application. What should a solutions architect recommend to meet this requirement?",
    "options_en": {
      "A": "Use Amazon ElastiCache for Redis.",
      "B": "Use Amazon DynamoDB Accelerator (DAX).",
      "C": "Replicate data by using DynamoDB global tables.",
      "D": "Use Amazon ElastiCache for Memcached with Auto Discovery enabled."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家娱乐公司正在使用 Amazon DynamoDB 存储媒体元数据。该应用程序是读取密集型的，并且遇到了延迟。该公司没有人员来处理额外的运营开销，并且需要提高 DynamoDB 的性能效率，而无需重新配置应用程序。解决方案架构师应该推荐什么来满足此要求？",
    "options_cn": {
      "A": "使用 Amazon ElastiCache for Redis。",
      "B": "使用 Amazon DynamoDB Accelerator (DAX)。",
      "C": "使用 DynamoDB 全局表复制数据。",
      "D": "使用启用了自动发现的 Amazon ElastiCache for Memcached。"
    }
  },
  {
    "id": 178,
    "topic": "1",
    "question_en": "A company’s infrastructure consists of Amazon EC2 instances and an Amazon RDS DB instance in a single AWS Region. The company wants to back up its data in a separate Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Backup to copy EC2 backups and RDS backups to the separate Region.",
      "B": "Use Amazon Data Lifecycle Manager (Amazon DLM) to copy EC2 backups and RDS backups to the separate Region.",
      "C": "Create Amazon Machine Images (AMIs) of the EC2 instances. Copy the AMIs to the separate Region. Create a read replica for the RDS DB instance in the separate Region.",
      "D": "Create Amazon Elastic Block Store (Amazon EBS) snapshots. Copy the EBS snapshots to the separate Region. Create RDS snapshots. Export the RDS snapshots to Amazon S3. Configure S3 Cross-Region Replication (CRR) to the separate Region."
    },
    "correct_answer": "A",
    "vote_percentage": "97%",
    "question_cn": "一家公司的基础设施包括单个 AWS 区域中的 Amazon EC2 实例和 Amazon RDS 数据库实例。该公司希望将其数据备份到另一个区域。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Backup 将 EC2 备份和 RDS 备份复制到单独的区域。",
      "B": "使用 Amazon Data Lifecycle Manager (Amazon DLM) 将 EC2 备份和 RDS 备份复制到单独的区域。",
      "C": "创建 EC2 实例的 Amazon Machine Images (AMI)。将 AMI 复制到单独的区域。在单独的区域中为 RDS 数据库实例创建只读副本。",
      "D": "创建 Amazon Elastic Block Store (Amazon EBS) 快照。将 EBS 快照复制到单独的区域。创建 RDS 快照。将 RDS 快照导出到 Amazon S3。配置 S3 跨区域复制 (CRR) 到单独的区域。"
    }
  },
  {
    "id": 179,
    "topic": "1",
    "question_en": "A solutions architect needs to securely store a database user name and password that an application uses to access an Amazon RDS DB instance. The application that accesses the database runs on an Amazon EC2 instance. The solutions architect wants to create a secure parameter in AWS Systems Manager Parameter Store. What should the solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Create an IAM role that has read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM role to the EC2 instance.",
      "B": "Create an IAM policy that allows read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM policy to the EC2 instance.",
      "C": "Create an IAM trust relationship between the Parameter Store parameter and the EC2 instance. Specify Amazon RDS as a principal in the trust policy.",
      "D": "Create an IAM trust relationship between the DB instance and the EC2 instance. Specify Systems Manager as a principal in the trust policy."
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一名解决方案架构师需要安全地存储一个应用程序用来访问 Amazon RDS 数据库实例的数据库用户名和密码。访问数据库的应用程序在 Amazon EC2 实例上运行。解决方案架构师希望在 AWS Systems Manager Parameter Store 中创建一个安全参数。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "创建一个 IAM 角色，该角色具有对 Parameter Store 参数的读取权限。允许解密访问用于加密该参数的 AWS Key Management Service (AWS KMS) 密钥。将此 IAM 角色分配给 EC2 实例。",
      "B": "创建一个 IAM 策略，该策略允许对 Parameter Store 参数的读取权限。允许解密访问用于加密该参数的 AWS Key Management Service (AWS KMS) 密钥。将此 IAM 策略分配给 EC2 实例。",
      "C": "在 Parameter Store 参数和 EC2 实例之间创建 IAM 信任关系。在信任策略中指定 Amazon RDS 作为委托人。",
      "D": "在数据库实例和 EC2 实例之间创建 IAM 信任关系。在信任策略中指定 Systems Manager 作为委托人。"
    }
  },
  {
    "id": 180,
    "topic": "1",
    "question_en": "A company is designing a cloud communications platform that is driven by APIs. The application is hosted on Amazon EC2 instances behind a Network Load Balancer (NLB). The company uses Amazon API Gateway to provide external users with access to the application through APIs. The company wants to protect the platform against web exploits like SQL injection and also wants to detect and mitigate large, sophisticated DDoS attacks. Which combination of solutions provides the MOST protection? (Choose two.)",
    "options_en": {
      "A": "Use AWS WAF to protect the NLB.",
      "B": "Use AWS Shield Advanced with the NLB.",
      "C": "Use AWS WAF to protect Amazon API Gateway.",
      "D": "Use Amazon GuardDuty with AWS Shield Standard",
      "E": "Use AWS Shield Standard with Amazon API Gateway."
    },
    "correct_answer": "B",
    "vote_percentage": "93%",
    "question_cn": "一家公司正在设计一个由 API 驱动的云通信平台。该应用程序托管在 Network Load Balancer (NLB) 后面的 Amazon EC2 实例上。该公司使用 Amazon API Gateway 通过 API 为外部用户提供对应用程序的访问。该公司希望保护平台免受 SQL 注入等 Web 攻击，并检测和缓解大型、复杂的 DDoS 攻击。哪种解决方案组合提供了最大的保护？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS WAF 保护 NLB。",
      "B": "将 AWS Shield Advanced 与 NLB 一起使用。",
      "C": "使用 AWS WAF 保护 Amazon API Gateway。",
      "D": "将 Amazon GuardDuty 与 AWS Shield Standard 一起使用。",
      "E": "将 AWS Shield Standard 与 Amazon API Gateway 一起使用。"
    }
  },
  {
    "id": 181,
    "topic": "1",
    "question_en": "A company has a legacy data processing application that runs on Amazon EC2 instances. Data is processed sequentially, but the order of results does not matter. The application uses a monolithic architecture. The only way that the company can scale the application to meet increased demand is to increase the size of the instances. The company’s developers have decided to rewrite the application to use a microservices architecture on Amazon Elastic Container Service (Amazon ECS). What should a solutions architect recommend for communication between the microservices?",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.",
      "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Add code to the data producers, and publish notifications to the topic. Add code to the data consumers to subscribe to the topic.",
      "C": "Create an AWS Lambda function to pass messages. Add code to the data producers to call the Lambda function with a data object. Add code to the data consumers to receive a data object that is passed from the Lambda function.",
      "D": "Create an Amazon DynamoDB table. Enable DynamoDB Streams. Add code to the data producers to insert data into the table. Add code to the data consumers to use the DynamoDB Streams API to detect new table entries and retrieve the data."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司有一个在 Amazon EC2 实例上运行的传统数据处理应用程序。数据被顺序处理，但结果的顺序无关紧要。该应用程序使用单体架构。该公司扩展应用程序以满足不断增长的需求的唯一方法是增加实例的大小。该公司的开发人员已决定重写该应用程序，以便在 Amazon Elastic Container Service (Amazon ECS) 上使用微服务架构。解决方案架构师应该为微服务之间的通信推荐什么？",
    "options_cn": {
      "A": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将代码添加到数据生成者，并将数据发送到队列。将代码添加到数据消费者以处理来自队列的数据。",
      "B": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将代码添加到数据生成者，并将通知发布到该主题。将代码添加到数据消费者以订阅该主题。",
      "C": "创建一个 AWS Lambda 函数来传递消息。将代码添加到数据生成者以使用数据对象调用 Lambda 函数。将代码添加到数据消费者以接收从 Lambda 函数传递的数据对象。",
      "D": "创建一个 Amazon DynamoDB 表。打开 DynamoDB Streams。将代码添加到数据生成者以将数据插入表中。将代码添加到数据消费者以使用 DynamoDB Streams API 检测新的表条目并检索数据。"
    }
  },
  {
    "id": 182,
    "topic": "1",
    "question_en": "A company wants to migrate its MySQL database from on premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes. Which solution meets these requirements?",
    "options_en": {
      "A": "Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.",
      "B": "Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data.",
      "C": "Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data.",
      "D": "Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance."
    },
    "correct_answer": "B",
    "vote_percentage": "97%",
    "question_cn": "一家公司希望将其 MySQL 数据库从本地迁移到 AWS。该公司最近经历了数据库中断，这对业务造成了重大影响。为了确保这种情况不再发生，该公司希望在 AWS 上获得一个可靠的数据库解决方案，该方案最大限度地减少数据丢失，并在至少两个节点上存储每笔交易。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon RDS 数据库实例，并与三个可用区中的三个节点进行同步复制。",
      "B": "创建一个启用了多可用区功能的 Amazon RDS MySQL 数据库实例，以同步复制数据。",
      "C": "创建一个 Amazon RDS MySQL 数据库实例，然后在另一个 AWS 区域中创建一个只读副本，该副本同步复制数据。",
      "D": "创建一个安装了 MySQL 引擎的 Amazon EC2 实例，该实例触发一个 AWS Lambda 函数，将数据同步复制到 Amazon RDS MySQL 数据库实例。"
    }
  },
  {
    "id": 183,
    "topic": "1",
    "question_en": "A company is building a new dynamic ordering website. The company wants to minimize server maintenance and patching. The website must be highly available and must scale read and write capacity as quickly as possible to meet changes in user demand. Which solution will meet these requirements?",
    "options_en": {
      "A": "Host static content in Amazon S3. Host dynamic content by using Amazon API Gateway and AWS Lambda. Use Amazon DynamoDB with on-demand capacity for the database. Configure Amazon CloudFront to deliver the website content.",
      "B": "Host static content in Amazon S3. Host dynamic content by using Amazon API Gateway and AWS Lambda. Use Amazon Aurora with Aurora Auto Scaling for the database. Configure Amazon CloudFront to deliver the website content.",
      "C": "Host all the website content on Amazon EC2 instances. Create an Auto Scaling group to scale the EC2 instances. Use an Application Load Balancer to distribute trafic. Use Amazon DynamoDB with provisioned write capacity for the database.",
      "D": "Host all the website content on Amazon EC2 instances. Create an Auto Scaling group to scale the EC2 instances. Use an Application Load Balancer to distribute trafic. Use Amazon Aurora with Aurora Auto Scaling for the database."
    },
    "correct_answer": "A",
    "vote_percentage": "94%",
    "question_cn": "一家公司正在构建一个新的动态订购网站。该公司希望最大限度地减少服务器维护和补丁。该网站必须具有高可用性，并且必须尽可能快地扩展读写容量，以满足用户需求的变化。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将静态内容托管在 Amazon S3 中。 使用 Amazon API Gateway 和 AWS Lambda 托管动态内容。 使用具有按需容量的 Amazon DynamoDB 作为数据库。 配置 Amazon CloudFront 交付网站内容。",
      "B": "将静态内容托管在 Amazon S3 中。 使用 Amazon API Gateway 和 AWS Lambda 托管动态内容。 使用具有 Aurora 自动缩放功能的 Amazon Aurora 作为数据库。 配置 Amazon CloudFront 交付网站内容。",
      "C": "将所有网站内容托管在 Amazon EC2 实例上。 创建一个 Auto Scaling 组来扩展 EC2 实例。 使用 Application Load Balancer 分配流量。 使用具有预置写入容量的 Amazon DynamoDB 作为数据库。",
      "D": "将所有网站内容托管在 Amazon EC2 实例上。 创建一个 Auto Scaling 组来扩展 EC2 实例。 使用 Application Load Balancer 分配流量。 使用具有 Aurora 自动缩放功能的 Amazon Aurora 作为数据库。"
    }
  },
  {
    "id": 184,
    "topic": "1",
    "question_en": "A company has an AWS account used for software engineering. The AWS account has access to the company’s on-premises data center through a pair of AWS Direct Connect connections. All non-VPC trafic routes to the virtual private gateway. A development team recently created an AWS Lambda function through the console. The development team needs to allow the function to access a database that runs in a private subnet in the company’s data center. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the Lambda function to run in the VPC with the appropriate security group.",
      "B": "Set up a VPN connection from AWS to the data center. Route the trafic from the Lambda function through the VPN.",
      "C": "Update the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect.",
      "D": "Create an Elastic IP address. Configure the Lambda function to send trafic through the Elastic IP address without an elastic network interface."
    },
    "correct_answer": "C",
    "vote_percentage": "73%",
    "question_cn": "一家公司有一个用于软件工程的 AWS 账户。该 AWS 账户通过一对 AWS Direct Connect 连接访问公司本地数据中心。所有非 VPC 流量路由到虚拟私有网关。一个开发团队最近通过控制台创建了一个 AWS Lambda 函数。开发团队需要允许该函数访问在公司数据中心内的私有子网中运行的数据库。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 Lambda 函数配置为在 VPC 中运行，并使用适当的安全组。",
      "B": "设置从 AWS 到数据中心的 VPN 连接。将来自 Lambda 函数的流量通过 VPN 路由。",
      "C": "更新 VPC 中的路由表，以允许 Lambda 函数通过 Direct Connect 访问本地数据中心。",
      "D": "创建一个弹性 IP 地址。将 Lambda 函数配置为通过弹性 IP 地址发送流量，而无需弹性网络接口。"
    }
  },
  {
    "id": 185,
    "topic": "1",
    "question_en": "A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?",
    "options_en": {
      "A": "Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.",
      "B": "Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.",
      "C": "Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.",
      "D": "Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon ECS 运行应用程序。该应用程序创建原始图像的调整大小版本，然后进行 Amazon S3 API 调用，将调整大小的图像存储在 Amazon S3 中。解决方案架构师如何确保应用程序有权访问 Amazon S3？",
    "options_cn": {
      "A": "在 AWS IAM 中更新 S3 角色，以允许从 Amazon ECS 进行读/写访问，然后重新启动容器。",
      "B": "创建一个具有 S3 权限的 IAM 角色，然后在任务定义中将该角色指定为 taskRoleArn。",
      "C": "创建一个安全组，允许从 Amazon ECS 访问 Amazon S3，并更新 ECS 集群使用的启动配置。",
      "D": "创建一个具有 S3 权限的 IAM 用户，然后在以该帐户登录的情况下重新启动 ECS 集群的 Amazon EC2 实例。"
    }
  },
  {
    "id": 186,
    "topic": "1",
    "question_en": "A company has a Windows-based application that must be migrated to AWS. The application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances that are deployed across multiple Availability Zone: What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Configure AWS Storage Gateway in volume gateway mode. Mount the volume to each Windows instance.",
      "B": "Configure Amazon FSx for Windows File Server. Mount the Amazon FSx file system to each Windows instance.",
      "C": "Configure a file system by using Amazon Elastic File System (Amazon EFS). Mount the EFS file system to each Windows instance.",
      "D": "Configure an Amazon Elastic Block Store (Amazon EBS) volume with the required size. Attach each EC2 instance to the volume. Mount the file system within the volume to each Windows instance."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个基于 Windows 的应用程序，该应用程序必须迁移到 AWS。该应用程序需要使用连接到多个 Amazon EC2 Windows 实例的共享 Windows 文件系统，这些实例部署在多个可用区。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "在卷网关模式下配置 AWS Storage Gateway。将卷挂载到每个 Windows 实例。",
      "B": "配置 Amazon FSx for Windows File Server。将 Amazon FSx 文件系统挂载到每个 Windows 实例。",
      "C": "使用 Amazon Elastic File System (Amazon EFS) 配置一个文件系统。将 EFS 文件系统挂载到每个 Windows 实例。",
      "D": "配置具有所需大小的 Amazon Elastic Block Store (Amazon EBS) 卷。将每个 EC2 实例连接到该卷。将卷中的文件系统挂载到每个 Windows 实例。"
    }
  },
  {
    "id": 187,
    "topic": "1",
    "question_en": "A company is developing an ecommerce application that will consist of a load-balanced front end, a container-based application, and a relational database. A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible. Which solutions meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon RDS DB instance in Multi-AZ mode.",
      "B": "Create an Amazon RDS DB instance and one or more replicas in another Availability Zone.",
      "C": "Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load.",
      "D": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load",
      "E": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在开发一个电子商务应用程序，该应用程序将包括一个负载均衡的前端、一个基于容器的应用程序和一个关系数据库。解决方案架构师需要创建一个高可用性解决方案，该方案尽可能减少手动干预。哪些解决方案符合这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 Multi-AZ 模式下创建 Amazon RDS 数据库实例。",
      "B": "在另一个可用区中创建 Amazon RDS 数据库实例和一个或多个副本。",
      "C": "创建一个基于 Amazon EC2 实例的 Docker 集群来处理动态应用程序负载。",
      "D": "创建一个使用 Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群来处理动态应用程序负载。",
      "E": "创建一个使用 Amazon EC2 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群来处理动态应用程序负载。"
    }
  },
  {
    "id": 188,
    "topic": "1",
    "question_en": "A company uses Amazon S3 as its data lake. The company has a new partner that must use SFTP to upload data files. A solutions architect needs to implement a highly available SFTP solution that minimizes operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Transfer Family to configure an SFTP-enabled server with a publicly accessible endpoint. Choose the S3 data lake as the destination.",
      "B": "Use Amazon S3 File Gateway as an SFTP server. Expose the S3 File Gateway endpoint URL to the new partner. Share the S3 File Gateway endpoint with the new partner.",
      "C": "Launch an Amazon EC2 instance in a private subnet in a VPInstruct the new partner to upload files to the EC2 instance by using a VPN. Run a cron job script, on the EC2 instance to upload files to the S3 data lake.",
      "D": "Launch Amazon EC2 instances in a private subnet in a VPC. Place a Network Load Balancer (NLB) in front of the EC2 instances. Create an SFTP listener port for the NLB. Share the NLB hostname with the new partner. Run a cron job script on the EC2 instances to upload files to the S3 data lake."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon S3 作为其数据湖。该公司有一个新合作伙伴，必须使用 SFTP 上传数据文件。一位解决方案架构师需要实施一个高可用性的 SFTP 解决方案，以最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Transfer Family 配置一个支持 SFTP 的服务器，该服务器具有公开可访问的终端节点。选择 S3 数据湖作为目标。",
      "B": "使用 Amazon S3 File Gateway 作为 SFTP 服务器。将 S3 File Gateway 终端节点 URL 暴露给新合作伙伴。与新合作伙伴共享 S3 File Gateway 终端节点。",
      "C": "在 VPC 的私有子网中启动一个 Amazon EC2 实例。指示新合作伙伴通过 VPN 将文件上传到 EC2 实例。在 EC2 实例上运行一个 cron job 脚本，将文件上传到 S3 数据湖。",
      "D": "在 VPC 的私有子网中启动 Amazon EC2 实例。在 EC2 实例前面放置一个 Network Load Balancer (NLB)。为 NLB 创建一个 SFTP 监听端口。与新合作伙伴共享 NLB 主机名。在 EC2 实例上运行一个 cron job 脚本，将文件上传到 S3 数据湖。"
    }
  },
  {
    "id": 189,
    "topic": "1",
    "question_en": "A company needs to store contract documents. A contract lasts for 5 years. During the 5-year period, the company must ensure that the documents cannot be overwritten or deleted. The company needs to encrypt the documents at rest and rotate the encryption keys automatically every year. Which combination of steps should a solutions architect take to meet these requirements with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Store the documents in Amazon S3. Use S3 Object Lock in governance mode.",
      "B": "Store the documents in Amazon S3. Use S3 Object Lock in compliance mode.",
      "C": "Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure key rotation.",
      "D": "Use server-side encryption with AWS Key Management Service (AWS KMS) customer managed keys. Configure key rotation",
      "E": "Use server-side encryption with AWS Key Management Service (AWS KMS) customer provided (imported) keys. Configure key rotation."
    },
    "correct_answer": "C",
    "vote_percentage": "77%",
    "question_cn": "一家公司需要存储合同文件。一份合同有效期为 5 年。在 5 年期间，公司必须确保文件不能被覆盖或删除。该公司需要在静态时加密文件，并每年自动轮换加密密钥。解决方案架构师应该采取哪些组合步骤，以最少的运营开销来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将文件存储在 Amazon S3 中。在管理模式下使用 S3 Object Lock。",
      "B": "将文件存储在 Amazon S3 中。在合规模式下使用 S3 Object Lock。",
      "C": "使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置密钥轮换。",
      "D": "使用带有 AWS Key Management Service (AWS KMS) 客户托管密钥的服务器端加密。配置密钥轮换。",
      "E": "使用带有 AWS Key Management Service (AWS KMS) 客户提供（导入）密钥的服务器端加密。配置密钥轮换。"
    }
  },
  {
    "id": 190,
    "topic": "1",
    "question_en": "A company has a web application that is based on Java and PHP. The company plans to move the application from on premises to AWS. The company needs the ability to test new site features frequently. The company also needs a highly available and managed solution that requires minimum operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon S3 bucket. Enable static web hosting on the S3 bucket. Upload the static content to the S3 bucket. Use AWS Lambda to process all dynamic content.",
      "B": "Deploy the web application to an AWS Elastic Beanstalk environment. Use URL swapping to switch between multiple Elastic Beanstalk environments for feature testing.",
      "C": "Deploy the web application to Amazon EC2 instances that are configured with Java and PHP. Use Auto Scaling groups and an Application Load Balancer to manage the website’s availability.",
      "D": "Containerize the web application. Deploy the web application to Amazon EC2 instances. Use the AWS Load Balancer Controller to dynamically route trafic between containers that contain the new site features for testing."
    },
    "correct_answer": "D",
    "vote_percentage": "90%",
    "question_cn": "一家公司有一个基于 Java 和 PHP 的 Web 应用程序。该公司计划将该应用程序从本地环境迁移到 AWS。该公司需要频繁测试新站点功能的能力。该公司还需要一个高可用且托管的解决方案，该解决方案需要最少的运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon S3 存储桶。在 S3 存储桶上启用静态网站托管。将静态内容上传到 S3 存储桶。使用 AWS Lambda 处理所有动态内容。",
      "B": "将 Web 应用程序部署到 AWS Elastic Beanstalk 环境。使用 URL 交换在多个 Elastic Beanstalk 环境之间切换以进行功能测试。",
      "C": "将 Web 应用程序部署到配置了 Java 和 PHP 的 Amazon EC2 实例。使用 Auto Scaling 组和 Application Load Balancer 来管理网站的可用性。",
      "D": "容器化 Web 应用程序。将 Web 应用程序部署到 Amazon EC2 实例。使用 AWS Load Balancer Controller 动态路由流量，在包含新站点功能的容器之间进行测试。"
    }
  },
  {
    "id": 191,
    "topic": "1",
    "question_en": "A company has an ordering application that stores customer information in Amazon RDS for MySQL. During regular business hours, employees run one-time queries for reporting purposes. Timeouts are occurring during order processing because the reporting queries are taking a long time to run. The company needs to eliminate the timeouts without preventing employees from performing queries. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a read replica. Move reporting queries to the read replica.",
      "B": "Create a read replica. Distribute the ordering application to the primary DB instance and the read replica.",
      "C": "Migrate the ordering application to Amazon DynamoDB with on-demand capacity.",
      "D": "Schedule the reporting queries for non-peak hours."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个订购应用程序，将客户信息存储在 Amazon RDS for MySQL 中。 在正常工作时间，员工运行一次性查询以进行报告。 由于报告查询的运行时间过长，订单处理期间会发生超时。 公司需要消除超时，同时不阻止员工执行查询。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个读取副本。 将报告查询移动到读取副本。",
      "B": "创建一个读取副本。 将订购应用程序分发到主数据库实例和读取副本。",
      "C": "将订购应用程序迁移到 Amazon DynamoDB 并使用按需容量。",
      "D": "将报告查询安排在非高峰时段进行。"
    }
  },
  {
    "id": 192,
    "topic": "1",
    "question_en": "A hospital wants to create digital copies for its large collection of historical written records. The hospital will continue to add hundreds of new documents each day. The hospital’s data team will scan the documents and will upload the documents to the AWS Cloud. A solutions architect must implement a solution to analyze the documents, extract the medical information, and store the documents so that an application can run SQL queries on the data. The solution must maximize scalability and operational eficiency. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Write the document information to an Amazon EC2 instance that runs a MySQL database.",
      "B": "Write the document information to an Amazon S3 bucket. Use Amazon Athena to query the data.",
      "C": "Create an Auto Scaling group of Amazon EC2 instances to run a custom application that processes the scanned files and extracts the medical information.",
      "D": "Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Rekognition to convert the documents to raw text. Use Amazon Transcribe Medical to detect and extract relevant medical information from the text",
      "E": "Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Textract to convert the documents to raw text. Use Amazon Comprehend Medical to detect and extract relevant medical information from the text."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家医院希望为其大量历史书面记录创建数字副本。 医院将继续每天添加数百份新文档。 医院的数据团队将扫描这些文档，并将文档上传到 AWS 云。 解决方案架构师必须实施一个解决方案来分析文档、提取医疗信息并存储文档，以便应用程序可以在数据上运行 SQL 查询。 该解决方案必须最大限度地提高可扩展性和运营效率。 解决方案架构师应该采取哪些组合步骤来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将文档信息写入运行 MySQL 数据库的 Amazon EC2 实例。",
      "B": "将文档信息写入 Amazon S3 存储桶。 使用 Amazon Athena 查询数据。",
      "C": "创建一个 Amazon EC2 实例的 Auto Scaling 组，以运行一个自定义应用程序来处理扫描的文件并提取医疗信息。",
      "D": "创建一个 AWS Lambda 函数，该函数在新文档上传时运行。 使用 Amazon Rekognition 将文档转换为原始文本。 使用 Amazon Transcribe Medical 从文本中检测并提取相关的医疗信息。",
      "E": "创建一个 AWS Lambda 函数，该函数在新文档上传时运行。 使用 Amazon Textract 将文档转换为原始文本。 使用 Amazon Comprehend Medical 从文本中检测并提取相关的医疗信息。"
    }
  },
  {
    "id": 193,
    "topic": "1",
    "question_en": "A company is running a batch application on Amazon EC2 instances. The application consists of a backend with multiple Amazon RDS databases. The application is causing a high number of reads on the databases. A solutions architect must reduce the number of database reads while ensuring high availability. What should the solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Add Amazon RDS read replicas.",
      "B": "Use Amazon ElastiCache for Redis.",
      "C": "Use Amazon Route 53 DNS caching",
      "D": "Use Amazon ElastiCache for Memcached."
    },
    "correct_answer": "A",
    "vote_percentage": "53%",
    "question_cn": "一家公司在 Amazon EC2 实例上运行一个批处理应用程序。该应用程序由具有多个 Amazon RDS 数据库的后端组成。该应用程序导致数据库上的读取次数很高。解决方案架构师必须减少数据库读取次数，同时确保高可用性。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "添加 Amazon RDS 副本读取器。",
      "B": "使用 Amazon ElastiCache for Redis。",
      "C": "使用 Amazon Route 53 DNS 缓存",
      "D": "使用 Amazon ElastiCache for Memcached。"
    }
  },
  {
    "id": 194,
    "topic": "1",
    "question_en": "A company needs to run a critical application on AWS. The company needs to use Amazon EC2 for the application’s database. The database must be highly available and must fail over automatically if a disruptive event occurs. Which solution will meet these requirements?",
    "options_en": {
      "A": "Launch two EC2 instances, each in a different Availability Zone in the same AWS Region. Install the database on both EC2 instances. Configure the EC2 instances as a cluster. Set up database replication.",
      "B": "Launch an EC2 instance in an Availability Zone. Install the database on the EC2 instance. Use an Amazon Machine Image (AMI) to back up the data. Use AWS CloudFormation to automate provisioning of the EC2 instance if a disruptive event occurs.",
      "C": "Launch two EC2 instances, each in a different AWS Region. Install the database on both EC2 instances. Set up database replication. Fail over the database to a second Region.",
      "D": "Launch an EC2 instance in an Availability Zone. Install the database on the EC2 instance. Use an Amazon Machine Image (AMI) to back up the data. Use EC2 automatic recovery to recover the instance if a disruptive event occurs."
    },
    "correct_answer": "C",
    "vote_percentage": "55%",
    "question_cn": "一家公司需要在 AWS 上运行一个关键应用程序。该公司需要使用 Amazon EC2 作为应用程序的数据库。数据库必须具有高可用性，并且如果发生中断事件，必须自动故障转移。以下哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在同一 AWS 区域的不同可用区中启动两个 EC2 实例。在两个 EC2 实例上安装数据库。将 EC2 实例配置为集群。设置数据库复制。",
      "B": "在一个可用区中启动一个 EC2 实例。在 EC2 实例上安装数据库。使用 Amazon Machine Image (AMI) 备份数据。使用 AWS CloudFormation 在发生中断事件时自动预置 EC2 实例。",
      "C": "在不同的 AWS 区域中启动两个 EC2 实例。在两个 EC2 实例上安装数据库。设置数据库复制。将数据库故障转移到第二个区域。",
      "D": "在一个可用区中启动一个 EC2 实例。在 EC2 实例上安装数据库。使用 Amazon Machine Image (AMI) 备份数据。使用 EC2 自动恢复来恢复实例，如果发生中断事件。"
    }
  },
  {
    "id": 195,
    "topic": "1",
    "question_en": "A company’s order system sends requests from clients to Amazon EC2 instances. The EC2 instances process the orders and then store the orders in a database on Amazon RDS. Users report that they must reprocess orders when the system fails. The company wants a resilient solution that can process orders automatically if a system outage occurs. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Move the EC2 instances into an Auto Scaling group. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to target an Amazon Elastic Container Service (Amazon ECS) task.",
      "B": "Move the EC2 instances into an Auto Scaling group behind an Application Load Balancer (ALB). Update the order system to send messages to the ALB endpoint.",
      "C": "Move the EC2 instances into an Auto Scaling group. Configure the order system to send messages to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the EC2 instances to consume messages from the queue.",
      "D": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Create an AWS Lambda function, and subscribe the function to the SNS topic. Configure the order system to send messages to the SNS topic. Send a command to the EC2 instances to process the messages by using AWS Systems Manager Run Command."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司的订单系统将来自客户端的请求发送到 Amazon EC2 实例。EC2 实例处理订单，然后将订单存储在 Amazon RDS 上的数据库中。用户报告说，当系统发生故障时，他们必须重新处理订单。该公司希望有一个弹性的解决方案，可以在系统中断时自动处理订单。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将 EC2 实例移入 Auto Scaling 组。创建一个 Amazon EventBridge (Amazon CloudWatch Events) 规则，以目标 Amazon Elastic Container Service (Amazon ECS) 任务。",
      "B": "将 EC2 实例移入 Application Load Balancer (ALB) 后面的 Auto Scaling 组。更新订单系统以将消息发送到 ALB 终端节点。",
      "C": "将 EC2 实例移入 Auto Scaling 组。配置订单系统将消息发送到 Amazon Simple Queue Service (Amazon SQS) 队列。配置 EC2 实例以使用队列中的消息。",
      "D": "创建 Amazon Simple Notification Service (Amazon SNS) 主题。创建一个 AWS Lambda 函数，并将该函数订阅到 SNS 主题。配置订单系统以将消息发送到 SNS 主题。使用 AWS Systems Manager Run Command 将命令发送到 EC2 实例以处理消息。"
    }
  },
  {
    "id": 196,
    "topic": "1",
    "question_en": "A company runs an application on a large fieet of Amazon EC2 instances. The application reads and writes entries into an Amazon DynamoDB table. The size of the DynamoDB table continuously grows, but the application needs only data from the last 30 days. The company needs a solution that minimizes cost and development effort. Which solution meets these requirements?",
    "options_en": {
      "A": "Use an AWS CloudFormation template to deploy the complete solution. Redeploy the CloudFormation stack every 30 days, and delete the original stack.",
      "B": "Use an EC2 instance that runs a monitoring application from AWS Marketplace. Configure the monitoring application to use Amazon DynamoDB Streams to store the timestamp when a new item is created in the table. Use a script that runs on the EC2 instance to delete items that have a timestamp that is older than 30 days.",
      "C": "Configure Amazon DynamoDB Streams to invoke an AWS Lambda function when a new item is created in the table. Configure the Lambda function to delete items in the table that are older than 30 days.",
      "D": "Extend the application to add an attribute that has a value of the current timestamp plus 30 days to each new item that is created in the table. Configure DynamoDB to use the attribute as the TTL attribute."
    },
    "correct_answer": "D",
    "vote_percentage": "92%",
    "question_cn": "一家公司在其大型 Amazon EC2 实例集群上运行一个应用程序。该应用程序在 Amazon DynamoDB 表中读取和写入条目。DynamoDB 表的大小持续增长，但应用程序只需要最近 30 天的数据。公司需要一个最大限度地降低成本和开发工作量的解决方案。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS CloudFormation 模板部署完整的解决方案。每 30 天重新部署 CloudFormation 堆栈，并删除原始堆栈。",
      "B": "使用一个 EC2 实例，该实例运行来自 AWS Marketplace 的监控应用程序。配置监控应用程序使用 Amazon DynamoDB Streams 来存储新项目在表中创建的时间戳。使用在 EC2 实例上运行的脚本删除时间戳超过 30 天的项目。",
      "C": "配置 Amazon DynamoDB Streams 以在表中创建新项目时调用 AWS Lambda 函数。配置 Lambda 函数以删除表中超过 30 天的项目。",
      "D": "扩展应用程序，为每个在新表中创建的新项目添加一个属性，该属性的值为当前时间戳加上 30 天。配置 DynamoDB 将该属性用作 TTL 属性。"
    }
  },
  {
    "id": 197,
    "topic": "1",
    "question_en": "A company has a Microsoft .NET application that runs on an on-premises Windows Server. The application stores data by using an Oracle Database Standard Edition server. The company is planning a migration to AWS and wants to minimize development changes while moving the application. The AWS application environment should be highly available. Which combination of actions should the company take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Refactor the application as serverless with AWS Lambda functions running .NET Core.",
      "B": "Rehost the application in AWS Elastic Beanstalk with the .NET platform in a Multi-AZ deployment.",
      "C": "Replatform the application to run on Amazon EC2 with the Amazon Linux Amazon Machine Image (AMI).",
      "D": "Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Amazon DynamoDB in a Multi-AZ deployment",
      "E": "Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Oracle on Amazon RDS in a Multi-AZ deployment."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司有一个在本地 Windows Server 上运行的 Microsoft .NET 应用程序。该应用程序使用 Oracle Database Standard Edition 服务器存储数据。该公司计划迁移到 AWS，并希望在移动应用程序时尽量减少开发更改。AWS 应用程序环境应具有高可用性。该公司应采取哪些组合操作来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "将应用程序重构为无服务器架构，使用运行 .NET Core 的 AWS Lambda 函数。",
      "B": "在 AWS Elastic Beanstalk 中重新托管应用程序，使用 .NET 平台进行 Multi-AZ 部署。",
      "C": "将应用程序重新平台化，使其在 Amazon EC2 上运行，使用 Amazon Linux Amazon 机器映像 (AMI)。",
      "D": "使用 AWS 数据库迁移服务 (AWS DMS) 将数据从 Oracle 数据库迁移到 Multi-AZ 部署中的 Amazon DynamoDB。",
      "E": "使用 AWS 数据库迁移服务 (AWS DMS) 将数据从 Oracle 数据库迁移到 Multi-AZ 部署中的 Amazon RDS 上的 Oracle。"
    }
  },
  {
    "id": 198,
    "topic": "1",
    "question_en": "A company runs a containerized application on a Kubernetes cluster in an on-premises data center. The company is using a MongoDB database for data storage. The company wants to migrate some of these environments to AWS, but no code changes or deployment method changes are possible at this time. The company needs a solution that minimizes operational overhead. Which solution meets these requirements?",
    "options_en": {
      "A": "Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 worker nodes for compute and MongoDB on EC2 for data storage.",
      "B": "Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute and Amazon DynamoDB for data storage",
      "C": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes for compute and Amazon DynamoDB for data storage.",
      "D": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate for compute and Amazon DocumentDB (with MongoDB compatibility) for data storage."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其本地数据中心内的 Kubernetes 集群上运行容器化应用程序。该公司使用 MongoDB 数据库进行数据存储。该公司希望将其中一些环境迁移到 AWS，但目前无法进行代码更改或部署方法更改。该公司需要一个解决方案，以最大限度地减少运营开销。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Service (Amazon ECS) 和 Amazon EC2 工作节点进行计算，并使用 EC2 上的 MongoDB 进行数据存储。",
      "B": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate 进行计算，并使用 Amazon DynamoDB 进行数据存储",
      "C": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 Amazon EC2 工作节点进行计算，并使用 Amazon DynamoDB 进行数据存储。",
      "D": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 AWS Fargate 进行计算，并使用 Amazon DocumentDB（兼容 MongoDB）进行数据存储。"
    }
  },
  {
    "id": 199,
    "topic": "1",
    "question_en": "A telemarketing company is designing its customer call center functionality on AWS. The company needs a solution that provides multiple speaker recognition and generates transcript files. The company wants to query the transcript files to analyze the business patterns. The transcript files must be stored for 7 years for auditing purposes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use machine learning models for transcript file analysis.",
      "B": "Use Amazon Transcribe for multiple speaker recognition. Use Amazon Athena for transcript file analysis.",
      "C": "Use Amazon Translate for multiple speaker recognition. Store the transcript files in Amazon Redshift. Use SQL queries for transcript file analysis.",
      "D": "Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use Amazon Textract for transcript file analysis."
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家电话营销公司正在 AWS 上设计其客户呼叫中心功能。该公司需要一个可以提供多发言人识别并生成转录文件的解决方案。该公司希望查询转录文件以分析业务模式。转录文件必须存储 7 年以供审计之用。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Rekognition 进行多发言人识别。将转录文件存储在 Amazon S3 中。使用机器学习模型进行转录文件分析。",
      "B": "使用 Amazon Transcribe 进行多发言人识别。使用 Amazon Athena 进行转录文件分析。",
      "C": "使用 Amazon Translate 进行多发言人识别。将转录文件存储在 Amazon Redshift 中。使用 SQL 查询进行转录文件分析。",
      "D": "使用 Amazon Rekognition 进行多发言人识别。将转录文件存储在 Amazon S3 中。使用 Amazon Textract 进行转录文件分析。"
    }
  },
  {
    "id": 200,
    "topic": "1",
    "question_en": "A company hosts its application on AWS. The company uses Amazon Cognito to manage users. When users log in to the application, the application fetches required data from Amazon DynamoDB by using a REST API that is hosted in Amazon API Gateway. The company wants an AWS managed solution that will control access to the REST API to reduce development efforts. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure an AWS Lambda function to be an authorizer in API Gateway to validate which user made the request.",
      "B": "For each user, create and assign an API key that must be sent with each request. Validate the key by using an AWS Lambda function.",
      "C": "Send the user’s email address in the header with every request. Invoke an AWS Lambda function to validate that the user with that email address has proper access.",
      "D": "Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request."
    },
    "correct_answer": "A",
    "vote_percentage": "98%",
    "question_cn": "一家公司在 AWS 上托管其应用程序。该公司使用 Amazon Cognito 管理用户。当用户登录到应用程序时，应用程序使用托管在 Amazon API Gateway 中的 REST API 从 Amazon DynamoDB 获取所需数据。该公司希望使用 AWS 托管解决方案来控制对 REST API 的访问，以减少开发工作量。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "配置一个 AWS Lambda 函数作为 API Gateway 中的授权方，以验证哪个用户发出了请求。",
      "B": "为每个用户创建并分配一个 API 密钥，该密钥必须随每个请求一起发送。使用 AWS Lambda 函数验证该密钥。",
      "C": "在每个请求的标头中发送用户的电子邮件地址。调用一个 AWS Lambda 函数来验证具有该电子邮件地址的用户是否具有适当的访问权限。",
      "D": "在 API Gateway 中配置 Amazon Cognito 用户池授权方，以允许 Amazon Cognito 验证每个请求。"
    }
  },
  {
    "id": 201,
    "topic": "1",
    "question_en": "A company is developing a marketing communications service that targets mobile app users. The company needs to send confirmation messages with Short Message Service (SMS) to its users. The users must be able to reply to the SMS messages. The company must store the responses for a year for analysis. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an Amazon Connect contact fiow to send the SMS messages. Use AWS Lambda to process the responses.",
      "B": "Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.",
      "C": "Use Amazon Simple Queue Service (Amazon SQS) to distribute the SMS messages. Use AWS Lambda to process the responses.",
      "D": "Create an Amazon Simple Notification Service (Amazon SNS) FIFO topic. Subscribe an Amazon Kinesis data stream to the SNS topic for analysis and archiving."
    },
    "correct_answer": "A",
    "vote_percentage": "87%",
    "question_cn": "一家公司正在开发一个针对移动应用程序用户的营销传播服务。该公司需要使用短消息服务 (SMS) 向其用户发送确认消息。用户必须能够回复 SMS 消息。该公司必须将回复存储一年以供分析。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Connect 联络流程来发送 SMS 消息。 使用 AWS Lambda 处理回复。",
      "B": "构建一个 Amazon Pinpoint 旅程。配置 Amazon Pinpoint 将事件发送到 Amazon Kinesis 数据流以进行分析和归档。",
      "C": "使用 Amazon Simple Queue Service (Amazon SQS) 分发 SMS 消息。使用 AWS Lambda 处理回复。",
      "D": "创建一个 Amazon Simple Notification Service (Amazon SNS) FIFO 主题。将 Amazon Kinesis 数据流订阅到 SNS 主题以进行分析和归档。"
    }
  },
  {
    "id": 202,
    "topic": "1",
    "question_en": "A company is planning to move its data to an Amazon S3 bucket. The data must be encrypted when it is stored in the S3 bucket. Additionally, the encryption key must be automatically rotated every year. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Move the data to the S3 bucket. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys.",
      "B": "Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket’s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket.",
      "C": "Create an AWS Key Management Service (AWS KMS) customer managed key. Set the S3 bucket’s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket. Manually rotate the KMS key every year.",
      "D": "Encrypt the data with customer key material before moving the data to the S3 bucket. Create an AWS Key Management Service (AWS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation."
    },
    "correct_answer": "B",
    "vote_percentage": "55%",
    "question_cn": "一家公司计划将其数据移动到 Amazon S3 存储桶。 数据在存储在 S3 存储桶中时必须进行加密。 此外，加密密钥必须每年自动轮换。 哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将数据移动到 S3 存储桶。 使用具有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。 使用 SSE-S3 加密密钥的内置密钥轮换行为。",
      "B": "创建 AWS Key Management Service (AWS KMS) 客户托管密钥。 启用自动密钥轮换。 将 S3 存储桶的默认加密行为设置为使用客户托管 KMS 密钥。 将数据移动到 S3 存储桶。",
      "C": "创建 AWS Key Management Service (AWS KMS) 客户托管密钥。 将 S3 存储桶的默认加密行为设置为使用客户托管 KMS 密钥。 将数据移动到 S3 存储桶。 每年手动轮换 KMS 密钥。",
      "D": "在将数据移动到 S3 存储桶之前，使用客户密钥材料对数据进行加密。 创建一个没有密钥材料的 AWS Key Management Service (AWS KMS) 密钥。 将客户密钥材料导入 KMS 密钥。 启用自动密钥轮换。"
    }
  },
  {
    "id": 203,
    "topic": "1",
    "question_en": "The customers of a finance company request appointments with financial advisors by sending text messages. A web application that runs on Amazon EC2 instances accepts the appointment requests. The text messages are published to an Amazon Simple Queue Service (Amazon SQS) queue through the web application. Another application that runs on EC2 instances then sends meeting invitations and meeting confirmation email messages to the customers. After successful scheduling, this application stores the meeting information in an Amazon DynamoDB database. As the company expands, customers report that their meeting invitations are taking longer to arrive. What should a solutions architect recommend to resolve this issue?",
    "options_en": {
      "A": "Add a DynamoDB Accelerator (DAX) cluster in front of the DynamoDB database.",
      "B": "Add an Amazon API Gateway API in front of the web application that accepts the appointment requests.",
      "C": "Add an Amazon CloudFront distribution. Set the origin as the web application that accepts the appointment requests.",
      "D": "Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家金融公司的客户通过发送短信来预约理财顾问。一个运行在 Amazon EC2 实例上的 Web 应用程序接受预约请求。短信通过该 Web 应用程序发布到 Amazon Simple Queue Service (Amazon SQS) 队列。另一个运行在 EC2 实例上的应用程序然后向客户发送会议邀请和会议确认电子邮件。成功安排后，该应用程序将会议信息存储在 Amazon DynamoDB 数据库中。随着公司的发展，客户报告说他们的会议邀请需要更长时间才能到达。解决方案架构师应该推荐什么来解决这个问题？",
    "options_cn": {
      "A": "在 DynamoDB 数据库前面添加一个 DynamoDB Accelerator (DAX) 集群。",
      "B": "在接受预约请求的 Web 应用程序前面添加一个 Amazon API Gateway API。",
      "C": "添加一个 Amazon CloudFront 分发。将源设置为接受预约请求的 Web 应用程序。",
      "D": "为发送会议邀请的应用程序添加一个 Auto Scaling 组。配置 Auto Scaling 组以根据 SQS 队列的深度进行扩展。"
    }
  },
  {
    "id": 204,
    "topic": "1",
    "question_en": "An online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS. The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access.",
      "B": "Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access.",
      "C": "Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.",
      "D": "Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家在线零售公司拥有超过 5000 万活跃客户，每天收到超过 25000 份订单。该公司为客户收集购买数据，并将这些数据存储在 Amazon S3 中。其他客户数据存储在 Amazon RDS 中。该公司希望向各个团队提供所有数据，以便团队可以执行分析。该解决方案必须提供对数据的细粒度权限管理能力，并且必须最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将购买数据迁移到直接写入 Amazon RDS。使用 RDS 访问控制来限制访问。",
      "B": "安排一个 AWS Lambda 函数，用于定期间隔将数据从 Amazon RDS 复制到 Amazon S3。创建一个 AWS Glue 爬虫。使用 Amazon Athena 查询数据。使用 S3 策略来限制访问。",
      "C": "使用 AWS Lake Formation 创建一个数据湖。创建与 Amazon RDS 的 AWS Glue JDBC 连接。在 Lake Formation 中注册 S3 存储桶。使用 Lake Formation 访问控制来限制访问。",
      "D": "创建一个 Amazon Redshift 集群。安排一个 AWS Lambda 函数，用于定期间隔将数据从 Amazon S3 和 Amazon RDS 复制到 Amazon Redshift。使用 Amazon Redshift 访问控制来限制访问。"
    }
  },
  {
    "id": 205,
    "topic": "1",
    "question_en": "A company hosts a marketing website in an on-premises data center. The website consists of static documents and runs on a single server. An administrator updates the website content infrequently and uses an SFTP client to upload new documents. The company decides to host its website on AWS and to use Amazon CloudFront. The company’s solutions architect creates a CloudFront distribution. The solutions architect must design the most cost-effective and resilient architecture for website hosting to serve as the CloudFront origin. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a virtual server by using Amazon Lightsail. Configure the web server in the Lightsail instance. Upload website content by using an SFTP client.",
      "B": "Create an AWS Auto Scaling group for Amazon EC2 instances. Use an Application Load Balancer. Upload website content by using an SFTP client.",
      "C": "Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.",
      "D": "Create a public Amazon S3 bucket. Configure AWS Transfer for SFTP. Configure the S3 bucket for website hosting. Upload website content by using the SFTP client."
    },
    "correct_answer": "C",
    "vote_percentage": "76%",
    "question_cn": "一家公司在其本地数据中心托管一个营销网站。该网站由静态文档组成，并在单个服务器上运行。管理员不经常更新网站内容，并使用 SFTP 客户端上传新文档。该公司决定在 AWS 上托管其网站并使用 Amazon CloudFront。该公司的解决方案架构师创建了一个 CloudFront 分发。解决方案架构师必须为网站托管设计最具成本效益和弹性的架构，以充当 CloudFront 源。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Lightsail 创建一个虚拟服务器。在 Lightsail 实例中配置 Web 服务器。使用 SFTP 客户端上传网站内容。",
      "B": "为 Amazon EC2 实例创建一个 AWS Auto Scaling 组。使用 Application Load Balancer。使用 SFTP 客户端上传网站内容。",
      "C": "创建一个私有的 Amazon S3 存储桶。使用 S3 存储桶策略允许从 CloudFront 源访问身份 (OAI) 进行访问。使用 AWS CLI 上传网站内容。",
      "D": "创建一个公共的 Amazon S3 存储桶。配置 AWS Transfer for SFTP。配置 S3 存储桶以用于网站托管。使用 SFTP 客户端上传网站内容。"
    }
  },
  {
    "id": 206,
    "topic": "1",
    "question_en": "A company wants to manage Amazon Machine Images (AMIs). The company currently copies AMIs to the same AWS Region where the AMIs were created. The company needs to design an application that captures AWS API calls and sends alerts whenever the Amazon EC2 CreateImage API operation is called within the company’s account. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Lambda function to query AWS CloudTrail logs and to send an alert when a CreateImage API call is detected.",
      "B": "Configure AWS CloudTrail with an Amazon Simple Notification Service (Amazon SNS) notification that occurs when updated logs are sent to Amazon S3. Use Amazon Athena to create a new table and to query on CreateImage when an API call is detected.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the CreateImage API call. Configure the target as an Amazon Simple Notification Service (Amazon SNS) topic to send an alert when a CreateImage API call is detected.",
      "D": "Configure an Amazon Simple Queue Service (Amazon SQS) FIFO queue as a target for AWS CloudTrail logs. Create an AWS Lambda function to send an alert to an Amazon Simple Notification Service (Amazon SNS) topic when a CreateImage API call is detected."
    },
    "correct_answer": "D",
    "vote_percentage": "72%",
    "question_cn": "一家公司希望管理 Amazon Machine Images (AMIs)。该公司目前将 AMIs 复制到创建 AMIs 的相同 AWS 区域。该公司需要设计一个应用程序，该应用程序捕获 AWS API 调用，并在公司帐户内调用 Amazon EC2 CreateImage API 操作时发送警报。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数来查询 AWS CloudTrail 日志，并在检测到 CreateImage API 调用时发送警报。",
      "B": "使用 Amazon Simple Notification Service (Amazon SNS) 通知配置 AWS CloudTrail，该通知发生在将更新的日志发送到 Amazon S3 时。使用 Amazon Athena 创建一个新表，并在检测到 API 调用时查询 CreateImage。",
      "C": "为 CreateImage API 调用创建一个 Amazon EventBridge (Amazon CloudWatch Events) 规则。将目标配置为 Amazon Simple Notification Service (Amazon SNS) 主题，以便在检测到 CreateImage API 调用时发送警报。",
      "D": "将 Amazon Simple Queue Service (Amazon SQS) FIFO 队列配置为 AWS CloudTrail 日志的目标。创建一个 AWS Lambda 函数，以便在检测到 CreateImage API 调用时将警报发送到 Amazon Simple Notification Service (Amazon SNS) 主题。"
    }
  },
  {
    "id": 207,
    "topic": "1",
    "question_en": "A company owns an asynchronous API that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using Amazon API Gateway to deploy the API front end, and an AWS Lambda function that invokes Amazon DynamoDB to store user requests before dispatching them to the processing microservices. The company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests. What should a solutions architect do to address this issue without impacting existing users?",
    "options_en": {
      "A": "Add throttling on the API Gateway with server-side throttling limits.",
      "B": "Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.",
      "C": "Create a secondary index in DynamoDB for the table with the user requests.",
      "D": "Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB."
    },
    "correct_answer": "D",
    "vote_percentage": "98%",
    "question_cn": "一家公司拥有一个异步 API，用于接收用户请求，并根据请求类型，将请求分发到适当的微服务进行处理。该公司正在使用 Amazon API Gateway 部署 API 前端，并使用一个 AWS Lambda 函数来调用 Amazon DynamoDB，以在将用户请求分发到处理微服务之前存储它们。该公司已根据其预算配置了尽可能多的 DynamoDB 吞吐量，但该公司仍然遇到可用性问题，并且正在丢失用户请求。 解决方案架构师应该怎么做才能解决此问题，而不会影响现有用户？",
    "options_cn": {
      "A": "在 API Gateway 上添加限制，并使用服务器端限制。 ",
      "B": "使用 DynamoDB Accelerator (DAX) 和 Lambda 缓冲对 DynamoDB 的写入。 ",
      "C": "为包含用户请求的表在 DynamoDB 中创建二级索引。",
      "D": "使用 Amazon Simple Queue Service (Amazon SQS) 队列和 Lambda 来缓冲对 DynamoDB 的写入。"
    }
  },
  {
    "id": 208,
    "topic": "1",
    "question_en": "A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
      "B": "Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
      "C": "Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access.",
      "D": "Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access."
    },
    "correct_answer": "B",
    "vote_percentage": "57%",
    "question_cn": "一家公司需要将数据从 Amazon EC2 实例移动到 Amazon S3 存储桶。该公司必须确保没有 API 调用和数据通过公共互联网路由。只有 EC2 实例可以访问以将数据上传到 S3 存储桶。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 EC2 实例所在的子网中为 Amazon S3 创建一个接口 VPC endpoint。将资源策略附加到 S3 存储桶，仅允许 EC2 实例的 IAM 角色进行访问。",
      "B": "在 EC2 实例所在的可用区中为 Amazon S3 创建一个网关 VPC endpoint。将适当的安全组附加到 endpoint。将资源策略附加到 S3 存储桶，仅允许 EC2 实例的 IAM 角色进行访问。",
      "C": "从 EC2 实例内部运行 nslookup 工具，以获取 S3 存储桶服务的 API endpoint 的私有 IP 地址。在 VPC 路由表中创建一条路由，为 EC2 实例提供对 S3 存储桶的访问权限。将资源策略附加到 S3 存储桶，仅允许 EC2 实例的 IAM 角色进行访问。",
      "D": "使用 AWS 提供的公开可用的 ip-ranges.json 文件来获取 S3 存储桶服务的 API endpoint 的私有 IP 地址。在 VPC 路由表中创建一条路由，为 EC2 实例提供对 S3 存储桶的访问权限。将资源策略附加到 S3 存储桶，仅允许 EC2 实例的 IAM 角色进行访问。"
    }
  },
  {
    "id": 209,
    "topic": "1",
    "question_en": "A solutions architect is designing the architecture of a new application being deployed to the AWS Cloud. The application will run on Amazon EC2 On-Demand Instances and will automatically scale across multiple Availability Zones. The EC2 instances will scale up and down frequently throughout the day. An Application Load Balancer (ALB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed. What should the solutions architect do to ensure that the architecture supports distributed session data management?",
    "options_en": {
      "A": "Use Amazon ElastiCache to manage and store session data.",
      "B": "Use session afinity (sticky sessions) of the ALB to manage session data.",
      "C": "Use Session Manager from AWS Systems Manager to manage the session.",
      "D": "Use the GetSessionToken API operation in AWS Security Token Service (AWS STS) to manage the session."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在设计部署到 AWS 云的新应用程序的架构。该应用程序将在 Amazon EC2 按需实例上运行，并将自动跨多个可用区扩展。 EC2 实例将在一天中频繁地上下扩展。一个 Application Load Balancer (ALB) 将处理负载分配。该架构需要支持分布式会话数据管理。如果需要，公司愿意更改代码。解决方案架构师应该怎么做才能确保架构支持分布式会话数据管理？",
    "options_cn": {
      "A": "使用 Amazon ElastiCache 管理和存储会话数据。",
      "B": "使用 ALB 的会话亲和性（粘性会话）来管理会话数据。",
      "C": "使用 AWS Systems Manager 中的 Session Manager 来管理会话。",
      "D": "使用 AWS Security Token Service (AWS STS) 中的 GetSessionToken API 操作来管理会话。"
    }
  },
  {
    "id": 210,
    "topic": "1",
    "question_en": "A company offers a food delivery service that is growing rapidly. Because of the growth, the company’s order processing system is experiencing scaling problems during peak trafic hours. The current architecture includes the following: • A group of Amazon EC2 instances that run in an Amazon EC2 Auto Scaling group to collect orders from the application • Another group of EC2 instances that run in an Amazon EC2 Auto Scaling group to fulfill orders The order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event. A solutions architect must ensure that the order collection process and the order fulfillment process can both scale properly during peak trafic hours. The solution must optimize utilization of the company’s AWS resources. Which solution meets these requirements?",
    "options_en": {
      "A": "Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure each Auto Scaling group’s minimum capacity according to peak workload values.",
      "B": "Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic that creates additional Auto Scaling groups on demand.",
      "C": "Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Scale the Auto Scaling groups based on notifications that the queues send.",
      "D": "Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the Auto Scaling groups based on this metric."
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家公司提供快速增长的食品配送服务。由于业务增长，该公司订单处理系统在高峰时段遇到了扩展问题。当前的架构包括以下内容： • 一组在 Amazon EC2 Auto Scaling 组中运行的 Amazon EC2 实例，用于从应用程序收集订单 • 另一组在 Amazon EC2 Auto Scaling 组中运行的 EC2 实例，用于履行订单 订单收集过程很快，但订单履行过程可能需要更长时间。由于扩展事件，数据不能丢失。一个解决方案架构师必须确保订单收集过程和订单履行过程都能够在高峰时段正确扩展。该解决方案必须优化公司 AWS 资源的利用率。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch 指标来监控 Auto Scaling 组中每个实例的 CPU。根据峰值工作负载值配置每个 Auto Scaling 组的最小容量。",
      "B": "使用 Amazon CloudWatch 指标来监控 Auto Scaling 组中每个实例的 CPU。配置 CloudWatch 告警以调用 Amazon Simple Notification Service (Amazon SNS) 主题，该主题按需创建额外的 Auto Scaling 组。",
      "C": "预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例来轮询它们各自的队列。根据队列发送的通知扩展 Auto Scaling 组。",
      "D": "预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例来轮询它们各自的队列。基于每个实例的积压计算创建一个指标。根据此指标扩展 Auto Scaling 组。"
    }
  },
  {
    "id": 211,
    "topic": "1",
    "question_en": "A company hosts multiple production applications. One of the applications consists of resources from Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service (Amazon SNS), and Amazon Simple Queue Service (Amazon SQS) across multiple AWS Regions. All company resources are tagged with a tag name of “application” and a value that corresponds to each application. A solutions architect must provide the quickest solution for identifying all of the tagged components. Which solution meets these requirements?",
    "options_en": {
      "A": "Use AWS CloudTrail to generate a list of resources with the application tag.",
      "B": "Use the AWS CLI to query each service across all Regions to report the tagged components.",
      "C": "Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag.",
      "D": "Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管多个生产应用程序。其中一个应用程序包含来自 Amazon EC2、AWS Lambda、Amazon RDS、Amazon Simple Notification Service (Amazon SNS) 和 Amazon Simple Queue Service (Amazon SQS) 的资源，这些资源分布在多个 AWS 区域。所有公司资源都使用标签名称“application”进行标记，其值对应于每个应用程序。解决方案架构师必须提供最快的解决方案来识别所有标记的组件。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS CloudTrail 生成带有 application 标签的资源列表。",
      "B": "使用 AWS CLI 查询所有区域中的每个服务，以报告标记的组件。",
      "C": "在 Amazon CloudWatch Logs Insights 中运行查询，以报告带有 application 标签的组件。",
      "D": "使用 AWS Resource Groups Tag Editor 运行查询，以全局报告带有 application 标签的资源。"
    }
  },
  {
    "id": 212,
    "topic": "1",
    "question_en": "A company needs to export its database once a day to Amazon S3 for other teams to access. The exported object size varies between 2 GB and 5 GB. The S3 access pattern for the data is variable and changes rapidly. The data must be immediately available and must remain accessible for up to 3 months. The company needs the most cost-effective solution that will not increase retrieval time. Which S3 storage class should the company use to meet these requirements?",
    "options_en": {
      "A": "S3 Intelligent-Tiering",
      "B": "S3 Glacier Instant Retrieval",
      "C": "S3 Standard",
      "D": "S3 Standard-Infrequent Access (S3 Standard-IA)"
    },
    "correct_answer": "A",
    "vote_percentage": "75%",
    "question_cn": "一家公司需要每天将数据库导出到 Amazon S3，供其他团队访问。 导出的对象大小在 2 GB 到 5 GB 之间变化。 数据的 S3 访问模式是可变的，并且变化迅速。 数据必须立即可用，并且必须保持可访问长达 3 个月。该公司需要最具成本效益的解决方案，且不会增加检索时间。该公司应该使用哪个 S3 存储类来满足这些要求？",
    "options_cn": {
      "A": "S3 Intelligent-Tiering",
      "B": "S3 Glacier Instant Retrieval",
      "C": "S3 Standard",
      "D": "S3 Standard-Infrequent Access (S3 Standard-IA)"
    }
  },
  {
    "id": 213,
    "topic": "1",
    "question_en": "A company is developing a new mobile app. The company must implement proper trafic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection. The company has minimal infrastructure and operational staff. The company needs to reduce its share of the responsibility in managing, updating, and securing servers for its AWS environment. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Configure AWS WAF rules and associate them with the ALB.",
      "B": "Deploy the application using Amazon S3 with public hosting enabled.",
      "C": "Deploy AWS Shield Advanced and add the ALB as a protected resource.",
      "D": "Create a new ALB that directs trafic to an Amazon EC2 instance running a third-party firewall, which then passes the trafic to the current ALB."
    },
    "correct_answer": "A",
    "vote_percentage": "72%",
    "question_cn": "一家公司正在开发一个新的移动应用程序。该公司必须实施适当的流量过滤，以保护其 Application Load Balancer (ALB) 免受常见的应用程序级攻击，例如跨站点脚本或 SQL 注入。该公司拥有最少的基础设施和运营人员。该公司需要减少其在管理、更新和保护其 AWS 环境服务器方面的责任份额。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "配置 AWS WAF 规则并将它们与 ALB 关联。",
      "B": "使用启用公共托管的 Amazon S3 部署应用程序。",
      "C": "部署 AWS Shield Advanced 并将 ALB 添加为受保护的资源。",
      "D": "创建一个新的 ALB，将流量定向到运行第三方防火墙的 Amazon EC2 实例，然后该实例将流量传递给当前的 ALB。"
    }
  },
  {
    "id": 214,
    "topic": "1",
    "question_en": "A company’s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.",
      "B": "Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.",
      "C": "Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type.",
      "D": "Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司的报告系统每天向 Amazon S3 存储桶交付数百个 .csv 文件。该公司必须将这些文件转换为 Apache Parquet 格式，并且必须将文件存储在转换后的数据存储桶中。哪种解决方案将以最少的开发工作量满足这些要求？",
    "options_cn": {
      "A": "创建一个安装了 Apache Spark 的 Amazon EMR 集群。编写一个 Spark 应用程序来转换数据。使用 EMR File System (EMRFS) 将文件写入转换后的数据存储桶。",
      "B": "创建一个 AWS Glue 爬虫来发现数据。创建一个 AWS Glue 提取、转换和加载 (ETL) 作业来转换数据。在输出步骤中指定转换后的数据存储桶。",
      "C": "使用 AWS Batch 创建一个具有 Bash 语法的作业定义来转换数据，并将数据输出到转换后的数据存储桶。使用作业定义提交一个作业。将数组作业指定为作业类型。",
      "D": "创建一个 AWS Lambda 函数来转换数据并将数据输出到转换后的数据存储桶。为 S3 存储桶配置事件通知。将 Lambda 函数指定为事件通知的目标。"
    }
  },
  {
    "id": 215,
    "topic": "1",
    "question_en": "A company has 700 TB of backup data stored in network attached storage (NAS) in its data center. This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer. What should a solutions architect do to migrate and store the data at the LOWEST cost?",
    "options_en": {
      "A": "Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.",
      "B": "Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on premises to Amazon S3 Glacier.",
      "C": "Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.",
      "D": "Use AWS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on- premises NAS storage to Amazon S3 Glacier."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其数据中心中拥有 700 TB 的备份数据，存储在网络附加存储 (NAS) 中。此备份数据需要能够访问，以满足不经常出现的法规请求，并且必须保留 7 年。该公司已决定将其备份数据从其数据中心迁移到 AWS。迁移必须在一个月内完成。该公司在其公共互联网连接上有 500 Mbps 的专用带宽可用于数据传输。解决方案架构师应该怎么做，以最低的成本迁移和存储数据？",
    "options_cn": {
      "A": "订购 AWS Snowball 设备来传输数据。使用生命周期策略将文件转换为 Amazon S3 Glacier Deep Archive。",
      "B": "在数据中心和 Amazon VPC 之间部署 VPN 连接。使用 AWS CLI 将数据从本地复制到 Amazon S3 Glacier。",
      "C": "配置 500 Mbps 的 AWS Direct Connect 连接，并将数据传输到 Amazon S3。使用生命周期策略将文件转换为 Amazon S3 Glacier Deep Archive。",
      "D": "使用 AWS DataSync 传输数据，并在本地部署 DataSync 代理。使用 DataSync 任务将文件从本地 NAS 存储复制到 Amazon S3 Glacier。"
    }
  },
  {
    "id": 216,
    "topic": "1",
    "question_en": "A company has a serverless website with millions of objects in an Amazon S3 bucket. The company uses the S3 bucket as the origin for an Amazon CloudFront distribution. The company did not set encryption on the S3 bucket before the objects were loaded. A solutions architect needs to enable encryption for all existing objects and for all objects that are added to the S3 bucket in the future. Which solution will meet these requirements with the LEAST amount of effort?",
    "options_en": {
      "A": "Create a new S3 bucket. Turn on the default encryption settings for the new S3 bucket. Download all existing objects to temporary local storage. Upload the objects to the new S3 bucket.",
      "B": "Turn on the default encryption settings for the S3 bucket. Use the S3 Inventory feature to create a .csv file that lists the unencrypted objects. Run an S3 Batch Operations job that uses the copy command to encrypt those objects.",
      "C": "Create a new encryption key by using AWS Key Management Service (AWS KMS). Change the settings on the S3 bucket to use server- side encryption with AWS KMS managed encryption keys (SSE-KMS). Turn on versioning for the S3 bucket.",
      "D": "Navigate to Amazon S3 in the AWS Management Console. Browse the S3 bucket’s objects. Sort by the encryption field. Select each unencrypted object. Use the Modify button to apply default encryption settings to every unencrypted object in the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一家公司拥有一个无服务器网站，其 Amazon S3 存储桶中存储了数百万个对象。该公司使用 S3 存储桶作为 Amazon CloudFront 分配的源。在加载对象之前，该公司未在 S3 存储桶上设置加密。一位解决方案架构师需要为所有现有对象以及将来添加到 S3 存储桶中的所有对象启用加密。哪种解决方案将以最少的精力满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 S3 存储桶。为新的 S3 存储桶打开默认加密设置。将所有现有对象下载到临时的本地存储。将对象上传到新的 S3 存储桶。",
      "B": "为 S3 存储桶打开默认加密设置。使用 S3 库存功能创建.csv 文件，列出未加密的对象。运行一个 S3 批量操作作业，该作业使用复制命令对这些对象进行加密。",
      "C": "使用 AWS Key Management Service (AWS KMS) 创建一个新的加密密钥。更改 S3 存储桶上的设置以使用带有 AWS KMS 托管加密密钥 (SSE-KMS) 的服务器端加密。为 S3 存储桶打开版本控制。",
      "D": "在 AWS 管理控制台中导航到 Amazon S3。浏览 S3 存储桶的对象。按加密字段排序。选择每个未加密的对象。使用“修改”按钮将默认加密设置应用于 S3 存储桶中的每个未加密对象。"
    }
  },
  {
    "id": 217,
    "topic": "1",
    "question_en": "A company runs a global web application on Amazon EC2 instances behind an Application Load Balancer. The application stores data in Amazon Aurora. The company needs to create a disaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.",
      "B": "Host a scaled-down deployment of the application in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora Replica in the second Region.",
      "C": "Replicate the primary infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora database that is restored from the latest snapshot.",
      "D": "Back up data with AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-passive failover. Create an Aurora second primary instance in the second Region."
    },
    "correct_answer": "D",
    "vote_percentage": "70%",
    "question_cn": "一家公司在Application Load Balancer后面的Amazon EC2实例上运行一个全球Web应用程序。该应用程序将数据存储在Amazon Aurora中。该公司需要创建一个灾难恢复解决方案，并且可以容忍长达30分钟的停机时间和潜在的数据丢失。当主要基础设施正常运行时，该解决方案不需要处理负载。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "部署具有所需基础设施元素的应用程序。使用Amazon Route 53配置主动-被动故障转移。在第二个AWS区域中创建一个Aurora副本。",
      "B": "在第二个AWS区域中托管一个缩减规模的应用程序部署。使用Amazon Route 53配置主动-主动故障转移。在第二个区域中创建一个Aurora副本。",
      "C": "在第二个AWS区域中复制主要基础设施。使用Amazon Route 53配置主动-主动故障转移。创建一个从最新快照还原的Aurora数据库。",
      "D": "使用AWS Backup备份数据。使用备份在第二个AWS区域中创建所需的基础设施。使用Amazon Route 53配置主动-被动故障转移。在第二个区域中创建一个Aurora第二个主实例。"
    }
  },
  {
    "id": 218,
    "topic": "1",
    "question_en": "A company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address. The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all trafic. A solutions architect needs to make the web server accessible from everywhere on port 443. Which combination of steps will accomplish this task? (Choose two.)",
    "options_en": {
      "A": "Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.",
      "B": "Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.",
      "C": "Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.",
      "D": "Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0",
      "E": "Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在公共子网中的 Amazon EC2 实例上运行一个 Web 服务器，该实例具有弹性 IP 地址。默认安全组已分配给 EC2 实例。默认网络 ACL 已被修改以阻止所有流量。解决方案架构师需要使 Web 服务器可以通过端口 443 从任何地方访问。哪两种步骤组合可以完成此任务？（选择两个。）",
    "options_cn": {
      "A": "创建一个安全组，其规则允许来自源 0.0.0.0/0 的 TCP 端口 443。",
      "B": "创建一个安全组，其规则允许到目标 0.0.0.0/0 的 TCP 端口 443。",
      "C": "更新网络 ACL 以允许来自源 0.0.0.0/0 的 TCP 端口 443。",
      "D": "更新网络 ACL 以允许来自源 0.0.0.0/0 和到目标 0.0.0.0/0 的入站/出站 TCP 端口 443。",
      "E": "更新网络 ACL 以允许来自源 0.0.0.0/0 的入站 TCP 端口 443 以及到目标 0.0.0.0/0 的出站 TCP 端口 32768-65535。"
    }
  },
  {
    "id": 219,
    "topic": "1",
    "question_en": "A company’s application is having performance issues. The application is stateful and needs to complete in-memory tasks on Amazon EC2 instances. The company used AWS CloudFormation to deploy infrastructure and used the M5 EC2 instance family. As trafic increased, the application performance degraded. Users are reporting delays when the users attempt to access the application. Which solution will resolve these issues in the MOST operationally eficient way?",
    "options_en": {
      "A": "Replace the EC2 instances with T3 EC2 instances that run in an Auto Scaling group. Make the changes by using the AWS Management Console.",
      "B": "Modify the CloudFormation templates to run the EC2 instances in an Auto Scaling group. Increase the desired capacity and the maximum capacity of the Auto Scaling group manually when an increase is necessary.",
      "C": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use Amazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning.",
      "D": "Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning."
    },
    "correct_answer": "D",
    "vote_percentage": "97%",
    "question_cn": "一家公司的应用程序遇到了性能问题。该应用程序是有状态的，需要在 Amazon EC2 实例上完成内存任务。该公司使用 AWS CloudFormation 部署基础设施，并使用了 M5 EC2 实例系列。随着流量的增加，应用程序的性能下降。用户报告在尝试访问应用程序时出现延迟。哪种解决方案将以最具运营效率的方式解决这些问题？",
    "options_cn": {
      "A": "将 EC2 实例替换为在 Auto Scaling 组中运行的 T3 EC2 实例。通过使用 AWS 管理控制台进行更改。",
      "B": "修改 CloudFormation 模板以在 Auto Scaling 组中运行 EC2 实例。当需要增加时，手动增加 Auto Scaling 组的所需容量和最大容量。",
      "C": "修改 CloudFormation 模板。将 EC2 实例替换为 R5 EC2 实例。使用 Amazon CloudWatch 内置的 EC2 内存指标来跟踪应用程序性能，以进行未来的容量规划。",
      "D": "修改 CloudFormation 模板。将 EC2 实例替换为 R5 EC2 实例。在 EC2 实例上部署 Amazon CloudWatch 代理，以生成自定义应用程序延迟指标，用于未来的容量规划。"
    }
  },
  {
    "id": 220,
    "topic": "1",
    "question_en": "A solutions architect is designing a new API using Amazon API Gateway that will receive requests from users. The volume of requests is highly variable; several hours can pass without receiving a single request. The data processing will take place asynchronously, but should be completed within a few seconds after a request is made. Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?",
    "options_en": {
      "A": "An AWS Glue job",
      "B": "An AWS Lambda function",
      "C": "A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS)",
      "D": "A containerized service hosted in Amazon ECS with Amazon EC2"
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一个解决方案架构师正在使用 Amazon API Gateway 设计一个新的 API，该 API 将接收来自用户的请求。请求量变化很大；几个小时内可能没有收到任何请求。数据处理将异步进行，但应在发出请求后的几秒钟内完成。解决方案架构师应该让 API 调用哪个计算服务以最低成本交付需求？",
    "options_cn": {
      "A": "一个 AWS Glue 作业",
      "B": "一个 AWS Lambda 函数",
      "C": "托管在 Amazon Elastic Kubernetes Service (Amazon EKS) 中的容器化服务",
      "D": "托管在 Amazon ECS 与 Amazon EC2 中的容器化服务"
    }
  },
  {
    "id": 221,
    "topic": "1",
    "question_en": "A company runs an application on a group of Amazon Linux EC2 instances. For compliance reasons, the company must retain all application log files for 7 years. The log files will be analyzed by a reporting tool that must be able to access all the files concurrently. Which storage solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Amazon Elastic Block Store (Amazon EBS)",
      "B": "Amazon Elastic File System (Amazon EFS)",
      "C": "Amazon EC2 instance store",
      "D": "Amazon S3"
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Amazon Linux EC2 实例组上运行一个应用程序。出于合规性原因，该公司必须将所有应用程序日志文件保留 7 年。这些日志文件将由一个报告工具进行分析，该工具必须能够同时访问所有文件。哪种存储解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "Amazon Elastic Block Store (Amazon EBS)",
      "B": "Amazon Elastic File System (Amazon EFS)",
      "C": "Amazon EC2 实例存储",
      "D": "Amazon S3"
    }
  },
  {
    "id": 222,
    "topic": "1",
    "question_en": "A company has hired an external vendor to perform work in the company’s AWS account. The vendor uses an automated tool that is hosted in an AWS account that the vendor owns. The vendor does not have IAM access to the company’s AWS account. How should a solutions architect grant this access to the vendor?",
    "options_en": {
      "A": "Create an IAM role in the company’s account to delegate access to the vendor’s IAM role. Attach the appropriate IAM policies to the role for the permissions that the vendor requires.",
      "B": "Create an IAM user in the company’s account with a password that meets the password complexity requirements. Attach the appropriate IAM policies to the user for the permissions that the vendor requires.",
      "C": "Create an IAM group in the company’s account. Add the tool’s IAM user from the vendor account to the group. Attach the appropriate IAM policies to the group for the permissions that the vendor requires.",
      "D": "Create a new identity provider by choosing “AWS account” as the provider type in the IAM console. Supply the vendor’s AWS account ID and user name. Attach the appropriate IAM policies to the new provider for the permissions that the vendor requires."
    },
    "correct_answer": "A",
    "vote_percentage": "87%",
    "question_cn": "一家公司聘请了一家外部供应商在其公司的 AWS 账户中执行工作。该供应商使用托管在其拥有的 AWS 账户中的自动化工具。该供应商无法访问公司 AWS 账户的 IAM。解决方案架构师应如何授予供应商此访问权限？",
    "options_cn": {
      "A": "在公司的账户中创建一个 IAM 角色，以将访问权限委派给供应商的 IAM 角色。将适当的 IAM 策略附加到该角色，以获取供应商所需的权限。",
      "B": "在公司的账户中创建一个 IAM 用户，该用户的密码符合密码复杂性要求。将适当的 IAM 策略附加到该用户，以获取供应商所需的权限。",
      "C": "在公司的账户中创建一个 IAM 组。将供应商账户中的工具的 IAM 用户添加到该组。将适当的 IAM 策略附加到该组，以获取供应商所需的权限。",
      "D": "通过在 IAM 控制台中选择“AWS 账户”作为提供商类型，创建一个新的身份提供商。提供供应商的 AWS 账户 ID 和用户名。将适当的 IAM 策略附加到新的提供商，以获取供应商所需的权限。"
    }
  },
  {
    "id": 223,
    "topic": "1",
    "question_en": "A company has deployed a Java Spring Boot application as a pod that runs on Amazon Elastic Kubernetes Service (Amazon EKS) in private subnets. The application needs to write data to an Amazon DynamoDB table. A solutions architect must ensure that the application can interact with the DynamoDB table without exposing trafic to the internet. Which combination of steps should the solutions architect take to accomplish this goal? (Choose two.)",
    "options_en": {
      "A": "Attach an IAM role that has suficient privileges to the EKS pod.",
      "B": "Attach an IAM user that has suficient privileges to the EKS pod.",
      "C": "Allow outbound connectivity to the DynamoDB table through the private subnets’ network ACLs.",
      "D": "Create a VPC endpoint for DynamoDB",
      "E": "Embed the access keys in the Java Spring Boot code."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司已将 Java Spring Boot 应用程序部署为在私有子网中的 Amazon Elastic Kubernetes Service (Amazon EKS) 上运行的 pod。该应用程序需要将数据写入 Amazon DynamoDB 表。解决方案架构师必须确保该应用程序可以与 DynamoDB 表交互，而不会将流量暴露到互联网。解决方案架构师应采取哪些步骤组合来实现此目标？（选择两项。）",
    "options_cn": {
      "A": "将具有足够权限的 IAM 角色附加到 EKS pod。",
      "B": "将具有足够权限的 IAM 用户附加到 EKS pod。",
      "C": "允许通过私有子网的网卡 ACL 对 DynamoDB 表进行出站连接。",
      "D": "为 DynamoDB 创建一个 VPC endpoint。",
      "E": "将访问密钥嵌入到 Java Spring Boot 代码中。"
    }
  },
  {
    "id": 224,
    "topic": "1",
    "question_en": "A company recently migrated its web application to AWS by rehosting the application on Amazon EC2 instances in a single AWS Region. The company wants to redesign its application architecture to be highly available and fault tolerant. Trafic must reach all running EC2 instances randomly. Which combination of steps should the company take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon Route 53 failover routing policy.",
      "B": "Create an Amazon Route 53 weighted routing policy.",
      "C": "Create an Amazon Route 53 multivalue answer routing policy.",
      "D": "Launch three EC2 instances: two instances in one Availability Zone and one instance in another Availability Zon",
      "E": "E. Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司最近通过在单个 AWS 区域中的 Amazon EC2 实例上重新托管应用程序，将其 Web 应用程序迁移到了 AWS。该公司希望重新设计其应用程序架构，使其具有高可用性和容错性。流量必须随机到达所有正在运行的 EC2 实例。该公司应采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建 Amazon Route 53 故障转移路由策略。",
      "B": "创建 Amazon Route 53 加权路由策略。",
      "C": "创建 Amazon Route 53 多值应答路由策略。",
      "D": "启动三个 EC2 实例：两个实例在一个可用区中，一个实例在另一个可用区中。",
      "E": "启动四个 EC2 实例：两个实例在一个可用区中，两个实例在另一个可用区中。"
    }
  },
  {
    "id": 225,
    "topic": "1",
    "question_en": "A media company collects and analyzes user activity data on premises. The company wants to migrate this capability to AWS. The user activity data store will continue to grow and will be petabytes in size. The company needs to build a highly available data ingestion solution that facilitates on-demand analytics of existing data and new data with SQL. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Send activity data to an Amazon Kinesis data stream. Configure the stream to deliver the data to an Amazon S3 bucket.",
      "B": "Send activity data to an Amazon Kinesis Data Firehose delivery stream. Configure the stream to deliver the data to an Amazon Redshift cluster.",
      "C": "Place activity data in an Amazon S3 bucket. Configure Amazon S3 to run an AWS Lambda function on the data as the data arrives in the S3 bucket.",
      "D": "Create an ingestion service on Amazon EC2 instances that are spread across multiple Availability Zones. Configure the service to forward data to an Amazon RDS Multi-AZ database."
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一家媒体公司在其内部部署中收集和分析用户活动数据。该公司希望将此功能迁移到 AWS。用户活动数据存储将持续增长，并将达到 PB 级别。该公司需要构建一个高可用性的数据摄取解决方案，该解决方案能够使用 SQL 对现有数据和新数据进行按需分析。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将活动数据发送到 Amazon Kinesis 数据流。配置该数据流将数据传送到 Amazon S3 存储桶。",
      "B": "将活动数据发送到 Amazon Kinesis Data Firehose 交付流。配置该流将数据传送到 Amazon Redshift 集群。",
      "C": "将活动数据放入 Amazon S3 存储桶。配置 Amazon S3 在数据到达 S3 存储桶时，对数据运行 AWS Lambda 函数。",
      "D": "在分布在多个可用区中的 Amazon EC2 实例上创建一个摄取服务。配置该服务将数据转发到 Amazon RDS 多可用区数据库。"
    }
  },
  {
    "id": 226,
    "topic": "1",
    "question_en": "A company collects data from thousands of remote devices by using a RESTful web services application that runs on an Amazon EC2 instance. The EC2 instance receives the raw data, transforms the raw data, and stores all the data in an Amazon S3 bucket. The number of remote devices will increase into the millions soon. The company needs a highly scalable solution that minimizes operational overhead. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Glue to process the raw data in Amazon S3.",
      "B": "Use Amazon Route 53 to route trafic to different EC2 instances.",
      "C": "Add more EC2 instances to accommodate the increasing amount of incoming data.",
      "D": "Send the raw data to Amazon Simple Queue Service (Amazon SQS). Use EC2 instances to process the data",
      "E": "Use Amazon API Gateway to send the raw data to an Amazon Kinesis data stream. Configure Amazon Kinesis Data Firehose to use the data stream as a source to deliver the data to Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司通过运行在 Amazon EC2 实例上的 RESTful Web 服务应用程序，从数千个远程设备收集数据。EC2 实例接收原始数据，转换原始数据，并将所有数据存储在 Amazon S3 存储桶中。远程设备的数量很快将增加到数百万。该公司需要一个高度可扩展的解决方案，以最大限度地减少运营开销。解决方案架构师应采取哪些步骤组合来满足这些要求？（选择两个）",
    "options_cn": {
      "A": "使用 AWS Glue 处理 Amazon S3 中的原始数据。",
      "B": "使用 Amazon Route 53 将流量路由到不同的 EC2 实例。",
      "C": "添加更多 EC2 实例以适应不断增加的传入数据量。",
      "D": "将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例处理数据。",
      "E": "使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流。配置 Amazon Kinesis Data Firehose 以使用该数据流作为 将数据传输到 Amazon S3 的 源。"
    }
  },
  {
    "id": 227,
    "topic": "1",
    "question_en": "A company needs to retain its AWS CloudTrail logs for 3 years. The company is enforcing CloudTrail across a set of AWS accounts by using AWS Organizations from the parent account. The CloudTrail target S3 bucket is configured with S3 Versioning enabled. An S3 Lifecycle policy is in place to delete current objects after 3 years. After the fourth year of use of the S3 bucket, the S3 bucket metrics show that the number of objects has continued to rise. However, the number of new CloudTrail logs that are delivered to the S3 bucket has remained consistent. Which solution will delete objects that are older than 3 years in the MOST cost-effective manner?",
    "options_en": {
      "A": "Configure the organization’s centralized CloudTrail trail to expire objects after 3 years.",
      "B": "Configure the S3 Lifecycle policy to delete previous versions as well as current versions.",
      "C": "Create an AWS Lambda function to enumerate and delete objects from Amazon S3 that are older than 3 years.",
      "D": "Configure the parent account as the owner of all objects that are delivered to the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "91%",
    "question_cn": "一家公司需要保留其 AWS CloudTrail 日志 3 年。该公司正在使用父账户的 AWS Organizations 在一组 AWS 账户中强制执行 CloudTrail。CloudTrail 目标 S3 存储桶配置了 S3 版本控制。已设置 S3 生命周期策略，在 3 年后删除当前对象。在使用 S3 存储桶的第四年之后，S3 存储桶指标显示对象的数量持续增加。但是，交付到 S3 存储桶的新 CloudTrail 日志的数量保持一致。哪种解决方案将以最具成本效益的方式删除超过 3 年的对象？",
    "options_cn": {
      "A": "配置该组织的集中 CloudTrail 跟踪，以便在 3 年后过期对象。",
      "B": "配置 S3 生命周期策略以删除以前的版本以及当前版本。",
      "C": "创建一个 AWS Lambda 函数，用于枚举并从 Amazon S3 中删除超过 3 年的对象。",
      "D": "将父账户配置为交付到 S3 存储桶的所有对象的拥有者。"
    }
  },
  {
    "id": 228,
    "topic": "1",
    "question_en": "A company has an API that receives real-time data from a fieet of monitoring devices. The API stores this data in an Amazon RDS DB instance for later analysis. The amount of data that the monitoring devices send to the API fiuctuates. During periods of heavy trafic, the API often returns timeout errors. After an inspection of the logs, the company determines that the database is not capable of processing the volume of write trafic that comes from the API. A solutions architect must minimize the number of connections to the database and must ensure that data is not lost during periods of heavy trafic. Which solution will meet these requirements?",
    "options_en": {
      "A": "Increase the size of the DB instance to an instance type that has more available memory.",
      "B": "Modify the DB instance to be a Multi-AZ DB instance. Configure the application to write to all active RDS DB instances.",
      "C": "Modify the API to write incoming data to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function that Amazon SQS invokes to write data from the queue to the database.",
      "D": "Modify the API to write incoming data to an Amazon Simple Notification Service (Amazon SNS) topic. Use an AWS Lambda function that Amazon SNS invokes to write data from the topic to the database."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个 API，用于接收来自一组监控设备的实时数据。该 API 将这些数据存储在 Amazon RDS 数据库实例中，以供以后分析。监控设备发送到 API 的数据量会波动。在流量高峰期间，API 经常会返回超时错误。在检查日志后，该公司确定数据库无法处理来自 API 的写入流量量。解决方案架构师必须最大限度地减少与数据库的连接数，并必须确保在流量高峰期间数据不会丢失。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将数据库实例的大小增加到具有更多可用内存的实例类型。",
      "B": "修改数据库实例，使其成为多可用区数据库实例。将应用程序配置为写入所有活动的 RDS 数据库实例。",
      "C": "修改 API，将传入数据写入 Amazon Simple Queue Service (Amazon SQS) 队列。使用 AWS Lambda 函数，该函数由 Amazon SQS 调用，用于将数据从队列写入数据库。",
      "D": "修改 API，将传入数据写入 Amazon Simple Notification Service (Amazon SNS) 主题。使用 AWS Lambda 函数，该函数由 Amazon SNS 调用，用于将数据从主题写入数据库。"
    }
  },
  {
    "id": 229,
    "topic": "1",
    "question_en": "A company manages its own Amazon EC2 instances that run MySQL databases. The company is manually managing replication and scaling as demand increases or decreases. The company needs a new solution that simplifies the process of adding or removing compute capacity to or from its database tier as needed. The solution also must offer improved performance, scaling, and durability with minimal effort from operations. Which solution meets these requirements?",
    "options_en": {
      "A": "Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.",
      "B": "Migrate the databases to Amazon Aurora Serverless for Aurora PostgreSQL.",
      "C": "Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.",
      "D": "Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司管理运行 MySQL 数据库的 Amazon EC2 实例。当需求增加或减少时，该公司手动管理复制和扩展。该公司需要一个新解决方案，以简化根据需要向其数据库层添加或删除计算容量的过程。该解决方案还必须提供改进的性能、扩展能力和耐用性，同时尽量减少运营工作量。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon Aurora Serverless for Aurora MySQL。",
      "B": "将数据库迁移到 Amazon Aurora Serverless for Aurora PostgreSQL。",
      "C": "将数据库合并到一个更大的 MySQL 数据库中。在更大的 EC2 实例上运行更大的数据库。",
      "D": "为数据库层创建一个 EC2 Auto Scaling 组。将现有数据库迁移到新环境。"
    }
  },
  {
    "id": 230,
    "topic": "1",
    "question_en": "A company is concerned that two NAT instances in use will no longer be able to support the trafic needed for the company’s application. A solutions architect wants to implement a solution that is highly available, fault tolerant, and automatically scalable. What should the solutions architect recommend?",
    "options_en": {
      "A": "Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone.",
      "B": "Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones.",
      "C": "Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.",
      "D": "Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer."
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一家公司担心正在使用的两个 NAT 实例将无法再支持公司应用程序所需的流量。解决方案架构师希望实施一个具有高可用性、容错能力和自动伸缩性的解决方案。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "删除这两个 NAT 实例，并在同一可用区中用两个 NAT 网关替换它们。",
      "B": "对不同可用区中的 NAT 实例使用带有网络负载均衡器的 Auto Scaling 组。",
      "C": "删除这两个 NAT 实例，并在不同可用区中用两个 NAT 网关替换它们。",
      "D": "用不同可用区中的 Spot 实例替换这两个 NAT 实例，并部署网络负载均衡器。"
    }
  },
  {
    "id": 231,
    "topic": "1",
    "question_en": "An application runs on an Amazon EC2 instance that has an Elastic IP address in VPC A. The application requires access to a database in VPC",
    "options_en": {
      "B": "Configure a VPC peering connection between VPC A and VPC B.",
      "A": "Create a DB instance security group that allows all trafic from the public IP address of the application server in VPC A.",
      "C": "Make the DB instance publicly accessible. Assign a public IP address to the DB instance.",
      "D": "Launch an EC2 instance with an Elastic IP address into VPC B. Proxy all requests through the new EC2 instance."
    },
    "correct_answer": "B",
    "vote_percentage": "88%",
    "question_cn": "一个应用程序运行在 VPC A 中的一个具有弹性 IP 地址的 Amazon EC2 实例上。该应用程序需要访问 VPC B 中的一个数据库。以下哪项解决方案可以满足此要求？",
    "options_cn": {
      "A": "创建一个数据库实例安全组，允许来自 VPC A 中应用程序服务器的公共 IP 地址的所有流量。",
      "B": "在 VPC A 和 VPC B 之间配置一个 VPC 对等连接。",
      "C": "使数据库实例可公开访问。为数据库实例分配一个公共 IP 地址。",
      "D": "将一个带有弹性 IP 地址的 EC2 实例启动到 VPC B 中。通过新的 EC2 实例代理所有请求。"
    }
  },
  {
    "id": 232,
    "topic": "1",
    "question_en": "A company runs demonstration environments for its customers on Amazon EC2 instances. Each environment is isolated in its own VPC. The company’s operations team needs to be notified when RDP or SSH access to an environment has been established.",
    "options_en": {
      "A": "Configure Amazon CloudWatch Application Insights to create AWS Systems Manager OpsItems when RDP or SSH access is detected.",
      "B": "Configure the EC2 instances with an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore policy attached.",
      "C": "Publish VPC fiow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state.",
      "D": "Configure an Amazon EventBridge rule to listen for events of type EC2 Instance State-change Notification. Configure an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the operations team to the topic."
    },
    "correct_answer": "C",
    "vote_percentage": "79%",
    "question_cn": "一家公司在其客户的 Amazon EC2 实例上运行演示环境。每个环境都隔离在其自己的 VPC 中。该公司运营团队需要在检测到 RDP 或 SSH 访问环境时收到通知。",
    "options_cn": {
      "A": "配置 Amazon CloudWatch Application Insights，以便在检测到 RDP 或 SSH 访问时创建 AWS Systems Manager OpsItems。",
      "B": "使用 IAM 实例配置文件配置 EC2 实例，该配置文件具有附加了 AmazonSSMManagedInstanceCore 策略的 IAM 角色。",
      "C": "将 VPC 流日志发布到 Amazon CloudWatch Logs。创建所需的指标筛选器。创建一个 Amazon CloudWatch 指标警报，当警报处于 ALARM 状态时，具有通知操作。",
      "D": "配置一个 Amazon EventBridge 规则来监听 EC2 实例状态更改通知类型的事件。配置一个 Amazon Simple Notification Service (Amazon SNS) 主题作为目标。将运营团队订阅到该主题。"
    }
  },
  {
    "id": 233,
    "topic": "1",
    "question_en": "A solutions architect has created a new AWS account and must secure AWS account root user access. Which combination of actions will accomplish this? (Choose two.)",
    "options_en": {
      "A": "Ensure the root user uses a strong password.",
      "B": "Enable multi-factor authentication to the root user.",
      "C": "Store root user access keys in an encrypted Amazon S3 bucket.",
      "D": "Add the root user to a group containing administrative permissions",
      "E": "Apply the required permissions to the root user with an inline policy document."
    },
    "correct_answer": "A",
    "vote_percentage": "79%",
    "question_cn": "一位解决方案架构师创建了一个新的 AWS 账户，并且必须保护 AWS 账户根用户的访问。哪两种操作的组合将实现此目的？（选择两项。）",
    "options_cn": {
      "A": "确保根用户使用强密码。",
      "B": "为根用户启用多因素身份验证。",
      "C": "将根用户访问密钥存储在加密的 Amazon S3 存储桶中。",
      "D": "将根用户添加到包含管理权限的组中。",
      "E": "使用内联策略文档将所需权限应用于根用户。"
    }
  },
  {
    "id": 234,
    "topic": "1",
    "question_en": "A company is building a new web-based customer relationship management application. The application will use several Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS) volumes behind an Application Load Balancer (ALB). The application will also use an Amazon Aurora database. All data for the application must be encrypted at rest and in transit. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Key Management Service (AWS KMS) certificates on the ALB to encrypt data in transit. Use AWS Certificate Manager (ACM) to encrypt the EBS volumes and Aurora database storage at rest.",
      "B": "Use the AWS root account to log in to the AWS Management Console. Upload the company’s encryption certificates. While in the root account, select the option to turn on encryption for all data at rest and in transit for the account.",
      "C": "Use AWS Key Management Service (AWS KMS) to encrypt the EBS volumes and Aurora database storage at rest. Attach an AWS Certificate Manager (ACM) certificate to the ALB to encrypt data in transit.",
      "D": "Use BitLocker to encrypt all data at rest. Import the company’s TLS certificate keys to AWS Key Management Service (AWS KMS) Attach the KMS keys to the ALB to encrypt data in transit."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在构建一个新的基于 Web 的客户关系管理应用程序。该应用程序将使用几个 Amazon EC2 实例，这些实例由 Application Load Balancer (ALB) 后面的 Amazon Elastic Block Store (Amazon EBS) 卷提供支持。该应用程序还将使用 Amazon Aurora 数据库。该应用程序的所有数据都必须在静态和传输过程中加密。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 ALB 上使用 AWS Key Management Service (AWS KMS) 证书来加密传输中的数据。使用 AWS Certificate Manager (ACM) 加密 EBS 卷和 Aurora 数据库存储的静态数据。",
      "B": "使用 AWS 根账户登录 AWS Management Console。上传公司的加密证书。在根账户中，选择打开账户所有静态和传输数据加密的选项。",
      "C": "使用 AWS Key Management Service (AWS KMS) 加密 EBS 卷和 Aurora 数据库存储的静态数据。将 AWS Certificate Manager (ACM) 证书附加到 ALB 以加密传输中的数据。",
      "D": "使用 BitLocker 加密所有静态数据。将公司的 TLS 证书密钥导入 AWS Key Management Service (AWS KMS)。将 KMS 密钥附加到 ALB 以加密传输中的数据。"
    }
  },
  {
    "id": 235,
    "topic": "1",
    "question_en": "A company is moving its on-premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables. The applications need to be migrated one by one with a month in between each migration. Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration. What should a solutions architect recommend?",
    "options_en": {
      "A": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables.",
      "B": "Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
      "C": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.",
      "D": "Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables."
    },
    "correct_answer": "C",
    "vote_percentage": "90%",
    "question_cn": "一家公司正在将其本地 Oracle 数据库迁移到 Amazon Aurora PostgreSQL。该数据库有多个应用程序写入相同的表。这些应用程序需要逐个迁移，每次迁移之间间隔一个月。管理层表示担心数据库的读写次数很高。在整个迁移过程中，数据必须在两个数据库之间保持同步。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "使用 AWS DataSync 进行初始迁移。使用 AWS Database Migration Service (AWS DMS) 创建一个更改数据捕获 (CDC) 复制任务和一个表映射，以选择所有表。",
      "B": "使用 AWS DataSync 进行初始迁移。使用 AWS Database Migration Service (AWS DMS) 创建一个完整加载加上更改数据捕获 (CDC) 复制任务和一个表映射，以选择所有表。",
      "C": "使用 AWS Schema Conversion Tool 和 AWS Database Migration Service (AWS DMS)，使用内存优化复制实例。创建一个完整加载加上更改数据捕获 (CDC) 复制任务和一个表映射，以选择所有表。",
      "D": "使用 AWS Schema Conversion Tool 和 AWS Database Migration Service (AWS DMS)，使用计算优化复制实例。创建一个完整加载加上更改数据捕获 (CDC) 复制任务和一个表映射，以选择最大的表。"
    }
  },
  {
    "id": 236,
    "topic": "1",
    "question_en": "A company has a three-tier application for image sharing. The application uses an Amazon EC2 instance for the front-end layer, another EC2 instance for the application layer, and a third EC2 instance for a MySQL database. A solutions architect must design a scalable and highly available solution that requires the least amount of change to the application. Which solution meets these requirements?",
    "options_en": {
      "A": "Use Amazon S3 to host the front-end layer. Use AWS Lambda functions for the application layer. Move the database to an Amazon DynamoDB table. Use Amazon S3 to store and serve users’ images.",
      "B": "Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS DB instance with multiple read replicas to serve users’ images.",
      "C": "Use Amazon S3 to host the front-end layer. Use a fieet of EC2 instances in an Auto Scaling group for the application layer. Move the database to a memory optimized instance type to store and serve users’ images.",
      "D": "Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS Multi-AZ DB instance. Use Amazon S3 to store and serve users’ images."
    },
    "correct_answer": "A",
    "vote_percentage": "69%",
    "question_cn": "一家公司有一个用于图像共享的三层应用程序。该应用程序使用 Amazon EC2 实例作为前端层，另一个 EC2 实例作为应用程序层，第三个 EC2 实例用于 MySQL 数据库。解决方案架构师必须设计一个可扩展且高度可用的解决方案，该方案要求对应用程序的更改最少。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 托管前端层。使用 AWS Lambda 函数作为应用程序层。将数据库移至 Amazon DynamoDB 表。使用 Amazon S3 存储和提供用户的图像。",
      "B": "对前端层和应用程序层使用负载均衡的 Multi-AZ AWS Elastic Beanstalk 环境。将数据库移至具有多个只读副本的 Amazon RDS DB 实例，以服务用户的图像。",
      "C": "使用 Amazon S3 托管前端层。使用 Auto Scaling 组中的 EC2 实例组作为应用程序层。将数据库移至内存优化实例类型以存储和提供用户的图像。",
      "D": "对前端层和应用程序层使用负载均衡的 Multi-AZ AWS Elastic Beanstalk 环境。将数据库移至 Amazon RDS Multi-AZ DB 实例。使用 Amazon S3 存储和提供用户的图像。"
    }
  },
  {
    "id": 237,
    "topic": "1",
    "question_en": "An application running on an Amazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both VPCs are in separate AWS accounts. The network administrator needs to design a solution to configure secure access to EC2 instance in VPC-B from VPC-",
    "options_en": {
      "A": "Set up a VPC peering connection between VPC-A and VPC-B.",
      "B": "Set up VPC gateway endpoints for the EC2 instance running in VPC-B.",
      "C": "Attach a virtual private gateway to VPC-B and set up routing from VPC-A.",
      "D": "Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-A."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "在 VPC-A 中运行的 Amazon EC2 实例需要访问 VPC-B 中另一个 EC2 实例中的文件。这两个 VPC 位于不同的 AWS 账户中。网络管理员需要设计一个解决方案，以配置从 VPC-A 到 VPC-B 中 EC2 实例的安全访问。",
    "options_cn": {
      "A": "在 VPC-A 和 VPC-B 之间建立 VPC 对等连接。",
      "B": "为在 VPC-B 中运行的 EC2 实例设置 VPC 网关端点。",
      "C": "将虚拟私有网关附加到 VPC-B，并设置来自 VPC-A 的路由。",
      "D": "为在 VPC-B 中运行的 EC2 实例创建私有虚拟接口 (VIF)，并从 VPC-A 添加适当的路由。"
    }
  },
  {
    "id": 238,
    "topic": "1",
    "question_en": "A company wants to experiment with individual AWS accounts for its engineer team. The company wants to be notified as soon as the Amazon EC2 instance usage for a given month exceeds a specific threshold for each account. What should a solutions architect do to meet this requirement MOST cost-effectively?",
    "options_en": {
      "A": "Use Cost Explorer to create a daily report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.",
      "B": "Use Cost Explorer to create a monthly report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.",
      "C": "Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.",
      "D": "Use AWS Cost and Usage Reports to create a report with hourly granularity. Integrate the report data with Amazon Athena. Use Amazon EventBridge to schedule an Athena query. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded."
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一家公司希望为其工程师团队试验各个 AWS 账户。该公司希望在给定月份每个账户的 Amazon EC2 实例使用量超过特定阈值时立即收到通知。解决方案架构师应该怎么做才能以最具成本效益的方式满足此要求？",
    "options_cn": {
      "A": "使用 Cost Explorer 创建按服务划分的每日成本报告。按 EC2 实例筛选报告。配置 Cost Explorer 在超过阈值时发送 Amazon Simple Email Service (Amazon SES) 通知。",
      "B": "使用 Cost Explorer 创建按服务划分的每月成本报告。按 EC2 实例筛选报告。配置 Cost Explorer 在超过阈值时发送 Amazon Simple Email Service (Amazon SES) 通知。",
      "C": "使用 AWS Budgets 为每个账户创建成本预算。将周期设置为每月。将范围设置为 EC2 实例。为预算设置警报阈值。配置 Amazon Simple Notification Service (Amazon SNS) 主题以在超过阈值时收到通知。",
      "D": "使用 AWS Cost and Usage Reports 创建具有每小时粒度的报告。将报告数据与 Amazon Athena 集成。使用 Amazon EventBridge 安排 Athena 查询。配置 Amazon Simple Notification Service (Amazon SNS) 主题以在超过阈值时收到通知。"
    }
  },
  {
    "id": 239,
    "topic": "1",
    "question_en": "A solutions architect needs to design a new microservice for a company’s application. Clients must be able to call an HTTPS endpoint to reach the microservice. The microservice also must use AWS Identity and Access Management (IAM) to authenticate calls. The solutions architect will write the logic for this microservice by using a single AWS Lambda function that is written in Go 1.x. Which solution will deploy the function in the MOST operationally eficient way?",
    "options_en": {
      "A": "Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.",
      "B": "Create a Lambda function URL for the function. Specify AWS_IAM as the authentication type.",
      "C": "Create an Amazon CloudFront distribution. Deploy the function to Lambda@Edge. Integrate IAM authentication logic into the Lambda@Edge function.",
      "D": "Create an Amazon CloudFront distribution. Deploy the function to CloudFront Functions. Specify AWS_IAM as the authentication type."
    },
    "correct_answer": "A",
    "vote_percentage": "65%",
    "question_cn": "一位解决方案架构师需要为公司的应用程序设计一个新的微服务。客户端必须能够调用一个 HTTPS 终端节点来访问该微服务。该微服务还必须使用 AWS Identity and Access Management (IAM) 来验证调用。解决方案架构师将使用单个 AWS Lambda 函数编写此微服务的逻辑，该函数用 Go 1.x 编写。哪种解决方案将以最具操作效率的方式部署该函数？",
    "options_cn": {
      "A": "创建一个 Amazon API Gateway REST API。配置该方法以使用 Lambda 函数。在 API 上启用 IAM 身份验证。",
      "B": "为该函数创建一个 Lambda 函数 URL。指定 AWS_IAM 作为身份验证类型。",
      "C": "创建一个 Amazon CloudFront 分发。将该函数部署到 Lambda@Edge。将 IAM 身份验证逻辑集成到 Lambda@Edge 函数中。",
      "D": "创建一个 Amazon CloudFront 分发。将该函数部署到 CloudFront Functions。指定 AWS_IAM 作为身份验证类型。"
    }
  },
  {
    "id": 240,
    "topic": "1",
    "question_en": "A company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate ofice users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached. Which solution provides the LOWEST data transfer egress cost for the company?",
    "options_en": {
      "A": "Host the visualization tool on premises and query the data warehouse directly over the internet.",
      "B": "Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet.",
      "C": "Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region.",
      "D": "Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region."
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家公司先前已将其数据仓库解决方案迁移到 AWS。该公司也有一个 AWS Direct Connect 连接。公司办公室用户使用可视化工具查询数据仓库。数据仓库返回的查询平均大小为 50 MB，可视化工具发送的每个网页大约为 500 KB。数据仓库返回的结果集未被缓存。哪种解决方案为公司提供了最低的数据传输出口成本？",
    "options_cn": {
      "A": "在本地托管可视化工具，并通过互联网直接查询数据仓库。",
      "B": "在与数据仓库相同的 AWS 区域中托管可视化工具。通过互联网访问它。",
      "C": "在本地托管可视化工具，并通过 Direct Connect 连接直接查询数据仓库，该连接位于同一 AWS 区域的某个位置。",
      "D": "在与数据仓库相同的 AWS 区域中托管可视化工具，并通过位于同一区域的 Direct Connect 连接进行访问。"
    }
  },
  {
    "id": 241,
    "topic": "1",
    "question_en": "An online learning company is migrating to the AWS Cloud. The company maintains its student records in a PostgreSQL database. The company needs a solution in which its data is available and online across multiple AWS Regions at all times. Which solution will meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Migrate the PostgreSQL database to a PostgreSQL cluster on Amazon EC2 instances.",
      "B": "Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on.",
      "C": "Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.",
      "D": "Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region."
    },
    "correct_answer": "C",
    "vote_percentage": "79%",
    "question_cn": "一家在线学习公司正在迁移到 AWS 云。该公司将其学生记录保存在 PostgreSQL 数据库中。该公司需要一个解决方案，使其数据始终在多个 AWS 区域中在线可用。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将 PostgreSQL 数据库迁移到 Amazon EC2 实例上的 PostgreSQL 集群。",
      "B": "将 PostgreSQL 数据库迁移到启用了 Multi-AZ 功能的 Amazon RDS for PostgreSQL 数据库实例。",
      "C": "将 PostgreSQL 数据库迁移到 Amazon RDS for PostgreSQL 数据库实例。在另一个区域中创建只读副本。",
      "D": "将 PostgreSQL 数据库迁移到 Amazon RDS for PostgreSQL 数据库实例。设置数据库快照，将其复制到另一个区域。"
    }
  },
  {
    "id": 242,
    "topic": "1",
    "question_en": "A company hosts its web application on AWS using seven Amazon EC2 instances. The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries. Which policy should be used to meet this requirement?",
    "options_en": {
      "A": "Simple routing policy",
      "B": "Latency routing policy",
      "C": "Multivalue routing policy",
      "D": "Geolocation routing policy"
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一家公司使用七个 Amazon EC2 实例在 AWS 上托管其 Web 应用程序。该公司要求在 DNS 查询的响应中返回所有运行正常的 EC2 实例的 IP 地址。应使用哪种策略来满足此要求？",
    "options_cn": {
      "A": "简单路由策略",
      "B": "延迟路由策略",
      "C": "多值路由策略",
      "D": "地理位置路由策略"
    }
  },
  {
    "id": 243,
    "topic": "1",
    "question_en": "A medical research lab produces data that is related to a new study. The lab wants to make the data available with minimum latency to clinics across the country for their on-premises, file-based applications. The data files are stored in an Amazon S3 bucket that has read-only permissions for each clinic. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic",
      "B": "Migrate the files to each clinic’s on-premises applications by using AWS DataSync for processing.",
      "C": "Deploy an AWS Storage Gateway volume gateway as a virtual machine (VM) on premises at each clinic.",
      "D": "Attach an Amazon Elastic File System (Amazon EFS) file system to each clinic’s on-premises servers."
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一个医学研究实验室产生与一项新研究相关的数据。该实验室希望以最小的延迟将数据提供给全国各地的诊所，以供其本地的、基于文件的应用程序使用。数据文件存储在 Amazon S3 存储桶中，该存储桶为每个诊所提供只读权限。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "在每个诊所的本地部署一个作为虚拟机 (VM) 的 AWS Storage Gateway 文件网关。",
      "B": "使用 AWS DataSync 将文件迁移到每个诊所的本地应用程序进行处理。",
      "C": "在每个诊所的本地部署一个作为虚拟机 (VM) 的 AWS Storage Gateway 卷网关。",
      "D": "将 Amazon Elastic File System (Amazon EFS) 文件系统连接到每个诊所的本地服务器。"
    }
  },
  {
    "id": 244,
    "topic": "1",
    "question_en": "A company is using a content management system that runs on a single Amazon EC2 instance. The EC2 instance contains both the web server and the database software. The company must make its website platform highly available and must enable the website to scale to meet user demand. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Move the database to Amazon RDS, and enable automatic backups. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer in the Availability Zone, and set the two instances as targets.",
      "B": "Migrate the database to an Amazon Aurora instance with a read replica in the same Availability Zone as the existing EC2 instance. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer, and set the two EC2 instances as targets.",
      "C": "Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.",
      "D": "Move the database to a separate EC2 instance, and schedule backups to Amazon S3. Create an Amazon Machine Image (AMI) from the original EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones."
    },
    "correct_answer": "C",
    "vote_percentage": "97%",
    "question_cn": "一家公司正在使用一个内容管理系统，该系统运行在单个 Amazon EC2 实例上。EC2 实例包含 Web 服务器和数据库软件。该公司必须使其网站平台具有高可用性，并且必须使网站能够扩展以满足用户需求。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "将数据库移动到 Amazon RDS，并启用自动备份。手动在同一可用区中启动另一个 EC2 实例。在可用区中配置 Application Load Balancer，并将这两个实例设置为目标。",
      "B": "将数据库迁移到 Amazon Aurora 实例，并在与现有 EC2 实例相同的可用区中创建一个只读副本。手动在同一可用区中启动另一个 EC2 实例。配置 Application Load Balancer，并将这两个 EC2 实例设置为目标。",
      "C": "将数据库移动到 Amazon Aurora，并在另一个可用区中创建一个只读副本。从 EC2 实例创建 Amazon Machine Image (AMI)。在两个可用区中配置 Application Load Balancer。附加一个 Auto Scaling 组，该组使用 AMI 跨两个可用区。",
      "D": "将数据库移动到单独的 EC2 实例，并将备份调度到 Amazon S3。从原始 EC2 实例创建 Amazon Machine Image (AMI)。在两个可用区中配置 Application Load Balancer。附加一个 Auto Scaling 组，该组使用 AMI 跨两个可用区。"
    }
  },
  {
    "id": 245,
    "topic": "1",
    "question_en": "A company is launching an application on AWS. The application uses an Application Load Balancer (ALB) to direct trafic to at least two Amazon EC2 instances in a single target group. The instances are in an Auto Scaling group for each environment. The company requires a development environment and a production environment. The production environment will have periods of high trafic. Which solution will configure the development environment MOST cost-effectively?",
    "options_en": {
      "A": "Reconfigure the target group in the development environment to have only one EC2 instance as a target.",
      "B": "Change the ALB balancing algorithm to least outstanding requests.",
      "C": "Reduce the size of the EC2 instances in both environments.",
      "D": "Reduce the maximum number of EC2 instances in the development environment’s Auto Scaling group."
    },
    "correct_answer": "A",
    "vote_percentage": "56%",
    "question_cn": "一家公司正在 AWS 上启动一个应用程序。该应用程序使用 Application Load Balancer (ALB) 将流量定向到单个目标组中至少两个 Amazon EC2 实例。这些实例位于每个环境的 Auto Scaling 组中。该公司需要一个开发环境和一个生产环境。生产环境将有高流量时段。哪个解决方案将以最具成本效益的方式配置开发环境？",
    "options_cn": {
      "A": "将开发环境中的目标组重新配置为仅将一个 EC2 实例作为目标。",
      "B": "将 ALB 负载均衡算法更改为未完成请求最少。",
      "C": "减小两个环境中 EC2 实例的大小。",
      "D": "减少开发环境的 Auto Scaling 组中 EC2 实例的最大数量。"
    }
  },
  {
    "id": 246,
    "topic": "1",
    "question_en": "A company runs a web application on Amazon EC2 instances in multiple Availability Zones. The EC2 instances are in private subnets. A solutions architect implements an internet-facing Application Load Balancer (ALB) and specifies the EC2 instances as the target group. However, the internet trafic is not reaching the EC2 instances. How should the solutions architect reconfigure the architecture to resolve this issue?",
    "options_en": {
      "A": "Replace the ALB with a Network Load Balancer. Configure a NAT gateway in a public subnet to allow internet trafic.",
      "B": "Move the EC2 instances to public subnets. Add a rule to the EC2 instances’ security groups to allow outbound trafic to 0.0.0.0/0.",
      "C": "Update the route tables for the EC2 instances’ subnets to send 0.0.0.0/0 trafic through the internet gateway route. Add a rule to the EC2 instances’ security groups to allow outbound trafic to 0.0.0.0/0.",
      "D": "Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets."
    },
    "correct_answer": "C",
    "vote_percentage": "83%",
    "question_cn": "一家公司在多个可用区中的 Amazon EC2 实例上运行一个 Web 应用程序。EC2 实例位于私有子网中。解决方案架构师实施了一个面向 Internet 的 Application Load Balancer (ALB) ，并将 EC2 实例指定为目标组。但是，Internet 流量无法到达 EC2 实例。解决方案架构师应如何重新配置架构以解决此问题？",
    "options_cn": {
      "A": "将 ALB 替换为 Network Load Balancer。在公有子网中配置一个 NAT Gateway 以允许 Internet 流量。",
      "B": "将 EC2 实例移至公有子网。向 EC2 实例的安全组添加一条规则，以允许到 0.0.0.0/0 的出站流量。",
      "C": "更新 EC2 实例子网的路由表，以通过 Internet 网关路由发送 0.0.0.0/0 流量。向 EC2 实例的安全组添加一条规则，以允许到 0.0.0.0/0 的出站流量。",
      "D": "在每个可用区中创建公有子网。将公有子网与 ALB 关联。使用指向私有子网的路由更新公有子网的路由表。"
    }
  },
  {
    "id": 247,
    "topic": "1",
    "question_en": "A company has deployed a database in Amazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding a read replica. Which combination of actions should a solutions architect take before implementing this change? (Choose two.)",
    "options_en": {
      "A": "Enable binlog replication on the RDS primary node.",
      "B": "Choose a failover priority for the source DB instance.",
      "C": "Allow long-running transactions to complete on the source DB instance.",
      "D": "Create a global table and specify the AWS Regions where the table will be availabl",
      "E": "E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司已在 Amazon RDS for MySQL 中部署了一个数据库。由于事务量增加，数据库支持团队报告针对数据库实例的读取速度变慢，并建议添加一个只读副本。解决方案架构师在实施此更改之前应采取哪些组合操作？（选择两项。）",
    "options_cn": {
      "A": "在 RDS 主节点上启用 binlog 复制。",
      "B": "为 源数据库实例选择故障转移优先级。",
      "C": "允许长时间运行的事务在 源数据库实例上完成。",
      "D": "创建一个全局表，并指定该表将可用的 AWS 区域。",
      "E": "通过将备份保留期设置为大于 0 的值，在 源实例上启用自动备份。"
    }
  },
  {
    "id": 248,
    "topic": "1",
    "question_en": "A company runs analytics software on Amazon EC2 instances. The software accepts job requests from users to process data that has been uploaded to Amazon S3. Users report that some submitted data is not being processed Amazon CloudWatch reveals that the EC2 instances have a consistent CPU utilization at or near 100%. The company wants to improve system performance and scale the system based on user load. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a copy of the instance. Place all instances behind an Application Load Balancer.",
      "B": "Create an S3 VPC endpoint for Amazon S3. Update the software to reference the endpoint.",
      "C": "Stop the EC2 instances. Modify the instance type to one with a more powerful CPU and more memory. Restart the instances.",
      "D": "Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司在 Amazon EC2 实例上运行分析软件。该软件接受用户提交的作业请求，以处理已上传到 Amazon S3 的数据。用户报告说，某些提交的数据未被处理。Amazon CloudWatch 显示 EC2 实例的 CPU 利用率持续稳定在或接近 100%。该公司希望提高系统性能并根据用户负载扩展系统。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建实例的副本。将所有实例置于 Application Load Balancer 之后。",
      "B": "为 Amazon S3 创建一个 S3 VPC endpoint。更新软件以引用该 endpoint。",
      "C": "停止 EC2 实例。将实例类型修改为具有更强大的 CPU 和更多内存的类型。重新启动实例。",
      "D": "将传入请求路由到 Amazon Simple Queue Service (Amazon SQS)。基于队列大小配置一个 EC2 Auto Scaling 组。更新软件以从队列中读取。"
    }
  },
  {
    "id": 249,
    "topic": "1",
    "question_en": "A company is implementing a shared storage solution for a media application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed. Which AWS solution meets these requirements?",
    "options_en": {
      "A": "Create an AWS Storage Gateway volume gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
      "B": "Create an AWS Storage Gateway tape gateway. Configure tapes to use Amazon S3. Connect the application server to the tape gateway.",
      "C": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
      "D": "Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system."
    },
    "correct_answer": "D",
    "vote_percentage": "98%",
    "question_cn": "一家公司正在为其托管在 AWS 云中的媒体应用程序实施共享存储解决方案。该公司需要使用 SMB 客户端访问数据的能力。该解决方案必须是完全托管的。哪种 AWS 解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Storage Gateway 卷网关。创建一个使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享。",
      "B": "创建一个 AWS Storage Gateway 磁带网关。配置磁带以使用 Amazon S3。将应用程序服务器连接到磁带网关。",
      "C": "创建一个 Amazon EC2 Windows 实例。在该实例上安装并配置一个 Windows 文件共享角色。将应用程序服务器连接到文件共享。",
      "D": "创建一个 Amazon FSx for Windows File Server 文件系统。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。"
    }
  },
  {
    "id": 250,
    "topic": "1",
    "question_en": "A company’s security team requests that network trafic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently. What should a solutions architect do to meet these requirements when configuring the logs?",
    "options_en": {
      "A": "Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days",
      "B": "Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.",
      "C": "Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent-Tiering.",
      "D": "Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days."
    },
    "correct_answer": "A",
    "vote_percentage": "92%",
    "question_cn": "一家公司的安全团队要求在 VPC 流日志中捕获网络流量。这些日志将被频繁访问 90 天，然后间歇性地访问。 解决方案架构师在配置日志时应采取什么措施来满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch 作为目标。将 CloudWatch 日志组设置为 90 天后过期。",
      "B": "使用 Amazon Kinesis 作为目标。配置 Kinesis 流，始终将日志保留 90 天。",
      "C": "使用 AWS CloudTrail 作为目标。配置 CloudTrail 保存到 Amazon S3 存储桶，并打开 S3 Intelligent-Tiering。",
      "D": "使用 Amazon S3 作为目标。打开 S3 生命周期策略，在 90 天后将日志转换为 S3 Standard-Infrequent Access (S3 Standard-IA)."
    }
  },
  {
    "id": 251,
    "topic": "1",
    "question_en": "An Amazon EC2 instance is located in a private subnet in a new VPC. This subnet does not have outbound internet access, but the EC2 instance needs the ability to download monthly security updates from an outside vendor. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an internet gateway, and attach it to the VPC. Configure the private subnet route table to use the internet gateway as the default route.",
      "B": "Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.",
      "C": "Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the NAT instance as the default route.",
      "D": "Create an internet gateway, and attach it to the VPC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the internet gateway as the default route."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一个 Amazon EC2 实例位于新 VPC 的一个私有子网中。该子网没有出站互联网访问权限，但 EC2 实例需要能够从外部供应商下载每月安全更新。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个互联网网关，并将其附加到 VPC。配置私有子网路由表以使用互联网网关作为默认路由。",
      "B": "创建一个 NAT 网关，并将其放置在公有子网中。配置私有子网路由表以使用 NAT 网关作为默认路由。",
      "C": "创建一个 NAT 实例，并将其放置在 EC2 实例所在的同一子网中。配置私有子网路由表以使用 NAT 实例作为默认路由。",
      "D": "创建一个互联网网关，并将其附加到 VPC。创建一个 NAT 实例，并将其放置在 EC2 实例所在的同一子网中。配置私有子网路由表以使用互联网网关作为默认路由。"
    }
  },
  {
    "id": 252,
    "topic": "1",
    "question_en": "A solutions architect needs to design a system to store client case files. The files are core company assets and are important. The number of files will grow over time. The files must be simultaneously accessible from multiple application servers that run on Amazon EC2 instances. The solution must have built-in redundancy. Which solution meets these requirements?",
    "options_en": {
      "A": "Amazon Elastic File System (Amazon EFS)",
      "B": "Amazon Elastic Block Store (Amazon EBS)",
      "C": "Amazon S3 Glacier Deep Archive",
      "D": "AWS Backup"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要设计一个系统来存储客户案例文件。这些文件是公司的核心资产，非常重要。文件数量会随着时间的推移而增加。这些文件必须可以同时从在 Amazon EC2 实例上运行的多个应用程序服务器访问。该解决方案必须具有内置冗余。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "Amazon Elastic File System (Amazon EFS)",
      "B": "Amazon Elastic Block Store (Amazon EBS)",
      "C": "Amazon S3 Glacier Deep Archive",
      "D": "AWS Backup"
    }
  },
  {
    "id": 253,
    "topic": "1",
    "question_en": "A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group. A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?",
    "options_en": {
      "A": "Deleting IAM users",
      "B": "Deleting directories",
      "C": "Deleting Amazon EC2 instances",
      "D": "Deleting logs from Amazon CloudWatch Logs"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师创建了两个 IAM 策略：策略 1 和策略 2。这两个策略都附加到一个 IAM 组。一位云工程师被添加为 IAM 用户到该 IAM 组。这位云工程师将能够执行哪个操作？",
    "options_cn": {
      "A": "删除 IAM 用户",
      "B": "删除目录",
      "C": "删除 Amazon EC2 实例",
      "D": "从 Amazon CloudWatch Logs 中删除日志"
    }
  },
  {
    "id": 254,
    "topic": "1",
    "question_en": "A company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers. What should a solutions architect do to correct this issue?",
    "options_en": {
      "A": "Create security group rules using the instance ID as the source or destination.",
      "B": "Create security group rules using the security group ID as the source or destination.",
      "C": "Create security group rules using the VPC CIDR blocks as the source or destination.",
      "D": "Create security group rules using the subnet CIDR blocks as the source or destination."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在审查将其三层应用程序迁移到 VPC 的情况。安全团队发现，在应用程序层之间的 Amazon EC2 安全组入站和出站规则中，没有应用最小权限原则。解决方案架构师应该怎么做来纠正这个问题？",
    "options_cn": {
      "A": "使用实例 ID 作为 源 或目标来创建安全组规则。",
      "B": "使用安全组 ID 作为 源 或目标来创建安全组规则。",
      "C": "使用 VPC CIDR 块作为 源 或目标来创建安全组规则。",
      "D": "使用子网 CIDR 块作为 源 或目标来创建安全组规则。"
    }
  },
  {
    "id": 255,
    "topic": "1",
    "question_en": "A company has an ecommerce checkout workfiow that writes an order to a database and calls a service to process the payment. Users are experiencing timeouts during the checkout process. When users resubmit the checkout form, multiple unique orders are created for the same desired transaction. How should a solutions architect refactor this workfiow to prevent the creation of multiple orders?",
    "options_en": {
      "A": "Configure the web application to send an order message to Amazon Kinesis Data Firehose. Set the payment service to retrieve the message from Kinesis Data Firehose and process the order.",
      "B": "Create a rule in AWS CloudTrail to invoke an AWS Lambda function based on the logged application path request. Use Lambda to query the database, call the payment service, and pass in the order information.",
      "C": "Store the order in the database. Send a message that includes the order number to Amazon Simple Notification Service (Amazon SNS). Set the payment service to poll Amazon SNS, retrieve the message, and process the order.",
      "D": "Store the order in the database. Send a message that includes the order number to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the payment service to retrieve the message and process the order. Delete the message from the queue."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个电子商务结账工作流程，该流程将订单写入数据库并调用服务来处理付款。用户在结账过程中遇到超时。当用户重新提交结账表单时，会为同一所需的交易创建多个唯一的订单。解决方案架构师应该如何重构此工作流程以防止创建多个订单？",
    "options_cn": {
      "A": "配置 Web 应用程序将订单消息发送到 Amazon Kinesis Data Firehose。设置付款服务以从 Kinesis Data Firehose 检索消息并处理订单。",
      "B": "在 AWS CloudTrail 中创建一条规则，以基于记录的应用程序路径请求来调用 AWS Lambda 函数。使用 Lambda 查询数据库，调用付款服务，并传入订单信息。",
      "C": "将订单存储在数据库中。发送一条包含订单号的消息到 Amazon Simple Notification Service (Amazon SNS)。设置付款服务以轮询 Amazon SNS，检索消息并处理订单。",
      "D": "将订单存储在数据库中。发送一条包含订单号的消息到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列。设置付款服务以检索消息并处理订单。从队列中删除该消息。"
    }
  },
  {
    "id": 256,
    "topic": "1",
    "question_en": "A solutions architect is implementing a document review application using an Amazon S3 bucket for storage. The solution must prevent accidental deletion of the documents and ensure that all versions of the documents are available. Users must be able to download, modify, and upload documents. Which combination of actions should be taken to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Enable a read-only bucket ACL.",
      "B": "Enable versioning on the bucket.",
      "C": "Attach an IAM policy to the bucket.",
      "D": "Enable MFA Delete on the bucket",
      "E": "Encrypt the bucket using AWS KMS."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在使用 Amazon S3 存储桶实施文档审核应用程序进行存储。该解决方案必须防止文档被意外删除，并确保所有版本的文档都可用。用户必须能够下载、修改和上传文档。应采取哪些操作组合才能满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "启用只读存储桶 ACL。",
      "B": "在存储桶上启用版本控制。",
      "C": "将 IAM 策略附加到存储桶。",
      "D": "在存储桶上启用 MFA 删除。",
      "E": "使用 AWS KMS 加密存储桶。"
    }
  },
  {
    "id": 257,
    "topic": "1",
    "question_en": "A company is building a solution that will report Amazon EC2 Auto Scaling events across all the applications in an AWS account. The company needs to use a serverless solution to store the EC2 Auto Scaling status data in Amazon S3. The company then will use the data in Amazon S3 to provide near-real-time updates in a dashboard. The solution must not affect the speed of EC2 instance launches. How should the company move the data to Amazon S3 to meet these requirements?",
    "options_en": {
      "A": "Use an Amazon CloudWatch metric stream to send the EC2 Auto Scaling status data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.",
      "B": "Launch an Amazon EMR cluster to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.",
      "C": "Create an Amazon EventBridge rule to invoke an AWS Lambda function on a schedule. Configure the Lambda function to send the EC2 Auto Scaling status data directly to Amazon S3.",
      "D": "Use a bootstrap script during the launch of an EC2 instance to install Amazon Kinesis Agent. Configure Kinesis Agent to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司正在构建一个解决方案，该方案将报告 AWS 账户中所有应用程序的 Amazon EC2 Auto Scaling 事件。该公司需要使用无服务器解决方案将 EC2 Auto Scaling 状态数据存储在 Amazon S3 中。然后，该公司将使用 Amazon S3 中的数据在仪表板中提供近乎实时的更新。该解决方案不能影响 EC2 实例的启动速度。该公司应如何将数据移动到 Amazon S3 以满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch 指标流将 EC2 Auto Scaling 状态数据发送到 Amazon Kinesis Data Firehose。将数据存储在 Amazon S3 中。",
      "B": "启动 Amazon EMR 集群以收集 EC2 Auto Scaling 状态数据，并将数据发送到 Amazon Kinesis Data Firehose。将数据存储在 Amazon S3 中。",
      "C": "创建 Amazon EventBridge 规则以按计划调用 AWS Lambda 函数。配置 Lambda 函数以将 EC2 Auto Scaling 状态数据直接发送到 Amazon S3。",
      "D": "在启动 EC2 实例期间使用引导脚本安装 Amazon Kinesis Agent。配置 Kinesis Agent 以收集 EC2 Auto Scaling 状态数据，并将数据发送到 Amazon Kinesis Data Firehose。将数据存储在 Amazon S3 中。"
    }
  },
  {
    "id": 258,
    "topic": "1",
    "question_en": "A company has an application that places hundreds of .csv files into an Amazon S3 bucket every hour. The files are 1 GB in size. Each time a file is uploaded, the company needs to convert the file to Apache Parquet format and place the output file into an S3 bucket. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Lambda function to download the .csv files, convert the files to Parquet format, and place the output files in an S3 bucket. Invoke the Lambda function for each S3 PUT event.",
      "B": "Create an Apache Spark job to read the .csv files, convert the files to Parquet format, and place the output files in an S3 bucket. Create an AWS Lambda function for each S3 PUT event to invoke the Spark job.",
      "C": "Create an AWS Glue table and an AWS Glue crawler for the S3 bucket where the application places the .csv files. Schedule an AWS Lambda function to periodically use Amazon Athena to query the AWS Glue table, convert the query results into Parquet format, and place the output files into an S3 bucket.",
      "D": "Create an AWS Glue extract, transform, and load (ETL) job to convert the .csv files to Parquet format and place the output files into an S3 bucket. Create an AWS Lambda function for each S3 PUT event to invoke the ETL job."
    },
    "correct_answer": "A",
    "vote_percentage": "89%",
    "question_cn": "一家公司有一个应用程序，每小时将数百个 .csv 文件放入 Amazon S3 存储桶中。这些文件的大小为 1 GB。每次上传文件时，公司都需要将文件转换为 Apache Parquet 格式，并将输出文件放入 S3 存储桶中。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数以下载 .csv 文件，将文件转换为 Parquet 格式，并将输出文件放入 S3 存储桶中。为每个 S3 PUT 事件调用 Lambda 函数。",
      "B": "创建一个 Apache Spark 作业以读取 .csv 文件，将文件转换为 Parquet 格式，并将输出文件放入 S3 存储桶中。为每个 S3 PUT 事件创建一个 AWS Lambda 函数来调用 Spark 作业。",
      "C": "为应用程序放置 .csv 文件的 S3 存储桶创建一个 AWS Glue 表和一个 AWS Glue 爬虫。安排一个 AWS Lambda 函数，以定期间隔使用 Amazon Athena 查询 AWS Glue 表，将查询结果转换为 Parquet 格式，并将输出文件放入 S3 存储桶中。",
      "D": "创建一个 AWS Glue 提取、转换和加载 (ETL) 作业，将 .csv 文件转换为 Parquet 格式，并将输出文件放入 S3 存储桶中。为每个 S3 PUT 事件创建一个 AWS Lambda 函数来调用 ETL 作业。"
    }
  },
  {
    "id": 259,
    "topic": "1",
    "question_en": "A company is implementing new data retention policies for all databases that run on Amazon RDS DB instances. The company must retain daily backups for a minimum period of 2 years. The backups must be consistent and restorable. Which solution should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan.",
      "B": "Configure a backup window for the RDS DB instances for daily snapshots. Assign a snapshot retention policy of 2 years to each RDS DB instance. Use Amazon Data Lifecycle Manager (Amazon DLM) to schedule snapshot deletions.",
      "C": "Configure database transaction logs to be automatically backed up to Amazon CloudWatch Logs with an expiration period of 2 years.",
      "D": "Configure an AWS Database Migration Service (AWS DMS) replication task. Deploy a replication instance, and configure a change data capture (CDC) task to stream database changes to Amazon S3 as the target. Configure S3 Lifecycle policies to delete the snapshots after 2 years."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司正在为所有在 Amazon RDS 数据库实例上运行的数据库实施新的数据保留策略。该公司必须将每日备份保留至少 2 年。备份必须一致且可恢复。解决方案架构师应推荐哪种解决方案来满足这些要求？",
    "options_cn": {
      "A": "在 AWS Backup 中创建一个备份库来保留 RDS 备份。创建一个新的备份计划，该计划具有每日时间表和创建后 2 年的到期时间。将 RDS 数据库实例分配给备份计划。",
      "B": "为 RDS 数据库实例配置备份窗口以进行每日快照。为每个 RDS 数据库实例分配 2 年的快照保留策略。使用 Amazon Data Lifecycle Manager (Amazon DLM) 来计划快照删除。",
      "C": "配置数据库事务日志，使其自动备份到 Amazon CloudWatch Logs，并设置 2 年的到期时间。",
      "D": "配置一个 AWS Database Migration Service (AWS DMS) 复制任务。部署一个复制实例，并配置一个变更数据捕获 (CDC) 任务，以将数据库更改流式传输到 Amazon S3 作为目标。配置 S3 生命周期策略以在 2 年后删除快照。"
    }
  },
  {
    "id": 260,
    "topic": "1",
    "question_en": "A company’s compliance team needs to move its file shares to AWS. The shares run on a Windows Server SMB file share. A self-managed on- premises Active Directory controls access to the files and folders. The company wants to use Amazon FSx for Windows File Server as part of the solution. The company must ensure that the on-premises Active Directory groups restrict access to the FSx for Windows File Server SMB compliance shares, folders, and files after the move to AWS. The company has created an FSx for Windows File Server file system. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Active Directory Connector to connect to the Active Directory. Map the Active Directory groups to IAM groups to restrict access.",
      "B": "Assign a tag with a Restrict tag key and a Compliance tag value. Map the Active Directory groups to IAM groups to restrict access.",
      "C": "Create an IAM service-linked role that is linked directly to FSx for Windows File Server to restrict access.",
      "D": "Join the file system to the Active Directory to restrict access."
    },
    "correct_answer": "D",
    "vote_percentage": "89%",
    "question_cn": "一家公司的合规团队需要将其文件共享迁移到 AWS。这些共享运行在 Windows Server SMB 文件共享上。一个自管理的本地 Active Directory 控制对文件和文件夹的访问。该公司希望使用 Amazon FSx for Windows File Server 作为解决方案的一部分。该公司必须确保在迁移到 AWS 之后，本地 Active Directory 组限制对 FSx for Windows File Server SMB 合规性共享、文件夹和文件的访问。该公司已经创建了一个 FSx for Windows File Server 文件系统。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Active Directory Connector 以连接到 Active Directory。将 Active Directory 组映射到 IAM 组以限制访问。",
      "B": "分配一个带有 Restrict 标签键和 Compliance 标签值的标签。将 Active Directory 组映射到 IAM 组以限制访问。",
      "C": "创建一个直接链接到 FSx for Windows File Server 的 IAM 服务链接角色以限制访问。",
      "D": "将文件系统加入到 Active Directory 以限制访问。"
    }
  },
  {
    "id": 261,
    "topic": "1",
    "question_en": "A company recently announced the deployment of its retail website to a global audience. The website runs on multiple Amazon EC2 instances behind an Elastic Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company wants to provide its customers with different versions of content based on the devices that the customers use to access the website. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Configure Amazon CloudFront to cache multiple versions of the content.",
      "B": "Configure a host header in a Network Load Balancer to forward trafic to different instances.",
      "C": "Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.",
      "D": "Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up host-based routing to different EC2 instances",
      "E": "Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up path-based routing to different EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司最近宣布向全球受众部署其零售网站。该网站在 Elastic Load Balancer 之后的多台 Amazon EC2 实例上运行。这些实例在多个可用区中的 Auto Scaling 组中运行。该公司希望根据客户用来访问网站的设备，向其客户提供不同版本的內容。解决方案架构师应采取哪些组合操作来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "配置 Amazon CloudFront 以缓存内容的多个版本。",
      "B": "在 Network Load Balancer 中配置主机标头，以将流量转发到不同的实例。",
      "C": "配置 Lambda@Edge 函数，以根据 User-Agent 标头向用户发送特定对象。",
      "D": "配置 AWS Global Accelerator。将请求转发到 Network Load Balancer (NLB)。配置 NLB 以设置基于主机的路由到不同的 EC2 实例。",
      "E": "配置 AWS Global Accelerator。将请求转发到 Network Load Balancer (NLB)。配置 NLB 以设置基于路径的路由到不同的 EC2 实例。"
    }
  },
  {
    "id": 262,
    "topic": "1",
    "question_en": "A company plans to use Amazon ElastiCache for its multi-tier web application. A solutions architect creates a Cache VPC for the ElastiCache cluster and an App VPC for the application’s Amazon EC2 instances. Both VPCs are in the us-east-1 Region. The solutions architect must implement a solution to provide the application’s EC2 instances with access to the ElastiCache cluster. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the ElastiCache cluster’s security group to allow inbound connection from the application’s security group.",
      "B": "Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route trafic through the Transit VPC. Configure an inbound rule for the ElastiCache cluster's security group to allow inbound connection from the application’s security group.",
      "C": "Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the peering connection’s security group to allow inbound connection from the application’s security group.",
      "D": "Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route trafic through the Transit VPC. Configure an inbound rule for the Transit VPC’s security group to allow inbound connection from the application’s security group."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划为其多层 Web 应用程序使用 Amazon ElastiCache。一位解决方案架构师为 ElastiCache 集群创建了一个缓存 VPC，并为应用程序的 Amazon EC2 实例创建了一个应用 VPC。这两个 VPC 都在 us-east-1 区域中。解决方案架构师必须实施一个解决方案，为应用程序的 EC2 实例提供对 ElastiCache 集群的访问权限。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "在 VPC 之间创建对等连接。在两个 VPC 中为对等连接添加路由表条目。为 ElastiCache 集群的安全组配置一个入站规则，以允许来自应用程序安全组的入站连接。",
      "B": "创建一个 Transit VPC。更新缓存 VPC 和应用 VPC 中的 VPC 路由表，以通过 Transit VPC 路由流量。为 ElastiCache 集群的安全组配置一个入站规则，以允许来自应用程序安全组的入站连接。",
      "C": "在 VPC 之间创建对等连接。在两个 VPC 中为对等连接添加路由表条目。为对等连接的安全组配置一个入站规则，以允许来自应用程序安全组的入站连接。",
      "D": "创建一个 Transit VPC。更新缓存 VPC 和应用 VPC 中的 VPC 路由表，以通过 Transit VPC 路由流量。为 Transit VPC 的安全组配置一个入站规则，以允许来自应用程序安全组的入站连接。"
    }
  },
  {
    "id": 263,
    "topic": "1",
    "question_en": "A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.",
      "B": "Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.",
      "C": "Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.",
      "D": "Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch typ",
      "E": "Specify a desired task number level of greater than or equal to 2. E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在构建一个由几个微服务组成的应用程序。该公司已决定使用容器技术在 AWS 上部署其软件。该公司需要一个解决方案，以最大限度地减少维护和扩展的持续工作量。该公司无法管理额外的基础设施。解决方案架构师应采取哪两种操作组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "部署一个 Amazon Elastic Container Service (Amazon ECS) 集群。",
      "B": "在跨多个可用区的 Amazon EC2 实例上部署 Kubernetes 控制平面。",
      "C": "使用 Amazon EC2 启动类型部署一个 Amazon Elastic Container Service (Amazon ECS) 服务。指定一个大于或等于 2 的所需任务数量级别。",
      "D": "使用 Fargate 启动类型部署一个 Amazon Elastic Container Service (Amazon ECS) 服务。指定一个大于或等于 2 的所需任务数量级别。",
      "E": "在跨多个可用区的 Amazon EC2 实例上部署 Kubernetes 工作节点。创建一个部署，为每个微服务指定两个或更多副本。"
    }
  },
  {
    "id": 264,
    "topic": "1",
    "question_en": "A company has a web application hosted over 10 Amazon EC2 instances with trafic directed by Amazon Route 53. The company occasionally experiences a timeout error when attempting to browse the application. The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error. What should a solutions architect implement to overcome these timeout errors?",
    "options_en": {
      "A": "Create a Route 53 simple routing policy record for each EC2 instance. Associate a health check with each record.",
      "B": "Create a Route 53 failover routing policy record for each EC2 instance. Associate a health check with each record.",
      "C": "Create an Amazon CloudFront distribution with EC2 instances as its origin. Associate a health check with the EC2 instances.",
      "D": "Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances. Route to the ALB from Route 53."
    },
    "correct_answer": "D",
    "vote_percentage": "66%",
    "question_cn": "一家公司在其 10 个 Amazon EC2 实例上托管一个 Web 应用程序，流量由 Amazon Route 53 引导。该公司偶尔在尝试浏览该应用程序时遇到超时错误。网络团队发现一些 DNS 查询返回运行状况不佳的实例的 IP 地址，导致超时错误。解决方案架构师应该实施什么来克服这些超时错误？",
    "options_cn": {
      "A": "为每个 EC2 实例创建 Route 53 简单路由策略记录。将运行状况检查与每条记录关联。",
      "B": "为每个 EC2 实例创建 Route 53 故障转移路由策略记录。将运行状况检查与每条记录关联。",
      "C": "创建一个 Amazon CloudFront 分发，将 EC2 实例作为其源。将运行状况检查与 EC2 实例关联。",
      "D": "在 EC2 实例前面创建一个 Application Load Balancer (ALB) 并进行运行状况检查。从 Route 53 路由到 ALB。"
    }
  },
  {
    "id": 265,
    "topic": "1",
    "question_en": "A solutions architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time. Which solution meets these requirements and is MOST secure?",
    "options_en": {
      "A": "Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.",
      "B": "Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.",
      "C": "Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.",
      "D": "Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要设计一个高可用应用程序，该应用程序由 Web、应用程序和数据库层组成。 HTTPS 内容交付应尽可能接近边缘，并具有最短的交付时间。哪种解决方案最符合这些要求，并且最安全？",
    "options_cn": {
      "A": "配置一个公共 Application Load Balancer (ALB)，并在公共子网中使用多个冗余的 Amazon EC2 实例。 配置 Amazon CloudFront 使用公共 ALB 作为源来交付 HTTPS 内容。",
      "B": "配置一个公共 Application Load Balancer，并在私有子网中使用多个冗余的 Amazon EC2 实例。 配置 Amazon CloudFront 使用 EC2 实例作为源来交付 HTTPS 内容。",
      "C": "配置一个公共 Application Load Balancer (ALB)，并在私有子网中使用多个冗余的 Amazon EC2 实例。 配置 Amazon CloudFront 使用公共 ALB 作为源来交付 HTTPS 内容。",
      "D": "配置一个公共 Application Load Balancer，并在公共子网中使用多个冗余的 Amazon EC2 实例。 配置 Amazon CloudFront 使用 EC2 实例作为源来交付 HTTPS 内容。"
    }
  },
  {
    "id": 266,
    "topic": "1",
    "question_en": "A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region. It runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect trafic to healthy endpoints. Which solution meets these requirements?",
    "options_en": {
      "A": "Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.",
      "B": "Create an Amazon CloudFront distribution and specify the ALB as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the trafic.",
      "C": "Create an Amazon CloudFront distribution and specify Amazon S3 as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the trafic.",
      "D": "Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the in-memory cache for DynamoDB hosting the application data."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行一个受欢迎的游戏平台。该应用程序对延迟很敏感，因为延迟会影响用户体验，并给某些玩家带来不公平的优势。该应用程序部署在每个 AWS 区域中。它运行在作为 Application Load Balancer (ALB) 后面的 Auto Scaling 组一部分的 Amazon EC2 实例上。 解决方案架构师需要实施一种机制来监控应用程序的健康状况，并将流量重定向到健康的端点。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在 AWS Global Accelerator 中配置一个加速器。为应用程序侦听的端口添加一个侦听器，并将其附加到每个区域中的区域端点。将 ALB 添加为端点。",
      "B": "创建一个 Amazon CloudFront 分发，并将 ALB 指定为源服务器。配置缓存行为以使用源缓存标头。使用 AWS Lambda 函数来优化流量。",
      "C": "创建一个 Amazon CloudFront 分发，并将 Amazon S3 指定为源服务器。配置缓存行为以使用源缓存标头。使用 AWS Lambda 函数来优化流量。",
      "D": "配置一个 Amazon DynamoDB 数据库，作为应用程序的数据存储。创建一个 DynamoDB Accelerator (DAX) 集群，作为 DynamoDB 托管应用程序数据的内存缓存。"
    }
  },
  {
    "id": 267,
    "topic": "1",
    "question_en": "A company has one million users that use its mobile app. The company must analyze the data usage in near-real time. The company also must encrypt the data in near-real time and must store the data in a centralized location in Apache Parquet format for further processing. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data. Invoke an AWS Lambda function to send the data to the Kinesis Data Analytics application.",
      "B": "Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data. Invoke an AWS Lambda function to send the data to the EMR cluster.",
      "C": "Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data.",
      "D": "Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一百万使用其移动应用程序的用户。该公司必须近乎实时地分析数据使用情况。该公司还必须近乎实时地加密数据，并以 Apache Parquet 格式将数据存储在集中位置以进行进一步处理。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Kinesis 数据流将数据存储在 Amazon S3 中。创建一个 Amazon Kinesis Data Analytics 应用程序来分析数据。调用一个 AWS Lambda 函数将数据发送到 Kinesis Data Analytics 应用程序。",
      "B": "创建一个 Amazon Kinesis 数据流将数据存储在 Amazon S3 中。创建一个 Amazon EMR 集群来分析数据。调用一个 AWS Lambda 函数将数据发送到 EMR 集群。",
      "C": "创建一个 Amazon Kinesis Data Firehose 交付流将数据存储在 Amazon S3 中。创建一个 Amazon EMR 集群来分析数据。",
      "D": "创建一个 Amazon Kinesis Data Firehose 交付流将数据存储在 Amazon S3 中。创建一个 Amazon Kinesis Data Analytics 应用程序来分析数据。"
    }
  },
  {
    "id": 268,
    "topic": "1",
    "question_en": "A gaming company has a web application that displays scores. The application runs on Amazon EC2 instances behind an Application Load Balancer. The application stores data in an Amazon RDS for MySQL database. Users are starting to experience long delays and interruptions that are caused by database read performance. The company wants to improve the user experience while minimizing changes to the application’s architecture. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use Amazon ElastiCache in front of the database.",
      "B": "Use RDS Proxy between the application and the database.",
      "C": "Migrate the application from EC2 instances to AWS Lambda.",
      "D": "Migrate the database from Amazon RDS for MySQL to Amazon DynamoDB."
    },
    "correct_answer": "A",
    "vote_percentage": "51%",
    "question_cn": "一家游戏公司有一个显示分数的 Web 应用程序。该应用程序在 Application Load Balancer 后面的 Amazon EC2 实例上运行。该应用程序将数据存储在 Amazon RDS for MySQL 数据库中。用户开始遇到因数据库读取性能而导致的长延迟和中断。该公司希望改善用户体验，同时最大限度地减少对应用程序架构的更改。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在数据库前面使用 Amazon ElastiCache。",
      "B": "在应用程序和数据库之间使用 RDS Proxy。",
      "C": "将应用程序从 EC2 实例迁移到 AWS Lambda。",
      "D": "将数据库从 Amazon RDS for MySQL 迁移到 Amazon DynamoDB。"
    }
  },
  {
    "id": 269,
    "topic": "1",
    "question_en": "An ecommerce company has noticed performance degradation of its Amazon RDS based web application. The performance degradation is attributed to an increase in the number of read-only SQL queries triggered by business analysts. A solutions architect needs to solve the problem with minimal changes to the existing web application. What should the solutions architect recommend?",
    "options_en": {
      "A": "Export the data to Amazon DynamoDB and have the business analysts run their queries.",
      "B": "Load the data into Amazon ElastiCache and have the business analysts run their queries.",
      "C": "Create a read replica of the primary database and have the business analysts run their queries.",
      "D": "Copy the data into an Amazon Redshift cluster and have the business analysts run their queries."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司注意到其基于 Amazon RDS 的 Web 应用程序的性能下降。这种性能下降归因于业务分析师触发的只读 SQL 查询数量的增加。解决方案架构师需要以最少的更改来解决现有 Web 应用程序的问题。 解决方案架构师应该建议什么？",
    "options_cn": {
      "A": "将数据导出到 Amazon DynamoDB，并让业务分析师运行他们的查询。",
      "B": "将数据加载到 Amazon ElastiCache，并让业务分析师运行他们的查询。",
      "C": "创建主数据库的只读副本，并让业务分析师运行他们的查询。",
      "D": "将数据复制到 Amazon Redshift 集群中，并让业务分析师运行他们的查询。"
    }
  },
  {
    "id": 270,
    "topic": "1",
    "question_en": "A company is using a centralized AWS account to store log data in various Amazon S3 buckets. A solutions architect needs to ensure that the data is encrypted at rest before the data is uploaded to the S3 buckets. The data also must be encrypted in transit. Which solution meets these requirements?",
    "options_en": {
      "A": "Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.",
      "B": "Use server-side encryption to encrypt the data that is being uploaded to the S3 buckets.",
      "C": "Create bucket policies that require the use of server-side encryption with S3 managed encryption keys (SSE-S3) for S3 uploads.",
      "D": "Enable the security option to encrypt the S3 buckets through the use of a default AWS Key Management Service (AWS KMS) key."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在使用一个集中的 AWS 账户，将日志数据存储在各种 Amazon S3 存储桶中。一位解决方案架构师需要确保在将数据上传到 S3 存储桶之前，数据在静态时被加密。数据也必须在传输过程中被加密。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用客户端加密来加密上传到 S3 存储桶的数据。",
      "B": "使用服务器端加密来加密上传到 S3 存储桶的数据。",
      "C": "创建存储桶策略，该策略要求使用服务器端加密，并使用 S3 托管加密密钥 (SSE-S3) 进行 S3 上传。",
      "D": "通过使用默认 AWS Key Management Service (AWS KMS) 密钥，打开加密 S3 存储桶的安全选项。"
    }
  },
  {
    "id": 271,
    "topic": "1",
    "question_en": "A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the ‘same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Increase the minimum capacity for the Auto Scaling group.",
      "B": "Increase the maximum capacity for the Auto Scaling group.",
      "C": "Configure scheduled scaling to scale up to the desired compute level.",
      "D": "Change the scaling policy to add more EC2 instances during each scaling operation."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师观察到，一个夜间批处理作业在达到所需的 Amazon EC2 容量之前，会自动扩展 1 小时。峰值容量“每晚相同”，批处理作业总是从凌晨 1 点开始。解决方案架构师需要找到一个经济高效的解决方案，该方案将允许快速达到所需的 EC2 容量，并在批处理作业完成后允许 Auto Scaling 组缩小。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "增加 Auto Scaling 组的最小容量。",
      "B": "增加 Auto Scaling 组的最大容量。",
      "C": "配置预定的缩放以扩展到所需的计算级别。",
      "D": "更改缩放策略以在每次缩放操作期间添加更多 EC2 实例。"
    }
  },
  {
    "id": 272,
    "topic": "1",
    "question_en": "A company serves a dynamic website from a fieet of Amazon EC2 instances behind an Application Load Balancer (ALB). The website needs to support multiple languages to serve customers around the world. The website’s architecture is running in the us-west-1 Region and is exhibiting high request latency for users that are located in other parts of the world. The website needs to serve requests quickly and eficiently regardless of a user’s location. However, the company does not want to recreate the existing architecture across multiple Regions. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Replace the existing architecture with a website that is served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.",
      "B": "Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to cache based on the Accept- Language request header.",
      "C": "Create an Amazon API Gateway API that is integrated with the ALB. Configure the API to use the HTTP integration type. Set up an API Gateway stage to enable the API cache based on the Accept-Language request header.",
      "D": "Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the EC2 instances and the ALB behind an Amazon Route 53 record set with a geolocation routing policy."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司通过 Application Load Balancer (ALB) 后的 Amazon EC2 实例集群提供动态网站。该网站需要支持多种语言来服务世界各地的客户。该网站的架构运行在 us-west-1 区域，并且对于位于世界其他地方的用户表现出高请求延迟。该网站需要快速有效地服务请求，而不管用户的位置如何。但是，该公司不想在多个区域中重新创建现有架构。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将现有架构替换为从 Amazon S3 存储桶提供的网站。配置一个 Amazon CloudFront 分发，将 S3 存储桶作为源。将缓存行为设置配置为基于 Accept-Language 请求标头进行缓存。",
      "B": "配置一个 Amazon CloudFront 分发，将 ALB 作为源。将缓存行为设置配置为基于 Accept-Language 请求标头进行缓存。",
      "C": "创建一个 Amazon API Gateway API，该 API 与 ALB 集成。将 API 配置为使用 HTTP 集成类型。设置一个 API Gateway 阶段，以基于 Accept-Language 请求标头启用 API 缓存。",
      "D": "在每个附加区域启动一个 EC2 实例，并配置 NGINX 以充当该区域的缓存服务器。将所有 EC2 实例和 ALB 放在一个 Amazon Route 53 记录集中，并使用地理位置路由策略。"
    }
  },
  {
    "id": 273,
    "topic": "1",
    "question_en": "A rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary. Which solution will meet these requirements with the LOWEST recovery time objective (RTO)?",
    "options_en": {
      "A": "Use an Amazon Aurora global database with a pilot light deployment.",
      "B": "Use an Amazon Aurora global database with a warm standby deployment.",
      "C": "Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment.",
      "D": "Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment."
    },
    "correct_answer": "B",
    "vote_percentage": "98%",
    "question_cn": "一家快速发展的电子商务公司正在单个 AWS 区域中运行其工作负载。一位解决方案架构师必须创建一个灾难恢复 (DR) 策略，该策略包括另一个 AWS 区域。该公司希望其数据库在 DR 区域中保持最新状态，且延迟尽可能低。DR 区域中的其余基础设施需要在缩减的容量下运行，并且必须能够根据需要进行扩展。哪种解决方案将以最低的恢复时间目标 (RTO) 满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Aurora 全局数据库和试点灯部署。",
      "B": "使用 Amazon Aurora 全局数据库和暖备用部署。",
      "C": "使用 Amazon RDS 多可用区数据库实例和试点灯部署。",
      "D": "使用 Amazon RDS 多可用区数据库实例和暖备用部署。"
    }
  },
  {
    "id": 274,
    "topic": "1",
    "question_en": "A company runs an application on Amazon EC2 instances. The company needs to implement a disaster recovery (DR) solution for the application. The DR solution needs to have a recovery time objective (RTO) of less than 4 hours. The DR solution also needs to use the fewest possible AWS resources during normal operations. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS Lambda and custom scripts.",
      "B": "Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.",
      "C": "Launch EC2 instances in a secondary AWS Region. Keep the EC2 instances in the secondary Region active at all times.",
      "D": "Launch EC2 instances in a secondary Availability Zone. Keep the EC2 instances in the secondary Availability Zone active at all times."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Amazon EC2 实例上运行一个应用程序。该公司需要为该应用程序实施灾难恢复 (DR) 解决方案。 DR 解决方案需要小于 4 小时的恢复时间目标 (RTO)。 DR 解决方案还需要在正常运行期间使用最少的 AWS 资源。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "创建 Amazon Machine Images (AMI) 以备份 EC2 实例。将 AMI 复制到辅助 AWS 区域。使用 AWS Lambda 和自定义脚本在辅助区域中自动部署基础设施。",
      "B": "创建 Amazon Machine Images (AMI) 以备份 EC2 实例。将 AMI 复制到辅助 AWS 区域。使用 AWS CloudFormation 在辅助区域中自动部署基础设施。",
      "C": "在辅助 AWS 区域中启动 EC2 实例。始终保持辅助区域中的 EC2 实例处于活动状态。",
      "D": "在辅助可用区中启动 EC2 实例。始终保持辅助可用区中的 EC2 实例处于活动状态。"
    }
  },
  {
    "id": 275,
    "topic": "1",
    "question_en": "A company runs an internal browser-based application. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight. Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning. How should the scaling be changed to address the staff complaints and keep costs to a minimum?",
    "options_en": {
      "A": "Implement a scheduled action that sets the desired capacity to 20 shortly before the ofice opens.",
      "B": "Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.",
      "C": "Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.",
      "D": "Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the ofice opens."
    },
    "correct_answer": "A",
    "vote_percentage": "66%",
    "question_cn": "一家公司运行一个内部基于浏览器的应用程序。该应用程序在Application Load Balancer后面的 Amazon EC2 实例上运行。这些实例在跨多个可用区的 Amazon EC2 Auto Scaling 组中运行。Auto Scaling 组在工作时间内扩展到 20 个实例，但在夜间缩减到 2 个实例。员工抱怨说，虽然应用程序在上午中期运行良好，但在一天开始时非常慢。应该如何更改扩展以解决员工的抱怨并最大限度地降低成本？",
    "options_cn": {
      "A": "实施一个预定操作，在办公室开始前不久将期望容量设置为 20。",
      "B": "实施一个在较低 CPU 阈值触发的步进扩展操作，并减少冷却时间。",
      "C": "实施一个在较低 CPU 阈值触发的目标跟踪操作，并减少冷却时间。",
      "D": "实施一个预定操作，在办公室开始前不久将最小和最大容量设置为 20。"
    }
  },
  {
    "id": 276,
    "topic": "1",
    "question_en": "A company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application’ s data layer that uses Oracle-specific PL/SQL functions. Trafic to the application has been steadily increasing. This is causing the EC2 instances to become overloaded and the RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that trafic will continue to increase at a steady but unpredictable rate before leveling off. What should a solutions architect do to ensure the system can automatically scale for the increased trafic? (Choose two.)",
    "options_en": {
      "A": "Configure storage Auto Scaling on the RDS for Oracle instance.",
      "B": "Migrate the database to Amazon Aurora to use Auto Scaling storage.",
      "C": "Configure an alarm on the RDS for Oracle instance for low free storage space.",
      "D": "Configure the Auto Scaling group to use the average CPU as the scaling metric",
      "E": "Configure the Auto Scaling group to use the average free memory as the scaling metric."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家公司在其自动伸缩组中的多个 Amazon EC2 实例上部署了一个多层应用程序。一个 Amazon RDS for Oracle 实例是该应用程序的数据层，它使用 Oracle 特有的 PL/SQL 函数。应用程序的流量一直在稳步增加。这导致 EC2 实例过载，并且 RDS 实例的存储空间不足。自动伸缩组没有任何伸缩指标，仅定义了最小的健康实例数。该公司预测，在达到稳定水平之前，流量将继续以稳定但不可预测的速度增长。 解决方案架构师应该怎么做才能确保系统可以自动扩展以应对增加的流量？（选择两个。）",
    "options_cn": {
      "A": "在 RDS for Oracle 实例上配置存储自动伸缩。",
      "B": "将数据库迁移到 Amazon Aurora 以使用自动伸缩存储。",
      "C": "在 RDS for Oracle 实例上配置一个关于可用存储空间低的告警。",
      "D": "配置自动伸缩组以使用平均 CPU 作为伸缩指标。",
      "E": "配置自动伸缩组以使用平均可用内存作为伸缩指标。"
    }
  },
  {
    "id": 277,
    "topic": "1",
    "question_en": "A company provides an online service for posting video content and transcoding it for use by any mobile platform. The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing. As the popularity of the service has grown over time, the storage costs have become too expensive. Which storage solution is MOST cost-effective?",
    "options_en": {
      "A": "Use AWS Storage Gateway for files to store and process the video content.",
      "B": "Use AWS Storage Gateway for volumes to store and process the video content.",
      "C": "Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).",
      "D": "Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司提供在线服务，用于发布视频内容并转码，以便在任何移动平台上使用。应用程序架构使用 Amazon Elastic File System (Amazon EFS) Standard 来收集和存储视频，以便多个 Amazon EC2 Linux 实例可以访问视频内容进行处理。随着服务越来越受欢迎，存储成本变得过于昂贵。哪种存储解决方案最具成本效益？",
    "options_cn": {
      "A": "使用 AWS Storage Gateway for files 来存储和处理视频内容。",
      "B": "使用 AWS Storage Gateway for volumes 来存储和处理视频内容。",
      "C": "使用 Amazon EFS 存储视频内容。处理完成后，将文件传输到 Amazon Elastic Block Store (Amazon EBS)。",
      "D": "使用 Amazon S3 存储视频内容。将文件临时移动到连接到服务器的 Amazon Elastic Block Store (Amazon EBS) 卷上进行处理。"
    }
  },
  {
    "id": 278,
    "topic": "1",
    "question_en": "A company wants to create an application to store employee data in a hierarchical structured relationship. The company needs a minimum- latency response to high-trafic queries for the employee data and must protect any sensitive data. The company also needs to receive monthly email messages if any financial information is present in the employee data. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use Amazon Redshift to store the employee data in hierarchies. Unload the data to Amazon S3 every month.",
      "B": "Use Amazon DynamoDB to store the employee data in hierarchies. Export the data to Amazon S3 every month.",
      "C": "Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly events to AWS Lambda.",
      "D": "Use Amazon Athena to analyze the employee data in Amazon S3. Integrate Athena with Amazon QuickSight to publish analysis dashboards and share the dashboards with users",
      "E": "Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司希望创建一个应用程序，以分层结构关系存储员工数据。该公司需要对员工数据的高流量查询提供最低延迟的响应，并且必须保护任何敏感数据。该公司还需要在员工数据中存在任何财务信息时，每月收到电子邮件消息。一个解决方案架构师应该采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Amazon Redshift 以分层结构存储员工数据。每月将数据卸载到 Amazon S3。",
      "B": "使用 Amazon DynamoDB 以分层结构存储员工数据。每月将数据导出到 Amazon S3。",
      "C": "为 AWS 账户配置 Amazon Macie。将 Macie 与 Amazon EventBridge 集成，以便每月向 AWS Lambda 发送事件。",
      "D": "使用 Amazon Athena 分析 Amazon S3 中的员工数据。将 Athena 与 Amazon QuickSight 集成，以发布分析仪表板并将仪表板与用户共享。",
      "E": "为 AWS 账户配置 Amazon Macie。将 Macie 与 Amazon EventBridge 集成，通过 Amazon Simple Notification Service (Amazon SNS) 订阅发送每月通知。"
    }
  },
  {
    "id": 279,
    "topic": "1",
    "question_en": "A company has an application that is backed by an Amazon DynamoDB table. The company’s compliance requirements specify that database backups must be taken every month, must be available for 6 months, and must be retained for 7 years. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years.",
      "B": "Create a DynamoDB on-demand backup of the DynamoDB table on the first day of each month. Transition the backup to Amazon S3 Glacier Flexible Retrieval after 6 months. Create an S3 Lifecycle policy to delete backups that are older than 7 years.",
      "C": "Use the AWS SDK to develop a script that creates an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the script on the first day of each month. Create a second script that will run on the second day of each month to transition DynamoDB backups that are older than 6 months to cold storage and to delete backups that are older than 7 years.",
      "D": "Use the AWS CLI to create an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the command on the first day of each month with a cron expression. Specify in the command to transition the backups to cold storage after 6 months and to delete the backups after 7 years."
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一家公司的应用程序由 Amazon DynamoDB 表提供支持。 公司的合规性要求规定，必须每月进行数据库备份，备份必须保留 6 个月，并且必须保留 7 年。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Backup 计划，在每月的第 1 天备份 DynamoDB 表。 指定一个生命周期策略，该策略在 6 个月后将备份转移到冷存储。 将每个备份的保留期设置为 7 年。",
      "B": "在每月的第 1 天创建 DynamoDB 按需备份。 在 6 个月后将备份转移到 Amazon S3 Glacier Flexible Retrieval。 创建一个 S3 生命周期策略以删除超过 7 年的备份。",
      "C": "使用 AWS SDK 开发一个脚本，该脚本创建 DynamoDB 表的按需备份。 设置一个 Amazon EventBridge 规则，该规则在每月的第 1 天运行该脚本。 创建第二个脚本，该脚本将在每月的第 2 天运行，以将超过 6 个月的 DynamoDB 备份转移到冷存储，并删除超过 7 年的备份。",
      "D": "使用 AWS CLI 创建 DynamoDB 表的按需备份。 设置一个 Amazon EventBridge 规则，该规则使用 cron 表达式在每月的第 1 天运行该命令。 在命令中指定在 6 个月后将备份转移到冷存储，并在 7 年后删除备份。"
    }
  },
  {
    "id": 280,
    "topic": "1",
    "question_en": "A company is using Amazon CloudFront with its website. The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company’s Amazon S3 buckets. The company needs to perform advanced analyses on the logs and build visualizations. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.",
      "B": "Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.",
      "C": "Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.",
      "D": "Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司在其网站上使用 Amazon CloudFront。该公司已在 CloudFront 分发上启用了日志记录，并将日志保存在公司的 Amazon S3 存储桶之一中。该公司需要对日志执行高级分析并构建可视化。解决方案架构师应如何满足这些要求？",
    "options_cn": {
      "A": "在 Amazon Athena 中使用标准 SQL 查询来分析 S3 存储桶中的 CloudFront 日志。 使用 AWS Glue 可视化结果。",
      "B": "在 Amazon Athena 中使用标准 SQL 查询来分析 S3 存储桶中的 CloudFront 日志。 使用 Amazon QuickSight 可视化结果。",
      "C": "在 Amazon DynamoDB 中使用标准 SQL 查询来分析 S3 存储桶中的 CloudFront 日志。使用 AWS Glue 可视化结果。",
      "D": "在 Amazon DynamoDB 中使用标准 SQL 查询来分析 S3 存储桶中的 CloudFront 日志。 使用 Amazon QuickSight 可视化结果。"
    }
  },
  {
    "id": 281,
    "topic": "1",
    "question_en": "A company runs a fieet of web servers using an Amazon RDS for PostgreSQL DB instance. After a routine compliance check, the company sets a standard that requires a recovery point objective (RPO) of less than 1 second for all its production databases. Which solution meets these requirements?",
    "options_en": {
      "A": "Enable a Multi-AZ deployment for the DB instance.",
      "B": "Enable auto scaling for the DB instance in one Availability Zone.",
      "C": "Configure the DB instance in one Availability Zone, and create multiple read replicas in a separate Availability Zone.",
      "D": "Configure the DB instance in one Availability Zone, and configure AWS Database Migration Service (AWS DMS) change data capture (CDC) tasks."
    },
    "correct_answer": "D",
    "vote_percentage": "91%",
    "question_cn": "一家公司使用 Amazon RDS for PostgreSQL 数据库实例运行一组 Web 服务器。在例行合规性检查之后，该公司制定了一项标准，要求其所有生产数据库的恢复点目标 (RPO) 小于 1 秒。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "为数据库实例启用多可用区部署。",
      "B": "在一个可用区中为数据库实例启用自动缩放。",
      "C": "在一个可用区中配置数据库实例，并在单独的可用区中创建多个只读副本。",
      "D": "在一个可用区中配置数据库实例，并配置 AWS Database Migration Service (AWS DMS) 变更数据捕获 (CDC) 任务。"
    }
  },
  {
    "id": 282,
    "topic": "1",
    "question_en": "A company runs a web application that is deployed on Amazon EC2 instances in the private subnet of a VPC. An Application Load Balancer (ALB) that extends across the public subnets directs web trafic to the EC2 instances. The company wants to implement new security measures to restrict inbound trafic from the ALB to the EC2 instances while preventing access from any other source inside or outside the private subnet of the EC2 instances. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure a route in a route table to direct trafic from the internet to the private IP addresses of the EC2 instances.",
      "B": "Configure the security group for the EC2 instances to only allow trafic that comes from the security group for the ALB.",
      "C": "Move the EC2 instances into the public subnet. Give the EC2 instances a set of Elastic IP addresses.",
      "D": "Configure the security group for the ALB to allow any TCP trafic on any port."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司运行一个部署在 VPC 私有子网中的 Amazon EC2 实例上的 Web 应用程序。一个跨越公有子网的 Application Load Balancer (ALB) 将 Web 流量定向到 EC2 实例。该公司希望实施新的安全措施，以限制来自 ALB 到 EC2 实例的入站流量，同时阻止来自 EC2 实例私有子网内部或外部任何其他 源 的访问。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在路由表中配置一个路由，将来自互联网的流量定向到 EC2 实例的私有 IP 地址。",
      "B": "配置 EC2 实例的安全组，只允许来自 ALB 安全组的流量。",
      "C": "将 EC2 实例移至公有子网。为 EC2 实例分配一组弹性 IP 地址。",
      "D": "配置 ALB 的安全组以允许任何端口上的任何 TCP 流量。"
    }
  },
  {
    "id": 283,
    "topic": "1",
    "question_en": "A research company runs experiments that are powered by a simulation application and a visualization application. The simulation application runs on Linux and outputs intermediate data to an NFS share every 5 minutes. The visualization application is a Windows desktop application that displays the simulation output and requires an SMB file system. The company maintains two synchronized file systems. This strategy is causing data duplication and ineficient resource usage. The company needs to migrate the applications to AWS without making code changes to either application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate both applications to AWS Lambda. Create an Amazon S3 bucket to exchange data between the applications.",
      "B": "Migrate both applications to Amazon Elastic Container Service (Amazon ECS). Configure Amazon FSx File Gateway for storage.",
      "C": "Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon Simple Queue Service (Amazon SQS) to exchange data between the applications.",
      "D": "Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon FSx for NetApp ONTAP for storage."
    },
    "correct_answer": "D",
    "vote_percentage": "98%",
    "question_cn": "一家研究公司运行由模拟应用程序和可视化应用程序驱动的实验。模拟应用程序在 Linux 上运行，每 5 分钟将中间数据输出到 NFS 共享。可视化应用程序是一个 Windows 桌面应用程序，用于显示模拟输出，并需要一个 SMB 文件系统。该公司维护两个同步的文件系统。这种策略导致数据重复和资源使用效率低下。该公司需要将应用程序迁移到 AWS，而无需对任何一个应用程序进行代码更改。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将两个应用程序迁移到 AWS Lambda。创建一个 Amazon S3 存储桶以在应用程序之间交换数据。",
      "B": "将两个应用程序迁移到 Amazon Elastic Container Service (Amazon ECS)。配置 Amazon FSx File Gateway 用于存储。",
      "C": "将模拟应用程序迁移到 Linux Amazon EC2 实例。将可视化应用程序迁移到 Windows EC2 实例。配置 Amazon Simple Queue Service (Amazon SQS) 以在应用程序之间交换数据。",
      "D": "将模拟应用程序迁移到 Linux Amazon EC2 实例。将可视化应用程序迁移到 Windows EC2 实例。配置 Amazon FSx for NetApp ONTAP 用于存储。"
    }
  },
  {
    "id": 284,
    "topic": "1",
    "question_en": "As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most eficient way to obtain this report information. Which solution meets these requirements?",
    "options_en": {
      "A": "Run a query with Amazon Athena to generate the report.",
      "B": "Create a report in Cost Explorer and download the report.",
      "C": "Access the bill details from the billing dashboard and download the bill.",
      "D": "Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES)."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "作为预算规划的一部分，管理层希望获得一份按用户列出的 AWS 计费项目的报告。这些数据将用于创建部门预算。一位解决方案架构师需要确定获取此报告信息的最有效方法。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 Amazon Athena 运行查询以生成报告。",
      "B": "在 Cost Explorer 中创建报告并下载该报告。",
      "C": "从账单仪表板访问账单详细信息并下载账单。",
      "D": "在 AWS Budgets 中修改一个成本预算，以通过 Amazon Simple Email Service (Amazon SES) 发出警报。"
    }
  },
  {
    "id": 285,
    "topic": "1",
    "question_en": "A company hosts its static website by using Amazon S3. The company wants to add a contact form to its webpage. The contact form will have dynamic server-side components for users to input their name, email address, phone number, and user message. The company anticipates that there will be fewer than 100 site visits each month. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Host a dynamic contact form page in Amazon Elastic Container Service (Amazon ECS). Set up Amazon Simple Email Service (Amazon SES) to connect to any third-party email provider.",
      "B": "Create an Amazon API Gateway endpoint with an AWS Lambda backend that makes a call to Amazon Simple Email Service (Amazon SES).",
      "C": "Convert the static webpage to dynamic by deploying Amazon Lightsail. Use client-side scripting to build the contact form. Integrate the form with Amazon WorkMail.",
      "D": "Create a t2.micro Amazon EC2 instance. Deploy a LAMP (Linux, Apache, MySQL, PHP/Perl/Python) stack to host the webpage. Use client-side scripting to build the contact form. Integrate the form with Amazon WorkMail."
    },
    "correct_answer": "B",
    "vote_percentage": "93%",
    "question_cn": "一家公司使用 Amazon S3 托管其静态网站。该公司希望在其网页中添加一个联系表单。联系表单将具有动态服务器端组件，供用户输入他们的姓名、电子邮件地址、电话号码和用户消息。该公司预计每月访问次数少于 100 次。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "在 Amazon Elastic Container Service (Amazon ECS) 中托管动态联系表单页面。 设置 Amazon Simple Email Service (Amazon SES) 以连接到任何第三方电子邮件提供商。",
      "B": "创建一个 Amazon API Gateway 端点，该端点具有一个调用 Amazon Simple Email Service (Amazon SES) 的 AWS Lambda 后端。",
      "C": "通过部署 Amazon Lightsail 将静态网页转换为动态网页。 使用客户端脚本构建联系表单。 将该表单与 Amazon WorkMail 集成。",
      "D": "创建一个 t2.micro Amazon EC2 实例。 部署一个 LAMP（Linux、Apache、MySQL、PHP/Perl/Python）堆栈来托管网页。 使用客户端脚本构建联系表单。 将该表单与 Amazon WorkMail 集成。"
    }
  },
  {
    "id": 286,
    "topic": "1",
    "question_en": "A company has a static website that is hosted on Amazon CloudFront in front of Amazon S3. The static website uses a database backend. The company notices that the website does not refiect updates that have been made in the website’s Git repository. The company checks the continuous integration and continuous delivery (CI/CD) pipeline between the Git repository and Amazon S3. The company verifies that the webhooks are configured properly and that the CI/CD pipeline is sending messages that indicate successful deployments. A solutions architect needs to implement a solution that displays the updates on the website. Which solution will meet these requirements?",
    "options_en": {
      "A": "Add an Application Load Balancer.",
      "B": "Add Amazon ElastiCache for Redis or Memcached to the database layer of the web application.",
      "C": "Invalidate the CloudFront cache.",
      "D": "Use AWS Certificate Manager (ACM) to validate the website’s SSL certificate."
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一家公司在其 Amazon S3 前面托管了一个静态网站，该网站位于 Amazon CloudFront 上。该静态网站使用数据库后端。该公司注意到，网站并未反映在网站的 Git 存储库中进行的更新。该公司检查了 Git 存储库和 Amazon S3 之间的持续集成和持续交付 (CI/CD) 管道。该公司验证了 Webhook 配置正确，并且 CI/CD 管道正在发送指示部署成功的消息。一位解决方案架构师需要实施一个解决方案，以在网站上显示更新。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "添加一个 Application Load Balancer。",
      "B": "在 Web 应用程序的数据库层添加 Amazon ElastiCache for Redis 或 Memcached。",
      "C": "使 CloudFront 缓存失效。",
      "D": "使用 AWS Certificate Manager (ACM) 验证网站的 SSL 证书。"
    }
  },
  {
    "id": 287,
    "topic": "1",
    "question_en": "A company wants to migrate a Windows-based application from on premises to the AWS Cloud. The application has three tiers: an application tier, a business tier, and a database tier with Microsoft SQL Server. The company wants to use specific features of SQL Server such as native backups and Data Quality Services. The company also needs to share files for processing between the tiers. How should a solutions architect design the architecture to meet these requirements?",
    "options_en": {
      "A": "Host all three tiers on Amazon EC2 instances. Use Amazon FSx File Gateway for file sharing between the tiers.",
      "B": "Host all three tiers on Amazon EC2 instances. Use Amazon FSx for Windows File Server for file sharing between the tiers.",
      "C": "Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use Amazon Elastic File System (Amazon EFS) for file sharing between the tiers.",
      "D": "Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume for file sharing between the tiers."
    },
    "correct_answer": "B",
    "vote_percentage": "89%",
    "question_cn": "一家公司希望将基于 Windows 的应用程序从本地迁移到 AWS 云。该应用程序有三层：应用层、业务层和具有 Microsoft SQL Server 的数据库层。该公司希望使用 SQL Server 的特定功能，例如原生备份和数据质量服务。该公司还需要在各层之间共享文件以进行处理。解决方案架构师应该如何设计架构以满足这些要求？",
    "options_cn": {
      "A": "将所有三层托管在 Amazon EC2 实例上。使用 Amazon FSx File Gateway 在各层之间共享文件。",
      "B": "将所有三层托管在 Amazon EC2 实例上。使用 Amazon FSx for Windows File Server 在各层之间共享文件。",
      "C": "将应用层和业务层托管在 Amazon EC2 实例上。将数据库层托管在 Amazon RDS 上。使用 Amazon Elastic File System (Amazon EFS) 在各层之间共享文件。",
      "D": "将应用层和业务层托管在 Amazon EC2 实例上。将数据库层托管在 Amazon RDS 上。使用 Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) 卷在各层之间共享文件。"
    }
  },
  {
    "id": 288,
    "topic": "1",
    "question_en": "A company is migrating a Linux-based web server group to AWS. The web servers must access files in a shared file store for some content. The company must not make any changes to the application. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an Amazon S3 Standard bucket with access to the web servers.",
      "B": "Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.",
      "C": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on all web servers.",
      "D": "Configure a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume to all web servers."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将基于 Linux 的 Web 服务器组迁移到 AWS。Web 服务器必须访问共享文件存储中的文件以获取一些内容。公司不得对应用程序进行任何更改。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon S3 标准存储桶，并允许 Web 服务器访问。",
      "B": "配置一个 Amazon CloudFront 分发，将 Amazon S3 存储桶作为源。",
      "C": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。在所有 Web 服务器上挂载 EFS 文件系统。",
      "D": "配置一个通用型 SSD (gp3) Amazon Elastic Block Store (Amazon EBS) 卷。将 EBS 卷挂载到所有 Web 服务器。"
    }
  },
  {
    "id": 289,
    "topic": "1",
    "question_en": "A company has an AWS Lambda function that needs read access to an Amazon S3 bucket that is located in the same AWS account. Which solution will meet these requirements in the MOST secure manner?",
    "options_en": {
      "A": "Apply an S3 bucket policy that grants read access to the S3 bucket.",
      "B": "Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to the S3 bucket.",
      "C": "Embed an access key and a secret key in the Lambda function’s code to grant the required IAM permissions for read access to the S3 bucket.",
      "D": "Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to all S3 buckets in the account."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个 AWS Lambda 函数，需要读取位于同一 AWS 账户中的 Amazon S3 存储桶。哪种解决方案将以最安全的方式满足这些要求？",
    "options_cn": {
      "A": "应用一个 S3 存储桶策略，授予对 S3 存储桶的读取访问权限。",
      "B": "将一个 IAM 角色应用于 Lambda 函数。将一个 IAM 策略应用于该角色以授予对 S3 存储桶的读取访问权限。",
      "C": "将访问密钥和秘密密钥嵌入到 Lambda 函数的代码中，以授予对 S3 存储桶的读取访问所需的 IAM 权限。",
      "D": "将一个 IAM 角色应用于 Lambda 函数。将一个 IAM 策略应用于该角色，以授予对该账户中所有 S3 存储桶的读取访问权限。"
    }
  },
  {
    "id": 290,
    "topic": "1",
    "question_en": "A company hosts a web application on multiple Amazon EC2 instances. The EC2 instances are in an Auto Scaling group that scales in response to user demand. The company wants to optimize cost savings without making a long-term commitment. Which EC2 instance purchasing option should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Dedicated Instances only",
      "B": "On-Demand Instances only",
      "C": "A mix of On-Demand Instances and Spot Instances",
      "D": "A mix of On-Demand Instances and Reserved Instances"
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一家公司在多个 Amazon EC2 实例上托管一个 Web 应用程序。EC2 实例位于一个 Auto Scaling 组中，该组会根据用户需求进行扩展。该公司希望优化成本节约，而无需做出长期承诺。解决方案架构师应该推荐哪种 EC2 实例购买选项来满足这些要求？",
    "options_cn": {
      "A": "仅限 Dedicated Instances",
      "B": "仅限 On-Demand Instances",
      "C": "On-Demand Instances 和 Spot Instances 的混合",
      "D": "On-Demand Instances 和 Reserved Instances 的混合"
    }
  },
  {
    "id": 291,
    "topic": "1",
    "question_en": "A media company uses Amazon CloudFront for its publicly available streaming video content. The company wants to secure the video content that is hosted in Amazon S3 by controlling who has access. Some of the company’s users are using a custom HTTP client that does not support cookies. Some of the company’s users are unable to change the hardcoded URLs that they are using for access. Which services or methods will meet these requirements with the LEAST impact to the users? (Choose two.)",
    "options_en": {
      "A": "Signed cookies",
      "B": "Signed URLs",
      "C": "AWS AppSync",
      "D": "JSON Web Token (JWT)",
      "E": "AWS Secrets Manager"
    },
    "correct_answer": "C",
    "vote_percentage": "85%",
    "question_cn": "一家媒体公司使用 Amazon CloudFront 提供公开流媒体视频内容。该公司希望通过控制访问权限来保护托管在 Amazon S3 中的视频内容。该公司的一些用户正在使用不支持 cookies 的自定义 HTTP 客户端。该公司的一些用户无法更改他们用于访问的硬编码 URL。哪些服务或方法将以对用户影响最小的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "签名 cookies",
      "B": "签名 URLs",
      "C": "AWS AppSync",
      "D": "JSON Web Token (JWT)",
      "E": "AWS Secrets Manager"
    }
  },
  {
    "id": 292,
    "topic": "1",
    "question_en": "A company is preparing a new data platform that will ingest real-time streaming data from multiple sources. The company needs to transform the data before writing the data to Amazon S3. The company needs the ability to use SQL to query the transformed data. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use Amazon Kinesis Data Streams to stream the data. Use Amazon Kinesis Data Analytics to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.",
      "B": "Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use AWS Glue to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.",
      "C": "Use AWS Database Migration Service (AWS DMS) to ingest the data. Use Amazon EMR to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.",
      "D": "Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use Amazon Kinesis Data Analytics to transform the data and to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3",
      "E": "Use Amazon Kinesis Data Streams to stream the data. Use AWS Glue to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "91%",
    "question_cn": "一家公司正在准备一个新的数据平台，该平台将从多个 源 获取实时流数据。该公司需要在将数据写入 Amazon S3 之前转换数据。该公司需要能够使用 SQL 查询转换后的数据。哪些解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Streams 传输数据流。使用 Amazon Kinesis Data Analytics 转换数据。使用 Amazon Kinesis Data Firehose 将数据写入 Amazon S3。使用 Amazon Athena 从 Amazon S3 查询转换后的数据。",
      "B": "使用 Amazon Managed Streaming for Apache Kafka (Amazon MSK) 传输数据流。使用 AWS Glue 转换数据并将数据写入 Amazon S3。使用 Amazon Athena 从 Amazon S3 查询转换后的数据。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 获取数据。使用 Amazon EMR 转换数据并将数据写入 Amazon S3。使用 Amazon Athena 从 Amazon S3 查询转换后的数据。",
      "D": "使用 Amazon Managed Streaming for Apache Kafka (Amazon MSK) 传输数据流。使用 Amazon Kinesis Data Analytics 转换数据并将数据写入 Amazon S3。使用 Amazon RDS 查询编辑器从 Amazon S3 查询转换后的数据。",
      "E": "使用 Amazon Kinesis Data Streams 传输数据流。使用 AWS Glue 转换数据。使用 Amazon Kinesis Data Firehose 将数据写入 Amazon S3。使用 Amazon RDS 查询编辑器从 Amazon S3 查询转换后的数据。"
    }
  },
  {
    "id": 293,
    "topic": "1",
    "question_en": "A company has an on-premises volume backup solution that has reached its end of life. The company wants to use AWS as part of a new backup solution and wants to maintain local access to all the data while it is backed up on AWS. The company wants to ensure that the data backed up on AWS is automatically and securely transferred. Which solution meets these requirements?",
    "options_en": {
      "A": "Use AWS Snowball to migrate data out of the on-premises solution to Amazon S3. Configure on-premises systems to mount the Snowball S3 endpoint to provide local access to the data.",
      "B": "Use AWS Snowball Edge to migrate data out of the on-premises solution to Amazon S3. Use the Snowball Edge file interface to provide on-premises systems with local access to the data.",
      "C": "Use AWS Storage Gateway and configure a cached volume gateway. Run the Storage Gateway software appliance on premises and configure a percentage of data to cache locally. Mount the gateway storage volumes to provide local access to the data.",
      "D": "Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司现有的本地卷备份解决方案已达到生命周期终点。该公司希望使用 AWS 作为新备份解决方案的一部分，并希望在 AWS 上备份数据的同时保持对所有数据的本地访问。该公司希望确保在 AWS 上备份的数据能够自动且安全地传输。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 AWS Snowball 将数据从本地解决方案迁移到 Amazon S3。配置本地系统以挂载 Snowball S3 端点，以提供对数据的本地访问。",
      "B": "使用 AWS Snowball Edge 将数据从本地解决方案迁移到 Amazon S3。使用 Snowball Edge 文件接口为本地系统提供对数据的本地访问。",
      "C": "使用 AWS Storage Gateway 并配置缓存卷网关。在本地运行 Storage Gateway 软件设备，并配置一部分数据在本地缓存。挂载网关存储卷以提供对数据的本地访问。",
      "D": "使用 AWS Storage Gateway 并配置存储卷网关。在本地运行 Storage Gateway 软件设备，并将网关存储卷映射到本地存储。挂载网关存储卷以提供对数据的本地访问。"
    }
  },
  {
    "id": 294,
    "topic": "1",
    "question_en": "An application that is hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Trafic must not traverse the internet. How should a solutions architect configure access to meet these requirements?",
    "options_en": {
      "A": "Create a private hosted zone by using Amazon Route 53.",
      "B": "Set up a gateway VPC endpoint for Amazon S3 in the VPC.",
      "C": "Configure the EC2 instances to use a NAT gateway to access the S3 bucket.",
      "D": "Establish an AWS Site-to-Site VPN connection between the VPC and the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "托管在 Amazon EC2 实例上的应用程序需要访问一个 Amazon S3 存储桶。流量不能穿过互联网。解决方案架构师应该如何配置访问以满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Route 53 创建一个私有托管区域。",
      "B": "在 VPC 中为 Amazon S3 设置一个网关 VPC endpoint。",
      "C": "配置 EC2 实例使用 NAT Gateway 访问 S3 存储桶。",
      "D": "在 VPC 和 S3 存储桶之间建立一个 AWS Site-to-Site VPN 连接。"
    }
  },
  {
    "id": 295,
    "topic": "1",
    "question_en": "An ecommerce company stores terabytes of customer data in the AWS Cloud. The data contains personally identifiable information (PII). The company wants to use the data in three applications. Only one of the applications needs to process the PII. The PII must be removed before the other two applications process the data. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the data in an Amazon DynamoDB table. Create a proxy application layer to intercept and process the data that each application requests.",
      "B": "Store the data in an Amazon S3 bucket. Process and transform the data by using S3 Object Lambda before returning the data to the requesting application.",
      "C": "Process the data and store the transformed data in three separate Amazon S3 buckets so that each application has its own custom dataset. Point each application to its respective S3 bucket.",
      "D": "Process the data and store the transformed data in three separate Amazon DynamoDB tables so that each application has its own custom dataset. Point each application to its respective DynamoDB table."
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一家电子商务公司将数TB的客户数据存储在 AWS Cloud 中。数据包含个人身份信息 (PII)。该公司希望在三个应用程序中使用这些数据。只有一个应用程序需要处理 PII。在另外两个应用程序处理数据之前，必须删除 PII。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将数据存储在 Amazon DynamoDB 表中。创建一个代理应用程序层来拦截和处理每个应用程序请求的数据。",
      "B": "将数据存储在 Amazon S3 存储桶中。在将数据返回给请求应用程序之前，使用 S3 Object Lambda 处理和转换数据。",
      "C": "处理数据并将转换后的数据存储在三个单独的 Amazon S3 存储桶中，以便每个应用程序都有自己的自定义数据集。将每个应用程序指向其各自的 S3 存储桶。",
      "D": "处理数据并将转换后的数据存储在三个单独的 Amazon DynamoDB 表中，以便每个应用程序都有自己的自定义数据集。将每个应用程序指向其各自的 DynamoDB 表。"
    }
  },
  {
    "id": 296,
    "topic": "1",
    "question_en": "A development team has launched a new application that is hosted on Amazon EC2 instances inside a development VPC. A solutions architect needs to create a new VPC in the same account. The new VPC will be peered with the development VPC. The VPC CIDR block for the development VPC is 192.168.0.0/24. The solutions architect needs to create a CIDR block for the new VPC. The CIDR block must be valid for a VPC peering connection to the development VPC. What is the SMALLEST CIDR block that meets these requirements?",
    "options_en": {
      "A": "10.0.1.0/32",
      "B": "192.168.0.0/24",
      "C": "192.168.1.0/32",
      "D": "10.0.1.0/24"
    },
    "correct_answer": "B",
    "vote_percentage": "98%",
    "question_cn": "一个开发团队启动了一个新的应用程序，该应用程序托管在开发 VPC 中的 Amazon EC2 实例上。 一位解决方案架构师需要在同一账户中创建一个新的 VPC。 新的 VPC 将与开发 VPC 对等互连。 开发 VPC 的 VPC CIDR 块是 192.168.0.0/24。 解决方案架构师需要为新的 VPC 创建一个 CIDR 块。 CIDR 块必须对与开发 VPC 的 VPC 对等连接有效。 满足这些要求的最小 CIDR 块是什么？",
    "options_cn": {
      "A": "10.0.1.0/32",
      "B": "192.168.0.0/24",
      "C": "192.168.1.0/32",
      "D": "10.0.1.0/24"
    }
  },
  {
    "id": 297,
    "topic": "1",
    "question_en": "A company deploys an application on five Amazon EC2 instances. An Application Load Balancer (ALB) distributes trafic to the instances by using a target group. The average CPU usage on each of the instances is below 10% most of the time, with occasional surges to 65%. A solutions architect needs to implement a solution to automate the scalability of the application. The solution must optimize the cost of the architecture and must ensure that the application has enough CPU resources when surges occur. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon CloudWatch alarm that enters the ALARM state when the CPUUtilization metric is less than 20%. Create an AWS Lambda function that the CloudWatch alarm invokes to terminate one of the EC2 instances in the ALB target group.",
      "B": "Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set a target tracking scaling policy that is based on the ASGAverageCPUUtilization metric. Set the minimum instances to 2, the desired capacity to 3, the maximum instances to 6, and the target value to 50%. Add the EC2 instances to the Auto Scaling group.",
      "C": "Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set the minimum instances to 2, the desired capacity to 3, and the maximum instances to 6. Add the EC2 instances to the Auto Scaling group.",
      "D": "Create two Amazon CloudWatch alarms. Configure the first CloudWatch alarm to enter the ALARM state when the average CPUUtilization metric is below 20%. Configure the second CloudWatch alarm to enter the ALARM state when the average CPUUtilization matric is above 50%. Configure the alarms to publish to an Amazon Simple Notification Service (Amazon SNS) topic to send an email message. After receiving the message, log in to decrease or increase the number of EC2 instances that are running."
    },
    "correct_answer": "D",
    "vote_percentage": "96%",
    "question_cn": "一家公司在五个 Amazon EC2 实例上部署了一个应用程序。一个 Application Load Balancer (ALB) 通过使用目标组将流量分配到这些实例。大多数时候，每个实例的平均 CPU 使用率低于 10%，偶尔会激增到 65%。一位解决方案架构师需要实施一个解决方案来自动化应用程序的可伸缩性。该解决方案必须优化架构的成本，并确保应用程序在激增时拥有足够的 CPU 资源。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon CloudWatch 警报，当 CPUUtilization 指标小于 20% 时进入 ALARM 状态。创建一个 AWS Lambda 函数， CloudWatch 警报会调用该函数来终止 ALB 目标组中的一个 EC2 实例。",
      "B": "创建一个 EC2 Auto Scaling 组。选择现有的 ALB 作为负载均衡器，并选择现有的目标组作为目标组。设置一个基于 ASGAverageCPUUtilization 指标的目标跟踪扩展策略。将最小实例数设置为 2，期望容量设置为 3，最大实例数设置为 6，目标值设置为 50%。将 EC2 实例添加到 Auto Scaling 组。",
      "C": "创建一个 EC2 Auto Scaling 组。选择现有的 ALB 作为负载均衡器，并选择现有的目标组作为目标组。将最小实例数设置为 2，期望容量设置为 3，最大实例数设置为 6。将 EC2 实例添加到 Auto Scaling 组。",
      "D": "创建两个 Amazon CloudWatch 警报。将第一个 CloudWatch 警报配置为在平均 CPUUtilization 指标低于 20% 时进入 ALARM 状态。将第二个 CloudWatch 警报配置为在平均 CPUUtilization 指标高于 50% 时进入 ALARM 状态。配置警报以发布到 Amazon Simple Notification Service (Amazon SNS) 主题以发送电子邮件消息。在收到消息后，登录以减少或增加正在运行的 EC2 实例的数量。"
    }
  },
  {
    "id": 298,
    "topic": "1",
    "question_en": "A company is running a critical business application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances run in an Auto Scaling group and access an Amazon RDS DB instance. The design did not pass an operational review because the EC2 instances and the DB instance are all located in a single Availability Zone. A solutions architect must update the design to use a second Availability Zone. Which solution will make the application highly available?",
    "options_en": {
      "A": "Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance with connections to each network.",
      "B": "Provision two subnets that extend across both Availability Zones. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance with connections to each network.",
      "C": "Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment.",
      "D": "Provision a subnet that extends across both Availability Zones. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在Application Load Balancer之后使用Amazon EC2实例运行关键业务应用程序。EC2实例在Auto Scaling组中运行并访问Amazon RDS DB实例。该设计未通过运营审查，因为EC2实例和DB实例都位于单个可用区中。一个解决方案架构师必须更新设计以使用第二个可用区。哪个解决方案将使应用程序具有高可用性？",
    "options_cn": {
      "A": "在每个可用区中预置一个子网。配置Auto Scaling组以跨两个可用区分配EC2实例。配置DB实例与每个网络建立连接。",
      "B": "预置两个跨越两个可用区的子网。配置Auto Scaling组以跨两个可用区分配EC2实例。配置DB实例与每个网络建立连接。",
      "C": "在每个可用区中预置一个子网。配置Auto Scaling组以跨两个可用区分配EC2实例。为DB实例配置Multi-AZ部署。",
      "D": "预置一个跨越两个可用区的子网。配置Auto Scaling组以跨两个可用区分配EC2实例。为DB实例配置Multi-AZ部署。"
    }
  },
  {
    "id": 299,
    "topic": "1",
    "question_en": "A research laboratory needs to process approximately 8 TB of data. The laboratory requires sub-millisecond latencies and a minimum throughput of 6 GBps for the storage subsystem. Hundreds of Amazon EC2 instances that run Amazon Linux will distribute and process the data. Which solution will meet the performance requirements?",
    "options_en": {
      "A": "Create an Amazon FSx for NetApp ONTAP file system. Sat each volume’ tiering policy to ALL. Import the raw data into the file system. Mount the fila system on the EC2 instances.",
      "B": "Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.",
      "C": "Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent HDD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.",
      "D": "Create an Amazon FSx for NetApp ONTAP file system. Set each volume’s tiering policy to NONE. Import the raw data into the file system. Mount the file system on the EC2 instances."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一个研究实验室需要处理大约 8 TB 的数据。该实验室需要亚毫秒级的延迟和存储子系统的最低 6 GBps 吞吐量。数百个运行 Amazon Linux 的 Amazon EC2 实例将分发和处理数据。哪种解决方案将满足性能要求？",
    "options_cn": {
      "A": "创建一个 Amazon FSx for NetApp ONTAP 文件系统。将每个卷的分层策略设置为 ALL。将原始数据导入文件系统。在 EC2 实例上挂载文件系统。",
      "B": "创建一个 Amazon S3 存储桶来存储原始数据。创建一个使用持久性 SSD 存储的 Amazon FSx for Lustre 文件系统。选择从 Amazon S3 导入数据和将数据导出到 Amazon S3 的选项。在 EC2 实例上挂载文件系统。",
      "C": "创建一个 Amazon S3 存储桶来存储原始数据。创建一个使用持久性 HDD 存储的 Amazon FSx for Lustre 文件系统。选择从 Amazon S3 导入数据和将数据导出到 Amazon S3 的选项。在 EC2 实例上挂载文件系统。",
      "D": "创建一个 Amazon FSx for NetApp ONTAP 文件系统。将每个卷的分层策略设置为 NONE。将原始数据导入文件系统。在 EC2 实例上挂载文件系统。"
    }
  },
  {
    "id": 300,
    "topic": "1",
    "question_en": "A company needs to migrate a legacy application from an on-premises data center to the AWS Cloud because of hardware capacity constraints. The application runs 24 hours a day, 7 days a week. The application’s database storage continues to grow over time. What should a solutions architect do to meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Migrate the application layer to Amazon EC2 Spot Instances. Migrate the data storage layer to Amazon S3.",
      "B": "Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon RDS On-Demand Instances.",
      "C": "Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon Aurora Reserved Instances.",
      "D": "Migrate the application layer to Amazon EC2 On-Demand Instances. Migrate the data storage layer to Amazon RDS Reserved Instances."
    },
    "correct_answer": "C",
    "vote_percentage": "86%",
    "question_cn": "由于硬件容量限制，一家公司需要将其旧版应用程序从本地数据中心迁移到 AWS 云。该应用程序每周 7 天、每天 24 小时运行。应用程序的数据库存储空间随着时间的推移不断增长。 解决方案架构师应该怎么做才能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将应用程序层迁移到 Amazon EC2 Spot 实例。将数据存储层迁移到 Amazon S3。",
      "B": "将应用程序层迁移到 Amazon EC2 Reserved 实例。将数据存储层迁移到 Amazon RDS On-Demand 实例。",
      "C": "将应用程序层迁移到 Amazon EC2 Reserved 实例。将数据存储层迁移到 Amazon Aurora Reserved 实例。",
      "D": "将应用程序层迁移到 Amazon EC2 On-Demand 实例。将数据存储层迁移到 Amazon RDS Reserved 实例。"
    }
  },
  {
    "id": 301,
    "topic": "1",
    "question_en": "A university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share. The laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days. Which AWS solution will meet these requirements?",
    "options_en": {
      "A": "AWS Snowcone",
      "B": "Amazon FSx File Gateway",
      "C": "AWS DataSync",
      "D": "AWS Transfer Family"
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一所大学研究实验室需要将 30 TB 的数据从本地 Windows 文件服务器迁移到 Amazon FSx for Windows File Server。该实验室拥有一个 1 Gbps 的网络链接，该链接由大学的许多其他部门共享。实验室希望实施一个数据迁移服务，以最大限度地提高数据传输的性能。然而，实验室需要能够控制该服务使用的带宽量，以最大限度地减少对其他部门的影响。数据迁移必须在接下来的 5 天内完成。以下哪个 AWS 解决方案将满足这些要求？",
    "options_cn": {
      "A": "AWS Snowcone",
      "B": "Amazon FSx File Gateway",
      "C": "AWS DataSync",
      "D": "AWS Transfer Family"
    }
  },
  {
    "id": 302,
    "topic": "1",
    "question_en": "A company wants to create a mobile app that allows users to stream slow-motion video clips on their mobile devices. Currently, the app captures video clips and uploads the video clips in raw format into an Amazon S3 bucket. The app retrieves these video clips directly from the S3 bucket. However, the videos are large in their raw format. Users are experiencing issues with buffering and playback on mobile devices. The company wants to implement solutions to maximize the performance and scalability of the app while minimizing operational overhead. Which combination of solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Deploy Amazon CloudFront for content delivery and caching.",
      "B": "Use AWS DataSync to replicate the video files across AW'S Regions in other S3 buckets.",
      "C": "Use Amazon Elastic Transcoder to convert the video files to more appropriate formats.",
      "D": "Deploy an Auto Sealing group of Amazon EC2 instances in Local Zones for content delivery and caching",
      "E": "Deploy an Auto Scaling group of Amazon EC2 instances to convert the video files to more appropriate formats."
    },
    "correct_answer": "A",
    "vote_percentage": "57%",
    "question_cn": "一家公司希望创建一个移动应用程序，允许用户在其移动设备上流式传输慢动作视频片段。目前，该应用程序捕获视频片段并将原始格式的视频片段上传到 Amazon S3 存储桶。该应用程序直接从 S3 存储桶检索这些视频片段。但是，视频以原始格式存储时非常大。用户在使用移动设备进行缓冲和播放时遇到问题。该公司希望实施解决方案，以最大限度地提高应用程序的性能和可扩展性，同时最大限度地减少运营开销。哪两种解决方案的组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "部署 Amazon CloudFront 进行内容交付和缓存。",
      "B": "使用 AWS DataSync 将视频文件复制到其他 AWS 区域的 S3 存储桶。",
      "C": "使用 Amazon Elastic Transcoder 将视频文件转换为更合适的格式。",
      "D": "在本地区域部署 Amazon EC2 实例的 Auto Scaling 组，用于内容交付和缓存。",
      "E": "部署 Amazon EC2 实例的 Auto Scaling 组，将视频文件转换为更合适的格式。"
    }
  },
  {
    "id": 303,
    "topic": "1",
    "question_en": "A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high trafic to the application upon its launch. However, the company wants to reduce costs when utilization decreases. What should a solutions architect recommend?",
    "options_en": {
      "A": "Use Amazon EC2 Auto Scaling to scale at certain periods based on previous trafic patterns.",
      "B": "Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.",
      "C": "Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.",
      "D": "Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在推出部署在 Amazon Elastic Container Service (Amazon ECS) 集群上的新应用程序，并且正在为 ECS 任务使用 Fargate 启动类型。该公司正在监控 CPU 和内存使用情况，因为它预计该应用程序在启动后会有高流量。但是，当利用率下降时，该公司希望降低成本。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "使用 Amazon EC2 Auto Scaling 根据之前的流量模式在特定时间段进行扩展。",
      "B": "使用 AWS Lambda 函数根据触发 Amazon CloudWatch 警报的指标突破来扩展 Amazon ECS。",
      "C": "使用 Amazon EC2 Auto Scaling 和简单扩展策略，以便在 ECS 指标突破触发 Amazon CloudWatch 警报时进行扩展。",
      "D": "使用 AWS Application Auto Scaling 和目标跟踪策略，以便在 ECS 指标突破触发 Amazon CloudWatch 警报时进行扩展。"
    }
  },
  {
    "id": 304,
    "topic": "1",
    "question_en": "A company recently created a disaster recovery site in a different AWS Region. The company needs to transfer large amounts of data back and forth between NFS file systems in the two Regions on a periodic basis. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS DataSync.",
      "B": "Use AWS Snowball devices.",
      "C": "Set up an SFTP server on Amazon EC2.",
      "D": "Use AWS Database Migration Service (AWS DMS)."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司最近在另一个 AWS 区域创建了一个灾难恢复站点。该公司需要定期间隔地在两个区域的 NFS 文件系统之间来回传输大量数据。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync。",
      "B": "使用 AWS Snowball 设备。",
      "C": "在 Amazon EC2 上设置 SFTP 服务器。",
      "D": "使用 AWS Database Migration Service (AWS DMS)。"
    }
  },
  {
    "id": 305,
    "topic": "1",
    "question_en": "A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed. Which AWS solution meets these requirements?",
    "options_en": {
      "A": "Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.",
      "B": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
      "C": "Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.",
      "D": "Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为托管在 AWS 云中的游戏应用程序设计共享存储解决方案。该公司需要能够使用 SMB 客户端访问数据。该解决方案必须是完全托管的。哪种 AWS 解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS DataSync 任务，将数据共享为可挂载的文件系统。将文件系统挂载到应用程序服务器。",
      "B": "创建一个 Amazon EC2 Windows 实例。在该实例上安装并配置 Windows 文件共享角色。将应用程序服务器连接到文件共享。",
      "C": "创建一个 Amazon FSx for Windows File Server 文件系统。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。",
      "D": "创建一个 Amazon S3 存储桶。为应用程序分配一个 IAM 角色以授予对 S3 存储桶的访问权限。将 S3 存储桶挂载到应用程序服务器。"
    }
  },
  {
    "id": 306,
    "topic": "1",
    "question_en": "A company wants to run an in-memory database for a latency-sensitive application that runs on Amazon EC2 instances. The application processes more than 100,000 transactions each minute and requires high network throughput. A solutions architect needs to provide a cost- effective network design that minimizes data transfer charges. Which solution meets these requirements?",
    "options_en": {
      "A": "Launch all EC2 instances in the same Availability Zone within the same AWS Region. Specify a placement group with cluster strategy when launching EC2 instances.",
      "B": "Launch all EC2 instances in different Availability Zones within the same AWS Region. Specify a placement group with partition strategy when launching EC2 instances.",
      "C": "Deploy an Auto Scaling group to launch EC2 instances in different Availability Zones based on a network utilization target.",
      "D": "Deploy an Auto Scaling group with a step scaling policy to launch EC2 instances in different Availability Zones."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望为在 Amazon EC2 实例上运行的对延迟敏感的应用程序运行内存数据库。该应用程序每分钟处理超过 100,000 笔交易，并且需要高网络吞吐量。 解决方案架构师需要提供一个经济高效的网络设计，以最大限度地减少数据传输费用。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在同一 AWS 区域内的同一可用区中启动所有 EC2 实例。在启动 EC2 实例时，指定具有集群策略的放置组。",
      "B": "在同一 AWS 区域内的不同可用区中启动所有 EC2 实例。在启动 EC2 实例时，指定具有分区策略的放置组。",
      "C": "部署一个 Auto Scaling 组，以根据网络利用率目标在不同的可用区中启动 EC2 实例。",
      "D": "部署一个具有步进扩展策略的 Auto Scaling 组，以在不同的可用区中启动 EC2 实例。"
    }
  },
  {
    "id": 307,
    "topic": "1",
    "question_en": "A company that primarily runs its application servers on premises has decided to migrate to AWS. The company wants to minimize its need to scale its Internet Small Computer Systems Interface (iSCSI) storage on premises. The company wants only its recently accessed data to remain stored locally. Which AWS solution should the company use to meet these requirements?",
    "options_en": {
      "A": "Amazon S3 File Gateway",
      "B": "AWS Storage Gateway Tape Gateway",
      "C": "AWS Storage Gateway Volume Gateway stored volumes",
      "D": "AWS Storage Gateway Volume Gateway cached volumes"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家主要在其本地运行应用程序服务器的公司已决定迁移到 AWS。该公司希望尽量减少其对本地 Internet Small Computer Systems Interface (iSCSI) 存储进行扩展的需求。该公司希望只有最近访问的数据保留在本地存储。该公司应该使用哪个 AWS 解决方案来满足这些要求？",
    "options_cn": {
      "A": "Amazon S3 File Gateway",
      "B": "AWS Storage Gateway Tape Gateway",
      "C": "AWS Storage Gateway Volume Gateway stored volumes",
      "D": "AWS Storage Gateway Volume Gateway cached volumes"
    }
  },
  {
    "id": 308,
    "topic": "1",
    "question_en": "A company has multiple AWS accounts that use consolidated billing. The company runs several active high performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company’s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts. The finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS. The finance team must review the appropriate Trusted Advisor check to reduce RDS costs. Which combination of steps should the finance team take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use the Trusted Advisor recommendations from the account where the RDS instances are running.",
      "B": "Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.",
      "C": "Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.",
      "D": "Review the Trusted Advisor check for Amazon RDS Idle DB Instances",
      "E": "Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization."
    },
    "correct_answer": "A",
    "vote_percentage": "61%",
    "question_cn": "一家公司有多个使用合并账单的 AWS 账户。该公司运行多个活跃的高性能 Amazon RDS for Oracle 按需 DB 实例 90 天。该公司的财务团队可以在合并账单账户和所有其他 AWS 账户中访问 AWS Trusted Advisor。财务团队需要使用适当的 AWS 账户来访问 Trusted Advisor 检查 RDS 的建议。财务团队必须查看适当的 Trusted Advisor 检查以减少 RDS 成本。财务团队应采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用运行 RDS 实例的账户中的 Trusted Advisor 建议。",
      "B": "使用合并账单账户中的 Trusted Advisor 建议，同时查看所有 RDS 实例检查。",
      "C": "查看 Amazon RDS 保留实例优化 的 Trusted Advisor 检查。",
      "D": "查看 Amazon RDS 空闲数据库实例 的 Trusted Advisor 检查。",
      "E": "查看 Amazon Redshift 保留节点优化 的 Trusted Advisor 检查。"
    }
  },
  {
    "id": 309,
    "topic": "1",
    "question_en": "A solutions architect needs to optimize storage costs. The solutions architect must identify any Amazon S3 buckets that are no longer being accessed or are rarely accessed. Which solution will accomplish this goal with the LEAST operational overhead?",
    "options_en": {
      "A": "Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.",
      "B": "Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console.",
      "C": "Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena.",
      "D": "Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs."
    },
    "correct_answer": "D",
    "vote_percentage": "93%",
    "question_cn": "一个解决方案架构师需要优化存储成本。该解决方案架构师必须识别不再被访问或很少被访问的 Amazon S3 存储桶。哪个解决方案将以最少的运营开销完成此目标？",
    "options_cn": {
      "A": "使用 S3 Storage Lens 仪表板分析存储桶访问模式以获取高级活动指标。",
      "B": "使用 AWS 管理控制台中 S3 仪表板分析存储桶访问模式。",
      "C": "为存储桶打开 Amazon CloudWatch BucketSizeBytes 指标。使用与 Amazon Athena 的指标数据分析存储桶访问模式。",
      "D": "为 S3 对象监控打开 AWS CloudTrail。使用与 Amazon CloudWatch Logs 集成的 CloudTrail 日志分析存储桶访问模式。"
    }
  },
  {
    "id": 310,
    "topic": "1",
    "question_en": "A company sells datasets to customers who do research in artificial intelligence and machine learning (AI/ML). The datasets are large, formatted files that are stored in an Amazon S3 bucket in the us-east-1 Region. The company hosts a web application that the customers use to purchase access to a given dataset. The web application is deployed on multiple Amazon EC2 instances behind an Application Load Balancer. After a purchase is made, customers receive an S3 signed URL that allows access to the files. The customers are distributed across North America and Europe. The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control.",
      "B": "Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.",
      "C": "Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control.",
      "D": "Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司向从事人工智能和机器学习 (AI/ML) 研究的客户销售数据集。数据集是大型格式化文件，存储在 us-east-1 区域的 Amazon S3 存储桶中。该公司托管一个 Web 应用程序，供客户用来购买对给定数据集的访问权限。Web 应用程序部署在 Application Load Balancer 后面的多个 Amazon EC2 实例上。购买后，客户会收到一个 S3 签名 URL，允许访问这些文件。客户分布在北美和欧洲。该公司希望降低与数据传输相关的成本，并希望保持或提高性能。解决方案架构师应如何做才能满足这些要求？",
    "options_cn": {
      "A": "在现有的 S3 存储桶上配置 S3 Transfer Acceleration。将客户请求定向到 S3 Transfer Acceleration 终端节点。继续使用 S3 签名 URL 进行访问控制。",
      "B": "部署一个 Amazon CloudFront 分发，将现有的 S3 存储桶作为源。将客户请求定向到 CloudFront URL。切换到 CloudFront 签名 URL 进行访问控制。",
      "C": "在 eu-central-1 区域设置第二个 S3 存储桶，并在存储桶之间设置 S3 跨区域复制。将客户请求定向到最近的区域。继续使用 S3 签名 URL 进行访问控制。",
      "D": "修改 Web 应用程序，以允许将数据集流式传输到最终用户。配置 Web 应用程序以从现有的 S3 存储桶读取数据。直接在应用程序中实施访问控制。"
    }
  },
  {
    "id": 311,
    "topic": "1",
    "question_en": "A company is using AWS to design a web application that will process insurance quotes. Users will request quotes from the application. Quotes must be separated by quote type, must be responded to within 24 hours, and must not get lost. The solution must maximize operational eficiency and must minimize maintenance. Which solution meets these requirements?",
    "options_en": {
      "A": "Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to use the Kinesis Client Library (KCL) to pool messages from its own data stream.",
      "B": "Create an AWS Lambda function and an Amazon Simple Notification Service (Amazon SNS) topic for each quote type. Subscribe the Lambda function to its associated SNS topic. Configure the application to publish requests for quotes to the appropriate SNS topic.",
      "C": "Create a single Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon Simple Queue Service (Amazon SQS) queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to use its own SQS queue.",
      "D": "Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon OpenSearch Service cluster. Configure the application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from OpenSearch Service and process them accordingly."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 AWS 设计一个将处理保险报价的 Web 应用程序。用户将从应用程序请求报价。报价必须按报价类型分隔，必须在 24 小时内响应，并且不得丢失。该解决方案必须最大限度地提高运营效率，并最大限度地减少维护。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "根据报价类型创建多个 Amazon Kinesis 数据流。配置 Web 应用程序以将消息发送到适当的数据流。配置每个后端应用程序服务器组，以使用 Kinesis Client Library (KCL) 从其自己的数据流中提取消息。",
      "B": "为每种报价类型创建一个 AWS Lambda 函数和一个 Amazon Simple Notification Service (Amazon SNS) 主题。将 Lambda 函数订阅到其关联的 SNS 主题。配置应用程序以将报价请求发布到相应的 SNS 主题。",
      "C": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将 Amazon Simple Queue Service (Amazon SQS) 队列订阅到 SNS 主题。配置 SNS 消息筛选，以根据报价类型将消息发布到适当的 SQS 队列。配置每个后端应用程序服务器以使用其自己的 SQS 队列。",
      "D": "根据报价类型创建多个 Amazon Kinesis Data Firehose 交付流，以将数据流传递到 Amazon OpenSearch Service 集群。配置应用程序以将消息发送到适当的交付流。配置每个后端应用程序服务器组以从 OpenSearch Service 搜索消息并相应地处理它们。"
    }
  },
  {
    "id": 312,
    "topic": "1",
    "question_en": "A company has an application that runs on several Amazon EC2 instances. Each EC2 instance has multiple Amazon Elastic Block Store (Amazon EBS) data volumes attached to it. The application’s EC2 instance configuration and data need to be backed up nightly. The application also needs to be recoverable in a different AWS Region. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Write an AWS Lambda function that schedules nightly snapshots of the application’s EBS volumes and copies the snapshots to a different Region.",
      "B": "Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EC2 instances as resources.",
      "C": "Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EBS volumes as resources.",
      "D": "Write an AWS Lambda function that schedules nightly snapshots of the application's EBS volumes and copies the snapshots to a different Availability Zone."
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家公司有一个在多个 Amazon EC2 实例上运行的应用程序。每个 EC2 实例都附带了多个 Amazon Elastic Block Store (Amazon EBS) 数据卷。该应用程序的 EC2 实例配置和数据需要每天晚上进行备份。该应用程序也需要在不同的 AWS 区域中可恢复。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "编写一个 AWS Lambda 函数，该函数计划每天晚上拍摄应用程序的 EBS 卷快照，并将快照复制到不同的区域。",
      "B": "通过使用 AWS Backup 创建一个备份计划来执行夜间备份。将备份复制到另一个区域。将应用程序的 EC2 实例添加为资源。",
      "C": "通过使用 AWS Backup 创建一个备份计划来执行夜间备份。将备份复制到另一个区域。将应用程序的 EBS 卷添加为资源。",
      "D": "编写一个 AWS Lambda 函数，该函数计划每天晚上拍摄应用程序的 EBS 卷快照，并将快照复制到不同的可用区。"
    }
  },
  {
    "id": 313,
    "topic": "1",
    "question_en": "A company is building a mobile app on AWS. The company wants to expand its reach to millions of users. The company needs to build a platform so that authorized users can watch the company’s content on their mobile devices. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Publish content to a public Amazon S3 bucket. Use AWS Key Management Service (AWS KMS) keys to stream content.",
      "B": "Set up IPsec VPN between the mobile app and the AWS environment to stream content.",
      "C": "Use Amazon CloudFront. Provide signed URLs to stream content.",
      "D": "Set up AWS Client VPN between the mobile app and the AWS environment to stream content."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上构建一个移动应用程序。该公司希望将其业务扩展到数百万用户。该公司需要构建一个平台，以便授权用户可以在他们的移动设备上观看公司的内容。 解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "将内容发布到公共 Amazon S3 存储桶。 使用 AWS Key Management Service (AWS KMS) 密钥来流式传输内容。",
      "B": "在移动应用程序和 AWS 环境之间设置 IPsec VPN 来流式传输内容。",
      "C": "使用 Amazon CloudFront。 提供已签名的 URL 来流式传输内容。",
      "D": "在移动应用程序和 AWS 环境之间设置 AWS Client VPN 来流式传输内容。"
    }
  },
  {
    "id": 314,
    "topic": "1",
    "question_en": "A company has an on-premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future. Which service should a solutions architect recommend?",
    "options_en": {
      "A": "Amazon Aurora MySQL",
      "B": "Amazon Aurora Serverless for MySQL",
      "C": "Amazon Redshift Spectrum",
      "D": "Amazon RDS for MySQL"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个内部部署的 MySQL 数据库，供全球销售团队使用，访问模式不频繁。销售团队要求数据库停机时间最短。数据库管理员希望在不选择特定实例类型的情况下将此数据库迁移到 AWS，以应对未来的更多用户。解决方案架构师应该推荐哪种服务？",
    "options_cn": {
      "A": "Amazon Aurora MySQL",
      "B": "Amazon Aurora Serverless for MySQL",
      "C": "Amazon Redshift Spectrum",
      "D": "Amazon RDS for MySQL"
    }
  },
  {
    "id": 315,
    "topic": "1",
    "question_en": "A company experienced a breach that affected several applications in its on-premises data center. The attacker took advantage of vulnerabilities in the custom applications that were running on the servers. The company is now migrating its applications to run on Amazon EC2 instances. The company wants to implement a solution that actively scans for vulnerabilities on the EC2 instances and sends a report that details the findings. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy AWS Shield to scan the EC2 instances for vulnerabilities. Create an AWS Lambda function to log any findings to AWS CloudTrail.",
      "B": "Deploy Amazon Macie and AWS Lambda functions to scan the EC2 instances for vulnerabilities. Log any findings to AWS CloudTrail.",
      "C": "Turn on Amazon GuardDuty. Deploy the GuardDuty agents to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.",
      "D": "Turn on Amazon Inspector. Deploy the Amazon Inspector agent to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings."
    },
    "correct_answer": "C",
    "vote_percentage": "97%",
    "question_cn": "一家公司遭遇了一次影响其本地数据中心中几个应用程序的入侵。攻击者利用了在服务器上运行的自定义应用程序中的漏洞。该公司现在正在迁移其应用程序以在 Amazon EC2 实例上运行。该公司希望实施一个主动扫描 EC2 实例中漏洞并发送详细结果报告的解决方案。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "部署 AWS Shield 以扫描 EC2 实例中的漏洞。创建 AWS Lambda 函数以将任何发现结果记录到 AWS CloudTrail。",
      "B": "部署 Amazon Macie 和 AWS Lambda 函数以扫描 EC2 实例中的漏洞。将任何发现结果记录到 AWS CloudTrail。",
      "C": "打开 Amazon GuardDuty。将 GuardDuty 代理部署到 EC2 实例。配置 AWS Lambda 函数以自动化生成和分发详细说明发现结果的报告。",
      "D": "打开 Amazon Inspector。将 Amazon Inspector 代理部署到 EC2 实例。配置 AWS Lambda 函数以自动化生成和分发详细说明发现结果的报告。"
    }
  },
  {
    "id": 316,
    "topic": "1",
    "question_en": "A company uses an Amazon EC2 instance to run a script to poll for and process messages in an Amazon Simple Queue Service (Amazon SQS) queue. The company wants to reduce operational costs while maintaining its ability to process a growing number of messages that are added to the queue. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Increase the size of the EC2 instance to process messages faster.",
      "B": "Use Amazon EventBridge to turn off the EC2 instance when the instance is underutilized.",
      "C": "Migrate the script on the EC2 instance to an AWS Lambda function with the appropriate runtime.",
      "D": "Use AWS Systems Manager Run Command to run the script on demand."
    },
    "correct_answer": "A",
    "vote_percentage": "90%",
    "question_cn": "一家公司使用 Amazon EC2 实例来运行脚本，以轮询和处理 Amazon Simple Queue Service (Amazon SQS) 队列中的消息。该公司希望降低运营成本，同时保持其处理添加到队列中的越来越多消息的能力。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "增加 EC2 实例的大小以更快地处理消息。",
      "B": "使用 Amazon EventBridge 在实例未被充分利用时关闭 EC2 实例。",
      "C": "将 EC2 实例上的脚本迁移到具有适当运行时的 AWS Lambda 函数。",
      "D": "使用 AWS Systems Manager Run Command 按需运行脚本。"
    }
  },
  {
    "id": 317,
    "topic": "1",
    "question_en": "A company uses a legacy application to produce data in CSV format. The legacy application stores the output data in Amazon S3. The company is deploying a new commercial off-the-shelf (COTS) application that can perform complex SQL queries to analyze data that is stored in Amazon Redshift and Amazon S3 only. However, the COTS application cannot process the .csv files that the legacy application produces. The company cannot update the legacy application to produce data in another format. The company needs to implement a solution so that the COTS application can use the data that the legacy application produces. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Glue extract, transform, and load (ETL) job that runs on a schedule. Configure the ETL job to process the .csv files and store the processed data in Amazon Redshift.",
      "B": "Develop a Python script that runs on Amazon EC2 instances to convert the .csv files to .sql files. Invoke the Python script on a cron schedule to store the output files in Amazon S3.",
      "C": "Create an AWS Lambda function and an Amazon DynamoDB table. Use an S3 event to invoke the Lambda function. Configure the Lambda function to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in the DynamoDB table.",
      "D": "Use Amazon EventBridge to launch an Amazon EMR cluster on a weekly schedule. Configure the EMR cluster to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in an Amazon Redshift table."
    },
    "correct_answer": "A",
    "vote_percentage": "97%",
    "question_cn": "一家公司使用旧版应用程序生成 CSV 格式的数据。旧版应用程序将输出数据存储在 Amazon S3 中。该公司正在部署一个新的商业现成 (COTS) 应用程序，该应用程序可以执行复杂的 SQL 查询来分析存储在 Amazon Redshift 和 Amazon S3 中的数据。但是，COTS 应用程序无法处理旧版应用程序生成的 .csv 文件。该公司无法更新旧版应用程序以生成另一种格式的数据。该公司需要实施一个解决方案，以便 COTS 应用程序可以使用旧版应用程序生成的数据。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个在计划上运行的 AWS Glue 提取、转换和加载 (ETL) 作业。配置 ETL 作业以处理 .csv 文件并将处理后的数据存储在 Amazon Redshift 中。",
      "B": "开发一个在 Amazon EC2 实例上运行的 Python 脚本，以将 .csv 文件转换为 .sql 文件。在 cron 计划上调用 Python 脚本，以将输出文件存储在 Amazon S3 中。",
      "C": "创建一个 AWS Lambda 函数和一个 Amazon DynamoDB 表。使用 S3 事件调用 Lambda 函数。配置 Lambda 函数以执行提取、转换和加载 (ETL) 作业来处理 .csv 文件并将处理后的数据存储在 DynamoDB 表中。",
      "D": "使用 Amazon EventBridge 每周启动一个 Amazon EMR 集群。配置 EMR 集群以执行提取、转换和加载 (ETL) 作业来处理 .csv 文件，并将处理后的数据存储在 Amazon Redshift 表中。"
    }
  },
  {
    "id": 318,
    "topic": "1",
    "question_en": "A company recently migrated its entire IT environment to the AWS Cloud. The company discovers that users are provisioning oversized Amazon EC2 instances and modifying security group rules without using the appropriate change control process. A solutions architect must devise a strategy to track and audit these inventory and configuration changes. Which actions should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Enable AWS CloudTrail and use it for auditing.",
      "B": "Use data lifecycle policies for the Amazon EC2 instances.",
      "C": "Enable AWS Trusted Advisor and reference the security dashboard.",
      "D": "Enable AWS Config and create rules for auditing and compliance purposes",
      "E": "Restore previous resource configurations with an AWS CloudFormation template."
    },
    "correct_answer": "A",
    "vote_percentage": "94%",
    "question_cn": "一家公司最近将其整个 IT 环境迁移到了 AWS 云。该公司发现用户正在预置超大 Amazon EC2 实例，并且在没有使用适当的变更控制流程的情况下修改安全组规则。解决方案架构师必须设计一种策略来跟踪和审计这些清单和配置更改。解决方案架构师应该采取哪些行动来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "启用 AWS CloudTrail 并将其用于审计。",
      "B": "为 Amazon EC2 实例使用数据生命周期策略。",
      "C": "启用 AWS Trusted Advisor 并参考安全仪表板。",
      "D": "启用 AWS Config 并创建用于审计和合规性的规则。",
      "E": "使用 AWS CloudFormation 模板还原先前的资源配置。"
    }
  },
  {
    "id": 319,
    "topic": "1",
    "question_en": "A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company’s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances. Which solution will meet this requirement with the LEAST amount of administrative overhead?",
    "options_en": {
      "A": "Use AWS Systems Manager Session Manager to connect to the EC2 instances.",
      "B": "Use AWS Security Token Service (AWS STS) to generate one-time SSH keys on demand.",
      "C": "Allow shared SSH access to a set of bastion instances. Configure all other instances to allow only SSH access from the bastion instances.",
      "D": "Use an Amazon Cognito custom authorizer to authenticate users. Invoke an AWS Lambda function to generate a temporary SSH key."
    },
    "correct_answer": "B",
    "vote_percentage": "83%",
    "question_cn": "一家公司在 AWS 云中拥有数百个基于 Linux 的 Amazon EC2 实例。系统管理员使用共享 SSH 密钥来管理这些实例。在最近的一次审计之后，公司的安全团队强制要求删除所有共享密钥。解决方案架构师必须设计一个解决方案，为 EC2 实例提供安全访问。哪个解决方案将以最少的管理开销满足此要求？",
    "options_cn": {
      "A": "使用 AWS Systems Manager Session Manager 连接到 EC2 实例。",
      "B": "使用 AWS Security Token Service (AWS STS) 按需生成一次性 SSH 密钥。",
      "C": "允许共享 SSH 访问一组堡垒实例。将所有其他实例配置为仅允许从堡垒实例进行 SSH 访问。",
      "D": "使用 Amazon Cognito 自定义授权程序对用户进行身份验证。调用 AWS Lambda 函数以生成临时 SSH 密钥。"
    }
  },
  {
    "id": 320,
    "topic": "1",
    "question_en": "A company is using a fieet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-fiight is lost. The company’s data science team wants to query ingested data in near-real time. Which solution provides near-real-time data querying that is scalable with minimal data loss?",
    "options_en": {
      "A": "Publish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data.",
      "B": "Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.",
      "C": "Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.",
      "D": "Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data."
    },
    "correct_answer": "A",
    "vote_percentage": "70%",
    "question_cn": "一家公司正在使用一组 Amazon EC2 实例从本地数据源摄取数据。数据为 JSON 格式，摄取速率可能高达 1 MB/s。当 EC2 实例重新启动时，正在传输的数据将会丢失。该公司的Data Science团队希望近乎实时地查询摄取的数据。哪种解决方案提供了近乎实时的数据查询，具有可扩展性且数据丢失最少？",
    "options_cn": {
      "A": "将数据发布到 Amazon Kinesis Data Streams，使用 Kinesis Data Analytics 查询数据。",
      "B": "将数据发布到 Amazon Kinesis Data Firehose，并将 Amazon Redshift 作为目标。使用 Amazon Redshift 查询数据。",
      "C": "将摄取的数据存储在 EC2 实例存储中。将数据发布到 Amazon Kinesis Data Firehose，并将 Amazon S3 作为目标。使用 Amazon Athena 查询数据。",
      "D": "将摄取的数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。将数据发布到 Amazon ElastiCache for Redis。订阅 Redis 频道以查询数据。"
    }
  },
  {
    "id": 321,
    "topic": "1",
    "question_en": "What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?",
    "options_en": {
      "A": "Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set.",
      "B": "Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private.",
      "C": "Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.",
      "D": "Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "解决方案架构师应采取什么措施来确保上传到 Amazon S3 存储桶的所有对象都被加密？",
    "options_cn": {
      "A": "更新存储桶策略，如果 PutObject 没有设置 s3:x-amz-acl 标头，则拒绝操作。",
      "B": "更新存储桶策略，如果 PutObject 没有将 s3:x-amz-acl 标头设置为 private，则拒绝操作。",
      "C": "更新存储桶策略，如果 PutObject 没有将 aws:SecureTransport 标头设置为 true，则拒绝操作。",
      "D": "更新存储桶策略，如果 PutObject 没有设置 x-amz-server-side-encryption 标头，则拒绝操作。"
    }
  },
  {
    "id": 322,
    "topic": "1",
    "question_en": "A solutions architect is designing a multi-tier application for a company. The application's users upload images from a mobile device. The application generates a thumbnail of each image and returns a message to the user to confirm that the image was uploaded successfully. The thumbnail generation can take up to 60 seconds, but the company wants to provide a faster response time to its users to notify them that the original image was received. The solutions architect must design the application to asynchronously dispatch requests to the different application tiers. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Write a custom AWS Lambda function to generate the thumbnail and alert the user. Use the image upload process as an event source to invoke the Lambda function.",
      "B": "Create an AWS Step Functions workfiow. Configure Step Functions to handle the orchestration between the application tiers and alert the user when thumbnail generation is complete.",
      "C": "Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received.",
      "D": "Create Amazon Simple Notification Service (Amazon SNS) notification topics and subscriptions. Use one subscription with the application to generate the thumbnail after the image upload is complete. Use a second subscription to message the user's mobile app by way of a push notification after thumbnail generation is complete."
    },
    "correct_answer": "C",
    "vote_percentage": "93%",
    "question_cn": "一位解决方案架构师正在为一家公司设计一个多层应用程序。应用程序的用户从移动设备上传图像。应用程序为每张图像生成缩略图，并向用户返回一条消息，以确认图像已成功上传。生成缩略图可能需要长达 60 秒的时间，但公司希望为用户提供更快的响应时间，以通知他们已收到原始图像。解决方案架构师必须设计应用程序以异步地将请求分派给不同的应用程序层。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "编写一个自定义 AWS Lambda 函数来生成缩略图并提醒用户。使用图像上传过程作为事件 源 来调用 Lambda 函数。",
      "B": "创建一个 AWS Step Functions 工作流程。配置 Step Functions 来处理应用程序层之间的编排，并在缩略图生成完成后提醒用户。",
      "C": "创建一个 Amazon Simple Queue Service (Amazon SQS) 消息队列。当上传图像时，将一条消息放置在 SQS 队列上以进行缩略图生成。通过应用程序消息提醒用户图像已收到。",
      "D": "创建 Amazon Simple Notification Service (Amazon SNS) 通知主题和订阅。使用一个订阅与应用程序一起在图像上传完成后生成缩略图。使用第二个订阅通过推送通知向用户的移动应用程序发送消息，在缩略图生成完成后。"
    }
  },
  {
    "id": 323,
    "topic": "1",
    "question_en": "A company’s facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance. A solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company’s security team to analyze. Which system architecture should the solutions architect recommend?",
    "options_en": {
      "A": "Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.",
      "B": "Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.",
      "C": "Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table.",
      "D": "Create a gateway VPC endpoint for Amazon S3. Configure a Site-to-Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司的设施在整个建筑物的每个入口处都设有读卡器。扫描徽章时，读卡器通过 HTTPS 发送一条消息，以指示谁试图访问该特定入口。解决方案架构师必须设计一个系统来处理来自传感器的这些消息。该解决方案必须具有高可用性，并且必须使结果可供公司的安全团队进行分析。解决方案架构师应该推荐哪种系统架构？",
    "options_cn": {
      "A": "启动一个 Amazon EC2 实例作为 HTTPS 端点并处理消息。配置 EC2 实例将结果保存到 Amazon S3 存储桶。",
      "B": "在 Amazon API Gateway 中创建 HTTPS 端点。配置 API Gateway 端点以调用 AWS Lambda 函数来处理消息并将结果保存到 Amazon DynamoDB 表中。",
      "C": "使用 Amazon Route 53 将传入的传感器消息定向到 AWS Lambda 函数。配置 Lambda 函数以处理消息并将结果保存到 Amazon DynamoDB 表中。",
      "D": "创建 Amazon S3 的网关 VPC endpoint。配置从设施网络到 VPC 的站点到站点 VPN 连接，以便可以通过 VPC endpoint 将传感器数据直接写入 S3 存储桶。"
    }
  },
  {
    "id": 324,
    "topic": "1",
    "question_en": "A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data. The company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency. Which solution will meet these requirements with the LEAST amount of change to the company's existing infrastructure?",
    "options_en": {
      "A": "Provision an Amazon S3 File Gateway as a virtual machine (VM) that is hosted on premises. Set the local cache to 10 TB. Modify existing applications to access the files through the NFS protocol. To recover from a disaster, provision an Amazon EC2 instance and mount the S3 bucket that contains the files.",
      "B": "Provision an AWS Storage Gateway tape gateway. Use a data backup solution to back up all existing data to a virtual tape library. Configure the data backup solution to run nightly after the initial backup is complete. To recover from a disaster, provision an Amazon EC2 instance and restore the data to an Amazon Elastic Block Store (Amazon EBS) volume from the volumes in the virtual tape library.",
      "C": "Provision an AWS Storage Gateway Volume Gateway cached volume. Set the local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.",
      "D": "Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance."
    },
    "correct_answer": "C",
    "vote_percentage": "77%",
    "question_cn": "一家公司希望为其主要的本地文件存储卷实施灾难恢复计划。文件存储卷是从本地存储服务器上的 Internet Small Computer Systems Interface (iSCSI) 设备挂载的。文件存储卷包含数百 TB 的数据。该公司希望确保最终用户保留对来自本地系统的所有文件类型的即时访问权限，而不会遇到延迟。哪种解决方案以对公司现有基础设施的更改最少的方式满足这些要求？",
    "options_cn": {
      "A": "将 Amazon S3 File Gateway 作为虚拟机 (VM) 预置，该虚拟机托管在本地。将本地缓存设置为 10 TB。修改现有应用程序以通过 NFS 协议访问文件。为了从灾难中恢复，预置 Amazon EC2 实例并挂载包含文件的 S3 存储桶。",
      "B": "预置 AWS Storage Gateway 磁带网关。使用数据备份解决方案将所有现有数据备份到虚拟磁带库。配置数据备份解决方案以在初始备份完成后每晚运行。为了从灾难中恢复，预置 Amazon EC2 实例并将数据从虚拟磁带库中的卷恢复到 Amazon Elastic Block Store (Amazon EBS) 卷。",
      "C": "预置 AWS Storage Gateway Volume Gateway 缓存卷。将本地缓存设置为 10 TB。通过 iSCSI 将 Volume Gateway 缓存卷挂载到现有文件服务器，并将所有文件复制到存储卷。配置存储卷的计划快照。为了从灾难中恢复，将快照还原到 Amazon Elastic Block Store (Amazon EBS) 卷，并将 EBS 卷附加到 Amazon EC2 实例。",
      "D": "预置 AWS Storage Gateway Volume Gateway 存储卷，其磁盘空间与现有文件存储卷相同。通过 iSCSI 将 Volume Gateway 存储卷挂载到现有文件服务器，并将所有文件复制到存储卷。配置存储卷的计划快照。为了从灾难中恢复，将快照还原到 Amazon Elastic Block Store (Amazon EBS) 卷，并将 EBS 卷附加到 Amazon EC2 实例。"
    }
  },
  {
    "id": 325,
    "topic": "1",
    "question_en": "A company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket. Upon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content. Which solution meets these requirements?",
    "options_en": {
      "A": "Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.",
      "B": "Update the S3 ACL to allow the application to access the protected content.",
      "C": "Redeploy the application to Amazon S3 to prevent eventually consistent reads in the S3 bucket from affecting the ability of users to access the protected content.",
      "D": "Update the Amazon Cognito pool to use custom attribute mappings within the identity pool and grant users the proper permissions to access the protected content."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司正在从一个 Amazon S3 存储桶托管一个 Web 应用程序。该应用程序使用 Amazon Cognito 作为身份提供商来验证用户身份，并返回一个 JSON Web Token (JWT)，该令牌提供对存储在另一个 S3 存储桶中的受保护资源的访问权限。部署应用程序后，用户报告错误并且无法访问受保护的内容。 解决方案架构师必须通过提供适当的权限来解决此问题，以便用户可以访问受保护的内容。 哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "更新 Amazon Cognito 身份池，以承担适当的 IAM 角色来访问受保护的内容。",
      "B": "更新 S3 ACL 以允许应用程序访问受保护的内容。",
      "C": "将应用程序重新部署到 Amazon S3，以防止 S3 存储桶中最终一致性读取影响用户访问受保护内容的能力。",
      "D": "更新 Amazon Cognito 池，以在身份池中使用自定义属性映射，并授予用户访问受保护内容的适当权限。"
    }
  },
  {
    "id": 326,
    "topic": "1",
    "question_en": "An image hosting company uploads its large assets to Amazon S3 Standard buckets. The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again. For the first 30 days after upload, the objects will be accessed frequently. The objects will be used less frequently after 30 days, but the access patterns for each object will be inconsistent. The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets. Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Move assets to S3 Intelligent-Tiering after 30 days.",
      "B": "Configure an S3 Lifecycle policy to clean up incomplete multipart uploads.",
      "C": "Configure an S3 Lifecycle policy to clean up expired object delete markers.",
      "D": "Move assets to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days",
      "E": "Move assets to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days."
    },
    "correct_answer": "A",
    "vote_percentage": "60%",
    "question_cn": "一家图片托管公司将其大型资产上传到 Amazon S3 Standard 存储桶。该公司使用 S3 API 并行执行 multipart uploads，如果再次上传相同的对象，则会覆盖。上传后的前 30 天，这些对象将被频繁访问。30 天后，这些对象的使用频率会降低，但每个对象的访问模式将是不一致的。该公司必须优化其 S3 存储成本，同时保持存储资产的高可用性和弹性。解决方案架构师应推荐哪两种操作组合来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "30 天后将资产移至 S3 Intelligent-Tiering。",
      "B": "配置 S3 生命周期策略以清理未完成的 multipart uploads。",
      "C": "配置 S3 生命周期策略以清理过期的对象删除标记。",
      "D": "30 天后将资产移至 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "E": "30 天后将资产移至 S3 One Zone-Infrequent Access (S3 One Zone-IA)。"
    }
  },
  {
    "id": 327,
    "topic": "1",
    "question_en": "A solutions architect must secure a VPC network that hosts Amazon EC2 instances. The EC2 instances contain highly sensitive data and run in a private subnet. According to company policy, the EC2 instances that run in the VPC can access only approved third-party software repositories on the internet for software product updates that use the third party’s URL. Other internet trafic must be blocked. Which solution meets these requirements?",
    "options_en": {
      "A": "Update the route table for the private subnet to route the outbound trafic to an AWS Network Firewall firewall. Configure domain list rule groups.",
      "B": "Set up an AWS WAF web ACL. Create a custom set of rules that filter trafic requests based on source and destination IP address range sets.",
      "C": "Implement strict inbound security group rules. Configure an outbound rule that allows trafic only to the authorized software repositories on the internet by specifying the URLs.",
      "D": "Configure an Application Load Balancer (ALB) in front of the EC2 instances. Direct all outbound trafic to the ALB. Use a URL-based rule listener in the ALB’s target group for outbound access to the internet."
    },
    "correct_answer": "A",
    "vote_percentage": "89%",
    "question_cn": "一位解决方案架构师必须保护托管 Amazon EC2 实例的 VPC 网络。EC2 实例包含高度敏感的数据，并在私有子网中运行。根据公司策略，在 VPC 中运行的 EC2 实例只能访问互联网上经过批准的第三方软件存储库，以获取使用第三方 URL 的软件产品更新。其他互联网流量必须被阻止。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "更新私有子网的路由表，将出站流量路由到 AWS Network Firewall 防火墙。配置域名列表规则组。",
      "B": "设置 AWS WAF Web ACL。创建自定义规则集，根据 源和目标 IP 地址范围集过滤流量请求。",
      "C": "实施严格的入站安全组规则。配置一个出站规则，仅允许流量通过指定 URL 访问互联网上的授权软件存储库。",
      "D": "在 EC2 实例前面配置 Application Load Balancer (ALB)。将所有出站流量定向到 ALB。在 ALB 的目标组中使用基于 URL 的规则监听器以访问互联网。"
    }
  },
  {
    "id": 328,
    "topic": "1",
    "question_en": "A company is hosting a three-tier ecommerce application in the AWS Cloud. The company hosts the website on Amazon S3 and integrates the website with an API that handles sales requests. The company hosts the API on three Amazon EC2 instances behind an Application Load Balancer (ALB). The API consists of static and dynamic front-end content along with backend workers that process sales requests asynchronously. The company is expecting a significant and sudden increase in the number of sales requests during events for the launch of new products. What should a solutions architect recommend to ensure that all the requests are processed successfully?",
    "options_en": {
      "A": "Add an Amazon CloudFront distribution for the dynamic content. Increase the number of EC2 instances to handle the increase in trafic.",
      "B": "Add an Amazon CloudFront distribution for the static content. Place the EC2 instances in an Auto Scaling group to launch new instances based on network trafic.",
      "C": "Add an Amazon CloudFront distribution for the dynamic content. Add an Amazon ElastiCache instance in front of the ALB to reduce trafic for the API to handle.",
      "D": "Add an Amazon CloudFront distribution for the static content. Add an Amazon Simple Queue Service (Amazon SQS) queue to receive requests from the website for later processing by the EC2 instances."
    },
    "correct_answer": "D",
    "vote_percentage": "69%",
    "question_cn": "一家公司在 AWS 云中托管一个三层电商应用程序。该公司将网站托管在 Amazon S3 上，并将网站与处理销售请求的 API 集成。该公司将 API 托管在 Application Load Balancer (ALB) 后面的三个 Amazon EC2 实例上。API 由静态和动态前端内容以及异步处理销售请求的后端工作程序组成。该公司预计在新产品发布活动期间，销售请求数量将出现显着且突然的增长。解决方案架构师应该推荐什么来确保所有请求都被成功处理？",
    "options_cn": {
      "A": "为动态内容添加 Amazon CloudFront 分发。增加 EC2 实例的数量以处理增加的流量。",
      "B": "为静态内容添加 Amazon CloudFront 分发。将 EC2 实例放入 Auto Scaling 组中，以根据网络流量启动新实例。",
      "C": "为动态内容添加 Amazon CloudFront 分发。在 ALB 前面添加 Amazon ElastiCache 实例，以减少 API 处理的流量。",
      "D": "为静态内容添加 Amazon CloudFront 分发。添加 Amazon Simple Queue Service (Amazon SQS) 队列以接收来自网站的请求，供 EC2 实例稍后处理。"
    }
  },
  {
    "id": 329,
    "topic": "1",
    "question_en": "A security audit reveals that Amazon EC2 instances are not being patched regularly. A solutions architect needs to provide a solution that will run regular security scans across a large fieet of EC2 instances. The solution should also patch the EC2 instances on a regular schedule and provide a report of each instance’s patch status. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up Amazon Macie to scan the EC2 instances for software vulnerabilities. Set up a cron job on each EC2 instance to patch the instance on a regular schedule.",
      "B": "Turn on Amazon GuardDuty in the account. Configure GuardDuty to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Session Manager to patch the EC2 instances on a regular schedule.",
      "C": "Set up Amazon Detective to scan the EC2 instances for software vulnerabilities. Set up an Amazon EventBridge scheduled rule to patch the EC2 instances on a regular schedule.",
      "D": "Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "安全审计显示，Amazon EC2 实例未定期进行补丁更新。 解决方案架构师需要提供一个解决方案，该方案将对大量的 EC2 实例定期运行安全扫描。 该解决方案还应定期对 EC2 实例进行补丁更新，并提供每个实例的补丁状态报告。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置 Amazon Macie 以扫描 EC2 实例中的软件漏洞。 在每个 EC2 实例上设置一个 cron 作业，以定期间隔对实例进行补丁更新。",
      "B": "在账户中打开 Amazon GuardDuty。 配置 GuardDuty 以扫描 EC2 实例中的软件漏洞。 设置 AWS Systems Manager Session Manager 以定期间隔对 EC2 实例进行补丁更新。",
      "C": "设置 Amazon Detective 以扫描 EC2 实例中的软件漏洞。 设置 Amazon EventBridge 定时规则，以定期间隔对 EC2 实例进行补丁更新。",
      "D": "在账户中打开 Amazon Inspector。 配置 Amazon Inspector 以扫描 EC2 实例中的软件漏洞。 设置 AWS Systems Manager Patch Manager 以定期间隔对 EC2 实例进行补丁更新。"
    }
  },
  {
    "id": 330,
    "topic": "1",
    "question_en": "A company is planning to store data on Amazon RDS DB instances. The company must encrypt the data at rest. What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Create a key in AWS Key Management Service (AWS KMS). Enable encryption for the DB instances.",
      "B": "Create an encryption key. Store the key in AWS Secrets Manager. Use the key to encrypt the DB instances.",
      "C": "Generate a certificate in AWS Certificate Manager (ACM). Enable SSL/TLS on the DB instances by using the certificate.",
      "D": "Generate a certificate in AWS Identity and Access Management (IAM). Enable SSL/TLS on the DB instances by using the certificate."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划将数据存储在 Amazon RDS 数据库实例上。该公司必须对静态数据进行加密。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "在 AWS Key Management Service (AWS KMS) 中创建一个密钥。为数据库实例启用加密。",
      "B": "创建一个加密密钥。将密钥存储在 AWS Secrets Manager 中。使用该密钥对数据库实例进行加密。",
      "C": "在 AWS Certificate Manager (ACM) 中生成一个证书。通过使用该证书在数据库实例上启用 SSL/TLS。",
      "D": "在 AWS Identity and Access Management (IAM) 中生成一个证书。通过使用该证书在数据库实例上启用 SSL/TLS。"
    }
  },
  {
    "id": 331,
    "topic": "1",
    "question_en": "A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company’s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use AWS Snowball.",
      "B": "Use AWS DataSync.",
      "C": "Use a secure VPN connection.",
      "D": "Use Amazon S3 Transfer Acceleration."
    },
    "correct_answer": "A",
    "vote_percentage": "91%",
    "question_cn": "一家公司必须在 30 天内将 20 TB 的数据从数据中心迁移到 AWS 云。该公司的网络带宽限制为 15 Mbps，且利用率不得超过 70%。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Snowball。",
      "B": "使用 AWS DataSync。",
      "C": "使用安全的 VPN 连接。",
      "D": "使用 Amazon S3 Transfer Acceleration。"
    }
  },
  {
    "id": 332,
    "topic": "1",
    "question_en": "A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees’ devices. The files are stored in an on-premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity. . Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound trafic to the employees’ IP addresses.",
      "B": "Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.",
      "C": "Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.",
      "D": "Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS IAM Identity Center (AWS Single Sign-On)."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司需要为其员工提供对机密和敏感文件的安全访问。该公司希望确保只有授权用户才能访问这些文件。这些文件必须安全地下载到员工的设备。这些文件存储在本地 Windows 文件服务器中。然而，由于远程使用量的增加，文件服务器的容量即将耗尽。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将文件服务器迁移到公有子网中的 Amazon EC2 实例。配置安全组以限制流入员工 IP 地址的流量。",
      "B": "将文件迁移到 Amazon FSx for Windows File Server 文件系统。将 Amazon FSx 文件系统与本地 Active Directory 集成。配置 AWS 客户端 VPN。",
      "C": "将文件迁移到 Amazon S3，并创建私有 VPC endpoint。创建签名 URL 以允许下载。",
      "D": "将文件迁移到 Amazon S3，并创建公有 VPC endpoint。允许员工使用 AWS IAM Identity Center (AWS Single Sign-On) 登录。"
    }
  },
  {
    "id": 333,
    "topic": "1",
    "question_en": "A company’s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month-end financial calculation batch runs. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?",
    "options_en": {
      "A": "Configure an Amazon CloudFront distribution in front of the ALB.",
      "B": "Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.",
      "C": "Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.",
      "D": "Configure Amazon ElastiCache to remove some of the workload from the EC2 instances."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的应用程序运行在 Application Load Balancer (ALB) 后面的 Amazon EC2 实例上。这些实例在跨多个可用区的 Amazon EC2 Auto Scaling 组中运行。在每个月的第一天午夜，当月末财务计算批处理运行时，应用程序会变得非常慢。这导致 EC2 实例的 CPU 利用率立即达到 100%，从而中断了应用程序。解决方案架构师应该建议什么来确保应用程序能够处理工作负载并避免停机？",
    "options_cn": {
      "A": "在 ALB 前配置 Amazon CloudFront 分发。",
      "B": "基于 CPU 利用率配置 EC2 Auto Scaling 简单伸缩策略。",
      "C": "基于每月的时间表配置 EC2 Auto Scaling 计划伸缩策略。",
      "D": "配置 Amazon ElastiCache 以从 EC2 实例中移除部分工作负载。"
    }
  },
  {
    "id": 334,
    "topic": "1",
    "question_en": "A company wants to give a customer the ability to use on-premises Microsoft Active Directory to download files that are stored in Amazon S3. The customer’s application uses an SFTP client to download the files. Which solution will meet these requirements with the LEAST operational overhead and no changes to the customer’s application?",
    "options_en": {
      "A": "Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.",
      "B": "Set up AWS Database Migration Service (AWS DMS) to synchronize the on-premises client with Amazon S3. Configure integrated Active Directory authentication.",
      "C": "Set up AWS DataSync to synchronize between the on-premises location and the S3 location by using AWS IAM Identity Center (AWS Single Sign-On).",
      "D": "Set up a Windows Amazon EC2 instance with SFTP to connect the on-premises client with Amazon S3. Integrate AWS Identity and Access Management (IAM)."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望让客户能够使用本地 Microsoft Active Directory 下载存储在 Amazon S3 中的文件。 客户的应用程序使用 SFTP 客户端下载文件。 哪种解决方案将以最低的运营开销满足这些要求，并且不对客户的应用程序进行任何更改？",
    "options_cn": {
      "A": "为 Amazon S3 设置 AWS Transfer Family 与 SFTP。 配置集成的 Active Directory 身份验证。",
      "B": "设置 AWS Database Migration Service (AWS DMS) 以将本地客户端与 Amazon S3 同步。 配置集成的 Active Directory 身份验证。",
      "C": "设置 AWS DataSync 以使用 AWS IAM Identity Center (AWS 单点登录) 在本地位置和 S3 位置之间进行同步。",
      "D": "设置一个带 SFTP 的 Windows Amazon EC2 实例，以将本地客户端与 Amazon S3 连接。 集成 AWS Identity and Access Management (IAM)。"
    }
  },
  {
    "id": 335,
    "topic": "1",
    "question_en": "A company is experiencing sudden increases in demand. The company needs to provision large Amazon EC2 instances from an Amazon Machine Image (AMI). The instances will run in an Auto Scaling group. The company needs a solution that provides minimum initialization latency to meet the demand. Which solution meets these requirements?",
    "options_en": {
      "A": "Use the aws ec2 register-image command to create an AMI from a snapshot. Use AWS Step Functions to replace the AMI in the Auto Scaling group.",
      "B": "Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.",
      "C": "Enable AMI creation and define lifecycle rules in Amazon Data Lifecycle Manager (Amazon DLM). Create an AWS Lambda function that modifies the AMI in the Auto Scaling group.",
      "D": "Use Amazon EventBridge to invoke AWS Backup lifecycle policies that provision AMIs. Configure Auto Scaling group capacity limits as an event source in EventBridge."
    },
    "correct_answer": "C",
    "vote_percentage": "91%",
    "question_cn": "一家公司正在经历需求的突然增长。该公司需要从一个 Amazon Machine Image (AMI) 中配置大型 Amazon EC2 实例。这些实例将在一个 Auto Scaling 组中运行。该公司需要一个能提供最短初始化延迟以满足需求的解决方案。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "使用 aws ec2 register-image 命令从快照创建 AMI。使用 AWS Step Functions 替换 Auto Scaling 组中的 AMI。",
      "B": "在快照上启用 Amazon Elastic Block Store (Amazon EBS) 快速快照恢复。使用该快照配置一个 AMI。用新的 AMI 替换 Auto Scaling 组中的 AMI。",
      "C": "启用 AMI 创建并在 Amazon Data Lifecycle Manager (Amazon DLM) 中定义生命周期规则。创建一个 AWS Lambda 函数来修改 Auto Scaling 组中的 AMI。",
      "D": "使用 Amazon EventBridge 调用 AWS Backup 生命周期策略来配置 AMI。将 Auto Scaling 组容量限制配置为 EventBridge 中的事件源。"
    }
  },
  {
    "id": 336,
    "topic": "1",
    "question_en": "A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company’s IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days. What should a solutions architect do to meet this requirement with the LEAST operational effort?",
    "options_en": {
      "A": "Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.",
      "B": "Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.",
      "C": "Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.",
      "D": "Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管了一个多层 Web 应用程序，该应用程序使用 Amazon Aurora MySQL 数据库集群进行存储。应用程序层托管在 Amazon EC2 实例上。该公司 IT 安全准则规定数据库凭证必须加密并每 14 天轮换一次。解决方案架构师应该怎么做才能以最少的运营工作量来满足此要求？",
    "options_cn": {
      "A": "创建一个新的 AWS Key Management Service (AWS KMS) 加密密钥。使用 AWS Secrets Manager 创建一个新密钥，该密钥使用 KMS 密钥和适当的凭证。将该密钥与 Aurora 数据库集群关联。配置 14 天的自定义轮换周期。",
      "B": "在 AWS Systems Manager Parameter Store 中创建两个参数：一个用于用户名，作为字符串参数，另一个使用 SecureString 类型作为密码。为密码参数选择 AWS Key Management Service (AWS KMS) 加密，并在应用程序层中加载这些参数。实现一个 AWS Lambda 函数，每 14 天轮换一次密码。",
      "C": "将包含凭证的文件存储在 AWS Key Management Service (AWS KMS) 加密的 Amazon Elastic File System (Amazon EFS) 文件系统中。在应用程序层的所有 EC2 实例中挂载 EFS 文件系统。限制对文件系统的文件的访问，以便应用程序可以读取该文件，并且只有超级用户才能修改该文件。实现一个 AWS Lambda 函数，每 14 天轮换一次 Aurora 中的密钥，并将新凭证写入该文件。",
      "D": "将包含凭证的文件存储在 AWS Key Management Service (AWS KMS) 加密的 Amazon S3 存储桶中，应用程序使用该存储桶来加载凭证。定期将文件下载到应用程序，以确保使用正确的凭证。实现一个 AWS Lambda 函数，每 14 天轮换一次 Aurora 凭证，并将这些凭证上传到 S3 存储桶中的文件。"
    }
  },
  {
    "id": 337,
    "topic": "1",
    "question_en": "A company has deployed a web application on AWS. The company hosts the backend database on Amazon RDS for MySQL with a primary DB instance and five read replicas to support scaling needs. The read replicas must lag no more than 1 second behind the primary DB instance. The database routinely runs scheduled stored procedures. As trafic on the website increases, the replicas experience additional lag during periods of peak load. A solutions architect must reduce the replication lag as much as possible. The solutions architect must minimize changes to the application code and must minimize ongoing operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the database to Amazon Aurora MySQL. Replace the read replicas with Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions.",
      "B": "Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the application to check the cache before the application queries the database. Replace the stored procedures with AWS Lambda functions.",
      "C": "Migrate the database to a MySQL database that runs on Amazon EC2 instances. Choose large, compute optimized EC2 instances for all replica nodes. Maintain the stored procedures on the EC2 instances.",
      "D": "Migrate the database to Amazon DynamoDB. Provision a large number of read capacity units (RCUs) to support the required throughput, and configure on-demand capacity scaling. Replace the stored procedures with DynamoDB streams."
    },
    "correct_answer": "A",
    "vote_percentage": "86%",
    "question_cn": "一家公司已在 AWS 上部署了一个 Web 应用程序。该公司将后端数据库托管在 Amazon RDS for MySQL 上，其中包含一个主数据库实例和五个只读副本以支持扩展需求。只读副本的延迟不得超过主数据库实例 1 秒。数据库会定期运行计划的存储过程。随着网站流量的增加，副本在高峰负载期间会遇到额外的延迟。一位解决方案架构师必须尽可能减少复制延迟。该解决方案架构师必须尽量减少对应用程序代码的更改，并尽量减少持续的运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon Aurora MySQL。用 Aurora 副本替换只读副本，并配置 Aurora 自动缩放。使用 Aurora MySQL 原生函数替换存储过程。",
      "B": "在数据库前面部署一个 Amazon ElastiCache for Redis 集群。修改应用程序以在应用程序查询数据库之前检查缓存。使用 AWS Lambda 函数替换存储过程。",
      "C": "将数据库迁移到在 Amazon EC2 实例上运行的 MySQL 数据库。为所有副本节点选择大型、计算优化的 EC2 实例。在 EC2 实例上维护存储过程。",
      "D": "将数据库迁移到 Amazon DynamoDB。配置大量读取容量单元 (RCU) 以支持所需的吞吐量，并配置按需容量扩展。使用 DynamoDB 流替换存储过程。"
    }
  },
  {
    "id": 338,
    "topic": "1",
    "question_en": "A solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster. The DR plan must replicate data to a secondary AWS Region. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region.",
      "B": "Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.",
      "C": "Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region.",
      "D": "Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region."
    },
    "correct_answer": "D",
    "vote_percentage": "56%",
    "question_cn": "一位解决方案架构师必须为高容量软件即服务 (SaaS) 平台创建一个灾难恢复 (DR) 计划。该平台的所有数据都存储在 Amazon Aurora MySQL 数据库集群中。 DR 计划必须将数据复制到辅助 AWS 区域。哪种解决方案能够以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 MySQL 二进制日志复制到辅助区域中的 Aurora 集群。为辅助区域中的 Aurora 集群预置一个数据库实例。",
      "B": "为数据库集群设置 Aurora 全局数据库。设置完成后，从辅助区域中删除数据库实例。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 持续将数据复制到辅助区域中的 Aurora 集群。 从辅助区域中删除数据库实例。",
      "D": "为数据库集群设置 Aurora 全局数据库。指定辅助区域中至少一个数据库实例。"
    }
  },
  {
    "id": 339,
    "topic": "1",
    "question_en": "A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use AWS Key Management Service (AWS KMS) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.",
      "B": "Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager.",
      "C": "Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.",
      "D": "Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个自定义应用程序，其中嵌入了凭证，用于从 Amazon RDS MySQL 数据库实例中检索信息。 管理层表示，必须以最少的编程工作量使应用程序更加安全。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Key Management Service (AWS KMS) 创建密钥。 将应用程序配置为从 AWS KMS 加载数据库凭证。 启用自动密钥轮换。",
      "B": "为应用程序用户在 RDS for MySQL 数据库上创建凭证，并将凭证存储在 AWS Secrets Manager 中。 将应用程序配置为从 Secrets Manager 加载数据库凭证。 创建一个 AWS Lambda 函数，该函数在 Secret Manager 中轮换凭证。",
      "C": "为应用程序用户在 RDS for MySQL 数据库上创建凭证，并将凭证存储在 AWS Secrets Manager 中。 将应用程序配置为从 Secrets Manager 加载数据库凭证。 使用 Secrets Manager 为应用程序用户在 RDS for MySQL 数据库中设置凭证轮换计划。",
      "D": "为应用程序用户在 RDS for MySQL 数据库上创建凭证，并将凭证存储在 AWS Systems Manager Parameter Store 中。 将应用程序配置为从 Parameter Store 加载数据库凭证。 使用 Parameter Store 为应用程序用户在 RDS for MySQL 数据库中设置凭证轮换计划。"
    }
  },
  {
    "id": 340,
    "topic": "1",
    "question_en": "A media company hosts its website on AWS. The website application’s architecture includes a fieet of Amazon EC2 instances behind an Application Load Balancer (ALB) and a database that is hosted on Amazon Aurora. The company’s cybersecurity team reports that the application is vulnerable to SQL injection. How should the company resolve this issue?",
    "options_en": {
      "A": "Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.",
      "B": "Create an ALB listener rule to reply to SQL injections with a fixed response.",
      "C": "Subscribe to AWS Shield Advanced to block all SQL injection attempts automatically.",
      "D": "Set up Amazon Inspector to block all SQL injection attempts automatically."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家媒体公司在其 AWS 上托管其网站。该网站应用程序的架构包括位于 Application Load Balancer (ALB) 后的 Amazon EC2 实例集群以及托管在 Amazon Aurora 上的数据库。该公司网络安全团队报告称，该应用程序容易受到 SQL 注入的攻击。该公司应如何解决此问题？",
    "options_cn": {
      "A": "在 ALB 前使用 AWS WAF。将适当的 Web ACL 与 AWS WAF 关联。",
      "B": "创建 ALB 监听器规则，以固定响应回复 SQL 注入。",
      "C": "订阅 AWS Shield Advanced 以自动阻止所有 SQL 注入尝试。",
      "D": "设置 Amazon Inspector 以自动阻止所有 SQL 注入尝试。"
    }
  },
  {
    "id": 341,
    "topic": "1",
    "question_en": "A company has an Amazon S3 data lake that is governed by AWS Lake Formation. The company wants to create a visualization in Amazon QuickSight by joining the data in the data lake with operational data that is stored in an Amazon Aurora MySQL database. The company wants to enforce column-level authorization so that the company’s marketing team can access only a subset of columns in the database. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon EMR to ingest the data directly from the database to the QuickSight SPICE engine. Include only the required columns.",
      "B": "Use AWS Glue Studio to ingest the data from the database to the S3 data lake. Attach an IAM policy to the QuickSight users to enforce column-level access control. Use Amazon S3 as the data source in QuickSight.",
      "C": "Use AWS Glue Elastic Views to create a materialized view for the database in Amazon S3. Create an S3 bucket policy to enforce column- level access control for the QuickSight users. Use Amazon S3 as the data source in QuickSight.",
      "D": "Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个由 AWS Lake Formation 管理的 Amazon S3 数据湖。该公司希望通过将数据湖中的数据与存储在 Amazon Aurora MySQL 数据库中的运营数据连接起来，在 Amazon QuickSight 中创建可视化。该公司希望实施列级授权，以便公司的营销团队只能访问数据库中的列子集。哪种解决方案能以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EMR 将数据直接从数据库摄取到 QuickSight SPICE 引擎。仅包含所需的列。",
      "B": "使用 AWS Glue Studio 将数据从数据库摄取到 S3 数据湖。为 QuickSight 用户附加一个 IAM 策略，以强制执行列级访问控制。使用 Amazon S3 作为 QuickSight 中的数据源。",
      "C": "使用 AWS Glue Elastic Views 为 Amazon S3 中的数据库创建物化视图。创建 S3 存储桶策略以强制执行 QuickSight 用户的列级访问控制。使用 Amazon S3 作为 QuickSight 中的数据源。",
      "D": "使用 Lake Formation 蓝图将数据从数据库摄取到 S3 数据湖。使用 Lake Formation 为 QuickSight 用户强制执行列级访问控制。使用 Amazon Athena 作为 QuickSight 中的数据源。"
    }
  },
  {
    "id": 342,
    "topic": "1",
    "question_en": "A transaction processing company has weekly scripted batch jobs that run on Amazon EC2 instances. The EC2 instances are in an Auto Scaling group. The number of transactions can vary, but the baseline CPU utilization that is noted on each run is at least 60%. The company needs to provision the capacity 30 minutes before the jobs run. Currently, engineers complete this task by manually modifying the Auto Scaling group parameters. The company does not have the resources to analyze the required capacity trends for the Auto Scaling group counts. The company needs an automated way to modify the Auto Scaling group’s desired capacity. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a dynamic scaling policy for the Auto Scaling group. Configure the policy to scale based on the CPU utilization metric. Set the target value for the metric to 60%.",
      "B": "Create a scheduled scaling policy for the Auto Scaling group. Set the appropriate desired capacity, minimum capacity, and maximum capacity. Set the recurrence to weekly. Set the start time to 30 minutes before the batch jobs run.",
      "C": "Create a predictive scaling policy for the Auto Scaling group. Configure the policy to scale based on forecast. Set the scaling metric to CPU utilization. Set the target value for the metric to 60%. In the policy, set the instances to pre-launch 30 minutes before the jobs run.",
      "D": "Create an Amazon EventBridge event to invoke an AWS Lambda function when the CPU utilization metric value for the Auto Scaling group reaches 60%. Configure the Lambda function to increase the Auto Scaling group’s desired capacity and maximum capacity by 20%."
    },
    "correct_answer": "C",
    "vote_percentage": "63%",
    "question_cn": "一家交易处理公司拥有每周在 Amazon EC2 实例上运行的脚本批量作业。 EC2 实例位于 Auto Scaling 组中。 交易数量可能有所不同，但在每次运行中注意到的基线 CPU 利用率至少为 60%。 该公司需要在作业运行前 30 分钟预置容量。 目前，工程师通过手动修改 Auto Scaling 组的参数来完成此任务。 该公司没有资源来分析 Auto Scaling 组计数所需的容量趋势。 该公司需要一种自动化的方式来修改 Auto Scaling 组的所需容量。 哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "为 Auto Scaling 组创建一个动态扩展策略。 将该策略配置为基于 CPU 利用率指标进行扩展。 将该指标的目标值设置为 60%。",
      "B": "为 Auto Scaling 组创建一个计划扩展策略。 设置适当的所需容量、最小容量和最大容量。 将重复设置为每周。 将开始时间设置为批量作业运行前 30 分钟。",
      "C": "为 Auto Scaling 组创建一个预测扩展策略。 将该策略配置为基于预测进行扩展。 将扩展指标设置为 CPU 利用率。 将该指标的目标值设置为 60%。 在策略中，将实例设置为在作业运行前 30 分钟预启动。",
      "D": "创建一个 Amazon EventBridge 事件，以便在 Auto Scaling 组的 CPU 利用率指标值达到 60% 时调用一个 AWS Lambda 函数。 配置 Lambda 函数，将 Auto Scaling 组的所需容量和最大容量增加 20%。"
    }
  },
  {
    "id": 343,
    "topic": "1",
    "question_en": "A solutions architect is designing a company’s disaster recovery (DR) architecture. The company has a MySQL database that runs on an Amazon EC2 instance in a private subnet with scheduled backup. The DR design needs to include multiple AWS Regions. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Migrate the MySQL database to multiple EC2 instances. Configure a standby EC2 instance in the DR Region. Turn on replication.",
      "B": "Migrate the MySQL database to Amazon RDS. Use a Multi-AZ deployment. Turn on read replication for the primary DB instance in the different Availability Zones.",
      "C": "Migrate the MySQL database to an Amazon Aurora global database. Host the primary DB cluster in the primary Region. Host the secondary DB cluster in the DR Region.",
      "D": "Store the scheduled backup of the MySQL database in an Amazon S3 bucket that is configured for S3 Cross-Region Replication (CRR). Use the data backup to restore the database in the DR Region."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在设计一家公司的灾难恢复（DR）架构。该公司有一个 MySQL 数据库，该数据库在私有子网中的 Amazon EC2 实例上运行，并有计划的备份。DR 设计需要在多个 AWS 区域中进行。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "将 MySQL 数据库迁移到多个 EC2 实例。在 DR 区域中配置一个备用 EC2 实例。打开复制功能。",
      "B": "将 MySQL 数据库迁移到 Amazon RDS。使用多可用区部署。打开在不同可用区中主数据库实例的读取复制。",
      "C": "将 MySQL 数据库迁移到 Amazon Aurora 全局数据库。在主区域中托管主数据库集群。在 DR 区域中托管辅助数据库集群。",
      "D": "将 MySQL 数据库的计划备份存储在配置为 S3 跨区域复制 (CRR) 的 Amazon S3 存储桶中。使用数据备份在 DR 区域中恢复数据库。"
    }
  },
  {
    "id": 344,
    "topic": "1",
    "question_en": "A company has a Java application that uses Amazon Simple Queue Service (Amazon SQS) to parse messages. The application cannot parse messages that are larger than 256 KB in size. The company wants to implement a solution to give the application the ability to parse messages as large as 50 MB. Which solution will meet these requirements with the FEWEST changes to the code?",
    "options_en": {
      "A": "Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.",
      "B": "Use Amazon EventBridge to post large messages from the application instead of Amazon SQS.",
      "C": "Change the limit in Amazon SQS to handle messages that are larger than 256 KB.",
      "D": "Store messages that are larger than 256 KB in Amazon Elastic File System (Amazon EFS). Configure Amazon SQS to reference this location in the messages."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个使用 Amazon Simple Queue Service (Amazon SQS) 解析消息的 Java 应用程序。该应用程序无法解析大于 256 KB 的消息。该公司希望实施一个解决方案，使应用程序能够解析大到 50 MB 的消息。哪种解决方案以对代码的更改最少的方式满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon SQS 扩展客户端库 for Java 将大于 256 KB 的消息托管在 Amazon S3 中。",
      "B": "使用 Amazon EventBridge 从应用程序发布大消息，而不是 Amazon SQS。",
      "C": "更改 Amazon SQS 中的限制以处理大于 256 KB 的消息。",
      "D": "将大于 256 KB 的消息存储在 Amazon Elastic File System (Amazon EFS) 中。配置 Amazon SQS 在消息中引用此位置。"
    }
  },
  {
    "id": 345,
    "topic": "1",
    "question_en": "A company wants to restrict access to the content of one of its main web applications and to protect the content by using authorization techniques available on AWS. The company wants to implement a serverless architecture and an authentication solution for fewer than 100 users. The solution needs to integrate with the main web application and serve web content globally. The solution must also scale as the company's user base grows while providing the lowest login latency possible. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use Amazon Cognito for authentication. Use Lambda@Edge for authorization. Use Amazon CloudFront to serve the web application globally.",
      "B": "Use AWS Directory Service for Microsoft Active Directory for authentication. Use AWS Lambda for authorization. Use an Application Load Balancer to serve the web application globally.",
      "C": "Use Amazon Cognito for authentication. Use AWS Lambda for authorization. Use Amazon S3 Transfer Acceleration to serve the web application globally.",
      "D": "Use AWS Directory Service for Microsoft Active Directory for authentication. Use Lambda@Edge for authorization. Use AWS Elastic Beanstalk to serve the web application globally."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望限制对其主要 Web 应用程序内容的访问，并通过使用 AWS 上可用的授权技术来保护内容。该公司希望实施无服务器架构和针对少于 100 个用户的身份验证解决方案。该解决方案需要与主要的 Web 应用程序集成并在全球范围内提供 Web 内容。该解决方案还必须随着公司用户群的增长而扩展，同时提供尽可能低的登录延迟。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Cognito 进行身份验证。使用 Lambda@Edge 进行授权。使用 Amazon CloudFront 在全球范围内提供 Web 应用程序。",
      "B": "使用 AWS Directory Service for Microsoft Active Directory 进行身份验证。使用 AWS Lambda 进行授权。使用 Application Load Balancer 在全球范围内提供 Web 应用程序。",
      "C": "使用 Amazon Cognito 进行身份验证。使用 AWS Lambda 进行授权。使用 Amazon S3 Transfer Acceleration 在全球范围内提供 Web 应用程序。",
      "D": "使用 AWS Directory Service for Microsoft Active Directory 进行身份验证。使用 Lambda@Edge 进行授权。使用 AWS Elastic Beanstalk 在全球范围内提供 Web 应用程序。"
    }
  },
  {
    "id": 346,
    "topic": "1",
    "question_en": "A company has an aging network-attached storage (NAS) array in its data center. The NAS array presents SMB shares and NFS shares to client workstations. The company does not want to purchase a new NAS array. The company also does not want to incur the cost of renewing the NAS array’s support contract. Some of the data is accessed frequently, but much of the data is inactive. A solutions architect needs to implement a solution that migrates the data to Amazon S3, uses S3 Lifecycle policies, and maintains the same look and feel for the client workstations. The solutions architect has identified AWS Storage Gateway as part of the solution. Which type of storage gateway should the solutions architect provision to meet these requirements?",
    "options_en": {
      "A": "Volume Gateway",
      "B": "Tape Gateway",
      "C": "Amazon FSx File Gateway",
      "D": "Amazon S3 File Gateway"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其数据中心拥有一个老化的网络附加存储 (NAS) 阵列。该 NAS 阵列向客户端工作站提供 SMB 共享和 NFS 共享。该公司不想购买新的 NAS 阵列。该公司也不想承担续订 NAS 阵列支持合同的费用。一些数据被频繁访问，但很多数据是不活动的。解决方案架构师需要实施一个解决方案，该方案将数据迁移到 Amazon S3，使用 S3 生命周期策略，并保持客户端工作站相同的外观和感觉。解决方案架构师已确定 AWS Storage Gateway 是解决方案的一部分。解决方案架构师应该配置哪种类型的存储网关来满足这些要求？",
    "options_cn": {
      "A": "卷网关",
      "B": "磁带网关",
      "C": "Amazon FSx 文件网关",
      "D": "Amazon S3 文件网关"
    }
  },
  {
    "id": 347,
    "topic": "1",
    "question_en": "A company has an application that is running on Amazon EC2 instances. A solutions architect has standardized the company on a particular instance family and various instance sizes based on the current needs of the company. The company wants to maximize cost savings for the application over the next 3 years. The company needs to be able to change the instance family and sizes in the next 6 months based on application popularity and usage. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Compute Savings Plan",
      "B": "EC2 Instance Savings Plan",
      "C": "Zonal Reserved Instances",
      "D": "Standard Reserved Instances"
    },
    "correct_answer": "D",
    "vote_percentage": "79%",
    "question_cn": "一家公司在其 Amazon EC2 实例上运行一个应用程序。解决方案架构师已根据公司当前的需求，将公司标准化为特定的实例系列和各种实例大小。该公司希望在未来 3 年内最大限度地节省应用程序的成本。该公司需要在未来 6 个月内根据应用程序的受欢迎程度和使用情况更改实例系列和大小。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "计算节省计划",
      "B": "EC2 实例节省计划",
      "C": "区域预留实例",
      "D": "标准预留实例"
    }
  },
  {
    "id": 348,
    "topic": "1",
    "question_en": "A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use provisioned mode and DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA). Reserve capacity for the forecasted workload.",
      "B": "Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).",
      "C": "Use on-demand mode. Set the read capacity units (RCUs) and write capacity units (WCUs) high enough to accommodate changes in the workload.",
      "D": "Use on-demand mode. Specify the read capacity units (RCUs) and write capacity units (WCUs) with reserved capacity."
    },
    "correct_answer": "A",
    "vote_percentage": "86%",
    "question_cn": "一家公司从使用可穿戴设备的众多参与者那里收集数据。该公司将数据存储在 Amazon DynamoDB 表中，并使用应用程序分析数据。数据工作负载是恒定的且可预测的。该公司希望保持或低于其 DynamoDB 的预测预算。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用预置模式和 DynamoDB 标准-不频繁访问（DynamoDB Standard-IA）。为预测的工作负载预留容量。",
      "B": "使用预置模式。指定读取容量单元 (RCU) 和写入容量单元 (WCU)。",
      "C": "使用按需模式。将读取容量单元 (RCU) 和写入容量单元 (WCU) 设置得足够高，以适应工作负载的变化。",
      "D": "使用按需模式。使用预留容量指定读取容量单元 (RCU) 和写入容量单元 (WCU)。"
    }
  },
  {
    "id": 349,
    "topic": "1",
    "question_en": "A company stores confidential data in an Amazon Aurora PostgreSQL database in the ap-southeast-3 Region. The database is encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The company was recently acquired and must securely share a backup of the database with the acquiring company’s AWS account in ap-southeast-3. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a database snapshot. Copy the snapshot to a new unencrypted snapshot. Share the new snapshot with the acquiring company’s AWS account.",
      "B": "Create a database snapshot. Add the acquiring company’s AWS account to the KMS key policy. Share the snapshot with the acquiring company’s AWS account.",
      "C": "Create a database snapshot that uses a different AWS managed KMS key. Add the acquiring company’s AWS account to the KMS key alias. Share the snapshot with the acquiring company's AWS account.",
      "D": "Create a database snapshot. Download the database snapshot. Upload the database snapshot to an Amazon S3 bucket. Update the S3 bucket policy to allow access from the acquiring company’s AWS account."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 ap-southeast-3 区域的 Amazon Aurora PostgreSQL 数据库中存储机密数据。该数据库使用 AWS Key Management Service (AWS KMS) 客户托管密钥进行加密。该公司最近被收购，必须安全地与收购公司在 ap-southeast-3 区域的 AWS 账户共享数据库的备份。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个数据库快照。将快照复制到一个新的未加密快照。与收购公司的 AWS 账户共享新快照。",
      "B": "创建一个数据库快照。将收购公司的 AWS 账户添加到 KMS 密钥策略中。与收购公司的 AWS 账户共享快照。",
      "C": "创建一个使用不同 AWS 托管 KMS 密钥的数据库快照。将收购公司的 AWS 账户添加到 KMS 密钥别名中。与收购公司的 AWS 账户共享快照。",
      "D": "创建一个数据库快照。下载数据库快照。将数据库快照上传到 Amazon S3 存储桶。更新 S3 存储桶策略以允许从收购公司的 AWS 账户进行访问。"
    }
  },
  {
    "id": 350,
    "topic": "1",
    "question_en": "A company uses a 100 GB Amazon RDS for Microsoft SQL Server Single-AZ DB instance in the us-east-1 Region to store customer transactions. The company needs high availability and automatic recovery for the DB instance. The company must also run reports on the RDS database several times a year. The report process causes transactions to take longer than usual to post to the customers’ accounts. The company needs a solution that will improve the performance of the report process. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment.",
      "B": "Take a snapshot of the current DB instance. Restore the snapshot to a new RDS deployment in another Availability Zone.",
      "C": "Create a read replica of the DB instance in a different Availability Zone. Point all requests for reports to the read replica.",
      "D": "Migrate the database to RDS Custom",
      "E": "Use RDS Proxy to limit reporting requests to the maintenance window."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用位于 us-east-1 区域的 100 GB Amazon RDS for Microsoft SQL Server 单可用区数据库实例来存储客户交易。该公司需要高可用性和数据库实例的自动恢复。该公司还必须每年多次在 RDS 数据库上运行报告。报告流程导致交易花费比平时更长的时间才能发布到客户的帐户。该公司需要一个能够提高报告流程性能的解决方案。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将数据库实例从单可用区数据库实例修改为多可用区部署。",
      "B": "拍摄当前数据库实例的快照。将快照还原到另一个可用区中的新 RDS 部署。",
      "C": "在不同的可用区中创建数据库实例的只读副本。将所有报告请求指向只读副本。",
      "D": "将数据库迁移到 RDS Custom。",
      "E": "使用 RDS Proxy 将报告请求限制在维护时段内。"
    }
  },
  {
    "id": 351,
    "topic": "1",
    "question_en": "A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workfiow. The company also wants to minimize operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Build out the workfiow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workfiow steps.",
      "B": "Build out the workfiow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workfiow steps on the EC2 instances.",
      "C": "Build out the workfiow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workfiow steps.",
      "D": "Build out the workfiow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workfiow steps."
    },
    "correct_answer": "D",
    "vote_percentage": "88%",
    "question_cn": "一家公司正在将其数据管理应用程序迁移到 AWS。该公司希望过渡到事件驱动架构。该架构需要更分散，并使用无服务器概念来执行工作流的不同方面。该公司还希望最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Glue 中构建工作流。使用 AWS Glue 调用 AWS Lambda 函数来处理工作流步骤。",
      "B": "在 AWS Step Functions 中构建工作流。将应用程序部署在 Amazon EC2 实例上。使用 Step Functions 在 EC2 实例上调用工作流步骤。",
      "C": "在 Amazon EventBridge 中构建工作流。使用 EventBridge 定期间隔调用 AWS Lambda 函数来处理工作流步骤。",
      "D": "在 AWS Step Functions 中构建工作流。使用 Step Functions 创建状态机。使用状态机调用 AWS Lambda 函数来处理工作流步骤。"
    }
  },
  {
    "id": 352,
    "topic": "1",
    "question_en": "A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience. Which solution will meet these requirements?",
    "options_en": {
      "A": "Setup a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.",
      "B": "Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.",
      "C": "Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.",
      "D": "Set up a VPC peering mesh between each Region. Turn on UDP for each VPC."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为其在线多人游戏设计网络。该游戏使用 UDP 网络协议，并将部署在八个 AWS 区域中。网络架构需要最大限度地减少延迟和丢包，以给最终用户提供高质量的游戏体验。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在每个区域设置一个 Transit Gateway。在每个 Transit Gateway 之间创建区域互连附件。",
      "B": "设置 AWS Global Accelerator，并在每个区域中使用 UDP 监听器和终端节点组。",
      "C": "设置 Amazon CloudFront，并打开 UDP。在每个区域配置一个源。",
      "D": "在每个区域之间设置 VPC 对等互联网状结构。为每个 VPC 打开 UDP。"
    }
  },
  {
    "id": 353,
    "topic": "1",
    "question_en": "A company hosts a three-tier web application on Amazon EC2 instances in a single Availability Zone. The web application uses a self- managed MySQL database that is hosted on an EC2 instance to store data in an Amazon Elastic Block Store (Amazon EBS) volume. The MySQL database currently uses a 1 TB Provisioned IOPS SSD (io2) EBS volume. The company expects trafic of 1,000 IOPS for both reads and writes at peak trafic. The company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an io2 Block Express EBS volume.",
      "B": "Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.",
      "C": "Use Amazon S3 Intelligent-Tiering access tiers.",
      "D": "Use two large EC2 instances to host the database in active-passive mode."
    },
    "correct_answer": "B",
    "vote_percentage": "89%",
    "question_cn": "一家公司在单个可用区内的 Amazon EC2 实例上托管一个三层 Web 应用程序。 该 Web 应用程序使用托管在 EC2 实例上的自管理 MySQL 数据库将数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。 MySQL 数据库当前使用 1 TB Provisioned IOPS SSD (io2) EBS 卷。该公司预计在峰值流量时，读取和写入的 IOPS 均为 1,000。该公司希望最大限度地减少任何中断、稳定性能并降低成本，同时保留双倍 IOPS 的容量。该公司希望将数据库层移动到完全托管的、具有高可用性和容错能力的解决方案。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon RDS for MySQL 数据库实例的多可用区部署，该实例带有 io2 Block Express EBS 卷。",
      "B": "使用 Amazon RDS for MySQL 数据库实例的多可用区部署，该实例带有 General Purpose SSD (gp2) EBS 卷。",
      "C": "使用 Amazon S3 Intelligent-Tiering 访问层。",
      "D": "使用两个大型 EC2 实例以主动-被动模式托管数据库。"
    }
  },
  {
    "id": 354,
    "topic": "1",
    "question_en": "A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak trafic or unpredictable trafic. The company needs a solution that reduces the application failures with the least amount of change to the code. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Reduce the Lambda concurrency rate.",
      "B": "Enable RDS Proxy on the RDS DB instance.",
      "C": "Resize the RDS DB instance class to accept more connections.",
      "D": "Migrate the database to Amazon DynamoDB with on-demand scaling."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上托管一个无服务器应用程序。该应用程序使用 Amazon API Gateway、AWS Lambda 和用于 PostgreSQL 数据库的 Amazon RDS。该公司注意到，在高峰流量或不可预测的流量期间，由于数据库连接超时，应用程序错误有所增加。该公司需要一个解决方案，以最少的代码更改来减少应用程序故障。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "降低 Lambda 并发速率。",
      "B": "在 RDS 数据库实例上启用 RDS 代理。",
      "C": "调整 RDS 数据库实例的大小以接受更多连接。",
      "D": "将数据库迁移到具有按需扩展的 Amazon DynamoDB。"
    }
  },
  {
    "id": 355,
    "topic": "1",
    "question_en": "A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory. Which solution will run the batch job within 15 minutes with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Lambda with functional scaling.",
      "B": "Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.",
      "C": "Use Amazon Lightsail with AWS Auto Scaling.",
      "D": "Use AWS Batch on Amazon EC2."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在将旧应用程序迁移到 AWS。该应用程序每小时运行一个批处理作业，并且是 CPU 密集型作业。批处理作业在本地服务器上平均需要 15 分钟。服务器有 64 个虚拟 CPU (vCPU) 和 512 GiB 内存。哪种解决方案将在 15 分钟内运行批处理作业，并且运营开销最少？",
    "options_cn": {
      "A": "使用 AWS Lambda 和功能扩展。",
      "B": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate。",
      "C": "使用 Amazon Lightsail 和 AWS Auto Scaling。",
      "D": "在 Amazon EC2 上使用 AWS Batch。"
    }
  },
  {
    "id": 356,
    "topic": "1",
    "question_en": "A company stores its data objects in Amazon S3 Standard storage. A solutions architect has found that 75% of the data is rarely accessed after 30 days. The company needs all the data to remain immediately accessible with the same high availability and resiliency, but the company wants to minimize storage costs. Which storage solution will meet these requirements?",
    "options_en": {
      "A": "Move the data objects to S3 Glacier Deep Archive after 30 days.",
      "B": "Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.",
      "C": "Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.",
      "D": "Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司将其数据对象存储在 Amazon S3 标准存储中。一位解决方案架构师发现，75% 的数据在 30 天后很少被访问。公司需要所有数据保持立即可访问，并具有相同的高可用性和弹性，但公司希望最大限度地降低存储成本。哪个存储解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 30 天后，将数据对象移动到 S3 Glacier Deep Archive。",
      "B": "在 30 天后，将数据对象移动到 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "C": "在 30 天后，将数据对象移动到 S3 One Zone-Infrequent Access (S3 One Zone-IA)。",
      "D": "立即将数据对象移动到 S3 One Zone-Infrequent Access (S3 One Zone-IA)。"
    }
  },
  {
    "id": 357,
    "topic": "1",
    "question_en": "A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.",
      "B": "Store the static files on Amazon S3. Use Amazon ElastiCache to cache objects at the edge.",
      "C": "Store the server-side code on Amazon Elastic File System (Amazon EFS). Mount the EFS volume on each EC2 instance to share the files.",
      "D": "Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files",
      "E": "Store the server-side code on a General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on each EC2 instance to share the files."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家游戏公司正在将其公共排行榜从数据中心迁移到 AWS 云。该公司使用 Application Load Balancer 后面的 Amazon EC2 Windows Server 实例来托管其动态应用程序。该公司需要为该应用程序提供高可用性的存储解决方案。该应用程序由静态文件和动态服务器端代码组成。解决方案架构师应采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将静态文件存储在 Amazon S3 中。使用 Amazon CloudFront 在边缘缓存对象。",
      "B": "将静态文件存储在 Amazon S3 中。使用 Amazon ElastiCache 在边缘缓存对象。",
      "C": "将服务器端代码存储在 Amazon Elastic File System (Amazon EFS) 中。 在每个 EC2 实例上挂载 EFS 卷以共享文件。",
      "D": "将服务器端代码存储在 Amazon FSx for Windows File Server 中。 在每个 EC2 实例上挂载 FSx for Windows File Server 卷以共享文件。",
      "E": "将服务器端代码存储在通用 SSD (gp2) Amazon Elastic Block Store (Amazon EBS) 卷中。在每个 EC2 实例上挂载 EBS 卷以共享文件。"
    }
  },
  {
    "id": 358,
    "topic": "1",
    "question_en": "A social media company runs its application on Amazon EC2 instances behind an Application Load Balancer (ALB). The ALB is the origin for an Amazon CloudFront distribution. The application has more than a billion images stored in an Amazon S3 bucket and processes thousands of images each second. The company wants to resize the images dynamically and serve appropriate formats to clients. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Install an external image management library on an EC2 instance. Use the image management library to process the images.",
      "B": "Create a CloudFront origin request policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.",
      "C": "Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.",
      "D": "Create a CloudFront response headers policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request."
    },
    "correct_answer": "D",
    "vote_percentage": "88%",
    "question_cn": "一家社交媒体公司在其Application Load Balancer (ALB) 之后，在Amazon EC2实例上运行其应用程序。ALB是Amazon CloudFront分发的源。该应用程序在Amazon S3存储桶中存储了超过十亿张图像，并且每秒处理数千张图像。该公司希望动态调整图像大小并为客户端提供适当的格式。哪个解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在EC2实例上安装外部图像管理库。使用图像管理库处理图像。",
      "B": "创建CloudFront源请求策略。使用该策略根据请求中的User-Agent HTTP标头自动调整图像大小并提供适当的格式。",
      "C": "使用带有外部图像管理库的Lambda@Edge函数。将Lambda@Edge函数与提供图像的CloudFront行为关联。",
      "D": "创建CloudFront响应标头策略。使用该策略根据请求中的User-Agent HTTP标头自动调整图像大小并提供适当的格式。"
    }
  },
  {
    "id": 359,
    "topic": "1",
    "question_en": "A hospital needs to store patient records in an Amazon S3 bucket. The hospital’s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.",
      "B": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.",
      "C": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.",
      "D": "Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie."
    },
    "correct_answer": "C",
    "vote_percentage": "84%",
    "question_cn": "一家医院需要在 Amazon S3 存储桶中存储患者记录。 医院的合规团队必须确保所有受保护的健康信息 (PHI) 在传输和静态时都被加密。 合规团队必须管理静态数据的加密密钥。 哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Certificate Manager (ACM) 中创建公共 SSL/TLS 证书。 将该证书与 Amazon S3 关联。 配置每个 S3 存储桶的默认加密，以使用具有 AWS KMS 密钥 (SSE-KMS) 的服务器端加密。 分配合规团队来管理 KMS 密钥。",
      "B": "在 S3 存储桶策略上使用 aws:SecureTransport 条件，仅允许通过 HTTPS (TLS) 的加密连接。 配置每个 S3 存储桶的默认加密，以使用具有 S3 托管加密密钥 (SSE-S3) 的服务器端加密。 分配合规团队来管理 SSE-S3 密钥。",
      "C": "在 S3 存储桶策略上使用 aws:SecureTransport 条件，仅允许通过 HTTPS (TLS) 的加密连接。 配置每个 S3 存储桶的默认加密，以使用具有 AWS KMS 密钥 (SSE-KMS) 的服务器端加密。 分配合规团队来管理 KMS 密钥。",
      "D": "在 S3 存储桶策略上使用 aws:SecureTransport 条件，仅允许通过 HTTPS (TLS) 的加密连接。 使用 Amazon Macie 保护存储在 Amazon S3 中的敏感数据。 分配合规团队来管理 Macie。"
    }
  },
  {
    "id": 360,
    "topic": "1",
    "question_en": "A company uses Amazon API Gateway to run a private gateway with two REST APIs in the same VPC. The BuyStock RESTful web service calls the CheckFunds RESTful web service to ensure that enough funds are available before a stock can be purchased. The company has noticed in the VPC fiow logs that the BuyStock RESTful web service calls the CheckFunds RESTful web service over the internet instead of through the VPC. A solutions architect must implement a solution so that the APIs communicate through the VPC. Which solution will meet these requirements with the FEWEST changes to the code?",
    "options_en": {
      "A": "Add an X-API-Key header in the HTTP header for authorization.",
      "B": "Use an interface endpoint.",
      "C": "Use a gateway endpoint.",
      "D": "Add an Amazon Simple Queue Service (Amazon SQS) queue between the two REST APIs."
    },
    "correct_answer": "A",
    "vote_percentage": "92%",
    "question_cn": "一家公司使用 Amazon API Gateway 运行一个私有网关，该网关在同一个 VPC 中有两个 REST API。BuyStock RESTful web 服务调用 CheckFunds RESTful web 服务，以确保在购买股票之前有足够的资金可用。该公司在 VPC 流日志中注意到，BuyStock RESTful web 服务通过互联网而不是通过 VPC 调用 CheckFunds RESTful web 服务。一个解决方案架构师必须实现一个解决方案，以便这些 API 通过 VPC 进行通信。以下哪个解决方案将以对代码的更改最少来满足这些要求？",
    "options_cn": {
      "A": "在 HTTP 标头中添加一个 X-API-Key 标头以进行授权。",
      "B": "使用接口 endpoint。",
      "C": "使用网关 endpoint。",
      "D": "在两个 REST API 之间添加一个 Amazon Simple Queue Service (Amazon SQS) 队列。"
    }
  },
  {
    "id": 361,
    "topic": "1",
    "question_en": "A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.",
      "B": "Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.",
      "C": "Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.",
      "D": "Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上托管多人游戏应用程序。该公司希望应用程序以亚毫秒级的延迟读取数据，并对历史数据运行一次性查询。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon RDS 存储经常访问的数据。运行一个定期的自定义脚本，将数据导出到 Amazon S3 存储桶。",
      "B": "将数据直接存储在 Amazon S3 存储桶中。实施 S3 生命周期策略，将较旧的数据移动到 S3 Glacier Deep Archive 进行长期存储。使用 Amazon Athena 对 Amazon S3 中的数据运行一次性查询。",
      "C": "使用 Amazon DynamoDB 和 DynamoDB Accelerator (DAX) 存储经常访问的数据。使用 DynamoDB 表导出将数据导出到 Amazon S3 存储桶。使用 Amazon Athena 对 Amazon S3 中的数据运行一次性查询。",
      "D": "使用 Amazon DynamoDB 存储经常访问的数据。打开流式传输到 Amazon Kinesis Data Streams。使用 Amazon Kinesis Data Firehose 从 Kinesis Data Streams 读取数据。将记录存储在 Amazon S3 存储桶中。"
    }
  },
  {
    "id": 362,
    "topic": "1",
    "question_en": "A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly. Which actions should a solutions architect take to meet this requirement? (Choose two.)",
    "options_en": {
      "A": "Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.",
      "B": "Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.",
      "C": "Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.",
      "D": "Write the messages to an Amazon Simple Queue Service (Amazon SQS) queu",
      "E": "Set the message attribute to use the payment ID. E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司使用一个支付处理系统，该系统要求特定支付 ID 的消息必须按照发送的顺序接收。 否则，支付可能被错误处理。 解决方案架构师应该采取哪些措施来满足此要求？（选择两项。）",
    "options_cn": {
      "A": "将消息写入以支付 ID 作为分区键的 Amazon DynamoDB 表。",
      "B": "将消息写入以支付 ID 作为分区键的 Amazon Kinesis 数据流。",
      "C": "将消息写入以支付 ID 作为键的 Amazon ElastiCache for Memcached 集群。",
      "D": "将消息写入 Amazon Simple Queue Service (Amazon SQS) 队列。 将消息属性设置为使用支付 ID。",
      "E": "将消息写入 Amazon Simple Queue Service (Amazon SQS) FIFO 队列。 将消息组设置为使用支付 ID。"
    }
  },
  {
    "id": 363,
    "topic": "1",
    "question_en": "A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events. Which solution will meet these requirements?",
    "options_en": {
      "A": "Amazon EventBridge event bus",
      "B": "Amazon Simple Notification Service (Amazon SNS) FIFO topics",
      "C": "Amazon Simple Notification Service (Amazon SNS) standard topics",
      "D": "Amazon Simple Queue Service (Amazon SQS) FIFO queues"
    },
    "correct_answer": "B",
    "vote_percentage": "73%",
    "question_cn": "一家公司正在构建一个游戏系统，该系统需要将独特的事件并发地发送到单独的排行榜、匹配和身份验证服务。该公司需要一个 AWS 事件驱动系统，以保证事件的顺序。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "Amazon EventBridge 事件总线",
      "B": "Amazon Simple Notification Service (Amazon SNS) FIFO 主题",
      "C": "Amazon Simple Notification Service (Amazon SNS) 标准主题",
      "D": "Amazon Simple Queue Service (Amazon SQS) FIFO 队列"
    }
  },
  {
    "id": 364,
    "topic": "1",
    "question_en": "A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture. A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.",
      "B": "Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.",
      "C": "Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.",
      "D": "Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS",
      "E": "Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS."
    },
    "correct_answer": "C",
    "vote_percentage": "73%",
    "question_cn": "一家医院正在设计一个收集病人症状的新应用程序。医院决定在架构中使用 Amazon Simple Queue Service (Amazon SQS) 和 Amazon Simple Notification Service (Amazon SNS)。一位解决方案架构师正在审查基础设施设计。数据必须在静态和传输过程中加密。只有医院的授权人员才能访问数据。解决方案架构师应采取哪些步骤组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 SQS 组件上打开服务器端加密。更新默认密钥策略，将密钥使用限制为一组授权主体。",
      "B": "通过使用 AWS Key Management Service (AWS KMS) 客户托管密钥，在 SNS 组件上打开服务器端加密。应用密钥策略以限制密钥使用权限为一组授权主体。",
      "C": "在 SNS 组件上打开加密。更新默认密钥策略，将密钥使用限制为一组授权主体。在主题策略中设置一个条件，仅允许通过 TLS 进行加密连接。",
      "D": "通过使用 AWS Key Management Service (AWS KMS) 客户托管密钥，在 SQS 组件上打开服务器端加密。应用密钥策略以限制密钥使用权限为一组授权主体。在队列策略中设置一个条件，仅允许通过 TLS 进行加密连接。",
      "E": "通过使用 AWS Key Management Service (AWS KMS) 客户托管密钥，在 SQS 组件上打开服务器端加密。应用 IAM 策略以限制密钥使用权限为一组授权主体。在队列策略中设置一个条件，仅允许通过 TLS 进行加密连接。"
    }
  },
  {
    "id": 365,
    "topic": "1",
    "question_en": "A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days. Which feature should the solutions architect include in the design to meet this requirement?",
    "options_en": {
      "A": "Read replicas",
      "B": "Manual snapshots",
      "C": "Automated backups",
      "D": "Multi-AZ deployments"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司运营一个由 Amazon RDS 支持的 Web 应用程序。一名新的数据库管理员不小心编辑了数据库表中的信息，导致数据丢失。为了帮助从这类事件中恢复，该公司希望能够将数据库恢复到过去 30 天内发生任何更改前 5 分钟的状态。解决方案架构师应该在设计中包含哪个功能来满足此要求？",
    "options_cn": {
      "A": "只读副本",
      "B": "手动快照",
      "C": "自动备份",
      "D": "多可用区部署"
    }
  },
  {
    "id": 366,
    "topic": "1",
    "question_en": "A company’s web application consists of an Amazon API Gateway API in front of an AWS Lambda function and an Amazon DynamoDB database. The Lambda function handles the business logic, and the DynamoDB table hosts the data. The application uses Amazon Cognito user pools to identify the individual users of the application. A solutions architect needs to update the application so that only users who have a subscription can access premium content. Which solution will meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Enable API caching and throttling on the API Gateway API.",
      "B": "Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription.",
      "C": "Apply fine-grained IAM permissions to the premium content in the DynamoDB table.",
      "D": "Implement API usage plans and API keys to limit the access of users who do not have a subscription."
    },
    "correct_answer": "C",
    "vote_percentage": "85%",
    "question_cn": "一家公司的 Web 应用程序由一个 Amazon API Gateway API、一个 AWS Lambda 函数和一个 Amazon DynamoDB 数据库组成。Lambda 函数处理业务逻辑，DynamoDB 表托管数据。该应用程序使用 Amazon Cognito 用户池来识别应用程序的各个用户。解决方案架构师需要更新应用程序，以便只有订阅用户才能访问高级内容。哪种解决方案将以最少的运营开销满足此要求？",
    "options_cn": {
      "A": "在 API Gateway API 上启用 API 缓存和限制。",
      "B": "在 API Gateway API 上设置 AWS WAF。创建一个规则来过滤未订阅的用户。",
      "C": "将细粒度的 IAM 权限应用于 DynamoDB 表中的高级内容。",
      "D": "实施 API 使用计划和 API 密钥，以限制未订阅用户的访问。"
    }
  },
  {
    "id": 367,
    "topic": "1",
    "question_en": "A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company’s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.",
      "B": "Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.",
      "C": "Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.",
      "D": "Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 Amazon Route 53 基于延迟的路由，将请求路由到其面向全球用户的基于 UDP 的应用程序。该应用程序托管在美国、亚洲和欧洲的公司本地数据中心的冗余服务器上。公司的合规性要求规定应用程序必须托管在本地。该公司希望提高应用程序的性能和可用性。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在三个 AWS 区域中配置三个 Network Load Balancer (NLB) 以寻址本地端点。使用 AWS Global Accelerator 创建一个加速器，并将 NLB 注册为其端点。使用指向加速器 DNS 的 CNAME 提供对应用程序的访问。",
      "B": "在三个 AWS 区域中配置三个 Application Load Balancer (ALB) 以寻址本地端点。使用 AWS Global Accelerator 创建一个加速器，并将 ALB 注册为其端点。使用指向加速器 DNS 的 CNAME 提供对应用程序的访问。",
      "C": "在三个 AWS 区域中配置三个 Network Load Balancer (NLB) 以寻址本地端点。在 Route 53 中，创建一个指向这三个 NLB 的基于延迟的记录，并将其用作 Amazon CloudFront 分配的源。使用指向 CloudFront DNS 的 CNAME 提供对应用程序的访问。",
      "D": "在三个 AWS 区域中配置三个 Application Load Balancer (ALB) 以寻址本地端点。在 Route 53 中，创建一个指向这三个 ALB 的基于延迟的记录，并将其用作 Amazon CloudFront 分配的源。使用指向 CloudFront DNS 的 CNAME 提供对应用程序的访问。"
    }
  },
  {
    "id": 368,
    "topic": "1",
    "question_en": "A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords. What should the solutions architect do to accomplish this?",
    "options_en": {
      "A": "Set an overall password policy for the entire AWS account.",
      "B": "Set a password policy for each IAM user in the AWS account.",
      "C": "Use third-party vendor software to set password requirements.",
      "D": "Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements."
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一个解决方案架构师希望所有新用户都具有特定的复杂性要求以及 IAM 用户密码的强制轮换周期。解决方案架构师应该怎么做才能实现此目标？",
    "options_cn": {
      "A": "为整个 AWS 账户设置一个总体的密码策略。",
      "B": "为 AWS 账户中的每个 IAM 用户设置密码策略。",
      "C": "使用第三方供应商软件设置密码要求。",
      "D": "将一个 Amazon CloudWatch 规则附加到 Create_newuser 事件，以使用适当的要求设置密码。"
    }
  },
  {
    "id": 369,
    "topic": "1",
    "question_en": "A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).",
      "B": "Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.",
      "C": "Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).",
      "D": "Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance."
    },
    "correct_answer": "A",
    "vote_percentage": "65%",
    "question_cn": "一家公司已将应用程序迁移到 Amazon EC2 Linux 实例。其中一个 EC2 实例按计划运行几个 1 小时的任务。这些任务由不同的团队编写，并且没有通用的编程语言。该公司担心这些任务在单个实例上运行时出现的性能和可扩展性问题。一位解决方案架构师需要实施一个解决方案来解决这些问题。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Batch 将任务作为作业运行。使用 Amazon EventBridge（Amazon CloudWatch Events）安排作业。",
      "B": "将 EC2 实例转换为容器。使用 AWS App Runner 按需创建容器以将任务作为作业运行。",
      "C": "将任务复制到 AWS Lambda 函数中。使用 Amazon EventBridge（Amazon CloudWatch Events）安排 Lambda 函数。",
      "D": "创建运行任务的 EC2 实例的 Amazon Machine Image (AMI)。使用 AMI 创建一个 Auto Scaling 组来运行该实例的多个副本。"
    }
  },
  {
    "id": 370,
    "topic": "1",
    "question_en": "A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance. Which solution meets these requirements?",
    "options_en": {
      "A": "Provision a NAT instance in a public subnet. Modify each private subnet's route table with a default route that points to the NAT instance.",
      "B": "Provision a NAT instance in a private subnet. Modify each private subnet's route table with a default route that points to the NAT instance.",
      "C": "Provision a NAT gateway in a public subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.",
      "D": "Provision a NAT gateway in a private subnet. Modify each private subnet's route table with a default route that points to the NAT gateway."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 VPC 中运行公共三层 Web 应用程序。该应用程序在多个可用区中的 Amazon EC2 实例上运行。在私有子网中运行的 EC2 实例需要通过互联网与许可证服务器通信。该公司需要一个能够最大限度地减少运营维护的托管解决方案。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "在公有子网中配置一个 NAT 实例。使用指向 NAT 实例的默认路由修改每个私有子网的路由表。",
      "B": "在私有子网中配置一个 NAT 实例。使用指向 NAT 实例的默认路由修改每个私有子网的路由表。",
      "C": "在公有子网中配置一个 NAT 网关。使用指向 NAT 网关的默认路由修改每个私有子网的路由表。",
      "D": "在私有子网中配置一个 NAT 网关。使用指向 NAT 网关的默认路由修改每个私有子网的路由表。"
    }
  },
  {
    "id": 371,
    "topic": "1",
    "question_en": "A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Use a Kubernetes plugin that uses the customer managed key to perform data encryption.",
      "B": "After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.",
      "C": "Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.",
      "D": "Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster",
      "E": "Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes."
    },
    "correct_answer": "A",
    "vote_percentage": "56%",
    "question_cn": "一家公司需要创建一个 Amazon Elastic Kubernetes Service (Amazon EKS) 集群来托管一个数字媒体流应用程序。EKS 集群将使用一个由 Amazon Elastic Block Store (Amazon EBS) 卷提供存储支持的托管节点组。该公司必须使用存储在 AWS Key Management Service (AWS KMS) 中的客户托管密钥对所有静态数据进行加密。哪种组合的操作将以最少的运营开销满足此要求？（选择两个。）",
    "options_cn": {
      "A": "使用一个 Kubernetes 插件，该插件使用客户托管密钥执行数据加密。",
      "B": "创建 EKS 集群后，找到 EBS 卷。使用客户托管密钥启用加密。",
      "C": "在将创建 EKS 集群的 AWS 区域中，默认启用 EBS 加密。选择客户托管密钥作为默认密钥。",
      "D": "创建 EKS 集群。创建一个 IAM 角色，该角色具有授予客户托管密钥权限的策略。将该角色与 EKS 集群关联。",
      "E": "将客户托管密钥作为 Kubernetes 密钥存储在 EKS 集群中。使用客户托管密钥对 EBS 卷进行加密。"
    }
  },
  {
    "id": 372,
    "topic": "1",
    "question_en": "A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code. When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.",
      "B": "Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.",
      "C": "Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.",
      "D": "Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance."
    },
    "correct_answer": "B",
    "vote_percentage": "66%",
    "question_cn": "一家公司希望将 Oracle 数据库迁移到 AWS。该数据库包含一个包含数百万个高分辨率地理信息系统 (GIS) 图像的表，这些图像由地理代码标识。发生自然灾害时，每隔几分钟就会更新数万张图像。每个地理代码都有一个与之关联的图像或行。该公司希望找到一个在高负载事件期间具有高可用性和可扩展性的解决方案。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "将图像和地理代码存储在数据库表中。使用在 Amazon RDS Multi-AZ DB 实例上运行的 Oracle。",
      "B": "将图像存储在 Amazon S3 存储桶中。使用 Amazon DynamoDB，将地理代码用作键，将图像 S3 URL 用作值。",
      "C": "将图像和地理代码存储在 Amazon DynamoDB 表中。在高负载期间配置 DynamoDB Accelerator (DAX)。",
      "D": "将图像存储在 Amazon S3 存储桶中。将地理代码和图像 S3 URL 存储在数据库表中。使用在 Amazon RDS Multi-AZ DB 实例上运行的 Oracle。"
    }
  },
  {
    "id": 373,
    "topic": "1",
    "question_en": "A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models. Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes. Which storage solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.",
      "B": "Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automatically move objects to S3 Glacier Deep Archive after 1 year.",
      "C": "Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.",
      "D": "Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year."
    },
    "correct_answer": "D",
    "vote_percentage": "91%",
    "question_cn": "一家公司有一个应用程序，从汽车上的物联网传感器收集数据。数据通过 Amazon Kinesis Data Firehose 流式传输并存储在 Amazon S3 中。这些数据每年产生数万亿个 S3 对象。每天早上，该公司使用过去 30 天的数据来重新训练一套机器学习 (ML) 模型。每年四次，该公司使用过去 12 个月的数据来执行分析并训练其他 ML 模型。这些数据必须在最多 1 年的时间内以最小的延迟可用。 1 年后，数据必须保留用于归档。哪种存储解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "使用 S3 Intelligent-Tiering 存储类。 创建一个 S3 生命周期策略，在 1 年后将对象转换到 S3 Glacier Deep Archive。",
      "B": "使用 S3 Intelligent-Tiering 存储类。 配置 S3 Intelligent-Tiering，在 1 年后自动将对象移动到 S3 Glacier Deep Archive。",
      "C": "使用 S3 Standard-Infrequent Access (S3 Standard-IA) 存储类。 创建一个 S3 生命周期策略，在 1 年后将对象转换到 S3 Glacier Deep Archive。",
      "D": "使用 S3 Standard 存储类。 创建一个 S3 生命周期策略，在 30 天后将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA)，然后在 1 年后转换为 S3 Glacier Deep Archive。"
    }
  },
  {
    "id": 374,
    "topic": "1",
    "question_en": "A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latency- sensitive application that runs in a single on-premises data center. A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness. Which solution meets these requirements?",
    "options_en": {
      "A": "Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.",
      "B": "Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.",
      "C": "Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.",
      "D": "Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 us-east-1 区域内的三个独立 VPC 中运行几个业务应用程序。这些应用程序必须能够在 VPC 之间通信。这些应用程序还必须能够每天将数百 GB 的数据一致地发送到在单个本地数据中心运行的延迟敏感型应用程序。一位解决方案架构师需要设计一个网络连接解决方案，以最大限度地提高成本效益。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "从数据中心配置三个 AWS Site-to-Site VPN 连接到 AWS。通过为每个 VPC 配置一个 VPN 连接来建立连接。",
      "B": "在每个 VPC 中启动一个第三方虚拟网络设备。在数据中心和每个虚拟设备之间建立一个 IPsec VPN 隧道。",
      "C": "从数据中心设置三个 AWS Direct Connect 连接到 us-east-1 中的 Direct Connect 网关。通过配置每个 VPC 使用一个 Direct Connect 连接来建立连接。",
      "D": "从数据中心设置一个 AWS Direct Connect 连接到 AWS。创建一个 Transit Gateway，并将每个 VPC 附加到 Transit Gateway。在 Direct Connect 连接和 Transit Gateway 之间建立连接。"
    }
  },
  {
    "id": 375,
    "topic": "1",
    "question_en": "An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete order- processing tasks. These tasks require manual approvals as part of the workfiow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Step Functions to build the application.",
      "B": "Integrate all the application components in an AWS Glue job.",
      "C": "Use Amazon Simple Queue Service (Amazon SQS) to build the application.",
      "D": "Use AWS Lambda functions and Amazon EventBridge events to build the application."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司正在构建一个分布式应用程序，该应用程序涉及多个无服务器函数和 AWS 服务来完成订单处理任务。这些任务需要手动批准作为工作流程的一部分。一位解决方案架构师需要为订单处理应用程序设计一个架构。该解决方案必须能够将多个 AWS Lambda 函数组合成响应迅速的无服务器应用程序。该解决方案还必须编排在 Amazon EC2 实例、容器或本地服务器上运行的数据和服务。哪种解决方案能够以最少的运营开销满足这些需求？",
    "options_cn": {
      "A": "使用 AWS Step Functions 构建应用程序。",
      "B": "将所有应用程序组件集成到 AWS Glue 作业中。",
      "C": "使用 Amazon Simple Queue Service (Amazon SQS) 构建应用程序。",
      "D": "使用 AWS Lambda 函数和 Amazon EventBridge 事件构建应用程序。"
    }
  },
  {
    "id": 376,
    "topic": "1",
    "question_en": "A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application trafic to the database changes significantly at random intervals. At times of high demand, users report that their applications experience database connection rejection errors. Which solution will resolve this issue with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.",
      "B": "Deploy Amazon ElastiCache for Memcached between the users’ applications and the DB instance.",
      "C": "Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users’ applications to use the new DB instance.",
      "D": "Configure Multi-AZ for the DB instance. Configure the users’ applications to switch between the DB instances."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司启动了一个 Amazon RDS for MySQL 数据库实例。大多数与数据库的连接来自无服务器应用程序。对数据库的应用程序流量会以随机间隔发生显著变化。在高需求时，用户报告他们的应用程序遇到数据库连接被拒绝的错误。哪种解决方案将以最少的运营开销解决此问题？",
    "options_cn": {
      "A": "在 RDS Proxy 中创建一个代理。将用户应用程序配置为通过 RDS Proxy 使用数据库实例。",
      "B": "在用户应用程序和数据库实例之间部署 Amazon ElastiCache for Memcached。",
      "C": "将数据库实例迁移到具有更高 I/O 容量的不同实例类型。将用户应用程序配置为使用新的数据库实例。",
      "D": "为数据库实例配置多可用区。将用户应用程序配置为在数据库实例之间切换。"
    }
  },
  {
    "id": 377,
    "topic": "1",
    "question_en": "A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST eficiently?",
    "options_en": {
      "A": "Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.",
      "B": "Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.",
      "C": "Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.",
      "D": "Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司最近部署了一个新的审计系统，用于集中收集有关 Amazon EC2 实例的操作系统版本、补丁和已安装软件的信息。解决方案架构师必须确保通过 EC2 Auto Scaling 组预置的所有实例在启动和终止后立即将报告成功发送到审计系统。哪种解决方案最有效地实现了这些目标？",
    "options_cn": {
      "A": "使用一个定期的 AWS Lambda 函数，并在所有 EC2 实例上远程运行一个脚本，以将数据发送到审计系统。",
      "B": "使用 EC2 Auto Scaling 生命周期钩子来运行自定义脚本，以便在实例启动和终止时将数据发送到审计系统。",
      "C": "使用 EC2 Auto Scaling 启动配置，通过用户数据运行自定义脚本，以便在实例启动和终止时将数据发送到审计系统。",
      "D": "在实例操作系统上运行自定义脚本，以将数据发送到审计系统。配置该脚本，以便在实例启动和终止时由 EC2 Auto Scaling 组调用。"
    }
  },
  {
    "id": 378,
    "topic": "1",
    "question_en": "A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solutions architect recommend?",
    "options_en": {
      "A": "Use Amazon Route 53 for trafic distribution and Amazon Aurora Serverless for data storage.",
      "B": "Use a Network Load Balancer for trafic distribution and Amazon DynamoDB on-demand for data storage.",
      "C": "Use a Network Load Balancer for trafic distribution and Amazon Aurora Global Database for data storage.",
      "D": "Use an Application Load Balancer for trafic distribution and Amazon DynamoDB global tables for data storage."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在开发一款实时多人游戏，该游戏使用 UDP 在 Auto Scaling 组中的客户端和服务器之间进行通信。预计白天会有需求高峰，因此游戏服务器平台必须相应地进行调整。开发人员希望将玩家分数和其他非关系型数据存储在无需干预即可扩展的数据库解决方案中。解决方案架构师应该推荐哪种解决方案？",
    "options_cn": {
      "A": "使用 Amazon Route 53 进行流量分配，并使用 Amazon Aurora Serverless 进行数据存储。",
      "B": "使用 Network Load Balancer 进行流量分配，并使用 Amazon DynamoDB 按需容量模式进行数据存储。",
      "C": "使用 Network Load Balancer 进行流量分配，并使用 Amazon Aurora Global Database 进行数据存储。",
      "D": "使用 Application Load Balancer 进行流量分配，并使用 Amazon DynamoDB 全局表进行数据存储。"
    }
  },
  {
    "id": 379,
    "topic": "1",
    "question_en": "A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations. Which solution will meet these requirements?",
    "options_en": {
      "A": "Establish a connection between the frontend application and the database to make queries faster by bypassing the API.",
      "B": "Configure provisioned concurrency for the Lambda function that handles the requests.",
      "C": "Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.",
      "D": "Increase the size of the database to increase the number of connections Lambda can establish at one time."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管一个前端应用程序，该应用程序使用与 AWS Lambda 集成的 Amazon API Gateway API 后端。 当 API 收到请求时，Lambda 函数会加载许多库。 然后，Lambda 函数连接到 Amazon RDS 数据库，处理数据，并将数据返回给前端应用程序。该公司希望确保所有用户的响应延迟尽可能低，同时对公司的运营变更最少。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在前端应用程序和数据库之间建立连接，通过绕过 API 来加快查询速度。",
      "B": "为处理请求的 Lambda 函数配置预置并发。",
      "C": "将查询结果缓存在 Amazon S3 中，以便更快地检索类似数据集。",
      "D": "增加数据库的大小，以增加 Lambda 可以一次建立的连接数。"
    }
  },
  {
    "id": 380,
    "topic": "1",
    "question_en": "A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance. Which solution will meet these requirements?",
    "options_en": {
      "A": "Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.",
      "B": "Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.",
      "C": "Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.",
      "D": "Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其本地工作负载迁移到 AWS 云。该公司已经使用了多个 Amazon EC2 实例和 Amazon RDS 数据库实例。该公司希望有一个解决方案，可以在非工作时间自动启动和停止 EC2 实例和数据库实例。该解决方案必须最大限度地降低成本并减少基础设施维护。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过使用弹性调整大小来扩展 EC2 实例。在非工作时间将数据库实例缩减到零。",
      "B": "在 AWS Marketplace 中探索合作伙伴解决方案，这些解决方案将按计划自动启动和停止 EC2 实例和数据库实例。",
      "C": "启动另一个 EC2 实例。配置一个 crontab 计划，以运行 shell 脚本，这些脚本将按计划启动和停止现有的 EC2 实例和数据库实例。",
      "D": "创建一个 AWS Lambda 函数，该函数将启动和停止 EC2 实例和数据库实例。配置 Amazon EventBridge 以按计划调用 Lambda 函数。"
    }
  },
  {
    "id": 381,
    "topic": "1",
    "question_en": "A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently. The reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process. Which solution will meet these requirements with the LEAST amount of change to the application code?",
    "options_en": {
      "A": "Set up a new Amazon DocumentDB (with MongoDB compatibility) cluster that includes a read replica. Scale the read replica to generate the reports.",
      "B": "Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.",
      "C": "Set up a new Amazon RDS for PostgreSQL Multi-AZ DB instance. Configure the reporting module to query the secondary RDS node so that the reporting module does not affect the primary node.",
      "D": "Set up a new Amazon DynamoDB table to store the documents. Use a fixed write capacity to support new document entries. Automatically scale the read capacity to support the reports."
    },
    "correct_answer": "D",
    "vote_percentage": "94%",
    "question_cn": "一家公司托管一个三层 Web 应用程序，该应用程序包括一个 PostgreSQL 数据库。该数据库存储文档的元数据。该公司搜索元数据中的关键术语，以检索该公司每月在报告中审查的文档。这些文档存储在 Amazon S3 中。这些文档通常只写入一次，但会经常更新。使用关系查询的报告过程需要几个小时。报告过程不得阻止任何文档修改或新文档的添加。解决方案架构师需要实施一个解决方案来加速报告过程。哪个解决方案将满足这些要求，并且对应用程序代码的更改最少？",
    "options_cn": {
      "A": "设置一个新的 Amazon DocumentDB（与 MongoDB 兼容）集群，其中包括一个只读副本。扩展只读副本以生成报告。",
      "B": "设置一个新的 Amazon Aurora PostgreSQL 数据库集群，其中包括一个 Aurora 副本。向 Aurora 副本发出查询以生成报告。",
      "C": "设置一个新的 Amazon RDS for PostgreSQL 多可用区数据库实例。将报告模块配置为查询辅助 RDS 节点，以便报告模块不影响主节点。",
      "D": "设置一个新的 Amazon DynamoDB 表来存储文档。使用固定的写入容量来支持新的文档条目。自动扩展读取容量以支持报告。"
    }
  },
  {
    "id": 382,
    "topic": "1",
    "question_en": "A company has a three-tier application on AWS that ingests sensor data from its users’ devices. The trafic fiows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database. What should a solutions architect do to improve the security of the data in transit?",
    "options_en": {
      "A": "Configure a TLS listener. Deploy the server certificate on the NLB.",
      "B": "Configure AWS Shield Advanced. Enable AWS WAF on the NLB.",
      "C": "Change the load balancer to an Application Load Balancer (ALB). Enable AWS WAF on the ALB.",
      "D": "Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances by using AWS Key Management Service (AWS KMS)."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上有一个三层应用程序，该应用程序从其用户的设备摄取传感器数据。流量通过 Network Load Balancer (NLB)，然后到用于 Web 层的 Amazon EC2 实例，最后到用于应用程序层的 EC2 实例。应用程序层调用一个数据库。解决方案架构师应该怎么做才能提高传输中数据的安全性？",
    "options_cn": {
      "A": "配置 TLS 监听器。 在 NLB 上部署服务器证书。",
      "B": "配置 AWS Shield Advanced。在 NLB 上启用 AWS WAF。",
      "C": "将负载均衡器更改为 Application Load Balancer (ALB)。在 ALB 上启用 AWS WAF。",
      "D": "使用 AWS Key Management Service (AWS KMS) 加密 EC2 实例上的 Amazon Elastic Block Store (Amazon EBS) 卷。"
    }
  },
  {
    "id": 383,
    "topic": "1",
    "question_en": "A company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year. Which Amazon EC2 pricing option is the MOST cost-effective?",
    "options_en": {
      "A": "Dedicated Reserved Hosts",
      "B": "Dedicated On-Demand Hosts",
      "C": "Dedicated Reserved Instances",
      "D": "Dedicated On-Demand Instances"
    },
    "correct_answer": "A",
    "vote_percentage": "89%",
    "question_cn": "一家公司计划将其商业现成的应用程序从其本地数据中心迁移到 AWS。该软件具有使用套接字和内核的软件许可模式，具有可预测的容量和正常运行时间要求。该公司希望使用其现有的许可证，这些许可证是今年早些时候购买的。哪种 Amazon EC2 定价选项最具成本效益？",
    "options_cn": {
      "A": "Dedicated Reserved Hosts",
      "B": "Dedicated On-Demand Hosts",
      "C": "Dedicated Reserved Instances",
      "D": "Dedicated On-Demand Instances"
    }
  },
  {
    "id": 384,
    "topic": "1",
    "question_en": "A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier.",
      "B": "Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA).",
      "C": "Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).",
      "D": "Use the Amazon Elastic File System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA)."
    },
    "correct_answer": "B",
    "vote_percentage": "93%",
    "question_cn": "一家公司在多个可用区运行 Amazon EC2 Linux 实例上的应用程序。该应用程序需要一个高可用性且符合可移植操作系统接口 (POSIX) 标准的存储层。该存储层必须提供最大的数据持久性，并且必须在 EC2 实例之间共享。存储层中的数据将在前 30 天内频繁访问，此后将不经常访问。哪种解决方案可以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 标准存储类。创建 S3 生命周期策略，将不经常访问的数据移动到 S3 Glacier。",
      "B": "使用 Amazon S3 标准存储类。创建 S3 生命周期策略，将不经常访问的数据移动到 S3 标准 - 不频繁访问 (S3 Standard-IA)。",
      "C": "使用 Amazon Elastic File System (Amazon EFS) 标准存储类。创建生命周期管理策略，将不经常访问的数据移动到 EFS 标准 - 不频繁访问 (EFS Standard-IA)。",
      "D": "使用 Amazon Elastic File System (Amazon EFS) 单区存储类。创建生命周期管理策略，将不经常访问的数据移动到 EFS 单区 - 不频繁访问 (EFS One Zone-IA)。"
    }
  },
  {
    "id": 385,
    "topic": "1",
    "question_en": "A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS. The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks. Which additional configuration strategy should the solutions architect use to meet these requirements?",
    "options_en": {
      "A": "Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.",
      "B": "Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.",
      "C": "Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.",
      "D": "Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在创建新的 VPC 设计。 有两个用于 Application Load Balancer 的公有子网，两个用于 Web 服务器的私有子网，以及两个用于 MySQL 的私有子网。 Web 服务器仅使用 HTTPS。 解决方案架构师已经为 Application Load Balancer 创建了一个安全组，允许来自 0.0.0.0/0 的 443 端口。 公司策略要求每个资源都具有完成其任务所需的最低访问权限。 解决方案架构师应该使用哪种额外的配置策略来满足这些要求？",
    "options_cn": {
      "A": "为 Web 服务器创建一个安全组，并允许来自 0.0.0.0/0 的 443 端口。 为 MySQL 服务器创建一个安全组，并允许来自 Web 服务器安全组的 3306 端口。",
      "B": "为 Web 服务器创建一个网络 ACL，并允许来自 0.0.0.0/0 的 443 端口。 为 MySQL 服务器创建一个网络 ACL，并允许来自 Web 服务器安全组的 3306 端口。",
      "C": "为 Web 服务器创建一个安全组，并允许来自 Application Load Balancer 的 443 端口。 为 MySQL 服务器创建一个安全组，并允许来自 Web 服务器安全组的 3306 端口。",
      "D": "为 Web 服务器创建一个网络 ACL，并允许来自 Application Load Balancer 的 443 端口。 为 MySQL 服务器创建一个网络 ACL，并允许来自 Web 服务器安全组的 3306 端口。"
    }
  },
  {
    "id": 386,
    "topic": "1",
    "question_en": "An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?",
    "options_en": {
      "A": "Implement Amazon SNS to store the database calls.",
      "B": "Implement Amazon ElastiCache to cache the large datasets.",
      "C": "Implement an RDS for MySQL read replica to cache database calls.",
      "D": "Implement Amazon Kinesis Data Firehose to stream the calls to the database."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司正在 AWS 上运行一个多层应用程序。前端和后端层都在 Amazon EC2 上运行，数据库在 Amazon RDS for MySQL 上运行。后端层与 RDS 实例通信。经常调用从数据库返回相同的数据集，导致性能下降。应采取什么行动来提高后端的性能？",
    "options_cn": {
      "A": "实施 Amazon SNS 来存储数据库调用。",
      "B": "实施 Amazon ElastiCache 来缓存大型数据集。",
      "C": "实施 RDS for MySQL 只读副本以缓存数据库调用。",
      "D": "实施 Amazon Kinesis Data Firehose 将调用流式传输到数据库。"
    }
  },
  {
    "id": 387,
    "topic": "1",
    "question_en": "A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)",
    "options_en": {
      "A": "Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.",
      "B": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.",
      "C": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached.",
      "D": "Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only",
      "E": "Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一位新员工作为部署工程师加入了公司。部署工程师将使用 AWS CloudFormation 模板来创建多个 AWS 资源。一位解决方案架构师希望部署工程师在执行工作活动时遵循最小权限原则。解决方案架构师应采取哪些组合措施来完成此目标？（选择两个。）",
    "options_cn": {
      "A": "让部署工程师使用 AWS 账户根用户凭证来执行 AWS CloudFormation 堆栈操作。",
      "B": "为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到附加了 PowerUsers IAM 策略的组中。",
      "C": "为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到附加了 AdministratorAccess IAM 策略的组中。",
      "D": "为部署工程师创建一个新的 IAM 用户，并将该 IAM 用户添加到具有仅允许 AWS CloudFormation 操作的 IAM 策略的组中。",
      "E": "为部署工程师创建一个 IAM 角色，以明确定义特定于 AWS CloudFormation 堆栈的权限，并使用该 IAM 角色启动堆栈。"
    }
  },
  {
    "id": 388,
    "topic": "1",
    "question_en": "A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information. The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states. What should a solutions architect recommend to fix the application?",
    "options_en": {
      "A": "Add an explicit rule to the private subnet’s network ACL to allow trafic from the web tier’s EC2 instances.",
      "B": "Add a route in the VPC route table to allow trafic between the web tier’s EC2 instances and the database tier.",
      "C": "Deploy the web tier's EC2 instances and the database tier’s RDS instance into two separate VPCs, and configure VPC peering.",
      "D": "Add an inbound rule to the security group of the database tier’s RDS instance to allow trafic from the web tiers security group."
    },
    "correct_answer": "D",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在 VPC 中部署一个两层 Web 应用程序。Web 层使用一个 Amazon EC2 Auto Scaling 组，该组具有跨多个可用区的公共子网。数据库层由一个位于单独私有子网中的 Amazon RDS for MySQL 数据库实例组成。Web 层需要访问数据库以检索产品信息。Web 应用程序没有按预期工作。Web 应用程序报告它无法连接到数据库。已确认数据库已启动并正在运行。网络 ACL、安全组和路由表的所有配置仍处于其默认状态。解决方案架构师应该建议采取什么措施来修复应用程序？",
    "options_cn": {
      "A": "将一个明确的规则添加到私有子网的网络 ACL 中，以允许来自 Web 层 EC2 实例的流量。",
      "B": "在 VPC 路由表中添加一条路由，以允许 Web 层的 EC2 实例和数据库层之间的流量。",
      "C": "将 Web 层的 EC2 实例和数据库层的 RDS 实例部署到两个单独的 VPC 中，并配置 VPC 对等连接。",
      "D": "将一条入站规则添加到数据库层 RDS 实例的安全组中，以允许来自 Web 层安全组的流量。"
    }
  },
  {
    "id": 389,
    "topic": "1",
    "question_en": "A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance. Which solution meets these requirements?",
    "options_en": {
      "A": "Deploy RDS read replicas to process the business reporting queries.",
      "B": "Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer.",
      "C": "Scale up the DB instance to a larger instance type to handle write operations and queries.",
      "D": "Deploy the DB instance in multiple Availability Zones to process the business reporting queries."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个大型数据集，用于其在线广告业务，该数据集存储在单个可用区中的 Amazon RDS for MySQL 数据库实例中。该公司希望业务报告查询在不影响对生产数据库实例的写入操作的情况下运行。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "部署 RDS 读取副本以处理业务报告查询。",
      "B": "通过将数据库实例置于 Elastic Load Balancer 之后来横向扩展数据库实例。",
      "C": "将数据库实例扩展到更大的实例类型以处理写入操作和查询。",
      "D": "在多个可用区中部署数据库实例以处理业务报告查询。"
    }
  },
  {
    "id": 390,
    "topic": "1",
    "question_en": "A company hosts a three-tier ecommerce application on a fieet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance. The company wants to optimize customer session management during transactions. The application must store session data durably. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Turn on the sticky sessions feature (session afinity) on the ALB.",
      "B": "Use an Amazon DynamoDB table to store customer session information.",
      "C": "Deploy an Amazon Cognito user pool to manage user session information.",
      "D": "Deploy an Amazon ElastiCache for Redis cluster to store customer session information",
      "E": "Use AWS Systems Manager Application Manager in the application to manage user session information."
    },
    "correct_answer": "B",
    "vote_percentage": "44%",
    "question_cn": "一家公司在其 Amazon EC2 实例集群上托管一个三层电子商务应用程序。这些实例在 Application Load Balancer (ALB) 之后，运行在一个 Auto Scaling 组中。所有电子商务数据都存储在 Amazon RDS for MariaDB Multi-AZ 数据库实例中。该公司希望在交易期间优化客户会话管理。该应用程序必须持久地存储会话数据。哪些解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 ALB 上打开粘性会话功能（会话亲和性）。",
      "B": "使用 Amazon DynamoDB 表来存储客户会话信息。",
      "C": "部署一个 Amazon Cognito 用户池来管理用户会话信息。",
      "D": "部署一个 Amazon ElastiCache for Redis 集群来存储客户会话信息。",
      "E": "在应用程序中使用 AWS Systems Manager Application Manager 来管理用户会话信息。"
    }
  },
  {
    "id": 391,
    "topic": "1",
    "question_en": "A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours. The backup strategy must maximize scalability and optimize resource utilization for this environment. Which solution will meet these requirements?",
    "options_en": {
      "A": "Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.",
      "B": "Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.",
      "C": "Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.",
      "D": "Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO."
    },
    "correct_answer": "D",
    "vote_percentage": "87%",
    "question_cn": "一家公司需要为其三层无状态 Web 应用程序制定备份策略。该 Web 应用程序在 Auto Scaling 组中的 Amazon EC2 实例上运行，该组具有动态伸缩策略，该策略配置为响应伸缩事件。数据库层在 Amazon RDS for PostgreSQL 上运行。Web 应用程序不需要在 EC2 实例上使用临时本地存储。该公司的恢复点目标 (RPO) 为 2 小时。备份策略必须最大程度地提高可伸缩性并优化此环境的资源利用率。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "每 2 小时拍摄 EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷和数据库的快照，以满足 RPO。",
      "B": "配置快照生命周期策略以拍摄 Amazon Elastic Block Store (Amazon EBS) 快照。在 Amazon RDS 中启用自动备份以满足 RPO。",
      "C": "保留 Web 和应用程序层的最新 Amazon Machine Images (AMI)。在 Amazon RDS 中启用自动备份并使用时间点恢复以满足 RPO。",
      "D": "每 2 小时拍摄 EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷的快照。在 Amazon RDS 中启用自动备份并使用时间点恢复以满足 RPO。"
    }
  },
  {
    "id": 392,
    "topic": "1",
    "question_en": "A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements?",
    "options_en": {
      "A": "Configure the security group for the web servers to allow inbound trafic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound trafic on port 3306 from the security group of the web servers.",
      "B": "Configure the security group for the web servers to allow inbound trafic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound trafic on port 3306 from the security group of the web servers.",
      "C": "Configure the security group for the web servers to allow inbound trafic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound trafic on port 3306 from the IP addresses of the customers.",
      "D": "Configure the security group for the web servers to allow inbound trafic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound trafic on port 3306 from 0.0.0.0/0."
    },
    "correct_answer": "A",
    "vote_percentage": "83%",
    "question_cn": "一家公司希望在 AWS 上部署一个新的公共 Web 应用程序。该应用程序包含一个使用 Amazon EC2 实例的 Web 服务器层。该应用程序还包含一个使用 Amazon RDS for MySQL 数据库实例的数据库层。该应用程序必须安全且可供具有动态 IP 地址的全球客户访问。解决方案架构师应如何配置安全组以满足这些要求？",
    "options_cn": {
      "A": "配置 Web 服务器的安全组，允许从 0.0.0.0/0 上的端口 443 传入流量。配置数据库实例的安全组，允许从 Web 服务器的安全组上的端口 3306 传入流量。",
      "B": "配置 Web 服务器的安全组，允许从客户的 IP 地址上的端口 443 传入流量。配置数据库实例的安全组，允许从 Web 服务器的安全组上的端口 3306 传入流量。",
      "C": "配置 Web 服务器的安全组，允许从客户的 IP 地址上的端口 443 传入流量。配置数据库实例的安全组，允许从客户的 IP 地址上的端口 3306 传入流量。",
      "D": "配置 Web 服务器的安全组，允许从 0.0.0.0/0 上的端口 443 传入流量。配置数据库实例的安全组，允许从 0.0.0.0/0 上的端口 3306 传入流量。"
    }
  },
  {
    "id": 393,
    "topic": "1",
    "question_en": "A payment processing company records all voice communication with its customers and stores the audio files in an Amazon S3 bucket. The company needs to capture the text from the audio files. The company must remove from the text any personally identifiable information (PII) that belongs to customers. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Process the audio files by using Amazon Kinesis Video Streams. Use an AWS Lambda function to scan for known PII patterns.",
      "B": "When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start an Amazon Textract task to analyze the call recordings.",
      "C": "Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.",
      "D": "Create an Amazon Connect contact fiow that ingests the audio files with transcription turned on. Embed an AWS Lambda function to scan for known PII patterns. Use Amazon EventBridge to start the contact fiow when an audio file is uploaded to the S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家支付处理公司会记录其与客户的所有语音通信，并将音频文件存储在 Amazon S3 存储桶中。该公司需要从音频文件中提取文本。该公司必须从文本中删除属于客户的任何个人身份信息 (PII)。解决方案架构师应如何满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Kinesis Video Streams 处理音频文件。使用 AWS Lambda 函数扫描已知的 PII 模式。",
      "B": "当音频文件上传到 S3 存储桶时，调用 AWS Lambda 函数以启动 Amazon Textract 任务来分析通话录音。",
      "C": "配置 Amazon Transcribe 转录作业，并打开 PII 隐藏。当音频文件上传到 S3 存储桶时，调用 AWS Lambda 函数以启动转录作业。将输出存储在单独的 S3 存储桶中。",
      "D": "创建一个 Amazon Connect 联系流程，该流程通过转录来摄取音频文件。嵌入一个 AWS Lambda 函数来扫描已知的 PII 模式。当音频文件上传到 S3 存储桶时，使用 Amazon EventBridge 启动联系流程。"
    }
  },
  {
    "id": 394,
    "topic": "1",
    "question_en": "A company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand. A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of read and write IOPS is higher than 20,000. What should a solutions architect do to improve the application performance?",
    "options_en": {
      "A": "Replace the volume with a magnetic volume.",
      "B": "Increase the number of IOPS on the gp3 volume.",
      "C": "Replace the volume with a Provisioned IOPS SSD (io2) volume.",
      "D": "Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes."
    },
    "correct_answer": "C",
    "vote_percentage": "40%",
    "question_cn": "一家公司在 AWS 云中运行多层电商 Web 应用程序。该应用程序运行在 Amazon EC2 实例上，并带有 Amazon RDS for MySQL Multi-AZ DB 实例。Amazon RDS 配置了最新一代的数据库实例，该实例具有 2,000 GB 的存储空间，位于通用 SSD (gp3) Amazon Elastic Block Store (Amazon EBS) 卷中。在需求量大的时期，数据库性能会影响应用程序。数据库管理员在 Amazon CloudWatch Logs 中分析日志，发现当读写 IOPS 数量高于 20,000 时，应用程序性能总会下降。解决方案架构师应该怎么做来提高应用程序性能？",
    "options_cn": {
      "A": "用磁性卷替换该卷。",
      "B": "增加 gp3 卷上的 IOPS 数量。",
      "C": "用预置 IOPS SSD (io2) 卷替换该卷。",
      "D": "用两个 1,000 GB 的 gp3 卷替换 2,000 GB 的 gp3 卷。"
    }
  },
  {
    "id": 395,
    "topic": "1",
    "question_en": "An IAM user made several configuration changes to AWS resources in their company's account during a production deployment last week. A solutions architect learned that a couple of security group rules are not configured as desired. The solutions architect wants to confirm which IAM user was responsible for making changes. Which service should the solutions architect use to find the desired information?",
    "options_en": {
      "A": "Amazon GuardDuty",
      "B": "Amazon Inspector",
      "C": "AWS CloudTrail",
      "D": "AWS Config"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一名 IAM 用户在上周的生产部署期间对其公司的账户中的 AWS 资源进行了一些配置更改。一位解决方案架构师了解到，几个安全组规则未按预期配置。解决方案架构师希望确认是哪个 IAM 用户负责进行更改。解决方案架构师应该使用哪项服务来查找所需信息？",
    "options_cn": {
      "A": "Amazon GuardDuty",
      "B": "Amazon Inspector",
      "C": "AWS CloudTrail",
      "D": "AWS Config"
    }
  },
  {
    "id": 396,
    "topic": "1",
    "question_en": "A company has implemented a self-managed DNS service on AWS. The solution consists of the following: • Amazon EC2 instances in different AWS Regions • Endpoints of a standard accelerator in AWS Global Accelerator The company wants to protect the solution against DDoS attacks. What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.",
      "B": "Subscribe to AWS Shield Advanced. Add the EC2 instances as resources to protect.",
      "C": "Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the accelerator.",
      "D": "Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "一家公司已在 AWS 上实施了自管理 DNS 服务。 解决方案包括以下内容：\n\n- 不同 AWS 区域中的 Amazon EC2 实例\n- AWS Global Accelerator 中标准加速器的端点\n\n该公司希望保护其解决方案免受 DDoS 攻击。 解决方案架构师应采取什么措施来满足此要求？",
    "options_cn": {
      "A": "订阅 AWS Shield Advanced。将加速器添加为要保护的资源。",
      "B": "订阅 AWS Shield Advanced。将 EC2 实例添加为要保护的资源。",
      "C": "创建一个包含基于速率规则的 AWS WAF Web ACL。将 Web ACL 与加速器关联。",
      "D": "创建一个包含基于速率规则的 AWS WAF Web ACL。将 Web ACL 与 EC2 实例关联。"
    }
  },
  {
    "id": 397,
    "topic": "1",
    "question_en": "An ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance. A solutions architect needs to minimize the amount of operational effort that is needed for the job to run. Which solution meets these requirements?",
    "options_en": {
      "A": "Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day.",
      "B": "Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function.",
      "C": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.",
      "D": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司需要运行一个每日计划任务，以聚合和过滤销售记录进行分析。该公司将销售记录存储在 Amazon S3 存储桶中。每个对象的大小最大为 10 GB。根据销售事件的数量，该作业可能需要长达一个小时才能完成。该作业的 CPU 和内存使用率是恒定的，并且提前已知。一个解决方案架构师需要最大限度地减少运行该作业所需的运营工作量。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，该函数具有 Amazon EventBridge 通知。将 EventBridge 事件计划为每天运行一次。",
      "B": "创建一个 AWS Lambda 函数。创建一个 Amazon API Gateway HTTP API，并将该 API 与该函数集成。创建一个 Amazon EventBridge 计划事件，该事件调用 API 并调用该函数。",
      "C": "创建一个具有 AWS Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群。创建一个 Amazon EventBridge 计划事件，该事件在集群上启动一个 ECS 任务来运行该作业。",
      "D": "创建一个具有 Amazon EC2 启动类型和具有至少一个 EC2 实例的 Auto Scaling 组的 Amazon Elastic Container Service (Amazon ECS) 集群。创建一个 Amazon EventBridge 计划事件，该事件在集群上启动一个 ECS 任务来运行该作业。"
    }
  },
  {
    "id": 398,
    "topic": "1",
    "question_en": "A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company’s internet connection can support an upload speed of 100 Mbps. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use Amazon S3 multi-part upload functionality to transfer the files over HTTPS.",
      "B": "Create a VPN connection between the on-premises NAS system and the nearest AWS Region. Transfer the data over the VPN connection.",
      "C": "Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.",
      "D": "Set up a 10 Gbps AWS Direct Connect connection between the company location and the nearest AWS Region. Transfer the data over a VPN connection into the Region to store the data in Amazon S3."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要将其本地网络附加存储 (NAS) 系统中的 600 TB 数据传输到 AWS 云。数据传输必须在 2 周内完成。数据是敏感的，并且必须在传输过程中加密。该公司的互联网连接可以支持 100 Mbps 的上传速度。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 多部分上传功能通过 HTTPS 传输文件。",
      "B": "在本地 NAS 系统和最近的 AWS 区域之间创建 VPN 连接。通过 VPN 连接传输数据。",
      "C": "使用 AWS Snow Family 控制台订购多个 AWS Snowball Edge 存储优化设备。使用这些设备将数据传输到 Amazon S3。",
      "D": "在公司所在地和最近的 AWS 区域之间设置 10 Gbps 的 AWS Direct Connect 连接。通过 VPN 连接将数据传输到该区域，以将数据存储在 Amazon S3 中。"
    }
  },
  {
    "id": 399,
    "topic": "1",
    "question_en": "A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company’s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP fiood attacks might take the application ofiine. A solutions architect must design a solution to protect the application from this type of attack. Which solution meets these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.",
      "B": "Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.",
      "C": "Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.",
      "D": "Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家金融公司在 AWS 上托管一个 Web 应用程序。该应用程序使用 Amazon API Gateway Regional API 终端节点，使用户能够检索当前的股票价格。该公司的安全团队注意到 API 请求数量有所增加。安全团队担心 HTTP 泛洪攻击可能会导致应用程序离线。解决方案架构师必须设计一个解决方案来保护应用程序免受此类攻击。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 API Gateway Regional API 终端节点前创建一个 Amazon CloudFront 分配，最大 TTL 为 24 小时。",
      "B": "创建一个 Regional AWS WAF Web ACL，其中包含基于速率的规则。将 Web ACL 与 API Gateway 阶段关联。",
      "C": "使用 Amazon CloudWatch 指标来监视 Count 指标，并在达到预定义速率时提醒安全团队。",
      "D": "在 API Gateway Regional API 终端节点前创建一个带有 Lambda@Edge 的 Amazon CloudFront 分配。创建一个 AWS Lambda 函数以阻止来自超出预定义速率的 IP 地址的请求。"
    }
  },
  {
    "id": 400,
    "topic": "1",
    "question_en": "A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application. What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.",
      "B": "Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.",
      "C": "Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.",
      "D": "Add a custom attribute to each record to fiag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家气象初创公司拥有一款自定义 Web 应用程序，用于在线向其用户销售天气数据。该公司使用 Amazon DynamoDB 存储其数据，并希望构建一项新服务，以便在每次记录新的天气事件时向四个内部团队的经理发送警报。该公司不希望这项新服务影响当前应用程序的性能。解决方案架构师应该怎么做才能以最少的运营开销来满足这些要求？",
    "options_cn": {
      "A": "使用 DynamoDB 事务将新的事件数据写入表。配置事务以通知内部团队。",
      "B": "让当前应用程序向四个 Amazon Simple Notification Service (Amazon SNS) 主题发布消息。让每个团队订阅一个主题。",
      "C": "在表上启用 Amazon DynamoDB Streams。使用触发器写入单个 Amazon Simple Notification Service (Amazon SNS) 主题，团队可以订阅该主题。",
      "D": "为每条记录添加一个自定义属性来标记新项目。编写一个 cron 作业，每分钟扫描一次表以查找新项目，并通知一个 Amazon Simple Queue Service (Amazon SQS) 队列，团队可以订阅该队列。"
    }
  },
  {
    "id": 401,
    "topic": "1",
    "question_en": "A company wants to use the AWS Cloud to make an existing application highly available and resilient. The current version of the application resides in the company's data center. The application recently experienced data loss after a database server crashed because of an unexpected power outage. The company needs a solution that avoids any single points of failure. The solution must give the application the ability to scale to meet user demand. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon RDS DB instance in a Multi-AZ configuration.",
      "B": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group in a single Availability Zone. Deploy the database on an EC2 instance. Enable EC2 Auto Recovery.",
      "C": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon RDS DB instance with a read replica in a single Availability Zone. Promote the read replica to replace the primary DB instance if the primary DB instance fails.",
      "D": "Deploy the application servers by using Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Deploy the primary and secondary database servers on EC2 instances across multiple Availability Zones. Use Amazon Elastic Block Store (Amazon EBS) Multi-Attach to create shared storage between the instances."
    },
    "correct_answer": "A",
    "vote_percentage": "90%",
    "question_cn": "一家公司希望使用 AWS Cloud 来使现有应用程序具有高可用性和弹性。该应用程序的当前版本位于公司的数据中心中。由于意外停电，数据库服务器崩溃后，该应用程序最近发生了数据丢失。公司需要一个解决方案来避免任何单点故障。该解决方案必须使应用程序能够扩展以满足用户需求。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过在多个可用区中使用 Auto Scaling 组中的 Amazon EC2 实例来部署应用程序服务器。 在 Multi-AZ 配置中使用 Amazon RDS DB 实例。",
      "B": "通过在单个可用区中使用 Auto Scaling 组中的 Amazon EC2 实例来部署应用程序服务器。在 EC2 实例上部署数据库。启用 EC2 自动恢复。",
      "C": "通过在多个可用区中使用 Auto Scaling 组中的 Amazon EC2 实例来部署应用程序服务器。 使用在单个可用区中具有只读副本的 Amazon RDS DB 实例。如果主数据库实例发生故障，将只读副本提升以替换主数据库实例。",
      "D": "通过在多个可用区中使用 Auto Scaling 组中的 Amazon EC2 实例来部署应用程序服务器。在跨多个可用区的 EC2 实例上部署主数据库和辅助数据库服务器。使用 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 在实例之间创建共享存储。"
    }
  },
  {
    "id": 402,
    "topic": "1",
    "question_en": "A company needs to ingest and handle large amounts of streaming data that its application generates. The application runs on Amazon EC2 instances and sends data to Amazon Kinesis Data Streams, which is configured with default settings. Every other day, the application consumes the data and writes the data to an Amazon S3 bucket for business intelligence (BI) processing. The company observes that Amazon S3 is not receiving all the data that the application sends to Kinesis Data Streams. What should a solutions architect do to resolve this issue?",
    "options_en": {
      "A": "Update the Kinesis Data Streams default settings by modifying the data retention period.",
      "B": "Update the application to use the Kinesis Producer Library (KPL) to send the data to Kinesis Data Streams.",
      "C": "Update the number of Kinesis shards to handle the throughput of the data that is sent to Kinesis Data Streams.",
      "D": "Turn on S3 Versioning within the S3 bucket to preserve every version of every object that is ingested in the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "64%",
    "question_cn": "一家公司需要摄取和处理其应用程序生成的大量流数据。该应用程序运行在 Amazon EC2 实例上，并将数据发送到 Amazon Kinesis Data Streams，后者配置了默认设置。每隔一天，应用程序就会使用数据，并将数据写入 Amazon S3 存储桶以进行商业智能 (BI) 处理。该公司观察到 Amazon S3 没有收到应用程序发送到 Kinesis Data Streams 的所有数据。解决方案架构师应该怎么做才能解决这个问题？",
    "options_cn": {
      "A": "通过修改数据保留期来更新 Kinesis Data Streams 默认设置。",
      "B": "更新应用程序以使用 Kinesis Producer Library (KPL) 将数据发送到 Kinesis Data Streams。",
      "C": "更新 Kinesis 分片的数量，以处理发送到 Kinesis Data Streams 的数据吞吐量。",
      "D": "在 S3 存储桶中打开 S3 版本控制，以保留摄取到 S3 存储桶中的每个对象的每个版本。"
    }
  },
  {
    "id": 403,
    "topic": "1",
    "question_en": "A developer has an application that uses an AWS Lambda function to upload files to Amazon S3 and needs the required permissions to perform the task. The developer already has an IAM user with valid IAM credentials required for Amazon S3. What should a solutions architect do to grant the permissions?",
    "options_en": {
      "A": "Add required IAM permissions in the resource policy of the Lambda function.",
      "B": "Create a signed request using the existing IAM credentials in the Lambda function.",
      "C": "Create a new IAM user and use the existing IAM credentials in the Lambda function.",
      "D": "Create an IAM execution role with the required permissions and attach the IAM role to the Lambda function."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "开发人员有一个应用程序，该应用程序使用 AWS Lambda 函数将文件上传到 Amazon S3，并且需要执行此任务所需的权限。开发人员已经拥有一个 IAM 用户，该用户具有 Amazon S3 所需的有效 IAM 凭证。解决方案架构师应该怎么做才能授予权限？",
    "options_cn": {
      "A": "在 Lambda 函数的资源策略中添加所需的 IAM 权限。",
      "B": "使用 Lambda 函数中现有的 IAM 凭证创建签名请求。",
      "C": "创建一个新的 IAM 用户，并在 Lambda 函数中使用现有的 IAM 凭证。",
      "D": "创建一个具有所需权限的 IAM 执行角色，并将该 IAM 角色附加到 Lambda 函数。"
    }
  },
  {
    "id": 404,
    "topic": "1",
    "question_en": "A company has deployed a serverless application that invokes an AWS Lambda function when new documents are uploaded to an Amazon S3 bucket. The application uses the Lambda function to process the documents. After a recent marketing campaign, the company noticed that the application did not process many of the documents. What should a solutions architect do to improve the architecture of this application?",
    "options_en": {
      "A": "Set the Lambda function's runtime timeout value to 15 minutes.",
      "B": "Configure an S3 bucket replication policy. Stage the documents in the S3 bucket for later processing.",
      "C": "Deploy an additional Lambda function. Load balance the processing of the documents across the two Lambda functions.",
      "D": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Send the requests to the queue. Configure the queue as an event source for Lambda."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司部署了一个无服务器应用程序，当新文档上传到 Amazon S3 存储桶时，该应用程序会调用一个 AWS Lambda 函数。该应用程序使用 Lambda 函数来处理这些文档。在最近的市场营销活动之后，该公司注意到该应用程序没有处理许多文档。解决方案架构师应该怎么做才能改进此应用程序的架构？",
    "options_cn": {
      "A": "将 Lambda 函数的运行时超时值设置为 15 分钟。",
      "B": "配置一个 S3 存储桶复制策略。将文档分阶段存储在 S3 存储桶中，以便稍后处理。",
      "C": "部署一个额外的 Lambda 函数。在两个 Lambda 函数之间负载均衡处理文档。",
      "D": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将请求发送到队列。将队列配置为 Lambda 的事件源。"
    }
  },
  {
    "id": 405,
    "topic": "1",
    "question_en": "A solutions architect is designing the architecture for a software demonstration environment. The environment will run on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). The system will experience significant increases in trafic during working hours but is not required to operate on weekends. Which combination of actions should the solutions architect take to ensure that the system can scale to meet demand? (Choose two.)",
    "options_en": {
      "A": "Use AWS Auto Scaling to adjust the ALB capacity based on request rate.",
      "B": "Use AWS Auto Scaling to scale the capacity of the VPC internet gateway.",
      "C": "Launch the EC2 instances in multiple AWS Regions to distribute the load across Regions.",
      "D": "Use a target tracking scaling policy to scale the Auto Scaling group based on instance CPU utilization",
      "E": "Use scheduled scaling to change the Auto Scaling group minimum, maximum, and desired capacity to zero for weekends. Revert to the default values at the start of the week."
    },
    "correct_answer": "D",
    "vote_percentage": "18%",
    "question_cn": "一位解决方案架构师正在为软件演示环境设计架构。 该环境将在位于 Application Load Balancer (ALB) 之后，Auto Scaling 组中的 Amazon EC2 实例上运行。 该系统在工作时间会经历流量的大幅增加，但不需要在周末运行。 解决方案架构师应采取哪些组合措施来确保系统能够扩展以满足需求？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Auto Scaling 根据请求速率调整 ALB 容量。",
      "B": "使用 AWS Auto Scaling 来扩展 VPC 互联网网关的容量。",
      "C": "在多个 AWS 区域中启动 EC2 实例，以跨区域分配负载。",
      "D": "使用目标跟踪扩展策略，根据实例的 CPU 利用率来扩展 Auto Scaling 组。",
      "E": "使用计划扩展将 Auto Scaling 组的最小、最大和所需容量设置为周末的零。 在一周开始时恢复为默认值。"
    }
  },
  {
    "id": 406,
    "topic": "1",
    "question_en": "A solutions architect is designing a two-tiered architecture that includes a public subnet and a database subnet. The web servers in the public subnet must be open to the internet on port 443. The Amazon RDS for MySQL DB instance in the database subnet must be accessible only to the web servers on port 3306. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create a network ACL for the public subnet. Add a rule to deny outbound trafic to 0.0.0.0/0 on port 3306.",
      "B": "Create a security group for the DB instance. Add a rule to allow trafic from the public subnet CIDR block on port 3306.",
      "C": "Create a security group for the web servers in the public subnet. Add a rule to allow trafic from 0.0.0.0/0 on port 443.",
      "D": "Create a security group for the DB instanc",
      "E": "Add a rule to allow trafic from the web servers’ security group on port 3306. E. Create a security group for the DB instance. Add a rule to deny all trafic except trafic from the web servers’ security group on port 3306."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在设计一个两层架构，其中包括一个公有子网和一个数据库子网。公有子网中的 Web 服务器必须在端口 443 上向互联网开放。数据库子网中的 Amazon RDS for MySQL DB 实例必须只能通过端口 3306 被 Web 服务器访问。解决方案架构师应采取哪些步骤组合来满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "为公有子网创建网络 ACL。添加一条规则，拒绝向 0.0.0.0/0 在端口 3306 上的出站流量。",
      "B": "为 DB 实例创建安全组。添加一条规则，允许来自公有子网 CIDR 块在端口 3306 上的流量。",
      "C": "为公有子网中的 Web 服务器创建安全组。添加一条规则，允许来自 0.0.0.0/0 在端口 443 上的流量。",
      "D": "为 DB 实例创建安全组。添加一条规则，允许来自 Web 服务器的安全组在端口 3306 上的流量。",
      "E": "为 DB 实例创建安全组。添加一条规则，拒绝所有流量，除了来自 Web 服务器的安全组在端口 3306 上的流量。"
    }
  },
  {
    "id": 407,
    "topic": "1",
    "question_en": "A company is implementing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use Lustre clients to access data. The solution must be fully managed. Which solution meets these requirements?",
    "options_en": {
      "A": "Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.",
      "B": "Create an AWS Storage Gateway file gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
      "C": "Create an Amazon Elastic File System (Amazon EFS) file system, and configure it to support Lustre. Attach the file system to the origin server. Connect the application server to the file system.",
      "D": "Create an Amazon FSx for Lustre file system. Attach the file system to the origin server. Connect the application server to the file system."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为其托管在 AWS 云中的游戏应用程序实施共享存储解决方案。该公司需要使用 Lustre 客户端访问数据的能力。该解决方案必须是完全托管的。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "创建一个 AWS DataSync 任务，将数据共享为可挂载的文件系统。将文件系统挂载到应用程序服务器。",
      "B": "创建一个 AWS Storage Gateway 文件网关。创建一个使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享。",
      "C": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统，并将其配置为支持 Lustre。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。",
      "D": "创建一个 Amazon FSx for Lustre 文件系统。将文件系统连接到源服务器。将应用程序服务器连接到文件系统。"
    }
  },
  {
    "id": 408,
    "topic": "1",
    "question_en": "A company runs an application that receives data from thousands of geographically dispersed remote devices that use UDP. The application processes the data immediately and sends a message back to the device if necessary. No data is stored. The company needs a solution that minimizes latency for the data transmission from the devices. The solution also must provide rapid failover to another AWS Region. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an Amazon Route 53 failover routing policy. Create a Network Load Balancer (NLB) in each of the two Regions. Configure the NLB to invoke an AWS Lambda function to process the data.",
      "B": "Use AWS Global Accelerator. Create a Network Load Balancer (NLB) in each of the two Regions as an endpoint. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the NLProcess the data in Amazon ECS.",
      "C": "Use AWS Global Accelerator. Create an Application Load Balancer (ALB) in each of the two Regions as an endpoint. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the ALB. Process the data in Amazon ECS.",
      "D": "Configure an Amazon Route 53 failover routing policy. Create an Application Load Balancer (ALB) in each of the two Regions. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the ALB. Process the data in Amazon ECS."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司运行一个应用程序，该应用程序从数千个使用 UDP 的地理位置分散的远程设备接收数据。应用程序立即处理数据，并在必要时向设备发送消息。不存储任何数据。该公司需要一个解决方案，以最大限度地减少从设备传输数据的延迟。该解决方案还必须提供到另一个 AWS 区域的快速故障转移。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Route 53 故障转移路由策略。在两个区域中的每一个中创建一个 Network Load Balancer (NLB)。配置 NLB 以调用 AWS Lambda 函数来处理数据。",
      "B": "使用 AWS Global Accelerator。在两个区域中的每一个中创建一个 Network Load Balancer (NLB) 作为端点。创建一个带有 Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群。在集群上创建一个 ECS 服务。将 ECS 服务设置为 NL 的目标。在 Amazon ECS 中处理数据。",
      "C": "使用 AWS Global Accelerator。在两个区域中的每一个中创建一个 Application Load Balancer (ALB) 作为端点。创建一个带有 Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群。在集群上创建一个 ECS 服务。将 ECS 服务设置为 ALB 的目标。在 Amazon ECS 中处理数据。",
      "D": "配置 Amazon Route 53 故障转移路由策略。在两个区域中的每一个中创建一个 Application Load Balancer (ALB)。创建一个带有 Fargate 启动类型的 Amazon Elastic Container Service (Amazon ECS) 集群。在集群上创建一个 ECS 服务。将 ECS 服务设置为 ALB 的目标。在 Amazon ECS 中处理数据。"
    }
  },
  {
    "id": 409,
    "topic": "1",
    "question_en": "A solutions architect must migrate a Windows Internet Information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user's on-premises network-attached storage (NAS). The solutions architect has proposed migrating the IIS web servers to Amazon EC2 instances in multiple Availability Zones that are connected to the storage solution, and configuring an Elastic Load Balancer attached to the instances. Which replacement to the on-premises file share is MOST resilient and durable?",
    "options_en": {
      "A": "Migrate the file share to Amazon RDS.",
      "B": "Migrate the file share to AWS Storage Gateway.",
      "C": "Migrate the file share to Amazon FSx for Windows File Server.",
      "D": "Migrate the file share to Amazon Elastic File System (Amazon EFS)."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "一个解决方案架构师必须将 Windows Internet Information Services (IIS) Web 应用程序迁移到 AWS。该应用程序当前依赖于用户本地网络附加存储 (NAS) 中托管的文件共享。解决方案架构师已建议将 IIS Web 服务器迁移到多个可用区中的 Amazon EC2 实例，这些实例连接到存储解决方案，并配置一个连接到这些实例的 Elastic Load Balancer。对本地文件共享的哪种替换方案的弹性和持久性最强？",
    "options_cn": {
      "A": "将文件共享迁移到 Amazon RDS。",
      "B": "将文件共享迁移到 AWS Storage Gateway。",
      "C": "将文件共享迁移到 Amazon FSx for Windows File Server。",
      "D": "将文件共享迁移到 Amazon Elastic File System (Amazon EFS)。"
    }
  },
  {
    "id": 410,
    "topic": "1",
    "question_en": "A company is deploying a new application on Amazon EC2 instances. The application writes data to Amazon Elastic Block Store (Amazon EBS) volumes. The company needs to ensure that all data that is written to the EBS volumes is encrypted at rest. Which solution will meet this requirement?",
    "options_en": {
      "A": "Create an IAM role that specifies EBS encryption. Attach the role to the EC2 instances.",
      "B": "Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the EC2 instances.",
      "C": "Create an EC2 instance tag that has a key of Encrypt and a value of True. Tag all instances that require encryption at the EBS level.",
      "D": "Create an AWS Key Management Service (AWS KMS) key policy that enforces EBS encryption in the account. Ensure that the key policy is active."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 Amazon EC2 实例上部署一个新的应用程序。该应用程序将数据写入 Amazon Elastic Block Store (Amazon EBS) 卷。公司需要确保写入 EBS 卷的所有数据在静态时都被加密。哪种解决方案将满足此要求？",
    "options_cn": {
      "A": "创建一个 IAM 角色，指定 EBS 加密。将该角色附加到 EC2 实例。",
      "B": "创建加密的 EBS 卷。将 EBS 卷附加到 EC2 实例。",
      "C": "创建一个 EC2 实例标签，其键为 Encrypt，值为 True。标记所有需要在 EBS 级别进行加密的实例。",
      "D": "创建一个 AWS Key Management Service (AWS KMS) 密钥策略，在账户中强制执行 EBS 加密。确保密钥策略处于活动状态。"
    }
  },
  {
    "id": 411,
    "topic": "1",
    "question_en": "A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?",
    "options_en": {
      "A": "Amazon DynamoDB",
      "B": "Amazon RDS for MySQL",
      "C": "MySQL-compatible Amazon Aurora Serverless",
      "D": "MySQL deployed on Amazon EC2 in an Auto Scaling group"
    },
    "correct_answer": "C",
    "vote_percentage": "89%",
    "question_cn": "一家公司有一个使用模式不固定的 Web 应用程序。每月月初会有大量使用，每周初会有适度使用，而一周内使用情况无法预测。该应用程序由一个 Web 服务器和一个在数据中心内运行的 MySQL 数据库服务器组成。该公司希望将应用程序迁移到 AWS 云，并且需要选择一个经济高效的数据库平台，该平台不需要修改数据库。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "Amazon DynamoDB",
      "B": "Amazon RDS for MySQL",
      "C": "MySQL 兼容的 Amazon Aurora Serverless",
      "D": "在 Amazon EC2 的 Auto Scaling 组中部署 MySQL"
    }
  },
  {
    "id": 412,
    "topic": "1",
    "question_en": "An image-hosting company stores its objects in Amazon S3 buckets. The company wants to avoid accidental exposure of the objects in the S3 buckets to the public. All S3 objects in the entire AWS account need to remain private. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon GuardDuty to monitor S3 bucket policies. Create an automatic remediation action rule that uses an AWS Lambda function to remediate any change that makes the objects public.",
      "B": "Use AWS Trusted Advisor to find publicly accessible S3 buckets. Configure email notifications in Trusted Advisor when a change is detected. Manually change the S3 bucket policy if it allows public access.",
      "C": "Use AWS Resource Access Manager to find publicly accessible S3 buckets. Use Amazon Simple Notification Service (Amazon SNS) to invoke an AWS Lambda function when a change is detected. Deploy a Lambda function that programmatically remediates the change.",
      "D": "Use the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account."
    },
    "correct_answer": "D",
    "vote_percentage": "94%",
    "question_cn": "一家图片托管公司将其对象存储在 Amazon S3 存储桶中。该公司希望避免 S3 存储桶中的对象意外向公众暴露。整个 AWS 账户中的所有 S3 对象都需要保持私有。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon GuardDuty 监控 S3 存储桶策略。创建自动修复操作规则，该规则使用 AWS Lambda 函数来修复任何使对象公开的更改。",
      "B": "使用 AWS Trusted Advisor 查找可公开访问的 S3 存储桶。在 Trusted Advisor 中配置电子邮件通知，以便在检测到更改时发送通知。如果 S3 存储桶策略允许公共访问，请手动更改该策略。",
      "C": "使用 AWS Resource Access Manager 查找可公开访问的 S3 存储桶。使用 Amazon Simple Notification Service (Amazon SNS) 在检测到更改时调用 AWS Lambda 函数。部署一个 Lambda 函数，以编程方式修复更改。",
      "D": "在账户级别使用 S3 阻止公共访问功能。使用 AWS Organizations 创建服务控制策略 (SCP)，以防止 IAM 用户更改该设置。将 SCP 应用于账户。"
    }
  },
  {
    "id": 413,
    "topic": "1",
    "question_en": "An ecommerce company is experiencing an increase in user trafic. The company’s store is deployed on Amazon EC2 instances as a two-tier web application consisting of a web tier and a separate database tier. As trafic increases, the company notices that the architecture is causing significant delays in sending timely marketing and order confirmation email to users. The company wants to reduce the time it spends resolving complex email delivery issues and minimize operational overhead. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a separate application tier using EC2 instances dedicated to email processing.",
      "B": "Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).",
      "C": "Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS).",
      "D": "Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个电商公司正在经历用户流量的增长。该公司的商店部署在 Amazon EC2 实例上，作为一个由 Web 层和一个单独的数据库层组成的双层 Web 应用程序。随着流量的增加，该公司注意到这种架构导致发送及时的营销和订单确认电子邮件给用户时出现显著的延迟。该公司希望减少解决复杂电子邮件传递问题所花费的时间，并最大限度地减少运营开销。解决方案架构师应采取什么措施来满足这些要求？",
    "options_cn": {
      "A": "使用专门用于电子邮件处理的 EC2 实例创建一个单独的应用程序层。",
      "B": "配置 Web 实例通过 Amazon Simple Email Service (Amazon SES) 发送电子邮件。",
      "C": "配置 Web 实例通过 Amazon Simple Notification Service (Amazon SNS) 发送电子邮件。",
      "D": "使用专门用于电子邮件处理的 EC2 实例创建一个单独的应用程序层。将实例放置在 Auto Scaling 组中。"
    }
  },
  {
    "id": 414,
    "topic": "1",
    "question_en": "A company has a business system that generates hundreds of reports each day. The business system saves the reports to a network share in CSV format. The company needs to store this data in the AWS Cloud in near-real time for analysis. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Use AWS DataSync to transfer the files to Amazon S3. Create a scheduled task that runs at the end of each day.",
      "B": "Create an Amazon S3 File Gateway. Update the business system to use a new network share from the S3 File Gateway.",
      "C": "Use AWS DataSync to transfer the files to Amazon S3. Create an application that uses the DataSync API in the automation workfiow.",
      "D": "Deploy an AWS Transfer for SFTP endpoint. Create a script that checks for new files on the network share and uploads the new files by using SFTP."
    },
    "correct_answer": "C",
    "vote_percentage": "85%",
    "question_cn": "一家公司有一个业务系统，每天生成数百份报告。该业务系统将报告保存为 CSV 格式的网络共享。该公司需要在 AWS 云中近乎实时地存储这些数据以供分析。哪种解决方案将以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 将文件传输到 Amazon S3。创建一个定期任务，每天结束时运行。",
      "B": "创建一个 Amazon S3 File Gateway。更新业务系统以使用来自 S3 File Gateway 的新网络共享。",
      "C": "使用 AWS DataSync 将文件传输到 Amazon S3。创建一个应用程序，该应用程序在自动化工作流程中使用 DataSync API。",
      "D": "部署一个 AWS Transfer for SFTP 端点。创建一个脚本，该脚本检查网络共享上的新文件，并通过使用 SFTP 上传新文件。"
    }
  },
  {
    "id": 415,
    "topic": "1",
    "question_en": "A company is storing petabytes of data in Amazon S3 Standard. The data is stored in multiple S3 buckets and is accessed with varying frequency. The company does not know access patterns for all the data. The company needs to implement a solution for each S3 bucket to optimize the cost of S3 usage. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create an S3 Lifecycle configuration with a rule to transition the objects in the S3 bucket to S3 Intelligent-Tiering.",
      "B": "Use the S3 storage class analysis tool to determine the correct tier for each object in the S3 bucket. Move each object to the identified storage tier.",
      "C": "Create an S3 Lifecycle configuration with a rule to transition the objects in the S3 bucket to S3 Glacier Instant Retrieval.",
      "D": "Create an S3 Lifecycle configuration with a rule to transition the objects in the S3 bucket to S3 One Zone-Infrequent Access (S3 One Zone-IA)."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 Amazon S3 Standard 中存储数 PB 的数据。数据存储在多个 S3 存储桶中，并且访问频率各不相同。该公司不了解所有数据的访问模式。该公司需要为每个 S3 存储桶实施一个解决方案，以优化 S3 使用的成本。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "创建一个 S3 生命周期配置，其中包含一条规则，将 S3 存储桶中的对象转换为 S3 Intelligent-Tiering。",
      "B": "使用 S3 存储类别分析工具确定 S3 存储桶中每个对象的正确层。将每个对象移动到已确定的存储层。",
      "C": "创建一个 S3 生命周期配置，其中包含一条规则，将 S3 存储桶中的对象转换为 S3 Glacier Instant Retrieval。",
      "D": "创建一个 S3 生命周期配置，其中包含一条规则，将 S3 存储桶中的对象转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)。"
    }
  },
  {
    "id": 416,
    "topic": "1",
    "question_en": "A rapidly growing global ecommerce company is hosting its web application on AWS. The web application includes static content and dynamic content. The website stores online transaction processing (OLTP) data in an Amazon RDS database The website’s users are experiencing slow page loads. Which combination of actions should a solutions architect take to resolve this issue? (Choose two.)",
    "options_en": {
      "A": "Configure an Amazon Redshift cluster.",
      "B": "Set up an Amazon CloudFront distribution.",
      "C": "Host the dynamic web content in Amazon S3.",
      "D": "Create a read replica for the RDS DB instanc",
      "E": "E. Configure a Multi-AZ deployment for the RDS DB instance."
    },
    "correct_answer": "B",
    "vote_percentage": "87%",
    "question_cn": "一家快速增长的全球电子商务公司正在 AWS 上托管其 Web 应用程序。该 Web 应用程序包括静态内容和动态内容。该网站将在线事务处理 (OLTP) 数据存储在 Amazon RDS 数据库中。该网站的用户遇到了页面加载缓慢的问题。解决方案架构师应采取哪些组合操作来解决此问题？（选择两项。）",
    "options_cn": {
      "A": "配置一个 Amazon Redshift 集群。",
      "B": "设置一个 Amazon CloudFront 分发。",
      "C": "将动态 Web 内容托管在 Amazon S3 中。",
      "D": "为 RDS 数据库实例创建一个只读副本。",
      "E": "为 RDS 数据库实例配置多可用区部署。"
    }
  },
  {
    "id": 417,
    "topic": "1",
    "question_en": "A company uses Amazon EC2 instances and AWS Lambda functions to run its application. The company has VPCs with public subnets and private subnets in its AWS account. The EC2 instances run in a private subnet in one of the VPCs. The Lambda functions need direct network access to the EC2 instances for the application to work. The application will run for at least 1 year. The company expects the number of Lambda functions that the application uses to increase during that time. The company wants to maximize its savings on all application resources and to keep network latency between the services low. Which solution will meet these requirements?",
    "options_en": {
      "A": "Purchase an EC2 Instance Savings Plan Optimize the Lambda functions’ duration and memory usage and the number of invocations. Connect the Lambda functions to the private subnet that contains the EC2 instances.",
      "B": "Purchase an EC2 Instance Savings Plan Optimize the Lambda functions' duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to a public subnet in the same VPC where the EC2 instances run.",
      "C": "Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to the private subnet that contains the EC2 instances.",
      "D": "Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Keep the Lambda functions in the Lambda service VPC."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon EC2 实例和 AWS Lambda 函数来运行其应用程序。该公司在其 AWS 账户中拥有具有公有子网和私有子网的 VPC。 EC2 实例在其中一个 VPC 的私有子网中运行。Lambda 函数需要直接网络访问 EC2 实例才能使应用程序正常工作。该应用程序将运行至少 1 年。该公司预计在此期间应用程序使用的 Lambda 函数数量会增加。该公司希望最大程度地节省所有应用程序资源并保持服务之间的低网络延迟。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "购买 EC2 实例储蓄计划。优化 Lambda 函数的持续时间和内存使用量以及调用的次数。将 Lambda 函数连接到包含 EC2 实例的私有子网。",
      "B": "购买 EC2 实例储蓄计划。优化 Lambda 函数的持续时间、内存使用量、调用的次数以及传输的数据量。将 Lambda 函数连接到 EC2 实例运行所在的同一 VPC 中的公有子网。",
      "C": "购买计算储蓄计划。优化 Lambda 函数的持续时间、内存使用量、调用的次数以及传输的数据量。将 Lambda 函数连接到包含 EC2 实例的私有子网。",
      "D": "购买计算储蓄计划。优化 Lambda 函数的持续时间、内存使用量、调用的次数以及传输的数据量。将 Lambda 函数保留在 Lambda 服务 VPC 中。"
    }
  },
  {
    "id": 418,
    "topic": "1",
    "question_en": "A solutions architect needs to allow team members to access Amazon S3 buckets in two different AWS accounts: a development account and a production account. The team currently has access to S3 buckets in the development account by using unique IAM users that are assigned to an IAM group that has appropriate permissions in the account. The solutions architect has created an IAM role in the production account. The role has a policy that grants access to an S3 bucket in the production account. Which solution will meet these requirements while complying with the principle of least privilege?",
    "options_en": {
      "A": "Attach the Administrator Access policy to the development account users.",
      "B": "Add the development account as a principal in the trust policy of the role in the production account.",
      "C": "Turn off the S3 Block Public Access feature on the S3 bucket in the production account.",
      "D": "Create a user in the production account with unique credentials for each team member."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要允许团队成员访问两个不同 AWS 账户中的 Amazon S3 存储桶：一个开发账户和一个生产账户。团队目前通过使用唯一的 IAM 用户访问开发账户中的 S3 存储桶，这些用户被分配到一个在账户中具有适当权限的 IAM 组。解决方案架构师已经在生产账户中创建了一个 IAM 角色。该角色具有一个策略，授予对生产账户中的 S3 存储桶的访问权限。哪个解决方案将满足这些要求，同时符合最小权限原则？",
    "options_cn": {
      "A": "将 Administrator Access 策略附加到开发账户用户。",
      "B": "将开发账户添加为生产账户中角色的信任策略中的委托人。",
      "C": "关闭生产账户中 S3 存储桶上的 S3 阻止公共访问功能。",
      "D": "为每个团队成员在生产账户中创建一个具有唯一凭据的用户。"
    }
  },
  {
    "id": 419,
    "topic": "1",
    "question_en": "A company uses AWS Organizations with all features enabled and runs multiple Amazon EC2 workloads in the ap-southeast-2 Region. The company has a service control policy (SCP) that prevents any resources from being created in any other Region. A security policy requires the company to encrypt all data at rest. An audit discovers that employees have created Amazon Elastic Block Store (Amazon EBS) volumes for EC2 instances without encrypting the volumes. The company wants any new EC2 instances that any IAM user or root user launches in ap-southeast-2 to use encrypted EBS volumes. The company wants a solution that will have minimal effect on employees who create EBS volumes. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "In the Amazon EC2 console, select the EBS encryption account attribute and define a default encryption key.",
      "B": "Create an IAM permission boundary. Attach the permission boundary to the root organizational unit (OU). Define the boundary to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals false.",
      "C": "Create an SCP. Attach the SCP to the root organizational unit (OU). Define the SCP to deny the ec2:CreateVolume action whenthe ec2:Encrypted condition equals false.",
      "D": "Update the IAM policies for each account to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals fals",
      "E": "E. In the Organizations management account, specify the Default EBS volume encryption setting."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司使用启用了所有功能的 AWS Organizations，并在 ap-southeast-2 区域运行多个 Amazon EC2 工作负载。该公司有一个服务控制策略 (SCP)，禁止在任何其他区域创建任何资源。一项安全策略要求公司对所有静态数据进行加密。审计发现，员工为 EC2 实例创建了 Amazon Elastic Block Store (Amazon EBS) 卷，但没有加密这些卷。该公司希望任何 IAM 用户或根用户在 ap-southeast-2 中启动的任何新 EC2 实例都使用加密的 EBS 卷。该公司希望一个对创建 EBS 卷的员工影响最小的解决方案。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 Amazon EC2 控制台中，选择 EBS 加密账户属性并定义一个默认加密密钥。",
      "B": "创建 IAM 权限边界。将权限边界附加到根组织单元 (OU)。定义边界以拒绝 ec2:CreateVolume 操作，当 ec2:Encrypted 条件等于 false 时。",
      "C": "创建 SCP。将 SCP 附加到根组织单元 (OU)。定义 SCP 以拒绝 ec2:CreateVolume 操作，当 ec2:Encrypted 条件等于 false 时。",
      "D": "更新每个账户的 IAM 策略，以拒绝 ec2:CreateVolume 操作，当 ec2:Encrypted 条件等于 false 时。",
      "E": "在 Organizations 管理账户中，指定默认的 EBS 卷加密设置。"
    }
  },
  {
    "id": 420,
    "topic": "1",
    "question_en": "A company wants to use an Amazon RDS for PostgreSQL DB cluster to simplify time-consuming database administrative tasks for production database workloads. The company wants to ensure that its database is highly available and will provide automatic failover support in most scenarios in less than 40 seconds. The company wants to ofioad reads off of the primary instance and keep costs as low as possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an Amazon RDS Multi-AZ DB instance deployment. Create one read replica and point the read workload to the read replica.",
      "B": "Use an Amazon RDS Multi-AZ DB duster deployment Create two read replicas and point the read workload to the read replicas.",
      "C": "Use an Amazon RDS Multi-AZ DB instance deployment. Point the read workload to the secondary instances in the Multi-AZ pair.",
      "D": "Use an Amazon RDS Multi-AZ DB cluster deployment Point the read workload to the reader endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "82%",
    "question_cn": "一家公司希望使用 Amazon RDS for PostgreSQL DB 集群来简化生产数据库工作负载中耗时的数据库管理任务。该公司希望确保其数据库具有高可用性，并在大多数情况下在 40 秒内提供自动故障转移支持。该公司希望将读取从主实例中卸载，并尽可能降低成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon RDS Multi-AZ DB 实例部署。创建一个读取副本并将读取工作负载指向读取副本。",
      "B": "使用 Amazon RDS Multi-AZ DB 集群部署。创建两个读取副本，并将读取工作负载指向读取副本。",
      "C": "使用 Amazon RDS Multi-AZ DB 实例部署。将读取工作负载指向 Multi-AZ 对中的辅助实例。",
      "D": "使用 Amazon RDS Multi-AZ DB 集群部署。将读取工作负载指向读取器端点。"
    }
  },
  {
    "id": 421,
    "topic": "1",
    "question_en": "A company runs a highly available SFTP service. The SFTP service uses two Amazon EC2 Linux instances that run with elastic IP addresses to accept trafic from trusted IP sources on the internet. The SFTP service is backed by shared storage that is attached to the instances. User accounts are created and managed as Linux users in the SFTP servers. The company wants a serverless option that provides high IOPS performance and highly configurable security. The company also wants to maintain control over user permissions. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the EBS volume to the SFTP service endpoint. Grant users access to the SFTP service.",
      "B": "Create an encrypted Amazon Elastic File System (Amazon EFS) volume. Create an AWS Transfer Family SFTP service with elastic IP addresses and a VPC endpoint that has internet-facing access. Attach a security group to the endpoint that allows only trusted IP addresses. Attach the EFS volume to the SFTP service endpoint. Grant users access to the SFTP service.",
      "C": "Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service.",
      "D": "Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a VPC endpoint that has internal access in a private subnet. Attach a security group that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service."
    },
    "correct_answer": "C",
    "vote_percentage": "82%",
    "question_cn": "一家公司运营一项高可用 SFTP 服务。SFTP 服务使用两个 Amazon EC2 Linux 实例，这些实例使用弹性 IP 地址运行，以接受来自互联网上受信任 IP 源的流量。SFTP 服务由连接到实例的共享存储提供支持。用户账户在 SFTP 服务器中作为 Linux 用户创建和管理。该公司想要一个无服务器选项，该选项提供高 IOPS 性能和高度可配置的安全性。该公司还希望保持对用户权限的控制。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个加密的 Amazon Elastic Block Store (Amazon EBS) 卷。创建一个 AWS Transfer Family SFTP 服务，该服务具有一个公共端点，仅允许受信任的 IP 地址。将 EBS 卷附加到 SFTP 服务端点。授予用户访问 SFTP 服务的权限。",
      "B": "创建一个加密的 Amazon Elastic File System (Amazon EFS) 卷。创建一个 AWS Transfer Family SFTP 服务，该服务具有弹性 IP 地址和具有面向 Internet 访问的 VPC 端点。将安全组附加到端点，该安全组仅允许受信任的 IP 地址。将 EFS 卷附加到 SFTP 服务端点。授予用户访问 SFTP 服务的权限。",
      "C": "创建一个已启用默认加密的 Amazon S3 存储桶。创建一个 AWS Transfer Family SFTP 服务，该服务具有一个公共端点，仅允许受信任的 IP 地址。将 S3 存储桶附加到 SFTP 服务端点。授予用户访问 SFTP 服务的权限。",
      "D": "创建一个已启用默认加密的 Amazon S3 存储桶。创建一个 AWS Transfer Family SFTP 服务，该服务具有 VPC 端点，该端点在私有子网中具有内部访问权限。附加一个仅允许受信任 IP 地址的安全组。将 S3 存储桶附加到 SFTP 服务端点。授予用户访问 SFTP 服务的权限。"
    }
  },
  {
    "id": 422,
    "topic": "1",
    "question_en": "A company is developing a new machine learning (ML) model solution on AWS. The models are developed as independent microservices that fetch approximately 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent. The company provides models to hundreds of users. The usage patterns for the models are irregular. Some models could be unused for days or weeks. Other models could receive batches of thousands of requests at a time. Which design should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Direct the requests from the API to a Network Load Balancer (NLB). Deploy the models as AWS Lambda functions that are invoked by the NLB.",
      "B": "Direct the requests from the API to an Application Load Balancer (ALB). Deploy the models as Amazon Elastic Container Service (Amazon ECS) services that read from an Amazon Simple Queue Service (Amazon SQS) queue. Use AWS App Mesh to scale the instances of the ECS cluster based on the SQS queue size.",
      "C": "Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the models as AWS Lambda functions that are invoked by SQS events. Use AWS Auto Scaling to increase the number of vCPUs for the Lambda functions based on the SQS queue size.",
      "D": "Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the models as Amazon Elastic Container Service (Amazon ECS) services that read from the queue. Enable AWS Auto Scaling on Amazon ECS for both the cluster and copies of the service based on the queue size."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上开发新的机器学习 (ML) 模型解决方案。这些模型被开发为独立的微服务，这些微服务在启动时从 Amazon S3 获取大约 1 GB 的模型数据，并将数据加载到内存中。用户通过异步 API 访问这些模型。用户可以发送一个请求或一批请求，并指定结果的发送位置。该公司向数百名用户提供模型。这些模型的使用模式是不规则的。某些模型可能几天或几周未使用。其他模型一次可能收到数千个请求。解决方案架构师应该推荐哪种设计来满足这些要求？",
    "options_cn": {
      "A": "将来自 API 的请求定向到 Network Load Balancer (NLB)。将这些模型部署为由 NLB 调用的 AWS Lambda 函数。",
      "B": "将来自 API 的请求定向到 Application Load Balancer (ALB)。将这些模型部署为从 Amazon Simple Queue Service (Amazon SQS) 队列读取的 Amazon Elastic Container Service (Amazon ECS) 服务。使用 AWS App Mesh 根据 SQS 队列大小扩展 ECS 集群的实例。",
      "C": "将来自 API 的请求定向到 Amazon Simple Queue Service (Amazon SQS) 队列。将这些模型部署为由 SQS 事件调用的 AWS Lambda 函数。使用 AWS Auto Scaling 根据 SQS 队列大小增加 Lambda 函数的 vCPU 数量。",
      "D": "将来自 API 的请求定向到 Amazon Simple Queue Service (Amazon SQS) 队列。将这些模型部署为从队列读取的 Amazon Elastic Container Service (Amazon ECS) 服务。在 Amazon ECS 上启用 AWS Auto Scaling，以便根据队列大小扩展集群和服务的副本。"
    }
  },
  {
    "id": 423,
    "topic": "1",
    "question_en": "A solutions architect wants to use the following JSON text as an identity-based policy to grant specific permissions: Which IAM principals can the solutions architect attach this policy to? (Choose two.)",
    "options_en": {
      "A": "Role",
      "B": "Group",
      "C": "Organization",
      "D": "Amazon Elastic Container Service (Amazon ECS) resource",
      "E": "Amazon EC2 resource"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "解决方案架构师希望使用以下 JSON 文本作为基于身份的策略来授予特定权限：解决方案架构师可以将此策略附加到哪些 IAM 主体？（选择两个。）",
    "options_cn": {
      "A": "角色",
      "B": "组",
      "C": "组织",
      "D": "Amazon Elastic Container Service (Amazon ECS) 资源",
      "E": "Amazon EC2 资源"
    }
  },
  {
    "id": 424,
    "topic": "1",
    "question_en": "A company is running a custom application on Amazon EC2 On-Demand Instances. The application has frontend nodes that need to run 24 hours a day, 7 days a week and backend nodes that need to run only for a short time based on workload. The number of backend nodes varies during the day. The company needs to scale out and scale in more instances based on workload. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use Reserved Instances for the frontend nodes. Use AWS Fargate for the backend nodes.",
      "B": "Use Reserved Instances for the frontend nodes. Use Spot Instances for the backend nodes.",
      "C": "Use Spot Instances for the frontend nodes. Use Reserved Instances for the backend nodes.",
      "D": "Use Spot Instances for the frontend nodes. Use AWS Fargate for the backend nodes."
    },
    "correct_answer": "B",
    "vote_percentage": "64%",
    "question_cn": "一家公司正在 Amazon EC2 On-Demand 实例上运行一个自定义应用程序。该应用程序具有需要每天 24 小时、每周 7 天运行的前端节点和仅根据工作负载在短时间内运行的后端节点。后端节点的数量在一天中变化。该公司需要根据工作负载扩展和缩减更多实例。哪种解决方案将以最具成本效益的方式满足这些需求？",
    "options_cn": {
      "A": "为前端节点使用 Reserved Instances。为后端节点使用 AWS Fargate。",
      "B": "为前端节点使用 Reserved Instances。为后端节点使用 Spot Instances。",
      "C": "为前端节点使用 Spot Instances。为后端节点使用 Reserved Instances。",
      "D": "为前端节点使用 Spot Instances。为后端节点使用 AWS Fargate。"
    }
  },
  {
    "id": 425,
    "topic": "1",
    "question_en": "A company uses high block storage capacity to runs its workloads on premises. The company's daily peak input and output transactions per second are not more than 15,000 IOPS. The company wants to migrate the workloads to Amazon EC2 and to provision disk performance independent of storage capacity. Which Amazon Elastic Block Store (Amazon EBS) volume type will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "GP2 volume type",
      "B": "io2 volume type",
      "C": "GP3 volume type",
      "D": "io1 volume type"
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "一家公司使用高块存储容量在其本地运行工作负载。该公司每天的峰值每秒输入和输出事务不超过 15,000 IOPS。该公司希望将工作负载迁移到 Amazon EC2，并配置与存储容量无关的磁盘性能。哪种 Amazon Elastic Block Store (Amazon EBS) 卷类型将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "GP2 卷类型",
      "B": "io2 卷类型",
      "C": "GP3 卷类型",
      "D": "io1 卷类型"
    }
  },
  {
    "id": 426,
    "topic": "1",
    "question_en": "A company needs to store data from its healthcare application. The application’s data frequently changes. A new regulation requires audit access at all levels of the stored data. The company hosts the application on an on-premises infrastructure that is running out of storage capacity. A solutions architect must securely migrate the existing data to AWS while satisfying the new regulation. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS DataSync to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.",
      "B": "Use AWS Snowcone to move the existing data to Amazon S3. Use AWS CloudTrail to log management events.",
      "C": "Use Amazon S3 Transfer Acceleration to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.",
      "D": "Use AWS Storage Gateway to move the existing data to Amazon S3. Use AWS CloudTrail to log management events."
    },
    "correct_answer": "B",
    "vote_percentage": "57%",
    "question_cn": "一家公司需要存储其医疗保健应用程序的数据。该应用程序的数据经常变化。一项新法规要求对存储数据的各个级别进行审计访问。该公司将应用程序托管在本地基础设施上，该基础设施的存储容量即将耗尽。一位解决方案架构师必须安全地将现有数据迁移到 AWS，同时满足新法规的要求。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 将现有数据移动到 Amazon S3。使用 AWS CloudTrail 记录数据事件。",
      "B": "使用 AWS Snowcone 将现有数据移动到 Amazon S3。使用 AWS CloudTrail 记录管理事件。",
      "C": "使用 Amazon S3 Transfer Acceleration 将现有数据移动到 Amazon S3。使用 AWS CloudTrail 记录数据事件。",
      "D": "使用 AWS Storage Gateway 将现有数据移动到 Amazon S3。使用 AWS CloudTrail 记录管理事件。"
    }
  },
  {
    "id": 427,
    "topic": "1",
    "question_en": "A solutions architect is implementing a complex Java application with a MySQL database. The Java application must be deployed on Apache Tomcat and must be highly available. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Deploy the application in AWS Lambda. Configure an Amazon API Gateway API to connect with the Lambda functions.",
      "B": "Deploy the application by using AWS Elastic Beanstalk. Configure a load-balanced environment and a rolling deployment policy.",
      "C": "Migrate the database to Amazon ElastiCache. Configure the ElastiCache security group to allow access from the application.",
      "D": "Launch an Amazon EC2 instance. Install a MySQL server on the EC2 instance. Configure the application on the server. Create an AMI. Use the AMI to create a launch template with an Auto Scaling group."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在实施一个具有 MySQL 数据库的复杂 Java 应用程序。Java 应用程序必须部署在 Apache Tomcat 上，并且必须具有高可用性。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在 AWS Lambda 中部署应用程序。配置 Amazon API Gateway API 以连接到 Lambda 函数。",
      "B": "使用 AWS Elastic Beanstalk 部署应用程序。配置负载均衡环境和滚动部署策略。",
      "C": "将数据库迁移到 Amazon ElastiCache。配置 ElastiCache 安全组，以允许从应用程序进行访问。",
      "D": "启动 Amazon EC2 实例。在 EC2 实例上安装 MySQL 服务器。在服务器上配置应用程序。创建一个 AMI。使用 AMI 创建一个具有 Auto Scaling group 的启动模板。"
    }
  },
  {
    "id": 428,
    "topic": "1",
    "question_en": "A serverless application uses Amazon API Gateway, AWS Lambda, and Amazon DynamoDB. The Lambda function needs permissions to read and write to the DynamoDB table. Which solution will give the Lambda function access to the DynamoDB table MOST securely?",
    "options_en": {
      "A": "Create an IAM user with programmatic access to the Lambda function. Attach a policy to the user that allows read and write access to the DynamoDB table. Store the access_key_id and secret_access_key parameters as part of the Lambda environment variables. Ensure that other AWS users do not have read and write access to the Lambda function configuration.",
      "B": "Create an IAM role that includes Lambda as a trusted service. Attach a policy to the role that allows read and write access to the DynamoDB table. Update the configuration of the Lambda function to use the new role as the execution role.",
      "C": "Create an IAM user with programmatic access to the Lambda function. Attach a policy to the user that allows read and write access to the DynamoDB table. Store the access_key_id and secret_access_key parameters in AWS Systems Manager Parameter Store as secure string parameters. Update the Lambda function code to retrieve the secure string parameters before connecting to the DynamoDB table.",
      "D": "Create an IAM role that includes DynamoDB as a trusted service. Attach a policy to the role that allows read and write access from the Lambda function. Update the code of the Lambda function to attach to the new role as an execution role."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个无服务器应用程序使用 Amazon API Gateway、AWS Lambda 和 Amazon DynamoDB。Lambda 函数需要权限来读取和写入 DynamoDB 表。哪种解决方案将最安全地赋予 Lambda 函数访问 DynamoDB 表的权限？",
    "options_cn": {
      "A": "创建一个 IAM 用户，使用编程访问权限访问 Lambda 函数。为该用户附加一个策略，允许对 DynamoDB 表进行读写访问。将 access_key_id 和 secret_access_key 参数存储为 Lambda 环境变量的一部分。确保其他 AWS 用户没有对 Lambda 函数配置的读写访问权限。",
      "B": "创建一个 IAM 角色，其中包括 Lambda 作为受信任的服务。为该角色附加一个策略，允许对 DynamoDB 表进行读写访问。更新 Lambda 函数的配置以使用新角色作为执行角色。",
      "C": "创建一个 IAM 用户，使用编程访问权限访问 Lambda 函数。为该用户附加一个策略，允许对 DynamoDB 表进行读写访问。将 access_key_id 和 secret_access_key 参数作为安全字符串参数存储在 AWS Systems Manager Parameter Store 中。更新 Lambda 函数代码以在连接到 DynamoDB 表之前检索安全字符串参数。",
      "D": "创建一个 IAM 角色，其中包括 DynamoDB 作为受信任的服务。为该角色附加一个策略，允许来自 Lambda 函数的读写访问。更新 Lambda 函数的代码以附加到新角色作为执行角色。"
    }
  },
  {
    "id": 429,
    "topic": "1",
    "question_en": "The following IAM policy is attached to an IAM group. This is the only policy applied to the group. What are the effective IAM permissions of this policy for group members?",
    "options_en": {
      "A": "Group members are permitted any Amazon EC2 action within the us-east-1 Region. Statements after the Allow permission are not applied.",
      "B": "Group members are denied any Amazon EC2 permissions in the us-east-1 Region unless they are logged in with multi-factor authentication (MFA).",
      "C": "Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for all Regions when logged in with multi- factor authentication (MFA). Group members are permitted any other Amazon EC2 action.",
      "D": "Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA). Group members are permitted any other Amazon EC2 action within the us-east-1 Region."
    },
    "correct_answer": "D",
    "vote_percentage": "85%",
    "question_cn": "以下 IAM 策略附加到一个 IAM 组。这是应用于该组的唯一策略。此策略对组成员的有效 IAM 权限是什么？",
    "options_cn": {
      "A": "组成员被允许在 us-east-1 区域内执行任何 Amazon EC2 操作。Allow 权限之后的语句不适用。",
      "B": "除非使用多因素身份验证 (MFA) 登录，否则组成员在 us-east-1 区域中被拒绝任何 Amazon EC2 权限。",
      "C": "组成员在使用多因素身份验证 (MFA) 登录时，被允许在所有区域执行 ec2:StopInstances 和 ec2:TerminateInstances 权限。组成员被允许任何其他 Amazon EC2 操作。",
      "D": "组成员仅在使用多因素身份验证 (MFA) 登录时，被允许在 us-east-1 区域执行 ec2:StopInstances 和 ec2:TerminateInstances 权限。组成员被允许在 us-east-1 区域内执行任何其他 Amazon EC2 操作。"
    }
  },
  {
    "id": 430,
    "topic": "1",
    "question_en": "A manufacturing company has machine sensors that upload .csv files to an Amazon S3 bucket. These .csv files must be converted into images and must be made available as soon as possible for the automatic generation of graphical reports. The images become irrelevant after 1 month, but the .csv files must be kept to train machine learning (ML) models twice a year. The ML trainings and audits are planned weeks in advance. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Launch an Amazon EC2 Spot Instance that downloads the .csv files every hour, generates the image files, and uploads the images to the S3 bucket.",
      "B": "Design an AWS Lambda function that converts the .csv files into images and stores the images in the S3 bucket. Invoke the Lambda function when a .csv file is uploaded.",
      "C": "Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Glacier 1 day after they are uploaded. Expire the image files after 30 days.",
      "D": "Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 One Zone- Infrequent Access (S3 One Zone-IA) 1 day after they are uploaded. Expire the image files after 30 days",
      "E": "Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Standard- Infrequent Access (S3 Standard-IA) 1 day after they are uploaded. Keep the image files in Reduced Redundancy Storage (RRS)."
    },
    "correct_answer": "B",
    "vote_percentage": "89%",
    "question_cn": "一家制造公司拥有将 .csv 文件上传到 Amazon S3 存储桶的机器传感器。这些 .csv 文件必须转换为图像，并尽快提供这些图像以自动生成图形报告。这些图像在 1 个月后变得无关紧要，但 .csv 文件必须保留以每年两次训练机器学习 (ML) 模型。ML 训练和审计提前几周计划。哪种步骤组合将以最具成本效益的方式满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "启动一个 Amazon EC2 Spot 实例，该实例每小时下载 .csv 文件，生成图像文件，并将图像上传到 S3 存储桶。",
      "B": "设计一个 AWS Lambda 函数，将 .csv 文件转换为图像，并将图像存储在 S3 存储桶中。在上传 .csv 文件时调用 Lambda 函数。",
      "C": "为 S3 存储桶中的 .csv 文件和图像文件创建 S3 生命周期规则。在上传 .csv 文件 1 天后，将 .csv 文件从 S3 Standard 转换为 S3 Glacier。在 30 天后删除图像文件。",
      "D": "为 S3 存储桶中的 .csv 文件和图像文件创建 S3 生命周期规则。在上传 .csv 文件 1 天后，将 .csv 文件从 S3 Standard 转换为 S3 One Zone- Infrequent Access (S3 One Zone-IA)。在 30 天后删除图像文件。",
      "E": "为 S3 存储桶中的 .csv 文件和图像文件创建 S3 生命周期规则。在上传 .csv 文件 1 天后，将 .csv 文件从 S3 Standard 转换为 S3 Standard- Infrequent Access (S3 Standard-IA)。将图像文件保存在 Reduced Redundancy Storage (RRS) 中。"
    }
  },
  {
    "id": 431,
    "topic": "1",
    "question_en": "A company has developed a new video game as a web application. The application is in a three-tier architecture in a VPC with Amazon RDS for MySQL in the database layer. Several players will compete concurrently online. The game’s developers want to display a top-10 scoreboard in near-real time and offer the ability to stop and restore the game while preserving the current scores. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Set up an Amazon ElastiCache for Memcached cluster to cache the scores for the web application to display.",
      "B": "Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display.",
      "C": "Place an Amazon CloudFront distribution in front of the web application to cache the scoreboard in a section of the application.",
      "D": "Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read trafic to the web application."
    },
    "correct_answer": "B",
    "vote_percentage": "96%",
    "question_cn": "一家公司开发了一款新的视频游戏，作为Web应用程序。该应用程序在VPC中使用三层架构，数据库层使用Amazon RDS for MySQL。几名玩家将同时在线竞争。游戏开发人员希望近乎实时地显示前10名排行榜，并提供暂停和恢复游戏的功能，同时保留当前分数。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "设置一个Amazon ElastiCache for Memcached集群，以缓存Web应用程序的分数供其显示。",
      "B": "设置一个Amazon ElastiCache for Redis集群，以计算和缓存Web应用程序的分数供其显示。",
      "C": "在Web应用程序前面放置一个Amazon CloudFront分发，以缓存应用程序一部分的排行榜。",
      "D": "在Amazon RDS for MySQL上创建一个只读副本，以运行查询来计算排行榜并将读取流量提供给Web应用程序。"
    }
  },
  {
    "id": 432,
    "topic": "1",
    "question_en": "An ecommerce company wants to use machine learning (ML) algorithms to build and train models. The company will use the models to visualize complex scenarios and to detect trends in customer data. The architecture team wants to integrate its ML models with a reporting platform to analyze the augmented data and use the data directly in its business intelligence dashboards. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Glue to create an ML transform to build and train models. Use Amazon OpenSearch Service to visualize the data.",
      "B": "Use Amazon SageMaker to build and train models. Use Amazon QuickSight to visualize the data.",
      "C": "Use a pre-built ML Amazon Machine Image (AMI) from the AWS Marketplace to build and train models. Use Amazon OpenSearch Service to visualize the data.",
      "D": "Use Amazon QuickSight to build and train models by using calculated fields. Use Amazon QuickSight to visualize the data."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司希望使用机器学习 (ML) 算法来构建和训练模型。该公司将使用这些模型来可视化复杂场景并检测客户数据中的趋势。架构团队希望将其 ML 模型与报告平台集成，以分析增强的数据，并在其商业智能仪表板中直接使用这些数据。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Glue 创建 ML 转换来构建和训练模型。使用 Amazon OpenSearch Service 可视化数据。",
      "B": "使用 Amazon SageMaker 构建和训练模型。使用 Amazon QuickSight 可视化数据。",
      "C": "使用 AWS Marketplace 中预构建的 ML Amazon Machine Image (AMI) 来构建和训练模型。使用 Amazon OpenSearch Service 可视化数据。",
      "D": "通过使用计算字段，使用 Amazon QuickSight 构建和训练模型。使用 Amazon QuickSight 可视化数据。"
    }
  },
  {
    "id": 433,
    "topic": "1",
    "question_en": "A company is running its production and nonproduction environment workloads in multiple AWS accounts. The accounts are in an organization in AWS Organizations. The company needs to design a solution that will prevent the modification of cost usage tags. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a custom AWS Config rule to prevent tag modification except by authorized principals.",
      "B": "Create a custom trail in AWS CloudTrail to prevent tag modification.",
      "C": "Create a service control policy (SCP) to prevent tag modification except by authorized principals.",
      "D": "Create custom Amazon CloudWatch logs to prevent tag modification."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在多个 AWS 账户中运行其生产和非生产环境工作负载。这些账户位于 AWS Organizations 中的一个组织中。该公司需要设计一个解决方案，以防止修改成本使用标签。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个自定义 AWS Config 规则，以防止标签修改，除非由授权主体执行。",
      "B": "在 AWS CloudTrail 中创建一个自定义跟踪，以防止标签修改。",
      "C": "创建一个服务控制策略 (SCP)，以防止标签修改，除非由授权主体执行。",
      "D": "创建自定义 Amazon CloudWatch 日志以防止标签修改。"
    }
  },
  {
    "id": 434,
    "topic": "1",
    "question_en": "A company hosts its application in the AWS Cloud. The application runs on Amazon EC2 instances behind an Elastic Load Balancer in an Auto Scaling group and with an Amazon DynamoDB table. The company wants to ensure the application can be made available in anotherAWS Region with minimal downtime. What should a solutions architect do to meet these requirements with the LEAST amount of downtime?",
    "options_en": {
      "A": "Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
      "B": "Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be launched when needed Configure DNS failover to point to the new disaster recovery Region's load balancer.",
      "C": "Create an AWS CloudFormation template to create EC2 instances and a load balancer to be launched when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.",
      "D": "Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger an AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer."
    },
    "correct_answer": "A",
    "vote_percentage": "52%",
    "question_cn": "一家公司在 AWS 云中托管其应用程序。该应用程序在 Auto Scaling 组中的 Application Load Balancer 后面的 Amazon EC2 实例上运行，并带有一个 Amazon DynamoDB 表。公司希望确保该应用程序可以在另一个 AWS 区域中使用，且停机时间最短。解决方案架构师应该怎么做才能以最少的停机时间满足这些要求？",
    "options_cn": {
      "A": "在灾难恢复区域中创建一个 Auto Scaling 组和一个负载均衡器。将 DynamoDB 表配置为全局表。配置 DNS 故障转移以指向新的灾难恢复区域的负载均衡器。",
      "B": "创建一个 AWS CloudFormation 模板，以创建 EC2 实例、负载均衡器和 DynamoDB 表，以便在需要时启动。配置 DNS 故障转移以指向新的灾难恢复区域的负载均衡器。",
      "C": "创建一个 AWS CloudFormation 模板，以创建 EC2 实例和负载均衡器，以便在需要时启动。将 DynamoDB 表配置为全局表。配置 DNS 故障转移以指向新的灾难恢复区域的负载均衡器。",
      "D": "在灾难恢复区域中创建一个 Auto Scaling 组和负载均衡器。将 DynamoDB 表配置为全局表。创建一个 Amazon CloudWatch 警报，以触发一个 AWS Lambda 函数，该函数更新 Amazon Route 53，指向灾难恢复负载均衡器。"
    }
  },
  {
    "id": 435,
    "topic": "1",
    "question_en": "A company needs to migrate a MySQL database from its on-premises data center to AWS within 2 weeks. The database is 20 TB in size. The company wants to complete the migration with minimal downtime. Which solution will migrate the database MOST cost-effectively?",
    "options_en": {
      "A": "Order an AWS Snowball Edge Storage Optimized device. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with replication of ongoing changes. Send the Snowball Edge device to AWS to finish the migration and continue the ongoing replication.",
      "B": "Order an AWS Snowmobile vehicle. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with ongoing changes. Send the Snowmobile vehicle back to AWS to finish the migration and continue the ongoing replication.",
      "C": "Order an AWS Snowball Edge Compute Optimized with GPU device. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with ongoing changes. Send the Snowball device to AWS to finish the migration and continue the ongoing replication",
      "D": "Order a 1 GB dedicated AWS Direct Connect connection to establish a connection with the data center. Use AWS Database Migration Service (AWS DMS) with AWS Schema Conversion Tool (AWS SCT) to migrate the database with replication of ongoing changes."
    },
    "correct_answer": "D",
    "vote_percentage": "85%",
    "question_cn": "一家公司需要在 2 周内将其 MySQL 数据库从其本地数据中心迁移到 AWS。数据库大小为 20 TB。该公司希望以最小的停机时间完成迁移。哪个解决方案将以最具成本效益的方式迁移数据库？",
    "options_cn": {
      "A": "订购一个 AWS Snowball Edge 存储优化设备。使用 AWS Database Migration Service (AWS DMS) 和 AWS Schema Conversion Tool (AWS SCT) 迁移数据库，并复制持续更改。将 Snowball Edge 设备发送到 AWS 以完成迁移并继续进行持续复制。",
      "B": "订购一辆 AWS Snowmobile 车辆。使用 AWS Database Migration Service (AWS DMS) 和 AWS Schema Conversion Tool (AWS SCT) 迁移数据库，并复制持续更改。将 Snowmobile 车辆发送回 AWS 以完成迁移并继续进行持续复制。",
      "C": "订购一个带有 GPU 的 AWS Snowball Edge Compute Optimized 设备。使用 AWS Database Migration Service (AWS DMS) 和 AWS Schema Conversion Tool (AWS SCT) 迁移数据库，并复制持续更改。将 Snowball 设备发送到 AWS 以完成迁移并继续进行持续复制。",
      "D": "订购 1 GB 专用 AWS Direct Connect 连接以与数据中心建立连接。使用 AWS Database Migration Service (AWS DMS) 和 AWS Schema Conversion Tool (AWS SCT) 迁移数据库，并复制持续更改。"
    }
  },
  {
    "id": 436,
    "topic": "1",
    "question_en": "A company moved its on-premises PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. The company successfully launched a new product. The workload on the database has increased. The company wants to accommodate the larger workload without adding infrastructure. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Buy reserved DB instances for the total workload. Make the Amazon RDS for PostgreSQL DB instance larger.",
      "B": "Make the Amazon RDS for PostgreSQL DB instance a Multi-AZ DB instance.",
      "C": "Buy reserved DB instances for the total workload. Add another Amazon RDS for PostgreSQL DB instance.",
      "D": "Make the Amazon RDS for PostgreSQL DB instance an on-demand DB instance."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司将其本地 PostgreSQL 数据库迁移到了 Amazon RDS for PostgreSQL 数据库实例。该公司成功发布了一个新产品。数据库上的工作负载增加了。该公司希望在不增加基础设施的情况下适应更大的工作负载。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "为总工作负载购买预留数据库实例。 将 Amazon RDS for PostgreSQL 数据库实例变得更大。",
      "B": "将 Amazon RDS for PostgreSQL 数据库实例设置为多可用区数据库实例。",
      "C": "为总工作负载购买预留数据库实例。添加另一个 Amazon RDS for PostgreSQL 数据库实例。",
      "D": "将 Amazon RDS for PostgreSQL 数据库实例设置为按需数据库实例。"
    }
  },
  {
    "id": 437,
    "topic": "1",
    "question_en": "A company operates an ecommerce website on Amazon EC2 instances behind an Application Load Balancer (ALB) in an Auto Scaling group. The site is experiencing performance issues related to a high request rate from illegitimate external systems with changing IP addresses. The security team is worried about potential DDoS attacks against the website. The company must block the illegitimate incoming requests in a way that has a minimal impact on legitimate users. What should a solutions architect recommend?",
    "options_en": {
      "A": "Deploy Amazon Inspector and associate it with the ALB.",
      "B": "Deploy AWS WAF, associate it with the ALB, and configure a rate-limiting rule.",
      "C": "Deploy rules to the network ACLs associated with the ALB to block the incomingtrafic.",
      "D": "Deploy Amazon GuardDuty and enable rate-limiting protection when configuring GuardDuty."
    },
    "correct_answer": "B",
    "vote_percentage": "95%",
    "question_cn": "一家公司在其 Application Load Balancer (ALB) 之后，在 Auto Scaling 组中的 Amazon EC2 实例上运营一个电子商务网站。该网站正经历与来自具有变化 IP 地址的非法外部系统的高请求速率相关的性能问题。安全团队担心针对该网站的潜在 DDoS 攻击。该公司必须以对合法用户影响最小的方式阻止非法传入请求。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "部署 Amazon Inspector 并将其与 ALB 关联。",
      "B": "部署 AWS WAF，将其与 ALB 关联，并配置一个速率限制规则。",
      "C": "将规则部署到与 ALB 关联的网络 ACL，以阻止传入流量。",
      "D": "部署 Amazon GuardDuty 并在配置 GuardDuty 时启用速率限制保护。"
    }
  },
  {
    "id": 438,
    "topic": "1",
    "question_en": "A company wants to share accounting data with an external auditor. The data is stored in an Amazon RDS DB instance that resides in a private subnet. The auditor has its own AWS account and requires its own copy of the database. What is the MOST secure way for the company to share the database with the auditor?",
    "options_en": {
      "A": "Create a read replica of the database. Configure IAM standard database authentication to grant the auditor access.",
      "B": "Export the database contents to text files. Store the files in an Amazon S3 bucket. Create a new IAM user for the auditor. Grant the user access to the S3 bucket.",
      "C": "Copy a snapshot of the database to an Amazon S3 bucket. Create an IAM user. Share the user's keys with the auditor to grant access to the object in the S3 bucket.",
      "D": "Create an encrypted snapshot of the database. Share the snapshot with the auditor. Allow access to the AWS Key Management Service (AWS KMS) encryption key."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望与外部审计员共享会计数据。数据存储在位于私有子网中的 Amazon RDS 数据库实例中。审计员有自己的 AWS 账户，并且需要自己的数据库副本。公司与审计员共享数据库的最安全方式是什么？",
    "options_cn": {
      "A": "创建数据库的只读副本。配置 IAM 标准数据库身份验证以授予审计员访问权限。",
      "B": "将数据库内容导出到文本文件。将文件存储在 Amazon S3 存储桶中。为审计员创建一个新的 IAM 用户。授予该用户访问 S3 存储桶的权限。",
      "C": "将数据库的快照复制到 Amazon S3 存储桶。创建一个 IAM 用户。与审计员共享用户的密钥，以授予其访问 S3 存储桶中对象的权限。",
      "D": "创建数据库的加密快照。与审计员共享快照。允许访问 AWS Key Management Service (AWS KMS) 加密密钥。"
    }
  },
  {
    "id": 439,
    "topic": "1",
    "question_en": "A solutions architect configured a VPC that has a small range of IP addresses. The number of Amazon EC2 instances that are in the VPC is increasing, and there is an insuficient number of IP addresses for future workloads. Which solution resolves this issue with the LEAST operational overhead?",
    "options_en": {
      "A": "Add an additional IPv4 CIDR block to increase the number of IP addresses and create additional subnets in the VPC. Create new resources in the new subnets by using the new CIDR.",
      "B": "Create a second VPC with additional subnets. Use a peering connection to connect the second VPC with the first VPC Update the routes and create new resources in the subnets of the second VPC.",
      "C": "Use AWS Transit Gateway to add a transit gateway and connect a second VPC with the first VPUpdate the routes of the transit gateway and VPCs. Create new resources in the subnets of the second VPC.",
      "D": "Create a second VPC. Create a Site-to-Site VPN connection between the first VPC and the second VPC by using a VPN-hosted solution on Amazon EC2 and a virtual private gateway. Update the route between VPCs to the trafic through the VPN. Create new resources in the subnets of the second VPC."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师配置了一个具有小范围 IP 地址的 VPC。VPC 中 Amazon EC2 实例的数量正在增加，并且没有足够的 IP 地址来满足未来的工作负载。哪种解决方案以最小的运营开销解决了这个问题？",
    "options_cn": {
      "A": "添加一个额外的 IPv4 CIDR 块以增加 IP 地址的数量，并在 VPC 中创建额外的子网。使用新的 CIDR 在新的子网中创建新资源。",
      "B": "创建一个具有额外子网的第二个 VPC。使用对等连接将第二个 VPC 与第一个 VPC 连接起来。更新路由并在第二个 VPC 的子网中创建新资源。",
      "C": "使用 AWS Transit Gateway 添加一个 transit gateway，并将第二个 VPC 与第一个 VPC 连接起来。更新 transit gateway 和 VPC 的路由。在第二个 VPC 的子网中创建新资源。",
      "D": "创建第二个 VPC。通过使用 Amazon EC2 上的 VPN 托管解决方案和虚拟专用网关，在第一个 VPC 和第二个 VPC 之间创建 Site-to-Site VPN 连接。更新 VPC 之间的路由以通过 VPN 传输流量。在第二个 VPC 的子网中创建新资源。"
    }
  },
  {
    "id": 440,
    "topic": "1",
    "question_en": "A company used an Amazon RDS for MySQL DB instance during application testing. Before terminating the DB instance at the end of the test cycle, a solutions architect created two backups. The solutions architect created the first backup by using the mysqldump utility to create a database dump. The solutions architect created the second backup by enabling the final DB snapshot option on RDS termination. The company is now planning for a new test cycle and wants to create a new DB instance from the most recent backup. The company has chosen a MySQL-compatible edition ofAmazon Aurora to host the DB instance. Which solutions will create the new DB instance? (Choose two.)",
    "options_en": {
      "A": "Import the RDS snapshot directly into Aurora.",
      "B": "Upload the RDS snapshot to Amazon S3. Then import the RDS snapshot into Aurora.",
      "C": "Upload the database dump to Amazon S3. Then import the database dump into Aurora.",
      "D": "Use AWS Database Migration Service (AWS DMS) to import the RDS snapshot into Aurora",
      "E": "Upload the database dump to Amazon S3. Then use AWS Database Migration Service (AWS DMS) to import the database dump into Aurora."
    },
    "correct_answer": "A",
    "vote_percentage": "80%",
    "question_cn": "一家公司在应用程序测试期间使用了 Amazon RDS for MySQL 数据库实例。在测试周期结束时终止数据库实例之前，一位解决方案架构师创建了两个备份。解决方案架构师使用 mysqldump 实用程序创建数据库转储来创建第一个备份。解决方案架构师通过在 RDS 终止时启用最终数据库快照选项来创建第二个备份。该公司现在计划进行新的测试周期，并希望从最新的备份中创建新的数据库实例。该公司选择了与 MySQL 兼容的 Amazon Aurora 版本来托管数据库实例。哪些解决方案将创建新的数据库实例？（选择两项。）",
    "options_cn": {
      "A": "将 RDS 快照直接导入 Aurora。",
      "B": "将 RDS 快照上传到 Amazon S3，然后将 RDS 快照导入 Aurora。",
      "C": "将数据库转储上传到 Amazon S3，然后将数据库转储导入 Aurora。",
      "D": "使用 AWS Database Migration Service (AWS DMS) 将 RDS 快照导入 Aurora。",
      "E": "将数据库转储上传到 Amazon S3，然后使用 AWS Database Migration Service (AWS DMS) 将数据库转储导入 Aurora。"
    }
  },
  {
    "id": 441,
    "topic": "1",
    "question_en": "A company hosts a multi-tier web application on Amazon Linux Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company observes that the Auto Scaling group launches more On-Demand Instances when the application's end users access high volumes of static web content. The company wants to optimize cost. What should a solutions architect do to redesign the application MOST cost-effectively?",
    "options_en": {
      "A": "Update the Auto Scaling group to use Reserved Instances instead of On-Demand Instances.",
      "B": "Update the Auto Scaling group to scale by launching Spot Instances instead of On-Demand Instances.",
      "C": "Create an Amazon CloudFront distribution to host the static web contents from an Amazon S3 bucket.",
      "D": "Create an AWS Lambda function behind an Amazon API Gateway API to host the static website contents."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在Application Load Balancer后面的Amazon Linux Amazon EC2实例上托管一个多层Web应用程序。这些实例在多个可用区中的Auto Scaling组中运行。该公司观察到，当应用程序的最终用户访问大量静态Web内容时，Auto Scaling组会启动更多按需实例。该公司希望优化成本。解决方案架构师应该怎么做才能以最具成本效益的方式重新设计应用程序？",
    "options_cn": {
      "A": "更新Auto Scaling组以使用Reserved Instances而不是On-Demand Instances。",
      "B": "更新Auto Scaling组以通过启动Spot Instances而不是On-Demand Instances进行扩展。",
      "C": "创建一个Amazon CloudFront分布，以从Amazon S3存储桶托管静态Web内容。",
      "D": "在Amazon API Gateway API后面创建一个AWS Lambda函数来托管静态网站内容。"
    }
  },
  {
    "id": 442,
    "topic": "1",
    "question_en": "A company stores several petabytes of data across multiple AWS accounts. The company uses AWS Lake Formation to manage its data lake. The company's data science team wants to securely share selective data from its accounts with the company's engineering team for analytical purposes. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Copy the required data to a common account. Create an IAM access role in that account. Grant access by specifying a permission policy that includes users from the engineering team accounts as trusted entities.",
      "B": "Use the Lake Formation permissions Grant command in each account where the data is stored to allow the required engineering team users to access the data.",
      "C": "Use AWS Data Exchange to privately publish the required data to the required engineering team accounts.",
      "D": "Use Lake Formation tag-based access control to authorize and grant cross-account permissions for the required data to the engineering team accounts."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司跨多个 AWS 账户存储了数 PB 的数据。该公司使用 AWS Lake Formation 来管理其数据湖。该公司的数据科学团队希望安全地与公司的工程团队共享其账户中的选择性数据，用于分析目的。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将所需数据复制到一个公共账户。在该账户中创建 IAM 访问角色。通过指定一个包括工程团队账户中的用户作为受信任实体的权限策略来授予访问权限。",
      "B": "在存储数据的每个账户中使用 Lake Formation 权限 Grant 命令，以允许所需的工程团队用户访问数据。",
      "C": "使用 AWS Data Exchange 私下将所需数据发布到所需的工程团队账户。",
      "D": "使用 Lake Formation 基于标签的访问控制，为工程团队账户授权并授予对所需数据的跨账户权限。"
    }
  },
  {
    "id": 443,
    "topic": "1",
    "question_en": "A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost- effective solution to minimize upload and download latency and maximize performance. What should a solutions architect do to accomplish this?",
    "options_en": {
      "A": "Use Amazon S3 with Transfer Acceleration to host the application.",
      "B": "Use Amazon S3 with CacheControl headers to host the application.",
      "C": "Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.",
      "D": "Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application."
    },
    "correct_answer": "A",
    "vote_percentage": "65%",
    "question_cn": "一家公司希望在 AWS 上托管一个可扩展的 Web 应用程序。该应用程序将由来自世界不同地理区域的用户访问。应用程序用户将能够下载和上传大小高达千兆字节的唯一数据。开发团队希望有一个经济高效的解决方案，以最大限度地减少上传和下载延迟并最大限度地提高性能。解决方案架构师应该怎么做才能实现这一目标？",
    "options_cn": {
      "A": "使用 Amazon S3 以及 S3 Transfer Acceleration 来托管应用程序。",
      "B": "使用 Amazon S3 以及 CacheControl 标头来托管应用程序。",
      "C": "使用 Amazon EC2 以及 Auto Scaling 和 Amazon CloudFront 来托管应用程序。",
      "D": "使用 Amazon EC2 以及 Auto Scaling 和 Amazon ElastiCache 来托管应用程序。"
    }
  },
  {
    "id": 444,
    "topic": "1",
    "question_en": "A company has hired a solutions architect to design a reliable architecture for its application. The application consists of one Amazon RDS DB instance and two manually provisioned Amazon EC2 instances that run web servers. The EC2 instances are located in a single Availability Zone. An employee recently deleted the DB instance, and the application was unavailable for 24 hours as a result. The company is concerned with the overall reliability of its environment. What should the solutions architect do to maximize reliability of the application's infrastructure?",
    "options_en": {
      "A": "Delete one EC2 instance and enable termination protection on the other EC2 instance. Update the DB instance to be Multi-AZ, and enable deletion protection.",
      "B": "Update the DB instance to be Multi-AZ, and enable deletion protection. Place the EC2 instances behind an Application Load Balancer, and run them in an EC2 Auto Scaling group across multiple Availability Zones.",
      "C": "Create an additional DB instance along with an Amazon API Gateway and an AWS Lambda function. Configure the application to invoke the Lambda function through API Gateway. Have the Lambda function write the data to the two DB instances.",
      "D": "Place the EC2 instances in an EC2 Auto Scaling group that has multiple subnets located in multiple Availability Zones. Use Spot Instances instead of On-Demand Instances. Set up Amazon CloudWatch alarms to monitor the health of the instances Update the DB instance to be Multi-AZ, and enable deletion protection."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司聘请了一位解决方案架构师来为其应用程序设计可靠的架构。 该应用程序由一个 Amazon RDS 数据库实例和两个手动配置的运行 Web 服务器的 Amazon EC2 实例组成。 EC2 实例位于单个可用区中。 一名员工最近删除了数据库实例，导致应用程序停用 24 小时。 公司担心其环境的整体可靠性。 解决方案架构师应该怎么做才能最大限度地提高应用程序基础设施的可靠性？",
    "options_cn": {
      "A": "删除一个 EC2 实例，并在另一个 EC2 实例上启用终止保护。 将数据库实例更新为 Multi-AZ，并启用删除保护。",
      "B": "将数据库实例更新为 Multi-AZ，并启用删除保护。 将 EC2 实例放置在 Application Load Balancer 后面，并在多个可用区中运行 EC2 Auto Scaling 组。",
      "C": "创建另一个数据库实例以及一个 Amazon API Gateway 和一个 AWS Lambda 函数。 将应用程序配置为通过 API Gateway 调用 Lambda 函数。 让 Lambda 函数将数据写入两个数据库实例。",
      "D": "将 EC2 实例放置在具有多个子网的 EC2 Auto Scaling 组中，这些子网位于多个可用区中。 使用 Spot 实例而不是按需实例。 设置 Amazon CloudWatch 警报以监控实例的运行状况。 将数据库实例更新为 Multi-AZ，并启用删除保护。"
    }
  },
  {
    "id": 445,
    "topic": "1",
    "question_en": "A company is storing 700 terabytes of data on a large network-attached storage (NAS) system in its corporate data center. The company has a hybrid environment with a 10 Gbps AWS Direct Connect connection. After an audit from a regulator, the company has 90 days to move the data to the cloud. The company needs to move the data eficiently and without disruption. The company still needs to be able to access and update the data during the transfer window. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an AWS DataSync agent in the corporate data center. Create a data transfer task Start the transfer to an Amazon S3 bucket.",
      "B": "Back up the data to AWS Snowball Edge Storage Optimized devices. Ship the devices to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.",
      "C": "Use rsync to copy the data directly from local storage to a designated Amazon S3 bucket over the Direct Connect connection.",
      "D": "Back up the data on tapes. Ship the tapes to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司将其 700 TB 的数据存储在其公司数据中心的大型网络附加存储 (NAS) 系统上。该公司拥有混合环境，具有 10 Gbps 的 AWS Direct Connect 连接。在监管机构的审计之后，该公司有 90 天的时间将数据迁移到云端。该公司需要高效地迁移数据且不中断。该公司在传输窗口期间仍然需要能够访问和更新数据。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在公司数据中心创建 AWS DataSync 代理。创建一个数据传输任务。开始传输到 Amazon S3 存储桶。",
      "B": "将数据备份到 AWS Snowball Edge 存储优化设备。将设备运送到 AWS 数据中心。在本地文件系统上挂载一个目标 Amazon S3 存储桶。",
      "C": "使用 rsync 通过 Direct Connect 连接将数据直接从本地存储复制到指定的 Amazon S3 存储桶。",
      "D": "将数据备份到磁带上。将磁带运送到 AWS 数据中心。在本地文件系统上挂载一个目标 Amazon S3 存储桶。"
    }
  },
  {
    "id": 446,
    "topic": "1",
    "question_en": "A company stores data in PDF format in an Amazon S3 bucket. The company must follow a legal requirement to retain all new and existing data in Amazon S3 for 7 years. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Turn on the S3 Versioning feature for the S3 bucket. Configure S3 Lifecycle to delete the data after 7 years. Configure multi-factor authentication (MFA) delete for all S3 objects.",
      "B": "Turn on S3 Object Lock with governance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Recopy all existing objects to bring the existing data into compliance.",
      "C": "Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Recopy all existing objects to bring the existing data into compliance.",
      "D": "Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Use S3 Batch Operations to bring the existing data into compliance."
    },
    "correct_answer": "C",
    "vote_percentage": "83%",
    "question_cn": "一家公司将 PDF 格式的数据存储在 Amazon S3 存储桶中。该公司必须遵守法律要求，将 Amazon S3 中所有新的和现有数据保留 7 年。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "为 S3 存储桶打开 S3 版本控制功能。配置 S3 生命周期以在 7 年后删除数据。为所有 S3 对象配置多因素身份验证 (MFA) 删除。",
      "B": "为 S3 存储桶打开 S3 对象锁定，并使用治理保留模式。将保留期设置为 7 年后到期。重新复制所有现有对象以使现有数据符合要求。",
      "C": "为 S3 存储桶打开 S3 对象锁定，并使用合规保留模式。将保留期设置为 7 年后到期。重新复制所有现有对象以使现有数据符合要求。",
      "D": "为 S3 存储桶打开 S3 对象锁定，并使用合规保留模式。将保留期设置为 7 年后到期。使用 S3 批量操作使现有数据符合要求。"
    }
  },
  {
    "id": 447,
    "topic": "1",
    "question_en": "A company has a stateless web application that runs on AWS Lambda functions that are invoked by Amazon API Gateway. The company wants to deploy the application across multiple AWS Regions to provide Regional failover capabilities. What should a solutions architect do to route trafic to multiple Regions?",
    "options_en": {
      "A": "Create Amazon Route 53 health checks for each Region. Use an active-active failover configuration.",
      "B": "Create an Amazon CloudFront distribution with an origin for each Region. Use CloudFront health checks to route trafic.",
      "C": "Create a transit gateway. Attach the transit gateway to the API Gateway endpoint in each Region. Configure the transit gateway to route requests.",
      "D": "Create an Application Load Balancer in the primary Region. Set the target group to point to the API Gateway endpoint hostnames in each Region."
    },
    "correct_answer": "A",
    "vote_percentage": "87%",
    "question_cn": "一家公司有一个无状态的 Web 应用程序，该应用程序在由 Amazon API Gateway 调用的 AWS Lambda 函数上运行。该公司希望跨多个 AWS 区域部署该应用程序，以提供区域故障转移功能。解决方案架构师应该怎么做才能将流量路由到多个区域？",
    "options_cn": {
      "A": "为每个区域创建 Amazon Route 53 运行状况检查。使用主动-主动故障转移配置。",
      "B": "创建一个 Amazon CloudFront 分发，其中包含每个区域的源。使用 CloudFront 运行状况检查来路由流量。",
      "C": "创建一个 transit gateway。将 transit gateway 附加到每个区域中的 API Gateway 端点。配置 transit gateway 以路由请求。",
      "D": "在主要区域创建一个 Application Load Balancer。将目标组设置为指向每个区域中的 API Gateway 端点主机名。"
    }
  },
  {
    "id": 448,
    "topic": "1",
    "question_en": "A company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center. The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications. What should a solutions architect do to mitigate any single point of failure in this architecture?",
    "options_en": {
      "A": "Add a set of VPNs between the Management and Production VPCs.",
      "B": "Add a second virtual private gateway and attach it to the Management VPC.",
      "C": "Add a second set of VPNs to the Management VPC from a second customer gateway device.",
      "D": "Add a second VPC peering connection between the Management VPC and the Production VPC."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有两个名为 Management 和 Production 的 VPC。 Management VPC 通过客户网关使用 VPN 连接到数据中心中的单个设备。 Production VPC 使用一个虚拟私有网关，该网关连接了两个 AWS Direct Connect 连接。 Management 和 Production VPC 都使用单个 VPC 对等连接来允许应用程序之间的通信。 解决方案架构师应该怎么做以减轻此架构中的任何单点故障？",
    "options_cn": {
      "A": "在 Management 和 Production VPC 之间添加一组 VPN。",
      "B": "添加第二个虚拟私有网关并将其连接到 Management VPC。",
      "C": "从第二个客户网关设备向 Management VPC 添加第二组 VPN。",
      "D": "在 Management VPC 和 Production VPC 之间添加第二个 VPC 对等连接。"
    }
  },
  {
    "id": 449,
    "topic": "1",
    "question_en": "A company runs its application on an Oracle database. The company plans to quickly migrate to AWS because of limited resources for the database, backup administration, and data center maintenance. The application uses third-party database features that require privileged access. Which solution will help the company migrate the database to AWS MOST cost-effectively?",
    "options_en": {
      "A": "Migrate the database to Amazon RDS for Oracle. Replace third-party features with cloud services.",
      "B": "Migrate the database to Amazon RDS Custom for Oracle. Customize the database settings to support third-party features.",
      "C": "Migrate the database to an Amazon EC2 Amazon Machine Image (AMI) for Oracle. Customize the database settings to support third- party features.",
      "D": "Migrate the database to Amazon RDS for PostgreSQL by rewriting the application code to remove dependency on Oracle APEX."
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "一家公司在其应用程序上运行 Oracle 数据库。由于数据库、备份管理和数据中心维护的资源有限，该公司计划快速迁移到 AWS。该应用程序使用需要特权访问的第三方数据库功能。哪种解决方案将帮助该公司以最具成本效益的方式将数据库迁移到 AWS？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon RDS for Oracle。用云服务替换第三方功能。",
      "B": "将数据库迁移到 Amazon RDS Custom for Oracle。自定义数据库设置以支持第三方功能。",
      "C": "将数据库迁移到 Amazon EC2 Amazon Machine Image (AMI) for Oracle。自定义数据库设置以支持第三方功能。",
      "D": "通过重写应用程序代码以删除对 Oracle APEX 的依赖性，将数据库迁移到 Amazon RDS for PostgreSQL。"
    }
  },
  {
    "id": 450,
    "topic": "1",
    "question_en": "A company has a three-tier web application that is in a single server. The company wants to migrate the application to the AWS Cloud. The company also wants the application to align with the AWS Well-Architected Framework and to be consistent with AWS recommended best practices for security, scalability, and resiliency. Which combination of solutions will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Create a VPC across two Availability Zones with the application's existing architecture. Host the application with existing architecture on an Amazon EC2 instance in a private subnet in each Availability Zone with EC2 Auto Scaling groups. Secure the EC2 instance with security groups and network access control lists (network ACLs).",
      "B": "Set up security groups and network access control lists (network ACLs) to control access to the database layer. Set up a single Amazon RDS database in a private subnet.",
      "C": "Create a VPC across two Availability Zones. Refactor the application to host the web tier, application tier, and database tier. Host each tier on its own private subnet with Auto Scaling groups for the web tier and application tier.",
      "D": "Use a single Amazon RDS databas",
      "E": "Allow database access only from the application tier security group. E. Use Elastic Load Balancers in front of the web tier. Control access by using security groups containing references to each layer's security groups",
      "F": "Use an Amazon RDS database Multi-AZ cluster deployment in private subnets. Allow database access only from application tier security groups."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司有一个三层 Web 应用程序，该应用程序位于单个服务器上。该公司希望将应用程序迁移到 AWS 云。该公司还希望应用程序与 AWS 架构完善框架保持一致，并与 AWS 推荐的安全、可扩展性和弹性最佳实践保持一致。哪种解决方案组合将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "在两个可用区之间创建一个 VPC，并使用应用程序的现有架构。使用现有架构在每个可用区中的私有子网中的 Amazon EC2 实例上托管应用程序，并使用 EC2 Auto Scaling 组。使用安全组和网络访问控制列表（网络 ACL）保护 EC2 实例。",
      "B": "设置安全组和网络访问控制列表（网络 ACL）以控制对数据库层的访问。在私有子网中设置单个 Amazon RDS 数据库。",
      "C": "在两个可用区之间创建一个 VPC。重构应用程序以托管 Web 层、应用程序层和数据库层。将每一层托管在其自己的私有子网中，并为 Web 层和应用程序层配置 Auto Scaling 组。",
      "D": "使用单个 Amazon RDS 数据库。仅允许从应用程序层安全组访问数据库。",
      "E": "在 Web 层前面使用 Elastic Load Balancer。通过使用包含对每一层安全组引用的安全组来控制访问。",
      "F": "在私有子网中使用 Amazon RDS 数据库 Multi-AZ 集群部署。仅允许从应用程序层安全组访问数据库。"
    }
  },
  {
    "id": 451,
    "topic": "1",
    "question_en": "A company is migrating its applications and databases to the AWS Cloud. The company will use Amazon Elastic Container Service (Amazon ECS), AWS Direct Connect, and Amazon RDS. Which activities will be managed by the company's operational team? (Choose three.)",
    "options_en": {
      "A": "Management of the Amazon RDS infrastructure layer, operating system, and platforms",
      "B": "Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window",
      "C": "Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection",
      "D": "Installation of patches for all minor and major database versions for Amazon RDS",
      "E": "Ensure the physical security of the Amazon RDS infrastructure in the data center",
      "F": "Encryption of the data that moves in transit through Direct Connect"
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其应用程序和数据库迁移到 AWS 云。该公司将使用 Amazon Elastic Container Service (Amazon ECS)、AWS Direct Connect 和 Amazon RDS。公司的运营团队将管理哪些活动？（选择三个。）",
    "options_cn": {
      "A": "管理 Amazon RDS 基础设施层、操作系统和平台",
      "B": "创建 Amazon RDS 数据库实例并配置计划维护窗口",
      "C": "在 Amazon ECS 上配置额外的软件组件，用于监控、补丁管理、日志管理和主机入侵检测",
      "D": "为 Amazon RDS 安装所有次要和主要数据库版本的补丁",
      "E": "确保数据中心内 Amazon RDS 基础设施的物理安全",
      "F": "加密通过 Direct Connect 传输的数据"
    }
  },
  {
    "id": 452,
    "topic": "1",
    "question_en": "A company runs a Java-based job on an Amazon EC2 instance. The job runs every hour and takes 10 seconds to run. The job runs on a scheduled interval and consumes 1 GB of memory. The CPU utilization of the instance is low except for short surges during which the job uses the maximum CPU available. The company wants to optimize the costs to run the job. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS App2Container (A2C) to containerize the job. Run the job as an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate with 0.5 virtual CPU (vCPU) and 1 GB of memory.",
      "B": "Copy the code into an AWS Lambda function that has 1 GB of memory. Create an Amazon EventBridge scheduled rule to run the code each hour.",
      "C": "Use AWS App2Container (A2C) to containerize the job. Install the container in the existing Amazon Machine Image (AMI). Ensure that the schedule stops the container when the task finishes.",
      "D": "Configure the existing schedule to stop the EC2 instance at the completion of the job and restart the EC2 instance when the next job starts."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Amazon EC2 实例上运行一个基于 Java 的作业。该作业每小时运行一次，需要 10 秒钟。该作业在预定的时间间隔内运行，并消耗 1 GB 内存。除了作业使用最大可用 CPU 的短时峰值外，实例的 CPU 利用率较低。该公司希望优化运行该作业的成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS App2Container (A2C) 将作业容器化。在 AWS Fargate 上将该作业作为 Amazon Elastic Container Service (Amazon ECS) 任务运行，配置 0.5 个虚拟 CPU (vCPU) 和 1 GB 内存。",
      "B": "将代码复制到具有 1 GB 内存的 AWS Lambda 函数中。创建一个 Amazon EventBridge 计划规则，以便每小时运行代码。",
      "C": "使用 AWS App2Container (A2C) 将作业容器化。将容器安装在现有的 Amazon Machine Image (AMI) 中。确保该计划在任务完成后停止容器。",
      "D": "配置现有计划，以便在作业完成后停止 EC2 实例，并在下一个作业开始时重新启动 EC2 实例。"
    }
  },
  {
    "id": 453,
    "topic": "1",
    "question_en": "A company wants to implement a backup strategy for Amazon EC2 data and multiple Amazon S3 buckets. Because of regulatory requirements, the company must retain backup files for a specific time period. The company must not alter the files for the duration of the retention period. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Backup to create a backup vault that has a vault lock in governance mode. Create the required backup plan.",
      "B": "Use Amazon Data Lifecycle Manager to create the required automated snapshot policy.",
      "C": "Use Amazon S3 File Gateway to create the backup. Configure the appropriate S3 Lifecycle management.",
      "D": "Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望为其 Amazon EC2 数据和多个 Amazon S3 存储桶实施备份策略。由于监管要求，该公司必须将备份文件保留一段特定的时间。在保留期内，公司不得更改文件。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Backup 创建一个备份库，该库在治理模式下具有库锁。创建所需的备份计划。",
      "B": "使用 Amazon Data Lifecycle Manager 创建所需的自动快照策略。",
      "C": "使用 Amazon S3 File Gateway 创建备份。配置适当的 S3 生命周期管理。",
      "D": "使用 AWS Backup 创建一个备份库，该库在合规模式下具有库锁。创建所需的备份计划。"
    }
  },
  {
    "id": 454,
    "topic": "1",
    "question_en": "A company has resources across multiple AWS Regions and accounts. A newly hired solutions architect discovers a previous employee did not provide details about the resources inventory. The solutions architect needs to build and map the relationship details of the various workloads across all accounts. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Use AWS Systems Manager Inventory to generate a map view from the detailed view report.",
      "B": "Use AWS Step Functions to collect workload details. Build architecture diagrams of the workloads manually.",
      "C": "Use Workload Discovery on AWS to generate architecture diagrams of the workloads.",
      "D": "Use AWS X-Ray to view the workload details. Build architecture diagrams with relationships."
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一家公司在多个 AWS 区域和账户中拥有资源。一位新聘用的解决方案架构师发现，之前的员工没有提供关于资源清单的详细信息。该解决方案架构师需要构建并映射所有账户中各种工作负载的关系细节。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Systems Manager Inventory 从详细视图报告生成地图视图。",
      "B": "使用 AWS Step Functions 收集工作负载详细信息。手动构建工作负载的架构图。",
      "C": "使用 AWS Workload Discovery 生成工作负载的架构图。",
      "D": "使用 AWS X-Ray 查看工作负载详细信息。构建具有关系的架构图。"
    }
  },
  {
    "id": 455,
    "topic": "1",
    "question_en": "A company uses AWS Organizations. The company wants to operate some of its AWS accounts with different budgets. The company wants to receive alerts and automatically prevent provisioning of additional resources on AWS accounts when the allocated budget threshold is met during a specific period. Which combination of solutions will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Use AWS Budgets to create a budget. Set the budget amount under the Cost and Usage Reports section of the required AWS accounts.",
      "B": "Use AWS Budgets to create a budget. Set the budget amount under the Billing dashboards of the required AWS accounts.",
      "C": "Create an IAM user for AWS Budgets to run budget actions with the required permissions.",
      "D": "Create an IAM role for AWS Budgets to run budget actions with the required permissions",
      "E": "Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources",
      "F": "Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司使用 AWS Organizations。该公司希望使用不同的预算来操作其部分 AWS 账户。当在特定时期内达到分配的预算阈值时，该公司希望接收警报并自动阻止在 AWS 账户上配置其他资源。哪些解决方案组合将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "使用 AWS Budgets 创建预算。在所需 AWS 账户的“成本和使用报告”部分设置预算金额。",
      "B": "使用 AWS Budgets 创建预算。在所需 AWS 账户的“计费控制面板”下设置预算金额。",
      "C": "为 AWS Budgets 创建一个 IAM 用户，以使用所需的权限运行预算操作。",
      "D": "为 AWS Budgets 创建一个 IAM 角色，以使用所需的权限运行预算操作。",
      "E": "添加警报，在每个账户达到其预算阈值时通知公司。添加一个预算操作，该操作选择使用适当的配置规则创建的 IAM 身份，以防止配置其他资源。",
      "F": "添加警报，在每个账户达到其预算阈值时通知公司。添加一个预算操作，该操作选择使用适当的服务控制策略 (SCP) 创建的 IAM 身份，以防止配置其他资源。"
    }
  },
  {
    "id": 456,
    "topic": "1",
    "question_en": "A company runs applications on Amazon EC2 instances in one AWS Region. The company wants to back up the EC2 instances to a second Region. The company also wants to provision EC2 resources in the second Region and manage the EC2 instances centrally from one AWS account. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region. Configure data replication.",
      "B": "Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.",
      "C": "Create a backup plan by using AWS Backup. Configure cross-Region backup to the second Region for the EC2 instances.",
      "D": "Deploy a similar number of EC2 instances in the second Region. Use AWS DataSync to transfer the data from the source Region to the second Region."
    },
    "correct_answer": "C",
    "vote_percentage": "79%",
    "question_cn": "一家公司在一个 AWS 区域的 Amazon EC2 实例上运行应用程序。该公司希望将 EC2 实例备份到第二个区域。该公司还希望在第二个区域配置 EC2 资源，并从一个 AWS 账户集中管理 EC2 实例。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "创建一个灾难恢复 (DR) 计划，该计划在第二个区域具有相似数量的 EC2 实例。配置数据复制。",
      "B": "创建 EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 时间点快照。定期将快照复制到第二个区域。",
      "C": "使用 AWS Backup 创建一个备份计划。为 EC2 实例配置跨区域备份到第二个区域。",
      "D": "在第二个区域部署相似数量的 EC2 实例。使用 AWS DataSync 将数据从源区域传输到第二个区域。"
    }
  },
  {
    "id": 457,
    "topic": "1",
    "question_en": "A company that uses AWS is building an application to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to authenticate application users while the users use the application to transfer data. The company must use Applicability Statement 2 (AS2) protocol. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication.",
      "B": "Use Amazon AppFlow fiows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.",
      "C": "Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.",
      "D": "Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication."
    },
    "correct_answer": "C",
    "vote_percentage": "86%",
    "question_cn": "一家使用 AWS 的公司正在构建一个应用程序，用于将数据传输给产品制造商。该公司拥有自己的身份提供商 (IdP)。该公司希望 IdP 对应用程序用户进行身份验证，同时用户使用该应用程序传输数据。该公司必须使用 Applicability Statement 2 (AS2) 协议。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 传输数据。创建一个 AWS Lambda 函数进行 IdP 身份验证。",
      "B": "使用 Amazon AppFlow 流传输数据。创建一个 Amazon Elastic Container Service (Amazon ECS) 任务进行 IdP 身份验证。",
      "C": "使用 AWS Transfer Family 传输数据。创建一个 AWS Lambda 函数进行 IdP 身份验证。",
      "D": "使用 AWS Storage Gateway 传输数据。创建一个 Amazon Cognito 身份池进行 IdP 身份验证。"
    }
  },
  {
    "id": 458,
    "topic": "1",
    "question_en": "A solutions architect is designing a RESTAPI in Amazon API Gateway for a cash payback service. The application requires 1 GB of memory and 2 GB of storage for its computation resources. The application will require that the data is in a relational format. Which additional combination ofAWS services will meet these requirements with the LEAST administrative effort? (Choose two.)",
    "options_en": {
      "A": "Amazon EC2",
      "B": "AWS Lambda",
      "C": "Amazon RDS",
      "D": "Amazon DynamoDB",
      "E": "Amazon Elastic Kubernetes Services (Amazon EKS)"
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一个解决方案架构师正在为现金返还服务设计 Amazon API Gateway 中的 REST API。该应用程序需要 1 GB 内存和 2 GB 存储空间用于其计算资源。 该应用程序将要求数据采用关系格式。 哪种额外的 AWS 服务组合将以最少的管理工作量满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "Amazon EC2",
      "B": "AWS Lambda",
      "C": "Amazon RDS",
      "D": "Amazon DynamoDB",
      "E": "Amazon Elastic Kubernetes Services (Amazon EKS)"
    }
  },
  {
    "id": 459,
    "topic": "1",
    "question_en": "A company uses AWS Organizations to run workloads within multiple AWS accounts. A tagging policy adds department tags to AWS resources when the company creates tags. An accounting team needs to determine spending on Amazon EC2 consumption. The accounting team must determine which departments are responsible for the costs regardless ofAWS account. The accounting team has access to AWS Cost Explorer for all AWS accounts within the organization and needs to access all reports from Cost Explorer. Which solution meets these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "From the Organizations management account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.",
      "B": "From the Organizations management account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.",
      "C": "From the Organizations member account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, and filter by EC2.",
      "D": "From the Organizations member account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS Organizations 在多个 AWS 账户中运行工作负载。当公司创建标签时，一个标签策略会将部门标签添加到 AWS 资源。一个会计团队需要确定 Amazon EC2 消耗的支出。会计团队必须确定哪些部门负责这些成本，而无论 AWS 账户如何。会计团队可以访问组织内的所有 AWS 账户的 AWS Cost Explorer，并需要访问 Cost Explorer 中的所有报告。哪种解决方案以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "从 Organizations 管理账户的账单控制台，激活一个名为 department 的用户定义成本分配标签。在 Cost Explorer 中创建一个成本报告，按标签名称分组，并按 EC2 筛选。",
      "B": "从 Organizations 管理账户的账单控制台，激活一个名为 department 的 AWS 定义成本分配标签。在 Cost Explorer 中创建一个成本报告，按标签名称分组，并按 EC2 筛选。",
      "C": "从 Organizations 成员账户的账单控制台，激活一个名为 department 的用户定义成本分配标签。在 Cost Explorer 中创建一个成本报告，按标签名称分组，并按 EC2 筛选。",
      "D": "从 Organizations 成员账户的账单控制台，激活一个名为 department 的 AWS 定义成本分配标签。在 Cost Explorer 中创建一个成本报告，按标签名称分组，并按 EC2 筛选。"
    }
  },
  {
    "id": 460,
    "topic": "1",
    "question_en": "A company wants to securely exchange data between its software as a service (SaaS) application Salesforce account and Amazon S3. The company must encrypt the data at rest by using AWS Key Management Service (AWS KMS) customer managed keys (CMKs). The company must also encrypt the data in transit. The company has enabled API access for the Salesforce account.",
    "options_en": {
      "A": "Create AWS Lambda functions to transfer the data securely from Salesforce to Amazon S3.",
      "B": "Create an AWS Step Functions workfiow. Define the task to transfer the data securely from Salesforce to Amazon S3.",
      "C": "Create Amazon AppFlow fiows to transfer the data securely from Salesforce to Amazon S3.",
      "D": "Create a custom connector for Salesforce to transfer the data securely from Salesforce to Amazon S3."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在其软件即服务 (SaaS) 应用程序 Salesforce 帐户和 Amazon S3 之间安全地交换数据。该公司必须使用 AWS Key Management Service (AWS KMS) 客户托管密钥 (CMK) 加密静态数据。该公司还必须加密传输中的数据。该公司已为 Salesforce 帐户启用了 API 访问。",
    "options_cn": {
      "A": "创建 AWS Lambda 函数以将数据从 Salesforce 安全地传输到 Amazon S3。",
      "B": "创建一个 AWS Step Functions 工作流程。定义将数据从 Salesforce 安全地传输到 Amazon S3 的任务。",
      "C": "创建 Amazon AppFlow 流以将数据从 Salesforce 安全地传输到 Amazon S3。",
      "D": "为 Salesforce 创建一个自定义连接器，以安全地将数据从 Salesforce 传输到 Amazon S3。"
    }
  },
  {
    "id": 461,
    "topic": "1",
    "question_en": "A company is developing a mobile gaming app in a single AWS Region. The app runs on multiple Amazon EC2 instances in an Auto Scaling group. The company stores the app data in Amazon DynamoDB. The app communicates by using TCP trafic and UDP trafic between the users and the servers. The application will be used globally. The company wants to ensure the lowest possible latency for all users. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Global Accelerator to create an accelerator. Create an Application Load Balancer (ALB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB.",
      "B": "Use AWS Global Accelerator to create an accelerator. Create a Network Load Balancer (NLB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB.",
      "C": "Create an Amazon CloudFront content delivery network (CDN) endpoint. Create a Network Load Balancer (NLB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB. Update CloudFront to use the NLB as the origin.",
      "D": "Create an Amazon CloudFront content delivery network (CDN) endpoint. Create an Application Load Balancer (ALB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB. Update CloudFront to use the ALB as the origin."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在单个 AWS 区域中开发移动游戏应用程序。该应用程序在 Auto Scaling 组中的多个 Amazon EC2 实例上运行。该公司将应用程序数据存储在 Amazon DynamoDB 中。该应用程序通过使用 TCP 和 UDP 流量在用户和服务器之间进行通信。该应用程序将在全球范围内使用。该公司希望确保所有用户的延迟尽可能低。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Global Accelerator 创建一个加速器。在加速器端点后面创建一个 Application Load Balancer (ALB)，该端点使用 Global Accelerator 集成并在 TCP 和 UDP 端口上侦听。更新 Auto Scaling 组以在 ALB 上注册实例。",
      "B": "使用 AWS Global Accelerator 创建一个加速器。在加速器端点后面创建一个 Network Load Balancer (NLB)，该端点使用 Global Accelerator 集成并在 TCP 和 UDP 端口上侦听。更新 Auto Scaling 组以在 NLB 上注册实例。",
      "C": "创建一个 Amazon CloudFront 内容分发网络 (CDN) 端点。在端点后面创建一个 Network Load Balancer (NLB)，并在 TCP 和 UDP 端口上侦听。更新 Auto Scaling 组以在 NLB 上注册实例。更新 CloudFront 以使用 NLB 作为源。",
      "D": "创建一个 Amazon CloudFront 内容分发网络 (CDN) 端点。在端点后面创建一个 Application Load Balancer (ALB)，并在 TCP 和 UDP 端口上侦听。更新 Auto Scaling 组以在 ALB 上注册实例。更新 CloudFront 以使用 ALB 作为源。"
    }
  },
  {
    "id": 462,
    "topic": "1",
    "question_en": "A company has an application that processes customer orders. The company hosts the application on an Amazon EC2 instance that saves the orders to an Amazon Aurora database. Occasionally when trafic is high the workload does not process orders fast enough. What should a solutions architect do to write the orders reliably to the database as quickly as possible?",
    "options_en": {
      "A": "Increase the instance size of the EC2 instance when trafic is high. Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic.",
      "B": "Write orders to an Amazon Simple Queue Service (Amazon SQS) queue. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database.",
      "C": "Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SNS topic.",
      "D": "Write orders to an Amazon Simple Queue Service (Amazon SQS) queue when the EC2 instance reaches CPU threshold limits. Use scheduled scaling of EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个处理客户订单的应用程序。该公司将该应用程序托管在 Amazon EC2 实例上，该实例将订单保存到 Amazon Aurora 数据库。偶尔，当流量很高时，工作负载无法足够快地处理订单。解决方案架构师应该怎么做才能尽快可靠地将订单写入数据库？",
    "options_cn": {
      "A": "当流量很高时，增加 EC2 实例的大小。将订单写入 Amazon Simple Notification Service (Amazon SNS)。将数据库端点订阅到 SNS 主题。",
      "B": "将订单写入 Amazon Simple Queue Service (Amazon SQS) 队列。使用 Auto Scaling 组中的 EC2 实例（位于 Application Load Balancer 之后）从 SQS 队列中读取并将订单处理到数据库中。",
      "C": "将订单写入 Amazon Simple Notification Service (Amazon SNS)。将数据库端点订阅到 SNS 主题。使用 Auto Scaling 组中的 EC2 实例（位于 Application Load Balancer 之后）从 SNS 主题中读取。",
      "D": "当 EC2 实例达到 CPU 阈值限制时，将订单写入 Amazon Simple Queue Service (Amazon SQS) 队列。使用 Auto Scaling 组中的 EC2 实例（位于 Application Load Balancer 之后）的计划缩放，以从 SQS 队列中读取并将订单处理到数据库中。"
    }
  },
  {
    "id": 463,
    "topic": "1",
    "question_en": "An IoT company is releasing a mattress that has sensors to collect data about a user’s sleep. The sensors will send data to an Amazon S3 bucket. The sensors collect approximately 2 MB of data every night for each mattress. The company must process and summarize the data for each mattress. The results need to be available as soon as possible. Data processing will require 1 GB of memory and will finish within 30 seconds. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use AWS Glue with a Scala job",
      "B": "Use Amazon EMR with an Apache Spark script",
      "C": "Use AWS Lambda with a Python script",
      "D": "Use AWS Glue with a PySpark job"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家物联网公司正在发布一款带有传感器的床垫，用于收集有关用户睡眠的数据。传感器将把数据发送到 Amazon S3 存储桶。传感器每晚为每个床垫收集大约 2 MB 的数据。该公司必须处理和汇总每个床垫的数据。结果需要尽快可用。数据处理将需要 1 GB 的内存，并在 30 秒内完成。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Glue 和一个 Scala 作业",
      "B": "使用 Amazon EMR 和一个 Apache Spark 脚本",
      "C": "使用 AWS Lambda 和一个 Python 脚本",
      "D": "使用 AWS Glue 和一个 PySpark 作业"
    }
  },
  {
    "id": 464,
    "topic": "1",
    "question_en": "A company hosts an online shopping application that stores all orders in an Amazon RDS for PostgreSQL Single-AZ DB instance. Management wants to eliminate single points of failure and has asked a solutions architect to recommend an approach to minimize database downtime without requiring any changes to the application code. Which solution meets these requirements?",
    "options_en": {
      "A": "Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.",
      "B": "Create a new RDS Multi-AZ deployment. Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot.",
      "C": "Create a read-only replica of the PostgreSQL database in another Availability Zone. Use Amazon Route 53 weighted record sets to distribute requests across the databases.",
      "D": "Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two. Use Amazon Route 53 weighted record sets to distribute requests across instances."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管了一个在线购物应用程序，该应用程序将所有订单存储在 Amazon RDS for PostgreSQL 单可用区数据库实例中。管理层希望消除单点故障，并要求解决方案架构师推荐一种方法，以最大限度地减少数据库停机时间，而无需对应用程序代码进行任何更改。哪个解决方案符合这些要求？",
    "options_cn": {
      "A": "通过修改数据库实例并指定多可用区选项，将现有的数据库实例转换为多可用区部署。",
      "B": "创建一个新的 RDS 多可用区部署。拍摄当前 RDS 实例的快照，并使用该快照还原新的多可用区部署。",
      "C": "在另一个可用区中创建 PostgreSQL 数据库的只读副本。使用 Amazon Route 53 加权记录集将请求分发到各个数据库。",
      "D": "将 RDS for PostgreSQL 数据库放置在 Amazon EC2 自动伸缩组中，最小组大小为两个。使用 Amazon Route 53 加权记录集将请求分发到各个实例。"
    }
  },
  {
    "id": 465,
    "topic": "1",
    "question_en": "A company is developing an application to support customer demands. The company wants to deploy the application on multiple Amazon EC2 Nitro-based instances within the same Availability Zone. The company also wants to give the application the ability to write to multiple block storage volumes in multiple EC2 Nitro-based instances simultaneously to achieve higher application availability. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use General Purpose SSD (gp3) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "B": "Use Throughput Optimized HDD (st1) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "C": "Use Provisioned IOPS SSD (io2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "D": "Use General Purpose SSD (gp2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach"
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "一家公司正在开发一个应用程序以支持客户需求。该公司希望将应用程序部署在同一可用区内的多个 Amazon EC2 Nitro 实例上。该公司还希望让应用程序能够同时写入多个 EC2 Nitro 实例中的多个块存储卷，以实现更高的应用程序可用性。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用通用型 SSD (gp3) EBS 卷和 Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "B": "使用吞吐量优化 HDD (st1) EBS 卷和 Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "C": "使用预置 IOPS SSD (io2) EBS 卷和 Amazon Elastic Block Store (Amazon EBS) Multi-Attach",
      "D": "使用通用型 SSD (gp2) EBS 卷和 Amazon Elastic Block Store (Amazon EBS) Multi-Attach"
    }
  },
  {
    "id": 466,
    "topic": "1",
    "question_en": "A company designed a stateless two-tier application that uses Amazon EC2 in a single Availability Zone and an Amazon RDS Multi-AZ DB instance. New company management wants to ensure the application is highly available. What should a solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Configure the application to use Multi-AZ EC2 Auto Scaling and create an Application Load Balancer",
      "B": "Configure the application to take snapshots of the EC2 instances and send them to a different AWS Region",
      "C": "Configure the application to use Amazon Route 53 latency-based routing to feed requests to the application",
      "D": "Configure Amazon Route 53 rules to handle incoming requests and create a Multi-AZ Application Load Balancer"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司设计了一个无状态的两层应用程序，该应用程序在一个可用区中使用 Amazon EC2 和一个 Amazon RDS Multi-AZ 数据库实例。新的公司管理层希望确保该应用程序具有高可用性。 解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "配置应用程序以使用 Multi-AZ EC2 Auto Scaling 并创建一个 Application Load Balancer。",
      "B": "配置应用程序以拍摄 EC2 实例的快照并将它们发送到不同的 AWS 区域。",
      "C": "配置应用程序以使用 Amazon Route 53 基于延迟的路由来将请求提供给应用程序。",
      "D": "配置 Amazon Route 53 规则以处理传入请求并创建一个 Multi-AZ Application Load Balancer。"
    }
  },
  {
    "id": 467,
    "topic": "1",
    "question_en": "A company uses AWS Organizations. A member account has purchased a Compute Savings Plan. Because of changes in the workloads inside the member account, the account no longer receives the full benefit of the Compute Savings Plan commitment. The company uses less than 50% of its purchased compute power.",
    "options_en": {
      "A": "Turn on discount sharing from the Billing Preferences section of the account console in the member account that purchased the Compute Savings Plan.",
      "B": "Turn on discount sharing from the Billing Preferences section of the account console in the company's Organizations management account.",
      "C": "Migrate additional compute workloads from another AWS account to the account that has the Compute Savings Plan.",
      "D": "Sell the excess Savings Plan commitment in the Reserved Instance Marketplace."
    },
    "correct_answer": "B",
    "vote_percentage": "68%",
    "question_cn": "一家公司使用 AWS Organizations。一个成员账户购买了 Compute Savings Plan。由于成员账户内工作负载的变化，该账户不再完全受益于 Compute Savings Plan 承诺。该公司使用了其购买的计算能力的 50% 以下。",
    "options_cn": {
      "A": "从购买 Compute Savings Plan 的成员账户控制台的 Billing Preferences 部分打开折扣共享。",
      "B": "从该公司 Organizations 管理账户控制台的 Billing Preferences 部分打开折扣共享。",
      "C": "将其他 AWS 账户中的计算工作负载迁移到拥有 Compute Savings Plan 的账户。",
      "D": "在 Reserved Instance Marketplace 中出售多余的 Savings Plan 承诺。"
    }
  },
  {
    "id": 468,
    "topic": "1",
    "question_en": "A company is developing a microservices application that will provide a search catalog for customers. The company must use REST APIs to present the frontend of the application to users. The REST APIs must access the backend services that the company hosts in containers in private VPC subnets. Which solution will meet these requirements?",
    "options_en": {
      "A": "Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.",
      "B": "Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.",
      "C": "Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS.",
      "D": "Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在开发一个微服务应用程序，该应用程序将为客户提供搜索目录。该公司必须使用 REST API 向用户呈现应用程序的前端。REST API 必须访问该公司在私有 VPC 子网中的容器中托管的后端服务。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon API Gateway 设计 WebSocket API。在私有子网中的 Amazon Elastic Container Service (Amazon ECS) 中托管应用程序。为 API Gateway 创建一个私有 VPC 链接以访问 Amazon ECS。",
      "B": "使用 Amazon API Gateway 设计 REST API。在私有子网中的 Amazon Elastic Container Service (Amazon ECS) 中托管应用程序。为 API Gateway 创建一个私有 VPC 链接以访问 Amazon ECS。",
      "C": "使用 Amazon API Gateway 设计 WebSocket API。在私有子网中的 Amazon Elastic Container Service (Amazon ECS) 中托管应用程序。为 API Gateway 创建一个安全组，供 API Gateway 访问 Amazon ECS。",
      "D": "使用 Amazon API Gateway 设计 REST API。在私有子网中的 Amazon Elastic Container Service (Amazon ECS) 中托管应用程序。为 API Gateway 创建一个安全组，供 API Gateway 访问 Amazon ECS。"
    }
  },
  {
    "id": 469,
    "topic": "1",
    "question_en": "A company stores raw collected data in an Amazon S3 bucket. The data is used for several types of analytics on behalf of the company's customers. The type of analytics requested determines the access pattern on the S3 objects. The company cannot predict or control the access pattern. The company wants to reduce its S3 costs. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use S3 replication to transition infrequently accessed objects to S3 Standard-Infrequent Access (S3 Standard-IA)",
      "B": "Use S3 Lifecycle rules to transition objects from S3 Standard to Standard-Infrequent Access (S3 Standard-IA)",
      "C": "Use S3 Lifecycle rules to transition objects from S3 Standard to S3 Intelligent-Tiering",
      "D": "Use S3 Inventory to identify and transition objects that have not been accessed from S3 Standard to S3 Intelligent-Tiering"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司将其收集的原始数据存储在 Amazon S3 存储桶中。这些数据用于代表公司客户进行多种类型的分析。请求的分析类型决定了对 S3 对象的访问模式。该公司无法预测或控制访问模式。该公司希望降低其 S3 成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 S3 复制将不经常访问的对象转换为 S3 标准 - 不频繁访问 (S3 Standard-IA)",
      "B": "使用 S3 生命周期规则将对象从 S3 标准转换为 S3 标准 - 不频繁访问 (S3 Standard-IA)",
      "C": "使用 S3 生命周期规则将对象从 S3 标准转换为 S3 Intelligent-Tiering",
      "D": "使用 S3 清单来识别未从 S3 标准访问的对象并将其转换为 S3 Intelligent-Tiering"
    }
  },
  {
    "id": 470,
    "topic": "1",
    "question_en": "A company has applications hosted on Amazon EC2 instances with IPv6 addresses. The applications must initiate communications with other external applications using the internet. However the company’s security policy states that any external service cannot initiate a connection to the EC2 instances. What should a solutions architect recommend to resolve this issue?",
    "options_en": {
      "A": "Create a NAT gateway and make it the destination of the subnet's route table",
      "B": "Create an internet gateway and make it the destination of the subnet's route table",
      "C": "Create a virtual private gateway and make it the destination of the subnet's route table",
      "D": "Create an egress-only internet gateway and make it the destination of the subnet's route table"
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在具有 IPv6 地址的 Amazon EC2 实例上托管应用程序。这些应用程序必须使用互联网与其他外部应用程序发起通信。但是，公司的安全策略规定，任何外部服务都不能发起与 EC2 实例的连接。解决方案架构师应该建议什么来解决此问题？",
    "options_cn": {
      "A": "创建一个 NAT 网关，并将其作为子网路由表的目的地",
      "B": "创建一个互联网网关，并将其作为子网路由表的目的地",
      "C": "创建一个虚拟专用网关，并将其作为子网路由表的目的地",
      "D": "创建一个仅限出口的互联网网关，并将其作为子网路由表的目的地"
    }
  },
  {
    "id": 471,
    "topic": "1",
    "question_en": "A company is creating an application that runs on containers in a VPC. The application stores and accesses data in an Amazon S3 bucket. During the development phase, the application will store and access 1 TB of data in Amazon S3 each day. The company wants to minimize costs and wants to prevent trafic from traversing the internet whenever possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Enable S3 Intelligent-Tiering for the S3 bucket",
      "B": "Enable S3 Transfer Acceleration for the S3 bucket",
      "C": "Create a gateway VPC endpoint for Amazon S3. Associate this endpoint with all route tables in the VPC",
      "D": "Create an interface endpoint for Amazon S3 in the VPC. Associate this endpoint with all route tables in the VPC"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在创建一个在 VPC 中的容器上运行的应用程序。该应用程序将数据存储在 Amazon S3 存储桶中并访问数据。在开发阶段，该应用程序每天将在 Amazon S3 中存储和访问 1 TB 的数据。该公司希望最大限度地降低成本，并希望尽可能防止流量穿越互联网。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 S3 存储桶启用 S3 Intelligent-Tiering",
      "B": "为 S3 存储桶启用 S3 Transfer Acceleration",
      "C": "为 Amazon S3 创建一个网关 VPC endpoint。将此 endpoint 与 VPC 中的所有路由表关联",
      "D": "在 VPC 中为 Amazon S3 创建一个接口 endpoint。将此 endpoint 与所有路由表关联"
    }
  },
  {
    "id": 472,
    "topic": "1",
    "question_en": "A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes. Which method should the solutions architect select?",
    "options_en": {
      "A": "Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.",
      "B": "Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas.",
      "C": "Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.",
      "D": "Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司有一个基于 Amazon DynamoDB 的数据存储的移动聊天应用程序。 用户希望以尽可能低的延迟读取新消息。 解决方案架构师需要设计一个最佳解决方案，该方案需要最少的应用程序更改。 解决方案架构师应该选择哪种方法？",
    "options_cn": {
      "A": "为新消息表配置 Amazon DynamoDB Accelerator (DAX)。 更新代码以使用 DAX 终端节点。",
      "B": "添加 DynamoDB 读取副本以处理增加的读取负载。 更新应用程序以指向读取副本的读取终端节点。",
      "C": "将 DynamoDB 中新消息表的读取容量单元的数量增加一倍。 继续使用现有的 DynamoDB 终端节点。",
      "D": "在应用程序堆栈中添加 Amazon ElastiCache for Redis 缓存。 更新应用程序以指向 Redis 缓存终端节点而不是 DynamoDB。"
    }
  },
  {
    "id": 473,
    "topic": "1",
    "question_en": "A company hosts a website on Amazon EC2 instances behind an Application Load Balancer (ALB). The website serves static content. Website trafic is increasing, and the company is concerned about a potential increase in cost.",
    "options_en": {
      "A": "Create an Amazon CloudFront distribution to cache state files at edge locations",
      "B": "Create an Amazon ElastiCache cluster. Connect the ALB to the ElastiCache cluster to serve cached files",
      "C": "Create an AWS WAF web ACL and associate it with the ALB. Add a rule to the web ACL to cache static files",
      "D": "Create a second ALB in an alternative AWS Region. Route user trafic to the closest Region to minimize data transfer costs"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在Application Load Balancer (ALB) 之后，在Amazon EC2实例上托管一个网站。该网站提供静态内容。网站流量正在增加，该公司担心潜在的成本增加。",
    "options_cn": {
      "A": "创建一个Amazon CloudFront 分发，在边缘站点缓存静态文件。",
      "B": "创建一个Amazon ElastiCache 集群。将 ALB 连接到 ElastiCache 集群以提供缓存文件。",
      "C": "创建一个AWS WAF Web ACL 并将其与 ALB 关联。在 Web ACL 中添加一个规则来缓存静态文件。",
      "D": "在另一个 AWS 区域创建一个 ALB。将用户流量路由到最近的区域，以最大限度地减少数据传输成本。"
    }
  },
  {
    "id": 474,
    "topic": "1",
    "question_en": "A company has multiple VPCs across AWS Regions to support and run workloads that are isolated from workloads in other Regions. Because of a recent application launch requirement, the company’s VPCs must communicate with all other VPCs across all Regions. Which solution will meet these requirements with the LEAST amount of administrative effort?",
    "options_en": {
      "A": "Use VPC peering to manage VPC communication in a single Region. Use VPC peering across Regions to manage VPC communications.",
      "B": "Use AWS Direct Connect gateways across all Regions to connect VPCs across regions and manage VPC communications.",
      "C": "Use AWS Transit Gateway to manage VPC communication in a single Region and Transit Gateway peering across Regions to manage VPC communications.",
      "D": "Use AWS PrivateLink across all Regions to connect VPCs across Regions and manage VPC communications"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在多个 AWS 区域中拥有多个 VPC，以支持和运行与其他区域中的工作负载隔离的工作负载。由于最近的应用发布需求，公司的 VPC 必须与所有区域中的所有其他 VPC 通信。哪种解决方案将以最少的管理工作量满足这些要求？",
    "options_cn": {
      "A": "使用 VPC 对等连接来管理单个区域中的 VPC 通信。使用跨区域的 VPC 对等连接来管理 VPC 通信。",
      "B": "使用 AWS Direct Connect 网关跨所有区域连接 VPC 并管理 VPC 通信。",
      "C": "使用 AWS Transit Gateway 来管理单个区域中的 VPC 通信，并使用跨区域的 Transit Gateway 对等连接来管理 VPC 通信。",
      "D": "使用 AWS PrivateLink 跨所有区域连接 VPC 并管理 VPC 通信。"
    }
  },
  {
    "id": 475,
    "topic": "1",
    "question_en": "A company is designing a containerized application that will use Amazon Elastic Container Service (Amazon ECS). The application needs to access a shared file system that is highly durable and can recover data to another AWS Region with a recovery point objective (RPO) of 8 hours. The file system needs to provide a mount target m each Availability Zone within a Region. A solutions architect wants to use AWS Backup to manage the replication to another Region. Which solution will meet these requirements?",
    "options_en": {
      "A": "Amazon FSx for Windows File Server with a Multi-AZ deployment",
      "B": "Amazon FSx for NetApp ONTAP with a Multi-AZ deployment",
      "C": "Amazon Elastic File System (Amazon EFS) with the Standard storage class",
      "D": "Amazon FSx for OpenZFS"
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家公司正在设计一个容器化应用程序，该应用程序将使用 Amazon Elastic Container Service (Amazon ECS)。该应用程序需要访问一个共享文件系统，该文件系统具有高度的持久性，并且能够将数据恢复到另一个 AWS 区域，恢复点目标 (RPO) 为 8 小时。该文件系统需要在区域内的每个可用区中提供一个挂载目标。解决方案架构师希望使用 AWS Backup 来管理复制到另一个区域。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "Amazon FSx for Windows File Server，具有多可用区部署",
      "B": "Amazon FSx for NetApp ONTAP，具有多可用区部署",
      "C": "Amazon Elastic File System (Amazon EFS)，使用标准存储类",
      "D": "Amazon FSx for OpenZFS"
    }
  },
  {
    "id": 476,
    "topic": "1",
    "question_en": "A company is expecting rapid growth in the near future. A solutions architect needs to configure existing users and grant permissions to new users on AWS. The solutions architect has decided to create IAM groups. The solutions architect will add the new users to IAM groups based on department. Which additional action is the MOST secure way to grant permissions to the new users?",
    "options_en": {
      "A": "Apply service control policies (SCPs) to manage access permissions",
      "B": "Create IAM roles that have least privilege permission. Attach the roles to the IAM groups",
      "C": "Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups",
      "D": "Create IAM roles. Associate the roles with a permissions boundary that defines the maximum permissions"
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家公司预计在不久的将来会快速增长。一位解决方案架构师需要在 AWS 上配置现有用户并向新用户授予权限。解决方案架构师已决定创建 IAM 组。解决方案架构师将根据部门将新用户添加到 IAM 组。授予新用户权限的最安全方式是什么？",
    "options_cn": {
      "A": "应用服务控制策略 (SCPs) 来管理访问权限。",
      "B": "创建具有最小权限的 IAM 角色。将这些角色附加到 IAM 组。",
      "C": "创建授予最小权限的 IAM 策略。将该策略附加到 IAM 组。",
      "D": "创建 IAM 角色。将这些角色与定义最大权限的权限边界关联。"
    }
  },
  {
    "id": 477,
    "topic": "1",
    "question_en": "A group requires permissions to list an Amazon S3 bucket and delete objects from that bucket. An administrator has created the following IAM policy to provide access to the bucket and applied that policy to the group. The group is not able to delete objects in the bucket. The company follows least-privilege access rules. Which statement should a solutions architect add to the policy to correct bucket access?",
    "options_en": {
      "A": "",
      "B": "",
      "C": "",
      "D": ""
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一个团队需要列出 Amazon S3 存储桶并从中删除对象的权限。 一位管理员创建了以下 IAM 策略以提供对该存储桶的访问权限，并将该策略应用于该团队。 该团队无法删除存储桶中的对象。 公司遵循最小权限访问规则。 解决方案架构师应该向该策略添加哪条语句来纠正存储桶访问？",
    "options_cn": {
      "A": " ",
      "B": " ",
      "C": " ",
      "D": " "
    }
  },
  {
    "id": 478,
    "topic": "1",
    "question_en": "A law firm needs to share information with the public. The information includes hundreds of files that must be publicly readable. Modifications or deletions of the files by anyone before a designated future date are prohibited. Which solution will meet these requirements in the MOST secure way?",
    "options_en": {
      "A": "Upload all files to an Amazon S3 bucket that is configured for static website hosting. Grant read-only IAM permissions to any AWS principals that access the S3 bucket until the designated date.",
      "B": "Create a new Amazon S3 bucket with S3 Versioning enabled. Use S3 Object Lock with a retention period in accordance with the designated date. Configure the S3 bucket for static website hosting. Set an S3 bucket policy to allow read-only access to the objects.",
      "C": "Create a new Amazon S3 bucket with S3 Versioning enabled. Configure an event trigger to run an AWS Lambda function in case of object modification or deletion. Configure the Lambda function to replace the objects with the original versions from a private S3 bucket.",
      "D": "Upload all files to an Amazon S3 bucket that is configured for static website hosting. Select the folder that contains the files. Use S3 Object Lock with a retention period in accordance with the designated date. Grant read-only IAM permissions to any AWS principals that access the S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家律师事务所需要与公众共享信息。这些信息包括数百个必须公开可读的文件。在指定的未来日期之前，禁止任何人修改或删除文件。哪种解决方案将以最安全的方式满足这些要求？",
    "options_cn": {
      "A": "将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。在指定日期之前，向访问 S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。",
      "B": "创建一个新的 Amazon S3 存储桶，并启用 S3 版本控制。使用 S3 Object Lock 并设置保留期以符合指定日期。配置 S3 存储桶用于静态网站托管。设置一个 S3 存储桶策略以允许对对象进行只读访问。",
      "C": "创建一个新的 Amazon S3 存储桶，并启用 S3 版本控制。配置一个事件触发器，以便在对象修改或删除的情况下运行 AWS Lambda 函数。配置 Lambda 函数以用来自私有 S3 存储桶的原始版本替换这些对象。",
      "D": "将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。选择包含文件的文件夹。使用 S3 Object Lock 并设置保留期以符合指定日期。向访问 S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。"
    }
  },
  {
    "id": 479,
    "topic": "1",
    "question_en": "A company is making a prototype of the infrastructure for its new website by manually provisioning the necessary infrastructure. This infrastructure includes an Auto Scaling group, an Application Load Balancer and an Amazon RDS database. After the configuration has been thoroughly validated, the company wants the capability to immediately deploy the infrastructure for development and production use in two Availability Zones in an automated fashion. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Use AWS Systems Manager to replicate and provision the prototype infrastructure in two Availability Zones",
      "B": "Define the infrastructure as a template by using the prototype infrastructure as a guide. Deploy the infrastructure with AWS CloudFormation.",
      "C": "Use AWS Config to record the inventory of resources that are used in the prototype infrastructure. Use AWS Config to deploy the prototype infrastructure into two Availability Zones.",
      "D": "Use AWS Elastic Beanstalk and configure it to use an automated reference to the prototype infrastructure to automatically deploy new environments in two Availability Zones."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在通过手动配置必要的基础设施来构建其新网站的基础设施原型。此基础设施包括一个 Auto Scaling 组、一个 Application Load Balancer 和一个 Amazon RDS 数据库。在彻底验证配置后，该公司希望能够以自动化方式立即在两个可用区中部署开发和生产使用的基础设施。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Systems Manager 在两个可用区中复制和配置原型基础设施。",
      "B": "使用原型基础设施作为指南，将基础设施定义为模板。使用 AWS CloudFormation 部署基础设施。",
      "C": "使用 AWS Config 记录原型基础设施中使用的资源清单。使用 AWS Config 将原型基础设施部署到两个可用区中。",
      "D": "使用 AWS Elastic Beanstalk 并将其配置为使用对原型基础设施的自动化引用，以自动在两个可用区中部署新环境。"
    }
  },
  {
    "id": 480,
    "topic": "1",
    "question_en": "A business application is hosted on Amazon EC2 and uses Amazon S3 for encrypted object storage. The chief information security oficer has directed that no application trafic between the two services should traverse the public internet. Which capability should the solutions architect use to meet the compliance requirements?",
    "options_en": {
      "A": "AWS Key Management Service (AWS KMS)",
      "B": "VPC endpoint",
      "C": "Private subnet",
      "D": "Virtual private gateway"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个业务应用程序托管在 Amazon EC2 上，并使用 Amazon S3 进行加密对象存储。首席信息安全官已指示两个服务之间的应用程序流量不应遍历公共互联网。解决方案架构师应使用哪种功能来满足合规性要求？",
    "options_cn": {
      "A": "AWS Key Management Service (AWS KMS)",
      "B": "VPC endpoint",
      "C": "私有子网",
      "D": "虚拟私有网关"
    }
  },
  {
    "id": 481,
    "topic": "1",
    "question_en": "A company hosts a three-tier web application in the AWS Cloud. A Multi-AZAmazon RDS for MySQL server forms the database layer Amazon ElastiCache forms the cache layer. The company wants a caching strategy that adds or updates data in the cache when a customer adds an item to the database. The data in the cache must always match the data in the database. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement the lazy loading caching strategy",
      "B": "Implement the write-through caching strategy",
      "C": "Implement the adding TTL caching strategy",
      "D": "Implement the AWS AppConfig caching strategy"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 云中托管一个三层 Web 应用程序。一个多可用区域的 Amazon RDS for MySQL 服务器构成数据库层，Amazon ElastiCache 构成缓存层。该公司希望实现一种缓存策略，以便当客户将项目添加到数据库时，将数据添加到缓存或更新缓存中的数据。缓存中的数据必须始终与数据库中的数据匹配。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "实施惰性加载缓存策略",
      "B": "实施直写缓存策略",
      "C": "实施添加 TTL 缓存策略",
      "D": "实施 AWS AppConfig 缓存策略"
    }
  },
  {
    "id": 482,
    "topic": "1",
    "question_en": "A company wants to migrate 100 GB of historical data from an on-premises location to an Amazon S3 bucket. The company has a 100 megabits per second (Mbps) internet connection on premises. The company needs to encrypt the data in transit to the S3 bucket. The company will store new data directly in Amazon S3. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use the s3 sync command in the AWS CLI to move the data directly to an S3 bucket",
      "B": "Use AWS DataSync to migrate the data from the on-premises location to an S3 bucket",
      "C": "Use AWS Snowball to move the data to an S3 bucket",
      "D": "Set up an IPsec VPN from the on-premises location to AWS. Use the s3 cp command in the AWS CLI to move the data directly to an S3 bucket"
    },
    "correct_answer": "B",
    "vote_percentage": "59%",
    "question_cn": "一家公司希望将 100 GB 的历史数据从本地位置迁移到 Amazon S3 存储桶。该公司在本地拥有 100 兆比特每秒 (Mbps) 的互联网连接。该公司需要在传输到 S3 存储桶的数据进行加密。该公司将把新数据直接存储在 Amazon S3 中。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 AWS CLI 中使用 s3 sync 命令将数据直接移动到 S3 存储桶",
      "B": "使用 AWS DataSync 将数据从本地位置迁移到 S3 存储桶",
      "C": "使用 AWS Snowball 将数据移动到 S3 存储桶",
      "D": "从本地位置设置到 AWS 的 IPsec VPN。在 AWS CLI 中使用 s3 cp 命令将数据直接移动到 S3 存储桶"
    }
  },
  {
    "id": 483,
    "topic": "1",
    "question_en": "A company containerized a Windows job that runs on .NET 6 Framework under a Windows container. The company wants to run this job in the AWS Cloud. The job runs every 10 minutes. The job’s runtime varies between 1 minute and 3 minutes. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an AWS Lambda function based on the container image of the job. Configure Amazon EventBridge to invoke the function every 10 minutes.",
      "B": "Use AWS Batch to create a job that uses AWS Fargate resources. Configure the job scheduling to run every 10 minutes.",
      "C": "Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a scheduled task based on the container image of the job to run every 10 minutes.",
      "D": "Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a standalone task based on the container image of the job. Use Windows task scheduler to run the job every 10 minutes."
    },
    "correct_answer": "A",
    "vote_percentage": "53%",
    "question_cn": "一家公司将一个在 .NET 6 Framework 下的 Windows 容器中运行的 Windows 作业容器化。该公司希望在 AWS 云中运行此作业。该作业每 10 分钟运行一次。该作业的运行时长在 1 分钟到 3 分钟之间。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "基于该作业的容器镜像创建 AWS Lambda 函数。配置 Amazon EventBridge 以每 10 分钟调用该函数。",
      "B": "使用 AWS Batch 创建一个使用 AWS Fargate 资源的作业。配置作业调度程序以每 10 分钟运行一次。",
      "C": "使用 Amazon Elastic Container Service (Amazon ECS) on AWS Fargate 运行该作业。创建一个基于该作业的容器镜像的计划任务，以每 10 分钟运行一次。",
      "D": "使用 Amazon Elastic Container Service (Amazon ECS) on AWS Fargate 运行该作业。创建一个基于该作业的容器镜像的独立任务。使用 Windows 任务计划程序每 10 分钟运行该作业。"
    }
  },
  {
    "id": 484,
    "topic": "1",
    "question_en": "A company wants to move from many standalone AWS accounts to a consolidated, multi-account architecture. The company plans to create many new AWS accounts for different business units. The company needs to authenticate access to these AWS accounts by using a centralized corporate directory service. Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.",
      "B": "Set up an Amazon Cognito identity pool. Configure AWS IAM Identity Center (AWS Single Sign-On) to accept Amazon Cognito authentication.",
      "C": "Configure a service control policy (SCP) to manage the AWS accounts. Add AWS IAM Identity Center (AWS Single Sign-On) to AWS Directory Service.",
      "D": "Create a new organization in AWS Organizations. Configure the organization's authentication mechanism to use AWS Directory Service directly",
      "E": "Set up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company's corporate directory service."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司希望从多个独立的 AWS 账户迁移到统一的、多账户架构。该公司计划为不同的业务部门创建许多新的 AWS 账户。该公司需要通过使用集中的企业目录服务来验证对这些 AWS 账户的访问。解决方案架构师应该推荐哪些操作组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 AWS Organizations 中创建一个新组织，并启用所有功能。在该组织中创建新的 AWS 账户。",
      "B": "设置一个 Amazon Cognito 身份池。配置 AWS IAM Identity Center (AWS Single Sign-On) 以接受 Amazon Cognito 身份验证。",
      "C": "配置服务控制策略 (SCP) 以管理 AWS 账户。将 AWS IAM Identity Center (AWS Single Sign-On) 添加到 AWS Directory Service。",
      "D": "在 AWS Organizations 中创建一个新组织。配置该组织的身份验证机制以直接使用 AWS Directory Service。",
      "E": "在组织中设置 AWS IAM Identity Center (AWS Single Sign-On)。配置 IAM Identity Center，并将其与公司的企业目录服务集成。"
    }
  },
  {
    "id": 485,
    "topic": "1",
    "question_en": "A company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes. What is the MOST cost-effective solution?",
    "options_en": {
      "A": "Store the video archives in Amazon S3 Glacier and use Expedited retrievals.",
      "B": "Store the video archives in Amazon S3 Glacier and use Standard retrievals.",
      "C": "Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).",
      "D": "Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)."
    },
    "correct_answer": "C",
    "vote_percentage": "96%",
    "question_cn": "一家公司正在寻找一个解决方案，可以将旧新闻片段的视频存档存储在 AWS 中。该公司需要最大限度地降低成本，并且很少需要恢复这些文件。当需要这些文件时，它们必须在最多五分钟内可用。什么是最具成本效益的解决方案？",
    "options_cn": {
      "A": "将视频存档存储在 Amazon S3 Glacier 中并使用 Expedited retrievals。",
      "B": "将视频存档存储在 Amazon S3 Glacier 中并使用 Standard retrievals。",
      "C": "将视频存档存储在 Amazon S3 Standard-Infrequent Access (S3 Standard-IA) 中。",
      "D": "将视频存档存储在 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) 中。"
    }
  },
  {
    "id": 486,
    "topic": "1",
    "question_en": "A company is building a three-tier application on AWS. The presentation tier will serve a static website The logic tier is a containerized application. This application will store data in a relational database. The company wants to simplify deployment and to reduce operational costs. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.",
      "B": "Use Amazon CloudFront to host static content. Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database.",
      "C": "Use Amazon S3 to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.",
      "D": "Use Amazon EC2 Reserved Instances to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上构建一个三层应用程序。表示层将服务于一个静态网站。逻辑层是一个容器化应用程序。此应用程序会将数据存储在关系数据库中。该公司希望简化部署并降低运营成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 托管静态内容。使用 Amazon Elastic Container Service (Amazon ECS) 与 AWS Fargate 获取计算能力。 使用托管的 Amazon RDS 集群作为数据库。",
      "B": "使用 Amazon CloudFront 托管静态内容。使用 Amazon Elastic Container Service (Amazon ECS) 与 Amazon EC2 获取计算能力。使用托管的 Amazon RDS 集群作为数据库。",
      "C": "使用 Amazon S3 托管静态内容。使用 Amazon Elastic Kubernetes Service (Amazon EKS) 与 AWS Fargate 获取计算能力。使用托管的 Amazon RDS 集群作为数据库。",
      "D": "使用 Amazon EC2 Reserved Instances 托管静态内容。使用 Amazon Elastic Kubernetes Service (Amazon EKS) 与 Amazon EC2 获取计算能力。使用托管的 Amazon RDS 集群作为数据库。"
    }
  },
  {
    "id": 487,
    "topic": "1",
    "question_en": "A company seeks a storage solution for its application. The solution must be highly available and scalable. The solution also must function as a file system be mountable by multiple Linux instances in AWS and on premises through native protocols, and have no minimum size requirements. The company has set up a Site-to-Site VPN for access from its on-premises network to its VPC. Which storage solution meets these requirements?",
    "options_en": {
      "A": "Amazon FSx Multi-AZ deployments",
      "B": "Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes",
      "C": "Amazon Elastic File System (Amazon EFS) with multiple mount targets",
      "D": "Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为其应用程序寻找存储解决方案。该解决方案必须具有高可用性和可扩展性。该解决方案还必须充当文件系统，可以通过原生协议由 AWS 和本地的多个 Linux 实例挂载，并且没有最小大小要求。该公司已经设置了站点到站点 VPN，以便从其本地网络访问其 VPC。哪种存储解决方案满足这些要求？",
    "options_cn": {
      "A": "Amazon FSx 多可用区部署",
      "B": "Amazon Elastic Block Store (Amazon EBS) 多重连接卷",
      "C": "具有多个挂载目标的 Amazon Elastic File System (Amazon EFS)",
      "D": "具有单个挂载目标和多个访问点的 Amazon Elastic File System (Amazon EFS)"
    }
  },
  {
    "id": 488,
    "topic": "1",
    "question_en": "A 4-year-old media company is using the AWS Organizations all features feature set to organize its AWS accounts. According to the company's finance team, the billing information on the member accounts must not be accessible to anyone, including the root user of the member accounts. Which solution will meet these requirements?",
    "options_en": {
      "A": "Add all finance team users to an IAM group. Attach an AWS managed policy named Billing to the group.",
      "B": "Attach an identity-based policy to deny access to the billing information to all users, including the root user.",
      "C": "Create a service control policy (SCP) to deny access to the billing information. Attach the SCP to the root organizational unit (OU).",
      "D": "Convert from the Organizations all features feature set to the Organizations consolidated billing feature set."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家成立 4 年的媒体公司正在使用 AWS Organizations 的所有功能特性集来组织其 AWS 账户。根据该公司的财务团队，成员账户上的账单信息不得被任何人访问，包括成员账户的根用户。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将所有财务团队用户添加到 IAM 组。将名为 Billing 的 AWS 托管策略附加到该组。",
      "B": "附加一个基于身份的策略，以拒绝所有用户（包括根用户）访问账单信息。",
      "C": "创建一个服务控制策略 (SCP) 以拒绝访问账单信息。将 SCP 附加到根组织单元 (OU)。",
      "D": "从 Organizations 的所有功能特性集转换为 Organizations 的合并账单功能特性集。"
    }
  },
  {
    "id": 489,
    "topic": "1",
    "question_en": "An ecommerce company runs an application in the AWS Cloud that is integrated with an on-premises warehouse solution. The company uses Amazon Simple Notification Service (Amazon SNS) to send order messages to an on-premises HTTPS endpoint so the warehouse application can process the orders. The local data center team has detected that some of the order messages were not received. A solutions architect needs to retain messages that are not delivered and analyze the messages for up to 14 days. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Configure an Amazon SNS dead letter queue that has an Amazon Kinesis Data Stream target with a retention period of 14 days.",
      "B": "Add an Amazon Simple Queue Service (Amazon SQS) queue with a retention period of 14 days between the application and Amazon SNS.",
      "C": "Configure an Amazon SNS dead letter queue that has an Amazon Simple Queue Service (Amazon SQS) target with a retention period of 14 days.",
      "D": "Configure an Amazon SNS dead letter queue that has an Amazon DynamoDB target with a TTL attribute set for a retention period of 14 days."
    },
    "correct_answer": "C",
    "vote_percentage": "71%",
    "question_cn": "一家电子商务公司在 AWS Cloud 中运行一个应用程序，该应用程序与本地仓库解决方案集成。该公司使用 Amazon Simple Notification Service (Amazon SNS) 将订单消息发送到本地 HTTPS 终端节点，以便仓库应用程序可以处理订单。本地数据中心团队检测到某些订单消息未被接收。解决方案架构师需要保留未交付的消息，并分析这些消息长达 14 天。哪种解决方案以最少的开发工作量满足这些要求？",
    "options_cn": {
      "A": "配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon Kinesis Data Stream 目标，保留期为 14 天。",
      "B": "在应用程序和 Amazon SNS 之间添加一个 Amazon Simple Queue Service (Amazon SQS) 队列，保留期为 14 天。",
      "C": "配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon Simple Queue Service (Amazon SQS) 目标，保留期为 14 天。",
      "D": "配置一个 Amazon SNS 死信队列，该队列具有一个 Amazon DynamoDB 目标，TTL 属性设置为保留期为 14 天。"
    }
  },
  {
    "id": 490,
    "topic": "1",
    "question_en": "A gaming company uses Amazon DynamoDB to store user information such as geographic location, player data, and leaderboards. The company needs to configure continuous backups to an Amazon S3 bucket with a minimal amount of coding. The backups must not affect availability of the application and must not affect the read capacity units (RCUs) that are defined for the table. Which solution meets these requirements?",
    "options_en": {
      "A": "Use an Amazon EMR cluster. Create an Apache Hive job to back up the data to Amazon S3.",
      "B": "Export the data directly from DynamoDB to Amazon S3 with continuous backups. Turn on point-in-time recovery for the table.",
      "C": "Configure Amazon DynamoDB Streams. Create an AWS Lambda function to consume the stream and export the data to an Amazon S3 bucket.",
      "D": "Create an AWS Lambda function to export the data from the database tables to Amazon S3 on a regular basis. Turn on point-in-time recovery for the table."
    },
    "correct_answer": "B",
    "vote_percentage": "87%",
    "question_cn": "一家游戏公司使用 Amazon DynamoDB 存储用户信息，例如地理位置、玩家数据和排行榜。该公司需要配置连续备份到 Amazon S3 存储桶，并且只需最少的编码。备份不得影响应用程序的可用性，也不得影响为表定义的读取容量单元 (RCU)。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EMR 集群。创建 Apache Hive 作业将数据备份到 Amazon S3。",
      "B": "通过连续备份直接将数据从 DynamoDB 导出到 Amazon S3。为表打开时间点恢复。",
      "C": "配置 Amazon DynamoDB Streams。创建一个 AWS Lambda 函数来使用流并将数据导出到 Amazon S3 存储桶。",
      "D": "创建一个 AWS Lambda 函数，用于定期间隔将数据从数据库表导出到 Amazon S3。为表打开时间点恢复。"
    }
  },
  {
    "id": 491,
    "topic": "1",
    "question_en": "A solutions architect is designing an asynchronous application to process credit card data validation requests for a bank. The application must be secure and be able to process each request at least once. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS Key Management Service (SSE-KMS) for encryption. Add the kms:Decrypt permission for the Lambda execution role.",
      "B": "Use AWS Lambda event source mapping. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use SQS managed encryption keys (SSE-SQS) for encryption. Add the encryption key invocation permission for the Lambda function.",
      "C": "Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use AWS KMS keys (SSE-KMS). Add the kms:Decrypt permission for the Lambda execution role.",
      "D": "Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS KMS keys (SSE-KMS) for encryption. Add the encryption key invocation permission for the Lambda function."
    },
    "correct_answer": "A",
    "vote_percentage": "69%",
    "question_cn": "一位解决方案架构师正在设计一个异步应用程序，以处理银行的信用卡数据验证请求。该应用程序必须安全且能够至少处理每个请求一次。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Lambda 事件源映射。将 Amazon Simple Queue Service (Amazon SQS) 标准队列设置为事件源。使用 AWS Key Management Service (SSE-KMS) 进行加密。为 Lambda 执行角色添加 kms:Decrypt 权限。",
      "B": "使用 AWS Lambda 事件源映射。使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列作为事件源。使用 SQS 托管加密密钥 (SSE-SQS) 进行加密。为 Lambda 函数添加加密密钥调用权限。",
      "C": "使用 AWS Lambda 事件源映射。将 Amazon Simple Queue Service (Amazon SQS) FIFO 队列设置为事件源。使用 AWS KMS 密钥 (SSE-KMS)。为 Lambda 执行角色添加 kms:Decrypt 权限。",
      "D": "使用 AWS Lambda 事件源映射。将 Amazon Simple Queue Service (Amazon SQS) 标准队列设置为事件源。使用 AWS KMS 密钥 (SSE-KMS) 进行加密。为 Lambda 函数添加加密密钥调用权限。"
    }
  },
  {
    "id": 492,
    "topic": "1",
    "question_en": "A company has multiple AWS accounts for development work. Some staff consistently use oversized Amazon EC2 instances, which causes the company to exceed the yearly budget for the development accounts. The company wants to centrally restrict the creation of AWS resources in these accounts. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Develop AWS Systems Manager templates that use an approved EC2 creation process. Use the approved Systems Manager templates to provision EC2 instances.",
      "B": "Use AWS Organizations to organize the accounts into organizational units (OUs). Define and attach a service control policy (SCP) to control the usage of EC2 instance types.",
      "C": "Configure an Amazon EventBridge rule that invokes an AWS Lambda function when an EC2 instance is created. Stop disallowed EC2 instance types.",
      "D": "Set up AWS Service Catalog products for the staff to create the allowed EC2 instance types. Ensure that staff can deploy EC2 instances only by using the Service Catalog products."
    },
    "correct_answer": "B",
    "vote_percentage": "94%",
    "question_cn": "一家公司为开发工作设置了多个 AWS 账户。一些员工持续使用过大的 Amazon EC2 实例，导致公司超出了开发账户的年度预算。该公司希望集中限制在这些账户中创建 AWS 资源。哪种解决方案以最少的开发工作量满足这些要求？",
    "options_cn": {
      "A": "开发 AWS Systems Manager 模板，使用经过批准的 EC2 创建流程。使用经过批准的 Systems Manager 模板来配置 EC2 实例。",
      "B": "使用 AWS Organizations 将账户组织到组织单元 (OU) 中。定义并附加一个服务控制策略 (SCP) 来控制 EC2 实例类型的使用。",
      "C": "配置一个 Amazon EventBridge 规则，该规则在创建 EC2 实例时调用一个 AWS Lambda 函数。停止不允许的 EC2 实例类型。",
      "D": "为员工设置 AWS Service Catalog 产品，以便他们创建允许的 EC2 实例类型。确保员工只能通过使用 Service Catalog 产品来部署 EC2 实例。"
    }
  },
  {
    "id": 493,
    "topic": "1",
    "question_en": "A company wants to use artificial intelligence (AI) to determine the quality of its customer service calls. The company currently manages calls in four different languages, including English. The company will offer new languages in the future. The company does not have the resources to regularly maintain machine learning (ML) models. The company needs to create written sentiment analysis reports from the customer service call recordings. The customer service call recording text must be translated into English. Which combination of steps will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Use Amazon Comprehend to translate the audio recordings into English.",
      "B": "Use Amazon Lex to create the written sentiment analysis reports.",
      "C": "Use Amazon Polly to convert the audio recordings into text.",
      "D": "Use Amazon Transcribe to convert the audio recordings in any language into text",
      "E": "Use Amazon Translate to translate text in any language to English",
      "F": "Use Amazon Comprehend to create the sentiment analysis reports."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司希望使用人工智能 (AI) 来确定其客户服务电话的质量。该公司目前管理四种不同语言的通话，包括英语。该公司将来会提供新语言。该公司没有资源定期维护机器学习 (ML) 模型。该公司需要从客户服务通话录音中创建书面情绪分析报告。客户服务通话录音文本必须翻译成英语。哪种步骤组合将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "使用 Amazon Comprehend 将音频录音翻译成英语。",
      "B": "使用 Amazon Lex 创建书面情绪分析报告。",
      "C": "使用 Amazon Polly 将音频录音转换为文本。",
      "D": "使用 Amazon Transcribe 将任何语言的音频录音转换为文本。",
      "E": "使用 Amazon Translate 将任何语言的文本翻译成英语。",
      "F": "使用 Amazon Comprehend 创建情绪分析报告。"
    }
  },
  {
    "id": 494,
    "topic": "1",
    "question_en": "A company uses Amazon EC2 instances to host its internal systems. As part of a deployment operation, an administrator tries to use the AWS CLI to terminate an EC2 instance. However, the administrator receives a 403 (Access Denied) error message. The administrator is using an IAM role that has the following IAM policy attached: What is the cause of the unsuccessful request?",
    "options_en": {
      "A": "The EC2 instance has a resource-based policy with a Deny statement.",
      "B": "The principal has not been specified in the policy statement.",
      "C": "The \"Action\" field does not grant the actions that are required to terminate the EC2 instance.",
      "D": "The request to terminate the EC2 instance does not originate from the CIDR blocks 192.0.2.0/24 or 203.0.113.0/24."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon EC2 实例来托管其内部系统。作为部署操作的一部分，管理员尝试使用 AWS CLI 来终止一个 EC2 实例。但是，管理员收到 403 (访问被拒绝) 错误消息。管理员正在使用附加了以下 IAM 策略的 IAM 角色：导致请求不成功的原因是什么？",
    "options_cn": {
      "A": "EC2 实例有一个带有 Deny 语句的基于资源的策略。",
      "B": "策略语句中未指定主体。",
      "C": "\"Action\" 字段未授予终止 EC2 实例所需的权限。",
      "D": "终止 EC2 实例的请求并非源自 CIDR 块 192.0.2.0/24 或 203.0.113.0/24。"
    }
  },
  {
    "id": 495,
    "topic": "1",
    "question_en": "A company is conducting an internal audit. The company wants to ensure that the data in an Amazon S3 bucket that is associated with the company’s AWS Lake Formation data lake does not contain sensitive customer or employee data. The company wants to discover personally identifiable information (PII) or financial information, including passport numbers and credit card numbers. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure AWS Audit Manager on the account. Select the Payment Card Industry Data Security Standards (PCI DSS) for auditing.",
      "B": "Configure Amazon S3 Inventory on the S3 bucket Configure Amazon Athena to query the inventory.",
      "C": "Configure Amazon Macie to run a data discovery job that uses managed identifiers for the required data types.",
      "D": "Use Amazon S3 Select to run a report across the S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在进行内部审计。该公司希望确保与公司 AWS Lake Formation 数据湖关联的 Amazon S3 存储桶中的数据不包含敏感的客户或员工数据。该公司希望发现个人身份信息 (PII) 或财务信息，包括护照号码和信用卡号码。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在账户上配置 AWS Audit Manager。选择支付卡行业数据安全标准 (PCI DSS) 进行审计。",
      "B": "在 S3 存储桶上配置 Amazon S3 Inventory。配置 Amazon Athena 来查询 Inventory。",
      "C": "配置 Amazon Macie 运行数据发现作业，该作业使用托管标识符来查找所需的数据类型。",
      "D": "使用 Amazon S3 Select 运行 S3 存储桶的报告。"
    }
  },
  {
    "id": 496,
    "topic": "1",
    "question_en": "A company uses on-premises servers to host its applications. The company is running out of storage capacity. The applications use both block storage and NFS storage. The company needs a high-performing solution that supports local caching without re-architecting its existing applications. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Mount Amazon S3 as a file system to the on-premises servers.",
      "B": "Deploy an AWS Storage Gateway file gateway to replace NFS storage.",
      "C": "Deploy AWS Snowball Edge to provision NFS mounts to on-premises servers.",
      "D": "Deploy an AWS Storage Gateway volume gateway to replace the block storag",
      "E": "E. Deploy Amazon Elastic File System (Amazon EFS) volumes and mount them to on-premises servers."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用本地服务器来托管其应用程序。该公司即将用完存储容量。这些应用程序同时使用块存储和 NFS 存储。该公司需要一个高性能的解决方案，支持本地缓存，而无需重新架构其现有应用程序。解决方案架构师应采取哪些行动组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将 Amazon S3 挂载为本地服务器的文件系统。",
      "B": "部署 AWS Storage Gateway 文件网关以替换 NFS 存储。",
      "C": "部署 AWS Snowball Edge 以向本地服务器提供 NFS 挂载。",
      "D": "部署 AWS Storage Gateway 卷网关以替换块存储。",
      "E": "部署 Amazon Elastic File System (Amazon EFS) 卷并将它们挂载到本地服务器。"
    }
  },
  {
    "id": 497,
    "topic": "1",
    "question_en": "A company has a service that reads and writes large amounts of data from an Amazon S3 bucket in the same AWS Region. The service is deployed on Amazon EC2 instances within the private subnet of a VPC. The service communicates with Amazon S3 over a NAT gateway in the public subnet. However, the company wants a solution that will reduce the data output costs. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Provision a dedicated EC2 NAT instance in the public subnet. Configure the route table for the private subnet to use the elastic network interface of this instance as the destination for all S3 trafic.",
      "B": "Provision a dedicated EC2 NAT instance in the private subnet. Configure the route table for the public subnet to use the elastic network interface of this instance as the destination for all S3 trafic.",
      "C": "Provision a VPC gateway endpoint. Configure the route table for the private subnet to use the gateway endpoint as the route for all S3 trafic.",
      "D": "Provision a second NAT gateway. Configure the route table for the private subnet to use this NAT gateway as the destination for all S3 trafic."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一项服务，该服务从同一 AWS 区域的 Amazon S3 存储桶读取和写入大量数据。该服务部署在 VPC 私有子网中的 Amazon EC2 实例上。该服务通过公共子网中的 NAT 网关与 Amazon S3 通信。但是，该公司希望找到一个能够降低数据输出成本的解决方案。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在公共子网中预置一个专用的 EC2 NAT 实例。配置私有子网的路由表，以使用此实例的弹性网络接口作为所有 S3 流量的目的地。",
      "B": "在私有子网中预置一个专用的 EC2 NAT 实例。配置公共子网的路由表，以使用此实例的弹性网络接口作为所有 S3 流量的目的地。",
      "C": "预置一个 VPC 网关终端节点。配置私有子网的路由表，以使用该网关终端节点作为所有 S3 流量的路由。",
      "D": "预置第二个 NAT 网关。配置私有子网的路由表，以使用此 NAT 网关作为所有 S3 流量的目的地。"
    }
  },
  {
    "id": 498,
    "topic": "1",
    "question_en": "A company uses Amazon S3 to store high-resolution pictures in an S3 bucket. To minimize application changes, the company stores the pictures as the latest version of an S3 object. The company needs to retain only the two most recent versions of the pictures. The company wants to reduce costs. The company has identified the S3 bucket as a large expense. Which solution will reduce the S3 costs with the LEAST operational overhead?",
    "options_en": {
      "A": "Use S3 Lifecycle to delete expired object versions and retain the two most recent versions.",
      "B": "Use an AWS Lambda function to check for older versions and delete all but the two most recent versions.",
      "C": "Use S3 Batch Operations to delete noncurrent object versions and retain only the two most recent versions.",
      "D": "Deactivate versioning on the S3 bucket and retain the two most recent versions."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon S3 在 S3 存储桶中存储高分辨率图片。为了最大限度地减少应用程序的更改，该公司将图片存储为 S3 对象的最新版本。该公司只需要保留图片的两个最新版本。该公司希望降低成本。该公司已确定 S3 存储桶是一项巨大的开支。哪种解决方案将以最少的运营开销来降低 S3 成本？",
    "options_cn": {
      "A": "使用 S3 Lifecycle 删除过期的对象版本并保留两个最新版本。",
      "B": "使用 AWS Lambda 函数检查较旧的版本并删除除两个最新版本之外的所有版本。",
      "C": "使用 S3 Batch Operations 删除非当前对象版本，并且只保留两个最新版本。",
      "D": "停用 S3 存储桶的版本控制并保留两个最新版本。"
    }
  },
  {
    "id": 499,
    "topic": "1",
    "question_en": "A company needs to minimize the cost of its 1 Gbps AWS Direct Connect connection. The company's average connection utilization is less than 10%. A solutions architect must recommend a solution that will reduce the cost without compromising security. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up a new 1 Gbps Direct Connect connection. Share the connection with another AWS account.",
      "B": "Set up a new 200 Mbps Direct Connect connection in the AWS Management Console.",
      "C": "Contact an AWS Direct Connect Partner to order a 1 Gbps connection. Share the connection with another AWS account.",
      "D": "Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account."
    },
    "correct_answer": "B",
    "vote_percentage": "83%",
    "question_cn": "一家公司需要最大限度地降低其 1 Gbps 的 AWS Direct Connect 连接成本。该公司的平均连接利用率低于 10%。一位解决方案架构师必须推荐一个在不损害安全性的前提下降低成本的解决方案。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置一个新的 1 Gbps 的 Direct Connect 连接。与其他 AWS 账户共享此连接。",
      "B": "在 AWS 管理控制台中设置一个新的 200 Mbps 的 Direct Connect 连接。",
      "C": "联系 AWS Direct Connect 合作伙伴订购 1 Gbps 的连接。与其他 AWS 账户共享此连接。",
      "D": "联系 AWS Direct Connect 合作伙伴为现有 AWS 账户订购 200 Mbps 的托管连接。"
    }
  },
  {
    "id": 500,
    "topic": "1",
    "question_en": "A company has multiple Windows file servers on premises. The company wants to migrate and consolidate its files into an Amazon FSx for Windows File Server file system. File permissions must be preserved to ensure that access rights do not change. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Deploy AWS DataSync agents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
      "B": "Copy the shares on each file server into Amazon S3 buckets by using the AWS CLI. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
      "C": "Remove the drives from each file server. Ship the drives to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.",
      "D": "Order an AWS Snowcone devic",
      "E": "Connect the device to the on-premises network. Launch AWS DataSync agents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system. E. Order an AWS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the AWS CLI. Ship the device back to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system."
    },
    "correct_answer": "A",
    "vote_percentage": "95%",
    "question_cn": "一家公司在本地有多个 Windows 文件服务器。该公司希望将其文件迁移并整合到 Amazon FSx for Windows File Server 文件系统中。必须保留文件权限以确保访问权限不发生变化。哪些解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在本地部署 AWS DataSync 代理。安排 DataSync 任务将数据传输到 FSx for Windows File Server 文件系统。",
      "B": "使用 AWS CLI 将每个文件服务器上的共享复制到 Amazon S3 存储桶中。安排 AWS DataSync 任务将数据传输到 FSx for Windows File Server 文件系统。",
      "C": "从每个文件服务器中移除驱动器。将驱动器运送到 AWS 以导入到 Amazon S3 中。安排 AWS DataSync 任务将数据传输到 FSx for Windows File Server 文件系统。",
      "D": "订购 AWS Snowcone 设备。将该设备连接到本地网络。在该设备上启动 AWS DataSync 代理。安排 DataSync 任务将数据传输到 FSx for Windows File Server 文件系统。",
      "E": "订购 AWS Snowball Edge 存储优化设备。将该设备连接到本地网络。使用 AWS CLI 将数据复制到该设备。将该设备寄回 AWS 以导入到 Amazon S3 中。安排 AWS DataSync 任务将数据传输到 FSx for Windows File Server 文件系统。"
    }
  },
  {
    "id": 501,
    "topic": "1",
    "question_en": "A company wants to ingest customer payment data into the company's data lake in Amazon S3. The company receives payment data every minute on average. The company wants to analyze the payment data in real time. Then the company wants to ingest the data into the data lake. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Use Amazon Kinesis Data Streams to ingest data. Use AWS Lambda to analyze the data in real time.",
      "B": "Use AWS Glue to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time.",
      "C": "Use Amazon Kinesis Data Firehose to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time.",
      "D": "Use Amazon API Gateway to ingest data. Use AWS Lambda to analyze the data in real time."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司希望将客户付款数据摄取到公司在 Amazon S3 中的数据湖中。该公司平均每分钟接收一次付款数据。该公司希望实时分析付款数据，然后将数据摄取到数据湖中。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Streams 摄取数据。使用 AWS Lambda 实时分析数据。",
      "B": "使用 AWS Glue 摄取数据。使用 Amazon Kinesis Data Analytics 实时分析数据。",
      "C": "使用 Amazon Kinesis Data Firehose 摄取数据。使用 Amazon Kinesis Data Analytics 实时分析数据。",
      "D": "使用 Amazon API Gateway 摄取数据。使用 AWS Lambda 实时分析数据。"
    }
  },
  {
    "id": 502,
    "topic": "1",
    "question_en": "A company runs a website that uses a content management system (CMS) on Amazon EC2. The CMS runs on a single EC2 instance and uses an Amazon Aurora MySQL Multi-AZ DB instance for the data tier. Website images are stored on an Amazon Elastic Block Store (Amazon EBS) volume that is mounted inside the EC2 instance. Which combination of actions should a solutions architect take to improve the performance and resilience of the website? (Choose two.)",
    "options_en": {
      "A": "Move the website images into an Amazon S3 bucket that is mounted on every EC2 instance",
      "B": "Share the website images by using an NFS share from the primary EC2 instance. Mount this share on the other EC2 instances.",
      "C": "Move the website images onto an Amazon Elastic File System (Amazon EFS) file system that is mounted on every EC2 instance.",
      "D": "Create an Amazon Machine Image (AMI) from the existing EC2 instanc",
      "E": "Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an accelerator in AWS Global Accelerator for the website E. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an Amazon CloudFront distribution for the website."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在其 Amazon EC2 上运行一个使用内容管理系统 (CMS) 的网站。该 CMS 在单个 EC2 实例上运行，并使用 Amazon Aurora MySQL 多可用区数据库实例作为数据层。网站图片存储在安装在 EC2 实例内的 Amazon Elastic Block Store (Amazon EBS) 卷上。解决方案架构师应采取哪些组合操作来提高网站的性能和弹性？（选择两个。）",
    "options_cn": {
      "A": "将网站图片移动到安装在每个 EC2 实例上的 Amazon S3 存储桶中。",
      "B": "通过使用来自主 EC2 实例的 NFS 共享来共享网站图片。在其他 EC2 实例上挂载此共享。",
      "C": "将网站图片移动到安装在每个 EC2 实例上的 Amazon Elastic File System (Amazon EFS) 文件系统中。",
      "D": "从现有的 EC2 实例创建 Amazon Machine Image (AMI)。使用 AMI 在 Application Load Balancer 后面预置新实例，作为 Auto Scaling 组的一部分。配置 Auto Scaling 组以保持至少两个实例。为网站配置 AWS Global Accelerator 中的加速器。",
      "E": "从现有的 EC2 实例创建 Amazon Machine Image (AMI)。使用 AMI 在 Application Load Balancer 后面预置新实例，作为 Auto Scaling 组的一部分。配置 Auto Scaling 组以保持至少两个实例。为网站配置 Amazon CloudFront 分发。"
    }
  },
  {
    "id": 503,
    "topic": "1",
    "question_en": "A company runs an infrastructure monitoring service. The company is building a new feature that will enable the service to monitor data in customer AWS accounts. The new feature will call AWS APIs in customer accounts to describe Amazon EC2 instances and read Amazon CloudWatch metrics. What should the company do to obtain access to customer accounts in the MOST secure way?",
    "options_en": {
      "A": "Ensure that the customers create an IAM role in their account with read-only EC2 and CloudWatch permissions and a trust policy to the company’s account.",
      "B": "Create a serverless API that implements a token vending machine to provide temporary AWS credentials for a role with read-only EC2 and CloudWatch permissions.",
      "C": "Ensure that the customers create an IAM user in their account with read-only EC2 and CloudWatch permissions. Encrypt and store customer access and secret keys in a secrets management system.",
      "D": "Ensure that the customers create an Amazon Cognito user in their account to use an IAM role with read-only EC2 and CloudWatch permissions. Encrypt and store the Amazon Cognito user and password in a secrets management system."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司运营着一个基础设施监控服务。该公司正在构建一个新功能，该功能将使该服务能够监控客户 AWS 账户中的数据。新功能将调用客户账户中的 AWS API 来描述 Amazon EC2 实例并读取 Amazon CloudWatch 指标。为了以最安全的方式获取对客户账户的访问权限，该公司应该怎么做？",
    "options_cn": {
      "A": "确保客户在其账户中创建一个 IAM 角色，该角色具有只读 EC2 和 CloudWatch 权限，并向该公司的账户授予信任策略。",
      "B": "创建一个无服务器 API，该 API 实现一个令牌发放机，以提供具有只读 EC2 和 CloudWatch 权限的角色的临时 AWS 凭证。",
      "C": "确保客户在其账户中创建一个具有只读 EC2 和 CloudWatch 权限的 IAM 用户。加密并将客户的访问密钥和秘密密钥存储在秘密管理系统中。",
      "D": "确保客户在其账户中创建一个 Amazon Cognito 用户，以使用具有只读 EC2 和 CloudWatch 权限的 IAM 角色。加密并将 Amazon Cognito 用户和密码存储在秘密管理系统中。"
    }
  },
  {
    "id": 504,
    "topic": "1",
    "question_en": "A company needs to connect several VPCs in the us-east-1 Region that span hundreds of AWS accounts. The company's networking team has its own AWS account to manage the cloud network. What is the MOST operationally eficient solution to connect the VPCs?",
    "options_en": {
      "A": "Set up VPC peering connections between each VPC. Update each associated subnet’s route table",
      "B": "Configure a NAT gateway and an internet gateway in each VPC to connect each VPC through the internet",
      "C": "Create an AWS Transit Gateway in the networking team’s AWS account. Configure static routes from each VPC.",
      "D": "Deploy VPN gateways in each VPC. Create a transit VPC in the networking team’s AWS account to connect to each VPC."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要在 us-east-1 区域连接数百个 AWS 账户中的多个 VPC。该公司的网络团队有自己的 AWS 账户来管理云网络。哪种解决方案在运营上最有效，可以连接这些 VPC？",
    "options_cn": {
      "A": "在每个 VPC 之间设置 VPC 对等连接。更新每个关联子网的路由表。",
      "B": "在每个 VPC 中配置 NAT Gateway 和 Internet Gateway，通过互联网连接每个 VPC。",
      "C": "在网络团队的 AWS 账户中创建一个 AWS Transit Gateway。从每个 VPC 配置静态路由。",
      "D": "在每个 VPC 中部署 VPN 网关。在网络团队的 AWS 账户中创建一个 Transit VPC 来连接每个 VPC。"
    }
  },
  {
    "id": 505,
    "topic": "1",
    "question_en": "A company has Amazon EC2 instances that run nightly batch jobs to process data. The EC2 instances run in an Auto Scaling group that uses On-Demand billing. If a job fails on one instance, another instance will reprocess the job. The batch jobs run between 12:00 AM and 06:00 AM local time every day. Which solution will provide EC2 instances to meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Purchase a 1-year Savings Plan for Amazon EC2 that covers the instance family of the Auto Scaling group that the batch job uses.",
      "B": "Purchase a 1-year Reserved Instance for the specific instance type and operating system of the instances in the Auto Scaling group that the batch job uses.",
      "C": "Create a new launch template for the Auto Scaling group. Set the instances to Spot Instances. Set a policy to scale out based on CPU usage.",
      "D": "Create a new launch template for the Auto Scaling group. Increase the instance size. Set a policy to scale out based on CPU usage."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有 Amazon EC2 实例，这些实例运行夜间批处理作业来处理数据。EC2 实例在 Auto Scaling 组中运行，该组使用按需计费。如果一个实例上的作业失败，另一个实例将重新处理该作业。批处理作业在每天当地时间凌晨 12:00 到凌晨 06:00 之间运行。哪种解决方案将以最具成本效益的方式提供 EC2 实例以满足这些要求？",
    "options_cn": {
      "A": "为 Amazon EC2 购买 1 年期 Savings Plan，涵盖批处理作业使用的 Auto Scaling 组的实例系列。",
      "B": "为 Auto Scaling 组中批处理作业使用的实例的特定实例类型和操作系统购买 1 年期 Reserved Instance。",
      "C": "为 Auto Scaling 组创建一个新的启动模板。将实例设置为 Spot Instances。设置一个基于 CPU 使用率进行扩展的策略。",
      "D": "为 Auto Scaling 组创建一个新的启动模板。增加实例大小。设置一个基于 CPU 使用率进行扩展的策略。"
    }
  },
  {
    "id": 506,
    "topic": "1",
    "question_en": "A social media company is building a feature for its website. The feature will give users the ability to upload photos. The company expects significant increases in demand during large events and must ensure that the website can handle the upload trafic from users. Which solution meets these requirements with the MOST scalability?",
    "options_en": {
      "A": "Upload files from the user's browser to the application servers. Transfer the files to an Amazon S3 bucket.",
      "B": "Provision an AWS Storage Gateway file gateway. Upload files directly from the user's browser to the file gateway.",
      "C": "Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket.",
      "D": "Provision an Amazon Elastic File System (Amazon EFS) file system. Upload files directly from the user's browser to the file system."
    },
    "correct_answer": "C",
    "vote_percentage": "92%",
    "question_cn": "一家社交媒体公司正在为其网站构建一项功能。该功能将允许用户上传照片。该公司预计在大型活动期间需求量会显着增加，并且必须确保该网站能够处理来自用户的上传流量。哪种解决方案以最高的扩展能力满足这些要求？",
    "options_cn": {
      "A": "从用户的浏览器将文件上传到应用程序服务器。将文件传输到 Amazon S3 存储桶。",
      "B": "配置一个 AWS Storage Gateway 文件网关。直接从用户的浏览器将文件上传到文件网关。",
      "C": "在应用程序中生成 Amazon S3 预签名 URL。直接从用户的浏览器将文件上传到 S3 存储桶。",
      "D": "配置一个 Amazon Elastic File System (Amazon EFS) 文件系统。直接从用户的浏览器将文件上传到文件系统。"
    }
  },
  {
    "id": 507,
    "topic": "1",
    "question_en": "A company has a web application for travel ticketing. The application is based on a database that runs in a single data center in North America. The company wants to expand the application to serve a global user base. The company needs to deploy the application to multiple AWS Regions. Average latency must be less than 1 second on updates to the reservation database. The company wants to have separate deployments of its web platform across multiple Regions. However, the company must maintain a single primary reservation database that is globally consistent. Which solution should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.",
      "B": "Migrate the database to an Amazon Aurora MySQL database. Deploy Aurora Read Replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.",
      "C": "Migrate the database to an Amazon RDS for MySQL database. Deploy MySQL read replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.",
      "D": "Migrate the application to an Amazon Aurora Serverless database. Deploy instances of the database to each Region. Use the correct Regional endpoint in each Regional deployment to access the database. Use AWS Lambda functions to process event streams in each Region to synchronize the databases."
    },
    "correct_answer": "B",
    "vote_percentage": "58%",
    "question_cn": "一家公司拥有一款用于旅行票务的 Web 应用程序。 该应用程序基于一个数据库，该数据库在北美的一个数据中心运行。 公司希望扩展该应用程序以服务于全球用户群。 公司需要将应用程序部署到多个 AWS 区域。 预订数据库的更新平均延迟必须小于 1 秒。 公司希望在多个区域中拥有其 Web 平台的单独部署。 但是，公司必须维护一个全局一致的单一主要预订数据库。 解决方案架构师应推荐哪种解决方案来满足这些要求？",
    "options_cn": {
      "A": "将应用程序转换为使用 Amazon DynamoDB。对中心预订表使用全局表。 在每个区域部署中使用正确的区域端点。",
      "B": "将数据库迁移到 Amazon Aurora MySQL 数据库。在每个区域部署 Aurora 副本。 在每个区域部署中使用正确的区域端点来访问数据库。",
      "C": "将数据库迁移到 Amazon RDS for MySQL 数据库。在每个区域部署 MySQL 副本。 在每个区域部署中使用正确的区域端点来访问数据库。",
      "D": "将应用程序迁移到 Amazon Aurora Serverless 数据库。 将数据库的实例部署到每个区域。 使用每个区域中的正确区域端点来访问数据库。 使用 AWS Lambda 函数处理每个区域中的事件流以同步数据库。"
    }
  },
  {
    "id": 508,
    "topic": "1",
    "question_en": "A company has migrated multiple Microsoft Windows Server workloads to Amazon EC2 instances that run in the us-west-1 Region. The company manually backs up the workloads to create an image as needed. In the event of a natural disaster in the us-west-1 Region, the company wants to recover workloads quickly in the us-west-2 Region. The company wants no more than 24 hours of data loss on the EC2 instances. The company also wants to automate any backups of the EC2 instances. Which solutions will meet these requirements with the LEAST administrative effort? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand.",
      "B": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region.",
      "C": "Create backup vaults in us-west-1 and in us-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2.",
      "D": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily",
      "E": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司已将多个 Microsoft Windows Server 工作负载迁移到在 us-west-1 区域中运行的 Amazon EC2 实例。该公司会根据需要手动备份工作负载以创建映像。如果 us-west-1 区域发生自然灾害，该公司希望快速恢复 us-west-2 区域中的工作负载。该公司希望 EC2 实例上的数据丢失不超过 24 小时。该公司还希望自动执行 EC2 实例的任何备份。哪些解决方案将以最少的管理工作满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建一个 Amazon EC2 支持的 Amazon Machine Image (AMI) 生命周期策略，以根据标签创建备份。将备份计划为每天运行两次。按需复制映像。",
      "B": "创建一个 Amazon EC2 支持的 Amazon Machine Image (AMI) 生命周期策略，以根据标签创建备份。将备份计划为每天运行两次。配置复制到 us-west-2 区域。",
      "C": "通过使用 AWS Backup 在 us-west-1 和 us-west-2 中创建备份库。创建一个基于标签值的 EC2 实例的备份计划。创建一个 AWS Lambda 函数，以作为计划作业运行，以将备份数据复制到 us-west-2。",
      "D": "通过使用 AWS Backup 创建一个备份库。使用 AWS Backup 为 EC2 实例创建一个基于标签值的备份计划。将复制的目标定义为 us-west-2。指定备份计划为每天运行两次。",
      "E": "通过使用 AWS Backup 创建一个备份库。使用 AWS Backup 为 EC2 实例创建一个基于标签值的备份计划。指定备份计划为每天运行两次。按需复制到 us-west-2。"
    }
  },
  {
    "id": 509,
    "topic": "1",
    "question_en": "A company operates a two-tier application for image processing. The application uses two Availability Zones, each with one public subnet and one private subnet. An Application Load Balancer (ALB) for the web tier uses the public subnets. Amazon EC2 instances for the application tier use the private subnets. Users report that the application is running more slowly than expected. A security audit of the web server log files shows that the application is receiving millions of illegitimate requests from a small number of IP addresses. A solutions architect needs to resolve the immediate performance problem while the company investigates a more permanent solution. What should the solutions architect recommend to meet this requirement?",
    "options_en": {
      "A": "Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.",
      "B": "Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.",
      "C": "Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources.",
      "D": "Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一家公司运营一个用于图像处理的两层应用程序。该应用程序使用两个可用区，每个可用区都有一个公有子网和一个私有子网。Web 层使用的 Application Load Balancer (ALB) 使用公有子网。应用程序层使用的 Amazon EC2 实例使用私有子网。用户报告说应用程序的运行速度比预期的要慢。对 Web 服务器日志文件的安全审计显示，该应用程序正在接收来自少量 IP 地址的数百万个非法请求。解决方案架构师需要解决当前的性能问题，同时公司调查一个更永久的解决方案。解决方案架构师应该推荐什么来满足此要求？",
    "options_cn": {
      "A": "修改 Web 层的入站安全组。添加一个拒绝规则，用于消耗资源的 IP 地址。",
      "B": "修改 Web 层子网的网络 ACL。添加一个拒绝规则，用于消耗资源的 IP 地址。",
      "C": "修改应用程序层的入站安全组。添加一个拒绝规则，用于消耗资源的 IP 地址。",
      "D": "修改应用程序层子网的网络 ACL。添加一个拒绝规则，用于消耗资源的 IP 地址。"
    }
  },
  {
    "id": 510,
    "topic": "1",
    "question_en": "A global marketing company has applications that run in the ap-southeast-2 Region and the eu-west-1 Region. Applications that run in a VPC in eu-west-1 need to communicate securely with databases that run in a VPC in ap-southeast-2. Which network design will meet these requirements?",
    "options_en": {
      "A": "Create a VPC peering connection between the eu-west-1 VPC and the ap-southeast-2 VPC. Create an inbound rule in the eu-west-1 application security group that allows trafic from the database server IP addresses in the ap-southeast-2 security group.",
      "B": "Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPC. Update the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that references the security group ID of the application servers in eu-west-1.",
      "C": "Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPUpdate the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that allows trafic from the eu-west-1 application server IP addresses.",
      "D": "Create a transit gateway with a peering attachment between the eu-west-1 VPC and the ap-southeast-2 VPC. After the transit gateways are properly peered and routing is configured, create an inbound rule in the database security group that references the security group ID of the application servers in eu-west-1."
    },
    "correct_answer": "B",
    "vote_percentage": "87%",
    "question_cn": "一家全球营销公司在其 ap-southeast-2 区域和 eu-west-1 区域中运行应用程序。需要在 eu-west-1 中的 VPC 中运行的应用程序安全地与在 ap-southeast-2 中的 VPC 中运行的数据库通信。哪种网络设计将满足这些要求？",
    "options_cn": {
      "A": "在 eu-west-1 VPC 和 ap-southeast-2 VPC 之间创建 VPC 对等连接。在 eu-west-1 应用程序安全组中创建一个入站规则，该规则允许来自 ap-southeast-2 安全组中的数据库服务器 IP 地址的流量。",
      "B": "在 ap-southeast-2 VPC 和 eu-west-1 VPC 之间配置 VPC 对等连接。更新子网路由表。在 ap-southeast-2 数据库安全组中创建一个入站规则，该规则引用 eu-west-1 中应用程序服务器的安全组 ID。",
      "C": "在 ap-southeast-2 VPC 和 eu-west-1 VPC 之间配置 VPC 对等连接。更新子网路由表。在 ap-southeast-2 数据库安全组中创建一个入站规则，该规则允许来自 eu-west-1 应用程序服务器 IP 地址的流量。",
      "D": "在 eu-west-1 VPC 和 ap-southeast-2 VPC 之间创建一个具有对等附件的 Transit Gateway。在正确对等 Transit Gateway 并配置路由后，在数据库安全组中创建一个入站规则，该规则引用 eu-west-1 中应用程序服务器的安全组 ID。"
    }
  },
  {
    "id": 511,
    "topic": "1",
    "question_en": "A company is developing software that uses a PostgreSQL database schema. The company needs to configure multiple development environments and databases for the company's developers. On average, each development environment is used for half of the 8-hour workday. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure each development environment with its own Amazon Aurora PostgreSQL database",
      "B": "Configure each development environment with its own Amazon RDS for PostgreSQL Single-AZ DB instances",
      "C": "Configure each development environment with its own Amazon Aurora On-Demand PostgreSQL-Compatible database",
      "D": "Configure each development environment with its own Amazon S3 bucket by using Amazon S3 Object Select"
    },
    "correct_answer": "B",
    "vote_percentage": "59%",
    "question_cn": "一家公司正在开发使用 PostgreSQL 数据库模式的软件。该公司需要为公司的开发人员配置多个开发环境和数据库。平均而言，每个开发环境使用 8 小时工作日的 50%。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用其自己的 Amazon Aurora PostgreSQL 数据库配置每个开发环境",
      "B": "使用其自己的 Amazon RDS for PostgreSQL Single-AZ DB 实例配置每个开发环境",
      "C": "使用其自己的 Amazon Aurora On-Demand PostgreSQL 兼容数据库配置每个开发环境",
      "D": "使用其自己的 Amazon S3 存储桶（通过使用 Amazon S3 Object Select）配置每个开发环境"
    }
  },
  {
    "id": 512,
    "topic": "1",
    "question_en": "A company uses AWS Organizations with resources tagged by account. The company also uses AWS Backup to back up its AWS infrastructure resources. The company needs to back up all AWS resources. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Config to identify all untagged resources. Tag the identified resources programmatically. Use tags in the backup plan.",
      "B": "Use AWS Config to identify all resources that are not running. Add those resources to the backup vault.",
      "C": "Require all AWS account owners to review their resources to identify the resources that need to be backed up.",
      "D": "Use Amazon Inspector to identify all noncompliant resources."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS Organizations，其资源按账户进行标记。该公司还使用 AWS Backup 来备份其 AWS 基础设施资源。该公司需要备份所有 AWS 资源。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Config 识别所有未标记的资源。以编程方式标记已识别的资源。在备份计划中使用标签。",
      "B": "使用 AWS Config 识别所有未运行的资源。将这些资源添加到备份库。",
      "C": "要求所有 AWS 账户所有者审查其资源以识别需要备份的资源。",
      "D": "使用 Amazon Inspector 识别所有不合规的资源。"
    }
  },
  {
    "id": 513,
    "topic": "1",
    "question_en": "A social media company wants to allow its users to upload images in an application that is hosted in the AWS Cloud. The company needs a solution that automatically resizes the images so that the images can be displayed on multiple device types. The application experiences unpredictable trafic patterns throughout the day. The company is seeking a highly available solution that maximizes scalability. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a static website hosted in Amazon S3 that invokes AWS Lambda functions to resize the images and store the images in an Amazon S3 bucket.",
      "B": "Create a static website hosted in Amazon CloudFront that invokes AWS Step Functions to resize the images and store the images in an Amazon RDS database.",
      "C": "Create a dynamic website hosted on a web server that runs on an Amazon EC2 instance. Configure a process that runs on the EC2 instance to resize the images and store the images in an Amazon S3 bucket.",
      "D": "Create a dynamic website hosted on an automatically scaling Amazon Elastic Container Service (Amazon ECS) cluster that creates a resize job in Amazon Simple Queue Service (Amazon SQS). Set up an image-resizing program that runs on an Amazon EC2 instance to process the resize jobs."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家社交媒体公司希望允许其用户在其托管在 AWS 云中的应用程序中上传图像。该公司需要一个解决方案，该解决方案可以自动调整图像大小，以便可以在多种设备类型上显示图像。该应用程序在一天中会经历不可预测的流量模式。该公司正在寻找一个高度可用的解决方案，该解决方案可以最大限度地提高可扩展性。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个托管在 Amazon S3 中的静态网站，该网站调用 AWS Lambda 函数来调整图像大小并将图像存储在 Amazon S3 存储桶中。",
      "B": "创建一个托管在 Amazon CloudFront 中的静态网站，该网站调用 AWS Step Functions 来调整图像大小并将图像存储在 Amazon RDS 数据库中。",
      "C": "创建一个托管在在 Amazon EC2 实例上运行的 Web 服务器上的动态网站。配置一个在 EC2 实例上运行的进程以调整图像大小并将图像存储在 Amazon S3 存储桶中。",
      "D": "创建一个托管在自动缩放的 Amazon Elastic Container Service (Amazon ECS) 集群上的动态网站，该集群在 Amazon Simple Queue Service (Amazon SQS) 中创建一个调整大小的作业。设置一个在 Amazon EC2 实例上运行的图像调整大小程序以处理调整大小的作业。"
    }
  },
  {
    "id": 514,
    "topic": "1",
    "question_en": "A company is running a microservices application on Amazon EC2 instances. The company wants to migrate the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster for scalability. The company must configure the Amazon EKS control plane with endpoint private access set to true and endpoint public access set to false to maintain security compliance. The company must also put the data plane in private subnets. However, the company has received error notifications because the node cannot join the cluster. Which solution will allow the node to join the cluster?",
    "options_en": {
      "A": "Grant the required permission in AWS Identity and Access Management (IAM) to the AmazonEKSNodeRole IAM role.",
      "B": "Create interface VPC endpoints to allow nodes to access the control plane.",
      "C": "Recreate nodes in the public subnet. Restrict security groups for EC2 nodes.",
      "D": "Allow outbound trafic in the security group of the nodes."
    },
    "correct_answer": "B",
    "vote_percentage": "53%",
    "question_cn": "一家公司正在 Amazon EC2 实例上运行微服务应用程序。该公司希望将应用程序迁移到 Amazon Elastic Kubernetes Service (Amazon EKS) 集群以实现可扩展性。该公司必须将 Amazon EKS 控制平面配置为将 endpoint private access 设置为 true，并将 endpoint public access 设置为 false，以保持安全合规性。该公司还必须将数据平面置于私有子网中。但是，该公司收到了错误通知，因为节点无法加入集群。哪个解决方案将允许节点加入集群？",
    "options_cn": {
      "A": "在 AWS Identity and Access Management (IAM) 中向 AmazonEKSNodeRole IAM 角色授予所需的权限。",
      "B": "创建接口 VPC endpoint 以允许节点访问控制平面。",
      "C": "在公共子网中重新创建节点。限制 EC2 节点的安全组。",
      "D": "允许节点安全组中的出站流量。"
    }
  },
  {
    "id": 515,
    "topic": "1",
    "question_en": "A company is migrating an on-premises application to AWS. The company wants to use Amazon Redshift as a solution. Which use cases are suitable for Amazon Redshift in this scenario? (Choose three.)",
    "options_en": {
      "A": "Supporting data APIs to access data with traditional, containerized, and event-driven applications",
      "B": "Supporting client-side and server-side encryption",
      "C": "Building analytics workloads during specified hours and when the application is not active",
      "D": "Caching data to reduce the pressure on the backend database",
      "E": "Scaling globally to support petabytes of data and tens of millions of requests per minute",
      "F": "Creating a secondary replica of the cluster by using the AWS Management Console"
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其本地应用程序迁移到 AWS。该公司希望使用 Amazon Redshift 作为解决方案。在此场景中，哪些用例适合 Amazon Redshift？（选择三个。）",
    "options_cn": {
      "A": "支持数据 API 以访问传统、容器化和事件驱动应用程序的数据",
      "B": "支持客户端和服务器端加密",
      "C": "在指定时间段和应用程序不活动时构建分析工作负载",
      "D": "缓存数据以减轻后端数据库的压力",
      "E": "在全球范围内扩展以支持 PB 级数据和每分钟数千万个请求",
      "F": "使用 AWS 管理控制台创建集群的次要副本"
    }
  },
  {
    "id": 516,
    "topic": "1",
    "question_en": "A company provides an API interface to customers so the customers can retrieve their financial information. Еhe company expects a larger number of requests during peak usage times of the year. The company requires the API to respond consistently with low latency to ensure customer satisfaction. The company needs to provide a compute host for the API. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use an Application Load Balancer and Amazon Elastic Container Service (Amazon ECS).",
      "B": "Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency.",
      "C": "Use an Application Load Balancer and an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.",
      "D": "Use Amazon API Gateway and AWS Lambda functions with reserved concurrency."
    },
    "correct_answer": "B",
    "vote_percentage": "74%",
    "question_cn": "一家公司为客户提供 API 接口，以便客户可以检索其财务信息。该公司预计在一年中的高峰使用时段会有大量请求。该公司要求 API 始终以低延迟响应，以确保客户满意度。该公司需要为 API 提供计算主机。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Application Load Balancer 和 Amazon Elastic Container Service (Amazon ECS)。",
      "B": "使用 Amazon API Gateway 和带有预置并发的 AWS Lambda 函数。",
      "C": "使用 Application Load Balancer 和 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。",
      "D": "使用 Amazon API Gateway 和带有保留并发的 AWS Lambda 函数。"
    }
  },
  {
    "id": 517,
    "topic": "1",
    "question_en": "A company wants to send all AWS Systems Manager Session Manager logs to an Amazon S3 bucket for archival purposes. Which solution will meet this requirement with the MOST operational eficiency?",
    "options_en": {
      "A": "Enable S3 logging in the Systems Manager console. Choose an S3 bucket to send the session data to.",
      "B": "Install the Amazon CloudWatch agent. Push all logs to a CloudWatch log group. Export the logs to an S3 bucket from the group for archival purposes.",
      "C": "Create a Systems Manager document to upload all server logs to a central S3 bucket. Use Amazon EventBridge to run the Systems Manager document against all servers that are in the account daily.",
      "D": "Install an Amazon CloudWatch agent. Push all logs to a CloudWatch log group. Create a CloudWatch logs subscription that pushes any incoming log events to an Amazon Kinesis Data Firehose delivery stream. Set Amazon S3 as the destination."
    },
    "correct_answer": "D",
    "vote_percentage": "92%",
    "question_cn": "一家公司希望将所有 AWS Systems Manager Session Manager 日志发送到 Amazon S3 存储桶以进行存档。哪种解决方案将以最高的运营效率满足此要求？",
    "options_cn": {
      "A": "在 Systems Manager 控制台中打开 S3 日志记录。选择一个 S3 存储桶以将会话数据发送到该存储桶。",
      "B": "安装 Amazon CloudWatch 代理。将所有日志推送到 CloudWatch 日志组。从该组导出日志到 S3 存储桶以进行存档。",
      "C": "创建一个 Systems Manager 文档，将所有服务器日志上传到中央 S3 存储桶。使用 Amazon EventBridge 每天对帐户中的所有服务器运行 Systems Manager 文档。",
      "D": "安装 Amazon CloudWatch 代理。将所有日志推送到 CloudWatch 日志组。创建一个 CloudWatch 日志订阅，将所有传入的日志事件推送到 Amazon Kinesis Data Firehose 传送流。设置 Amazon S3 作为目的地。"
    }
  },
  {
    "id": 518,
    "topic": "1",
    "question_en": "An application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime. Which solution meets these requirements with the LEAST amount of effort?",
    "options_en": {
      "A": "Enable storage autoscaling in RDS",
      "B": "Increase the RDS database instance size",
      "C": "Change the RDS database instance storage type to Provisioned IOPS",
      "D": "Back up the RDS database, increase the storage capacity, restore the database, and stop the previous instance"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一个应用程序使用 Amazon RDS MySQL 数据库实例。RDS 数据库的磁盘空间不足。一个解决方案架构师希望在不停机的情况下增加磁盘空间。哪个解决方案以最少的精力满足这些要求？",
    "options_cn": {
      "A": "在 RDS 中启用存储自动扩展。",
      "B": "增加 RDS 数据库实例的大小。",
      "C": "将 RDS 数据库实例存储类型更改为 Provisioned IOPS。",
      "D": "备份 RDS 数据库，增加存储容量，恢复数据库，并停止之前的实例。"
    }
  },
  {
    "id": 519,
    "topic": "1",
    "question_en": "A consulting company provides professional services to customers worldwide. The company provides solutions and tools for customers to expedite gathering and analyzing data on AWS. The company needs to centrally manage and deploy a common set of solutions and tools for customers to use for self-service purposes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create AWS CloudFormation templates for the customers.",
      "B": "Create AWS Service Catalog products for the customers.",
      "C": "Create AWS Systems Manager templates for the customers.",
      "D": "Create AWS Config items for the customers."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家咨询公司为全球客户提供专业服务。该公司为客户提供解决方案和工具，以加速在 AWS 上收集和分析数据。该公司需要集中管理和部署一套通用的解决方案和工具，供客户用于自助服务。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为客户创建 AWS CloudFormation 模板。",
      "B": "为客户创建 AWS Service Catalog 产品。",
      "C": "为客户创建 AWS Systems Manager 模板。",
      "D": "为客户创建 AWS Config 项目。"
    }
  },
  {
    "id": 520,
    "topic": "1",
    "question_en": "A company is designing a new web application that will run on Amazon EC2 Instances. The application will use Amazon DynamoDB for backend data storage. The application trafic will be unpredictable. The company expects that the application read and write throughput to the database will be moderate to high. The company needs to scale in response to application trafic. Which DynamoDB table configuration will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure DynamoDB with provisioned read and write by using the DynamoDB Standard table class. Set DynamoDB auto scaling to a maximum defined capacity.",
      "B": "Configure DynamoDB in on-demand mode by using the DynamoDB Standard table class.",
      "C": "Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity.",
      "D": "Configure DynamoDB in on-demand mode by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class."
    },
    "correct_answer": "B",
    "vote_percentage": "63%",
    "question_cn": "一家公司正在设计一个将在 Amazon EC2 实例上运行的新 Web 应用程序。 该应用程序将使用 Amazon DynamoDB 作为后端数据存储。 应用程序的流量将是不可预测的。 公司预计对数据库的应用程序读写吞吐量将从中等到高。 公司需要根据应用程序流量进行扩展。 哪种 DynamoDB 表配置将最经济高效地满足这些要求？",
    "options_cn": {
      "A": "使用 DynamoDB 标准表类配置 DynamoDB，并使用预置的读写。 将 DynamoDB 自动伸缩设置为最大定义容量。",
      "B": "使用 DynamoDB 标准表类以按需模式配置 DynamoDB。",
      "C": "使用 DynamoDB 标准不频繁访问 (DynamoDB Standard-IA) 表类配置 DynamoDB，并使用预置的读写。 将 DynamoDB 自动伸缩设置为最大定义容量。",
      "D": "使用 DynamoDB 标准不频繁访问 (DynamoDB Standard-IA) 表类以按需模式配置 DynamoDB。"
    }
  },
  {
    "id": 521,
    "topic": "1",
    "question_en": "A retail company has several businesses. The IT team for each business manages its own AWS account. Each team account is part of an organization in AWS Organizations. Each team monitors its product inventory levels in an Amazon DynamoDB table in the team's own AWS account. The company is deploying a central inventory reporting application into a shared AWS account. The application must be able to read items from all the teams' DynamoDB tables. Which authentication option will meet these requirements MOST securely?",
    "options_en": {
      "A": "Integrate DynamoDB with AWS Secrets Manager in the inventory application account. Configure the application to use the correct secret from Secrets Manager to authenticate and read the DynamoDB table. Schedule secret rotation for every 30 days.",
      "B": "In every business account, create an IAM user that has programmatic access. Configure the application to use the correct IAM user access key ID and secret access key to authenticate and read the DynamoDB table. Manually rotate IAM access keys every 30 days.",
      "C": "In every business account, create an IAM role named BU_ROLE with a policy that gives the role access to the DynamoDB table and a trust policy to trust a specific role in the inventory application account. In the inventory account, create a role named APP_ROLE that allows access to the STS AssumeRole API operation. Configure the application to use APP_ROLE and assume the crossaccount role BU_ROLE to read the DynamoDB table.",
      "D": "Integrate DynamoDB with AWS Certificate Manager (ACM). Generate identity certificates to authenticate DynamoDB. Configure the application to use the correct certificate to authenticate and read the DynamoDB table."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家零售公司拥有多家业务。每个业务的 IT 团队都管理自己的 AWS 账户。每个团队账户都是 AWS Organizations 中组织的一部分。每个团队都会在其团队自己的 AWS 账户中的 Amazon DynamoDB 表中监控其产品库存水平。公司正在将一个中央库存报告应用程序部署到共享的 AWS 账户中。该应用程序必须能够从所有团队的 DynamoDB 表中读取项目。哪种身份验证选项最安全地满足这些要求？",
    "options_cn": {
      "A": "将 DynamoDB 与库存应用程序账户中的 AWS Secrets Manager 集成。配置应用程序使用来自 Secrets Manager 的正确密钥进行身份验证并读取 DynamoDB 表。安排每 30 天轮换一次密钥。",
      "B": "在每个业务账户中，创建一个具有编程访问权限的 IAM 用户。配置应用程序使用正确的 IAM 用户访问密钥 ID 和秘密访问密钥进行身份验证并读取 DynamoDB 表。手动轮换 IAM 访问密钥，每 30 天一次。",
      "C": "在每个业务账户中，创建一个名为 BU_ROLE 的 IAM 角色，该角色具有访问 DynamoDB 表的策略和信任策略，以信任库存应用程序账户中的特定角色。在库存账户中，创建一个名为 APP_ROLE 的角色，该角色允许访问 STS AssumeRole API 操作。配置应用程序使用 APP_ROLE 并代入跨账户角色 BU_ROLE 以读取 DynamoDB 表。",
      "D": "将 DynamoDB 与 AWS Certificate Manager (ACM) 集成。生成身份证书以对 DynamoDB 进行身份验证。配置应用程序使用正确的证书进行身份验证并读取 DynamoDB 表。"
    }
  },
  {
    "id": 522,
    "topic": "1",
    "question_en": "A company runs container applications by using Amazon Elastic Kubernetes Service (Amazon EKS). The company's workload is not consistent throughout the day. The company wants Amazon EKS to scale in and out according to the workload. Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Use an AWS Lambda function to resize the EKS cluster.",
      "B": "Use the Kubernetes Metrics Server to activate horizontal pod autoscaling.",
      "C": "Use the Kubernetes Cluster Autoscaler to manage the number of nodes in the cluster.",
      "D": "Use Amazon API Gateway and connect it to Amazon EKS",
      "E": "Use AWS App Mesh to observe network activity."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 运行容器应用程序。该公司的负载在一天中并不一致。该公司希望 Amazon EKS 根据工作负载进行横向扩展和缩减。以下哪种步骤组合将以最小的运营开销满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "使用 AWS Lambda 函数调整 EKS 集群的大小。",
      "B": "使用 Kubernetes Metrics Server 激活水平 Pod 自动伸缩。",
      "C": "使用 Kubernetes Cluster Autoscaler 管理集群中的节点数量。",
      "D": "使用 Amazon API Gateway 并将其连接到 Amazon EKS。",
      "E": "使用 AWS App Mesh 观察网络活动。"
    }
  },
  {
    "id": 523,
    "topic": "1",
    "question_en": "A company runs a microservice-based serverless web application. The application must be able to retrieve data from multiple Amazon DynamoDB tables A solutions architect needs to give the application the ability to retrieve the data with no impact on the baseline performance of the application. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "AWS AppSync pipeline resolvers",
      "B": "Amazon CloudFront with Lambda@Edge functions",
      "C": "Edge-optimized Amazon API Gateway with AWS Lambda functions",
      "D": "Amazon Athena Federated Query with a DynamoDB connector"
    },
    "correct_answer": "A",
    "vote_percentage": "49%",
    "question_cn": "一家公司运营一个基于微服务的无服务器 Web 应用程序。 该应用程序必须能够从多个 Amazon DynamoDB 表中检索数据。 一个解决方案架构师需要为该应用程序提供检索数据的能力，且不对应用程序的基线性能造成影响。 哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "AWS AppSync pipeline resolvers",
      "B": "带有 Lambda@Edge 函数的 Amazon CloudFront",
      "C": "带有 AWS Lambda 函数的 Edge-optimized Amazon API Gateway",
      "D": "带有 DynamoDB 连接器的 Amazon Athena Federated Query"
    }
  },
  {
    "id": 524,
    "topic": "1",
    "question_en": "A company wants to analyze and troubleshoot Access Denied errors and Unauthorized errors that are related to IAM permissions. The company has AWS CloudTrail turned on. Which solution will meet these requirements with the LEAST effort?",
    "options_en": {
      "A": "Use AWS Glue and write custom scripts to query CloudTrail logs for the errors.",
      "B": "Use AWS Batch and write custom scripts to query CloudTrail logs for the errors.",
      "C": "Search CloudTrail logs with Amazon Athena queries to identify the errors.",
      "D": "Search CloudTrail logs with Amazon QuickSight. Create a dashboard to identify the errors."
    },
    "correct_answer": "C",
    "vote_percentage": "68%",
    "question_cn": "一家公司希望分析和排除与 IAM 权限相关的“访问被拒绝”和“未授权”错误。该公司已启用 AWS CloudTrail。哪种解决方案以最少的精力满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Glue 并编写自定义脚本来查询 CloudTrail 日志以查找这些错误。",
      "B": "使用 AWS Batch 并编写自定义脚本来查询 CloudTrail 日志以查找这些错误。",
      "C": "使用 Amazon Athena 查询搜索 CloudTrail 日志以识别这些错误。",
      "D": "使用 Amazon QuickSight 搜索 CloudTrail 日志。创建一个仪表板以识别这些错误。"
    }
  },
  {
    "id": 525,
    "topic": "1",
    "question_en": "A company wants to add its existing AWS usage cost to its operation cost dashboard. A solutions architect needs to recommend a solution that will give the company access to its usage cost programmatically. The company must be able to access cost data for the current year and forecast costs for the next 12 months. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Access usage cost-related data by using the AWS Cost Explorer API with pagination.",
      "B": "Access usage cost-related data by using downloadable AWS Cost Explorer report .csv files.",
      "C": "Configure AWS Budgets actions to send usage cost data to the company through FTP.",
      "D": "Create AWS Budgets reports for usage cost data. Send the data to the company through SMTP."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将其现有的 AWS 使用成本添加到其运营成本仪表板中。一位解决方案架构师需要推荐一个解决方案，该解决方案将使该公司能够以编程方式访问其使用成本。该公司必须能够访问当年的成本数据并预测未来 12 个月的成本。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用带有分页功能的 AWS Cost Explorer API 访问与使用成本相关的数据。",
      "B": "使用可下载的 AWS Cost Explorer 报告 .csv 文件访问与使用成本相关的数据。",
      "C": "配置 AWS Budgets 操作，通过 FTP 将使用成本数据发送给公司。",
      "D": "创建 AWS Budgets 报告以获取使用成本数据。通过 SMTP 将数据发送给公司。"
    }
  },
  {
    "id": 526,
    "topic": "1",
    "question_en": "A solutions architect is reviewing the resilience of an application. The solutions architect notices that a database administrator recently failed over the application's Amazon Aurora PostgreSQL database writer instance as part of a scaling exercise. The failover resulted in 3 minutes of downtime for the application. Which solution will reduce the downtime for scaling exercises with the LEAST operational overhead?",
    "options_en": {
      "A": "Create more Aurora PostgreSQL read replicas in the cluster to handle the load during failover.",
      "B": "Set up a secondary Aurora PostgreSQL cluster in the same AWS Region. During failover, update the application to use the secondary cluster's writer endpoint.",
      "C": "Create an Amazon ElastiCache for Memcached cluster to handle the load during failover.",
      "D": "Set up an Amazon RDS proxy for the database. Update the application to use the proxy endpoint."
    },
    "correct_answer": "D",
    "vote_percentage": "72%",
    "question_cn": "一位解决方案架构师正在审查应用程序的弹性。该解决方案架构师注意到数据库管理员最近作为扩展练习的一部分，故障转移了应用程序的 Amazon Aurora PostgreSQL 数据库写入器实例。故障转移导致应用程序停机 3 分钟。哪种解决方案将以最少的运营开销来减少扩展练习的停机时间？",
    "options_cn": {
      "A": "在集群中创建更多 Aurora PostgreSQL 只读副本以处理故障转移期间的负载。",
      "B": "在同一 AWS 区域设置一个辅助 Aurora PostgreSQL 集群。在故障转移期间，更新应用程序以使用辅助集群的写入器端点。",
      "C": "创建一个 Amazon ElastiCache for Memcached 集群来处理故障转移期间的负载。",
      "D": "为数据库设置一个 Amazon RDS 代理。更新应用程序以使用代理端点。"
    }
  },
  {
    "id": 527,
    "topic": "1",
    "question_en": "A company has a regional subscription-based streaming service that runs in a single AWS Region. The architecture consists of web servers and application servers on Amazon EC2 instances. The EC2 instances are in Auto Scaling groups behind Elastic Load Balancers. The architecture includes an Amazon Aurora global database cluster that extends across multiple Availability Zones. The company wants to expand globally and to ensure that its application has minimal downtime. Which solution will provide the MOST fault tolerance?",
    "options_en": {
      "A": "Extend the Auto Scaling groups for the web tier and the application tier to deploy instances in Availability Zones in a second Region. Use an Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.",
      "B": "Deploy the web tier and the application tier to a second Region. Add an Aurora PostgreSQL cross-Region Aurora Replica in the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed.",
      "C": "Deploy the web tier and the application tier to a second Region. Create an Aurora PostgreSQL database in the second Region. Use AWS Database Migration Service (AWS DMS) to replicate the primary database to the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.",
      "D": "Deploy the web tier and the application tier to a second Region. Use an Amazon Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed."
    },
    "correct_answer": "B",
    "vote_percentage": "94%",
    "question_cn": "一家公司拥有一个基于区域的订阅流媒体服务，该服务在一个 AWS 区域中运行。该架构包括 Amazon EC2 实例上的 Web 服务器和应用程序服务器。EC2 实例位于 Elastic Load Balancer 之后的 Auto Scaling 组中。该架构包括一个跨多个可用区的 Amazon Aurora 全局数据库集群。该公司希望进行全球扩展，并确保其应用程序停机时间最短。哪种解决方案将提供最大的容错能力？",
    "options_cn": {
      "A": "扩展 Web 层和应用程序层的 Auto Scaling 组，以在第二个区域的可用区中部署实例。使用 Aurora 全局数据库在主区域和第二个区域中部署数据库。使用 Amazon Route 53 运行状况检查和故障转移路由策略到第二个区域。",
      "B": "将 Web 层和应用程序层部署到第二个区域。在第二个区域中添加 Aurora PostgreSQL 跨区域 Aurora 副本。使用 Amazon Route 53 运行状况检查和故障转移路由策略到第二个区域。根据需要将辅助数据库提升为主数据库。",
      "C": "将 Web 层和应用程序层部署到第二个区域。在第二个区域中创建一个 Aurora PostgreSQL 数据库。使用 AWS Database Migration Service (AWS DMS) 将主数据库复制到第二个区域。使用 Amazon Route 53 运行状况检查和故障转移路由策略到第二个区域。",
      "D": "将 Web 层和应用程序层部署到第二个区域。使用 Amazon Aurora 全局数据库在主区域和第二个区域中部署数据库。使用 Amazon Route 53 运行状况检查和故障转移路由策略到第二个区域。根据需要将辅助数据库提升为主数据库。"
    }
  },
  {
    "id": 528,
    "topic": "1",
    "question_en": "A data analytics company wants to migrate its batch processing system to AWS. The company receives thousands of small data files periodically during the day through FTP. An on-premises batch job processes the data files overnight. However, the batch job takes hours to finish running. The company wants the AWS solution to process incoming data files as soon as possible with minimal changes to the FTP clients that send the files. The solution must delete the incoming data files after the files have been processed successfully. Processing for each file needs to take 3-8 minutes. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Use an Amazon EC2 instance that runs an FTP server to store incoming files as objects in Amazon S3 Glacier Flexible Retrieval. Configure a job queue in AWS Batch. Use Amazon EventBridge rules to invoke the job to process the objects nightly from S3 Glacier Flexible Retrieval. Delete the objects after the job has processed the objects.",
      "B": "Use an Amazon EC2 instance that runs an FTP server to store incoming files on an Amazon Elastic Block Store (Amazon EBS) volume. Configure a job queue in AWS Batch. Use Amazon EventBridge rules to invoke the job to process the files nightly from the EBS volume. Delete the files after the job has processed the files.",
      "C": "Use AWS Transfer Family to create an FTP server to store incoming files on an Amazon Elastic Block Store (Amazon EBS) volume. Configure a job queue in AWS Batch. Use an Amazon S3 event notification when each file arrives to invoke the job in AWS Batch. Delete the files after the job has processed the files.",
      "D": "Use AWS Transfer Family to create an FTP server to store incoming files in Amazon S3 Standard. Create an AWS Lambda function to process the files and to delete the files after they are processed. Use an S3 event notification to invoke the Lambda function when the files arrive."
    },
    "correct_answer": "B",
    "vote_percentage": "93%",
    "question_cn": "一家数据分析公司希望将其批处理系统迁移到 AWS。该公司每天通过 FTP 定期间隔接收数千个小数据文件。一个本地批处理作业在夜间处理数据文件。但是，批处理作业需要数小时才能完成运行。该公司希望 AWS 解决方案尽快处理传入数据文件，同时尽可能减少对发送文件的 FTP 客户端的更改。该解决方案必须在文件成功处理后删除传入数据文件。每个文件的处理需要 3-8 分钟。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "使用运行 FTP 服务器的 Amazon EC2 实例将传入文件作为对象存储在 Amazon S3 Glacier Flexible Retrieval 中。在 AWS Batch 中配置一个作业队列。使用 Amazon EventBridge 规则每天晚上从 S3 Glacier Flexible Retrieval 中调用作业来处理这些对象。在作业处理完对象后删除这些对象。",
      "B": "使用运行 FTP 服务器的 Amazon EC2 实例将传入文件存储在 Amazon Elastic Block Store (Amazon EBS) 卷上。在 AWS Batch 中配置一个作业队列。使用 Amazon EventBridge 规则每天晚上从 EBS 卷调用作业来处理这些文件。在作业处理完文件后删除这些文件。",
      "C": "使用 AWS Transfer Family 创建一个 FTP 服务器，将传入文件存储在 Amazon Elastic Block Store (Amazon EBS) 卷上。在 AWS Batch 中配置一个作业队列。当每个文件到达时，使用 Amazon S3 事件通知来调用 AWS Batch 中的作业。在作业处理完文件后删除这些文件。",
      "D": "使用 AWS Transfer Family 创建一个 FTP 服务器，将传入文件存储在 Amazon S3 Standard 中。创建一个 AWS Lambda 函数来处理文件，并在处理完文件后删除这些文件。使用 S3 事件通知在文件到达时调用 Lambda 函数。"
    }
  },
  {
    "id": 529,
    "topic": "1",
    "question_en": "A company is migrating its workloads to AWS. The company has transactional and sensitive data in its databases. The company wants to use AWS Cloud solutions to increase security and reduce operational overhead for the databases. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the databases to Amazon EC2. Use an AWS Key Management Service (AWS KMS) AWS managed key for encryption.",
      "B": "Migrate the databases to Amazon RDS Configure encryption at rest.",
      "C": "Migrate the data to Amazon S3 Use Amazon Macie for data security and protection",
      "D": "Migrate the database to Amazon RDS. Use Amazon CloudWatch Logs for data security and protection."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其工作负载迁移到 AWS。该公司在其数据库中拥有事务性和敏感数据。该公司希望使用 AWS 云解决方案来提高安全性并减少数据库的运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon EC2。使用 AWS Key Management Service (AWS KMS) 的 AWS 托管密钥进行加密。",
      "B": "将数据库迁移到 Amazon RDS。配置静态加密。",
      "C": "将数据迁移到 Amazon S3。使用 Amazon Macie 进行数据安全和保护",
      "D": "将数据库迁移到 Amazon RDS。使用 Amazon CloudWatch Logs 进行数据安全和保护。"
    }
  },
  {
    "id": 530,
    "topic": "1",
    "question_en": "A company has an online gaming application that has TCP and UDP multiplayer gaming capabilities. The company uses Amazon Route 53 to point the application trafic to multiple Network Load Balancers (NLBs) in different AWS Regions. The company needs to improve application performance and decrease latency for the online game in preparation for user growth. Which solution will meet these requirements?",
    "options_en": {
      "A": "Add an Amazon CloudFront distribution in front of the NLBs. Increase the Cache-Control max-age parameter.",
      "B": "Replace the NLBs with Application Load Balancers (ALBs). Configure Route 53 to use latency-based routing.",
      "C": "Add AWS Global Accelerator in front of the NLBs. Configure a Global Accelerator endpoint to use the correct listener ports.",
      "D": "Add an Amazon API Gateway endpoint behind the NLBs. Enable API caching. Override method caching for the different stages."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个具有 TCP 和 UDP 多人游戏功能的在线游戏应用程序。该公司使用 Amazon Route 53 将应用程序流量指向不同 AWS 区域中的多个 Network Load Balancer (NLB)。该公司需要提高应用程序性能并减少在线游戏的延迟，为用户增长做好准备。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 NLB 前面添加 Amazon CloudFront 分发。增加 Cache-Control max-age 参数。",
      "B": "用 Application Load Balancer (ALB) 替换 NLB。配置 Route 53 以使用基于延迟的路由。",
      "C": "在 NLB 前面添加 AWS Global Accelerator。配置 Global Accelerator 终端节点以使用正确的监听器端口。",
      "D": "在 NLB 后面添加 Amazon API Gateway 终端节点。启用 API 缓存。覆盖不同阶段的方法缓存。"
    }
  },
  {
    "id": 531,
    "topic": "1",
    "question_en": "A company needs to integrate with a third-party data feed. The data feed sends a webhook to notify an external service when new data is ready for consumption. A developer wrote an AWS Lambda function to retrieve data when the company receives a webhook callback. The developer must make the Lambda function available for the third party to call. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create a function URL for the Lambda function. Provide the Lambda function URL to the third party for the webhook.",
      "B": "Deploy an Application Load Balancer (ALB) in front of the Lambda function. Provide the ALB URL to the third party for the webhook.",
      "C": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Attach the topic to the Lambda function. Provide the public hostname of the SNS topic to the third party for the webhook.",
      "D": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Attach the queue to the Lambda function. Provide the public hostname of the SQS queue to the third party for the webhook."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要与第三方数据源集成。当新数据准备好供使用时，数据源会发送一个 webhook 来通知外部服务。开发人员编写了一个 AWS Lambda 函数，以便在公司收到 webhook 回调时检索数据。开发人员必须使 Lambda 函数可供第三方调用。哪个解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "为 Lambda 函数创建一个函数 URL。将 Lambda 函数 URL 提供给第三方用于 webhook。",
      "B": "在 Lambda 函数前面部署一个 Application Load Balancer (ALB)。将 ALB URL 提供给第三方用于 webhook。",
      "C": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将该主题附加到 Lambda 函数。将 SNS 主题的公共主机名提供给第三方用于 webhook。",
      "D": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将该队列附加到 Lambda 函数。将 SQS 队列的公共主机名提供给第三方用于 webhook。"
    }
  },
  {
    "id": 532,
    "topic": "1",
    "question_en": "A company has a workload in an AWS Region. Customers connect to and access the workload by using an Amazon API Gateway REST API. The company uses Amazon Route 53 as its DNS provider. The company wants to provide individual and secure URLs for all customers. Which combination of steps will meet these requirements with the MOST operational eficiency? (Choose three.)",
    "options_en": {
      "A": "Register the required domain in a registrar. Create a wildcard custom domain name in a Route 53 hosted zone and record in the zone that points to the API Gateway endpoint.",
      "B": "Request a wildcard certificate that matches the domains in AWS Certificate Manager (ACM) in a different Region.",
      "C": "Create hosted zones for each customer as required in Route 53. Create zone records that point to the API Gateway endpoint.",
      "D": "Request a wildcard certificate that matches the custom domain name in AWS Certificate Manager (ACM) in the same Region",
      "E": "Create multiple API endpoints for each customer in API Gateway",
      "F": "Create a custom domain name in API Gateway for the REST API. Import the certificate from AWS Certificate Manager (ACM)."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 区域中有一个工作负载。客户使用 Amazon API Gateway REST API 连接并访问该工作负载。该公司使用 Amazon Route 53 作为其 DNS 提供商。该公司希望为所有客户提供单独且安全的 URL。哪种步骤组合将以最高的运营效率满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "在注册商处注册所需的域名。在 Route 53 托管区域中创建一个通配符自定义域名，并在该区域中创建指向 API Gateway 终端节点的记录。",
      "B": "在另一个区域的 AWS Certificate Manager (ACM) 中请求与这些域匹配的通配符证书。",
      "C": "根据需要在 Route 53 中为每个客户创建托管区域。创建指向 API Gateway 终端节点的区域记录。",
      "D": "在同一区域的 AWS Certificate Manager (ACM) 中请求与自定义域名匹配的通配符证书。",
      "E": "在 API Gateway 中为每个客户创建多个 API 终端节点。",
      "F": "在 API Gateway 中为 REST API 创建一个自定义域名。从 AWS Certificate Manager (ACM) 导入证书。"
    }
  },
  {
    "id": 533,
    "topic": "1",
    "question_en": "A company stores data in Amazon S3. According to regulations, the data must not contain personally identifiable information (PII). The company recently discovered that S3 buckets have some objects that contain PII. The company needs to automatically detect PII in S3 buckets and to notify the company’s security team. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData event type from Macie findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team.",
      "B": "Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team.",
      "C": "Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData:S3Object/Personal event type from Macie findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team.",
      "D": "Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team."
    },
    "correct_answer": "C",
    "vote_percentage": "83%",
    "question_cn": "一家公司将数据存储在 Amazon S3 中。根据法规，数据不得包含个人身份信息 (PII)。该公司最近发现 S3 存储桶中存在包含 PII 的对象。该公司需要自动检测 S3 存储桶中的 PII，并通知公司的安全团队。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Macie。创建一个 Amazon EventBridge 规则，以从 Macie 调查结果中筛选 SensitiveData 事件类型，并向安全团队发送 Amazon Simple Notification Service (Amazon SNS) 通知。",
      "B": "使用 Amazon GuardDuty。创建一个 Amazon EventBridge 规则，以从 GuardDuty 调查结果中筛选 CRITICAL 事件类型，并向安全团队发送 Amazon Simple Notification Service (Amazon SNS) 通知。",
      "C": "使用 Amazon Macie。创建一个 Amazon EventBridge 规则，以从 Macie 调查结果中筛选 SensitiveData:S3Object/Personal 事件类型，并向安全团队发送 Amazon Simple Queue Service (Amazon SQS) 通知。",
      "D": "使用 Amazon GuardDuty。创建一个 Amazon EventBridge 规则，以从 GuardDuty 调查结果中筛选 CRITICAL 事件类型，并向安全团队发送 Amazon Simple Queue Service (Amazon SQS) 通知。"
    }
  },
  {
    "id": 534,
    "topic": "1",
    "question_en": "A company wants to build a logging solution for its multiple AWS accounts. The company currently stores the logs from all accounts in a centralized account. The company has created an Amazon S3 bucket in the centralized account to store the VPC fiow logs and AWS CloudTrail logs. All logs must be highly available for 30 days for frequent analysis, retained for an additional 60 days for backup purposes, and deleted 90 days after creation. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Transition objects to the S3 Standard storage class 30 days after creation. Write an expiration action that directs Amazon S3 to delete objects after 90 days.",
      "B": "Transition objects to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class 30 days after creation. Move all objects to the S3 Glacier Flexible Retrieval storage class after 90 days. Write an expiration action that directs Amazon S3 to delete objects after 90 days.",
      "C": "Transition objects to the S3 Glacier Flexible Retrieval storage class 30 days after creation. Write an expiration action that directs Amazon S3 to delete objects after 90 days.",
      "D": "Transition objects to the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class 30 days after creation. Move all objects to the S3 Glacier Flexible Retrieval storage class after 90 days. Write an expiration action that directs Amazon S3 to delete objects after 90 days."
    },
    "correct_answer": "B",
    "vote_percentage": "62%",
    "question_cn": "一家公司希望为其多个 AWS 账户构建一个日志记录解决方案。该公司目前将所有账户的日志存储在一个集中账户中。该公司已在集中账户中创建了一个 Amazon S3 存储桶，用于存储 VPC 流日志和 AWS CloudTrail 日志。所有日志必须在创建后 30 天内高度可用，以供频繁分析，额外保留 60 天用于备份，并在创建后 90 天删除。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在创建 30 天后，将对象过渡到 S3 标准存储类。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。",
      "B": "在创建 30 天后，将对象过渡到 S3 Standard-IA 存储类。在 90 天后，将所有对象移动到 S3 Glacier Flexible Retrieval 存储类。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。",
      "C": "在创建 30 天后，将对象过渡到 S3 Glacier Flexible Retrieval 存储类。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。",
      "D": "在创建 30 天后，将对象过渡到 S3 One Zone-IA 存储类。在 90 天后，将所有对象移动到 S3 Glacier Flexible Retrieval 存储类。编写一个过期操作，指示 Amazon S3 在 90 天后删除对象。"
    }
  },
  {
    "id": 535,
    "topic": "1",
    "question_en": "A company is building an Amazon Elastic Kubernetes Service (Amazon EKS) cluster for its workloads. All secrets that are stored in Amazon EKS must be encrypted in the Kubernetes etcd key-value store. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a new AWS Key Management Service (AWS KMS) key. Use AWS Secrets Manager to manage, rotate, and store all secrets in Amazon EKS.",
      "B": "Create a new AWS Key Management Service (AWS KMS) key. Enable Amazon EKS KMS secrets encryption on the Amazon EKS cluster.",
      "C": "Create the Amazon EKS cluster with default options. Use the Amazon Elastic Block Store (Amazon EBS) Container Storage Interface (CSI) driver as an add-on.",
      "D": "Create a new AWS Key Management Service (AWS KMS) key with the alias/aws/ebs alias. Enable default Amazon Elastic Block Store (Amazon EBS) volume encryption for the account."
    },
    "correct_answer": "D",
    "vote_percentage": "95%",
    "question_cn": "一家公司正在为其工作负载构建 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。存储在 Amazon EKS 中的所有密钥都必须在 Kubernetes etcd 键值存储中加密。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 AWS Key Management Service (AWS KMS) 密钥。使用 AWS Secrets Manager 在 Amazon EKS 中管理、轮换和存储所有密钥。",
      "B": "创建一个新的 AWS Key Management Service (AWS KMS) 密钥。在 Amazon EKS 集群上打开 Amazon EKS KMS 密钥加密。",
      "C": "使用默认选项创建 Amazon EKS 集群。将 Amazon Elastic Block Store (Amazon EBS) 容器存储接口 (CSI) 驱动程序用作附加组件。",
      "D": "创建一个新的 AWS Key Management Service (AWS KMS) 密钥，别名为/aws/ebs。为账户打开默认的 Amazon Elastic Block Store (Amazon EBS) 卷加密。"
    }
  },
  {
    "id": 536,
    "topic": "1",
    "question_en": "A company wants to provide data scientists with near real-time read-only access to the company's production Amazon RDS for PostgreSQL database. The database is currently configured as a Single-AZ database. The data scientists use complex queries that will not affect the production database. The company needs a solution that is highly available. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Scale the existing production database in a maintenance window to provide enough power for the data scientists.",
      "B": "Change the setup from a Single-AZ to a Multi-AZ instance deployment with a larger secondary standby instance. Provide the data scientists access to the secondary instance.",
      "C": "Change the setup from a Single-AZ to a Multi-AZ instance deployment. Provide two additional read replicas for the data scientists.",
      "D": "Change the setup from a Single-AZ to a Multi-AZ cluster deployment with two readable standby instances. Provide read endpoints to the data scientists."
    },
    "correct_answer": "C",
    "vote_percentage": "82%",
    "question_cn": "一家公司希望为数据科学家提供对公司生产 Amazon RDS for PostgreSQL 数据库的近乎实时的只读访问权限。该数据库目前配置为单可用区数据库。数据科学家使用复杂的查询，这些查询不会影响生产数据库。该公司需要一个高可用性的解决方案。哪种解决方案能最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在维护窗口期间扩展现有的生产数据库，为数据科学家提供足够的算力。",
      "B": "将设置从单可用区更改为多可用区实例部署，并使用一个更大的辅助备用实例。为数据科学家提供对辅助实例的访问权限。",
      "C": "将设置从单可用区更改为多可用区实例部署。为数据科学家提供两个额外的只读副本。",
      "D": "将设置从单可用区更改为多可用区集群部署，并提供两个可读备用实例。为数据科学家提供读取端点。"
    }
  },
  {
    "id": 537,
    "topic": "1",
    "question_en": "A company runs a three-tier web application in the AWS Cloud that operates across three Availability Zones. The application architecture has an Application Load Balancer, an Amazon EC2 web server that hosts user session states, and a MySQL database that runs on an EC2 instance. The company expects sudden increases in application trafic. The company wants to be able to scale to meet future application capacity demands and to ensure high availability across all three Availability Zones. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the MySQL database to Amazon RDS for MySQL with a Multi-AZ DB cluster deployment. Use Amazon ElastiCache for Redis with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones.",
      "B": "Migrate the MySQL database to Amazon RDS for MySQL with a Multi-AZ DB cluster deployment. Use Amazon ElastiCache for Memcached with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones.",
      "C": "Migrate the MySQL database to Amazon DynamoDB Use DynamoDB Accelerator (DAX) to cache reads. Store the session data in DynamoDB. Migrate the web server to an Auto Scaling group that is in three Availability Zones.",
      "D": "Migrate the MySQL database to Amazon RDS for MySQL in a single Availability Zone. Use Amazon ElastiCache for Redis with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones."
    },
    "correct_answer": "B",
    "vote_percentage": "79%",
    "question_cn": "一家公司在 AWS 云中运行一个三层 Web 应用程序，该应用程序跨越三个可用区。该应用程序架构包含一个 Application Load Balancer、一个托管用户会话状态的 Amazon EC2 Web 服务器和一个在 EC2 实例上运行的 MySQL 数据库。该公司预计应用程序流量会突然增加。该公司希望能够扩展以满足未来的应用程序容量需求，并确保跨所有三个可用区的高可用性。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 MySQL 数据库迁移到 Amazon RDS for MySQL，并进行多可用区数据库集群部署。使用具有高可用性的 Amazon ElastiCache for Redis 来存储会话数据并缓存读取操作。将 Web 服务器迁移到位于三个可用区中的 Auto Scaling 组。",
      "B": "将 MySQL 数据库迁移到 Amazon RDS for MySQL，并进行多可用区数据库集群部署。使用具有高可用性的 Amazon ElastiCache for Memcached 来存储会话数据并缓存读取操作。将 Web 服务器迁移到位于三个可用区中的 Auto Scaling 组。",
      "C": "将 MySQL 数据库迁移到 Amazon DynamoDB。使用 DynamoDB Accelerator (DAX) 来缓存读取操作。将会话数据存储在 DynamoDB 中。将 Web 服务器迁移到位于三个可用区中的 Auto Scaling 组。",
      "D": "将 MySQL 数据库迁移到单个可用区中的 Amazon RDS for MySQL。使用具有高可用性的 Amazon ElastiCache for Redis 来存储会话数据并缓存读取操作。将 Web 服务器迁移到位于三个可用区中的 Auto Scaling 组。"
    }
  },
  {
    "id": 538,
    "topic": "1",
    "question_en": "A global video streaming company uses Amazon CloudFront as a content distribution network (CDN). The company wants to roll out content in a phased manner across multiple countries. The company needs to ensure that viewers who are outside the countries to which the company rolls out content are not able to view the content. Which solution will meet these requirements?",
    "options_en": {
      "A": "Add geographic restrictions to the content in CloudFront by using an allow list. Set up a custom error message.",
      "B": "Set up a new URL tor restricted content. Authorize access by using a signed URL and cookies. Set up a custom error message.",
      "C": "Encrypt the data for the content that the company distributes. Set up a custom error message.",
      "D": "Create a new URL for restricted content. Set up a time-restricted access policy for signed URLs."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家全球视频流公司使用 Amazon CloudFront 作为内容分发网络 (CDN)。该公司希望分阶段向多个国家/地区推出内容。该公司需要确保位于该公司未推出内容的国家/地区的观看者无法观看该内容。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过使用允许列表，在 CloudFront 中为内容添加地理限制。设置自定义错误消息。",
      "B": "为受限内容设置一个新 URL。通过使用签名 URL 和 Cookie 授权访问。设置自定义错误消息。",
      "C": "加密公司分发的内容数据。设置自定义错误消息。",
      "D": "为受限内容创建一个新 URL。为签名 URL 设置时间限制访问策略。"
    }
  },
  {
    "id": 539,
    "topic": "1",
    "question_en": "A company wants to use the AWS Cloud to improve its on-premises disaster recovery (DR) configuration. The company's core production business application uses Microsoft SQL Server Standard, which runs on a virtual machine (VM). The application has a recovery point objective (RPO) of 30 seconds or fewer and a recovery time objective (RTO) of 60 minutes. The DR solution needs to minimize costs wherever possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure a multi-site active/active setup between the on-premises server and AWS by using Microsoft SQL Server Enterprise with Always On availability groups.",
      "B": "Configure a warm standby Amazon RDS for SQL Server database on AWS. Configure AWS Database Migration Service (AWS DMS) to use change data capture (CDC).",
      "C": "Use AWS Elastic Disaster Recovery configured to replicate disk changes to AWS as a pilot light.",
      "D": "Use third-party backup software to capture backups every night. Store a secondary set of backups in Amazon S3."
    },
    "correct_answer": "D",
    "vote_percentage": "58%",
    "question_cn": "一家公司希望使用 AWS Cloud 来改善其本地灾难恢复 (DR) 配置。该公司的核心生产业务应用程序使用 Microsoft SQL Server Standard，该应用程序运行在虚拟机 (VM) 上。该应用程序的恢复点目标 (RPO) 为 30 秒或更短，恢复时间目标 (RTO) 为 60 分钟。DR 解决方案需要尽可能降低成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过使用 Microsoft SQL Server Enterprise 和 Always On 可用性组，在本地服务器和 AWS 之间配置多站点 active/active 设置。",
      "B": "在 AWS 上配置一个 warm standby Amazon RDS for SQL Server 数据库。配置 AWS Database Migration Service (AWS DMS) 以使用更改数据捕获 (CDC)。",
      "C": "使用 AWS Elastic Disaster Recovery，配置其将磁盘更改复制到 AWS 作为 pilot light。",
      "D": "使用第三方备份软件每晚捕获备份。将第二组备份存储在 Amazon S3 中。"
    }
  },
  {
    "id": 540,
    "topic": "1",
    "question_en": "A company has an on-premises server that uses an Oracle database to process and store customer information. The company wants to use an AWS database service to achieve higher availability and to improve application performance. The company also wants to ofioad reporting from its primary database system. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Use AWS Database Migration Service (AWS DMS) to create an Amazon RDS DB instance in multiple AWS Regions. Point the reporting functions toward a separate DB instance from the primary DB instance.",
      "B": "Use Amazon RDS in a Single-AZ deployment to create an Oracle database. Create a read replica in the same zone as the primary DB instance. Direct the reporting functions to the read replica.",
      "C": "Use Amazon RDS deployed in a Multi-AZ cluster deployment to create an Oracle database. Direct the reporting functions to use the reader instance in the cluster deployment.",
      "D": "Use Amazon RDS deployed in a Multi-AZ instance deployment to create an Amazon Aurora database. Direct the reporting functions to the reader instances."
    },
    "correct_answer": "D",
    "vote_percentage": "67%",
    "question_cn": "一家公司拥有一台本地服务器，该服务器使用 Oracle 数据库来处理和存储客户信息。该公司希望使用 AWS 数据库服务来实现更高的可用性并提高应用程序性能。该公司还希望将报表功能从其主要数据库系统卸载。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Database Migration Service (AWS DMS) 在多个 AWS 区域中创建 Amazon RDS 数据库实例。将报表功能指向与主数据库实例不同的数据库实例。",
      "B": "在单可用区部署中使用 Amazon RDS 创建 Oracle 数据库。在与主数据库实例相同的可用区中创建只读副本。将报表功能定向到只读副本。",
      "C": "在多可用区集群部署中使用 Amazon RDS 创建 Oracle 数据库。将报表功能定向到集群部署中的读取器实例。",
      "D": "在多可用区实例部署中使用 Amazon RDS 创建 Amazon Aurora 数据库。将报表功能定向到读取器实例。"
    }
  },
  {
    "id": 541,
    "topic": "1",
    "question_en": "A company wants to build a web application on AWS. Client access requests to the website are not predictable and can be idle for a long time. Only customers who have paid a subscription fee can have the ability to sign in and use the web application. Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.)",
    "options_en": {
      "A": "Create an AWS Lambda function to retrieve user information from Amazon DynamoDB. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.",
      "B": "Create an Amazon Elastic Container Service (Amazon ECS) service behind an Application Load Balancer to retrieve user information from Amazon RDS. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.",
      "C": "Create an Amazon Cognito user pool to authenticate users.",
      "D": "Create an Amazon Cognito identity pool to authenticate users",
      "E": "Use AWS Amplify to serve the frontend web content with HTML, CSS, and JS. Use an integrated Amazon CloudFront configuration",
      "F": "Use Amazon S3 static web hosting with PHP, CSS, and JS. Use Amazon CloudFront to serve the frontend web content."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司希望在 AWS 上构建一个 Web 应用程序。客户端对网站的访问请求是不可预测的，并且可以闲置很长时间。只有支付了订阅费的客户才能登录并使用 Web 应用程序。哪些步骤组合将以最具成本效益的方式满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，用于从 Amazon DynamoDB 检索用户信息。创建一个 Amazon API Gateway 端点以接受 RESTful API。将 API 调用发送到 Lambda 函数。",
      "B": "创建一个位于 Application Load Balancer 之后的 Amazon Elastic Container Service (Amazon ECS) 服务，用于从 Amazon RDS 检索用户信息。创建一个 Amazon API Gateway 端点以接受 RESTful API。将 API 调用发送到 Lambda 函数。",
      "C": "创建一个 Amazon Cognito 用户池来验证用户。",
      "D": "创建一个 Amazon Cognito 身份池来验证用户。",
      "E": "使用 AWS Amplify 通过 HTML、CSS 和 JS 提供前端 Web 内容。使用集成的 Amazon CloudFront 配置。",
      "F": "使用 Amazon S3 静态 Web 托管，其中包含 PHP、CSS 和 JS。使用 Amazon CloudFront 提供前端 Web 内容。"
    }
  },
  {
    "id": 542,
    "topic": "1",
    "question_en": "A media company uses an Amazon CloudFront distribution to deliver content over the internet. The company wants only premium customers to have access to the media streams and file content. The company stores all content in an Amazon S3 bucket. The company also delivers content on demand to customers for a specific purpose, such as movie rentals or music downloads. Which solution will meet these requirements?",
    "options_en": {
      "A": "Generate and provide S3 signed cookies to premium customers.",
      "B": "Generate and provide CloudFront signed URLs to premium customers.",
      "C": "Use origin access control (OAC) to limit the access of non-premium customers.",
      "D": "Generate and activate field-level encryption to block non-premium customers."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家媒体公司使用 Amazon CloudFront 分发来通过互联网提供内容。该公司只希望高级客户才能访问媒体流和文件内容。该公司将所有内容存储在 Amazon S3 存储桶中。该公司还根据特定目的（如电影租赁或音乐下载）按需向客户提供内容。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "生成 S3 签名 Cookie 并提供给高级客户。",
      "B": "生成 CloudFront 签名 URL 并提供给高级客户。",
      "C": "使用源访问控制 (OAC) 来限制非高级客户的访问。",
      "D": "生成并激活字段级加密以阻止非高级客户。"
    }
  },
  {
    "id": 543,
    "topic": "1",
    "question_en": "A company runs Amazon EC2 instances in multiple AWS accounts that are individually bled. The company recently purchased a Savings Pian. Because of changes in the company’s business requirements, the company has decommissioned a large number of EC2 instances. The company wants to use its Savings Plan discounts on its other AWS accounts. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "From the AWS Account Management Console of the management account, turn on discount sharing from the billing preferences section.",
      "B": "From the AWS Account Management Console of the account that purchased the existing Savings Plan, turn on discount sharing from the billing preferences section. Include all accounts.",
      "C": "From the AWS Organizations management account, use AWS Resource Access Manager (AWS RAM) to share the Savings Plan with other accounts.",
      "D": "Create an organization in AWS Organizations in a new payer account. Invite the other AWS accounts to join the organization from the management account",
      "E": "Create an organization in AWS Organizations in the existing AWS account with the existing EC2 instances and Savings Plan. Invite the other AWS accounts to join the organization from the management account."
    },
    "correct_answer": "A",
    "vote_percentage": "40%",
    "question_cn": "一家公司在多个单独计费的 AWS 账户中运行 Amazon EC2 实例。该公司最近购买了 Savings Plan。由于公司业务需求的变化，该公司已停用了大量 EC2 实例。该公司希望在其其他 AWS 账户上使用其 Savings Plan 折扣。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "从管理账户的 AWS 账户管理控制台中，从计费偏好部分打开折扣共享。",
      "B": "从购买现有 Savings Plan 的账户的 AWS 账户管理控制台中，从计费偏好部分打开折扣共享。包括所有账户。",
      "C": "从 AWS Organizations 管理账户中，使用 AWS Resource Access Manager (AWS RAM) 与其他账户共享 Savings Plan。",
      "D": "在新付款人账户的 AWS Organizations 中创建一个组织。从管理账户邀请其他 AWS 账户加入该组织。",
      "E": "在包含现有 EC2 实例和 Savings Plan 的现有 AWS 账户的 AWS Organizations 中创建一个组织。从管理账户邀请其他 AWS 账户加入该组织。"
    }
  },
  {
    "id": 544,
    "topic": "1",
    "question_en": "A retail company uses a regional Amazon API Gateway API for its public REST APIs. The API Gateway endpoint is a custom domain name that points to an Amazon Route 53 alias record. A solutions architect needs to create a solution that has minimal effects on customers and minimal data loss to release the new version of APIs. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a canary release deployment stage for API Gateway. Deploy the latest API version. Point an appropriate percentage of trafic to the canary stage. After API verification, promote the canary stage to the production stage.",
      "B": "Create a new API Gateway endpoint with a new version of the API in OpenAPI YAML file format. Use the import-to-update operation in merge mode into the API in API Gateway. Deploy the new version of the API to the production stage.",
      "C": "Create a new API Gateway endpoint with a new version of the API in OpenAPI JSON file format. Use the import-to-update operation in overwrite mode into the API in API Gateway. Deploy the new version of the API to the production stage.",
      "D": "Create a new API Gateway endpoint with new versions of the API definitions. Create a custom domain name for the new API Gateway API. Point the Route 53 alias record to the new API Gateway API custom domain name."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家零售公司使用区域 Amazon API Gateway API 来处理其公共 REST API。API Gateway 终端节点是一个自定义域名，指向 Amazon Route 53 别名记录。解决方案架构师需要创建一个对客户影响最小且数据丢失最小的解决方案来发布新版本的 API。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 API Gateway 创建一个 canary 发布部署阶段。部署最新的 API 版本。将适当比例的流量指向 canary 阶段。在 API 验证后，将 canary 阶段升级到生产阶段。",
      "B": "使用 OpenAPI YAML 文件格式创建包含新版本 API 的新 API Gateway 终端节点。在 API Gateway 中使用 import-to-update 操作以合并模式导入 API。将新版本的 API 部署到生产阶段。",
      "C": "使用 OpenAPI JSON 文件格式创建包含新版本 API 的新 API Gateway 终端节点。在 API Gateway 中使用 import-to-update 操作以覆盖模式导入 API。将新版本的 API 部署到生产阶段。",
      "D": "创建一个包含新版本 API 定义的新 API Gateway 终端节点。为新的 API Gateway API 创建自定义域名。将 Route 53 别名记录指向新的 API Gateway API 自定义域名。"
    }
  },
  {
    "id": 545,
    "topic": "1",
    "question_en": "A company wants to direct its users to a backup static error page if the company's primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53. The domain is pointing to an Application Load Balancer (ALB). The company needs a solution that minimizes changes and infrastructure overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Update the Route 53 records to use a latency routing policy. Add a static error page that is hosted in an Amazon S3 bucket to the records so that the trafic is sent to the most responsive endpoints.",
      "B": "Set up a Route 53 active-passive failover configuration. Direct trafic to a static error page that is hosted in an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.",
      "C": "Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance that hosts a static error page as endpoints. Configure Route 53 to send requests to the instance only if the health checks fail for the ALB.",
      "D": "Update the Route 53 records to use a multivalue answer routing policy. Create a health check. Direct trafic to the website if the health check passes. Direct trafic to a static error page that is hosted in Amazon S3 if the health check does not pass."
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一家公司希望在其主要网站不可用时，将用户定向到备份静态错误页面。该公司的主要网站的 DNS 记录托管在 Amazon Route 53 中。该域名指向 Application Load Balancer (ALB)。该公司需要一个可以最大限度地减少更改和基础设施开销的解决方案。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "更新 Route 53 记录以使用延迟路由策略。将托管在 Amazon S3 存储桶中的静态错误页面添加到记录中，以便将流量发送到响应速度最快的端点。",
      "B": "设置 Route 53 主动-被动故障转移配置。当 Route 53 运行状况检查确定 ALB 端点运行状况不佳时，将流量定向到托管在 Amazon S3 存储桶中的静态错误页面。",
      "C": "使用 ALB 和托管静态错误页面的 Amazon EC2 实例作为端点，设置 Route 53 主动-主动配置。配置 Route 53，仅在 ALB 的运行状况检查失败时，才将请求发送到该实例。",
      "D": "更新 Route 53 记录以使用多值答案路由策略。创建一个运行状况检查。如果运行状况检查通过，则将流量定向到网站。如果运行状况检查未通过，则将流量定向到托管在 Amazon S3 中的静态错误页面。"
    }
  },
  {
    "id": 546,
    "topic": "1",
    "question_en": "A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information oficer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workfiows. What should a solutions architect recommend?",
    "options_en": {
      "A": "Set up AWS Storage Gateway to connect with the backup applications using the NFS interface.",
      "B": "Set up an Amazon EFS file system that connects with the backup applications using the NFS interface.",
      "C": "Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface.",
      "D": "Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "最近对一家公司的 IT 支出的分析强调需要降低备份成本。公司首席信息官希望简化本地备份基础设施，并通过取消使用物理备份磁带来降低成本。公司必须保留对本地备份应用程序和工作流程的现有投资。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "设置 AWS Storage Gateway，使用 NFS 接口与备份应用程序连接。",
      "B": "设置 Amazon EFS 文件系统，使用 NFS 接口与备份应用程序连接。",
      "C": "设置 Amazon EFS 文件系统，使用 iSCSI 接口与备份应用程序连接。",
      "D": "设置 AWS Storage Gateway，使用 iSCSI-虚拟磁带库 (VTL) 接口与备份应用程序连接。"
    }
  },
  {
    "id": 547,
    "topic": "1",
    "question_en": "A company has data collection sensors at different locations. The data collection sensors stream a high volume of data to the company. The company wants to design a platform on AWS to ingest and process high-volume streaming data. The solution must be scalable and support data collection in near real time. The company must store the data in Amazon S3 for future reporting. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon Kinesis Data Firehose to deliver streaming data to Amazon S3.",
      "B": "Use AWS Glue to deliver streaming data to Amazon S3.",
      "C": "Use AWS Lambda to deliver streaming data and store the data to Amazon S3.",
      "D": "Use AWS Database Migration Service (AWS DMS) to deliver streaming data to Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "84%",
    "question_cn": "一家公司在不同地点设有数据收集传感器。这些数据收集传感器向公司流式传输大量数据。该公司希望在 AWS 上设计一个平台来摄取和处理大容量流数据。该解决方案必须具有可扩展性，并支持近实时的数据收集。该公司必须将数据存储在 Amazon S3 中，以供将来报告。哪种解决方案以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Firehose 将流数据传输到 Amazon S3。",
      "B": "使用 AWS Glue 将流数据传输到 Amazon S3。",
      "C": "使用 AWS Lambda 传输流数据并将数据存储到 Amazon S3。",
      "D": "使用 AWS Database Migration Service (AWS DMS) 将流数据传输到 Amazon S3。"
    }
  },
  {
    "id": 548,
    "topic": "1",
    "question_en": "A company has separate AWS accounts for its finance, data analytics, and development departments. Because of costs and security concerns, the company wants to control which services each AWS account can use. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Systems Manager templates to control which AWS services each department can use.",
      "B": "Create organization units (OUs) for each department in AWS Organizations. Attach service control policies (SCPs) to the OUs.",
      "C": "Use AWS CloudFormation to automatically provision only the AWS services that each department can use.",
      "D": "Set up a list of products in AWS Service Catalog in the AWS accounts to manage and control the usage of specific AWS services."
    },
    "correct_answer": "B",
    "vote_percentage": "89%",
    "question_cn": "一家公司为其财务、数据分析和开发部门分别设置了 AWS 账户。由于成本和安全方面的考虑，公司希望控制每个 AWS 账户可以使用哪些服务。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Systems Manager 模板来控制每个部门可以使用哪些 AWS 服务。",
      "B": "在 AWS Organizations 中为每个部门创建组织单位（OU）。将服务控制策略（SCP）附加到 OU。",
      "C": "使用 AWS CloudFormation 自动配置每个部门可以使用的 AWS 服务。",
      "D": "在 AWS 账户中设置 AWS Service Catalog 中的产品列表，以管理和控制特定 AWS 服务的使用。"
    }
  },
  {
    "id": 549,
    "topic": "1",
    "question_en": "A company has created a multi-tier application for its ecommerce website. The website uses an Application Load Balancer that resides in the public subnets, a web tier in the public subnets, and a MySQL cluster hosted on Amazon EC2 instances in the private subnets. The MySQL database needs to retrieve product catalog and pricing information that is hosted on the internet by a third-party provider. A solutions architect must devise a strategy that maximizes security without increasing operational overhead. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Deploy a NAT instance in the VPC. Route all the internet-based trafic through the NAT instance.",
      "B": "Deploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound trafic to the NAT gateway.",
      "C": "Configure an internet gateway and attach it to the VPModify the private subnet route table to direct internet-bound trafic to the internet gateway.",
      "D": "Configure a virtual private gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound trafic to the virtual private gateway."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司为其电子商务网站创建了一个多层应用程序。该网站使用位于公共子网中的 Application Load Balancer，公共子网中的 Web 层以及托管在私有子网中的 Amazon EC2 实例上的 MySQL 集群。MySQL 数据库需要检索由第三方提供商托管在互联网上的产品目录和定价信息。解决方案架构师必须设计一种策略，该策略可在不增加运营开销的情况下最大程度地提高安全性。解决方案架构师应如何满足这些要求？",
    "options_cn": {
      "A": "在 VPC 中部署 NAT 实例。将所有基于互联网的流量路由到 NAT 实例。",
      "B": "在公共子网中部署 NAT 网关。修改私有子网路由表，将所有互联网流量导向 NAT 网关。",
      "C": "配置互联网网关并将其附加到 VPC。修改私有子网路由表，将互联网流量导向互联网网关。",
      "D": "配置虚拟私有网关并将其附加到 VPC。修改私有子网路由表，将互联网流量导向虚拟私有网关。"
    }
  },
  {
    "id": 550,
    "topic": "1",
    "question_en": "A company is using AWS Key Management Service (AWS KMS) keys to encrypt AWS Lambda environment variables. A solutions architect needs to ensure that the required permissions are in place to decrypt and use the environment variables. Which steps must the solutions architect take to implement the correct permissions? (Choose two.)",
    "options_en": {
      "A": "Add AWS KMS permissions in the Lambda resource policy.",
      "B": "Add AWS KMS permissions in the Lambda execution role.",
      "C": "Add AWS KMS permissions in the Lambda function policy.",
      "D": "Allow the Lambda execution role in the AWS KMS key policy",
      "E": "Allow the Lambda resource policy in the AWS KMS key policy."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 AWS Key Management Service (AWS KMS) 密钥来加密 AWS Lambda 环境变量。一位解决方案架构师需要确保具备解密和使用环境变量的必要权限。解决方案架构师必须采取哪些步骤才能实施正确的权限？（选择两项。）",
    "options_cn": {
      "A": "在 Lambda 资源策略中添加 AWS KMS 权限。",
      "B": "在 Lambda 执行角色中添加 AWS KMS 权限。",
      "C": "在 Lambda 函数策略中添加 AWS KMS 权限。",
      "D": "在 AWS KMS 密钥策略中允许 Lambda 执行角色。",
      "E": "在 AWS KMS 密钥策略中允许 Lambda 资源策略。"
    }
  },
  {
    "id": 551,
    "topic": "1",
    "question_en": "A company has a financial application that produces reports. The reports average 50 KB in size and are stored in Amazon S3. The reports are frequently accessed during the first week after production and must be stored for several years. The reports must be retrievable within 6 hours. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier after 7 days.",
      "B": "Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) after 7 days.",
      "C": "Use S3 Intelligent-Tiering. Configure S3 Intelligent-Tiering to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier.",
      "D": "Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier Deep Archive after 7 days."
    },
    "correct_answer": "B",
    "vote_percentage": "65%",
    "question_cn": "一家公司有一个生成报告的金融应用程序。报告平均大小为 50 KB，并存储在 Amazon S3 中。报告在生成后的第一周内会被频繁访问，并且必须存储数年。报告必须在 6 小时内可检索。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "使用 S3 Standard。使用 S3 生命周期规则在 7 天后将报告转换为 S3 Glacier。",
      "B": "使用 S3 Standard。使用 S3 生命周期规则在 7 天后将报告转换为 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "C": "使用 S3 Intelligent-Tiering。配置 S3 Intelligent-Tiering 将报告转换为 S3 Standard-Infrequent Access (S3 Standard-IA) 和 S3 Glacier。",
      "D": "使用 S3 Standard。使用 S3 生命周期规则在 7 天后将报告转换为 S3 Glacier Deep Archive。"
    }
  },
  {
    "id": 552,
    "topic": "1",
    "question_en": "A company needs to optimize the cost of its Amazon EC2 instances. The company also needs to change the type and family of its EC2 instances every 2-3 months. What should the company do to meet these requirements?",
    "options_en": {
      "A": "Purchase Partial Upfront Reserved Instances for a 3-year term.",
      "B": "Purchase a No Upfront Compute Savings Plan for a 1-year term.",
      "C": "Purchase All Upfront Reserved Instances for a 1-year term.",
      "D": "Purchase an All Upfront EC2 Instance Savings Plan for a 1-year term."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要优化其 Amazon EC2 实例的成本。该公司还需要每 2-3 个月更改其 EC2 实例的类型和系列。该公司应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "为期 3 年，购买部分预付费的预留实例。",
      "B": "为期 1 年，购买无预付计算节省计划。",
      "C": "为期 1 年，购买全部预付费的预留实例。",
      "D": "为期 1 年，购买全部预付费的 EC2 实例节省计划。"
    }
  },
  {
    "id": 553,
    "topic": "1",
    "question_en": "A solutions architect needs to review a company's Amazon S3 buckets to discover personally identifiable information (PII). The company stores the PII data in the us-east-1 Region and us-west-2 Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure Amazon Macie in each Region. Create a job to analyze the data that is in Amazon S3.",
      "B": "Configure AWS Security Hub for all Regions. Create an AWS Config rule to analyze the data that is in Amazon S3.",
      "C": "Configure Amazon Inspector to analyze the data that is in Amazon S3.",
      "D": "Configure Amazon GuardDuty to analyze the data that is in Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要审查一家公司的 Amazon S3 存储桶以发现个人身份信息 (PII)。该公司将 PII 数据存储在 us-east-1 区域和 us-west-2 区域。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在每个区域配置 Amazon Macie。创建一个作业来分析 Amazon S3 中的数据。",
      "B": "为所有区域配置 AWS Security Hub。创建一个 AWS Config 规则来分析 Amazon S3 中的数据。",
      "C": "配置 Amazon Inspector 来分析 Amazon S3 中的数据。",
      "D": "配置 Amazon GuardDuty 来分析 Amazon S3 中的数据。"
    }
  },
  {
    "id": 554,
    "topic": "1",
    "question_en": "A company's SAP application has a backend SQL Server database in an on-premises environment. The company wants to migrate its on- premises application and database server to AWS. The company needs an instance type that meets the high demands of its SAP database. On-premises performance data shows that both the SAP application and the database have high memory utilization. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use the compute optimized instance family for the application. Use the memory optimized instance family for the database.",
      "B": "Use the storage optimized instance family for both the application and the database.",
      "C": "Use the memory optimized instance family for both the application and the database.",
      "D": "Use the high performance computing (HPC) optimized instance family for the application. Use the memory optimized instance family for the database."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的 SAP 应用程序在本地环境中有一个后端 SQL Server 数据库。该公司希望将其本地应用程序和数据库服务器迁移到 AWS。该公司需要一种实例类型来满足其 SAP 数据库的高需求。本地性能数据显示，SAP 应用程序和数据库都具有高内存利用率。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为应用程序使用计算优化实例系列。为数据库使用内存优化实例系列。",
      "B": "为应用程序和数据库都使用存储优化设备实例系列。",
      "C": "为应用程序和数据库都使用内存优化实例系列。",
      "D": "为应用程序使用高性能计算 (HPC) 优化实例系列。为数据库使用内存优化实例系列。"
    }
  },
  {
    "id": 555,
    "topic": "1",
    "question_en": "A company runs an application in a VPC with public and private subnets. The VPC extends across multiple Availability Zones. The application runs on Amazon EC2 instances in private subnets. The application uses an Amazon Simple Queue Service (Amazon SQS) queue. A solutions architect needs to design a secure solution to establish a connection between the EC2 instances and the SQS queue. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the private subnets. Add to the endpoint a security group that has an inbound access rule that allows trafic from the EC2 instances that are in the private subnets.",
      "B": "Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach to the interface endpoint a VPC endpoint policy that allows access from the EC2 instances that are in the private subnets.",
      "C": "Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach an Amazon SQS access policy to the interface VPC endpoint that allows requests from only a specified VPC endpoint.",
      "D": "Implement a gateway endpoint for Amazon SQS. Add a NAT gateway to the private subnets. Attach an IAM role to the EC2 instances that allows access to the SQS queue."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在具有公有子网和私有子网的 VPC 中运行应用程序。VPC 跨多个可用区。该应用程序在私有子网中的 Amazon EC2 实例上运行。该应用程序使用 Amazon Simple Queue Service (Amazon SQS) 队列。解决方案架构师需要设计一个安全解决方案，以在 EC2 实例和 SQS 队列之间建立连接。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Amazon SQS 实施一个接口 VPC endpoint。配置该 endpoint 以使用私有子网。为该 endpoint 添加一个安全组，该安全组具有一个入站访问规则，允许来自私有子网中的 EC2 实例的流量。",
      "B": "为 Amazon SQS 实施一个接口 VPC endpoint。配置该 endpoint 以使用公有子网。将一个 VPC endpoint 策略附加到接口 endpoint，该策略允许来自私有子网中的 EC2 实例的访问。",
      "C": "为 Amazon SQS 实施一个接口 VPC endpoint。配置该 endpoint 以使用公有子网。将 Amazon SQS 访问策略附加到接口 VPC endpoint，该策略仅允许来自指定 VPC endpoint 的请求。",
      "D": "为 Amazon SQS 实施一个网关 endpoint。将一个 NAT Gateway 添加到私有子网。将一个 IAM 角色附加到 EC2 实例，该角色允许访问 SQS 队列。"
    }
  },
  {
    "id": 556,
    "topic": "1",
    "question_en": "A solutions architect is using an AWS CloudFormation template to deploy a three-tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an IAM role to read the DynamoDB tables. Associate the role with the application instances by referencing an instance profile.",
      "B": "Create an IAM role that has the required permissions to read and write from the DynamoDB tables. Add the role to the EC2 instance profile, and associate the instance profile with the application instances.",
      "C": "Use the parameter section in the AWS CloudFormation template to have the user input access and secret keys from an already-created IAM user that has the required permissions to read and write from the DynamoDB tables.",
      "D": "Create an IAM user in the AWS CloudFormation template that has the required permissions to read and write from the DynamoDB tables. Use the GetAtt function to retrieve the access and secret keys, and pass them to the application instances through the user data."
    },
    "correct_answer": "B",
    "vote_percentage": "87%",
    "question_cn": "一位解决方案架构师正在使用 AWS CloudFormation 模板来部署一个三层 Web 应用程序。该 Web 应用程序包含一个 Web 层和一个应用程序层，该层将用户数据存储在 Amazon DynamoDB 表中并从中检索用户数据。 Web 层和应用程序层托管在 Amazon EC2 实例上，数据库层不可公开访问。应用程序 EC2 实例需要访问 DynamoDB 表，而无需在模板中暴露 API 凭证。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 IAM 角色来读取 DynamoDB 表。通过引用实例配置文件将该角色与应用程序实例关联。",
      "B": "创建一个 IAM 角色，该角色具有从 DynamoDB 表中读取和写入所需的权限。将该角色添加到 EC2 实例配置文件，并将实例配置文件与应用程序实例关联。",
      "C": "使用 AWS CloudFormation 模板中的参数部分，让用户输入来自已创建的 IAM 用户（该用户具有从 DynamoDB 表中读取和写入所需的权限）的访问密钥和密钥。 ",
      "D": "在 AWS CloudFormation 模板中创建一个 IAM 用户，该用户具有从 DynamoDB 表中读取和写入所需的权限。使用 GetAtt 函数检索访问密钥和密钥，并通过用户数据将它们传递给应用程序实例。"
    }
  },
  {
    "id": 557,
    "topic": "1",
    "question_en": "A solutions architect manages an analytics application. The application stores large amounts of semistructured data in an Amazon S3 bucket. The solutions architect wants to use parallel data processing to process the data more quickly. The solutions architect also wants to use information that is stored in an Amazon Redshift database to enrich the data. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Athena to process the S3 data. Use AWS Glue with the Amazon Redshift data to enrich the S3 data.",
      "B": "Use Amazon EMR to process the S3 data. Use Amazon EMR with the Amazon Redshift data to enrich the S3 data.",
      "C": "Use Amazon EMR to process the S3 data. Use Amazon Kinesis Data Streams to move the S3 data into Amazon Redshift so that the data can be enriched.",
      "D": "Use AWS Glue to process the S3 data. Use AWS Lake Formation with the Amazon Redshift data to enrich the S3 data."
    },
    "correct_answer": "D",
    "vote_percentage": "71%",
    "question_cn": "一位解决方案架构师管理一个分析应用程序。该应用程序将大量半结构化数据存储在 Amazon S3 存储桶中。解决方案架构师希望使用并行数据处理来更快地处理数据。解决方案架构师还希望使用存储在 Amazon Redshift 数据库中的信息来丰富数据。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Athena 处理 S3 数据。使用 AWS Glue 和 Amazon Redshift 数据来丰富 S3 数据。",
      "B": "使用 Amazon EMR 处理 S3 数据。使用 Amazon EMR 和 Amazon Redshift 数据来丰富 S3 数据。",
      "C": "使用 Amazon EMR 处理 S3 数据。使用 Amazon Kinesis Data Streams 将 S3 数据移动到 Amazon Redshift，以便可以丰富数据。",
      "D": "使用 AWS Glue 处理 S3 数据。使用 AWS Lake Formation 和 Amazon Redshift 数据来丰富 S3 数据。"
    }
  },
  {
    "id": 558,
    "topic": "1",
    "question_en": "A company has two VPCs that are located in the us-west-2 Region within the same AWS account. The company needs to allow network trafic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month. What is the MOST cost-effective solution to connect these VPCs?",
    "options_en": {
      "A": "Implement AWS Transit Gateway to connect the VPCs. Update the route tables of each VPC to use the transit gateway for inter-VPC communication.",
      "B": "Implement an AWS Site-to-Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter-VPC communication.",
      "C": "Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter- VPC communication.",
      "D": "Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter-VPC communication."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在同一 AWS 账户中的 us-west-2 区域中拥有两个 VPC。该公司需要允许这些 VPC 之间的网络流量。每个月将发生大约 500 GB 的数据传输。连接这些 VPC 的最具成本效益的解决方案是什么？",
    "options_cn": {
      "A": "实施 AWS Transit Gateway 以连接 VPC。更新每个 VPC 的路由表以使用 Transit Gateway 进行 VPC 间通信。",
      "B": "在 VPC 之间实施 AWS Site-to-Site VPN 隧道。更新每个 VPC 的路由表以使用 VPN 隧道进行 VPC 间通信。",
      "C": "在 VPC 之间设置 VPC 对等连接。更新每个 VPC 的路由表以使用 VPC 对等连接进行 VPC 间通信。",
      "D": "在 VPC 之间设置 1 GB 的 AWS Direct Connect 连接。更新每个 VPC 的路由表以使用 Direct Connect 连接进行 VPC 间通信。"
    }
  },
  {
    "id": 559,
    "topic": "1",
    "question_en": "A company hosts multiple applications on AWS for different product lines. The applications use different compute resources, including Amazon EC2 instances and Application Load Balancers. The applications run in different AWS accounts under the same organization in AWS Organizations across multiple AWS Regions. Teams for each product line have tagged each compute resource in the individual accounts. The company wants more details about the cost for each product line from the consolidated billing feature in Organizations. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Select a specific AWS generated tag in the AWS Billing console.",
      "B": "Select a specific user-defined tag in the AWS Billing console.",
      "C": "Select a specific user-defined tag in the AWS Resource Groups console.",
      "D": "Activate the selected tag from each AWS account",
      "E": "Activate the selected tag from the Organizations management account."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 上为不同的产品线托管多个应用程序。这些应用程序使用不同的计算资源，包括 Amazon EC2 实例和 Application Load Balancer。这些应用程序在 AWS Organizations 中的不同 AWS 账户中运行，跨越多个 AWS 区域。每个产品线的团队已经在各个账户中标记了每个计算资源。该公司希望从 Organizations 的合并账单功能中获取关于每个产品线的更多成本详细信息。哪些步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 AWS 账单控制台中选择一个特定的 AWS 生成的标签。",
      "B": "在 AWS 账单控制台中选择一个特定的用户自定义标签。",
      "C": "在 AWS Resource Groups 控制台中选择一个特定的用户自定义标签。",
      "D": "从每个 AWS 账户中激活所选标签。",
      "E": "从 Organizations 管理账户中激活所选标签。"
    }
  },
  {
    "id": 560,
    "topic": "1",
    "question_en": "A company's solutions architect is designing an AWS multi-account solution that uses AWS Organizations. The solutions architect has organized the company's accounts into organizational units (OUs). The solutions architect needs a solution that will identify any changes to the OU hierarchy. The solution also needs to notify the company's operations team of any changes. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Provision the AWS accounts by using AWS Control Tower. Use account drift notifications to identify the changes to the OU hierarchy.",
      "B": "Provision the AWS accounts by using AWS Control Tower. Use AWS Config aggregated rules to identify the changes to the OU hierarchy.",
      "C": "Use AWS Service Catalog to create accounts in Organizations. Use an AWS CloudTrail organization trail to identify the changes to the OU hierarchy.",
      "D": "Use AWS CloudFormation templates to create accounts in Organizations. Use the drift detection operation on a stack to identify the changes to the OU hierarchy."
    },
    "correct_answer": "A",
    "vote_percentage": "79%",
    "question_cn": "一家公司的解决方案架构师正在设计一个使用 AWS Organizations 的 AWS 多账户解决方案。解决方案架构师已将公司的账户组织到组织单元 (OU) 中。解决方案架构师需要一个解决方案来识别 OU 层次结构的任何更改。该解决方案还需要将任何更改通知给公司的运营团队。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Control Tower 配置 AWS 账户。使用账户漂移通知来识别 OU 层次结构的更改。",
      "B": "使用 AWS Control Tower 配置 AWS 账户。使用 AWS Config 聚合规则来识别 OU 层次结构的更改。",
      "C": "使用 AWS Service Catalog 在 Organizations 中创建账户。使用 AWS CloudTrail 组织跟踪来识别 OU 层次结构的更改。",
      "D": "使用 AWS CloudFormation 模板在 Organizations 中创建账户。对堆栈使用漂移检测操作来识别 OU 层次结构的更改。"
    }
  },
  {
    "id": 561,
    "topic": "1",
    "question_en": "A company's website handles millions of requests each day, and the number of requests continues to increase. A solutions architect needs to improve the response time of the web application. The solutions architect determines that the application needs to decrease latency when retrieving product details from the Amazon DynamoDB table. Which solution will meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Set up a DynamoDB Accelerator (DAX) cluster. Route all read requests through DAX.",
      "B": "Set up Amazon ElastiCache for Redis between the DynamoDB table and the web application. Route all read requests through Redis.",
      "C": "Set up Amazon ElastiCache for Memcached between the DynamoDB table and the web application. Route all read requests through Memcached.",
      "D": "Set up Amazon DynamoDB Streams on the table, and have AWS Lambda read from the table and populate Amazon ElastiCache. Route all read requests through ElastiCache."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司的网站每天处理数百万个请求，而且请求数量持续增加。一位解决方案架构师需要提高 Web 应用程序的响应时间。解决方案架构师确定应用程序需要在从 Amazon DynamoDB 表检索产品详细信息时减少延迟。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "设置 DynamoDB Accelerator (DAX) 集群。将所有读取请求路由通过 DAX。",
      "B": "在 DynamoDB 表和 Web 应用程序之间设置 Amazon ElastiCache for Redis。将所有读取请求路由通过 Redis。",
      "C": "在 DynamoDB 表和 Web 应用程序之间设置 Amazon ElastiCache for Memcached。将所有读取请求路由通过 Memcached。",
      "D": "在表上设置 Amazon DynamoDB Streams，并让 AWS Lambda 从表中读取数据并填充 Amazon ElastiCache。将所有读取请求路由通过 ElastiCache。"
    }
  },
  {
    "id": 562,
    "topic": "1",
    "question_en": "A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not travel across the internet. Which combination of steps should the solutions architect take to meet this requirement? (Choose two.)",
    "options_en": {
      "A": "Create a route table entry for the endpoint.",
      "B": "Create a gateway endpoint for DynamoDB.",
      "C": "Create an interface endpoint for Amazon EC2.",
      "D": "Create an elastic network interface for the endpoint in each of the subnets of the VPC",
      "E": "Create a security group entry in the endpoint's security group to provide access."
    },
    "correct_answer": "A",
    "vote_percentage": "69%",
    "question_cn": "一位解决方案架构师需要确保来自 VPC 中 Amazon EC2 实例的对 Amazon DynamoDB 的 API 调用不会跨互联网传输。解决方案架构师应采取哪些组合步骤来满足此要求？（选择两项。）",
    "options_cn": {
      "A": "为终端节点创建路由表条目。",
      "B": "为 DynamoDB 创建一个网关终端节点。",
      "C": "为 Amazon EC2 创建一个接口终端节点。",
      "D": "在 VPC 的每个子网中为终端节点创建一个弹性网络接口。",
      "E": "在终端节点的安全组中创建一个安全组条目以提供访问权限。"
    }
  },
  {
    "id": 555,
    "topic": "",
    "question_en": "Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the private subnets. Add to the endpoint a security group that has an inbound access rule that allows traffic from the EC2 instances that are in the private subnets.",
    "options_en": {},
    "correct_answer": "",
    "vote_percentage": "",
    "question_cn": "为 Amazon SQS 实施一个 VPC 终端节点。配置该终端节点以使用私有子网。为该终端节点添加一个安全组，该安全组包含一个入站访问规则，允许来自位于私有子网中的 EC2 实例的流量。",
    "options_cn": {
      "A": "创建一个 IAM 策略，允许 EC2 实例访问 SQS。将此策略附加到 EC2 实例的 IAM 角色。",
      "B": "创建一个 VPC 终端节点，并将它配置为使用私有子网。在终端节点的安全组中，添加一个允许来自私有子网中 EC2 实例的流量的入站规则。",
      "C": "创建一个 NAT Gateway，以便 EC2 实例可以通过它访问 SQS。在 NAT Gateway 的安全组中，添加一个允许来自 EC2 实例的流量的入站规则。",
      "D": "创建一个 Application Load Balancer，并将它配置为指向 SQS。在 ALB 的安全组中，添加一个允许来自 EC2 实例的流量的入站规则。"
    }
  },
  {
    "id": 563,
    "topic": "1",
    "question_en": "A company runs its applications on both Amazon Elastic Kubernetes Service (Amazon EKS) clusters and on-premises Kubernetes clusters. The company wants to view all clusters and workloads from a central location. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon CloudWatch Container Insights to collect and group the cluster information.",
      "B": "Use Amazon EKS Connector to register and connect all Kubernetes clusters.",
      "C": "Use AWS Systems Manager to collect and view the cluster information.",
      "D": "Use Amazon EKS Anywhere as the primary cluster to view the other clusters with native Kubernetes commands."
    },
    "correct_answer": "B",
    "vote_percentage": "92%",
    "question_cn": "一家公司在其 Amazon Elastic Kubernetes Service (Amazon EKS) 集群和本地 Kubernetes 集群上运行其应用程序。该公司希望从一个中心位置查看所有集群和工作负载。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch Container Insights 收集并分组集群信息。",
      "B": "使用 Amazon EKS Connector 注册并连接所有 Kubernetes 集群。",
      "C": "使用 AWS Systems Manager 收集和查看集群信息。",
      "D": "使用 Amazon EKS Anywhere 作为主集群，使用原生 Kubernetes 命令查看其他集群。"
    }
  },
  {
    "id": 564,
    "topic": "1",
    "question_en": "A company is building an ecommerce application and needs to store sensitive customer information. The company needs to give customers the ability to complete purchase transactions on the website. The company also needs to ensure that sensitive customer data is protected, even from database administrators. Which solution meets these requirements?",
    "options_en": {
      "A": "Store sensitive data in an Amazon Elastic Block Store (Amazon EBS) volume. Use EBS encryption to encrypt the data. Use an IAM instance role to restrict access.",
      "B": "Store sensitive data in Amazon RDS for MySQL. Use AWS Key Management Service (AWS KMS) client-side encryption to encrypt the data.",
      "C": "Store sensitive data in Amazon S3. Use AWS Key Management Service (AWS KMS) server-side encryption to encrypt the data. Use S3 bucket policies to restrict access.",
      "D": "Store sensitive data in Amazon FSx for Windows Server. Mount the file share on application servers. Use Windows file permissions to restrict access."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在构建一个电子商务应用程序，需要存储敏感的客户信息。该公司需要让客户能够在网站上完成购买交易。该公司还需要确保敏感的客户数据受到保护，即使是数据库管理员也无法访问。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "将敏感数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。使用 EBS 加密来加密数据。使用 IAM 实例角色来限制访问。",
      "B": "将敏感数据存储在 Amazon RDS for MySQL 中。使用 AWS Key Management Service (AWS KMS) 客户端加密来加密数据。",
      "C": "将敏感数据存储在 Amazon S3 中。使用 AWS Key Management Service (AWS KMS) 服务器端加密来加密数据。使用 S3 存储桶策略来限制访问。",
      "D": "将敏感数据存储在 Amazon FSx for Windows Server 中。在应用程序服务器上挂载文件共享。使用 Windows 文件权限来限制访问。"
    }
  },
  {
    "id": 565,
    "topic": "1",
    "question_en": "A company has an on-premises MySQL database that handles transactional data. The company is migrating the database to the AWS Cloud. The migrated database must maintain compatibility with the company's applications that use the database. The migrated database also must scale automatically during periods of increased demand. Which migration solution will meet these requirements?",
    "options_en": {
      "A": "Use native MySQL tools to migrate the database to Amazon RDS for MySQL. Configure elastic storage scaling.",
      "B": "Migrate the database to Amazon Redshift by using the mysqldump utility. Turn on Auto Scaling for the Amazon Redshift cluster.",
      "C": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon Aurora. Turn on Aurora Auto Scaling.",
      "D": "Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon DynamoDB. Configure an Auto Scaling policy."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一台处理事务数据的本地 MySQL 数据库。该公司正在将该数据库迁移到 AWS 云。迁移后的数据库必须与使用该数据库的公司的应用程序保持兼容性。迁移后的数据库还必须在需求增加期间自动扩展。哪个迁移解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用原生 MySQL 工具将数据库迁移到 Amazon RDS for MySQL。配置弹性存储扩展。",
      "B": "使用 mysqldump 实用程序将数据库迁移到 Amazon Redshift。为 Amazon Redshift 集群打开 Auto Scaling。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 将数据库迁移到 Amazon Aurora。打开 Aurora Auto Scaling。",
      "D": "使用 AWS Database Migration Service (AWS DMS) 将数据库迁移到 Amazon DynamoDB。配置 Auto Scaling 策略。"
    }
  },
  {
    "id": 566,
    "topic": "1",
    "question_en": "A company runs multiple Amazon EC2 Linux instances in a VPC across two Availability Zones. The instances host applications that use a hierarchical directory structure. The applications need to read and write rapidly and concurrently to shared storage. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an Amazon S3 bucket. Allow access from all the EC2 instances in the VPC.",
      "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system from each EC2 instance.",
      "C": "Create a file system on a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume. Attach the EBS volume to all the EC2 instances.",
      "D": "Create file systems on Amazon Elastic Block Store (Amazon EBS) volumes that are attached to each EC2 instance. Synchronize the EBS volumes across the different EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司在跨越两个可用区的 VPC 中运行多个 Amazon EC2 Linux 实例。这些实例托管使用分层目录结构的应用程序。应用程序需要快速且并发地读写共享存储。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon S3 存储桶。允许从 VPC 中的所有 EC2 实例进行访问。",
      "B": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。从每个 EC2 实例挂载 EFS 文件系统。",
      "C": "在预置 IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) 卷上创建文件系统。将 EBS 卷附加到所有 EC2 实例。",
      "D": "在附加到每个 EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷上创建文件系统。在不同的 EC2 实例之间同步 EBS 卷。"
    }
  },
  {
    "id": 567,
    "topic": "1",
    "question_en": "A solutions architect is designing a workload that will store hourly energy consumption by business tenants in a building. The sensors will feed a database through HTTP requests that will add up usage for each tenant. The solutions architect must use managed services when possible. The workload will receive more features in the future as the solutions architect adds independent components. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in an Amazon DynamoDB table.",
      "B": "Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon S3 bucket to store the processed data.",
      "C": "Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in a Microsoft SQL Server Express database on an Amazon EC2 instance.",
      "D": "Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon Elastic File System (Amazon EFS) shared file system to store the processed data."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在设计一个工作负载，用于存储建筑物中业务租户的每小时能源消耗。传感器将通过 HTTP 请求将数据馈送到数据库，这些请求将累加每个租户的用量。解决方案架构师必须尽可能使用托管服务。随着解决方案架构师添加独立组件，工作负载将在未来接收更多功能。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon API Gateway 和 AWS Lambda 函数接收来自传感器的数据，处理数据，并将数据存储在 Amazon DynamoDB 表中。",
      "B": "使用由 Amazon EC2 实例的 Auto Scaling 组支持的 Elastic Load Balancer 接收和处理来自传感器的数据。使用 Amazon S3 存储桶存储已处理的数据。",
      "C": "使用 Amazon API Gateway 和 AWS Lambda 函数接收来自传感器的数据，处理数据，并将数据存储在 Amazon EC2 实例上的 Microsoft SQL Server Express 数据库中。",
      "D": "使用由 Amazon EC2 实例的 Auto Scaling 组支持的 Elastic Load Balancer 接收和处理来自传感器的数据。使用 Amazon Elastic File System (Amazon EFS) 共享文件系统存储已处理的数据。"
    }
  },
  {
    "id": 568,
    "topic": "1",
    "question_en": "A solutions architect is designing the storage architecture for a new web application used for storing and viewing engineering drawings. All application components will be deployed on the AWS infrastructure. The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?",
    "options_en": {
      "A": "Amazon S3 with Amazon CloudFront",
      "B": "Amazon S3 Glacier with Amazon ElastiCache",
      "C": "Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront",
      "D": "AWS Storage Gateway with Amazon ElastiCache"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在为用于存储和查看工程图纸的新 Web 应用程序设计存储架构。所有应用程序组件都将部署在 AWS 基础设施上。应用程序设计必须支持缓存，以最大限度地减少用户等待工程图纸加载的时间。该应用程序必须能够存储 PB 级数据。 解决方案架构师应该使用哪种存储和缓存组合？",
    "options_cn": {
      "A": "Amazon S3 与 Amazon CloudFront",
      "B": "Amazon S3 Glacier 与 Amazon ElastiCache",
      "C": "Amazon Elastic Block Store (Amazon EBS) 卷与 Amazon CloudFront",
      "D": "AWS Storage Gateway 与 Amazon ElastiCache"
    }
  },
  {
    "id": 569,
    "topic": "1",
    "question_en": "An Amazon EventBridge rule targets a third-party API. The third-party API has not received any incoming trafic. A solutions architect needs to determine whether the rule conditions are being met and if the rule's target is being invoked. Which solution will meet these requirements?",
    "options_en": {
      "A": "Check for metrics in Amazon CloudWatch in the namespace for AWS/Events.",
      "B": "Review events in the Amazon Simple Queue Service (Amazon SQS) dead-letter queue.",
      "C": "Check for the events in Amazon CloudWatch Logs.",
      "D": "Check the trails in AWS CloudTrail for the EventBridge events."
    },
    "correct_answer": "A",
    "vote_percentage": "69%",
    "question_cn": "一个 Amazon EventBridge 规则指向一个第三方 API。该第三方 API 尚未收到任何传入流量。一个解决方案架构师需要确定是否满足规则条件以及是否调用了规则的目标。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 Amazon CloudWatch 的 AWS/Events 命名空间中检查指标。",
      "B": "查看 Amazon Simple Queue Service (Amazon SQS) 死信队列中的事件。",
      "C": "在 Amazon CloudWatch Logs 中检查事件。",
      "D": "检查 AWS CloudTrail 中 EventBridge 事件的跟踪记录。"
    }
  },
  {
    "id": 570,
    "topic": "1",
    "question_en": "A company has a large workload that runs every Friday evening. The workload runs on Amazon EC2 instances that are in two Availability Zones in the us-east-1 Region. Normally, the company must run no more than two instances at all times. However, the company wants to scale up to six instances each Friday to handle a regularly repeating increased workload. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a reminder in Amazon EventBridge to scale the instances.",
      "B": "Create an Auto Scaling group that has a scheduled action.",
      "C": "Create an Auto Scaling group that uses manual scaling.",
      "D": "Create an Auto Scaling group that uses automatic scaling."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一项大型工作负载，该工作负载每周五晚上运行。 该工作负载在 us-east-1 区域的两个可用区中的 Amazon EC2 实例上运行。 通常情况下，该公司在任何时候都不能运行超过两个实例。 但是，该公司希望在每个周五扩展到六个实例，以处理定期重复增加的工作负载。 哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 Amazon EventBridge 中创建一个提醒，以扩展实例。",
      "B": "创建一个具有计划操作的 Auto Scaling 组。",
      "C": "创建一个使用手动扩展的 Auto Scaling 组。",
      "D": "创建一个使用自动扩展的 Auto Scaling 组。"
    }
  },
  {
    "id": 571,
    "topic": "1",
    "question_en": "A company is creating a REST API. The company has strict requirements for the use of TLS. The company requires TLSv1.3 on the API endpoints. The company also requires a specific public third-party certificate authority (CA) to sign the TLS certificate. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use a local machine to create a certificate that is signed by the third-party CImport the certificate into AWS Certificate Manager (ACM). Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.",
      "B": "Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.",
      "C": "Use AWS Certificate Manager (ACM) to create a certificate that is signed by the third-party CA. Import the certificate into AWS Certificate Manager (ACM). Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate.",
      "D": "Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate."
    },
    "correct_answer": "A",
    "vote_percentage": "72%",
    "question_cn": "一家公司正在创建 REST API。该公司对 TLS 的使用有严格的要求。该公司要求在 API 终端节点上使用 TLSv1.3。该公司还要求使用特定的公共第三方证书颁发机构 (CA) 来签署 TLS 证书。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用本地机器创建由第三方 CA 签名的证书。将证书导入 AWS Certificate Manager (ACM)。在 Amazon API Gateway 中创建一个带有自定义域名的 HTTP API。配置自定义域名以使用该证书。",
      "B": "在 AWS Certificate Manager (ACM) 中创建由第三方 CA 签名的证书。在 Amazon API Gateway 中创建一个带有自定义域名的 HTTP API。配置自定义域名以使用该证书。",
      "C": "使用 AWS Certificate Manager (ACM) 创建由第三方 CA 签名的证书。将证书导入 AWS Certificate Manager (ACM)。创建一个带有 Lambda 函数 URL 的 AWS Lambda 函数。配置 Lambda 函数 URL 以使用该证书。",
      "D": "在 AWS Certificate Manager (ACM) 中创建由第三方 CA 签名的证书。创建一个带有 Lambda 函数 URL 的 AWS Lambda 函数。配置 Lambda 函数 URL 以使用该证书。"
    }
  },
  {
    "id": 572,
    "topic": "1",
    "question_en": "A company runs an application on AWS. The application receives inconsistent amounts of usage. The application uses AWS Direct Connect to connect to an on-premises MySQL-compatible database. The on-premises database consistently uses a minimum of 2 GiB of memory. The company wants to migrate the on-premises database to a managed AWS service. The company wants to use auto scaling capabilities to manage unexpected workload increases. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Provision an Amazon DynamoDB database with default read and write capacity settings.",
      "B": "Provision an Amazon Aurora database with a minimum capacity of 1 Aurora capacity unit (ACU).",
      "C": "Provision an Amazon Aurora Serverless v2 database with a minimum capacity of 1 Aurora capacity unit (ACU).",
      "D": "Provision an Amazon RDS for MySQL database with 2 GiB of memory."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行应用程序。该应用程序接收到的使用量不一致。该应用程序使用 AWS Direct Connect 连接到本地 MySQL 兼容数据库。本地数据库始终使用至少 2 GiB 的内存。该公司希望将本地数据库迁移到托管 AWS 服务。该公司希望使用自动伸缩功能来管理意外的工作负载增加。哪种解决方案以最小的管理开销满足这些要求？",
    "options_cn": {
      "A": "配置一个 Amazon DynamoDB 数据库，使用默认的读取和写入容量设置。",
      "B": "配置一个 Amazon Aurora 数据库，最小容量为 1 个 Aurora 容量单元 (ACU)。",
      "C": "配置一个 Amazon Aurora Serverless v2 数据库，最小容量为 1 个 Aurora 容量单元 (ACU)。",
      "D": "配置一个 Amazon RDS for MySQL 数据库，使用 2 GiB 的内存。"
    }
  },
  {
    "id": 573,
    "topic": "1",
    "question_en": "A company wants to use an event-driven programming model with AWS Lambda. The company wants to reduce startup latency for Lambda functions that run on Java 11. The company does not have strict latency requirements for the applications. The company wants to reduce cold starts and outlier latencies when a function scales up. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure Lambda provisioned concurrency.",
      "B": "Increase the timeout of the Lambda functions.",
      "C": "Increase the memory of the Lambda functions.",
      "D": "Configure Lambda SnapStart."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望使用基于事件的编程模型与 AWS Lambda。该公司希望减少在 Java 11 上运行的 Lambda 函数的启动延迟。该公司对应用程序的延迟没有严格的要求。该公司希望在函数扩展时减少冷启动和异常延迟。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置 Lambda 预置并发。",
      "B": "增加 Lambda 函数的超时时间。",
      "C": "增加 Lambda 函数的内存。",
      "D": "配置 Lambda SnapStart。"
    }
  },
  {
    "id": 574,
    "topic": "1",
    "question_en": "A financial services company launched a new application that uses an Amazon RDS for MySQL database. The company uses the application to track stock market trends. The company needs to operate the application for only 2 hours at the end of each week. The company needs to optimize the cost of running the database. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Migrate the existing RDS for MySQL database to an Aurora Serverless v2 MySQL database cluster.",
      "B": "Migrate the existing RDS for MySQL database to an Aurora MySQL database cluster.",
      "C": "Migrate the existing RDS for MySQL database to an Amazon EC2 instance that runs MySQL. Purchase an instance reservation for the EC2 instance.",
      "D": "Migrate the existing RDS for MySQL database to an Amazon Elastic Container Service (Amazon ECS) cluster that uses MySQL container images to run tasks."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家金融服务公司推出了一款使用 Amazon RDS for MySQL 数据库的新应用程序。该公司使用该应用程序跟踪股票市场趋势。该公司每周只需要在周末运行该应用程序 2 小时。该公司需要优化运行数据库的成本。哪种解决方案可以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "将现有的 RDS for MySQL 数据库迁移到 Aurora Serverless v2 MySQL 数据库集群。",
      "B": "将现有的 RDS for MySQL 数据库迁移到 Aurora MySQL 数据库集群。",
      "C": "将现有的 RDS for MySQL 数据库迁移到运行 MySQL 的 Amazon EC2 实例。购买 EC2 实例的预留。",
      "D": "将现有的 RDS for MySQL 数据库迁移到使用 MySQL 容器镜像运行任务的 Amazon Elastic Container Service (Amazon ECS) 集群。"
    }
  },
  {
    "id": 575,
    "topic": "1",
    "question_en": "A company deploys its applications on Amazon Elastic Kubernetes Service (Amazon EKS) behind an Application Load Balancer in an AWS Region. The application needs to store data in a PostgreSQL database engine. The company wants the data in the database to be highly available. The company also needs increased capacity for read workloads. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create an Amazon DynamoDB database table configured with global tables.",
      "B": "Create an Amazon RDS database with Multi-AZ deployments.",
      "C": "Create an Amazon RDS database with Multi-AZ DB cluster deployment.",
      "D": "Create an Amazon RDS database configured with cross-Region read replicas."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 AWS 区域的 Application Load Balancer 后面的 Amazon Elastic Kubernetes Service (Amazon EKS) 上部署其应用程序。该应用程序需要在 PostgreSQL 数据库引擎中存储数据。该公司希望数据库中的数据具有高可用性。该公司还需要增加读取工作负载的容量。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "创建一个配置了全局表的 Amazon DynamoDB 数据库表。",
      "B": "创建一个具有多可用区部署的 Amazon RDS 数据库。",
      "C": "创建一个具有多可用区数据库集群部署的 Amazon RDS 数据库。",
      "D": "创建一个配置了跨区域读取副本的 Amazon RDS 数据库。"
    }
  },
  {
    "id": 576,
    "topic": "1",
    "question_en": "A company is building a RESTful serverless web application on AWS by using Amazon API Gateway and AWS Lambda. The users of this web application will be geographically distributed, and the company wants to reduce the latency of API requests to these users. Which type of endpoint should a solutions architect use to meet these requirements?",
    "options_en": {
      "A": "Private endpoint",
      "B": "Regional endpoint",
      "C": "Interface VPC endpoint",
      "D": "Edge-optimized endpoint"
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上构建一个使用 Amazon API Gateway 和 AWS Lambda 的无服务器 RESTful Web 应用程序。 该 Web 应用程序的用户将分布在不同地理位置，并且公司希望减少这些用户 API 请求的延迟。 解决方案架构师应该使用哪种类型的端点来满足这些要求？",
    "options_cn": {
      "A": "私有端点",
      "B": "区域端点",
      "C": "接口 VPC 端点",
      "D": "边缘优化端点"
    }
  },
  {
    "id": 577,
    "topic": "1",
    "question_en": "A company uses an Amazon CloudFront distribution to serve content pages for its website. The company needs to ensure that clients use a TLS certificate when accessing the company's website. The company wants to automate the creation and renewal of the TLS certificates. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Use a CloudFront security policy to create a certificate.",
      "B": "Use a CloudFront origin access control (OAC) to create a certificate.",
      "C": "Use AWS Certificate Manager (ACM) to create a certificate. Use DNS validation for the domain.",
      "D": "Use AWS Certificate Manager (ACM) to create a certificate. Use email validation for the domain."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon CloudFront 分发来为其网站提供内容页面。该公司需要确保客户在使用 TLS 证书访问该公司网站时。该公司希望自动化 TLS 证书的创建和续订。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "使用 CloudFront 安全策略创建证书。",
      "B": "使用 CloudFront 源访问控制 (OAC) 创建证书。",
      "C": "使用 AWS Certificate Manager (ACM) 创建证书。对域使用 DNS 验证。",
      "D": "使用 AWS Certificate Manager (ACM) 创建证书。对域使用电子邮件验证。"
    }
  },
  {
    "id": 578,
    "topic": "1",
    "question_en": "A company deployed a serverless application that uses Amazon DynamoDB as a database layer. The application has experienced a large increase in users. The company wants to improve database response time from milliseconds to microseconds and to cache requests to the database. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use DynamoDB Accelerator (DAX).",
      "B": "Migrate the database to Amazon Redshift.",
      "C": "Migrate the database to Amazon RDS.",
      "D": "Use Amazon ElastiCache for Redis."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家公司部署了一个使用 Amazon DynamoDB 作为数据库层的无服务器应用程序。该应用程序的用户数量大幅增加。公司希望将数据库响应时间从毫秒缩短到微秒，并缓存对数据库的请求。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 DynamoDB Accelerator (DAX)。",
      "B": "将数据库迁移到 Amazon Redshift。",
      "C": "将数据库迁移到 Amazon RDS。",
      "D": "使用 Amazon ElastiCache for Redis。"
    }
  },
  {
    "id": 579,
    "topic": "1",
    "question_en": "A company runs an application that uses Amazon RDS for PostgreSQL. The application receives trafic only on weekdays during business hours. The company wants to optimize costs and reduce operational overhead based on this usage. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use the Instance Scheduler on AWS to configure start and stop schedules.",
      "B": "Turn off automatic backups. Create weekly manual snapshots of the database.",
      "C": "Create a custom AWS Lambda function to start and stop the database based on minimum CPU utilization.",
      "D": "Purchase All Upfront reserved DB instances."
    },
    "correct_answer": "C",
    "vote_percentage": "95%",
    "question_cn": "一家公司运行一个使用 Amazon RDS for PostgreSQL 的应用程序。该应用程序仅在工作日的营业时间内接收流量。该公司希望根据此使用情况优化成本并减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS 上的 Instance Scheduler 配置启动和停止计划。",
      "B": "关闭自动备份。每周手动拍摄数据库快照。",
      "C": "创建一个自定义 AWS Lambda 函数，根据最低 CPU 利用率启动和停止数据库。",
      "D": "购买 All Upfront 预留数据库实例。"
    }
  },
  {
    "id": 580,
    "topic": "1",
    "question_en": "A company uses locally attached storage to run a latency-sensitive application on premises. The company is using a lift and shift method to move the application to the AWS Cloud. The company does not want to change the application architecture. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for Lustre file system to run the application.",
      "B": "Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP2 volume to run the application.",
      "C": "Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for OpenZFS file system to run the application.",
      "D": "Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP3 volume to run the application."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用本地连接的存储在其场所运行一个对延迟敏感的应用程序。该公司正在使用一种迁移方法将应用程序移动到 AWS 云。该公司不想更改应用程序架构。哪种解决方案可以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EC2 实例配置一个 Auto Scaling 组。使用 Amazon FSx for Lustre 文件系统来运行该应用程序。",
      "B": "在 Amazon EC2 实例上托管应用程序。使用 Amazon Elastic Block Store (Amazon EBS) GP2 卷来运行该应用程序。",
      "C": "使用 Amazon EC2 实例配置一个 Auto Scaling 组。使用 Amazon FSx for OpenZFS 文件系统来运行该应用程序。",
      "D": "在 Amazon EC2 实例上托管应用程序。使用 Amazon Elastic Block Store (Amazon EBS) GP3 卷来运行该应用程序。"
    }
  },
  {
    "id": 581,
    "topic": "1",
    "question_en": "A company runs a stateful production application on Amazon EC2 instances. The application requires at least two EC2 instances to always be running. A solutions architect needs to design a highly available and fault-tolerant architecture for the application. The solutions architect creates an Auto Scaling group of EC2 instances. Which set of additional steps should the solutions architect take to meet these requirements?",
    "options_en": {
      "A": "Set the Auto Scaling group's minimum capacity to two. Deploy one On-Demand Instance in one Availability Zone and one On-Demand Instance in a second Availability Zone.",
      "B": "Set the Auto Scaling group's minimum capacity to four. Deploy two On-Demand Instances in one Availability Zone and two On-Demand Instances in a second Availability Zone.",
      "C": "Set the Auto Scaling group's minimum capacity to two. Deploy four Spot Instances in one Availability Zone.",
      "D": "Set the Auto Scaling group's minimum capacity to four. Deploy two On-Demand Instances in one Availability Zone and two Spot Instances in a second Availability Zone."
    },
    "correct_answer": "D",
    "vote_percentage": "70%",
    "question_cn": "一家公司在 Amazon EC2 实例上运行一个有状态的生产应用程序。该应用程序需要至少两个 EC2 实例始终运行。一位解决方案架构师需要为该应用程序设计一个高可用性和容错的架构。该解决方案架构师创建了一个 EC2 实例的 Auto Scaling 组。解决方案架构师应该采取哪一组额外的步骤来满足这些要求？",
    "options_cn": {
      "A": "将 Auto Scaling 组的最小容量设置为 2。在一个可用区中部署一个按需实例，在第二个可用区中部署一个按需实例。",
      "B": "将 Auto Scaling 组的最小容量设置为 4。在一个可用区中部署两个按需实例，在第二个可用区中部署两个按需实例。",
      "C": "将 Auto Scaling 组的最小容量设置为 2。在一个可用区中部署四个 Spot 实例。",
      "D": "将 Auto Scaling 组的最小容量设置为 4。在一个可用区中部署两个按需实例，在第二个可用区中部署两个 Spot 实例。"
    }
  },
  {
    "id": 582,
    "topic": "1",
    "question_en": "An ecommerce company uses Amazon Route 53 as its DNS provider. The company hosts its website on premises and in the AWS Cloud. The company's on-premises data center is near the us-west-1 Region. The company uses the eu-central-1 Region to host the website. The company wants to minimize load time for the website as much as possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up a geolocation routing policy. Send the trafic that is near us-west-1 to the on-premises data center. Send the trafic that is near eu-central-1 to eu-central-1.",
      "B": "Set up a simple routing policy that routes all trafic that is near eu-central-1 to eu-central-1 and routes all trafic that is near the on- premises datacenter to the on-premises data center.",
      "C": "Set up a latency routing policy. Associate the policy with us-west-1.",
      "D": "Set up a weighted routing policy. Split the trafic evenly between eu-central-1 and the on-premises data center."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家电子商务公司使用 Amazon Route 53 作为其 DNS 提供商。该公司在其本地和 AWS 云中托管其网站。该公司的本地数据中心靠近 us-west-1 区域。该公司使用 eu-central-1 区域来托管网站。该公司希望尽可能减少网站的加载时间。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置地理位置路由策略。将靠近 us-west-1 的流量发送到本地数据中心。将靠近 eu-central-1 的流量发送到 eu-central-1。",
      "B": "设置一个简单路由策略，将所有靠近 eu-central-1 的流量路由到 eu-central-1，并将所有靠近本地数据中心的流量路由到本地数据中心。",
      "C": "设置一个延迟路由策略。将该策略与 us-west-1 关联。",
      "D": "设置加权路由策略。在 eu-central-1 和本地数据中心之间平均分配流量。"
    }
  },
  {
    "id": 583,
    "topic": "1",
    "question_en": "A company has 5 PB of archived data on physical tapes. The company needs to preserve the data on the tapes for another 10 years for compliance purposes. The company wants to migrate to AWS in the next 6 months. The data center that stores the tapes has a 1 Gbps uplink internet connectivity. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Read the data from the tapes on premises. Stage the data in a local NFS storage. Use AWS DataSync to migrate the data to Amazon S3 Glacier Flexible Retrieval.",
      "B": "Use an on-premises backup application to read the data from the tapes and to write directly to Amazon S3 Glacier Deep Archive.",
      "C": "Order multiple AWS Snowball devices that have Tape Gateway. Copy the physical tapes to virtual tapes in Snowball. Ship the Snowball devices to AWS. Create a lifecycle policy to move the tapes to Amazon S3 Glacier Deep Archive.",
      "D": "Configure an on-premises Tape Gateway. Create virtual tapes in the AWS Cloud. Use backup software to copy the physical tape to the virtual tape."
    },
    "correct_answer": "C",
    "vote_percentage": "97%",
    "question_cn": "一家公司拥有 5 PB 的已存档数据，这些数据存储在物理磁带上。该公司需要将磁带上的数据保留 10 年，以符合法规遵从性要求。该公司希望在接下来的 6 个月内迁移到 AWS。存储磁带的数据中心具有 1 Gbps 的上行互联网连接。哪种解决方案可以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "从本地磁带中读取数据。将数据暂存在本地 NFS 存储中。使用 AWS DataSync 将数据迁移到 Amazon S3 Glacier Flexible Retrieval。",
      "B": "使用本地备份应用程序从磁带中读取数据，并直接写入 Amazon S3 Glacier Deep Archive。",
      "C": "订购多个具有 Tape Gateway 的 AWS Snowball 设备。将物理磁带复制到 Snowball 中的虚拟磁带。将 Snowball 设备运送到 AWS。创建生命周期策略以将磁带移动到 Amazon S3 Glacier Deep Archive。",
      "D": "配置本地 Tape Gateway。在 AWS 云中创建虚拟磁带。使用备份软件将物理磁带复制到虚拟磁带。"
    }
  },
  {
    "id": 584,
    "topic": "1",
    "question_en": "A company is deploying an application that processes large quantities of data in parallel. The company plans to use Amazon EC2 instances for the workload. The network architecture must be configurable to prevent groups of nodes from sharing the same underlying hardware. Which networking solution meets these requirements?",
    "options_en": {
      "A": "Run the EC2 instances in a spread placement group.",
      "B": "Group the EC2 instances in separate accounts.",
      "C": "Configure the EC2 instances with dedicated tenancy.",
      "D": "Configure the EC2 instances with shared tenancy."
    },
    "correct_answer": "A",
    "vote_percentage": "82%",
    "question_cn": "一家公司正在部署一个应用程序，该应用程序并行处理大量数据。该公司计划使用 Amazon EC2 实例来处理工作负载。网络架构必须可配置，以防止节点组共享相同的底层硬件。哪种网络解决方案满足这些要求？",
    "options_cn": {
      "A": "在分散放置组中运行 EC2 实例。",
      "B": "将 EC2 实例分组到不同的账户中。",
      "C": "使用专有租用配置 EC2 实例。",
      "D": "使用共享租用配置 EC2 实例。"
    }
  },
  {
    "id": 585,
    "topic": "1",
    "question_en": "A solutions architect is designing a disaster recovery (DR) strategy to provide Amazon EC2 capacity in a failover AWS Region. Business requirements state that the DR strategy must meet capacity in the failover Region. Which solution will meet these requirements?",
    "options_en": {
      "A": "Purchase On-Demand Instances in the failover Region.",
      "B": "Purchase an EC2 Savings Plan in the failover Region.",
      "C": "Purchase regional Reserved Instances in the failover Region.",
      "D": "Purchase a Capacity Reservation in the failover Region."
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "一个解决方案架构师正在设计一个灾难恢复 (DR) 策略，以在故障转移 AWS 区域中提供 Amazon EC2 容量。 业务需求规定，DR 策略必须满足故障转移区域中的容量。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在故障转移区域购买按需实例。",
      "B": "在故障转移区域购买 EC2 储蓄计划。",
      "C": "在故障转移区域购买区域预留实例。",
      "D": "在故障转移区域购买容量预留。"
    }
  },
  {
    "id": 586,
    "topic": "1",
    "question_en": "A company has five organizational units (OUs) as part of its organization in AWS Organizations. Each OU correlates to the five businesses that the company owns. The company's research and development (R&D) business is separating from the company and will need its own organization. A solutions architect creates a separate new management account for this purpose. What should the solutions architect do next in the new management account?",
    "options_en": {
      "A": "Have the R&D AWS account be part of both organizations during the transition.",
      "B": "Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.",
      "C": "Create a new R&D AWS account in the new organization. Migrate resources from the prior R&D AWS account to the new R&D AWS account.",
      "D": "Have the R&D AWS account join the new organization. Make the new management account a member of the prior organization."
    },
    "correct_answer": "C",
    "vote_percentage": "87%",
    "question_cn": "一家公司在其 AWS Organizations 中有五个组织单元 (OU)。每个 OU 与该公司拥有的五个业务相关。该公司的研发 (R&D) 业务将从公司分离出来，并且需要自己的组织。一位解决方案架构师为此创建了一个单独的新的管理账户。解决方案架构师在新管理账户中接下来应该怎么做？",
    "options_cn": {
      "A": "在过渡期间，让研发 AWS 账户成为两个组织的一部分。",
      "B": "在研发 AWS 账户离开之前的组织之后，邀请研发 AWS 账户加入新的组织。",
      "C": "在新组织中创建一个新的研发 AWS 账户。将资源从之前的研发 AWS 账户迁移到新的研发 AWS 账户。",
      "D": "让研发 AWS 账户加入新的组织。将新的管理账户作为之前组织的成员。"
    }
  },
  {
    "id": 587,
    "topic": "1",
    "question_en": "A company is designing a solution to capture customer activity in different web applications to process analytics and make predictions. Customer activity in the web applications is unpredictable and can increase suddenly. The company requires a solution that integrates with other web applications. The solution must include an authorization step for security purposes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB.",
      "B": "Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization.",
      "C": "Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization.",
      "D": "Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives on an Amazon Elastic File System (Amazon EFS) file system. Use an AWS Lambda function to resolve authorization."
    },
    "correct_answer": "D",
    "vote_percentage": "84%",
    "question_cn": "一家公司正在设计一个解决方案，以捕获不同 Web 应用程序中的客户活动，用于处理分析和进行预测。 Web 应用程序中的客户活动是不可预测的，并且可能突然增加。该公司需要一个与其他 Web 应用程序集成的解决方案。该解决方案必须包括一个用于安全目的的授权步骤。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 Amazon Elastic Container Service (Amazon ECS) 容器实例前面配置一个 Gateway Load Balancer (GWLB)，该实例将公司接收到的信息存储在 Amazon Elastic File System (Amazon EFS) 文件系统中。授权在 GWLB 上解决。",
      "B": "在 Amazon Kinesis 数据流前面配置一个 Amazon API Gateway 终端节点，该数据流将公司接收到的信息存储在 Amazon S3 存储桶中。使用 AWS Lambda 函数来解决授权。",
      "C": "在 Amazon API Gateway 终端节点前面配置一个 Amazon Kinesis Data Firehose，该数据流将公司接收到的信息存储在 Amazon S3 存储桶中。使用 API Gateway Lambda 授权器来解决授权。",
      "D": "在 Amazon Elastic Container Service (Amazon ECS) 容器实例前面配置一个 Gateway Load Balancer (GWLB)，该实例将公司接收到的信息存储在 Amazon Elastic File System (Amazon EFS) 文件系统中。使用 AWS Lambda 函数来解决授权。"
    }
  },
  {
    "id": 588,
    "topic": "1",
    "question_en": "An ecommerce company wants a disaster recovery solution for its Amazon RDS DB instances that run Microsoft SQL Server Enterprise Edition. The company's current recovery point objective (RPO) and recovery time objective (RTO) are 24 hours. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a cross-Region read replica and promote the read replica to the primary instance.",
      "B": "Use AWS Database Migration Service (AWS DMS) to create RDS cross-Region replication.",
      "C": "Use cross-Region replication every 24 hours to copy native backups to an Amazon S3 bucket.",
      "D": "Copy automatic snapshots to another Region every 24 hours."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司希望为其运行 Microsoft SQL Server Enterprise Edition 的 Amazon RDS DB 实例提供灾难恢复解决方案。该公司当前的恢复点目标 (RPO) 和恢复时间目标 (RTO) 为 24 小时。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "创建跨区域只读副本并将只读副本提升为主实例。",
      "B": "使用 AWS Database Migration Service (AWS DMS) 创建 RDS 跨区域复制。",
      "C": "每 24 小时使用跨区域复制将本机备份复制到 Amazon S3 存储桶。",
      "D": "每 24 小时将自动快照复制到另一个区域。"
    }
  },
  {
    "id": 589,
    "topic": "1",
    "question_en": "A company runs a web application on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer that has sticky sessions enabled. The web server currently hosts the user session state. The company wants to ensure high availability and avoid user session state loss in the event of a web server outage. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an Amazon ElastiCache for Memcached instance to store the session data. Update the application to use ElastiCache for Memcached to store the session state.",
      "B": "Use Amazon ElastiCache for Redis to store the session state. Update the application to use ElastiCache for Redis to store the session state.",
      "C": "Use an AWS Storage Gateway cached volume to store session data. Update the application to use AWS Storage Gateway cached volume to store the session state.",
      "D": "Use Amazon RDS to store the session state. Update the application to use Amazon RDS to store the session state."
    },
    "correct_answer": "D",
    "vote_percentage": "89%",
    "question_cn": "一家公司在Application Load Balancer后面的Auto Scaling组中的Amazon EC2实例上运行一个Web应用程序，该负载均衡器已启用粘性会话。Web服务器当前托管用户会话状态。该公司希望确保高可用性，并在Web服务器发生故障时避免用户会话状态丢失。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用Amazon ElastiCache for Memcached实例存储会话数据。更新应用程序以使用ElastiCache for Memcached存储会话状态。",
      "B": "使用Amazon ElastiCache for Redis存储会话状态。更新应用程序以使用ElastiCache for Redis存储会话状态。",
      "C": "使用AWS Storage Gateway缓存卷存储会话数据。更新应用程序以使用AWS Storage Gateway缓存卷存储会话状态。",
      "D": "使用Amazon RDS存储会话状态。更新应用程序以使用Amazon RDS存储会话状态。"
    }
  },
  {
    "id": 590,
    "topic": "1",
    "question_en": "A company migrated a MySQL database from the company's on-premises data center to an Amazon RDS for MySQL DB instance. The company sized the RDS DB instance to meet the company's average daily workload. Once a month, the database performs slowly when the company runs queries for a report. The company wants to have the ability to run reports and maintain the performance of the daily workloads. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a read replica of the database. Direct the queries to the read replica.",
      "B": "Create a backup of the database. Restore the backup to another DB instance. Direct the queries to the new database.",
      "C": "Export the data to Amazon S3. Use Amazon Athena to query the S3 bucket.",
      "D": "Resize the DB instance to accommodate the additional workload."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司将 MySQL 数据库从公司的本地数据中心迁移到 Amazon RDS for MySQL DB 实例。该公司调整了 RDS DB 实例的大小以满足该公司的平均每日工作负载。每个月，当公司运行查询以获取报告时，数据库的运行速度会变慢。该公司希望能够运行报告并保持每日工作负载的性能。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建数据库的只读副本。将查询定向到只读副本。",
      "B": "创建数据库的备份。将备份还原到另一个 DB 实例。将查询定向到新数据库。",
      "C": "将数据导出到 Amazon S3。使用 Amazon Athena 查询 S3 存储桶。",
      "D": "调整 DB 实例的大小以适应额外的工作负载。"
    }
  },
  {
    "id": 591,
    "topic": "1",
    "question_en": "A company runs a container application by using Amazon Elastic Kubernetes Service (Amazon EKS). The application includes microservices that manage customers and place orders. The company needs to route incoming requests to the appropriate microservices. Which solution will meet this requirement MOST cost-effectively?",
    "options_en": {
      "A": "Use the AWS Load Balancer Controller to provision a Network Load Balancer.",
      "B": "Use the AWS Load Balancer Controller to provision an Application Load Balancer.",
      "C": "Use an AWS Lambda function to connect the requests to Amazon EKS.",
      "D": "Use Amazon API Gateway to connect the requests to Amazon EKS."
    },
    "correct_answer": "C",
    "vote_percentage": "75%",
    "question_cn": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 运行容器应用程序。该应用程序包括管理客户和下订单的微服务。该公司需要将传入的请求路由到适当的微服务。哪种解决方案将以最具成本效益的方式满足此要求？",
    "options_cn": {
      "A": "使用 AWS Load Balancer Controller 配置 Network Load Balancer。",
      "B": "使用 AWS Load Balancer Controller 配置 Application Load Balancer。",
      "C": "使用 AWS Lambda 函数将请求连接到 Amazon EKS。",
      "D": "使用 Amazon API Gateway 将请求连接到 Amazon EKS。"
    }
  },
  {
    "id": 592,
    "topic": "1",
    "question_en": "A company uses AWS and sells access to copyrighted images. The company’s global customer base needs to be able to access these images quickly. The company must deny access to users from specific countries. The company wants to minimize costs as much as possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon S3 to store the images. Turn on multi-factor authentication (MFA) and public bucket access. Provide customers with a link to the S3 bucket.",
      "B": "Use Amazon S3 to store the images. Create an IAM user for each customer. Add the users to a group that has permission to access the S3 bucket.",
      "C": "Use Amazon EC2 instances that are behind Application Load Balancers (ALBs) to store the images. Deploy the instances only in the countries the company services. Provide customers with links to the ALBs for their specific country's instances.",
      "D": "Use Amazon S3 to store the images. Use Amazon CloudFront to distribute the images with geographic restrictions. Provide a signed URL for each customer to access the data in CloudFront."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS 并出售对受版权保护的图像的访问权限。该公司的全球客户群需要能够快速访问这些图像。该公司必须拒绝来自特定国家/地区的用户的访问权限。该公司希望尽可能降低成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 存储图像。打开多重身份验证 (MFA) 和公共存储桶访问权限。为客户提供指向 S3 存储桶的链接。",
      "B": "使用 Amazon S3 存储图像。为每个客户创建一个 IAM 用户。将用户添加到有权访问 S3 存储桶的组。",
      "C": "使用位于 Application Load Balancer (ALB) 后的 Amazon EC2 实例存储图像。仅在公司服务的国家/地区部署实例。为客户提供指向其特定国家/地区的实例的 ALB 的链接。",
      "D": "使用 Amazon S3 存储图像。使用 Amazon CloudFront 分发带有地理限制的图像。为每个客户提供签名 URL 以访问 CloudFront 中的数据。"
    }
  },
  {
    "id": 593,
    "topic": "1",
    "question_en": "A solutions architect is designing a highly available Amazon ElastiCache for Redis based solution. The solutions architect needs to ensure that failures do not result in performance degradation or loss of data locally and within an AWS Region. The solution needs to provide high availability at the node level and at the Region level. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Multi-AZ Redis replication groups with shards that contain multiple nodes.",
      "B": "Use Redis shards that contain multiple nodes with Redis append only files (AOF) turned on.",
      "C": "Use a Multi-AZ Redis cluster with more than one read replica in the replication group.",
      "D": "Use Redis shards that contain multiple nodes with Auto Scaling turned on."
    },
    "correct_answer": "A",
    "vote_percentage": "75%",
    "question_cn": "一个解决方案架构师正在设计一个高可用性的基于 Amazon ElastiCache for Redis 的解决方案。解决方案架构师需要确保故障不会导致本地和 AWS 区域内出现性能下降或数据丢失。该解决方案需要在节点级别和区域级别提供高可用性。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用具有包含多个节点的 shard 的多可用区 Redis 复制组。",
      "B": "使用包含多个节点的 Redis shard，并打开 Redis 追加文件 (AOF)。",
      "C": "使用多可用区 Redis 集群，在复制组中有多个只读副本。",
      "D": "使用包含多个节点的 Redis shard，并打开 Auto Scaling。"
    }
  },
  {
    "id": 594,
    "topic": "1",
    "question_en": "A company plans to migrate to AWS and use Amazon EC2 On-Demand Instances for its application. During the migration testing phase, a technical team observes that the application takes a long time to launch and load memory to become fully productive. Which solution will reduce the launch time of the application during the next testing phase?",
    "options_en": {
      "A": "Launch two or more EC2 On-Demand Instances. Turn on auto scaling features and make the EC2 On-Demand Instances available during the next testing phase.",
      "B": "Launch EC2 Spot Instances to support the application and to scale the application so it is available during the next testing phase.",
      "C": "Launch the EC2 On-Demand Instances with hibernation turned on. Configure EC2 Auto Scaling warm pools during the next testing phase.",
      "D": "Launch EC2 On-Demand Instances with Capacity Reservations. Start additional EC2 instances during the next testing phase."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划迁移到 AWS，并为其应用程序使用 Amazon EC2 按需实例。在迁移测试阶段，技术团队观察到应用程序需要很长时间才能启动并加载内存以完全投入生产。哪个解决方案将在下一次测试阶段减少应用程序的启动时间？",
    "options_cn": {
      "A": "启动两个或更多 EC2 按需实例。打开自动缩放功能，并在下一次测试阶段提供 EC2 按需实例。",
      "B": "启动 EC2 Spot 实例以支持应用程序并扩展应用程序，以便在下一次测试阶段可用。",
      "C": "启动已启用休眠的 EC2 按需实例。在下一次测试阶段配置 EC2 Auto Scaling 温池。",
      "D": "启动带有容量预留的 EC2 按需实例。在下一次测试阶段启动额外的 EC2 实例。"
    }
  },
  {
    "id": 595,
    "topic": "1",
    "question_en": "A company's applications run on Amazon EC2 instances in Auto Scaling groups. The company notices that its applications experience sudden trafic increases on random days of the week. The company wants to maintain application performance during sudden trafic increases. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use manual scaling to change the size of the Auto Scaling group.",
      "B": "Use predictive scaling to change the size of the Auto Scaling group.",
      "C": "Use dynamic scaling to change the size of the Auto Scaling group.",
      "D": "Use schedule scaling to change the size of the Auto Scaling group."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的应用程序在 Auto Scaling 组中的 Amazon EC2 实例上运行。该公司注意到其应用程序在一周中的随机日子会遇到突然的流量增加。该公司希望在突然的流量增加期间保持应用程序的性能。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用手动扩展来更改 Auto Scaling 组的大小。",
      "B": "使用预测扩展来更改 Auto Scaling 组的大小。",
      "C": "使用动态扩展来更改 Auto Scaling 组的大小。",
      "D": "使用计划扩展来更改 Auto Scaling 组的大小。"
    }
  },
  {
    "id": 596,
    "topic": "1",
    "question_en": "An ecommerce application uses a PostgreSQL database that runs on an Amazon EC2 instance. During a monthly sales event, database usage increases and causes database connection issues for the application. The trafic is unpredictable for subsequent monthly sales events, which impacts the sales forecast. The company needs to maintain performance when there is an unpredictable increase in trafic. Which solution resolves this issue in the MOST cost-effective way?",
    "options_en": {
      "A": "Migrate the PostgreSQL database to Amazon Aurora Serverless v2.",
      "B": "Enable auto scaling for the PostgreSQL database on the EC2 instance to accommodate increased usage.",
      "C": "Migrate the PostgreSQL database to Amazon RDS for PostgreSQL with a larger instance type.",
      "D": "Migrate the PostgreSQL database to Amazon Redshift to accommodate increased usage."
    },
    "correct_answer": "C",
    "vote_percentage": "93%",
    "question_cn": "一个电子商务应用程序使用在 Amazon EC2 实例上运行的 PostgreSQL 数据库。在每月促销活动期间，数据库使用量增加，导致应用程序的数据库连接问题。后续每月促销活动的流量是不可预测的，这影响了销售预测。该公司需要在流量不可预测地增加时保持性能。哪种解决方案以最具成本效益的方式解决了这个问题？",
    "options_cn": {
      "A": "将 PostgreSQL 数据库迁移到 Amazon Aurora Serverless v2。",
      "B": "为 EC2 实例上的 PostgreSQL 数据库启用自动缩放以适应增加的使用量。",
      "C": "将 PostgreSQL 数据库迁移到 Amazon RDS for PostgreSQL，使用更大的实例类型。",
      "D": "将 PostgreSQL 数据库迁移到 Amazon Redshift 以适应增加的使用量。"
    }
  },
  {
    "id": 597,
    "topic": "1",
    "question_en": "A company hosts an internal serverless application on AWS by using Amazon API Gateway and AWS Lambda. The company’s employees report issues with high latency when they begin using the application each day. The company wants to reduce latency. Which solution will meet these requirements?",
    "options_en": {
      "A": "Increase the API Gateway throttling limit.",
      "B": "Set up a scheduled scaling to increase Lambda provisioned concurrency before employees begin to use the application each day.",
      "C": "Create an Amazon CloudWatch alarm to initiate a Lambda function as a target for the alarm at the beginning of each day.",
      "D": "Increase the Lambda function memory."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司通过使用 Amazon API Gateway 和 AWS Lambda 在 AWS 上托管内部无服务器应用程序。公司员工报告说，他们每天开始使用该应用程序时会遇到高延迟的问题。该公司希望减少延迟。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "增加 API Gateway 限制。 ",
      "B": "设置一个计划扩展，以便在员工每天开始使用该应用程序之前增加 Lambda 预置并发。 ",
      "C": "创建一个 Amazon CloudWatch 警报，以在每天开始时将一个 Lambda 函数作为警报的目标。 ",
      "D": "增加 Lambda 函数内存。 "
    }
  },
  {
    "id": 598,
    "topic": "1",
    "question_en": "A research company uses on-premises devices to generate data for analysis. The company wants to use the AWS Cloud to analyze the data. The devices generate .csv files and support writing the data to an SMB file share. Company analysts must be able to use SQL commands to query the data. The analysts will run queries periodically throughout the day. Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.)",
    "options_en": {
      "A": "Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.",
      "B": "Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway made.",
      "C": "Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.",
      "D": "Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts",
      "E": "Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts",
      "F": "Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家研究公司使用本地设备生成用于分析的数据。该公司希望使用 AWS Cloud 来分析数据。这些设备生成 .csv 文件，并支持将数据写入 SMB 文件共享。公司分析师必须能够使用 SQL 命令查询数据。分析师将在一天中定期间隔运行查询。哪种步骤组合将以最具成本效益的方式满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "在本地以 Amazon S3 File Gateway 模式部署 AWS Storage Gateway。",
      "B": "在本地以 Amazon FSx File Gateway 模式部署 AWS Storage Gateway。",
      "C": "设置 AWS Glue 爬虫，基于 Amazon S3 中的数据创建表。",
      "D": "设置一个带有 EMR 文件系统 (EMRFS) 的 Amazon EMR 集群，以查询 Amazon S3 中的数据。为分析师提供访问权限。",
      "E": "设置一个 Amazon Redshift 集群，以查询 Amazon S3 中的数据。为分析师提供访问权限。",
      "F": "设置 Amazon Athena 以查询 Amazon S3 中的数据。为分析师提供访问权限。"
    }
  },
  {
    "id": 599,
    "topic": "1",
    "question_en": "A company wants to use Amazon Elastic Container Service (Amazon ECS) clusters and Amazon RDS DB instances to build and run a payment processing application. The company will run the application in its on-premises data center for compliance purposes. A solutions architect wants to use AWS Outposts as part of the solution. The solutions architect is working with the company's operational team to build the application. Which activities are the responsibility of the company's operational team? (Choose three.)",
    "options_en": {
      "A": "Providing resilient power and network connectivity to the Outposts racks",
      "B": "Managing the virtualization hypervisor, storage systems, and the AWS services that run on Outposts",
      "C": "Physical security and access controls of the data center environment",
      "D": "Availability of the Outposts infrastructure including the power supplies, servers, and networking equipment within the Outposts racks",
      "E": "Physical maintenance of Outposts components",
      "F": "Providing extra capacity for Amazon ECS clusters to mitigate server failures and maintenance events"
    },
    "correct_answer": "A",
    "vote_percentage": "21%",
    "question_cn": "一家公司希望使用 Amazon Elastic Container Service (Amazon ECS) 集群和 Amazon RDS 数据库实例来构建和运行支付处理应用程序。出于合规性考虑，该公司将在其本地数据中心运行该应用程序。一位解决方案架构师希望使用 AWS Outposts 作为解决方案的一部分。该解决方案架构师正在与公司的运营团队合作构建该应用程序。以下哪些活动是该公司运营团队的责任？（选择三个。）",
    "options_cn": {
      "A": "为 Outposts 机架提供弹性的电源和网络连接",
      "B": "管理虚拟化管理程序、存储系统以及在 Outposts 上运行的 AWS 服务",
      "C": "数据中心环境的物理安全和访问控制",
      "D": "Outposts 基础设施的可用性，包括 Outposts 机架内的电源、服务器和网络设备",
      "E": "Outposts 组件的物理维护",
      "F": "为 Amazon ECS 集群提供额外的容量，以减轻服务器故障和维护事件"
    }
  },
  {
    "id": 600,
    "topic": "1",
    "question_en": "A company is planning to migrate a TCP-based application into the company's VPC. The application is publicly accessible on a nonstandard TCP port through a hardware appliance in the company's data center. This public endpoint can process up to 3 million requests per second with low latency. The company requires the same level of performance for the new public endpoint in AWS. What should a solutions architect recommend to meet this requirement?",
    "options_en": {
      "A": "Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.",
      "B": "Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.",
      "C": "Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.",
      "D": "Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划将其基于 TCP 的应用程序迁移到公司的 VPC 中。该应用程序通过公司数据中心中的硬件设备，在非标准 TCP 端口上公开访问。此公共端点每秒可以处理多达 300 万个请求，并且具有低延迟。该公司要求 AWS 中的新公共端点具有相同的性能水平。解决方案架构师应该推荐什么来满足此要求？",
    "options_cn": {
      "A": "部署一个 Network Load Balancer (NLB)。将 NLB 配置为通过应用程序所需的 TCP 端口进行公开访问。",
      "B": "部署一个 Application Load Balancer (ALB)。将 ALB 配置为通过应用程序所需的 TCP 端口进行公开访问。",
      "C": "部署一个 Amazon CloudFront 分发，该分发侦听应用程序所需的 TCP 端口。使用 Application Load Balancer 作为源。",
      "D": "部署一个 Amazon API Gateway API，该 API 配置有应用程序所需的 TCP 端口。配置具有预置并发的 AWS Lambda 函数来处理请求。"
    }
  },
  {
    "id": 601,
    "topic": "1",
    "question_en": "A company runs its critical database on an Amazon RDS for PostgreSQL DB instance. The company wants to migrate to Amazon Aurora PostgreSQL with minimal downtime and data loss. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a DB snapshot of the RDS for PostgreSQL DB instance to populate a new Aurora PostgreSQL DB cluster.",
      "B": "Create an Aurora read replica of the RDS for PostgreSQL DB instance. Promote the Aurora read replicate to a new Aurora PostgreSQL DB cluster.",
      "C": "Use data import from Amazon S3 to migrate the database to an Aurora PostgreSQL DB cluster.",
      "D": "Use the pg_dump utility to back up the RDS for PostgreSQL database. Restore the backup to a new Aurora PostgreSQL DB cluster."
    },
    "correct_answer": "B",
    "vote_percentage": "85%",
    "question_cn": "一家公司在其 Amazon RDS for PostgreSQL 数据库实例上运行关键数据库。该公司希望以最小的停机时间和数据丢失迁移到 Amazon Aurora PostgreSQL。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建 RDS for PostgreSQL 数据库实例的数据库快照，以填充一个新的 Aurora PostgreSQL 数据库集群。",
      "B": "创建 RDS for PostgreSQL 数据库实例的 Aurora 副本。将 Aurora 副本提升到新的 Aurora PostgreSQL 数据库集群。",
      "C": "使用从 Amazon S3 导入的数据将数据库迁移到 Aurora PostgreSQL 数据库集群。",
      "D": "使用 pg_dump 实用程序备份 RDS for PostgreSQL 数据库。将备份恢复到新的 Aurora PostgreSQL 数据库集群。"
    }
  },
  {
    "id": 602,
    "topic": "1",
    "question_en": "A company's infrastructure consists of hundreds of Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) storage. A solutions architect must ensure that every EC2 instance can be recovered after a disaster. What should the solutions architect do to meet this requirement with the LEAST amount of effort?",
    "options_en": {
      "A": "Take a snapshot of the EBS storage that is attached to each EC2 instance. Create an AWS CloudFormation template to launch new EC2 instances from the EBS storage.",
      "B": "Take a snapshot of the EBS storage that is attached to each EC2 instance. Use AWS Elastic Beanstalk to set the environment based on the EC2 template and attach the EBS storage.",
      "C": "Use AWS Backup to set up a backup plan for the entire group of EC2 instances. Use the AWS Backup API or the AWS CLI to speed up the restore process for multiple EC2 instances.",
      "D": "Create an AWS Lambda function to take a snapshot of the EBS storage that is attached to each EC2 instance and copy the Amazon Machine Images (AMIs). Create another Lambda function to perform the restores with the copied AMIs and attach the EBS storage."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的基础设施由数百个 Amazon EC2 实例组成，这些实例使用 Amazon Elastic Block Store (Amazon EBS) 存储。一位解决方案架构师必须确保在发生灾难后可以恢复每个 EC2 实例。为了以最少的精力满足此要求，解决方案架构师应该怎么做？",
    "options_cn": {
      "A": "拍摄附加到每个 EC2 实例的 EBS 存储的快照。创建一个 AWS CloudFormation 模板，以便从 EBS 存储启动新的 EC2 实例。",
      "B": "拍摄附加到每个 EC2 实例的 EBS 存储的快照。使用 AWS Elastic Beanstalk 根据 EC2 模板设置环境并附加 EBS 存储。",
      "C": "使用 AWS Backup 为整个 EC2 实例组设置备份计划。使用 AWS Backup API 或 AWS CLI 加快多个 EC2 实例的恢复过程。",
      "D": "创建一个 AWS Lambda 函数来拍摄附加到每个 EC2 实例的 EBS 存储的快照，并复制 Amazon Machine Images (AMIs)。创建另一个 Lambda 函数，使用复制的 AMI 执行恢复并附加 EBS 存储。"
    }
  },
  {
    "id": 603,
    "topic": "1",
    "question_en": "A company recently migrated to the AWS Cloud. The company wants a serverless solution for large-scale parallel on-demand processing of a semistructured dataset. The data consists of logs, media files, sales transactions, and IoT sensor data that is stored in Amazon S3. The company wants the solution to process thousands of items in the dataset in parallel. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Use the AWS Step Functions Map state in Inline mode to process the data in parallel.",
      "B": "Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.",
      "C": "Use AWS Glue to process the data in parallel.",
      "D": "Use several AWS Lambda functions to process the data in parallel."
    },
    "correct_answer": "B",
    "vote_percentage": "94%",
    "question_cn": "一家公司最近迁移到了 AWS 云。该公司希望使用无服务器解决方案，以大规模并行按需处理半结构化数据集。数据由日志、媒体文件、销售交易和 IoT 传感器数据组成，这些数据存储在 Amazon S3 中。该公司希望该解决方案能够并行处理数据集中数千个项目。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "在内联模式下使用 AWS Step Functions Map 状态并行处理数据。",
      "B": "在分布式模式下使用 AWS Step Functions Map 状态并行处理数据。",
      "C": "使用 AWS Glue 并行处理数据。",
      "D": "使用多个 AWS Lambda 函数并行处理数据。"
    }
  },
  {
    "id": 604,
    "topic": "1",
    "question_en": "A company will migrate 10 PB of data to Amazon S3 in 6 weeks. The current data center has a 500 Mbps uplink to the internet. Other on- premises applications share the uplink. The company can use 80% of the internet bandwidth for this one-time migration task. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.",
      "B": "Use rsync to transfer the data directly to Amazon S3.",
      "C": "Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3.",
      "D": "Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "94%",
    "question_cn": "一家公司将在 6 周内将 10 PB 的数据迁移到 Amazon S3。当前数据中心具有 500 Mbps 的上行链路到互联网。其他本地应用程序共享上行链路。该公司可以使用 80% 的互联网带宽来完成此一次性迁移任务。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 AWS DataSync 将数据迁移到 Amazon S3 并自动验证数据。",
      "B": "使用 rsync 将数据直接传输到 Amazon S3。",
      "C": "使用 AWS CLI 和多个复制进程将数据直接发送到 Amazon S3。",
      "D": "订购多个 AWS Snowball 设备。将数据复制到设备。将设备发送到 AWS 以将数据复制到 Amazon S3。"
    }
  },
  {
    "id": 605,
    "topic": "1",
    "question_en": "A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy an Amazon S3 File Gateway.",
      "B": "Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.",
      "C": "Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.",
      "D": "Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有多个本地互联网小型计算机系统接口 (ISCSI) 网络存储服务器。该公司希望通过迁移到 AWS 云来减少这些服务器的数量。解决方案架构师必须提供对常用数据的低延迟访问，并减少对本地服务器的依赖，同时将基础设施更改降到最低。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "部署 Amazon S3 File Gateway。",
      "B": "部署 Amazon Elastic Block Store (Amazon EBS) 存储，并将备份到 Amazon S3。",
      "C": "部署一个 AWS Storage Gateway 卷网关，该网关配置有存储卷。",
      "D": "部署一个 AWS Storage Gateway 卷网关，该网关配置有缓存卷。"
    }
  },
  {
    "id": 606,
    "topic": "1",
    "question_en": "A solutions architect is designing an application that will allow business users to upload objects to Amazon S3. The solution needs to maximize object durability. Objects also must be readily available at any time and for any length of time. Users will access objects frequently within the first 30 days after the objects are uploaded, but users are much less likely to access objects that are older than 30 days. Which solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Glacier after 30 days.",
      "B": "Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.",
      "C": "Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 One Zone-Infrequent Access (S3 One Zone- IA) after 30 days.",
      "D": "Store all the objects in S3 Intelligent-Tiering with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一位解决方案架构师正在设计一个应用程序，该应用程序将允许业务用户将对象上传到 Amazon S3。该解决方案需要最大化对象持久性。对象还必须随时可用，并且可以使用任何时长。用户在对象上传后的前 30 天内会频繁访问对象，但用户访问 30 天以上的对象的可能性要小得多。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "将所有对象存储在 S3 Standard 中，并使用 S3 生命周期规则在 30 天后将对象转换为 S3 Glacier。",
      "B": "将所有对象存储在 S3 Standard 中，并使用 S3 生命周期规则在 30 天后将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "C": "将所有对象存储在 S3 Standard 中，并使用 S3 生命周期规则在 30 天后将对象转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)。",
      "D": "使用 S3 Intelligent-Tiering 存储所有对象，并使用 S3 生命周期规则在 30 天后将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA)。"
    }
  },
  {
    "id": 607,
    "topic": "1",
    "question_en": "A company has migrated a two-tier application from its on-premises data center to the AWS Cloud. The data tier is a Multi-AZ deployment of Amazon RDS for Oracle with 12 TB of General Purpose SSD Amazon Elastic Block Store (Amazon EBS) storage. The application is designed to process and store documents in the database as binary large objects (blobs) with an average document size of 6 MB. The database size has grown over time, reducing the performance and increasing the cost of storage. The company must improve the database performance and needs a solution that is highly available and resilient. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.",
      "B": "Increase the RDS DB instance size. Increase the storage capacity to 24 TiChange the storage type to Provisioned IOPS.",
      "C": "Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.",
      "D": "Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司已将其两层应用程序从其本地数据中心迁移到 AWS 云。数据层是 Amazon RDS for Oracle 的多可用区部署，具有 12 TB 的通用 SSD Amazon Elastic Block Store (Amazon EBS) 存储。该应用程序设计为处理并将文档作为二进制大对象 (blob) 存储在数据库中，平均文档大小为 6 MB。随着时间的推移，数据库大小不断增长，降低了性能并增加了存储成本。公司必须提高数据库性能，并且需要一个高可用性和弹性的解决方案。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "减小 RDS 数据库实例大小。将存储容量增加到 24 TiB。将存储类型更改为 Magnetic。",
      "B": "增大 RDS 数据库实例大小。将存储容量增加到 24 TiB。将存储类型更改为 Provisioned IOPS。",
      "C": "创建一个 Amazon S3 存储桶。更新应用程序以将文档存储在 S3 存储桶中。将对象元数据存储在现有数据库中。",
      "D": "创建一个 Amazon DynamoDB 表。更新应用程序以使用 DynamoDB。使用 AWS Database Migration Service (AWS DMS) 将数据从 Oracle 数据库迁移到 DynamoDB。"
    }
  },
  {
    "id": 608,
    "topic": "1",
    "question_en": "A company has an application that serves clients that are deployed in more than 20.000 retail storefront locations around the world. The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The retail locations communicate with the web application over the public internet. The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP. The company's security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter trafic. Update the IP addresses in the rule to include the registered IP addresses.",
      "B": "Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict trafic to the ALModify the firewall rules to include the registered IP addresses.",
      "C": "Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.",
      "D": "Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家公司有一个应用程序，为部署在全球超过 20,000 个零售店地点的客户提供服务。该应用程序由后端 Web 服务组成，这些服务通过 HTTPS 在端口 443 上公开。该应用程序托管在 Application Load Balancer (ALB) 后面的 Amazon EC2 实例上。零售店通过公共互联网与 Web 应用程序通信。该公司允许每个零售店注册其本地 ISP 分配给该零售店的 IP 地址。该公司的安全团队建议通过仅限制对零售店注册的 IP 地址的访问来提高应用程序端点的安全性。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将 AWS WAF Web ACL 与 ALB 关联。在 ALB 上使用 IP 规则集来过滤流量。更新规则中的 IP 地址以包含已注册的 IP 地址。",
      "B": "部署 AWS Firewall Manager 以管理 ALB。配置防火墙规则以限制流量到 ALB。修改防火墙规则以包含已注册的 IP 地址。",
      "C": "将 IP 地址存储在 Amazon DynamoDB 表中。在 ALB 上配置 AWS Lambda 授权函数以验证传入请求是否来自已注册的 IP 地址。",
      "D": "在包含 ALB 公共接口的子网上配置网络 ACL。使用每个已注册 IP 地址的条目更新网络 ACL 上的入口规则。"
    }
  },
  {
    "id": 609,
    "topic": "1",
    "question_en": "A company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an IAM role that includes permissions to access Lake Formation tables.",
      "B": "Create data filters to implement row-level security and cell-level security.",
      "C": "Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.",
      "D": "Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 AWS Lake Formation 在 AWS 上构建一个数据分析平台。该平台将从不同的源（例如 Amazon S3 和 Amazon RDS）摄取数据。该公司需要一个安全解决方案，以防止访问包含敏感信息的数据部分。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 IAM 角色，该角色包含访问 Lake Formation 表的权限。",
      "B": "创建数据过滤器以实施行级安全性和单元级安全性。",
      "C": "创建一个 AWS Lambda 函数，在 Lake Formation 摄取数据之前删除敏感信息。",
      "D": "创建一个 AWS Lambda 函数，该函数定期间隔查询并从 Lake Formation 表中删除敏感信息。"
    }
  },
  {
    "id": 610,
    "topic": "1",
    "question_en": "A company deploys Amazon EC2 instances that run in a VPC. The EC2 instances load source data into Amazon S3 buckets so that the data can be processed in the future. According to compliance laws, the data must not be transmitted over the public internet. Servers in the company's on-premises data center will consume the output from an application that runs on the EC2 instances. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy an interface VPC endpoint for Amazon EC2. Create an AWS Site-to-Site VPN connection between the company and the VPC.",
      "B": "Deploy a gateway VPC endpoint for Amazon S3. Set up an AWS Direct Connect connection between the on-premises network and the VPC.",
      "C": "Set up an AWS Transit Gateway connection from the VPC to the S3 buckets. Create an AWS Site-to-Site VPN connection between the company and the VPC.",
      "D": "Set up proxy EC2 instances that have routes to NAT gateways. Configure the proxy EC2 instances to fetch S3 data and feed the application instances."
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一家公司部署了在 VPC 中运行的 Amazon EC2 实例。EC2 实例将 源数据 加载到 Amazon S3 存储桶中，以便将来可以处理数据。根据合规性法规，数据不得通过公共互联网传输。该公司本地数据中心中的服务器将使用在 EC2 实例上运行的应用程序的输出。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Amazon EC2 部署接口 VPC endpoint。在公司和 VPC 之间创建 AWS Site-to-Site VPN 连接。",
      "B": "为 Amazon S3 部署网关 VPC endpoint。在本地网络和 VPC 之间设置 AWS Direct Connect 连接。",
      "C": "从 VPC 到 S3 存储桶设置 AWS Transit Gateway 连接。在公司和 VPC 之间创建 AWS Site-to-Site VPN 连接。",
      "D": "设置具有指向 NAT 网关的路由的代理 EC2 实例。配置代理 EC2 实例以获取 S3 数据并提供给应用程序实例。"
    }
  },
  {
    "id": 611,
    "topic": "1",
    "question_en": "A company has an application with a REST-based interface that allows data to be received in near-real time from a third-party vendor. Once received, the application processes and stores the data for further analysis. The application is running on Amazon EC2 instances. The third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests. Which design should a solutions architect recommend to provide a more scalable solution?",
    "options_en": {
      "A": "Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.",
      "B": "Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third-party vendor.",
      "C": "Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.",
      "D": "Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个基于 REST 的接口的应用程序，允许近乎实时地从第三方供应商接收数据。接收到数据后，应用程序会处理并存储数据以供进一步分析。该应用程序运行在 Amazon EC2 实例上。第三方供应商在向应用程序发送数据时收到了许多 503 Service Unavailable 错误。当数据量激增时，计算容量达到其最大限制，并且应用程序无法处理所有请求。解决方案架构师应该推荐哪种设计以提供更具可扩展性的解决方案？",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Streams 摄取数据。使用 AWS Lambda 函数处理数据。",
      "B": "在现有应用程序之上使用 Amazon API Gateway。为第三方供应商创建一个具有配额限制的使用计划。",
      "C": "使用 Amazon Simple Notification Service (Amazon SNS) 摄取数据。将 EC2 实例放入 Application Load Balancer 后面的 Auto Scaling 组中。",
      "D": "将应用程序重新打包为容器。使用 Amazon Elastic Container Service (Amazon ECS) 使用 EC2 启动类型部署应用程序，并使用 Auto Scaling 组。"
    }
  },
  {
    "id": 612,
    "topic": "1",
    "question_en": "A company has an application that runs on Amazon EC2 instances in a private subnet. The application needs to process sensitive information from an Amazon S3 bucket. The application must not use the internet to connect to the S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an internet gateway. Update the S3 bucket policy to allow access from the internet gateway. Update the application to use the new internet gateway.",
      "B": "Configure a VPN connection. Update the S3 bucket policy to allow access from the VPN connection. Update the application to use the new VPN connection.",
      "C": "Configure a NAT gateway. Update the S3 bucket policy to allow access from the NAT gateway. Update the application to use the new NAT gateway.",
      "D": "Configure a VPC endpoint. Update the S3 bucket policy to allow access from the VPC endpoint. Update the application to use the new VPC endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个应用程序，该程序运行在私有子网中的 Amazon EC2 实例上。该应用程序需要处理来自 Amazon S3 存储桶的敏感信息。该应用程序不得使用互联网连接到 S3 存储桶。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置一个互联网网关。更新 S3 存储桶策略以允许从互联网网关进行访问。更新应用程序以使用新的互联网网关。",
      "B": "配置一个 VPN 连接。更新 S3 存储桶策略以允许从 VPN 连接进行访问。更新应用程序以使用新的 VPN 连接。",
      "C": "配置一个 NAT 网关。更新 S3 存储桶策略以允许从 NAT 网关进行访问。更新应用程序以使用新的 NAT 网关。",
      "D": "配置一个 VPC endpoint。更新 S3 存储桶策略以允许从 VPC endpoint 进行访问。更新应用程序以使用新的 VPC endpoint。"
    }
  },
  {
    "id": 613,
    "topic": "1",
    "question_en": "A company uses Amazon Elastic Kubernetes Service (Amazon EKS) to run a container application. The EKS cluster stores sensitive information in the Kubernetes secrets object. The company wants to ensure that the information is encrypted. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use the container application to encrypt the information by using AWS Key Management Service (AWS KMS).",
      "B": "Enable secrets encryption in the EKS cluster by using AWS Key Management Service (AWS KMS).",
      "C": "Implement an AWS Lambda function to encrypt the information by using AWS Key Management Service (AWS KMS).",
      "D": "Use AWS Systems Manager Parameter Store to encrypt the information by using AWS Key Management Service (AWS KMS)."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 运行容器应用程序。EKS 集群将敏感信息存储在 Kubernetes 秘密对象中。该公司希望确保信息被加密。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用容器应用程序通过使用 AWS Key Management Service (AWS KMS) 加密信息。",
      "B": "通过使用 AWS Key Management Service (AWS KMS) 在 EKS 集群中打开秘密加密。",
      "C": "实施一个 AWS Lambda 函数，通过使用 AWS Key Management Service (AWS KMS) 加密信息。",
      "D": "使用 AWS Systems Manager Parameter Store 通过使用 AWS Key Management Service (AWS KMS) 加密信息。"
    }
  },
  {
    "id": 614,
    "topic": "1",
    "question_en": "A company is designing a new multi-tier web application that consists of the following components: • Web and application servers that run on Amazon EC2 instances as part of Auto Scaling groups • An Amazon RDS DB instance for data storage A solutions architect needs to limit access to the application servers so that only the web servers can access them. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy AWS PrivateLink in front of the application servers. Configure the network ACL to allow only the web servers to access the application servers.",
      "B": "Deploy a VPC endpoint in front of the application servers. Configure the security group to allow only the web servers to access the application servers.",
      "C": "Deploy a Network Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the network ACL to allow only the web servers to access the application servers.",
      "D": "Deploy an Application Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the security group to allow only the web servers to access the application servers."
    },
    "correct_answer": "A",
    "vote_percentage": "83%",
    "question_cn": "一家公司正在设计一个新的多层 Web 应用程序，该应用程序由以下组件组成：• 在作为 Auto Scaling 组一部分的 Amazon EC2 实例上运行的 Web 和应用程序服务器 • 用于数据存储的 Amazon RDS DB 实例 解决方案架构师需要限制对应用程序服务器的访问，以便只有 Web 服务器才能访问它们。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在应用程序服务器前面部署 AWS PrivateLink。配置网络 ACL 以允许只有 Web 服务器才能访问应用程序服务器。",
      "B": "在应用程序服务器前面部署 VPC 端点。配置安全组以允许只有 Web 服务器才能访问应用程序服务器。",
      "C": "部署具有包含应用程序服务器的 Auto Scaling 组的目标组的网络负载均衡器。配置网络 ACL 以允许只有 Web 服务器才能访问应用程序服务器。",
      "D": "部署具有包含应用程序服务器的 Auto Scaling 组的目标组的 Application Load Balancer。配置安全组以允许只有 Web 服务器才能访问应用程序服务器。"
    }
  },
  {
    "id": 615,
    "topic": "1",
    "question_en": "A company runs a critical, customer-facing application on Amazon Elastic Kubernetes Service (Amazon EKS). The application has a microservices architecture. The company needs to implement a solution that collects, aggregates, and summarizes metrics and logs from the application in a centralized location. Which solution meets these requirements?",
    "options_en": {
      "A": "Run the Amazon CloudWatch agent in the existing EKS cluster. View the metrics and logs in the CloudWatch console.",
      "B": "Run AWS App Mesh in the existing EKS cluster. View the metrics and logs in the App Mesh console.",
      "C": "Configure AWS CloudTrail to capture data events. Query CloudTrail by using Amazon OpenSearch Service.",
      "D": "Configure Amazon CloudWatch Container Insights in the existing EKS cluster. View the metrics and logs in the CloudWatch console."
    },
    "correct_answer": "C",
    "vote_percentage": "90%",
    "question_cn": "一家公司在 Amazon Elastic Kubernetes Service (Amazon EKS) 上运行关键的面向客户的应用程序。该应用程序具有微服务架构。该公司需要实施一个解决方案，该解决方案从应用程序中收集、聚合和总结指标和日志，并将其集中存储。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "在现有的 EKS 集群中运行 Amazon CloudWatch 代理。在 CloudWatch 控制台中查看指标和日志。",
      "B": "在现有的 EKS 集群中运行 AWS App Mesh。在 App Mesh 控制台中查看指标和日志。",
      "C": "配置 AWS CloudTrail 以捕获数据事件。使用 Amazon OpenSearch Service 查询 CloudTrail。",
      "D": "在现有的 EKS 集群中配置 Amazon CloudWatch Container Insights。在 CloudWatch 控制台中查看指标和日志。"
    }
  },
  {
    "id": 616,
    "topic": "1",
    "question_en": "A company has deployed its newest product on AWS. The product runs in an Auto Scaling group behind a Network Load Balancer. The company stores the product’s objects in an Amazon S3 bucket. The company recently experienced malicious attacks against its systems. The company needs a solution that continuously monitors for malicious activity in the AWS account, workloads, and access patterns to the S3 bucket. The solution must also report suspicious activity and display the information on a dashboard. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure Amazon Macie to monitor and report findings to AWS Config.",
      "B": "Configure Amazon Inspector to monitor and report findings to AWS CloudTrail.",
      "C": "Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub.",
      "D": "Configure AWS Config to monitor and report findings to Amazon EventBridge."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司已在 AWS 上部署了其最新产品。该产品在一个 Network Load Balancer 后的 Auto Scaling 组中运行。该公司将其产品的对象存储在 Amazon S3 存储桶中。该公司最近遭受了针对其系统的恶意攻击。该公司需要一个解决方案，该解决方案持续监控 AWS 账户、工作负载和对 S3 存储桶的访问模式中的恶意活动。该解决方案还必须报告可疑活动并在仪表板上显示信息。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Macie 以监控并将调查结果报告给 AWS Config。",
      "B": "配置 Amazon Inspector 以监控并将调查结果报告给 AWS CloudTrail。",
      "C": "配置 Amazon GuardDuty 以监控并将调查结果报告给 AWS Security Hub。",
      "D": "配置 AWS Config 以监控并将调查结果报告给 Amazon EventBridge。"
    }
  },
  {
    "id": 617,
    "topic": "1",
    "question_en": "A company wants to migrate an on-premises data center to AWS. The data center hosts a storage server that stores data in an NFS-based file system. The storage server holds 200 GB of data. The company needs to migrate the data without interruption to existing services. Multiple resources in AWS must be able to access the data by using the NFS protocol. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon FSx for Lustre file system.",
      "B": "Create an Amazon Elastic File System (Amazon EFS) file system.",
      "C": "Create an Amazon S3 bucket to receive the data.",
      "D": "Manually use an operating system copy command to push the data into the AWS destination",
      "E": "Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司希望将其本地数据中心迁移到 AWS。数据中心托管一个存储服务器，该服务器将数据存储在基于 NFS 的文件系统中。存储服务器包含 200 GB 的数据。公司需要在不中断现有服务的情况下迁移数据。AWS 中的多个资源必须能够通过使用 NFS 协议来访问数据。哪种步骤组合将以最具成本效益的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建 Amazon FSx for Lustre 文件系统。",
      "B": "创建 Amazon Elastic File System (Amazon EFS) 文件系统。",
      "C": "创建 Amazon S3 存储桶以接收数据。",
      "D": "手动使用操作系统复制命令将数据推送到 AWS 目标。",
      "E": "在本地数据中心安装 AWS DataSync 代理。使用 DataSync 任务在本地位置和 AWS 之间进行数据迁移。"
    }
  },
  {
    "id": 618,
    "topic": "1",
    "question_en": "A company wants to use Amazon FSx for Windows File Server for its Amazon EC2 instances that have an SMB file share mounted as a volume in the us-east-1 Region. The company has a recovery point objective (RPO) of 5 minutes for planned system maintenance or unplanned service disruptions. The company needs to replicate the file system to the us-west-2 Region. The replicated data must not be deleted by any user for 5 years. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
      "B": "Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
      "C": "Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.",
      "D": "Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望为其在 us-east-1 区域中作为卷挂载 SMB 文件共享的 Amazon EC2 实例使用 Amazon FSx for Windows File Server。该公司对计划内的系统维护或计划外的服务中断的恢复点目标 (RPO) 为 5 分钟。该公司需要将文件系统复制到 us-west-2 区域。复制的数据不得被任何用户删除，为期 5 年。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 us-east-1 中创建一个 FSx for Windows File Server 文件系统，该系统具有 Single-AZ 2 部署类型。使用 AWS Backup 创建一个每日备份计划，其中包括一个将备份复制到 us-west-2 的备份规则。为 us-west-2 中的目标 Vault 配置 AWS Backup Vault Lock 的合规模式。配置最短持续时间为 5 年。",
      "B": "在 us-east-1 中创建一个 FSx for Windows File Server 文件系统，该系统具有 Multi-AZ 部署类型。使用 AWS Backup 创建一个每日备份计划，其中包括一个将备份复制到 us-west-2 的备份规则。为 us-west-2 中的目标 Vault 配置 AWS Backup Vault Lock 的管理模式。配置最短持续时间为 5 年。",
      "C": "在 us-east-1 中创建一个 FSx for Windows File Server 文件系统，该系统具有 Multi-AZ 部署类型。使用 AWS Backup 创建一个每日备份计划，其中包括一个将备份复制到 us-west-2 的备份规则。为 us-west-2 中的目标 Vault 配置 AWS Backup Vault Lock 的合规模式。配置最短持续时间为 5 年。",
      "D": "在 us-east-1 中创建一个 FSx for Windows File Server 文件系统，该系统具有 Single-AZ 2 部署类型。使用 AWS Backup 创建一个每日备份计划，其中包括一个将备份复制到 us-west-2 的备份规则。为 us-west-2 中的目标 Vault 配置 AWS Backup Vault Lock 的管理模式。配置最短持续时间为 5 年。"
    }
  },
  {
    "id": 619,
    "topic": "1",
    "question_en": "A solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Because the individual developers will have AWS account root user- level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified. Which action meets these requirements?",
    "options_en": {
      "A": "Create an IAM policy that prohibits changes to CloudTrail. and attach it to the root user.",
      "B": "Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled.",
      "C": "Create a service control policy (SCP) that prohibits changes to CloudTrail, and attach it the developer accounts.",
      "D": "Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the management account."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在为一家公司设计安全解决方案，该公司希望通过 AWS Organizations 为开发人员提供单独的 AWS 账户，同时维护标准安全控制。由于各个开发人员将拥有对其自己账户的 AWS 账户根用户级别的访问权限，因此解决方案架构师希望确保应用于新开发人员账户的强制性 AWS CloudTrail 配置不会被修改。哪个操作满足这些要求？",
    "options_cn": {
      "A": "创建一个 IAM 策略，禁止更改 CloudTrail，并将其附加到根用户。",
      "B": "在开发人员账户内从 CloudTrail 创建一个新的跟踪，并启用组织跟踪选项。",
      "C": "创建一个服务控制策略 (SCP)，禁止更改 CloudTrail，并将其附加到开发人员账户。",
      "D": "为 CloudTrail 创建一个服务关联角色，其策略条件仅允许从管理账户中的 Amazon 资源名称 (ARN) 进行更改。"
    }
  },
  {
    "id": 620,
    "topic": "1",
    "question_en": "A company is planning to deploy a business-critical application in the AWS Cloud. The application requires durable storage with consistent, low-latency performance. Which type of storage should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Instance store volume",
      "B": "Amazon ElastiCache for Memcached cluster",
      "C": "Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume",
      "D": "Throughput Optimized HDD Amazon Elastic Block Store (Amazon EBS) volume"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划在 AWS 云中部署一项关键业务应用程序。该应用程序需要具有一致的低延迟性能的持久性存储。 解决方案架构师应该推荐哪种类型的存储来满足这些需求？",
    "options_cn": {
      "A": "实例存储卷",
      "B": "用于 Memcached 集群的 Amazon ElastiCache",
      "C": "预置 IOPS SSD Amazon Elastic Block Store (Amazon EBS) 卷",
      "D": "吞吐量优化 HDD Amazon Elastic Block Store (Amazon EBS) 卷"
    }
  },
  {
    "id": 621,
    "topic": "1",
    "question_en": "An online photo-sharing company stores its photos in an Amazon S3 bucket that exists in the us-west-1 Region. The company needs to store a copy of all new photos in the us-east-1 Region. Which solution will meet this requirement with the LEAST operational effort?",
    "options_en": {
      "A": "Create a second S3 bucket in us-east-1. Use S3 Cross-Region Replication to copy photos from the existing S3 bucket to the second S3 bucket.",
      "B": "Create a cross-origin resource sharing (CORS) configuration of the existing S3 bucket. Specify us-east-1 in the CORS rule's AllowedOrigin element.",
      "C": "Create a second S3 bucket in us-east-1 across multiple Availability Zones. Create an S3 Lifecycle rule to save photos into the second S3 bucket.",
      "D": "Create a second S3 bucket in us-east-1. Configure S3 event notifications on object creation and update events to invoke an AWS Lambda function to copy photos from the existing S3 bucket to the second S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家在线照片分享公司将其照片存储在位于 us-west-1 区域的 Amazon S3 存储桶中。该公司需要在 us-east-1 区域存储所有新照片的副本。哪种解决方案将以最少的运营工作量满足此要求？",
    "options_cn": {
      "A": "在 us-east-1 中创建第二个 S3 存储桶。使用 S3 跨区域复制将照片从现有 S3 存储桶复制到第二个 S3 存储桶。",
      "B": "创建现有 S3 存储桶的跨源资源共享 (CORS) 配置。在 CORS 规则的 AllowedOrigin 元素中指定 us-east-1。",
      "C": "在 us-east-1 中创建跨多个可用区的第二个 S3 存储桶。创建 S3 生命周期规则以将照片保存到第二个 S3 存储桶中。",
      "D": "在 us-east-1 中创建第二个 S3 存储桶。配置 S3 事件通知，针对对象创建和更新事件，以调用 AWS Lambda 函数将照片从现有 S3 存储桶复制到第二个 S3 存储桶。"
    }
  },
  {
    "id": 622,
    "topic": "1",
    "question_en": "A company is creating a new web application for its subscribers. The application will consist of a static single page and a persistent database layer. The application will have millions of users for 4 hours in the morning, but the application will have only a few thousand users during the rest of the day. The company's data architects have requested the ability to rapidly evolve their schema. Which solutions will meet these requirements and provide the MOST scalability? (Choose two.)",
    "options_en": {
      "A": "Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.",
      "B": "Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.",
      "C": "Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.",
      "D": "Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin",
      "E": "Deploy the web servers for static content across a fieet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume."
    },
    "correct_answer": "C",
    "vote_percentage": "60%",
    "question_cn": "一家公司正在为其订阅者创建一个新的 Web 应用程序。该应用程序将包含一个静态单页和一个持久数据库层。该应用程序将在早晨的 4 个小时内拥有数百万用户，但在一天中的其余时间只有几千个用户。该公司的数据架构师要求能够快速演进其模式。哪些解决方案将满足这些要求并提供最大的可扩展性？（选择两个。）",
    "options_cn": {
      "A": "部署 Amazon DynamoDB 作为数据库解决方案。按需预置容量。",
      "B": "部署 Amazon Aurora 作为数据库解决方案。选择无服务器数据库引擎模式。",
      "C": "部署 Amazon DynamoDB 作为数据库解决方案。确保启用 DynamoDB 自动伸缩。",
      "D": "将静态内容部署到 Amazon S3 存储桶中。预置一个以 S3 存储桶为源的 Amazon CloudFront 分发。",
      "E": "将用于静态内容的 Web 服务器部署到 Auto Scaling 组中的一组 Amazon EC2 实例中。将这些实例配置为定期从 Amazon Elastic File System (Amazon EFS) 卷刷新内容。"
    }
  },
  {
    "id": 623,
    "topic": "1",
    "question_en": "A company uses Amazon API Gateway to manage its REST APIs that third-party service providers access. The company must protect the REST APIs from SQL injection and cross-site scripting attacks. What is the MOST operationally eficient solution that meets these requirements?",
    "options_en": {
      "A": "Configure AWS Shield.",
      "B": "Configure AWS WAF.",
      "C": "Set up API Gateway with an Amazon CloudFront distribution. Configure AWS Shield in CloudFront.",
      "D": "Set up API Gateway with an Amazon CloudFront distribution. Configure AWS WAF in CloudFront."
    },
    "correct_answer": "A",
    "vote_percentage": "89%",
    "question_cn": "一家公司使用 Amazon API Gateway 管理第三方服务提供商访问的 REST API。公司必须保护 REST API 免受 SQL 注入和跨站点脚本攻击。哪种解决方案在运营上效率最高，并且满足这些要求？",
    "options_cn": {
      "A": "配置 AWS Shield。",
      "B": "配置 AWS WAF。",
      "C": "使用 Amazon CloudFront 分发配置 API Gateway。在 CloudFront 中配置 AWS Shield。",
      "D": "使用 Amazon CloudFront 分发配置 API Gateway。在 CloudFront 中配置 AWS WAF。"
    }
  },
  {
    "id": 624,
    "topic": "1",
    "question_en": "A company wants to provide users with access to AWS resources. The company has 1,500 users and manages their access to on-premises resources through Active Directory user groups on the corporate network. However, the company does not want users to have to maintain another identity to access the resources. A solutions architect must manage user access to the AWS resources while preserving access to the on-premises resources. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an IAM user for each user in the company. Attach the appropriate policies to each user.",
      "B": "Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.",
      "C": "Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.",
      "D": "Configure Security Assertion Markup Language (SAML) 2 0-based federation. Create roles with the appropriate policies attached Map the roles to the Active Directory groups."
    },
    "correct_answer": "D",
    "vote_percentage": "92%",
    "question_cn": "一家公司希望为用户提供对 AWS 资源的访问权限。该公司有 1,500 名用户，并通过公司网络上的 Active Directory 用户组管理他们对本地资源的访问。但是，该公司不希望用户为了访问资源而维护另一个身份。一位解决方案架构师必须管理用户对 AWS 资源的访问权限，同时保留对本地资源的访问权限。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "为公司中的每个用户创建一个 IAM 用户。将适当的策略附加到每个用户。",
      "B": "使用 Amazon Cognito 和 Active Directory 用户池。创建带有附加的适当策略的角色。",
      "C": "定义跨账户角色，并附加适当的策略。将角色映射到 Active Directory 组。",
      "D": "配置基于安全断言标记语言 (SAML) 2.0 的联合身份验证。创建带有附加的适当策略的角色。将角色映射到 Active Directory 组。"
    }
  },
  {
    "id": 625,
    "topic": "1",
    "question_en": "A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights. Which configuration should the solutions architect choose to meet these requirements?",
    "options_en": {
      "A": "Configure Amazon CloudFront with AWS WAF.",
      "B": "Configure Application Load Balancers with AWS WAF",
      "C": "Configure Amazon Route 53 with a geolocation policy",
      "D": "Configure Amazon Route 53 with a geoproximity routing policy"
    },
    "correct_answer": "A",
    "vote_percentage": "77%",
    "question_cn": "一家公司在其多个 Application Load Balancer 后面托管一个网站。该公司在全球范围内对其内容拥有不同的分发权。 解决方案架构师需要确保为用户提供正确的内容，且不违反分发权。 解决方案架构师应选择哪种配置来满足这些要求？",
    "options_cn": {
      "A": "使用 AWS WAF 配置 Amazon CloudFront。",
      "B": "使用 AWS WAF 配置 Application Load Balancer。",
      "C": "使用地理位置策略配置 Amazon Route 53。",
      "D": "使用地理邻近路由策略配置 Amazon Route 53。"
    }
  },
  {
    "id": 626,
    "topic": "1",
    "question_en": "A company stores its data on premises. The amount of data is growing beyond the company's available capacity. The company wants to migrate its data from the on-premises location to an Amazon S3 bucket. The company needs a solution that will automatically validate the integrity of the data after the transfer. Which solution will meet these requirements?",
    "options_en": {
      "A": "Order an AWS Snowball Edge device. Configure the Snowball Edge device to perform the online data transfer to an S3 bucket",
      "B": "Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.",
      "C": "Create an Amazon S3 File Gateway on premises Configure the S3 File Gateway to perform the online data transfer to an S3 bucket",
      "D": "Configure an accelerator in Amazon S3 Transfer Acceleration on premises. Configure the accelerator to perform the online data transfer to an S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司将其数据存储在本地。数据量正在增长，超出了公司的可用容量。该公司希望将其数据从本地位置迁移到 Amazon S3 存储桶。该公司需要一个解决方案，该解决方案将在传输后自动验证数据的完整性。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "订购 AWS Snowball Edge 存储优化设备。将 Snowball Edge 设备配置为执行在线数据传输到 S3 存储桶。",
      "B": "在本地部署 AWS DataSync 代理。将 DataSync 代理配置为执行在线数据传输到 S3 存储桶。",
      "C": "在本地创建 Amazon S3 文件网关。配置 S3 文件网关以执行在线数据传输到 S3 存储桶。",
      "D": "在本地配置 Amazon S3 传输加速器。配置加速器以执行在线数据传输到 S3 存储桶。"
    }
  },
  {
    "id": 627,
    "topic": "1",
    "question_en": "A company wants to migrate two DNS servers to AWS. The servers host a total of approximately 200 zones and receive 1 million requests each day on average. The company wants to maximize availability while minimizing the operational overhead that is related to the management of the two servers. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Create 200 new hosted zones in the Amazon Route 53 console Import zone files.",
      "B": "Launch a single large Amazon EC2 instance Import zone tiles. Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.",
      "C": "Migrate the servers to AWS by using AWS Server Migration Service (AWS SMS). Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.",
      "D": "Launch an Amazon EC2 instance in an Auto Scaling group across two Availability Zones. Import zone files. Set the desired capacity to 1 and the maximum capacity to 3 for the Auto Scaling group. Configure scaling alarms to scale based on CPU utilization."
    },
    "correct_answer": "A",
    "vote_percentage": "94%",
    "question_cn": "一家公司希望将两台 DNS 服务器迁移到 AWS。服务器总共托管大约 200 个区域，平均每天收到 100 万个请求。公司希望最大限度地提高可用性，同时最大限度地减少与管理这两台服务器相关的运营开销。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "在 Amazon Route 53 控制台中创建 200 个新的托管区域，并导入区域文件。",
      "B": "启动一个大型 Amazon EC2 实例，导入区域文件。配置 Amazon CloudWatch 告警和通知，以提醒公司任何停机时间。",
      "C": "使用 AWS Server Migration Service (AWS SMS) 将服务器迁移到 AWS。配置 Amazon CloudWatch 告警和通知，以提醒公司任何停机时间。",
      "D": "在跨两个可用区的 Auto Scaling 组中启动一个 Amazon EC2 实例。导入区域文件。将 Auto Scaling 组的所需容量设置为 1，最大容量设置为 3。配置基于 CPU 利用率进行扩展的告警。"
    }
  },
  {
    "id": 628,
    "topic": "1",
    "question_en": "A global company runs its applications in multiple AWS accounts in AWS Organizations. The company's applications use multipart uploads to upload data to multiple Amazon S3 buckets across AWS Regions. The company wants to report on incomplete multipart uploads for cost compliance purposes. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure AWS Config with a rule to report the incomplete multipart upload object count.",
      "B": "Create a service control policy (SCP) to report the incomplete multipart upload object count.",
      "C": "Configure S3 Storage Lens to report the incomplete multipart upload object count.",
      "D": "Create an S3 Multi-Region Access Point to report the incomplete multipart upload object count."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家全球性公司在 AWS Organizations 的多个 AWS 账户中运行其应用程序。该公司的应用程序使用 multipart uploads 将数据上传到跨 AWS 区域的多个 Amazon S3 存储桶。该公司希望报告未完成的 multipart uploads 以进行成本合规性。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用规则配置 AWS Config 来报告未完成的 multipart upload 对象计数。",
      "B": "创建服务控制策略 (SCP) 来报告未完成的 multipart upload 对象计数。",
      "C": "配置 S3 Storage Lens 来报告未完成的 multipart upload 对象计数。",
      "D": "创建 S3 Multi-Region Access Point 来报告未完成的 multipart upload 对象计数。"
    }
  },
  {
    "id": 629,
    "topic": "1",
    "question_en": "A company runs a production database on Amazon RDS for MySQL. The company wants to upgrade the database version for security compliance reasons. Because the database contains critical data, the company wants a quick solution to upgrade and test functionality without losing any data. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an RDS manual snapshot. Upgrade to the new version of Amazon RDS for MySQL.",
      "B": "Use native backup and restore. Restore the data to the upgraded new version of Amazon RDS for MySQL.",
      "C": "Use AWS Database Migration Service (AWS DMS) to replicate the data to the upgraded new version of Amazon RDS for MySQL.",
      "D": "Use Amazon RDS Blue/Green Deployments to deploy and test production changes."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Amazon RDS for MySQL 上运行生产数据库。该公司希望出于安全合规性的原因升级数据库版本。由于数据库包含关键数据，该公司希望有一个快速的解决方案来升级和测试功能，而不会丢失任何数据。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建 RDS 手动快照。升级到 Amazon RDS for MySQL 的新版本。",
      "B": "使用本机备份和还原。将数据还原到已升级的 Amazon RDS for MySQL 的新版本。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 将数据复制到已升级的 Amazon RDS for MySQL 的新版本。",
      "D": "使用 Amazon RDS Blue/Green 部署来部署和测试生产更改。"
    }
  },
  {
    "id": 630,
    "topic": "1",
    "question_en": "A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete. If the job is interrupted, it has to restart from the beginning. How should the solutions architect address this issue in the MOST cost-effective manner?",
    "options_en": {
      "A": "Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.",
      "B": "Create an AWS Lambda function triggered by an Amazon EventBridge scheduled event.",
      "C": "Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge scheduled event.",
      "D": "Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge scheduled event."
    },
    "correct_answer": "C",
    "vote_percentage": "87%",
    "question_cn": "一位解决方案架构师正在创建一个每天运行一次且最多需要 2 小时才能完成的数据处理作业。如果该作业中断，则必须从头开始重新启动。解决方案架构师应如何以最具成本效益的方式解决此问题？",
    "options_cn": {
      "A": "创建一个在 Amazon EC2 预留实例上本地运行的脚本，该脚本由 cron 作业触发。",
      "B": "创建一个由 Amazon EventBridge 定时事件触发的 AWS Lambda 函数。",
      "C": "使用由 Amazon EventBridge 定时事件触发的 Amazon Elastic Container Service (Amazon ECS) Fargate 任务。",
      "D": "使用由 Amazon EventBridge 定时事件触发的在 Amazon EC2 上运行的 Amazon Elastic Container Service (Amazon ECS) 任务。"
    }
  },
  {
    "id": 631,
    "topic": "1",
    "question_en": "A social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database.",
      "B": "Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.",
      "C": "Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database.",
      "D": "Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database."
    },
    "correct_answer": "B",
    "vote_percentage": "88%",
    "question_cn": "一家社交媒体公司希望将其用户档案、关系和互动数据库存储在 AWS 云中。该公司需要一个应用程序来监控数据库中的任何更改。该应用程序需要分析数据实体之间的关系，并向用户提供建议。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Neptune 存储信息。使用 Amazon Kinesis Data Streams 处理数据库中的更改。",
      "B": "使用 Amazon Neptune 存储信息。使用 Neptune Streams 处理数据库中的更改。",
      "C": "使用 Amazon Quantum Ledger Database (Amazon QLDB) 存储信息。使用 Amazon Kinesis Data Streams 处理数据库中的更改。",
      "D": "使用 Amazon Quantum Ledger Database (Amazon QLDB) 存储信息。使用 Neptune Streams 处理数据库中的更改。"
    }
  },
  {
    "id": 632,
    "topic": "1",
    "question_en": "A company is creating a new application that will store a large amount of data. The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones. The needed amount of storage space will continue to grow for the next 6 months. Which storage solution should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.",
      "B": "Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.",
      "C": "Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.",
      "D": "Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在创建一个新应用程序，该应用程序将存储大量数据。数据将每小时进行分析，并将由部署在多个可用区中的多个 Amazon EC2 Linux 实例修改。所需的存储空间将在未来 6 个月内持续增长。解决方案架构师应该推荐哪种存储解决方案来满足这些要求？",
    "options_cn": {
      "A": "将数据存储在 Amazon S3 Glacier 中。更新 S3 Glacier 库策略以允许应用程序实例访问。",
      "B": "将数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。将 EBS 卷挂载到应用程序实例上。",
      "C": "将数据存储在 Amazon Elastic File System (Amazon EFS) 文件系统中。将文件系统挂载到应用程序实例上。",
      "D": "将数据存储在应用程序实例之间共享的 Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS 卷中。"
    }
  },
  {
    "id": 633,
    "topic": "1",
    "question_en": "A company manages an application that stores data on an Amazon RDS for PostgreSQL Multi-AZ DB instance. Increases in trafic are causing performance problems. The company determines that database queries are the primary reason for the slow performance. What should a solutions architect do to improve the application's performance?",
    "options_en": {
      "A": "Serve read trafic from the Multi-AZ standby replica.",
      "B": "Configure the DB instance to use Transfer Acceleration.",
      "C": "Create a read replica from the source DB instance. Serve read trafic from the read replica.",
      "D": "Use Amazon Kinesis Data Firehose between the application and Amazon RDS to increase the concurrency of database requests."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司管理一个应用程序，该应用程序将数据存储在 Amazon RDS for PostgreSQL 多可用区数据库实例上。流量的增加导致了性能问题。该公司确定数据库查询是性能缓慢的主要原因。解决方案架构师应该怎么做来提高应用程序的性能？",
    "options_cn": {
      "A": "从多可用区备用副本提供读取流量。",
      "B": "将数据库实例配置为使用 Transfer Acceleration。",
      "C": "从源数据库实例创建读取副本。从读取副本提供读取流量。",
      "D": "在应用程序和 Amazon RDS 之间使用 Amazon Kinesis Data Firehose 来增加数据库请求的并发性。"
    }
  },
  {
    "id": 634,
    "topic": "1",
    "question_en": "A company collects 10 GB of telemetry data daily from various machines. The company stores the data in an Amazon S3 bucket in a source data account. The company has hired several consulting agencies to use this data for analysis. Each agency needs read access to the data for its analysts. The company must share the data from the source data account by choosing a solution that maximizes security and operational eficiency. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure S3 global tables to replicate data for each agency.",
      "B": "Make the S3 bucket public for a limited time. Inform only the agencies.",
      "C": "Configure cross-account access for the S3 bucket to the accounts that the agencies own.",
      "D": "Set up an IAM user for each analyst in the source data account. Grant each user access to the S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "93%",
    "question_cn": "一家公司每天从各种机器收集 10 GB 的遥测数据。该公司将数据存储在源数据账户的 Amazon S3 存储桶中。该公司聘请了几家咨询机构来使用这些数据进行分析。每个机构都需要访问数据的读取权限，供其分析师使用。该公司必须通过选择一个能够最大化安全性和运营效率的解决方案，来共享源数据账户中的数据。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 S3 全局表，为每个机构复制数据。",
      "B": "将 S3 存储桶公开一段有限的时间。仅通知这些机构。",
      "C": "为 S3 存储桶配置跨账户访问权限，使其指向这些机构拥有的账户。",
      "D": "在源数据账户中为每个分析师设置一个 IAM 用户。授予每个用户访问 S3 存储桶的权限。"
    }
  },
  {
    "id": 635,
    "topic": "1",
    "question_en": "A company uses Amazon FSx for NetApp ONTAP in its primary AWS Region for CIFS and NFS file shares. Applications that run on Amazon EC2 instances access the file shares. The company needs a storage disaster recovery (DR) solution in a secondary Region. The data that is replicated in the secondary Region needs to be accessed by using the same protocols as the primary Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Lambda function to copy the data to an Amazon S3 bucket. Replicate the S3 bucket to the secondary Region.",
      "B": "Create a backup of the FSx for ONTAP volumes by using AWS Backup. Copy the volumes to the secondary Region. Create a new FSx for ONTAP instance from the backup.",
      "C": "Create an FSx for ONTAP instance in the secondary Region. Use NetApp SnapMirror to replicate data from the primary Region to the secondary Region.",
      "D": "Create an Amazon Elastic File System (Amazon EFS) volume. Migrate the current data to the volume. Replicate the volume to the secondary Region."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其主 AWS 区域中使用 Amazon FSx for NetApp ONTAP 用于 CIFS 和 NFS 文件共享。在 Amazon EC2 实例上运行的应用程序访问文件共享。该公司需要在辅助区域中建立存储灾难恢复 (DR) 解决方案。在辅助区域中复制的数据需要使用与主区域相同的协议进行访问。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数将数据复制到 Amazon S3 存储桶。将 S3 存储桶复制到辅助区域。",
      "B": "使用 AWS Backup 创建 FSx for ONTAP 卷的备份。将卷复制到辅助区域。从备份创建新的 FSx for ONTAP 实例。",
      "C": "在辅助区域中创建 FSx for ONTAP 实例。使用 NetApp SnapMirror 将数据从主区域复制到辅助区域。",
      "D": "创建一个 Amazon Elastic File System (Amazon EFS) 卷。将当前数据迁移到该卷。将卷复制到辅助区域。"
    }
  },
  {
    "id": 636,
    "topic": "1",
    "question_en": "A development team is creating an event-based application that uses AWS Lambda functions. Events will be generated when files are added to an Amazon S3 bucket. The development team currently has Amazon Simple Notification Service (Amazon SNS) configured as the event target from Amazon S3. What should a solutions architect do to process the events from Amazon S3 in a scalable way?",
    "options_en": {
      "A": "Create an SNS subscription that processes the event in Amazon Elastic Container Service (Amazon ECS) before the event runs in Lambda.",
      "B": "Create an SNS subscription that processes the event in Amazon Elastic Kubernetes Service (Amazon EKS) before the event runs in Lambda",
      "C": "Create an SNS subscription that sends the event to Amazon Simple Queue Service (Amazon SQS). Configure the SOS queue to trigger a Lambda function.",
      "D": "Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一个开发团队正在创建一个基于事件的应用程序，该应用程序使用 AWS Lambda 函数。当文件添加到 Amazon S3 存储桶时，将生成事件。该开发团队目前已将 Amazon Simple Notification Service (Amazon SNS) 配置为来自 Amazon S3 的事件目标。解决方案架构师应该怎么做才能以可扩展的方式处理来自 Amazon S3 的事件？",
    "options_cn": {
      "A": "创建一个 SNS 订阅，在 Lambda 中运行事件之前，在 Amazon Elastic Container Service (Amazon ECS) 中处理该事件。",
      "B": "创建一个 SNS 订阅，在 Lambda 中运行事件之前，在 Amazon Elastic Kubernetes Service (Amazon EKS) 中处理该事件",
      "C": "创建一个 SNS 订阅，将事件发送到 Amazon Simple Queue Service (Amazon SQS)。配置 SQS 队列以触发 Lambda 函数。",
      "D": "创建一个 SNS 订阅，将事件发送到 AWS Server Migration Service (AWS SMS)。配置 Lambda 函数以从 SMS 事件轮询。"
    }
  },
  {
    "id": 637,
    "topic": "1",
    "question_en": "A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth. Data can be queried using simple key-value requests. Which combination ofAWS services would meet these requirements? (Choose two.)",
    "options_en": {
      "A": "AWS Fargate",
      "B": "AWS Lambda",
      "C": "Amazon DynamoDB",
      "D": "Amazon EC2 Auto Scaling",
      "E": "MySQL-compatible Amazon Aurora"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个解决方案架构师正在设计一个位于 Amazon API Gateway 之后的新服务。该服务的请求模式将是不可预测的，并且可以从 0 个请求突然更改为每秒超过 500 个请求。目前需要在后端数据库中持久保存的数据总大小小于 1 GB，并且未来的增长不可预测。可以使用简单的键值请求来查询数据。哪种 AWS 服务组合可以满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "AWS Fargate",
      "B": "AWS Lambda",
      "C": "Amazon DynamoDB",
      "D": "Amazon EC2 Auto Scaling",
      "E": "MySQL-compatible Amazon Aurora"
    }
  },
  {
    "id": 638,
    "topic": "1",
    "question_en": "A company collects and shares research data with the company's employees all over the world. The company wants to collect and store the data in an Amazon S3 bucket and process the data in the AWS Cloud. The company will share the data with the company's employees. The company needs a secure solution in the AWS Cloud that minimizes operational overhead. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an AWS Lambda function to create an S3 presigned URL. Instruct employees to use the URL.",
      "B": "Create an IAM user for each employee. Create an IAM policy for each employee to allow S3 access. Instruct employees to use the AWS Management Console.",
      "C": "Create an S3 File Gateway. Create a share for uploading and a share for downloading. Allow employees to mount shares on their local computers to use S3 File Gateway.",
      "D": "Configure AWS Transfer Family SFTP endpoints. Select the custom identity provider options. Use AWS Secrets Manager to manage the user credentials Instruct employees to use Transfer Family."
    },
    "correct_answer": "D",
    "vote_percentage": "39%",
    "question_cn": "一家公司在全球范围内收集并与公司员工共享研究数据。该公司希望将数据收集并存储在 Amazon S3 存储桶中，并在 AWS 云中处理数据。该公司将与公司员工共享数据。该公司需要在 AWS 云中提供一个安全的解决方案，以最大限度地减少运营开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Lambda 函数创建 S3 预签名 URL。指示员工使用该 URL。",
      "B": "为每个员工创建 IAM 用户。为每个员工创建 IAM 策略以允许 S3 访问。指示员工使用 AWS 管理控制台。",
      "C": "创建 S3 文件网关。创建用于上传的共享和用于下载的共享。允许员工在其本地计算机上挂载共享以使用 S3 文件网关。",
      "D": "配置 AWS Transfer Family SFTP 端点。选择自定义身份提供程序选项。使用 AWS Secrets Manager 管理用户凭证。指示员工使用 Transfer Family。"
    }
  },
  {
    "id": 639,
    "topic": "1",
    "question_en": "A company is building a new furniture inventory application. The company has deployed the application on a fieet ofAmazon EC2 instances across multiple Availability Zones. The EC2 instances run behind an Application Load Balancer (ALB) in their VPC. A solutions architect has observed that incoming trafic seems to favor one EC2 instance, resulting in latency for some requests. What should the solutions architect do to resolve this issue?",
    "options_en": {
      "A": "Disable session afinity (sticky sessions) on the ALB",
      "B": "Replace the ALB with a Network Load Balancer",
      "C": "Increase the number of EC2 instances in each Availability Zone",
      "D": "Adjust the frequency of the health checks on the ALB's target group"
    },
    "correct_answer": "A",
    "vote_percentage": "89%",
    "question_cn": "一家公司正在构建一个新的家具库存应用程序。该公司已将该应用程序部署在一组 Amazon EC2 实例上，这些实例分布在多个可用区。 EC2 实例在其 VPC 中的 Application Load Balancer (ALB) 后面运行。 解决方案架构师观察到，传入的流量似乎偏向于一个 EC2 实例，导致某些请求的延迟。 解决方案架构师应该怎么做来解决这个问题？",
    "options_cn": {
      "A": "在 ALB 上禁用会话关联（粘性会话）",
      "B": "用 Network Load Balancer 替换 ALB",
      "C": "增加每个可用区中 EC2 实例的数量",
      "D": "调整 ALB 目标组上的健康检查频率"
    }
  },
  {
    "id": 640,
    "topic": "1",
    "question_en": "A company has an application workfiow that uses an AWS Lambda function to download and decrypt files from Amazon S3. These files are encrypted using AWS Key Management Service (AWS KMS) keys. A solutions architect needs to design a solution that will ensure the required permissions are set correctly. Which combination of actions accomplish this? (Choose two.)",
    "options_en": {
      "A": "Attach the kms:decrypt permission to the Lambda function’s resource policy",
      "B": "Grant the decrypt permission for the Lambda IAM role in the KMS key's policy",
      "C": "Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.",
      "D": "Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function",
      "E": "Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司有一个应用程序工作流程，使用 AWS Lambda 函数从 Amazon S3 下载和解密文件。 这些文件使用 AWS Key Management Service (AWS KMS) 密钥进行加密。 解决方案架构师需要设计一个解决方案，以确保正确设置所需的权限。 哪些操作组合可以完成此操作？（选择两个。）",
    "options_cn": {
      "A": "将 kms:decrypt 权限附加到 Lambda 函数的资源策略。",
      "B": "在 KMS 密钥的策略中，授予 Lambda IAM 角色解密权限。",
      "C": "在 KMS 密钥的策略中，授予 Lambda 资源策略解密权限。",
      "D": "创建一个新的 IAM 策略，其中包含 kms:decrypt 权限，并将该策略附加到 Lambda 函数。",
      "E": "创建一个新的 IAM 角色，其中包含 kms:decrypt 权限，并将执行角色附加到 Lambda 函数。"
    }
  },
  {
    "id": 641,
    "topic": "1",
    "question_en": "A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations management account to query AWS Cost and Usage Reports for all member accounts. The team must run this query once a month and provide a detailed analysis of the bill. Which solution is the MOST scalable and cost-effective way to meet these requirements?",
    "options_en": {
      "A": "Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.",
      "B": "Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3 Use Amazon Athena for analysis.",
      "C": "Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3 Use Amazon Redshift for analysis.",
      "D": "Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight tor analysis."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望监控其 AWS 成本以进行财务审查。云运营团队正在 AWS Organizations 管理账户中设计一个架构，以查询所有成员账户的 AWS 成本和使用情况报告。该团队必须每月运行一次此查询并提供账单的详细分析。哪种解决方案是满足这些要求的最具可扩展性和成本效益的方式？",
    "options_cn": {
      "A": "在管理账户中启用成本和使用情况报告。将报告发送到 Amazon Kinesis。使用 Amazon EMR 进行分析。",
      "B": "在管理账户中启用成本和使用情况报告。将报告发送到 Amazon S3。使用 Amazon Athena 进行分析。",
      "C": "为成员账户启用成本和使用情况报告。将报告发送到 Amazon S3。使用 Amazon Redshift 进行分析。",
      "D": "为成员账户启用成本和使用情况报告。将报告发送到 Amazon Kinesis。使用 Amazon QuickSight 进行分析。"
    }
  },
  {
    "id": 642,
    "topic": "1",
    "question_en": "A company wants to run a gaming application on Amazon EC2 instances that are part of an Auto Scaling group in the AWS Cloud. The application will transmit data by using UDP packets. The company wants to ensure that the application can scale out and in as trafic increases and decreases. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Attach a Network Load Balancer to the Auto Scaling group.",
      "B": "Attach an Application Load Balancer to the Auto Scaling group.",
      "C": "Deploy an Amazon Route 53 record set with a weighted policy to route trafic appropriately.",
      "D": "Deploy a NAT instance that is configured with port forwarding to the EC2 instances in the Auto Scaling group."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在 AWS 云中运行作为 Auto Scaling 组一部分的 Amazon EC2 实例上的游戏应用程序。该应用程序将使用 UDP 数据包传输数据。该公司希望确保应用程序可以随着流量的增加和减少而横向扩展和缩减。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将 Network Load Balancer 附加到 Auto Scaling 组。",
      "B": "将 Application Load Balancer 附加到 Auto Scaling 组。",
      "C": "部署一个具有加权策略的 Amazon Route 53 记录集，以适当地路由流量。",
      "D": "部署一个配置了端口转发的 NAT 实例，该实例连接到 Auto Scaling 组中的 EC2 实例。"
    }
  },
  {
    "id": 643,
    "topic": "1",
    "question_en": "A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web trafic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze trafic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store the logs in Amazon S3. Use Amazon Athena tor analysis.",
      "B": "Store the logs in Amazon RDS. Use a database client for analysis.",
      "C": "Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis.",
      "D": "Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL-based analysis."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司在其 AWS 上为其不同的品牌运营多个网站。每个网站每天生成数十 GB 的网络流量日志。一位解决方案架构师需要设计一个可扩展的解决方案，使公司的开发人员能够分析所有公司网站的流量模式。开发人员每周将按需进行此分析，持续数月。该解决方案必须支持使用标准 SQL 的查询。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "将日志存储在 Amazon S3 中。使用 Amazon Athena 进行分析。",
      "B": "将日志存储在 Amazon RDS 中。使用数据库客户端进行分析。",
      "C": "将日志存储在 Amazon OpenSearch Service 中。使用 OpenSearch Service 进行分析。",
      "D": "将日志存储在 Amazon EMR 集群中。使用支持的开源框架进行基于 SQL 的分析。"
    }
  },
  {
    "id": 644,
    "topic": "1",
    "question_en": "An international company has a subdomain for each country that the company operates in. The subdomains are formatted as example.com, country1.example.com, and country2.example.com. The company's workloads are behind an Application Load Balancer. The company wants to encrypt the website data that is in transit. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example com and a wildcard certificate for *.example.com.",
      "B": "Use the AWS Certificate Manager (ACM) console to request a private certificate for the apex top domain example.com and a wildcard certificate for *.example.com.",
      "C": "Use the AWS Certificate Manager (ACM) console to request a public and private certificate for the apex top domain example.com.",
      "D": "Validate domain ownership by email address. Switch to DNS validation by adding the required DNS records to the DNS provider. E. Validate domain ownership for the domain by adding the required DNS records to the DNS provider."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家跨国公司为该公司运营的每个国家/地区都有一个子域。子域的格式为 example.com、country1.example.com 和 country2.example.com。该公司的负载位于 Application Load Balancer 之后。该公司希望对正在传输的网站数据进行加密。哪两种步骤的组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Certificate Manager (ACM) 控制台为顶级域 example.com 请求一个公共证书，并为 *.example.com 请求一个通配符证书。",
      "B": "使用 AWS Certificate Manager (ACM) 控制台为顶级域 example.com 请求一个私有证书，并为 *.example.com 请求一个通配符证书。",
      "C": "使用 AWS Certificate Manager (ACM) 控制台为顶级域 example.com 请求一个公共和私有证书。",
      "D": "通过电子邮件地址验证域所有权。通过将所需的 DNS 记录添加到 DNS 提供商来切换到 DNS 验证。 E. 通过将所需的 DNS 记录添加到 DNS 提供商来验证该域的域所有权。"
    }
  },
  {
    "id": 645,
    "topic": "1",
    "question_en": "A company is required to use cryptographic keys in its on-premises key manager. The key manager is outside of the AWS Cloud because of regulatory and compliance requirements. The company wants to manage encryption and decryption by using cryptographic keys that are retained outside of the AWS Cloud and that support a variety of external key managers from different vendors. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS CloudHSM key store backed by a CloudHSM cluster.",
      "B": "Use an AWS Key Management Service (AWS KMS) external key store backed by an external key manager.",
      "C": "Use the default AWS Key Management Service (AWS KMS) managed key store.",
      "D": "Use a custom key store backed by an AWS CloudHSM cluster."
    },
    "correct_answer": "B",
    "vote_percentage": "93%",
    "question_cn": "一家公司需要在其本地密钥管理器中使用加密密钥。由于法规和合规性要求，该密钥管理器位于 AWS Cloud 之外。该公司希望通过使用保留在 AWS Cloud 之外的加密密钥来管理加密和解密，并且支持来自不同供应商的各种外部密钥管理器。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用由 CloudHSM 集群支持的 AWS CloudHSM 密钥存储。",
      "B": "使用由外部密钥管理器支持的 AWS Key Management Service (AWS KMS) 外部密钥存储。",
      "C": "使用默认的 AWS Key Management Service (AWS KMS) 托管密钥存储。",
      "D": "使用由 AWS CloudHSM 集群支持的自定义密钥存储。"
    }
  },
  {
    "id": 646,
    "topic": "1",
    "question_en": "A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud. The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously. The workload requires access latency within 1 ms. After processing has completed, engineers will need access to the dataset for manual postprocessing. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.",
      "B": "Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.",
      "C": "Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.",
      "D": "Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要在 AWS 云中托管高性能计算 (HPC) 工作负载。该工作负载将在数百个 Amazon EC2 实例上运行，并将需要并行访问共享文件系统，以实现大型数据集的分布式处理。将同时跨多个实例访问数据集。该工作负载需要 1 毫秒内的访问延迟。处理完成后，工程师将需要访问数据集以进行手动后期处理。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic File System (Amazon EFS) 作为共享文件系统。从 Amazon EFS 访问数据集。",
      "B": "挂载一个 Amazon S3 存储桶作为共享文件系统。直接从 S3 存储桶执行后期处理。",
      "C": "使用 Amazon FSx for Lustre 作为共享文件系统。将文件系统链接到 Amazon S3 存储桶以进行后期处理。",
      "D": "配置 AWS Resource Access Manager 以共享一个 Amazon S3 存储桶，以便可以将其挂载到所有实例上进行处理和后期处理。"
    }
  },
  {
    "id": 647,
    "topic": "1",
    "question_en": "A gaming company is building an application with Voice over IP capabilities. The application will serve trafic to users across the world. The application needs to be highly available with an automated failover across AWS Regions. The company wants to minimize the latency of users without relying on IP address caching on user devices. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use AWS Global Accelerator with health checks.",
      "B": "Use Amazon Route 53 with a geolocation routing policy.",
      "C": "Create an Amazon CloudFront distribution that includes multiple origins.",
      "D": "Create an Application Load Balancer that uses path-based routing."
    },
    "correct_answer": "A",
    "vote_percentage": "96%",
    "question_cn": "一家游戏公司正在构建一个具有语音 over IP 功能的应用程序。 该应用程序将为世界各地的用户提供服务。 该应用程序需要具有高可用性，并在 AWS 区域之间进行自动故障转移。 公司希望最大限度地减少用户的延迟，而无需依赖用户设备上的 IP 地址缓存。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Global Accelerator 以及运行状况检查。",
      "B": "使用 Amazon Route 53 和地理位置路由策略。",
      "C": "创建包含多个 源的 Amazon CloudFront 分发。",
      "D": "创建使用基于路径的路由的 Application Load Balancer。"
    }
  },
  {
    "id": 648,
    "topic": "1",
    "question_en": "A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities. A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Use Amazon FSx for Lustre scratch file systems.",
      "B": "Use Amazon FSx for Lustre persistent file systems.",
      "C": "Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode.",
      "D": "Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家天气预报公司需要以亚毫秒级的延迟处理数百 GB 的数据。该公司在其数据中心拥有一个高性能计算 (HPC) 环境，并希望扩展其预测能力。一位解决方案架构师必须确定一个高可用性的云存储解决方案，该解决方案能够处理大量持续的吞吐量。存储在该解决方案中的文件应可供数千个计算实例访问，这些实例将同时访问和处理整个数据集。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon FSx for Lustre 临时文件系统。",
      "B": "使用 Amazon FSx for Lustre 持久文件系统。",
      "C": "使用 Amazon Elastic File System (Amazon EFS)，采用突增吞吐量模式。",
      "D": "使用 Amazon Elastic File System (Amazon EFS)，采用预置吞吐量模式。"
    }
  },
  {
    "id": 649,
    "topic": "1",
    "question_en": "An ecommerce company runs a PostgreSQL database on premises. The database stores data by using high IOPS Amazon Elastic Block Store (Amazon EBS) block storage. The daily peak I/O transactions per second do not exceed 15,000 IOPS. The company wants to migrate the database to Amazon RDS for PostgreSQL and provision disk IOPS performance independent of disk storage capacity. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure the General Purpose SSD (gp2) EBS volume storage type and provision 15,000 IOPS.",
      "B": "Configure the Provisioned IOPS SSD (io1) EBS volume storage type and provision 15,000 IOPS.",
      "C": "Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS.",
      "D": "Configure the EBS magnetic volume type to achieve maximum IOPS."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司在本地运行 PostgreSQL 数据库。该数据库使用高 IOPS Amazon Elastic Block Store (Amazon EBS) 块存储来存储数据。每天的峰值每秒 I/O 事务数不超过 15,000 IOPS。该公司希望将数据库迁移到 Amazon RDS for PostgreSQL 并提供独立于磁盘存储容量的磁盘 IOPS 性能。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "配置通用 SSD (gp2) EBS 卷存储类型并配置 15,000 IOPS。",
      "B": "配置预置 IOPS SSD (io1) EBS 卷存储类型并配置 15,000 IOPS。",
      "C": "配置通用 SSD (gp3) EBS 卷存储类型并配置 15,000 IOPS。",
      "D": "配置 EBS 磁性卷类型以实现最大 IOPS。"
    }
  },
  {
    "id": 650,
    "topic": "1",
    "question_en": "A company wants to migrate its on-premises Microsoft SQL Server Enterprise edition database to AWS. The company's online application uses the database to process transactions. The data analysis team uses the same production database to run reports for analytical processing. The company wants to reduce operational overhead by moving to managed services wherever possible. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Migrate to Amazon RDS for Microsoft SOL Server. Use read replicas for reporting purposes",
      "B": "Migrate to Microsoft SQL Server on Amazon EC2. Use Always On read replicas for reporting purposes",
      "C": "Migrate to Amazon DynamoDB. Use DynamoDB on-demand replicas for reporting purposes",
      "D": "Migrate to Amazon Aurora MySQL. Use Aurora read replicas for reporting purposes"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将其本地 Microsoft SQL Server Enterprise 版本数据库迁移到 AWS。该公司的在线应用程序使用数据库来处理事务。数据分析团队使用相同的生产数据库运行报告以进行分析处理。该公司希望通过尽可能转移到托管服务来减少运营开销。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "迁移到 Amazon RDS for Microsoft SQL Server。 使用只读副本进行报告。",
      "B": "迁移到 Amazon EC2 上的 Microsoft SQL Server。 使用 Always On 只读副本进行报告。",
      "C": "迁移到 Amazon DynamoDB。 使用 DynamoDB 按需副本进行报告。",
      "D": "迁移到 Amazon Aurora MySQL。 使用 Aurora 只读副本进行报告。"
    }
  },
  {
    "id": 651,
    "topic": "1",
    "question_en": "A company stores a large volume of image files in an Amazon S3 bucket. The images need to be readily available for the first 180 days. The images are infrequently accessed for the next 180 days. After 360 days, the images need to be archived but must be available instantly upon request. After 5 years, only auditors can access the images. The auditors must be able to retrieve the images within 12 hours. The images cannot be lost during this process. A developer will use S3 Standard storage for the first 180 days. The developer needs to configure an S3 Lifecycle rule. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 180 days. S3 Glacier Instant Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.",
      "B": "Transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 180 days. S3 Glacier Flexible Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.",
      "C": "Transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 180 days, S3 Glacier Instant Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.",
      "D": "Transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 180 days, S3 Glacier Flexible Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years."
    },
    "correct_answer": "C",
    "vote_percentage": "82%",
    "question_cn": "一家公司将大量图像文件存储在 Amazon S3 存储桶中。这些图像需要在最初的 180 天内随时可用。在接下来的 180 天内，这些图像的访问频率较低。360 天后，这些图像需要被归档，但必须在请求时立即可用。5 年后，只有审计人员才能访问这些图像。审计人员必须能够在 12 小时内检索这些图像。在此过程中，图像不能丢失。开发人员将使用 S3 标准存储进行最初的 180 天的存储。开发人员需要配置一个 S3 生命周期规则。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "在 180 天后，将对象转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)。360 天后使用 S3 Glacier Instant Retrieval，5 年后使用 S3 Glacier Deep Archive。",
      "B": "在 180 天后，将对象转换为 S3 One Zone-Infrequent Access (S3 One Zone-IA)。360 天后使用 S3 Glacier Flexible Retrieval，5 年后使用 S3 Glacier Deep Archive。",
      "C": "在 180 天后，将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA)。360 天后使用 S3 Glacier Instant Retrieval，5 年后使用 S3 Glacier Deep Archive。",
      "D": "在 180 天后，将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA)。360 天后使用 S3 Glacier Flexible Retrieval，5 年后使用 S3 Glacier Deep Archive。"
    }
  },
  {
    "id": 652,
    "topic": "1",
    "question_en": "A company has a large data workload that runs for 6 hours each day. The company cannot lose any data while the process is running. A solutions architect is designing an Amazon EMR cluster configuration to support this critical data workload. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure a long-running cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.",
      "B": "Configure a transient cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.",
      "C": "Configure a transient cluster that runs the primary node on an On-Demand Instance and the core nodes and task nodes on Spot Instances.",
      "D": "Configure a long-running cluster that runs the primary node on an On-Demand Instance, the core nodes on Spot Instances, and the task nodes on Spot Instances."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个大型数据工作负载，每天运行 6 个小时。公司在流程运行时不能丢失任何数据。一位解决方案架构师正在设计 Amazon EMR 集群配置以支持这项关键数据工作负载。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置一个长期运行的集群，该集群在按需实例上运行主节点和核心节点，并在竞价实例上运行任务节点。",
      "B": "配置一个瞬态集群，该集群在按需实例上运行主节点和核心节点，并在竞价实例上运行任务节点。",
      "C": "配置一个瞬态集群，该集群在按需实例上运行主节点，并在竞价实例上运行核心节点和任务节点。",
      "D": "配置一个长期运行的集群，该集群在按需实例上运行主节点，在竞价实例上运行核心节点，并在竞价实例上运行任务节点。"
    }
  },
  {
    "id": 653,
    "topic": "1",
    "question_en": "A company maintains an Amazon RDS database that maps users to cost centers. The company has accounts in an organization in AWS Organizations. The company needs a solution that will tag all resources that are created in a specific AWS account in the organization. The solution must tag each resource with the cost center ID of the user who created the resource. Which solution will meet these requirements?",
    "options_en": {
      "A": "Move the specific AWS account to a new organizational unit (OU) in Organizations from the management account. Create a service control policy (SCP) that requires all existing resources to have the correct cost center tag before the resources are created. Apply the SCP to the new OU.",
      "B": "Create an AWS Lambda function to tag the resources after the Lambda function looks up the appropriate cost center from the RDS database. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function.",
      "C": "Create an AWS CloudFormation stack to deploy an AWS Lambda function. Configure the Lambda function to look up the appropriate cost center from the RDS database and to tag resources. Create an Amazon EventBridge scheduled rule to invoke the CloudFormation stack.",
      "D": "Create an AWS Lambda function to tag the resources with a default value. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function when a resource is missing the cost center tag."
    },
    "correct_answer": "B",
    "vote_percentage": "54%",
    "question_cn": "一家公司维护一个将用户映射到成本中心的 Amazon RDS 数据库。该公司在 AWS Organizations 中拥有组织内的账户。该公司需要一个解决方案来标记在该组织中特定 AWS 账户中创建的所有资源。该解决方案必须使用创建资源的用户的成本中心 ID 标记每个资源。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将特定 AWS 账户从管理账户移动到 Organizations 中的新组织单元 (OU)。创建一个服务控制策略 (SCP)，要求所有现有资源在创建资源之前具有正确的成本中心标签。将 SCP 应用于新的 OU。",
      "B": "创建一个 AWS Lambda 函数，以便在 Lambda 函数从 RDS 数据库中查找适当的成本中心后标记资源。配置一个 Amazon EventBridge 规则，该规则对 AWS CloudTrail 事件做出反应以调用 Lambda 函数。",
      "C": "创建一个 AWS CloudFormation 堆栈来部署一个 AWS Lambda 函数。将 Lambda 函数配置为从 RDS 数据库中查找适当的成本中心并标记资源。创建一个 Amazon EventBridge 定时规则来调用 CloudFormation 堆栈。",
      "D": "创建一个 AWS Lambda 函数，使用默认值标记资源。配置一个 Amazon EventBridge 规则，该规则对 AWS CloudTrail 事件做出反应，当资源缺少成本中心标签时调用 Lambda 函数。"
    }
  },
  {
    "id": 654,
    "topic": "1",
    "question_en": "A company recently migrated its web application to the AWS Cloud. The company uses an Amazon EC2 instance to run multiple processes to host the application. The processes include an Apache web server that serves static content. The Apache web server makes requests to a PHP application that uses a local Redis server for user sessions. The company wants to redesign the architecture to be highly available and to use AWS managed solutions. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Elastic Beanstalk to host the static content and the PHP application. Configure Elastic Beanstalk to deploy its EC2 instance into a public subnet. Assign a public IP address.",
      "B": "Use AWS Lambda to host the static content and the PHP application. Use an Amazon API Gateway REST API to proxy requests to the Lambda function. Set the API Gateway CORS configuration to respond to the domain name. Configure Amazon ElastiCache for Redis to handle session information.",
      "C": "Keep the backend code on the EC2 instance. Create an Amazon ElastiCache for Redis cluster that has Multi-AZ enabled. Configure the ElastiCache for Redis cluster in cluster mode. Copy the frontend resources to Amazon S3. Configure the backend code to reference the EC2 instance.",
      "D": "Configure an Amazon CloudFront distribution with an Amazon S3 endpoint to an S3 bucket that is configured to host the static content. Configure an Application Load Balancer that targets an Amazon Elastic Container Service (Amazon ECS) service that runs AWS Fargate tasks for the PHP application. Configure the PHP application to use an Amazon ElastiCache for Redis cluster that runs in multiple Availability Zones."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司最近将其 Web 应用程序迁移到了 AWS 云。该公司使用 Amazon EC2 实例运行多个进程来托管该应用程序。这些进程包括一个 Apache Web 服务器，用于提供静态内容。Apache Web 服务器向一个 PHP 应用程序发出请求，该应用程序使用本地 Redis 服务器进行用户会话。该公司希望重新设计架构，使其具有高可用性并使用 AWS 托管解决方案。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Elastic Beanstalk 托管静态内容和 PHP 应用程序。将 Elastic Beanstalk 配置为其 EC2 实例部署到公有子网。分配一个公有 IP 地址。",
      "B": "使用 AWS Lambda 托管静态内容和 PHP 应用程序。使用 Amazon API Gateway REST API 代理对 Lambda 函数的请求。将 API Gateway CORS 配置设置为响应域名。配置 Amazon ElastiCache for Redis 以处理会话信息。",
      "C": "将后端代码保留在 EC2 实例上。创建一个启用了 Multi-AZ 的 Amazon ElastiCache for Redis 集群。在集群模式下配置 ElastiCache for Redis 集群。将前端资源复制到 Amazon S3。配置后端代码以引用 EC2 实例。",
      "D": "使用指向配置为托管静态内容的 S3 存储桶的 Amazon S3 端点的 Amazon CloudFront 分发。配置一个 Application Load Balancer，该负载均衡器将目标指向一个 Amazon Elastic Container Service (Amazon ECS) 服务，该服务为 PHP 应用程序运行 AWS Fargate 任务。配置 PHP 应用程序以使用在多个可用区中运行的 Amazon ElastiCache for Redis 集群。"
    }
  },
  {
    "id": 655,
    "topic": "1",
    "question_en": "A company runs a web application on Amazon EC2 instances in an Auto Scaling group that has a target group. The company designed the application to work with session afinity (sticky sessions) for a better user experience. The application must be available publicly over the internet as an endpoint. A WAF must be applied to the endpoint for additional security. Session afinity (sticky sessions) must be configured on the endpoint. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create a public Network Load Balancer. Specify the application target group.",
      "B": "Create a Gateway Load Balancer. Specify the application target group.",
      "C": "Create a public Application Load Balancer. Specify the application target group.",
      "D": "Create a second target group. Add Elastic IP addresses to the EC2 instances",
      "E": "Create a web ACL in AWS WAF. Associate the web ACL with the endpoint"
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在具有目标组的 Auto Scaling 组中运行 Amazon EC2 实例上的 Web 应用程序。该公司设计了该应用程序，使其可以使用会话关联（粘性会话）以获得更好的用户体验。该应用程序必须通过互联网公开可用作端点。必须将 WAF 应用于端点以获得额外的安全性。必须在端点上配置会话关联（粘性会话）。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建公共 Network Load Balancer。指定应用程序目标组。",
      "B": "创建 Gateway Load Balancer。指定应用程序目标组。",
      "C": "创建公共 Application Load Balancer。指定应用程序目标组。",
      "D": "创建第二个目标组。将弹性 IP 地址添加到 EC2 实例。",
      "E": "在 AWS WAF 中创建 Web ACL。将 Web ACL 与端点关联"
    }
  },
  {
    "id": 656,
    "topic": "1",
    "question_en": "A company runs a website that stores images of historical events. Website users need the ability to search and view images based on the year that the event in the image occurred. On average, users request each image only once or twice a year. The company wants a highly available solution to store and deliver the images to users. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Store images in Amazon Elastic Block Store (Amazon EBS). Use a web server that runs on Amazon EC2.",
      "B": "Store images in Amazon Elastic File System (Amazon EFS). Use a web server that runs on Amazon EC2.",
      "C": "Store images in Amazon S3 Standard. Use S3 Standard to directly deliver images by using a static website.",
      "D": "Store images in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Use S3 Standard-IA to directly deliver images by using a static website."
    },
    "correct_answer": "C",
    "vote_percentage": "90%",
    "question_cn": "一家公司运营一个网站，存储历史事件的图像。网站用户需要能够根据图像中事件发生的年份来搜索和查看图像。平均而言，用户每年仅请求每张图像一两次。该公司希望使用一个高可用性的解决方案来存储和向用户提供图像。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将图像存储在 Amazon Elastic Block Store (Amazon EBS) 中。使用在 Amazon EC2 上运行的 Web 服务器。",
      "B": "将图像存储在 Amazon Elastic File System (Amazon EFS) 中。使用在 Amazon EC2 上运行的 Web 服务器。",
      "C": "将图像存储在 Amazon S3 Standard 中。 使用 S3 Standard 通过静态网站直接提供图像。",
      "D": "将图像存储在 Amazon S3 Standard-Infrequent Access (S3 Standard-IA) 中。使用 S3 Standard-IA 通过静态网站直接提供图像。"
    }
  },
  {
    "id": 657,
    "topic": "1",
    "question_en": "A company has multiple AWS accounts in an organization in AWS Organizations that different business units use. The company has multiple ofices around the world. The company needs to update security group rules to allow new ofice CIDR ranges or to remove old CIDR ranges across the organization. The company wants to centralize the management of security group rules to minimize the administrative overhead that updating CIDR ranges requires. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create VPC security groups in the organization's management account. Update the security groups when a CIDR range update is necessary.",
      "B": "Create a VPC customer managed prefix list that contains the list of CIDRs. Use AWS Resource Access Manager (AWS RAM) to share the prefix list across the organization. Use the prefix list in the security groups across the organization.",
      "C": "Create an AWS managed prefix list. Use an AWS Security Hub policy to enforce the security group update across the organization. Use an AWS Lambda function to update the prefix list automatically when the CIDR ranges change.",
      "D": "Create security groups in a central administrative AWS account. Create an AWS Firewall Manager common security group policy for the whole organization. Select the previously created security groups as primary groups in the policy."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS Organizations 中拥有多个 AWS 账户，不同的业务部门使用这些账户。该公司在全球范围内设有多个办事处。该公司需要更新安全组规则以允许新的办事处 CIDR 范围或删除整个组织中的旧 CIDR 范围。该公司希望集中管理安全组规则，以最大限度地减少更新 CIDR 范围所需的管理开销。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在组织的管理账户中创建 VPC 安全组。在需要更新 CIDR 范围时更新安全组。",
      "B": "创建一个包含 CIDR 列表的 VPC 客户托管前缀列表。使用 AWS Resource Access Manager (AWS RAM) 在整个组织中共享前缀列表。在整个组织的安全组中使用前缀列表。",
      "C": "创建一个 AWS 托管前缀列表。使用 AWS Security Hub 策略来强制整个组织的安全组更新。使用 AWS Lambda 函数在 CIDR 范围更改时自动更新前缀列表。",
      "D": "在中央管理 AWS 账户中创建安全组。为整个组织创建一个 AWS Firewall Manager 公共安全组策略。选择先前创建的安全组作为策略中的主要组。"
    }
  },
  {
    "id": 658,
    "topic": "1",
    "question_en": "A company uses an on-premises network-attached storage (NAS) system to provide file shares to its high performance computing (HPC) workloads. The company wants to migrate its latency-sensitive HPC workloads and its storage to the AWS Cloud. The company must be able to provide NFS and SMB multi-protocol access from the file system. Which solution will meet these requirements with the LEAST latency? (Choose two.)",
    "options_en": {
      "A": "Deploy compute optimized EC2 instances into a cluster placement group.",
      "B": "Deploy compute optimized EC2 instances into a partition placement group.",
      "C": "Attach the EC2 instances to an Amazon FSx for Lustre file system.",
      "D": "Attach the EC2 instances to an Amazon FSx for OpenZFS file system",
      "E": "Attach the EC2 instances to an Amazon FSx for NetApp ONTAP file system."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司使用本地网络附加存储 (NAS) 系统为其高性能计算 (HPC) 工作负载提供文件共享。该公司希望将其对延迟敏感的 HPC 工作负载及其存储迁移到 AWS 云。该公司必须能够从文件系统提供 NFS 和 SMB 多协议访问。哪种解决方案将以最低的延迟满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "将计算优化 EC2 实例部署到集群放置组中。",
      "B": "将计算优化 EC2 实例部署到分区放置组中。",
      "C": "将 EC2 实例连接到 Amazon FSx for Lustre 文件系统。",
      "D": "将 EC2 实例连接到 Amazon FSx for OpenZFS 文件系统。",
      "E": "将 EC2 实例连接到 Amazon FSx for NetApp ONTAP 文件系统。"
    }
  },
  {
    "id": 659,
    "topic": "1",
    "question_en": "A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks. The existing data center has a Site-to-Site VPN connection to AWS that is 90% utilized. Which AWS service should a solutions architect use to meet these requirements?",
    "options_en": {
      "A": "AWS DataSync with a VPC endpoint",
      "B": "AWS Direct Connect",
      "C": "AWS Snowball Edge Storage Optimized",
      "D": "AWS Storage Gateway"
    },
    "correct_answer": "C",
    "vote_percentage": "93%",
    "question_cn": "一家公司正在搬迁其数据中心，并希望在两周内安全地将 50 TB 的数据传输到 AWS。现有数据中心与 AWS 之间有一个站点到站点 VPN 连接，该连接已使用 90%。解决方案架构师应使用哪种 AWS 服务来满足这些要求？",
    "options_cn": {
      "A": "带有 VPC endpoint 的 AWS DataSync",
      "B": "AWS Direct Connect",
      "C": "AWS Snowball Edge 存储优化设备",
      "D": "AWS Storage Gateway"
    }
  },
  {
    "id": 660,
    "topic": "1",
    "question_en": "A company hosts an application on Amazon EC2 On-Demand Instances in an Auto Scaling group. Application peak hours occur at the same time each day. Application users report slow application performance at the start of peak hours. The application performs normally 2-3 hours after peak hours begin. The company wants to ensure that the application works properly at the start of peak hours. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an Application Load Balancer to distribute trafic properly to the instances.",
      "B": "Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on memory utilization.",
      "C": "Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on CPU utilization.",
      "D": "Configure a scheduled scaling policy for the Auto Scaling group to launch new instances before peak hours."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Auto Scaling 组中的 Amazon EC2 按需实例上托管一个应用程序。应用程序高峰时段每天在同一时间发生。应用程序用户报告说在高峰时段开始时应用程序性能缓慢。在高峰时段开始后的 2-3 小时内，应用程序运行正常。该公司希望确保应用程序在高峰时段开始时正常工作。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Application Load Balancer 以将流量正确分配给实例。",
      "B": "为 Auto Scaling 组配置动态伸缩策略，以根据内存利用率启动新实例。",
      "C": "为 Auto Scaling 组配置动态伸缩策略，以根据 CPU 利用率启动新实例。",
      "D": "为 Auto Scaling 组配置一个定时伸缩策略，在高峰时段之前启动新实例。"
    }
  },
  {
    "id": 661,
    "topic": "1",
    "question_en": "A company runs applications on AWS that connect to the company's Amazon RDS database. The applications scale on weekends and at peak times of the year. The company wants to scale the database more effectively for its applications that connect to the database. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon DynamoDB with connection pooling with a target group configuration for the database. Change the applications to use the DynamoDB endpoint.",
      "B": "Use Amazon RDS Proxy with a target group for the database. Change the applications to use the RDS Proxy endpoint.",
      "C": "Use a custom proxy that runs on Amazon EC2 as an intermediary to the database. Change the applications to use the custom proxy endpoint.",
      "D": "Use an AWS Lambda function to provide connection pooling with a target group configuration for the database. Change the applications to use the Lambda function."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行连接到公司 Amazon RDS 数据库的应用程序。这些应用程序在周末和一年中的高峰时段进行扩展。该公司希望更有效地扩展连接到数据库的应用程序的数据库。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon DynamoDB 配合连接池以及数据库的目标组配置。更改应用程序以使用 DynamoDB 端点。",
      "B": "使用 Amazon RDS Proxy 配合数据库的目标组。更改应用程序以使用 RDS Proxy 端点。",
      "C": "使用在 Amazon EC2 上运行的自定义代理作为数据库的中介。更改应用程序以使用自定义代理端点。",
      "D": "使用 AWS Lambda 函数来提供连接池以及数据库的目标组配置。更改应用程序以使用 Lambda 函数。"
    }
  },
  {
    "id": 662,
    "topic": "1",
    "question_en": "A company uses AWS Cost Explorer to monitor its AWS costs. The company notices that Amazon Elastic Block Store (Amazon EBS) storage and snapshot costs increase every month. However, the company does not purchase additional EBS storage every month. The company wants to optimize monthly costs for its current storage usage. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use logs in Amazon CloudWatch Logs to monitor the storage utilization of Amazon EBS. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.",
      "B": "Use a custom script to monitor space usage. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.",
      "C": "Delete all expired and unused snapshots to reduce snapshot costs.",
      "D": "Delete all nonessential snapshots. Use Amazon Data Lifecycle Manager to create and manage the snapshots according to the company's snapshot policy requirements."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS Cost Explorer 来监控其 AWS 成本。该公司注意到 Amazon Elastic Block Store (Amazon EBS) 存储和快照成本每个月都在增加。然而，该公司每个月并未购买额外的 EBS 存储。该公司希望优化其当前存储使用的每月成本。哪个解决方案将以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch Logs 中的日志来监控 Amazon EBS 的存储利用率。使用 Amazon EBS 弹性卷来减小 EBS 卷的大小。",
      "B": "使用自定义脚本来监控空间使用情况。使用 Amazon EBS 弹性卷来减小 EBS 卷的大小。",
      "C": "删除所有已过期和未使用的快照以降低快照成本。",
      "D": "删除所有非必要的快照。使用 Amazon Data Lifecycle Manager 根据公司的快照策略要求创建和管理快照。"
    }
  },
  {
    "id": 663,
    "topic": "1",
    "question_en": "A company is developing a new application on AWS. The application consists of an Amazon Elastic Container Service (Amazon ECS) cluster, an Amazon S3 bucket that contains assets for the application, and an Amazon RDS for MySQL database that contains the dataset for the application. The dataset contains sensitive information. The company wants to ensure that only the ECS cluster can access the data in the RDS for MySQL database and the data in the S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a new AWS Key Management Service (AWS KMS) customer managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the KMS key policy includes encrypt and decrypt permissions for the ECS task execution role.",
      "B": "Create an AWS Key Management Service (AWS KMS) AWS managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the S3 bucket policy specifies the ECS task execution role as a user.",
      "C": "Create an S3 bucket policy that restricts bucket access to the ECS task execution role. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in.",
      "D": "Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in. Create a VPC endpoint for Amazon S3. Update the S3 bucket policy to allow access from only the S3 VPC endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "61%",
    "question_cn": "一家公司正在 AWS 上开发一个新应用程序。该应用程序包含一个 Amazon Elastic Container Service (Amazon ECS) 集群、一个包含应用程序资产的 Amazon S3 存储桶以及一个包含应用程序数据集的 Amazon RDS for MySQL 数据库。数据集包含敏感信息。该公司希望确保只有 ECS 集群可以访问 RDS for MySQL 数据库中的数据和 S3 存储桶中的数据。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 AWS Key Management Service (AWS KMS) 客户托管密钥，以加密 S3 存储桶和 RDS for MySQL 数据库。确保 KMS 密钥策略包含 ECS 任务执行角色的加密和解密权限。",
      "B": "创建一个 AWS Key Management Service (AWS KMS) AWS 托管密钥，以加密 S3 存储桶和 RDS for MySQL 数据库。确保 S3 存储桶策略将 ECS 任务执行角色指定为用户。",
      "C": "创建 S3 存储桶策略，将存储桶访问限制为 ECS 任务执行角色。为 Amazon RDS for MySQL 创建一个 VPC endpoint。更新 RDS for MySQL 安全组，仅允许来自 ECS 集群将在其中生成任务的子网的访问。",
      "D": "为 Amazon RDS for MySQL 创建一个 VPC endpoint。更新 RDS for MySQL 安全组，仅允许来自 ECS 集群将在其中生成任务的子网的访问。为 Amazon S3 创建一个 VPC endpoint。更新 S3 存储桶策略，仅允许来自 S3 VPC endpoint 的访问。"
    }
  },
  {
    "id": 664,
    "topic": "1",
    "question_en": "A company has a web application that runs on premises. The application experiences latency issues during peak hours. The latency issues occur twice each month. At the start of a latency issue, the application's CPU utilization immediately increases to 10 times its normal amount. The company wants to migrate the application to AWS to improve latency. The company also wants to scale the application automatically when application demand increases. The company will use AWS Elastic Beanstalk for application deployment. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale based on requests.",
      "B": "Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale based on requests.",
      "C": "Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale on a schedule.",
      "D": "Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale on predictive metrics."
    },
    "correct_answer": "B",
    "vote_percentage": "56%",
    "question_cn": "一家公司有一个在本地运行的 Web 应用程序。该应用程序在高峰时段遇到延迟问题。 延迟问题每月发生两次。 在延迟问题开始时，应用程序的 CPU 利用率立即增加到其正常数量的 10 倍。 公司希望将应用程序迁移到 AWS 以改善延迟。 公司还希望在应用程序需求增加时自动扩展应用程序。 公司将使用 AWS Elastic Beanstalk 进行应用程序部署。 哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Elastic Beanstalk 环境以使用无限模式的可突发性能实例。配置环境以根据请求进行扩展。",
      "B": "配置 Elastic Beanstalk 环境以使用计算优化实例。配置环境以根据请求进行扩展。",
      "C": "配置 Elastic Beanstalk 环境以使用计算优化实例。配置环境以按计划进行扩展。",
      "D": "配置 Elastic Beanstalk 环境以使用无限模式的可突发性能实例。配置环境以根据预测指标进行扩展。"
    }
  },
  {
    "id": 665,
    "topic": "1",
    "question_en": "A company has customers located across the world. The company wants to use automation to secure its systems and network infrastructure. The company's security team must be able to track and audit all incremental changes to the infrastructure. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Organizations to set up the infrastructure. Use AWS Config to track changes.",
      "B": "Use AWS CloudFormation to set up the infrastructure. Use AWS Config to track changes.",
      "C": "Use AWS Organizations to set up the infrastructure. Use AWS Service Catalog to track changes.",
      "D": "Use AWS CloudFormation to set up the infrastructure. Use AWS Service Catalog to track changes."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在全球各地都有客户。该公司希望使用自动化来保护其系统和网络基础设施。该公司的安全团队必须能够跟踪和审计对基础设施的所有增量更改。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Organizations 设置基础设施。使用 AWS Config 跟踪更改。",
      "B": "使用 AWS CloudFormation 设置基础设施。使用 AWS Config 跟踪更改。",
      "C": "使用 AWS Organizations 设置基础设施。使用 AWS Service Catalog 跟踪更改。",
      "D": "使用 AWS CloudFormation 设置基础设施。使用 AWS Service Catalog 跟踪更改。"
    }
  },
  {
    "id": 666,
    "topic": "1",
    "question_en": "A startup company is hosting a website for its customers on an Amazon EC2 instance. The website consists of a stateless Python application and a MySQL database. The website serves only a small amount of trafic. The company is concerned about the reliability of the instance and needs to migrate to a highly available architecture. The company cannot modify the application code. Which combination of actions should a solutions architect take to achieve high availability for the website? (Choose two.)",
    "options_en": {
      "A": "Provision an internet gateway in each Availability Zone in use.",
      "B": "Migrate the database to an Amazon RDS for MySQL Multi-AZ DB instance.",
      "C": "Migrate the database to Amazon DynamoDB, and enable DynamoDB auto scaling.",
      "D": "Use AWS DataSync to synchronize the database data across multiple EC2 instances",
      "E": "Create an Application Load Balancer to distribute trafic to an Auto Scaling group of EC2 instances that are distributed across two Availability Zones."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家初创公司正在 Amazon EC2 实例上为其客户托管一个网站。该网站由一个无状态的 Python 应用程序和一个 MySQL 数据库组成。该网站仅提供少量流量。该公司担心实例的可靠性，需要迁移到一个高可用性架构。该公司无法修改应用程序代码。解决方案架构师应采取哪些组合操作来实现网站的高可用性？（选择两个。）",
    "options_cn": {
      "A": "在使用的每个可用区中配置一个互联网网关。",
      "B": "将数据库迁移到 Amazon RDS for MySQL 多可用区数据库实例。",
      "C": "将数据库迁移到 Amazon DynamoDB，并启用 DynamoDB 自动伸缩。",
      "D": "使用 AWS DataSync 将数据库数据同步到多个 EC2 实例。",
      "E": "创建一个 Application Load Balancer，将流量分配给分布在两个可用区中的 EC2 实例的 Auto Scaling 组。"
    }
  },
  {
    "id": 667,
    "topic": "1",
    "question_en": "A company is moving its data and applications to AWS during a multiyear migration project. The company wants to securely access data on Amazon S3 from the company's AWS Region and from the company's on-premises location. The data must not traverse the internet. The company has established an AWS Direct Connect connection between its Region and its on-premises location. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create gateway endpoints for Amazon S3. Use the gateway endpoints to securely access the data from the Region and the on-premises location.",
      "B": "Create a gateway in AWS Transit Gateway to access Amazon S3 securely from the Region and the on-premises location.",
      "C": "Create interface endpoints for Amazon S3. Use the interface endpoints to securely access the data from the Region and the on- premises location.",
      "D": "Use an AWS Key Management Service (AWS KMS) key to access the data securely from the Region and the on-premises location."
    },
    "correct_answer": "A",
    "vote_percentage": "82%",
    "question_cn": "一家公司正在进行一项多年迁移项目，将其数据和应用程序迁移到 AWS。该公司希望安全地从公司的 AWS 区域和公司的本地位置访问 Amazon S3 上的数据。数据不得遍历互联网。该公司已在其区域和本地位置之间建立了 AWS Direct Connect 连接。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Amazon S3 创建网关端点。使用网关端点从该区域和本地位置安全地访问数据。",
      "B": "在 AWS Transit Gateway 中创建一个网关，以便从该区域和本地位置安全地访问 Amazon S3。",
      "C": "为 Amazon S3 创建接口端点。使用接口端点从该区域和本地位置安全地访问数据。",
      "D": "使用 AWS Key Management Service (AWS KMS) 密钥从该区域和本地位置安全地访问数据。"
    }
  },
  {
    "id": 668,
    "topic": "1",
    "question_en": "A company created a new organization in AWS Organizations. The organization has multiple accounts for the company's development teams. The development team members use AWS IAM Identity Center (AWS Single Sign-On) to access the accounts. For each of the company's applications, the development teams must use a predefined application name to tag resources that are created. A solutions architect needs to design a solution that gives the development team the ability to create resources only if the application name tag has an approved value. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an IAM group that has a conditional Allow policy that requires the application name tag to be specified for resources to be created.",
      "B": "Create a cross-account role that has a Deny policy for any resource that has the application name tag.",
      "C": "Create a resource group in AWS Resource Groups to validate that the tags are applied to all resources in all accounts.",
      "D": "Create a tag policy in Organizations that has a list of allowed application names."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS Organizations 中创建了一个新组织。该组织拥有用于该公司开发团队的多个账户。开发团队成员使用 AWS IAM Identity Center (AWS Single Sign-On) 访问账户。对于该公司的每个应用程序，开发团队必须使用预定义的应用程序名称来标记创建的资源。解决方案架构师需要设计一个解决方案，该解决方案使开发团队能够仅在应用程序名称标签具有批准值时才能创建资源。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 IAM 组，该组具有条件允许策略，该策略要求必须为要创建的资源指定应用程序名称标签。",
      "B": "创建一个跨账户角色，该角色具有拒绝应用程序名称标签的任何资源的策略。",
      "C": "在 AWS 资源组中创建资源组，以验证标签是否应用于所有账户中的所有资源。",
      "D": "在 Organizations 中创建标签策略，其中包含允许的应用程序名称的列表。"
    }
  },
  {
    "id": 669,
    "topic": "1",
    "question_en": "A company runs its databases on Amazon RDS for PostgreSQL. The company wants a secure solution to manage the master user password by rotating the password every 30 days. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon EventBridge to schedule a custom AWS Lambda function to rotate the password every 30 days.",
      "B": "Use the modify-db-instance command in the AWS CLI to change the password.",
      "C": "Integrate AWS Secrets Manager with Amazon RDS for PostgreSQL to automate password rotation.",
      "D": "Integrate AWS Systems Manager Parameter Store with Amazon RDS for PostgreSQL to automate password rotation."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Amazon RDS for PostgreSQL 上运行数据库。该公司希望通过每 30 天轮换一次密码来管理主用户密码的安全解决方案。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EventBridge 安排自定义 AWS Lambda 函数，每 30 天轮换一次密码。",
      "B": "使用 AWS CLI 中的 modify-db-instance 命令更改密码。",
      "C": "将 AWS Secrets Manager 与 Amazon RDS for PostgreSQL 集成，以自动轮换密码。",
      "D": "将 AWS Systems Manager Parameter Store 与 Amazon RDS for PostgreSQL 集成，以自动轮换密码。"
    }
  },
  {
    "id": 670,
    "topic": "1",
    "question_en": "A company performs tests on an application that uses an Amazon DynamoDB table. The tests run for 4 hours once a week. The company knows how many read and write operations the application performs to the table each second during the tests. The company does not currently use DynamoDB for any other use case. A solutions architect needs to optimize the costs for the table. Which solution will meet these requirements?",
    "options_en": {
      "A": "Choose on-demand mode. Update the read and write capacity units appropriately.",
      "B": "Choose provisioned mode. Update the read and write capacity units appropriately.",
      "C": "Purchase DynamoDB reserved capacity for a 1-year term.",
      "D": "Purchase DynamoDB reserved capacity for a 3-year term."
    },
    "correct_answer": "A",
    "vote_percentage": "75%",
    "question_cn": "一家公司对其使用 Amazon DynamoDB 表的应用程序进行测试。测试每周运行一次，持续 4 小时。该公司知道应用程序在测试期间每秒对表执行的读写操作数量。该公司目前没有将 DynamoDB 用于任何其他用例。解决方案架构师需要优化表的成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "选择按需模式。适当地更新读取和写入容量单位。",
      "B": "选择预置模式。适当地更新读取和写入容量单位。",
      "C": "购买 DynamoDB 预留容量，为期 1 年。",
      "D": "购买 DynamoDB 预留容量，为期 3 年。"
    }
  },
  {
    "id": 671,
    "topic": "1",
    "question_en": "A company runs its applications on Amazon EC2 instances. The company performs periodic financial assessments of its AWS costs. The company recently identified unusual spending. The company needs a solution to prevent unusual spending. The solution must monitor costs and notify responsible stakeholders in the event of unusual spending. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an AWS Budgets template to create a zero spend budget.",
      "B": "Create an AWS Cost Anomaly Detection monitor in the AWS Billing and Cost Management console.",
      "C": "Create AWS Pricing Calculator estimates for the current running workload pricing details.",
      "D": "Use Amazon CloudWatch to monitor costs and to identify unusual spending."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Amazon EC2 实例上运行其应用程序。该公司定期进行其 AWS 成本的财务评估。该公司最近发现了异常支出。该公司需要一个解决方案来防止异常支出。该解决方案必须监控成本，并在发生异常支出时通知相关利益相关者。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Budgets 模板创建一个零支出预算。",
      "B": "在 AWS Billing and Cost Management 控制台中创建 AWS Cost Anomaly Detection 监控。",
      "C": "为当前运行的工作负载定价详细信息创建 AWS 定价计算器估算。",
      "D": "使用 Amazon CloudWatch 监控成本并识别异常支出。"
    }
  },
  {
    "id": 672,
    "topic": "1",
    "question_en": "A marketing company receives a large amount of new clickstream data in Amazon S3 from a marketing campaign. The company needs to analyze the clickstream data in Amazon S3 quickly. Then the company needs to determine whether to process the data further in the data pipeline. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data.",
      "B": "Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data.",
      "C": "Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data.",
      "D": "Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data."
    },
    "correct_answer": "D",
    "vote_percentage": "92%",
    "question_cn": "一家营销公司从营销活动中在 Amazon S3 中接收大量新的点击流数据。该公司需要快速分析 Amazon S3 中的点击流数据，然后确定是否需要在数据管道中进一步处理数据。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 Spark 目录中创建外部表。配置 AWS Glue 中的作业以查询数据。",
      "B": "配置 AWS Glue 爬虫程序以爬取数据。配置 Amazon Athena 以查询数据。",
      "C": "在 Hive 元存储中创建外部表。配置 Amazon EMR 中的 Spark 作业以查询数据。",
      "D": "配置 AWS Glue 爬虫程序以爬取数据。配置 Amazon Kinesis Data Analytics 使用 SQL 查询数据。"
    }
  },
  {
    "id": 673,
    "topic": "1",
    "question_en": "A company runs an SMB file server in its data center. The file server stores large files that the company frequently accesses for up to 7 days after the file creation date. After 7 days, the company needs to be able to access the files with a maximum retrieval time of 24 hours. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.",
      "B": "Create an Amazon S3 File Gateway to increase the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.",
      "C": "Create an Amazon FSx File Gateway to increase the company's storage space. Create an Amazon S3 Lifecycle policy to transition the data after 7 days.",
      "D": "Configure access to Amazon S3 for each user. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days."
    },
    "correct_answer": "D",
    "vote_percentage": "82%",
    "question_cn": "一家公司在其数据中心运行一个 SMB 文件服务器。该文件服务器存储大型文件，公司在文件创建日期后的 7 天内频繁访问这些文件。7 天后，公司需要能够访问这些文件，最大检索时间为 24 小时。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS DataSync 将超过 7 天的数据从 SMB 文件服务器复制到 AWS。",
      "B": "创建一个 Amazon S3 File Gateway 以增加公司的存储空间。创建一个 S3 生命周期策略，在 7 天后将数据转移到 S3 Glacier Deep Archive。",
      "C": "创建一个 Amazon FSx File Gateway 以增加公司的存储空间。创建一个 Amazon S3 生命周期策略，在 7 天后转移数据。",
      "D": "为每个用户配置对 Amazon S3 的访问权限。创建一个 S3 生命周期策略，在 7 天后将数据转移到 S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 674,
    "topic": "1",
    "question_en": "A company runs a web application on Amazon EC2 instances in an Auto Scaling group. The application uses a database that runs on an Amazon RDS for PostgreSQL DB instance. The application performs slowly when trafic increases. The database experiences a heavy read load during periods of high trafic. Which actions should a solutions architect take to resolve these performance issues? (Choose two.)",
    "options_en": {
      "A": "Turn on auto scaling for the DB instance.",
      "B": "Create a read replica for the DB instance. Configure the application to send read trafic to the read replica.",
      "C": "Convert the DB instance to a Multi-AZ DB instance deployment. Configure the application to send read trafic to the standby DB instance.",
      "D": "Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster",
      "E": "Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance."
    },
    "correct_answer": "A",
    "vote_percentage": "86%",
    "question_cn": "一家公司在 Auto Scaling 组中的 Amazon EC2 实例上运行一个 Web 应用程序。该应用程序使用在 Amazon RDS for PostgreSQL 数据库实例上运行的数据库。当流量增加时，应用程序运行缓慢。在高峰时，数据库会经历繁重的读取负载。解决方案架构师应采取哪些措施来解决这些性能问题？（选择两个。）",
    "options_cn": {
      "A": "为数据库实例打开自动伸缩。",
      "B": "为数据库实例创建一个只读副本。配置应用程序将读取流量发送到只读副本。",
      "C": "将数据库实例转换为多可用区数据库实例部署。配置应用程序将读取流量发送到备用数据库实例。",
      "D": "创建一个 Amazon ElastiCache 集群。配置应用程序将查询结果缓存在 ElastiCache 集群中。",
      "E": "配置 Auto Scaling 组子网，以确保在与数据库实例相同的可用区中预置 EC2 实例。"
    }
  },
  {
    "id": 675,
    "topic": "1",
    "question_en": "A company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) volumes to run an application. The company creates one snapshot of each EBS volume every day to meet compliance requirements. The company wants to implement an architecture that prevents the accidental deletion of EBS volume snapshots. The solution must not change the administrative rights of the storage administrator user. Which solution will meet these requirements with the LEAST administrative effort?",
    "options_en": {
      "A": "Create an IAM role that has permission to delete snapshots. Attach the role to a new EC2 instance. Use the AWS CLI from the new EC2 instance to delete snapshots.",
      "B": "Create an IAM policy that denies snapshot deletion. Attach the policy to the storage administrator user.",
      "C": "Add tags to the snapshots. Create retention rules in Recycle Bin for EBS snapshots that have the tags.",
      "D": "Lock the EBS snapshots to prevent deletion."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon EC2 实例和 Amazon Elastic Block Store (Amazon EBS) 卷来运行一个应用程序。该公司每天都会拍摄每个 EBS 卷的快照，以满足合规性要求。该公司希望实施一种架构，以防止意外删除 EBS 卷快照。该解决方案不得更改存储管理员用户的管理权限。哪种解决方案将以最小的管理工作量满足这些要求？",
    "options_cn": {
      "A": "创建一个具有删除快照权限的 IAM 角色。将该角色附加到新的 EC2 实例。从新的 EC2 实例中使用 AWS CLI 删除快照。",
      "B": "创建一个拒绝删除快照的 IAM 策略。将该策略附加到存储管理员用户。",
      "C": "为快照添加标签。在回收站中为具有这些标签的 EBS 快照创建保留规则。",
      "D": "锁定 EBS 快照以防止删除。"
    }
  },
  {
    "id": 676,
    "topic": "1",
    "question_en": "A company's application uses Network Load Balancers, Auto Scaling groups, Amazon EC2 instances, and databases that are deployed in an Amazon VPC. The company wants to capture information about trafic to and from the network interfaces in near real time in its Amazon VPC. The company wants to send the information to Amazon OpenSearch Service for analysis. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Streams to stream the logs from the log group to OpenSearch Service.",
      "B": "Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Firehose to stream the logs from the log group to OpenSearch Service.",
      "C": "Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Streams to stream the logs from the trail to OpenSearch Service.",
      "D": "Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Firehose to stream the logs from the trail to OpenSearch Service."
    },
    "correct_answer": "B",
    "vote_percentage": "92%",
    "question_cn": "一家公司的应用程序使用 Network Load Balancer、Auto Scaling 组、Amazon EC2 实例以及部署在 Amazon VPC 中的数据库。该公司希望在其 Amazon VPC 中近乎实时地捕获有关进出网络接口的流量信息。该公司希望将这些信息发送到 Amazon OpenSearch Service 进行分析。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 Amazon CloudWatch Logs 中创建一个日志组。配置 VPC Flow Logs 将日志数据发送到该日志组。使用 Amazon Kinesis Data Streams 将日志从该日志组流式传输到 OpenSearch Service。",
      "B": "在 Amazon CloudWatch Logs 中创建一个日志组。配置 VPC Flow Logs 将日志数据发送到该日志组。使用 Amazon Kinesis Data Firehose 将日志从该日志组流式传输到 OpenSearch Service。",
      "C": "在 AWS CloudTrail 中创建一个追踪。配置 VPC Flow Logs 将日志数据发送到该追踪。使用 Amazon Kinesis Data Streams 将日志从该追踪流式传输到 OpenSearch Service。",
      "D": "在 AWS CloudTrail 中创建一个追踪。配置 VPC Flow Logs 将日志数据发送到该追踪。使用 Amazon Kinesis Data Firehose 将日志从该追踪流式传输到 OpenSearch Service。"
    }
  },
  {
    "id": 677,
    "topic": "1",
    "question_en": "A company is developing an application that will run on a production Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster has managed node groups that are provisioned with On-Demand Instances. The company needs a dedicated EKS cluster for development work. The company will use the development cluster infrequently to test the resiliency of the application. The EKS cluster must manage all the nodes. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a managed node group that contains only Spot Instances.",
      "B": "Create two managed node groups. Provision one node group with On-Demand Instances. Provision the second node group with Spot Instances.",
      "C": "Create an Auto Scaling group that has a launch configuration that uses Spot Instances. Configure the user data to add the nodes to the EKS cluster.",
      "D": "Create a managed node group that contains only On-Demand Instances."
    },
    "correct_answer": "D",
    "vote_percentage": "50%",
    "question_cn": "一家公司正在开发一个应用程序，该应用程序将在生产 Amazon Elastic Kubernetes Service (Amazon EKS) 集群上运行。EKS 集群具有使用按需实例配置的托管节点组。该公司需要一个用于开发工作的专用 EKS 集群。该公司将不频繁地使用开发集群来测试应用程序的弹性。EKS 集群必须管理所有节点。哪种解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个仅包含 Spot 实例的托管节点组。",
      "B": "创建两个托管节点组。使用按需实例配置一个节点组。使用 Spot 实例配置第二个节点组。",
      "C": "创建一个具有使用 Spot 实例的启动配置的自动伸缩组。配置用户数据以将节点添加到 EKS 集群。",
      "D": "创建一个仅包含按需实例的托管节点组。"
    }
  },
  {
    "id": 678,
    "topic": "1",
    "question_en": "A company stores sensitive data in Amazon S3. A solutions architect needs to create an encryption solution. The company needs to fully control the ability of users to create, rotate, and disable encryption keys with minimal effort for any data that must be encrypted. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use default server-side encryption with Amazon S3 managed encryption keys (SSE-S3) to store the sensitive data.",
      "B": "Create a customer managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).",
      "C": "Create an AWS managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).",
      "D": "Download S3 objects to an Amazon EC2 instance. Encrypt the objects by using customer managed keys. Upload the encrypted objects back into Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司将敏感数据存储在 Amazon S3 中。一位解决方案架构师需要创建一个加密解决方案。该公司需要完全控制用户创建、轮换和禁用加密密钥的能力，并且对任何必须加密的数据的操作要将工作量降到最低。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的默认服务器端加密来存储敏感数据。",
      "B": "使用 AWS Key Management Service (AWS KMS) 创建客户托管密钥。使用新密钥通过使用带有 AWS KMS 密钥 (SSE-KMS) 的服务器端加密来加密 S3 对象。",
      "C": "使用 AWS Key Management Service (AWS KMS) 创建 AWS 托管密钥。使用新密钥通过使用带有 AWS KMS 密钥 (SSE-KMS) 的服务器端加密来加密 S3 对象。",
      "D": "将 S3 对象下载到 Amazon EC2 实例。使用客户托管密钥加密这些对象。将加密后的对象上传回 Amazon S3。"
    }
  },
  {
    "id": 679,
    "topic": "1",
    "question_en": "A company wants to back up its on-premises virtual machines (VMs) to AWS. The company's backup solution exports on-premises backups to an Amazon S3 bucket as objects. The S3 backups must be retained for 30 days and must be automatically deleted after 30 days. Which combination of steps will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Create an S3 bucket that has S3 Object Lock enabled.",
      "B": "Create an S3 bucket that has object versioning enabled.",
      "C": "Configure a default retention period of 30 days for the objects.",
      "D": "Configure an S3 Lifecycle policy to protect the objects for 30 days",
      "E": "Configure an S3 Lifecycle policy to expire the objects after 30 days",
      "F": "Configure the backup solution to tag the objects with a 30-day retention period"
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司希望将其本地虚拟机 (VM) 备份到 AWS。该公司的备份解决方案将本地备份作为对象导出到 Amazon S3 存储桶。 S3 备份必须保留 30 天，并且必须在 30 天后自动删除。哪三种步骤的组合将满足这些要求？（选择三项。）",
    "options_cn": {
      "A": "创建一个已启用 S3 对象锁定的 S3 存储桶。",
      "B": "创建一个已启用对象版本控制的 S3 存储桶。",
      "C": "为这些对象配置 30 天的默认保留期。",
      "D": "配置一个 S3 生命周期策略以保护对象 30 天。",
      "E": "配置一个 S3 生命周期策略以在 30 天后使对象过期。",
      "F": "将备份解决方案配置为使用 30 天的保留期标记这些对象。"
    }
  },
  {
    "id": 680,
    "topic": "1",
    "question_en": "A solutions architect needs to copy files from an Amazon S3 bucket to an Amazon Elastic File System (Amazon EFS) file system and another S3 bucket. The files must be copied continuously. New files are added to the original S3 bucket consistently. The copied files should be overwritten only if the source file changes. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.",
      "B": "Create an AWS Lambda function. Mount the file system to the function. Set up an S3 event notification to invoke the function when files are created and changed in Amazon S3. Configure the function to copy files to the file system and the destination S3 bucket.",
      "C": "Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer all data.",
      "D": "Launch an Amazon EC2 instance in the same VPC as the file system. Mount the file system. Create a script to routinely synchronize all objects that changed in the origin S3 bucket to the destination S3 bucket and the mounted file system."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一名解决方案架构师需要将文件从一个 Amazon S3 存储桶复制到 Amazon EFS 文件系统和另一个 S3 存储桶。必须连续复制文件。新文件会持续添加到源 S3 存储桶。仅当 源 文件更改时才应覆盖已复制的文件。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "为目标 S3 存储桶和 EFS 文件系统创建 AWS DataSync 位置。为目标 S3 存储桶和 EFS 文件系统创建任务。将传输模式设置为仅传输已更改的数据。",
      "B": "创建一个 AWS Lambda 函数。将文件系统挂载到该函数。设置一个 S3 事件通知，以便在 Amazon S3 中创建和更改文件时调用该函数。配置该函数以将文件复制到文件系统和目标 S3 存储桶。",
      "C": "为目标 S3 存储桶和 EFS 文件系统创建 AWS DataSync 位置。为目标 S3 存储桶和 EFS 文件系统创建任务。将传输模式设置为传输所有数据。",
      "D": "在与文件系统相同的 VPC 中启动一个 Amazon EC2 实例。挂载文件系统。创建一个脚本，以定期同步源 S3 存储桶中更改的所有对象到目标 S3 存储桶和已挂载的文件系统。"
    }
  },
  {
    "id": 681,
    "topic": "1",
    "question_en": "A company uses Amazon EC2 instances and stores data on Amazon Elastic Block Store (Amazon EBS) volumes. The company must ensure that all data is encrypted at rest by using AWS Key Management Service (AWS KMS). The company must be able to control rotation of the encryption keys. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a customer managed key. Use the key to encrypt the EBS volumes.",
      "B": "Use an AWS managed key to encrypt the EBS volumes. Use the key to configure automatic key rotation.",
      "C": "Create an external KMS key with imported key material. Use the key to encrypt the EBS volumes.",
      "D": "Use an AWS owned key to encrypt the EBS volumes."
    },
    "correct_answer": "C",
    "vote_percentage": "94%",
    "question_cn": "题目 1\n题干: 一家公司使用 Amazon EC2 实例并将数据存储在 Amazon Elastic Block Store (Amazon EBS) 卷上。该公司必须确保所有静态数据通过使用 AWS Key Management Service (AWS KMS) 进行加密。该公司必须能够控制加密密钥的轮换。哪种解决方案将以最低的运营开销满足这些要求？\n选项:\n   A. 创建一个客户托管密钥。使用该密钥加密 EBS 卷。\n   B. 使用 AWS 托管密钥加密 EBS 卷。使用该密钥配置自动密钥轮换。\n   C. 使用导入的密钥材料创建一个外部 KMS 密钥。使用该密钥加密 EBS 卷。\n   D. 使用 AWS 拥有的密钥加密 EBS 卷。",
    "options_cn": {
      "A": "创建一个客户托管密钥。使用该密钥加密 EBS 卷。",
      "B": "使用 AWS 托管密钥加密 EBS 卷。使用该密钥配置自动密钥轮换。",
      "C": "使用导入的密钥材料创建一个外部 KMS 密钥。使用该密钥加密 EBS 卷。",
      "D": "使用 AWS 拥有的密钥加密 EBS 卷。"
    }
  },
  {
    "id": 682,
    "topic": "1",
    "question_en": "A company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The solution must automatically identify noncompliant resources and enforce compliance policies on findings. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes.",
      "B": "Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Lambda and Amazon EventBridge to automate the detection and remediation of unencrypted EBS volumes.",
      "C": "Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes.",
      "D": "Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes."
    },
    "correct_answer": "B",
    "vote_percentage": "94%",
    "question_cn": "一家公司需要一个解决方案，以强制对 Amazon EC2 实例上的静态数据进行加密。该解决方案必须自动识别不合规的资源，并对发现结果执行合规策略。哪个解决方案将以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "使用 IAM 策略，该策略允许用户仅创建已加密的 Amazon Elastic Block Store (Amazon EBS) 卷。使用 AWS Config 和 AWS Systems Manager 自动化检测和修复未加密的 EBS 卷。",
      "B": "使用 AWS Key Management Service (AWS KMS) 管理对已加密的 Amazon Elastic Block Store (Amazon EBS) 卷的访问。使用 AWS Lambda 和 Amazon EventBridge 自动化检测和修复未加密的 EBS 卷。",
      "C": "使用 Amazon Macie 检测未加密的 Amazon Elastic Block Store (Amazon EBS) 卷。使用 AWS Systems Manager Automation 规则自动加密现有和新的 EBS 卷。",
      "D": "使用 Amazon Inspector 检测未加密的 Amazon Elastic Block Store (Amazon EBS) 卷。使用 AWS Systems Manager Automation 规则自动加密现有和新的 EBS 卷。"
    }
  },
  {
    "id": 683,
    "topic": "1",
    "question_en": "A company is migrating its multi-tier on-premises application to AWS. The application consists of a single-node MySQL database and a multi- node web tier. The company must minimize changes to the application during the migration. The company wants to improve application resiliency after the migration. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Migrate the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer.",
      "B": "Migrate the database to Amazon EC2 instances in an Auto Scaling group behind a Network Load Balancer.",
      "C": "Migrate the database to an Amazon RDS Multi-AZ deployment.",
      "D": "Migrate the web tier to an AWS Lambda function",
      "E": "Migrate the database to an Amazon DynamoDB table."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "题目 2\n题干: 一家公司正在将其多层本地应用程序迁移到 AWS。该应用程序包含一个单节点 MySQL 数据库和一个多节点 Web 层。该公司必须最大限度地减少迁移期间对应用程序的更改。该公司希望在迁移后提高应用程序的弹性。哪些步骤的组合将满足这些要求？（选择两个。）\n选项:\n   A. 将 Web 层迁移到位于 Application Load Balancer 后面的 Auto Scaling 组中的 Amazon EC2 实例。\n   B. 将数据库迁移到位于 Network Load Balancer 后面的 Auto Scaling 组中的 Amazon EC2 实例。\n   C. 将数据库迁移到 Amazon RDS Multi-AZ 部署。\n   D. 将 Web 层迁移到 AWS Lambda 函数。\nE. 将数据库迁移到 Amazon DynamoDB 表。",
    "options_cn": {
      "A": "将 Web 层迁移到位于 Application Load Balancer 后面的 Auto Scaling 组中的 Amazon EC2 实例。",
      "B": "将数据库迁移到位于 Network Load Balancer 后面的 Auto Scaling 组中的 Amazon EC2 实例。",
      "C": "将数据库迁移到 Amazon RDS Multi-AZ 部署。",
      "D": "将 Web 层迁移到 AWS Lambda 函数。",
      "E": "将数据库迁移到 Amazon DynamoDB 表。"
    }
  },
  {
    "id": 684,
    "topic": "1",
    "question_en": "A company wants to migrate its web applications from on premises to AWS. The company is located close to the eu-central-1 Region. Because of regulations, the company cannot launch some of its applications in eu-central-1. The company wants to achieve single-digit millisecond latency. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to an edge location in Amazon CloudFront.",
      "B": "Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone.",
      "C": "Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to the regional edge caches in Amazon CloudFront.",
      "D": "Deploy the applications in AWS Wavelength Zones by extending the company’s VPC from eu-central-1 to the chosen Wavelength Zone."
    },
    "correct_answer": "B",
    "vote_percentage": "72%",
    "question_cn": "题目 3\n题干: 一家公司希望将其 Web 应用程序从本地迁移到 AWS。该公司位于 eu-central-1 区域附近。由于法规原因，该公司无法在 eu-central-1 中启动其部分应用程序。该公司希望实现个位数的毫秒级延迟。哪种解决方案将满足这些要求？\n选项:\n   A. 在 eu-central-1 中部署应用程序。将公司的 VPC 从 eu-central-1 扩展到 Amazon CloudFront 中的边缘站点。\n   B. 通过将公司的 VPC 从 eu-central-1 扩展到所选的 Local Zone，在 AWS Local Zones 中部署应用程序。\n   C. 在 eu-central-1 中部署应用程序。将公司的 VPC 从 eu-central-1 扩展到 Amazon CloudFront 中的区域边缘缓存。\n   D. 通过将公司的 VPC 从 eu-central-1 扩展到所选的 Wavelength Zone，在 AWS Wavelength Zones 中部署应用程序。",
    "options_cn": {
      "A": "在 eu-central-1 中部署应用程序。将公司的 VPC 从 eu-central-1 扩展到 Amazon CloudFront 中的边缘站点。",
      "B": "通过将公司的 VPC 从 eu-central-1 扩展到所选的 Local Zone，在 AWS Local Zones 中部署应用程序。",
      "C": "在 eu-central-1 中部署应用程序。将公司的 VPC 从 eu-central-1 扩展到 Amazon CloudFront 中的区域边缘缓存。",
      "D": "通过将公司的 VPC 从 eu-central-1 扩展到所选的 Wavelength Zone，在 AWS Wavelength Zones 中部署应用程序。"
    }
  },
  {
    "id": 685,
    "topic": "1",
    "question_en": "A company’s ecommerce website has unpredictable trafic and uses AWS Lambda functions to directly access a private Amazon RDS for PostgreSQL DB instance. The company wants to maintain predictable database performance and ensure that the Lambda invocations do not overload the database with too many connections. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Point the client driver at an RDS custom endpoint. Deploy the Lambda functions inside a VPC.",
      "B": "Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions inside a VPC.",
      "C": "Point the client driver at an RDS custom endpoint. Deploy the Lambda functions outside a VPC.",
      "D": "Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions outside a VPC."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "题目 4\n题干: 一家公司的电子商务网站具有不可预测的流量，并使用 AWS Lambda 函数直接访问私有 Amazon RDS for PostgreSQL 数据库实例。该公司希望保持可预测的数据库性能，并确保 Lambda 调用不会使用过多的连接使数据库过载。解决方案架构师应如何满足这些要求？\n选项:\n   A. 将客户端驱动程序指向 RDS 自定义终端节点。在 VPC 内部部署 Lambda 函数。\n   B. 将客户端驱动程序指向 RDS 代理终端节点。在 VPC 内部部署 Lambda 函数。\n   C. 将客户端驱动程序指向 RDS 自定义终端节点。在 VPC 外部部署 Lambda 函数。\n   D. 将客户端驱动程序指向 RDS 代理终端节点。在 VPC 外部部署 Lambda 函数。",
    "options_cn": {
      "A": "将客户端驱动程序指向 RDS 自定义终端节点。在 VPC 内部部署 Lambda 函数。",
      "B": "将客户端驱动程序指向 RDS 代理终端节点。在 VPC 内部部署 Lambda 函数。",
      "C": "将客户端驱动程序指向 RDS 自定义终端节点。在 VPC 外部部署 Lambda 函数。",
      "D": "将客户端驱动程序指向 RDS 代理终端节点。在 VPC 外部部署 Lambda 函数。"
    }
  },
  {
    "id": 686,
    "topic": "1",
    "question_en": "A company is creating an application. The company stores data from tests of the application in multiple on-premises locations. The company needs to connect the on-premises locations to VPCs in an AWS Region in the AWS Cloud. The number of accounts and VPCs will increase during the next year. The network architecture must simplify the administration of new connections and must provide the ability to scale. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Create a peering connection between the VPCs. Create a VPN connection between the VPCs and the on-premises locations.",
      "B": "Launch an Amazon EC2 instance. On the instance, include VPN software that uses a VPN connection to connect all VPCs and on- premises locations.",
      "C": "Create a transit gateway. Create VPC attachments for the VPC connections. Create VPN attachments for the on-premises connections.",
      "D": "Create an AWS Direct Connect connection between the on-premises locations and a central VPC. Connect the central VPC to other VPCs by using peering connections."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "题目 5\n题干: 一家公司正在创建一个应用程序。该公司从应用程序测试中存储来自多个本地位置的数据。该公司需要将本地位置连接到 AWS 区域中的 VPC。帐户和 VPC 的数量将在明年增加。网络架构必须简化新连接的管理，并提供扩展能力。哪种解决方案将以最低的管理开销满足这些要求？\n选项:\n   A. 在 VPC 之间创建对等连接。在 VPC 和本地位置之间创建 VPN 连接。\n   B. 启动 Amazon EC2 实例。在该实例上，包括使用 VPN 连接连接所有 VPC 和本地位置的 VPN 软件。\n   C. 创建一个 transit gateway。为 VPC 连接创建 VPC 附件。为本地连接创建 VPN 附件。\n   D. 在本地位置和中央 VPC 之间创建 AWS Direct Connect 连接。使用对等连接将中央 VPC 连接到其他 VPC。",
    "options_cn": {
      "A": "在 VPC 之间创建对等连接。在 VPC 和本地位置之间创建 VPN 连接。",
      "B": "启动 Amazon EC2 实例。在该实例上，包括使用 VPN 连接连接所有 VPC 和本地位置的 VPN 软件。",
      "C": "创建一个 transit gateway。为 VPC 连接创建 VPC 附件。为本地连接创建 VPN 附件。",
      "D": "在本地位置和中央 VPC 之间创建 AWS Direct Connect 连接。使用对等连接将中央 VPC 连接到其他 VPC。"
    }
  },
  {
    "id": 687,
    "topic": "1",
    "question_en": "A company that uses AWS needs a solution to predict the resources needed for manufacturing processes each month. The solution must use historical values that are currently stored in an Amazon S3 bucket. The company has no machine learning (ML) experience and wants to use a managed service for the training and predictions. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference.",
      "B": "Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.",
      "C": "Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints to create predictions based on the inputs.",
      "D": "Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor to create a prediction based on the inputs",
      "E": "Train an Amazon Forsecast predictor by using the historical data in the S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "16%",
    "question_cn": "题目 6\n题干: 一家使用 AWS 的公司需要一个解决方案来预测每个月制造过程中所需的资源。该解决方案必须使用当前存储在 Amazon S3 存储桶中的历史值。该公司没有机器学习 (ML) 经验，并且希望使用托管服务进行训练和预测。哪些步骤的组合将满足这些要求？（选择两个。）\n选项:\n   A. 部署 Amazon SageMaker 模型。创建一个用于推断的 SageMaker 终端节点。\n   B. 使用 Amazon SageMaker 通过使用 S3 存储桶中的历史数据来训练模型。\n   C. 配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon SageMaker 终端节点根据输入创建预测。\n   D. 配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon Forecast 预测器根据输入创建预测。\nE. 使用 S3 存储桶中的历史数据来训练 Amazon Forsecast 预测器。",
    "options_cn": {
      "A": "部署 Amazon SageMaker 模型。创建一个用于推断的 SageMaker 终端节点。",
      "B": "使用 Amazon SageMaker 通过使用 S3 存储桶中的历史数据来训练模型。",
      "C": "配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon SageMaker 终端节点根据输入创建预测。",
      "D": "配置一个带有函数 URL 的 AWS Lambda 函数，该函数使用 Amazon Forecast 预测器根据输入创建预测。",
      "E": "使用 S3 存储桶中的历史数据来训练 Amazon Forsecast 预测器。"
    }
  },
  {
    "id": 688,
    "topic": "1",
    "question_en": "A company manages AWS accounts in AWS Organizations. AWS IAM Identity Center (AWS Single Sign-On) and AWS Control Tower are configured for the accounts. The company wants to manage multiple user permissions across all the accounts. The permissions will be used by multiple IAM users and must be split between the developer and administrator teams. Each team requires different permissions. The company wants a solution that includes new users that are hired on both teams. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Create a custom IAM policy for each group to set fine-grained permissions.",
      "B": "Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Attach AWS managed IAM policies to each user as needed for fine-grained permissions.",
      "C": "Create individual users in IAM Identity Center. Create new developer and administrator groups in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each group. Assign the new groups to the appropriate accounts. Assign the new permission sets to the new groups. When new users are hired, add them to the appropriate group.",
      "D": "Create individual users in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each user. Assign the users to the appropriate accounts. Grant additional IAM permissions to the users from within specific accounts. When new users are hired, add them to IAM Identity Center and assign them to the accounts."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS Organizations 中管理 AWS 账户。这些账户已配置 AWS IAM Identity Center (AWS Single Sign-On) 和 AWS Control Tower。该公司希望跨所有账户管理多个用户权限。这些权限将由多个 IAM 用户使用，并且必须在开发人员和管理员团队之间划分。每个团队需要不同的权限。该公司希望一个解决方案，其中包括两支队伍中招聘的新用户。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在每个账户的 IAM Identity Center 中创建单个用户。在 IAM Identity Center 中创建单独的开发人员和管理员组。将用户分配到相应的组。为每个组创建一个自定义 IAM 策略以设置细粒度权限。",
      "B": "在每个账户的 IAM Identity Center 中创建单个用户。在 IAM Identity Center 中创建单独的开发人员和管理员组。将用户分配到相应的组。根据需要将 AWS 托管 IAM 策略附加到每个用户以实现细粒度权限。",
      "C": "在 IAM Identity Center 中创建单个用户。在 IAM Identity Center 中创建新的开发人员和管理员组。创建新的权限集，其中包括每个组的相应 IAM 策略。将新组分配给相应的账户。将新的权限集分配给新组。当招聘新用户时，将他们添加到相应的组。",
      "D": "在 IAM Identity Center 中创建单个用户。创建新的权限集，其中包括每个用户的相应 IAM 策略。将用户分配给相应的账户。从特定账户内向用户授予额外的 IAM 权限。当招聘新用户时，将他们添加到 IAM Identity Center 并将他们分配给账户。"
    }
  },
  {
    "id": 689,
    "topic": "1",
    "question_en": "A company wants to standardize its Amazon Elastic Block Store (Amazon EBS) volume encryption strategy. The company also wants to minimize the cost and configuration effort required to operate the volume encryption check. Which solution will meet these requirements?",
    "options_en": {
      "A": "Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Use Amazon EventBridge to schedule an AWS Lambda function to run the API calls.",
      "B": "Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Run the API calls on an AWS Fargate task.",
      "C": "Create an AWS Identity and Access Management (IAM) policy that requires the use of tags on EBS volumes. Use AWS Cost Explorer to display resources that are not properly tagged. Encrypt the untagged resources manually.",
      "D": "Create an AWS Config rule for Amazon EBS to evaluate if a volume is encrypted and to fiag the volume if it is not encrypted."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "题目 7\n题干: 一家公司希望标准化其 Amazon Elastic Block Store (Amazon EBS) 卷加密策略。该公司还希望最大限度地减少操作卷加密检查所需的成本和配置工作量。哪种解决方案将满足这些要求？\n选项:\n   A. 编写 API 调用来描述 EBS 卷，并确认 EBS 卷已加密。使用 Amazon EventBridge 计划一个 AWS Lambda 函数来运行 API 调用。\n   B. 编写 API 调用来描述 EBS 卷，并确认 EBS 卷已加密。在 AWS Fargate 任务上运行 API 调用。\n   C. 创建一个 AWS Identity and Access Management (IAM) 策略，该策略要求在 EBS 卷上使用标签。使用 AWS Cost Explorer 显示未正确标记的资源。手动加密未标记的资源。\n   D. 为 Amazon EBS 创建一个 AWS Config 规则，以评估卷是否已加密，并在未加密时标记卷。",
    "options_cn": {
      "A": "编写 API 调用来描述 EBS 卷，并确认 EBS 卷已加密。使用 Amazon EventBridge 计划一个 AWS Lambda 函数来运行 API 调用。",
      "B": "编写 API 调用来描述 EBS 卷，并确认 EBS 卷已加密。在 AWS Fargate 任务上运行 API 调用。",
      "C": "创建一个 AWS Identity and Access Management (IAM) 策略，该策略要求在 EBS 卷上使用标签。使用 AWS Cost Explorer 显示未正确标记的资源。手动加密未标记的资源。",
      "D": "为 Amazon EBS 创建一个 AWS Config 规则，以评估卷是否已加密，并在未加密时标记卷。"
    }
  },
  {
    "id": 690,
    "topic": "1",
    "question_en": "A company regularly uploads GB-sized files to Amazon S3. After the company uploads the files, the company uses a fieet of Amazon EC2 Spot Instances to transcode the file format. The company needs to scale throughput when the company uploads data from the on-premises data center to Amazon S3 and when the company downloads data from Amazon S3 to the EC2 instances. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use the S3 bucket access point instead of accessing the S3 bucket directly.",
      "B": "Upload the files into multiple S3 buckets.",
      "C": "Use S3 multipart uploads.",
      "D": "Fetch multiple byte-ranges of an object in parallel",
      "E": "Add a random prefix to each object when uploading the files."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "题目 8\n题干: 一家公司定期将 GB 大小的文件上传到 Amazon S3。在公司上传文件后，该公司使用一组 Amazon EC2 Spot 实例来转码文件格式。当公司将数据从本地数据中心上传到 Amazon S3 以及当公司将数据从 Amazon S3 下载到 EC2 实例时，该公司需要扩展吞吐量。哪些解决方案将满足这些要求？（选择两个。）\n选项:\n   A. 使用 S3 存储桶访问点，而不是直接访问 S3 存储桶。\n   B. 将文件上传到多个 S3 存储桶。\n   C. 使用 S3 多部分上传。\n   D. 并行获取对象的多个字节范围。\nE. 在上传文件时，为每个对象添加一个随机前缀。",
    "options_cn": {
      "A": "使用 S3 存储桶访问点，而不是直接访问 S3 存储桶。",
      "B": "将文件上传到多个 S3 存储桶。",
      "C": "使用 S3 多部分上传。",
      "D": "并行获取对象的多个字节范围。",
      "E": "在上传文件时，为每个对象添加一个随机前缀。"
    }
  },
  {
    "id": 691,
    "topic": "1",
    "question_en": "A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones. The web application runs on Amazon EC2 instances that are in an Auto Scaling group. The company plans to make frequent changes to the content. The solution must have strong consistency in returning the new content as soon as the changes occur. Which solutions meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.",
      "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.",
      "C": "Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.",
      "D": "Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group",
      "E": "Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一位解决方案架构师正在为部署在多个可用区中的 Web 应用程序设计共享存储解决方案。Web 应用程序在 Auto Scaling 组中的 Amazon EC2 实例上运行。公司计划频繁更改内容。该解决方案必须在更改发生后立即以强一致性返回新内容。哪些解决方案符合这些要求？（选择两项。）",
    "options_cn": {
      "A": "使用 AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) 块存储，该存储已挂载到各个 EC2 实例。",
      "B": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。将 EFS 文件系统挂载到各个 EC2 实例上。",
      "C": "创建一个共享 Amazon Elastic Block Store (Amazon EBS) 卷。将 EBS 卷挂载到各个 EC2 实例上。",
      "D": "使用 AWS DataSync 在 Auto Scaling 组中的 EC2 主机之间执行数据的持续同步。",
      "E": "创建一个 Amazon S3 存储桶来存储 Web 内容。将 Cache-Control 标头的元数据设置为 no-cache。使用 Amazon CloudFront 交付内容。"
    }
  },
  {
    "id": 692,
    "topic": "1",
    "question_en": "A company is deploying an application in three AWS Regions using an Application Load Balancer. Amazon Route 53 will be used to distribute trafic between these Regions. Which Route 53 configuration should a solutions architect use to provide the MOST high-performing experience?",
    "options_en": {
      "A": "Create an A record with a latency policy.",
      "B": "Create an A record with a geolocation policy.",
      "C": "Create a CNAME record with a failover policy.",
      "D": "Create a CNAME record with a geoproximity policy."
    },
    "correct_answer": "D",
    "vote_percentage": "81%",
    "question_cn": "一家公司正在使用 Application Load Balancer 在三个 AWS 区域中部署应用程序。Amazon Route 53 将用于在这些区域之间分配流量。解决方案架构师应该使用哪种 Route 53 配置来提供最高的性能体验？",
    "options_cn": {
      "A": "创建一个带有延迟策略的 A 记录。",
      "B": "创建一个带有地理位置策略的 A 记录。",
      "C": "创建一个带有故障转移策略的 CNAME 记录。",
      "D": "创建一个带有地理邻近策略的 CNAME 记录。"
    }
  },
  {
    "id": 693,
    "topic": "1",
    "question_en": "A company has a web application that includes an embedded NoSQL database. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group in a single Availability Zone. A recent increase in trafic requires the application to be highly available and for the database to be eventually consistent. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with its replication service on the EC2 instances.",
      "B": "Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS).",
      "C": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the embedded NoSQL database with its replication service on the EC2 instances.",
      "D": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS)."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个Web应用程序，其中包含一个嵌入式NoSQL数据库。该应用程序在Application Load Balancer (ALB) 后的Amazon EC2实例上运行。这些实例在单个可用区中的Amazon EC2 Auto Scaling组中运行。最近流量的增加要求应用程序具有高可用性，并且数据库具有最终一致性。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将ALB替换为Network Load Balancer。在EC2实例上维护嵌入式NoSQL数据库及其复制服务。",
      "B": "将ALB替换为Network Load Balancer。使用AWS Database Migration Service (AWS DMS) 将嵌入式NoSQL数据库迁移到Amazon DynamoDB。",
      "C": "修改Auto Scaling组以使用跨三个可用区的EC2实例。在EC2实例上维护嵌入式NoSQL数据库及其复制服务。",
      "D": "修改Auto Scaling组以使用跨三个可用区的EC2实例。使用AWS Database Migration Service (AWS DMS) 将嵌入式NoSQL数据库迁移到Amazon DynamoDB。"
    }
  },
  {
    "id": 694,
    "topic": "1",
    "question_en": "A company is building a shopping application on AWS. The application offers a catalog that changes once each month and needs to scale with trafic volume. The company wants the lowest possible latency from the application. Data from each user's shopping cart needs to be highly available. User session data must be available even if the user is disconnected and reconnects. What should a solutions architect do to ensure that the shopping cart data is preserved at all times?",
    "options_en": {
      "A": "Configure an Application Load Balancer to enable the sticky sessions feature (session afinity) for access to the catalog in Amazon Aurora.",
      "B": "Configure Amazon ElastiCache for Redis to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.",
      "C": "Configure Amazon OpenSearch Service to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.",
      "D": "Configure an Amazon EC2 instance with Amazon Elastic Block Store (Amazon EBS) storage for the catalog and shopping cart. Configure automated snapshots."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上构建一个购物应用程序。该应用程序提供每月更新一次的商品目录，并且需要随着流量的增加而扩展。公司希望应用程序的延迟尽可能低。每个用户的购物车数据需要具有高可用性。用户会话数据即使在用户断开连接并重新连接后也必须可用。解决方案架构师应该怎么做才能确保购物车数据始终被保留？",
    "options_cn": {
      "A": "配置 Application Load Balancer 以启用 Amazon Aurora 中对商品目录的访问的粘性会话功能（会话亲和性）。",
      "B": "配置 Amazon ElastiCache for Redis 以缓存来自 Amazon DynamoDB 的商品目录数据和来自用户会话的购物车数据。",
      "C": "配置 Amazon OpenSearch Service 以缓存来自 Amazon DynamoDB 的商品目录数据和来自用户会话的购物车数据。",
      "D": "配置一个带有 Amazon Elastic Block Store (Amazon EBS) 存储的 Amazon EC2 实例，用于商品目录和购物车。配置自动快照。"
    }
  },
  {
    "id": 695,
    "topic": "1",
    "question_en": "A company is building a microservices-based application that will be deployed on Amazon Elastic Kubernetes Service (Amazon EKS). The microservices will interact with each other. The company wants to ensure that the application is observable to identify performance issues in the future. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the application to use Amazon ElastiCache to reduce the number of requests that are sent to the microservices.",
      "B": "Configure Amazon CloudWatch Container Insights to collect metrics from the EKS clusters. Configure AWS X-Ray to trace the requests between the microservices.",
      "C": "Configure AWS CloudTrail to review the API calls. Build an Amazon QuickSight dashboard to observe the microservice interactions.",
      "D": "Use AWS Trusted Advisor to understand the performance of the application."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在构建一个基于微服务的应用程序，该应用程序将部署在 Amazon Elastic Kubernetes Service (Amazon EKS) 上。微服务将相互交互。公司希望确保应用程序是可观察的，以便将来识别性能问题。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置应用程序以使用 Amazon ElastiCache 来减少发送到微服务的请求数量。",
      "B": "配置 Amazon CloudWatch Container Insights 以从 EKS 集群收集指标。配置 AWS X-Ray 以跟踪微服务之间的请求。",
      "C": "配置 AWS CloudTrail 以审查 API 调用。构建 Amazon QuickSight 仪表板以观察微服务交互。",
      "D": "使用 AWS Trusted Advisor 来了解应用程序的性能。"
    }
  },
  {
    "id": 696,
    "topic": "1",
    "question_en": "A company needs to provide customers with secure access to its data. The company processes customer data and stores the results in an Amazon S3 bucket. All the data is subject to strong regulations and security requirements. The data must be encrypted at rest. Each customer must be able to access only their data from their AWS account. Company employees must not be able to access the data. Which solution will meet these requirements?",
    "options_en": {
      "A": "Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the private certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides.",
      "B": "Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In the S3 bucket policy, deny decryption of data for all principals except an IAM role that the customer provides.",
      "C": "Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In each KMS key policy, deny decryption of data for all principals except an IAM role that the customer provides.",
      "D": "Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the public certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides."
    },
    "correct_answer": "D",
    "vote_percentage": "73%",
    "question_cn": "一家公司需要为客户提供对其数据的安全访问。该公司处理客户数据并将结果存储在 Amazon S3 存储桶中。所有数据都受到严格的法规和安全要求。数据必须在静态时加密。每个客户必须只能从其 AWS 账户访问其数据。公司员工不得访问数据。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为每个客户预置一个 AWS Certificate Manager (ACM) 证书。在客户端加密数据。在私有证书策略中，拒绝除客户提供的 IAM 角色之外的所有主体的证书访问权限。",
      "B": "为每个客户预置一个单独的 AWS Key Management Service (AWS KMS) 密钥。在服务器端加密数据。在 S3 存储桶策略中，拒绝除客户提供的 IAM 角色之外的所有主体的数据解密权限。",
      "C": "为每个客户预置一个单独的 AWS Key Management Service (AWS KMS) 密钥。在服务器端加密数据。在每个 KMS 密钥策略中，拒绝除客户提供的 IAM 角色之外的所有主体的数据解密权限。",
      "D": "为每个客户预置一个 AWS Certificate Manager (ACM) 证书。在客户端加密数据。在公共证书策略中，拒绝除客户提供的 IAM 角色之外的所有主体的证书访问权限。"
    }
  },
  {
    "id": 697,
    "topic": "1",
    "question_en": "A solutions architect creates a VPC that includes two public subnets and two private subnets. A corporate security mandate requires the solutions architect to launch all Amazon EC2 instances in a private subnet. However, when the solutions architect launches an EC2 instance that runs a web server on ports 80 and 443 in a private subnet, no external internet trafic can connect to the server. What should the solutions architect do to resolve this issue?",
    "options_en": {
      "A": "Attach the EC2 instance to an Auto Scaling group in a private subnet. Ensure that the DNS record for the website resolves to the Auto Scaling group identifier.",
      "B": "Provision an internet-facing Application Load Balancer (ALB) in a public subnet. Add the EC2 instance to the target group that is associated with the ALEnsure that the DNS record for the website resolves to the ALB.",
      "C": "Launch a NAT gateway in a private subnet. Update the route table for the private subnets to add a default route to the NAT gateway. Attach a public Elastic IP address to the NAT gateway.",
      "D": "Ensure that the security group that is attached to the EC2 instance allows HTTP trafic on port 80 and HTTPS trafic on port 443. Ensure that the DNS record for the website resolves to the public IP address of the EC2 instance."
    },
    "correct_answer": "D",
    "vote_percentage": "83%",
    "question_cn": "一位解决方案架构师创建了一个包含两个公共子网和两个私有子网的 VPC。 公司的安全规定要求解决方案架构师在私有子网中启动所有 Amazon EC2 实例。 然而，当解决方案架构师在私有子网中启动一个在端口 80 和 443 上运行 Web 服务器的 EC2 实例时，没有任何外部互联网流量可以连接到该服务器。 解决方案架构师应该怎么做才能解决这个问题？",
    "options_cn": {
      "A": "将 EC2 实例附加到私有子网中的 Auto Scaling 组。 确保网站的 DNS 记录解析为 Auto Scaling 组标识符。",
      "B": "在公共子网中配置一个面向互联网的 Application Load Balancer (ALB)。 将 EC2 实例添加到与 ALB 关联的目标组中。 确保网站的 DNS 记录解析到 ALB。",
      "C": "在私有子网中启动一个 NAT Gateway。 更新私有子网的路由表以添加指向 NAT Gateway 的默认路由。 将一个公有 Elastic IP 地址附加到 NAT Gateway。",
      "D": "确保附加到 EC2 实例的安全组允许端口 80 上的 HTTP 流量和端口 443 上的 HTTPS 流量。 确保网站的 DNS 记录解析为 EC2 实例的公有 IP 地址。"
    }
  },
  {
    "id": 698,
    "topic": "1",
    "question_en": "A company is deploying a new application to Amazon Elastic Kubernetes Service (Amazon EKS) with an AWS Fargate cluster. The application needs a storage solution for data persistence. The solution must be highly available and fault tolerant. The solution also must be shared between multiple application containers. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create Amazon Elastic Block Store (Amazon EBS) volumes in the same Availability Zones where EKS worker nodes are placed. Register the volumes in a StorageClass object on an EKS cluster. Use EBS Multi-Attach to share the data between containers.",
      "B": "Create an Amazon Elastic File System (Amazon EFS) file system. Register the file system in a StorageClass object on an EKS cluster. Use the same file system for all containers.",
      "C": "Create an Amazon Elastic Block Store (Amazon EBS) volume. Register the volume in a StorageClass object on an EKS cluster. Use the same volume for all containers.",
      "D": "Create Amazon Elastic File System (Amazon EFS) file systems in the same Availability Zones where EKS worker nodes are placed. Register the file systems in a StorageClass object on an EKS cluster. Create an AWS Lambda function to synchronize the data between file systems."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 AWS Fargate 集群将新应用程序部署到 Amazon Elastic Kubernetes Service (Amazon EKS)。该应用程序需要一个用于数据持久性的存储解决方案。该解决方案必须具备高可用性和容错能力。该解决方案还必须在多个应用程序容器之间共享。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 EKS 工作节点所在的可用区中创建 Amazon Elastic Block Store (Amazon EBS) 卷。在 EKS 集群的 StorageClass 对象中注册这些卷。使用 EBS Multi-Attach 在容器之间共享数据。",
      "B": "创建一个 Amazon Elastic File System (Amazon EFS) 文件系统。在 EKS 集群的 StorageClass 对象中注册该文件系统。所有容器使用相同的文件系统。",
      "C": "创建一个 Amazon Elastic Block Store (Amazon EBS) 卷。在 EKS 集群的 StorageClass 对象中注册该卷。所有容器使用相同的卷。",
      "D": "在 EKS 工作节点所在的可用区中创建 Amazon Elastic File System (Amazon EFS) 文件系统。在 EKS 集群的 StorageClass 对象中注册这些文件系统。创建一个 AWS Lambda 函数以在文件系统之间同步数据。"
    }
  },
  {
    "id": 699,
    "topic": "1",
    "question_en": "A company has an application that uses Docker containers in its local data center. The application runs on a container host that stores persistent data in a volume on the host. The container instances use the stored persistent data. The company wants to move the application to a fully managed service because the company does not want to manage any servers or storage infrastructure. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes. Create an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. Use the EBS volume as a persistent volume mounted in the containers.",
      "B": "Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.",
      "C": "Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon S3 bucket. Map the S3 bucket as a persistent storage volume mounted in the containers.",
      "D": "Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers."
    },
    "correct_answer": "B",
    "vote_percentage": "90%",
    "question_cn": "一家公司在其本地数据中心使用 Docker 容器构建应用程序。该应用程序运行在容器主机上，该主机将其持久数据存储在主机上的卷中。容器实例使用存储的持久数据。公司希望将应用程序迁移到完全托管的服务，因为它不想管理任何服务器或存储基础设施。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和自管理节点。创建一个附加到 Amazon EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷。将 EBS 卷用作在容器中挂载的持久卷。",
      "B": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate 启动类型。创建一个 Amazon Elastic File System (Amazon EFS) 卷。将 EFS 卷添加为在容器中挂载的持久存储卷。",
      "C": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate 启动类型。创建一个 Amazon S3 存储桶。将 S3 存储桶映射为在容器中挂载的持久存储卷。",
      "D": "使用 Amazon Elastic Container Service (Amazon ECS) 和 Amazon EC2 启动类型。创建一个 Amazon Elastic File System (Amazon EFS) 卷。将 EFS 卷添加为在容器中挂载的持久存储卷。"
    }
  },
  {
    "id": 700,
    "topic": "1",
    "question_en": "A gaming company wants to launch a new internet-facing application in multiple AWS Regions. The application will use the TCP and UDP protocols for communication. The company needs to provide high availability and minimum latency for global users. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create internal Network Load Balancers in front of the application in each Region.",
      "B": "Create external Application Load Balancers in front of the application in each Region.",
      "C": "Create an AWS Global Accelerator accelerator to route trafic to the load balancers in each Region.",
      "D": "Configure Amazon Route 53 to use a geolocation routing policy to distribute the trafic",
      "E": "Configure Amazon CloudFront to handle the trafic and route requests to the application in each Region"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "题目 9\n题干: 一家游戏公司希望在多个 AWS 区域中启动一个新的面向 Internet 的应用程序。该应用程序将使用 TCP 和 UDP 协议进行通信。该公司需要为全球用户提供高可用性和最低的延迟。解决方案架构师应采取哪些组合操作来满足这些要求？（选择两个。）\n选项:\n   A. 在每个区域中的应用程序前面创建内部 Network Load Balancer。\n   B. 在每个区域中的应用程序前面创建外部 Application Load Balancer。\n   C. 创建一个 AWS Global Accelerator 加速器，以将流量路由到每个区域中的负载均衡器。\n   D. 配置 Amazon Route 53 以使用地理位置路由策略来分配流量。\nE. 配置 Amazon CloudFront 以处理流量并将请求路由到每个区域中的应用程序",
    "options_cn": {
      "A": "在每个区域中的应用程序前面创建内部 Network Load Balancer。",
      "B": "在每个区域中的应用程序前面创建外部 Application Load Balancer。",
      "C": "创建一个 AWS Global Accelerator 加速器，以将流量路由到每个区域中的负载均衡器。",
      "D": "配置 Amazon Route 53 以使用地理位置路由策略来分配流量。",
      "E": "配置 Amazon CloudFront 以处理流量并将请求路由到每个区域中的应用程序"
    }
  },
  {
    "id": 701,
    "topic": "1",
    "question_en": "A city has deployed a web application running on Amazon EC2 instances behind an Application Load Balancer (ALB). The application's users have reported sporadic performance, which appears to be related to DDoS attacks originating from random IP addresses. The city needs a solution that requires minimal configuration changes and provides an audit trail for the DDoS sources. Which solution meets these requirements?",
    "options_en": {
      "A": "Enable an AWS WAF web ACL on the ALB, and configure rules to block trafic from unknown sources.",
      "B": "Subscribe to Amazon Inspector. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.",
      "C": "Subscribe to AWS Shield Advanced. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.",
      "D": "Create an Amazon CloudFront distribution for the application, and set the ALB as the origin. Enable an AWS WAF web ACL on the distribution, and configure rules to block trafic from unknown sources"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个城市部署了一个 Web 应用程序，该应用程序运行在 Application Load Balancer (ALB) 之后运行的 Amazon EC2 实例上。 应用程序的用户报告了零星的性能问题，这似乎与来自随机 IP 地址的 DDoS 攻击有关。 该城市需要一个解决方案，该方案需要最少的配置更改，并为 DDoS 源提供审计跟踪。 哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "在 ALB 上启用 AWS WAF Web ACL，并配置规则以阻止来自未知源的流量。",
      "B": "订阅 Amazon Inspector。 聘请 AWS DDoS 响应团队 (DRT) 将缓解控制措施集成到服务中。",
      "C": "订阅 AWS Shield Advanced。 聘请 AWS DDoS 响应团队 (DRT) 将缓解控制措施集成到服务中。",
      "D": "为应用程序创建 Amazon CloudFront 分发，并将 ALB 设置为源。 在分发上启用 AWS WAF Web ACL，并配置规则以阻止来自未知源的流量"
    }
  },
  {
    "id": 702,
    "topic": "1",
    "question_en": "A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage Optimized devices. The company has a high performance computing (HPC) cluster that is hosted on AWS to look for oil and gas deposits. A solutions architect must provide the cluster with consistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge Storage Optimized devices. The company is sending the devices back to AWS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage Gateway file gateway to use the S3 bucket. Access the file gateway from the HPC cluster instances.",
      "B": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances.",
      "C": "Create an Amazon S3 bucket and an Amazon Elastic File System (Amazon EFS) file system. Import the data into the S3 bucket. Copy the data from the S3 bucket to the EFS file system. Access the EFS file system from the HPC cluster instances.",
      "D": "Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file system. Access the FSx for Lustre file system from the HPC cluster instances."
    },
    "correct_answer": "C",
    "vote_percentage": "53%",
    "question_cn": "一家公司将 200 TB 的数据从最近的海洋调查复制到 AWS Snowball Edge 存储优化设备上。该公司拥有一个托管在 AWS 上的高性能计算 (HPC) 集群，用于寻找石油和天然气沉积。 解决方案架构师必须为集群提供一致的亚毫秒级延迟和对 Snowball Edge 存储优化设备上数据的高吞吐量访问。该公司将设备发送回 AWS。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon S3 存储桶。将数据导入 S3 存储桶。配置一个 AWS Storage Gateway 文件网关以使用 S3 存储桶。从 HPC 集群实例访问文件网关。",
      "B": "创建一个 Amazon S3 存储桶。将数据导入 S3 存储桶。配置 Amazon FSx for Lustre 文件系统，并将其与 S3 存储桶集成。从 HPC 集群实例访问 FSx for Lustre 文件系统。",
      "C": "创建一个 Amazon S3 存储桶和一个 Amazon Elastic File System (Amazon EFS) 文件系统。将数据导入 S3 存储桶。将数据从 S3 存储桶复制到 EFS 文件系统。从 HPC 集群实例访问 EFS 文件系统。",
      "D": "创建一个 Amazon FSx for Lustre 文件系统。将数据直接导入 FSx for Lustre 文件系统。从 HPC 集群实例访问 FSx for Lustre 文件系统。"
    }
  },
  {
    "id": 703,
    "topic": "1",
    "question_en": "A company has NFS servers in an on-premises data center that need to periodically back up small amounts of data to Amazon S3. Which solution meets these requirements and is MOST cost-effective?",
    "options_en": {
      "A": "Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.",
      "B": "Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.",
      "C": "Set up an SFTP sync using AWS Transfer for SFTP to sync data from on premises to Amazon S3.",
      "D": "Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在本地数据中心拥有 NFS 服务器，需要定期间隔地将少量数据备份到 Amazon S3。哪种解决方案满足这些要求且最具成本效益？",
    "options_cn": {
      "A": "设置 AWS Glue 将数据从本地服务器复制到 Amazon S3。",
      "B": "在本地服务器上设置 AWS DataSync 代理，并将数据同步到 Amazon S3。",
      "C": "使用 AWS Transfer for SFTP 设置 SFTP 同步，将数据从本地同步到 Amazon S3。",
      "D": "在本地数据中心和 VPC 之间设置 AWS Direct Connect 连接，并将数据复制到 Amazon S3。"
    }
  },
  {
    "id": 704,
    "topic": "1",
    "question_en": "An online video game company must maintain ultra-low latency for its game servers. The game servers run on Amazon EC2 instances. The company needs a solution that can handle millions of UDP internet trafic requests each second. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an Application Load Balancer with the required protocol and ports for the internet trafic. Specify the EC2 instances as the targets.",
      "B": "Configure a Gateway Load Balancer for the internet trafic. Specify the EC2 instances as the targets.",
      "C": "Configure a Network Load Balancer with the required protocol and ports for the internet trafic. Specify the EC2 instances as the targets.",
      "D": "Launch an identical set of game servers on EC2 instances in separate AWS Regions. Route internet trafic to both sets of EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家在线视频游戏公司必须为其游戏服务器保持超低延迟。游戏服务器在 Amazon EC2 实例上运行。该公司需要一个能够每秒处理数百万个 UDP 互联网流量请求的解决方案。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "配置一个 Application Load Balancer，并为互联网流量配置所需的协议和端口。将 EC2 实例指定为目标。",
      "B": "为互联网流量配置一个 Gateway Load Balancer。将 EC2 实例指定为目标。",
      "C": "配置一个 Network Load Balancer，并为互联网流量配置所需的协议和端口。将 EC2 实例指定为目标。",
      "D": "在不同的 AWS 区域的 EC2 实例上启动一组相同的游戏服务器。将互联网流量路由到两组 EC2 实例。"
    }
  },
  {
    "id": 705,
    "topic": "1",
    "question_en": "A company runs a three-tier application in a VPC. The database tier uses an Amazon RDS for MySQL DB instance. The company plans to migrate the RDS for MySQL DB instance to an Amazon Aurora PostgreSQL DB cluster. The company needs a solution that replicates the data changes that happen during the migration to the new database. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to transform the database objects.",
      "B": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to create an Aurora PostgreSQL read replica on the RDS for MySQL DB instance.",
      "C": "Configure an Aurora MySQL read replica for the RDS for MySQL DB instance.",
      "D": "Define an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) to migrate the data",
      "E": "Promote the Aurora PostgreSQL read replica to a standalone Aurora PostgreSQL DB cluster when the replica lag is zero."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "题目 10\n题干: 一家公司在 VPC 中运行一个三层应用程序。数据库层使用 Amazon RDS for MySQL DB 实例。该公司计划将 RDS for MySQL 数据库实例迁移到 Amazon Aurora PostgreSQL 数据库集群。该公司需要一个解决方案，该解决方案可以复制在迁移期间发生到新数据库的数据更改。哪些步骤的组合将满足这些要求？（选择两个。）\n选项:\n   A. 使用 AWS Database Migration Service (AWS DMS) 模式转换来转换数据库对象。\n   B. 使用 AWS Database Migration Service (AWS DMS) 模式转换在 RDS for MySQL 数据库实例上创建 Aurora PostgreSQL 读副本。\n   C. 为 RDS for MySQL 数据库实例配置 Aurora MySQL 读副本。\n   D. 定义一个带有更改数据捕获 (CDC) 的 AWS Database Migration Service (AWS DMS) 任务来迁移数据。\nE. 当副本滞后为零时，将 Aurora PostgreSQL 读副本提升为独立的 Aurora PostgreSQL 数据库集群。",
    "options_cn": {
      "A": "使用 AWS Database Migration Service (AWS DMS) 模式转换来转换数据库对象。",
      "B": "使用 AWS Database Migration Service (AWS DMS) 模式转换在 RDS for MySQL 数据库实例上创建 Aurora PostgreSQL 读副本。",
      "C": "为 RDS for MySQL 数据库实例配置 Aurora MySQL 读副本。",
      "D": "定义一个带有更改数据捕获 (CDC) 的 AWS Database Migration Service (AWS DMS) 任务来迁移数据。",
      "E": "当副本滞后为零时，将 Aurora PostgreSQL 读副本提升为独立的 Aurora PostgreSQL 数据库集群。"
    }
  },
  {
    "id": 706,
    "topic": "1",
    "question_en": "A company hosts a database that runs on an Amazon RDS instance that is deployed to multiple Availability Zones. The company periodically runs a script against the database to report new entries that are added to the database. The script that runs against the database negatively affects the performance of a critical application. The company needs to improve application performance with minimal costs. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Add functionality to the script to identify the instance that has the fewest active connections. Configure the script to read from that instance to report the total new entries.",
      "B": "Create a read replica of the database. Configure the script to query only the read replica to report the total new entries.",
      "C": "Instruct the development team to manually export the new entries for the day in the database at the end of each day.",
      "D": "Use Amazon ElastiCache to cache the common queries that the script runs against the database."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管一个数据库，该数据库运行在部署到多个可用区的 Amazon RDS 实例上。该公司定期间隔对数据库运行一个脚本，以报告添加到数据库的新条目。针对数据库运行的脚本会对关键应用程序的性能产生负面影响。该公司需要以最低的成本提高应用程序的性能。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "向脚本添加功能，以识别具有最少活动连接的实例。配置脚本以从该实例读取数据，以报告总的新条目。",
      "B": "创建数据库的只读副本。配置脚本仅查询只读副本以报告总的新条目。",
      "C": "指示开发团队在每天结束时手动导出数据库中每天的新条目。",
      "D": "使用 Amazon ElastiCache 缓存脚本针对数据库运行的常见查询。"
    }
  },
  {
    "id": 707,
    "topic": "1",
    "question_en": "A company is using an Application Load Balancer (ALB) to present its application to the internet. The company finds abnormal trafic access patterns across the application. A solutions architect needs to improve visibility into the infrastructure to help the company understand these abnormalities better. What is the MOST operationally eficient solution that meets these requirements?",
    "options_en": {
      "A": "Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant information.",
      "B": "Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.",
      "C": "Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line for the relevant information.",
      "D": "Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire trafic access log information."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "题目 11\n题干: 一家公司正在使用 Application Load Balancer (ALB) 向 Internet 呈现其应用程序。该公司发现应用程序的访问模式异常。解决方案架构师需要提高对基础设施的可见性，以帮助公司更好地了解这些异常情况。哪种解决方案最能满足这些要求？\n选项:\n   A. 在 Amazon Athena 中为 AWS CloudTrail 日志创建一个表。为相关信息创建一个查询。\n   B. 为 Amazon S3 打开 ALB 访问日志。在 Amazon Athena 中创建一个表，并查询日志。\n   C. 为 Amazon S3 打开 ALB 访问日志。在文本编辑器中打开每个文件，并搜索每一行以获取相关信息。\n   D. 在专用的 Amazon EC2 实例上使用 Amazon EMR 直接查询 ALB 以获取流量访问日志信息。",
    "options_cn": {
      "A": "在 Amazon Athena 中为 AWS CloudTrail 日志创建一个表。为相关信息创建一个查询。",
      "B": "为 Amazon S3 打开 ALB 访问日志。在 Amazon Athena 中创建一个表，并查询日志。",
      "C": "为 Amazon S3 打开 ALB 访问日志。在文本编辑器中打开每个文件，并搜索每一行以获取相关信息。",
      "D": "在专用的 Amazon EC2 实例上使用 Amazon EMR 直接查询 ALB 以获取流量访问日志信息。"
    }
  },
  {
    "id": 708,
    "topic": "1",
    "question_en": "A company wants to use NAT gateways in its AWS environment. The company's Amazon EC2 instances in private subnets must be able to connect to the public internet through the NAT gateways. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create public NAT gateways in the same private subnets as the EC2 instances.",
      "B": "Create private NAT gateways in the same private subnets as the EC2 instances.",
      "C": "Create public NAT gateways in public subnets in the same VPCs as the EC2 instances.",
      "D": "Create private NAT gateways in public subnets in the same VPCs as the EC2 instances."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在其 AWS 环境中使用 NAT 网关。该公司位于私有子网中的 Amazon EC2 实例必须能够通过 NAT 网关连接到公共互联网。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在与 EC2 实例相同的私有子网中创建公共 NAT 网关。",
      "B": "在与 EC2 实例相同的私有子网中创建私有 NAT 网关。",
      "C": "在与 EC2 实例相同的 VPC 的公共子网中创建公共 NAT 网关。",
      "D": "在与 EC2 实例相同的 VPC 的公共子网中创建私有 NAT 网关。"
    }
  },
  {
    "id": 709,
    "topic": "1",
    "question_en": "A company has an organization in AWS Organizations. The company runs Amazon EC2 instances across four AWS accounts in the root organizational unit (OU). There are three nonproduction accounts and one production account. The company wants to prohibit users from launching EC2 instances of a certain size in the nonproduction accounts. The company has created a service control policy (SCP) to deny access to launch instances that use the prohibited types. Which solutions to deploy the SCP will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Attach the SCP to the root OU for the organization.",
      "B": "Attach the SCP to the three nonproduction Organizations member accounts.",
      "C": "Attach the SCP to the Organizations management account.",
      "D": "Create an OU for the production account. Attach the SCP to the OU. Move the production member account into the new OU",
      "E": "Create an OU for the required accounts. Attach the SCP to the OU. Move the nonproduction member accounts into the new OU."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS Organizations 中有一个组织。该公司在根组织单元 (OU) 中的四个 AWS 账户上运行 Amazon EC2 实例。有三个非生产账户和一个生产账户。该公司希望禁止用户在非生产账户中启动特定大小的 EC2 实例。该公司创建了一个服务控制策略 (SCP) 以拒绝访问启动使用被禁止类型的实例。哪些部署 SCP 的解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将 SCP 附加到组织的根 OU。",
      "B": "将 SCP 附加到三个非生产 Organizations 成员账户。",
      "C": "将 SCP 附加到 Organizations 管理账户。",
      "D": "为生产账户创建一个 OU。将 SCP 附加到该 OU。将生产成员账户移动到新的 OU 中。",
      "E": "为所需账户创建一个 OU。将 SCP 附加到该 OU。将非生产成员账户移动到新的 OU 中。"
    }
  },
  {
    "id": 710,
    "topic": "1",
    "question_en": "A company’s website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3. Which solution meets these requirements?",
    "options_en": {
      "A": "Set up S3 bucket policies to allow access from a VPC endpoint.",
      "B": "Set up an IAM policy to grant read-write access to the S3 bucket.",
      "C": "Set up a NAT gateway to access resources outside the private subnet.",
      "D": "Set up an access key ID and a secret access key to access the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管在 Amazon EC2 实例上的网站处理存储在 Amazon S3 中的机密数据。由于安全问题，该公司要求其 EC2 资源和 Amazon S3 之间建立私密且安全的连接。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "设置 S3 存储桶策略以允许从 VPC endpoint 访问。",
      "B": "设置 IAM 策略以授予对 S3 存储桶的读写访问权限。",
      "C": "设置 NAT Gateway 以访问私有子网之外的资源。",
      "D": "设置访问密钥 ID 和秘密访问密钥以访问 S3 存储桶。"
    }
  },
  {
    "id": 711,
    "topic": "1",
    "question_en": "An ecommerce company runs its application on AWS. The application uses an Amazon Aurora PostgreSQL cluster in Multi-AZ mode for the underlying database. During a recent promotional campaign, the application experienced heavy read load and write load. Users experienced timeout issues when they attempted to access the application. A solutions architect needs to make the application architecture more scalable and highly available. Which solution will meet these requirements with the LEAST downtime?",
    "options_en": {
      "A": "Create an Amazon EventBridge rule that has the Aurora cluster as a source. Create an AWS Lambda function to log the state change events of the Aurora cluster. Add the Lambda function as a target for the EventBridge rule. Add additional reader nodes to fail over to.",
      "B": "Modify the Aurora cluster and activate the zero-downtime restart (ZDR) feature. Use Database Activity Streams on the cluster to track the cluster status.",
      "C": "Add additional reader instances to the Aurora cluster. Create an Amazon RDS Proxy target group for the Aurora cluster.",
      "D": "Create an Amazon ElastiCache for Redis cache. Replicate data from the Aurora cluster to Redis by using AWS Database Migration Service (AWS DMS) with a write-around approach."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司在 AWS 上运行其应用程序。该应用程序使用 Multi-AZ 模式的 Amazon Aurora PostgreSQL 集群作为底层数据库。在最近的促销活动中，应用程序经历了繁重的读取负载和写入负载。用户在尝试访问该应用程序时遇到了超时问题。 解决方案架构师需要使应用程序架构更具可扩展性和高可用性。哪种解决方案将以最少的停机时间满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon EventBridge 规则，该规则将 Aurora 集群作为 源。创建一个 AWS Lambda 函数来记录 Aurora 集群的状态更改事件。将 Lambda 函数添加为 EventBridge 规则的目标。添加额外的读取节点以进行故障转移。",
      "B": "修改 Aurora 集群并激活零停机重启 (ZDR) 功能。 使用数据库活动流来跟踪集群状态。",
      "C": "为 Aurora 集群添加额外的读取实例。 为 Aurora 集群创建 Amazon RDS Proxy 目标组。",
      "D": "创建一个 Amazon ElastiCache for Redis 缓存。使用 AWS Database Migration Service (AWS DMS) 并采用旁路写入方式，将数据从 Aurora 集群复制到 Redis。"
    }
  },
  {
    "id": 712,
    "topic": "1",
    "question_en": "A company is designing a web application on AWS. The application will use a VPN connection between the company’s existing data centers and the company's VPCs. The company uses Amazon Route 53 as its DNS service. The application must use private DNS records to communicate with the on-premises services from a VPC. Which solution will meet these requirements in the MOST secure manner?",
    "options_en": {
      "A": "Create a Route 53 Resolver outbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.",
      "B": "Create a Route 53 Resolver inbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.",
      "C": "Create a Route 53 private hosted zone. Associate the private hosted zone with the VPC.",
      "D": "Create a Route 53 public hosted zone. Create a record for each service to allow service communication"
    },
    "correct_answer": "C",
    "vote_percentage": "91%",
    "question_cn": "一家公司正在 AWS 上设计一个 Web 应用程序。该应用程序将使用公司现有数据中心与其 VPC 之间的 VPN 连接。该公司使用 Amazon Route 53 作为其 DNS 服务。该应用程序必须使用私有 DNS 记录才能从 VPC 与本地服务通信。哪种解决方案将以最安全的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个 Route 53 Resolver 出站端点。创建一个解析器规则。将该解析器规则与 VPC 关联。",
      "B": "创建一个 Route 53 Resolver 入站端点。创建一个解析器规则。将该解析器规则与 VPC 关联。",
      "C": "创建一个 Route 53 私有托管区域。将该私有托管区域与 VPC 关联。",
      "D": "创建一个 Route 53 公共托管区域。为每个服务创建记录以允许服务通信"
    }
  },
  {
    "id": 713,
    "topic": "1",
    "question_en": "A company is running a photo hosting service in the us-east-1 Region. The service enables users across multiple countries to upload and view photos. Some photos are heavily viewed for months, and others are viewed for less than a week. The application allows uploads of up to 20 MB for each photo. The service uses the photo metadata to determine which photos to display to each user. Which solution provides the appropriate user access MOST cost-effectively?",
    "options_en": {
      "A": "Store the photos in Amazon DynamoDB. Turn on DynamoDB Accelerator (DAX) to cache frequently viewed items.",
      "B": "Store the photos in the Amazon S3 Intelligent-Tiering storage class. Store the photo metadata and its S3 location in DynamoDB.",
      "C": "Store the photos in the Amazon S3 Standard storage class. Set up an S3 Lifecycle policy to move photos older than 30 days to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Use the object tags to keep track of metadata.",
      "D": "Store the photos in the Amazon S3 Glacier storage class. Set up an S3 Lifecycle policy to move photos older than 30 days to the S3 Glacier Deep Archive storage class. Store the photo metadata and its S3 location in Amazon OpenSearch Service."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 us-east-1 区域运行一个照片托管服务。该服务允许全球各地的用户上传和查看照片。有些照片会被频繁查看数月，而另一些照片的查看时间不到一周。该应用程序允许每个照片上传高达 20 MB 的内容。该服务使用照片元数据来确定要向每个用户显示哪些照片。哪种解决方案能以最具成本效益的方式提供适当的用户访问？",
    "options_cn": {
      "A": "将照片存储在 Amazon DynamoDB 中。打开 DynamoDB Accelerator (DAX) 以缓存经常查看的项目。",
      "B": "将照片存储在 Amazon S3 Intelligent-Tiering 存储类中。将照片元数据及其 S3 位置存储在 DynamoDB 中。",
      "C": "将照片存储在 Amazon S3 Standard 存储类中。设置 S3 生命周期策略，将超过 30 天的照片移动到 S3 Standard-Infrequent Access (S3 Standard-IA) 存储类。使用对象标签来跟踪元数据。",
      "D": "将照片存储在 Amazon S3 Glacier 存储类中。设置 S3 生命周期策略，将超过 30 天的照片移动到 S3 Glacier Deep Archive 存储类。将照片元数据及其 S3 位置存储在 Amazon OpenSearch Service 中。"
    }
  },
  {
    "id": 714,
    "topic": "1",
    "question_en": "A company runs a highly available web application on Amazon EC2 instances behind an Application Load Balancer. The company uses Amazon CloudWatch metrics. As the trafic to the web application increases, some EC2 instances become overloaded with many outstanding requests. The CloudWatch metrics show that the number of requests processed and the time to receive the responses from some EC2 instances are both higher compared to other EC2 instances. The company does not want new requests to be forwarded to the EC2 instances that are already overloaded. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use the round robin routing algorithm based on the RequestCountPerTarget and ActiveConnectionCount CloudWatch metrics.",
      "B": "Use the least outstanding requests algorithm based on the RequestCountPerTarget and ActiveConnectionCount CloudWatch metrics.",
      "C": "Use the round robin routing algorithm based on the RequestCount and TargetResponseTime CloudWatch metrics.",
      "D": "Use the least outstanding requests algorithm based on the RequestCount and TargetResponseTime CloudWatch metrics."
    },
    "correct_answer": "C",
    "vote_percentage": "79%",
    "question_cn": "一家公司在 Application Load Balancer 后面的 Amazon EC2 实例上运行一个高可用性 Web 应用程序。该公司使用 Amazon CloudWatch 指标。随着 Web 应用程序的流量增加，一些 EC2 实例因大量未完成的请求而过载。CloudWatch 指标显示，与其它 EC2 实例相比，某些 EC2 实例处理的请求数量和接收响应的时间都更高。该公司不希望将新请求转发到已经过载的 EC2 实例。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "根据 RequestCountPerTarget 和 ActiveConnectionCount CloudWatch 指标使用轮询路由算法。",
      "B": "根据 RequestCountPerTarget 和 ActiveConnectionCount CloudWatch 指标使用最少未完成请求算法。",
      "C": "根据 RequestCount 和 TargetResponseTime CloudWatch 指标使用轮询路由算法。",
      "D": "根据 RequestCount 和 TargetResponseTime CloudWatch 指标使用最少未完成请求算法。"
    }
  },
  {
    "id": 715,
    "topic": "1",
    "question_en": "A company uses Amazon EC2, AWS Fargate, and AWS Lambda to run multiple workloads in the company's AWS account. The company wants to fully make use of its Compute Savings Plans. The company wants to receive notification when coverage of the Compute Savings Plans drops. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create a daily budget for the Savings Plans by using AWS Budgets. Configure the budget with a coverage threshold to send notifications to the appropriate email message recipients.",
      "B": "Create a Lambda function that runs a coverage report against the Savings Plans. Use Amazon Simple Email Service (Amazon SES) to email the report to the appropriate email message recipients.",
      "C": "Create an AWS Budgets report for the Savings Plans budget. Set the frequency to daily.",
      "D": "Create a Savings Plans alert subscription. Enable all notification options. Enter an email address to receive notifications."
    },
    "correct_answer": "B",
    "vote_percentage": "76%",
    "question_cn": "一家公司使用 Amazon EC2、AWS Fargate 和 AWS Lambda 在其公司的 AWS 账户中运行多个工作负载。该公司希望充分利用其 Compute Savings Plans。该公司希望在 Compute Savings Plans 的覆盖率下降时收到通知。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Budgets 为 Savings Plans 创建每日预算。使用覆盖率阈值配置预算，以便向相应的电子邮件消息接收者发送通知。",
      "B": "创建一个 Lambda 函数，该函数针对 Savings Plans 运行覆盖率报告。使用 Amazon Simple Email Service (Amazon SES) 将报告通过电子邮件发送给相应的电子邮件消息接收者。",
      "C": "为 Savings Plans 预算创建 AWS Budgets 报告。将频率设置为每日。",
      "D": "创建 Savings Plans 警报订阅。启用所有通知选项。输入一个电子邮件地址以接收通知。"
    }
  },
  {
    "id": 716,
    "topic": "1",
    "question_en": "A company runs a real-time data ingestion solution on AWS. The solution consists of the most recent version of Amazon Managed Streaming for Apache Kafka (Amazon MSK). The solution is deployed in a VPC in private subnets across three Availability Zones. A solutions architect needs to redesign the data ingestion solution to be publicly available over the internet. The data in transit must also be encrypted. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Configure public subnets in the existing VPC. Deploy an MSK cluster in the public subnets. Update the MSK cluster security settings to enable mutual TLS authentication.",
      "B": "Create a new VPC that has public subnets. Deploy an MSK cluster in the public subnets. Update the MSK cluster security settings to enable mutual TLS authentication.",
      "C": "Deploy an Application Load Balancer (ALB) that uses private subnets. Configure an ALB security group inbound rule to allow inbound trafic from the VPC CIDR block for HTTPS protocol.",
      "D": "Deploy a Network Load Balancer (NLB) that uses private subnets. Configure an NLB listener for HTTPS communication over the internet."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 上运行实时数据摄取解决方案。该解决方案包含最新版本的 Amazon Managed Streaming for Apache Kafka (Amazon MSK)。该解决方案部署在跨三个可用区的私有子网中的 VPC 中。解决方案架构师需要重新设计数据摄取解决方案，使其可以通过 Internet 公开访问。传输中的数据也必须加密。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "在现有的 VPC 中配置公共子网。在公共子网中部署 MSK 集群。更新 MSK 集群安全设置以启用相互 TLS 身份验证。",
      "B": "创建一个具有公共子网的新 VPC。在公共子网中部署 MSK 集群。更新 MSK 集群安全设置以启用相互 TLS 身份验证。",
      "C": "部署一个使用私有子网的 Application Load Balancer (ALB)。配置 ALB 安全组入站规则，以允许来自 VPC CIDR 块的 HTTPS 协议的入站流量。",
      "D": "部署一个使用私有子网的 Network Load Balancer (NLB)。为通过 Internet 的 HTTPS 通信配置 NLB 侦听器。"
    }
  },
  {
    "id": 717,
    "topic": "1",
    "question_en": "A company wants to migrate an on-premises legacy application to AWS. The application ingests customer order files from an on-premises enterprise resource planning (ERP) system. The application then uploads the files to an SFTP server. The application uses a scheduled job that checks for order files every hour. The company already has an AWS account that has connectivity to the on-premises network. The new application on AWS must support integration with the existing ERP system. The new application must be secure and resilient and must use the SFTP protocol to process orders from the ERP system immediately. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an AWS Transfer Family SFTP internet-facing server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use S3 Event Notifications to send s3:ObjectCreated:* events to the Lambda function.",
      "B": "Create an AWS Transfer Family SFTP internet-facing server in one Availability Zone. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workfiow to invoke the Lambda function.",
      "C": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Step Functions state machine to process order files. Use Amazon EventBridge Scheduler to invoke the state machine to periodically check Amazon EFS for order files.",
      "D": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workfiow to invoke the Lambda function."
    },
    "correct_answer": "A",
    "vote_percentage": "76%",
    "question_cn": "一家公司希望将本地遗留应用程序迁移到 AWS。该应用程序从本地企业资源规划 (ERP) 系统摄取客户订单文件。然后，该应用程序将文件上传到 SFTP 服务器。该应用程序使用一个计划作业，每小时检查一次订单文件。该公司已经拥有一个 AWS 账户，该账户已连接到本地网络。AWS 上的新应用程序必须支持与现有 ERP 系统的集成。新应用程序必须安全且具有弹性，并且必须使用 SFTP 协议立即处理来自 ERP 系统的订单。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在两个可用区中创建一个面向互联网的 AWS Transfer Family SFTP 服务器。使用 Amazon S3 存储。创建 AWS Lambda 函数来处理订单文件。使用 S3 事件通知将 s3:ObjectCreated:* 事件发送到 Lambda 函数。",
      "B": "在一个可用区中创建一个面向互联网的 AWS Transfer Family SFTP 服务器。使用 Amazon Elastic File System (Amazon EFS) 存储。创建 AWS Lambda 函数来处理订单文件。使用 Transfer Family 托管工作流来调用 Lambda 函数。",
      "C": "在两个可用区中创建一个内部 AWS Transfer Family SFTP 服务器。使用 Amazon Elastic File System (Amazon EFS) 存储。创建 AWS Step Functions 状态机来处理订单文件。使用 Amazon EventBridge Scheduler 定期间隔调用状态机来检查 Amazon EFS 中的订单文件。",
      "D": "在两个可用区中创建一个内部 AWS Transfer Family SFTP 服务器。使用 Amazon S3 存储。创建 AWS Lambda 函数来处理订单文件。使用 Transfer Family 托管工作流来调用 Lambda 函数。"
    }
  },
  {
    "id": 718,
    "topic": "1",
    "question_en": "A company’s applications use Apache Hadoop and Apache Spark to process data on premises. The existing infrastructure is not scalable and is complex to manage. A solutions architect must design a scalable solution that reduces operational complexity. The solution must keep the data processing on premises. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS) data and application. Use an Amazon EMR cluster to process the data.",
      "B": "Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS) cluster. Create an Amazon EMR cluster to process the data.",
      "C": "Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.",
      "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon EMR cluster to process the data."
    },
    "correct_answer": "A",
    "vote_percentage": "83%",
    "question_cn": "一家公司的应用程序使用 Apache Hadoop 和 Apache Spark 在本地处理数据。现有的基础设施不可扩展且难以管理。一位解决方案架构师必须设计一个可扩展的解决方案，以降低运营复杂性。该解决方案必须在本地保留数据处理。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Site-to-Site VPN 访问本地 Hadoop 分布式文件系统 (HDFS) 数据和应用程序。使用 Amazon EMR 集群处理数据。",
      "B": "使用 AWS DataSync 连接到本地 Hadoop 分布式文件系统 (HDFS) 集群。创建 Amazon EMR 集群来处理数据。",
      "C": "将 Apache Hadoop 应用程序和 Apache Spark 应用程序迁移到 AWS Outposts 上的 Amazon EMR 集群。使用 EMR 集群处理数据。",
      "D": "使用 AWS Snowball 设备将数据迁移到 Amazon S3 存储桶。创建 Amazon EMR 集群来处理数据。"
    }
  },
  {
    "id": 719,
    "topic": "1",
    "question_en": "A company is migrating a large amount of data from on-premises storage to AWS. Windows, Mac, and Linux based Amazon EC2 instances in the same AWS Region will access the data by using SMB and NFS storage protocols. The company will access a portion of the data routinely. The company will access the remaining data infrequently. The company needs to design a solution to host the data. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon Elastic File System (Amazon EFS) volume that uses EFS Intelligent-Tiering. Use AWS DataSync to migrate the data to the EFS volume.",
      "B": "Create an Amazon FSx for ONTAP instance. Create an FSx for ONTAP file system with a root volume that uses the auto tiering policy. Migrate the data to the FSx for ONTAP volume.",
      "C": "Create an Amazon S3 bucket that uses S3 Intelligent-Tiering. Migrate the data to the S3 bucket by using an AWS Storage Gateway Amazon S3 File Gateway.",
      "D": "Create an Amazon FSx for OpenZFS file system. Migrate the data to the new volume."
    },
    "correct_answer": "C",
    "vote_percentage": "70%",
    "question_cn": "一家公司正在将大量数据从本地存储迁移到 AWS。 位于同一 AWS 区域的基于 Windows、Mac 和 Linux 的 Amazon EC2 实例将通过 SMB 和 NFS 存储协议访问数据。该公司将定期访问部分数据。该公司将不经常访问剩余的数据。该公司需要设计一个解决方案来托管数据。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个使用 EFS Intelligent-Tiering 的 Amazon Elastic File System (Amazon EFS) 卷。使用 AWS DataSync 将数据迁移到 EFS 卷。",
      "B": "创建 Amazon FSx for ONTAP 实例。创建一个 FSx for ONTAP 文件系统，其根卷使用自动分层策略。将数据迁移到 FSx for ONTAP 卷。",
      "C": "创建一个使用 S3 Intelligent-Tiering 的 Amazon S3 存储桶。使用 AWS Storage Gateway Amazon S3 File Gateway 将数据迁移到 S3 存储桶。",
      "D": "创建一个 Amazon FSx for OpenZFS 文件系统。将数据迁移到新卷。"
    }
  },
  {
    "id": 720,
    "topic": "1",
    "question_en": "A manufacturing company runs its report generation application on AWS. The application generates each report in about 20 minutes. The application is built as a monolith that runs on a single Amazon EC2 instance. The application requires frequent updates to its tightly coupled modules. The application becomes complex to maintain as the company adds new features. Each time the company patches a software module, the application experiences downtime. Report generation must restart from the beginning after any interruptions. The company wants to redesign the application so that the application can be fiexible, scalable, and gradually improved. The company wants to minimize application downtime. Which solution will meet these requirements?",
    "options_en": {
      "A": "Run the application on AWS Lambda as a single function with maximum provisioned concurrency.",
      "B": "Run the application on Amazon EC2 Spot Instances as microservices with a Spot Fleet default allocation strategy.",
      "C": "Run the application on Amazon Elastic Container Service (Amazon ECS) as microservices with service auto scaling.",
      "D": "Run the application on AWS Elastic Beanstalk as a single application environment with an all-at-once deployment strategy."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家制造公司在 AWS 上运行其报告生成应用程序。该应用程序大约需要 20 分钟生成每个报告。该应用程序被构建为一个整体，在单个 Amazon EC2 实例上运行。该应用程序需要频繁更新其紧密耦合的模块。当公司添加新功能时，该应用程序变得难以维护。每次公司修补一个软件模块时，该应用程序都会经历停机时间。报告生成在任何中断后都必须从头开始。公司希望重新设计应用程序，以便应用程序可以灵活、可扩展并逐步改进。公司希望最大限度地减少应用程序停机时间。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Lambda 上将应用程序作为具有最大预置并发的单个函数运行。",
      "B": "在 Amazon EC2 Spot Instances 上将应用程序作为微服务运行，并使用 Spot Fleet 默认分配策略。",
      "C": "在 Amazon Elastic Container Service (Amazon ECS) 上将应用程序作为微服务运行，并使用服务自动伸缩。",
      "D": "在 AWS Elastic Beanstalk 上将应用程序作为具有一次性部署策略的单个应用程序环境运行。"
    }
  },
  {
    "id": 721,
    "topic": "1",
    "question_en": "A company wants to rearchitect a large-scale web application to a serverless microservices architecture. The application uses Amazon EC2 instances and is written in Python. The company selected one component of the web application to test as a microservice. The component supports hundreds of requests each second. The company wants to create and test the microservice on an AWS solution that supports Python. The solution must also scale automatically and require minimal infrastructure and minimal operational support. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use a Spot Fleet with auto scaling of EC2 instances that run the most recent Amazon Linux operating system.",
      "B": "Use an AWS Elastic Beanstalk web server environment that has high availability configured.",
      "C": "Use Amazon Elastic Kubernetes Service (Amazon EKS). Launch Auto Scaling groups of self-managed EC2 instances.",
      "D": "Use an AWS Lambda function that runs custom developed code."
    },
    "correct_answer": "C",
    "vote_percentage": "80%",
    "question_cn": "一家公司希望将大规模 Web 应用程序重新架构为无服务器微服务架构。该应用程序使用 Amazon EC2 实例，并使用 Python 编写。该公司选择 Web 应用程序的一个组件作为微服务进行测试。该组件每秒支持数百个请求。该公司希望在支持 Python 的 AWS 解决方案上创建和测试该微服务。该解决方案还必须自动扩展，并需要最少的 infrastructure 和最少的运营支持。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Spot Fleet 和 EC2 实例的自动伸缩，运行最新的 Amazon Linux 操作系统。",
      "B": "使用配置了高可用性的 AWS Elastic Beanstalk Web 服务器环境。",
      "C": "使用 Amazon Elastic Kubernetes Service (Amazon EKS)。启动自管理的 EC2 实例的 Auto Scaling 组。",
      "D": "使用运行自定义开发代码的 AWS Lambda 函数。"
    }
  },
  {
    "id": 722,
    "topic": "1",
    "question_en": "A company has an AWS Direct Connect connection from its on-premises location to an AWS account. The AWS account has 30 different VPCs in the same AWS Region. The VPCs use private virtual interfaces (VIFs). Each VPC has a CIDR block that does not overlap with other networks under the company's control. The company wants to centrally manage the networking architecture while still allowing each VPC to communicate with all other VPCs and on- premises networks. Which solution will meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Create a transit gateway, and associate the Direct Connect connection with a new transit VIF. Turn on the transit gateway's route propagation feature.",
      "B": "Create a Direct Connect gateway. Recreate the private VIFs to use the new gateway. Associate each VPC by creating new virtual private gateways.",
      "C": "Create a transit VPConnect the Direct Connect connection to the transit VPCreate a peering connection between all other VPCs in the Region. Update the route tables.",
      "D": "Create AWS Site-to-Site VPN connections from on premises to each VPC. Ensure that both VPN tunnels are UP for each connection. Turn on the route propagation feature."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司通过 AWS Direct Connect 连接将其本地位置连接到 AWS 账户。AWS 账户在同一 AWS 区域中拥有 30 个不同的 VPC。这些 VPC 使用私有虚拟接口 (VIF)。每个 VPC 都有一个 CIDR 块，该块与公司控制下的其他网络不重叠。该公司希望集中管理网络架构，同时仍然允许每个 VPC 与所有其他 VPC 和本地网络通信。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Transit Gateway，并将 Direct Connect 连接与新的 Transit VIF 关联。打开 Transit Gateway 的路由传播功能。",
      "B": "创建一个 Direct Connect 网关。重新创建私有 VIF 以使用新网关。通过创建新的虚拟私有网关来关联每个 VPC。",
      "C": "创建一个 Transit VPC，并将 Direct Connect 连接到 Transit VPC。在区域内的所有其他 VPC 之间创建对等连接。更新路由表。",
      "D": "从本地到每个 VPC 创建 AWS Site-to-Site VPN 连接。确保每个连接的两个 VPN 隧道都处于 UP 状态。打开路由传播功能。"
    }
  },
  {
    "id": 723,
    "topic": "1",
    "question_en": "A company has applications that run on Amazon EC2 instances. The EC2 instances connect to Amazon RDS databases by using an IAM role that has associated policies. The company wants to use AWS Systems Manager to patch the EC2 instances without disrupting the running applications. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role.",
      "B": "Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances.",
      "C": "Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances.",
      "D": "Remove the existing policies from the existing IAM role. Add the AmazonSSMManagedInstanceCore policy to the existing IAM role."
    },
    "correct_answer": "C",
    "vote_percentage": "60%",
    "question_cn": "一家公司拥有运行在 Amazon EC2 实例上的应用程序。EC2 实例通过使用具有关联策略的 IAM 角色连接到 Amazon RDS 数据库。该公司希望使用 AWS Systems Manager 补丁 EC2 实例，而不会中断正在运行的应用程序。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 IAM 角色。将 AmazonSSMManagedInstanceCore 策略附加到新的 IAM 角色。将新的 IAM 角色附加到 EC2 实例和现有的 IAM 角色。",
      "B": "创建一个 IAM 用户。将 AmazonSSMManagedInstanceCore 策略附加到 IAM 用户。配置 Systems Manager 以使用 IAM 用户来管理 EC2 实例。",
      "C": "在 Systems Manager 中启用默认主机配置管理来管理 EC2 实例。",
      "D": "从现有 IAM 角色中删除现有策略。将 AmazonSSMManagedInstanceCore 策略添加到现有的 IAM 角色。"
    }
  },
  {
    "id": 724,
    "topic": "1",
    "question_en": "A company runs container applications by using Amazon Elastic Kubernetes Service (Amazon EKS) and the Kubernetes Horizontal Pod Autoscaler. The workload is not consistent throughout the day. A solutions architect notices that the number of nodes does not automatically scale out when the existing nodes have reached maximum capacity in the cluster, which causes performance issues. Which solution will resolve this issue with the LEAST administrative overhead?",
    "options_en": {
      "A": "Scale out the nodes by tracking the memory usage.",
      "B": "Use the Kubernetes Cluster Autoscaler to manage the number of nodes in the cluster.",
      "C": "Use an AWS Lambda function to resize the EKS cluster automatically.",
      "D": "Use an Amazon EC2 Auto Scaling group to distribute the workload."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 Kubernetes Horizontal Pod Autoscaler 运行容器应用程序。工作负载在一天中并不一致。一位解决方案架构师注意到，当现有节点已达到集群中的最大容量时，节点的数量不会自动横向扩展，这会导致性能问题。哪个解决方案将以最少的管理开销解决此问题？",
    "options_cn": {
      "A": "通过跟踪内存使用情况来横向扩展节点。",
      "B": "使用 Kubernetes 集群自动伸缩器来管理集群中的节点数量。",
      "C": "使用 AWS Lambda 函数自动调整 EKS 集群的大小。",
      "D": "使用 Amazon EC2 Auto Scaling 组来分发工作负载。"
    }
  },
  {
    "id": 725,
    "topic": "1",
    "question_en": "A company maintains about 300 TB in Amazon S3 Standard storage month after month. The S3 objects are each typically around 50 GB in size and are frequently replaced with multipart uploads by their global application. The number and size of S3 objects remain constant, but the company's S3 storage costs are increasing each month. How should a solutions architect reduce costs in this situation?",
    "options_en": {
      "A": "Switch from multipart uploads to Amazon S3 Transfer Acceleration.",
      "B": "Enable an S3 Lifecycle policy that deletes incomplete multipart uploads.",
      "C": "Configure S3 inventory to prevent objects from being archived too quickly.",
      "D": "Configure Amazon CloudFront to reduce the number of objects stored in Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司每月在 Amazon S3 标准存储中维护约 300 TB 的数据。S3 对象的大小通常约为 50 GB，并且由其全球应用程序使用 multipart uploads 频繁替换。S3 对象的数量和大小保持不变，但公司的 S3 存储成本每月都在增加。解决方案架构师应如何在这种情况下降低成本？",
    "options_cn": {
      "A": "从 multipart uploads 切换到 Amazon S3 Transfer Acceleration。",
      "B": "打开一个 S3 生命周期策略，该策略将删除未完成的 multipart uploads。",
      "C": "配置 S3 inventory 以防止对象过快地被归档。",
      "D": "配置 Amazon CloudFront 以减少存储在 Amazon S3 中的对象数量。"
    }
  },
  {
    "id": 726,
    "topic": "1",
    "question_en": "A company has deployed a multiplayer game for mobile devices. The game requires live location tracking of players based on latitude and longitude. The data store for the game must support rapid updates and retrieval of locations. The game uses an Amazon RDS for PostgreSQL DB instance with read replicas to store the location data. During peak usage periods, the database is unable to maintain the performance that is needed for reading and writing updates. The game's user base is increasing rapidly. What should a solutions architect do to improve the performance of the data tier?",
    "options_en": {
      "A": "Take a snapshot of the existing DB instance. Restore the snapshot with Multi-AZ enabled.",
      "B": "Migrate from Amazon RDS to Amazon OpenSearch Service with OpenSearch Dashboards.",
      "C": "Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance. Modify the game to use DAX.",
      "D": "Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the game to use Redis."
    },
    "correct_answer": "D",
    "vote_percentage": "60%",
    "question_cn": "一家公司为移动设备部署了一款多人游戏。该游戏需要根据纬度和经度对玩家进行实时位置追踪。该游戏的数据存储必须支持对位置数据进行快速更新和检索。该游戏使用一个 Amazon RDS for PostgreSQL 数据库实例以及只读副本，来存储位置数据。在高峰使用时段，数据库无法保持读取和写入更新所需的性能。该游戏的玩家数量正在迅速增加。解决方案架构师应该怎么做来提高数据层的性能？",
    "options_cn": {
      "A": "拍摄现有数据库实例的快照。使用启用 Multi-AZ 的方式恢复该快照。",
      "B": "从 Amazon RDS 迁移到 Amazon OpenSearch Service，并使用 OpenSearch Dashboards。",
      "C": "在现有的数据库实例之前部署 Amazon DynamoDB Accelerator (DAX)。修改游戏以使用 DAX。",
      "D": "在现有的数据库实例之前部署 Amazon ElastiCache for Redis 集群。修改游戏以使用 Redis。"
    }
  },
  {
    "id": 727,
    "topic": "1",
    "question_en": "A company stores critical data in Amazon DynamoDB tables in the company's AWS account. An IT administrator accidentally deleted a DynamoDB table. The deletion caused a significant loss of data and disrupted the company's operations. The company wants to prevent this type of disruption in the future. Which solution will meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure a trail in AWS CloudTrail. Create an Amazon EventBridge rule for delete actions. Create an AWS Lambda function to automatically restore deleted DynamoDB tables.",
      "B": "Create a backup and restore plan for the DynamoDB tables. Recover the DynamoDB tables manually.",
      "C": "Configure deletion protection on the DynamoDB tables.",
      "D": "Enable point-in-time recovery on the DynamoDB tables."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 AWS 账户中将关键数据存储在 Amazon DynamoDB 表中。一位 IT 管理员意外删除了一个 DynamoDB 表。删除操作导致大量数据丢失，并中断了公司的运营。该公司希望在将来防止此类中断。以下哪种解决方案以最小的运营开销满足此要求？",
    "options_cn": {
      "A": "在 AWS CloudTrail 中配置一个追踪。为删除操作创建 Amazon EventBridge 规则。创建一个 AWS Lambda 函数以自动恢复已删除的 DynamoDB 表。",
      "B": "为 DynamoDB 表创建备份和恢复计划。手动恢复 DynamoDB 表。",
      "C": "在 DynamoDB 表上配置删除保护。",
      "D": "在 DynamoDB 表上打开时间点恢复。"
    }
  },
  {
    "id": 728,
    "topic": "1",
    "question_en": "A company has an on-premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs. The solution must allow for immediate retrieval of data at no additional cost. How can these requirements be met?",
    "options_en": {
      "A": "Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.",
      "B": "Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.",
      "C": "Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.",
      "D": "Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3."
    },
    "correct_answer": "B",
    "vote_percentage": "56%",
    "question_cn": "一家公司本地数据中心即将耗尽存储容量。该公司希望将其存储基础设施迁移到 AWS，同时最大限度地降低带宽成本。该解决方案必须允许立即检索数据，且不产生额外费用。如何满足这些要求？",
    "options_cn": {
      "A": "部署 Amazon S3 Glacier Vault，并启用加速检索。为工作负载启用预置检索容量。",
      "B": "使用缓存卷部署 AWS Storage Gateway。使用 Storage Gateway 将数据存储在 Amazon S3 中，同时在本地保留经常访问的数据子集的副本。",
      "C": "使用存储卷部署 AWS Storage Gateway 以在本地存储数据。使用 Storage Gateway 异步备份数据的即时点快照到 Amazon S3。",
      "D": "部署 AWS Direct Connect 以连接本地数据中心。配置 AWS Storage Gateway 以在本地存储数据。使用 Storage Gateway 异步备份数据的即时点快照到 Amazon S3。"
    }
  },
  {
    "id": 729,
    "topic": "1",
    "question_en": "A company runs a three-tier web application in a VPC across multiple Availability Zones. Amazon EC2 instances run in an Auto Scaling group for the application tier. The company needs to make an automated scaling plan that will analyze each resource's daily and weekly historical workload trends. The configuration must scale resources appropriately according to both the forecast and live changes in utilization. Which scaling strategy should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Implement dynamic scaling with step scaling based on average CPU utilization from the EC2 instances.",
      "B": "Enable predictive scaling to forecast and scale. Configure dynamic scaling with target tracking",
      "C": "Create an automated scheduled scaling action based on the trafic patterns of the web application.",
      "D": "Set up a simple scaling policy. Increase the cooldown period based on the EC2 instance startup time."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其VPC中跨多个可用区运行一个三层Web应用程序。Amazon EC2实例在应用程序层的一个Auto Scaling组中运行。该公司需要制定一个自动化扩展计划，该计划将分析每个资源的每日和每周的历史工作负载趋势。该配置必须根据预测和利用率的实时变化来适当地扩展资源。解决方案架构师应该推荐哪种扩展策略来满足这些要求？",
    "options_cn": {
      "A": "实施基于EC2实例平均CPU利用率的阶梯式动态扩展。",
      "B": "启用预测式扩展以进行预测和扩展。使用目标跟踪配置动态扩展。",
      "C": "根据Web应用程序的流量模式创建自动计划的扩展操作。",
      "D": "设置一个简单的扩展策略。根据EC2实例启动时间增加冷却期。"
    }
  },
  {
    "id": 730,
    "topic": "1",
    "question_en": "A package delivery company has an application that uses Amazon EC2 instances and an Amazon Aurora MySQL DB cluster. As the application becomes more popular, EC2 instance usage increases only slightly. DB cluster usage increases at a much faster rate. The company adds a read replica, which reduces the DB cluster usage for a short period of time. However, the load continues to increase. The operations that cause the increase in DB cluster usage are all repeated read statements that are related to delivery details. The company needs to alleviate the effect of repeated reads on the DB cluster. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Implement an Amazon ElastiCache for Redis cluster between the application and the DB cluster.",
      "B": "Add an additional read replica to the DB cluster.",
      "C": "Configure Aurora Auto Scaling for the Aurora read replicas.",
      "D": "Modify the DB cluster to have multiple writer instances."
    },
    "correct_answer": "A",
    "vote_percentage": "86%",
    "question_cn": "一家包裹递送公司有一个使用 Amazon EC2 实例和 Amazon Aurora MySQL 数据库集群的应用程序。随着应用程序越来越受欢迎，EC2 实例的使用量略有增加。数据库集群的使用量以更快的速度增加。该公司添加了一个只读副本，这在短时间内减少了数据库集群的使用量。然而，负载持续增加。导致数据库集群使用量增加的操作都是与递送详细信息相关的重复读取语句。该公司需要减轻重复读取对数据库集群的影响。哪种解决方案将最经济高效地满足这些要求？",
    "options_cn": {
      "A": "在应用程序和数据库集群之间实施一个 Amazon ElastiCache for Redis 集群。",
      "B": "为数据库集群添加一个额外的只读副本。",
      "C": "为 Aurora 只读副本配置 Aurora Auto Scaling。",
      "D": "修改数据库集群以具有多个写入实例。"
    }
  },
  {
    "id": 731,
    "topic": "1",
    "question_en": "A company has an application that uses an Amazon DynamoDB table for storage. A solutions architect discovers that many requests to the table are not returning the latest data. The company's users have not reported any other issues with database performance. Latency is in an acceptable range. Which design change should the solutions architect recommend?",
    "options_en": {
      "A": "Add read replicas to the table.",
      "B": "Use a global secondary index (GSI).",
      "C": "Request strongly consistent reads for the table.",
      "D": "Request eventually consistent reads for the table."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个应用程序，使用 Amazon DynamoDB 表进行存储。一位解决方案架构师发现，许多对该表的请求没有返回最新的数据。该公司用户没有报告数据库性能方面的任何其他问题。延迟在可接受的范围内。解决方案架构师应该建议哪种设计更改？",
    "options_cn": {
      "A": "为该表添加读取副本。",
      "B": "使用全局二级索引 (GSI)。",
      "C": "为该表请求强一致性读取。",
      "D": "为该表请求最终一致性读取。"
    }
  },
  {
    "id": 732,
    "topic": "1",
    "question_en": "A company has deployed its application on Amazon EC2 instances with an Amazon RDS database. The company used the principle of least privilege to configure the database access credentials. The company's security team wants to protect the application and the database from SQL injection and other web-based attacks. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use security groups and network ACLs to secure the database and application servers.",
      "B": "Use AWS WAF to protect the application. Use RDS parameter groups to configure the security settings.",
      "C": "Use AWS Network Firewall to protect the application and the database.",
      "D": "Use different database accounts in the application code for different functions. Avoid granting excessive privileges to the database users."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司已将其应用程序部署在带有 Amazon RDS 数据库的 Amazon EC2 实例上。该公司使用最小权限原则来配置数据库访问凭据。该公司的安全团队希望保护应用程序和数据库免受 SQL 注入和其他基于 Web 的攻击。哪种解决方案将以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用安全组和网络 ACL 来保护数据库和应用程序服务器。",
      "B": "使用 AWS WAF 保护应用程序。使用 RDS 参数组来配置安全设置。",
      "C": "使用 AWS Network Firewall 来保护应用程序和数据库。",
      "D": "在应用程序代码中使用不同的数据库账户，用于不同的功能。避免向数据库用户授予过多的权限。"
    }
  },
  {
    "id": 733,
    "topic": "1",
    "question_en": "An ecommerce company runs applications in AWS accounts that are part of an organization in AWS Organizations. The applications run on Amazon Aurora PostgreSQL databases across all the accounts. The company needs to prevent malicious activity and must identify abnormal failed and incomplete login attempts to the databases. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Attach service control policies (SCPs) to the root of the organization to identity the failed login attempts.",
      "B": "Enable the Amazon RDS Protection feature in Amazon GuardDuty for the member accounts of the organization.",
      "C": "Publish the Aurora general logs to a log group in Amazon CloudWatch Logs. Export the log data to a central Amazon S3 bucket.",
      "D": "Publish all the Aurora PostgreSQL database events in AWS CloudTrail to a central Amazon S3 bucket."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家电子商务公司在其 AWS 账户中运行应用程序，这些账户是 AWS Organizations 组织的一部分。应用程序在所有账户的 Amazon Aurora PostgreSQL 数据库上运行。该公司需要防止恶意活动，并且必须识别数据库中异常的登录尝试失败和未完成的登录尝试。哪种解决方案将以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "将服务控制策略 (SCP) 附加到组织的根目录，以识别登录尝试失败的情况。",
      "B": "在组织的成员账户中启用 Amazon GuardDuty 的 Amazon RDS 保护功能。",
      "C": "将 Aurora 常规日志发布到 Amazon CloudWatch Logs 中的一个日志组。将日志数据导出到中央 Amazon S3 存储桶。",
      "D": "将所有 Aurora PostgreSQL 数据库事件发布到 AWS CloudTrail 中，并将其发布到中央 Amazon S3 存储桶。"
    }
  },
  {
    "id": 734,
    "topic": "1",
    "question_en": "A company has an AWS Direct Connect connection from its corporate data center to its VPC in the us-east-1 Region. The company recently acquired a corporation that has several VPCs and a Direct Connect connection between its on-premises data center and the eu-west-2 Region. The CIDR blocks for the VPCs of the company and the corporation do not overlap. The company requires connectivity between two Regions and the data centers. The company needs a solution that is scalable while reducing operational overhead. What should a solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Set up inter-Region VPC peering between the VPC in us-east-1 and the VPCs in eu-west-2.",
      "B": "Create private virtual interfaces from the Direct Connect connection in us-east-1 to the VPCs in eu-west-2.",
      "C": "Establish VPN appliances in a fully meshed VPN network hosted by Amazon EC2. Use AWS VPN CloudHub to send and receive data between the data centers and each VPC.",
      "D": "Connect the existing Direct Connect connection to a Direct Connect gateway. Route trafic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司通过 AWS Direct Connect 连接，将其企业数据中心连接到 us-east-1 区域的 VPC。该公司最近收购了一家公司，该公司拥有多个 VPC，并拥有一个 Direct Connect 连接，将其本地数据中心连接到 eu-west-2 区域。该公司和被收购公司的 VPC 的 CIDR 块不重叠。该公司需要在两个区域和数据中心之间建立连接。该公司需要一个可扩展的解决方案，同时减少运营开销。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在 us-east-1 中的 VPC 和 eu-west-2 中的 VPC 之间设置区域间 VPC 对等连接。",
      "B": "从 us-east-1 中的 Direct Connect 连接创建到 eu-west-2 中的 VPC 的私有虚拟接口。",
      "C": "在由 Amazon EC2 托管的全网状 VPN 网络中建立 VPN 设备。使用 AWS VPN CloudHub 在数据中心和每个 VPC 之间发送和接收数据。",
      "D": "将现有的 Direct Connect 连接到 Direct Connect 网关。将来自每个区域中 VPC 的虚拟私有网关的流量路由到 Direct Connect 网关。"
    }
  },
  {
    "id": 735,
    "topic": "1",
    "question_en": "A company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard. A solutions architect needs to design a solution that can handle large trafic spikes, process the mobile game updates in order of receipt, and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB.",
      "B": "Push score updates to Amazon Kinesis Data Streams. Process the updates with a fieet of Amazon EC2 instances set up for Auto Scaling. Store the processed updates in Amazon Redshift.",
      "C": "Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to process the updates. Store the processed updates in a SQL database running on Amazon EC2.",
      "D": "Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue. Use a fieet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue. Store the processed updates in an Amazon RDS Multi-AZ DB instance."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在开发一款手机游戏，该游戏将分数更新流式传输到后端处理器，然后在排行榜上发布结果。一位解决方案架构师需要设计一个解决方案，该解决方案能够处理大型流量峰值，按接收顺序处理手机游戏更新，并将已处理的更新存储在一个高可用性数据库中。该公司还希望最大限度地减少维护该解决方案所需的管理开销。解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "将分数更新推送到 Amazon Kinesis Data Streams。 使用 AWS Lambda 处理 Kinesis Data Streams 中的更新。 将已处理的更新存储在 Amazon DynamoDB 中。",
      "B": "将分数更新推送到 Amazon Kinesis Data Streams。使用一组设置为自动扩缩的 Amazon EC2 实例来处理更新。将已处理的更新存储在 Amazon Redshift 中。",
      "C": "将分数更新推送到 Amazon Simple Notification Service (Amazon SNS) 主题。 将 AWS Lambda 函数订阅到 SNS 主题以处理更新。将已处理的更新存储在 Amazon EC2 上运行的 SQL 数据库中。",
      "D": "将分数更新推送到 Amazon Simple Queue Service (Amazon SQS) 队列。 使用一组具有自动扩缩的 Amazon EC2 实例来处理 SQS 队列中的更新。 将已处理的更新存储在 Amazon RDS 多可用区数据库实例中。"
    }
  },
  {
    "id": 736,
    "topic": "1",
    "question_en": "A company has multiple AWS accounts with applications deployed in the us-west-2 Region. Application logs are stored within Amazon S3 buckets in each account. The company wants to build a centralized log analysis solution that uses a single S3 bucket. Logs must not leave us- west-2, and the company wants to incur minimal operational overhead. Which solution meets these requirements and is MOST cost-effective?",
    "options_en": {
      "A": "Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket.",
      "B": "Use S3 Same-Region Replication to replicate logs from the S3 buckets to another S3 bucket in us-west-2. Use this S3 bucket for log analysis.",
      "C": "Write a script that uses the PutObject API operation every day to copy the entire contents of the buckets to another S3 bucket in us- west-2. Use this S3 bucket for log analysis.",
      "D": "Write AWS Lambda functions in these accounts that are triggered every time logs are delivered to the S3 buckets (s3:ObjectCreated:* event). Copy the logs to another S3 bucket in us-west-2. Use this S3 bucket for log analysis."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有多个 AWS 账户，其应用程序部署在 us-west-2 区域。应用程序日志存储在每个账户的 Amazon S3 存储桶中。该公司希望构建一个使用单个 S3 存储桶的集中式日志分析解决方案。日志不得离开 us-west-2，并且该公司希望产生最少的运营开销。以下哪个解决方案满足这些要求并且最具成本效益？",
    "options_cn": {
      "A": "创建一个 S3 生命周期策略，将对象从其中一个应用程序 S3 存储桶复制到集中式 S3 存储桶。",
      "B": "使用 S3 同区域复制将日志从 S3 存储桶复制到 us-west-2 中的另一个 S3 存储桶。使用此 S3 存储桶进行日志分析。",
      "C": "编写一个脚本，每天使用 PutObject API 操作将存储桶的全部内容复制到 us-west-2 中的另一个 S3 存储桶。使用此 S3 存储桶进行日志分析。",
      "D": "在这些账户中编写 AWS Lambda 函数，这些函数在每次将日志传递到 S3 存储桶（s3:ObjectCreated:* 事件）时触发。将日志复制到 us-west-2 中的另一个 S3 存储桶。使用此 S3 存储桶进行日志分析。"
    }
  },
  {
    "id": 737,
    "topic": "1",
    "question_en": "A company has an application that delivers on-demand training videos to students around the world. The application also allows authorized content developers to upload videos. The data is stored in an Amazon S3 bucket in the us-east-2 Region. The company has created an S3 bucket in the eu-west-2 Region and an S3 bucket in the ap-southeast-1 Region. The company wants to replicate the data to the new S3 buckets. The company needs to minimize latency for developers who upload videos and students who stream videos near eu-west-2 and ap-southeast-1. Which combination of steps will meet these requirements with the FEWEST changes to the application? (Choose two.)",
    "options_en": {
      "A": "Configure one-way replication from the us-east-2 S3 bucket to the eu-west-2 S3 bucket. Configure one-way replication from the us-east-2 S3 bucket to the ap-southeast-1 S3 bucket.",
      "B": "Configure one-way replication from the us-east-2 S3 bucket to the eu-west-2 S3 bucket. Configure one-way replication from the eu-west- 2 S3 bucket to the ap-southeast-1 S3 bucket.",
      "C": "Configure two-way (bidirectional) replication among the S3 buckets that are in all three Regions.",
      "D": "Create an S3 Multi-Region Access Point. Modify the application to use the Amazon Resource Name (ARN) of the Multi-Region Access Point for video streaming. Do not modify the application for video uploads",
      "E": "Create an S3 Multi-Region Access Point. Modify the application to use the Amazon Resource Name (ARN) of the Multi-Region Access Point for video streaming and uploads."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司有一个应用程序，为世界各地的学生提供点播培训视频。该应用程序还允许授权内容开发人员上传视频。数据存储在 us-east-2 区域的 Amazon S3 存储桶中。该公司已在 eu-west-2 区域和 ap-southeast-1 区域创建了 S3 存储桶。该公司希望将数据复制到新的 S3 存储桶。该公司需要最大限度地减少靠近 eu-west-2 和 ap-southeast-1 的开发人员上传视频和学生流式传输视频的延迟。以下哪种组合步骤将以对应用程序的更改最少的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "配置从 us-east-2 S3 存储桶到 eu-west-2 S3 存储桶的单向复制。配置从 us-east-2 S3 存储桶到 ap-southeast-1 S3 存储桶的单向复制。",
      "B": "配置从 us-east-2 S3 存储桶到 eu-west-2 S3 存储桶的单向复制。配置从 eu-west-2 S3 存储桶到 ap-southeast-1 S3 存储桶的单向复制。",
      "C": "在所有三个区域的 S3 存储桶之间配置双向复制。",
      "D": "创建一个 S3 多区域访问点。修改应用程序以使用多区域访问点的 Amazon Resource Name (ARN) 进行视频流。不要修改应用程序进行视频上传。",
      "E": "创建一个 S3 多区域访问点。修改应用程序以使用多区域访问点的 Amazon Resource Name (ARN) 进行视频流和上传。"
    }
  },
  {
    "id": 738,
    "topic": "1",
    "question_en": "A company has a new mobile app. Anywhere in the world, users can see local news on topics they choose. Users also can post photos and videos from inside the app. Users access content often in the first minutes after the content is posted. New content quickly replaces older content, and then the older content disappears. The local nature of the news means that users consume 90% of the content within the AWS Region where it is uploaded. Which solution will optimize the user experience by providing the LOWEST latency for content uploads?",
    "options_en": {
      "A": "Upload and store content in Amazon S3. Use Amazon CloudFront for the uploads.",
      "B": "Upload and store content in Amazon S3. Use S3 Transfer Acceleration for the uploads.",
      "C": "Upload content to Amazon EC2 instances in the Region that is closest to the user. Copy the data to Amazon S3.",
      "D": "Upload and store content in Amazon S3 in the Region that is closest to the user. Use multiple distributions of Amazon CloudFront."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "题目 12\n题干: 一家公司有一个新的移动应用程序。在世界任何地方，用户都可以看到他们选择的本地新闻。用户还可以从应用程序内部发布照片和视频。用户经常在发布内容后的几分钟内访问内容。新内容会很快替换旧内容，然后旧内容会消失。新闻的本地性质意味着用户在上传内容的 AWS 区域内消耗了 90% 的内容。哪个解决方案将通过为内容上传提供最低的延迟来优化用户体验？\n选项:\n   A. 上传并将内容存储在 Amazon S3 中。使用 Amazon CloudFront 进行上传。\n   B. 上传并将内容存储在 Amazon S3 中。使用 S3 Transfer Acceleration 进行上传。\n   C. 将内容上传到最靠近用户的区域中的 Amazon EC2 实例。将数据复制到 Amazon S3。\n   D. 在最靠近用户的区域中的 Amazon S3 中上传和存储内容。使用 Amazon CloudFront 的多个分发。",
    "options_cn": {
      "A": "上传并将内容存储在 Amazon S3 中。使用 Amazon CloudFront 进行上传。",
      "B": "上传并将内容存储在 Amazon S3 中。使用 S3 Transfer Acceleration 进行上传。",
      "C": "将内容上传到最靠近用户的区域中的 Amazon EC2 实例。将数据复制到 Amazon S3。",
      "D": "在最靠近用户的区域中的 Amazon S3 中上传和存储内容。使用 Amazon CloudFront 的多个分发。"
    }
  },
  {
    "id": 739,
    "topic": "1",
    "question_en": "A company is building a new application that uses serverless architecture. The architecture will consist of an Amazon API Gateway REST API and AWS Lambda functions to manage incoming requests. The company wants to add a service that can send messages received from the API Gateway REST API to multiple target Lambda functions for processing. The service must offer message filtering that gives the target Lambda functions the ability to receive only the messages the functions need. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Send the requests from the API Gateway REST API to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon Simple Queue Service (Amazon SQS) queues to the SNS topic. Configure the target Lambda functions to poll the different SQS queues.",
      "B": "Send the requests from the API Gateway REST API to Amazon EventBridge. Configure EventBridge to invoke the target Lambda functions.",
      "C": "Send the requests from the API Gateway REST API to Amazon Managed Streaming for Apache Kafka (Amazon MSK). Configure Amazon MSK to publish the messages to the target Lambda functions.",
      "D": "Send the requests from the API Gateway REST API to multiple Amazon Simple Queue Service (Amazon SQS) queues. Configure the target Lambda functions to poll the different SQS queues."
    },
    "correct_answer": "D",
    "vote_percentage": "68%",
    "question_cn": "题目 13\n题干: 一家公司正在构建一个使用无服务器架构的新应用程序。该架构将由 Amazon API Gateway REST API 和 AWS Lambda 函数组成，以管理传入的请求。该公司希望添加一项服务，该服务可以将从 API Gateway REST API 接收的消息发送到多个目标 Lambda 函数进行处理。该服务必须提供消息筛选，使目标 Lambda 函数能够仅接收函数需要的消息。哪个解决方案将以最低的运营开销满足这些要求？\n选项:\n   A. 将 API Gateway REST API 中的请求发送到 Amazon Simple Notification Service (Amazon SNS) 主题。将 Amazon Simple Queue Service (Amazon SQS) 队列订阅到 SNS 主题。配置目标 Lambda 函数以轮询不同的 SQS 队列。\n   B. 将 API Gateway REST API 中的请求发送到 Amazon EventBridge。配置 EventBridge 以调用目标 Lambda 函数。\n   C. 将 API Gateway REST API 中的请求发送到 Amazon Managed Streaming for Apache Kafka (Amazon MSK)。配置 Amazon MSK 以将消息发布到目标 Lambda 函数。\n   D. 将 API Gateway REST API 中的请求发送到多个 Amazon Simple Queue Service (Amazon SQS) 队列。配置目标 Lambda 函数以轮询不同的 SQS 队列。",
    "options_cn": {
      "A": "将 API Gateway REST API 中的请求发送到 Amazon Simple Notification Service (Amazon SNS) 主题。将 Amazon Simple Queue Service (Amazon SQS) 队列订阅到 SNS 主题。配置目标 Lambda 函数以轮询不同的 SQS 队列。",
      "B": "将 API Gateway REST API 中的请求发送到 Amazon EventBridge。配置 EventBridge 以调用目标 Lambda 函数。",
      "C": "将 API Gateway REST API 中的请求发送到 Amazon Managed Streaming for Apache Kafka (Amazon MSK)。配置 Amazon MSK 以将消息发布到目标 Lambda 函数。",
      "D": "将 API Gateway REST API 中的请求发送到多个 Amazon Simple Queue Service (Amazon SQS) 队列。配置目标 Lambda 函数以轮询不同的 SQS 队列。"
    }
  },
  {
    "id": 740,
    "topic": "1",
    "question_en": "A company migrated millions of archival files to Amazon S3. A solutions architect needs to implement a solution that will encrypt all the archival data by using a customer-provided key. The solution must encrypt existing unencrypted objects and future objects. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a list of unencrypted objects by filtering an Amazon S3 Inventory report. Configure an S3 Batch Operations job to encrypt the objects from the list with a server-side encryption with a customer-provided key (SSE-C). Configure the S3 default encryption feature to use a server-side encryption with a customer-provided key (SSE-C).",
      "B": "Use S3 Storage Lens metrics to identify unencrypted S3 buckets. Configure the S3 default encryption feature to use a server-side encryption with AWS KMS keys (SSE-KMS).",
      "C": "Create a list of unencrypted objects by filtering the AWS usage report for Amazon S3. Configure an AWS Batch job to encrypt the objects from the list with a server-side encryption with AWS KMS keys (SSE-KMS). Configure the S3 default encryption feature to use a server-side encryption with AWS KMS keys (SSE-KMS).",
      "D": "Create a list of unencrypted objects by filtering the AWS usage report for Amazon S3. Configure the S3 default encryption feature to use a server-side encryption with a customer-provided key (SSE-C)."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司将数百万个存档文件迁移到 Amazon S3。 一位解决方案架构师需要实施一个解决方案，该解决方案将使用客户提供的密钥加密所有存档数据。 该解决方案必须加密现有的未加密对象和未来的对象。 哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过过滤 Amazon S3 清单报告创建未加密对象的列表。配置一个 S3 批量操作作业，使用客户提供的密钥（SSE-C）进行服务器端加密来加密列表中的对象。配置 S3 默认加密功能以使用客户提供的密钥（SSE-C）进行服务器端加密。",
      "B": "使用 S3 Storage Lens 指标来识别未加密的 S3 存储桶。 配置 S3 默认加密功能以使用 AWS KMS 密钥（SSE-KMS）进行服务器端加密。",
      "C": "通过过滤 Amazon S3 的 AWS 使用情况报告来创建未加密对象的列表。 配置一个 AWS Batch 作业，使用 AWS KMS 密钥（SSE-KMS）进行服务器端加密来加密列表中的对象。 配置 S3 默认加密功能以使用 AWS KMS 密钥（SSE-KMS）进行服务器端加密。",
      "D": "通过过滤 Amazon S3 的 AWS 使用情况报告来创建未加密对象的列表。配置 S3 默认加密功能以使用客户提供的密钥（SSE-C）进行服务器端加密。"
    }
  },
  {
    "id": 741,
    "topic": "1",
    "question_en": "The DNS provider that hosts a company's domain name records is experiencing outages that cause service disruption for a website running on AWS. The company needs to migrate to a more resilient managed DNS service and wants the service to run on AWS. What should a solutions architect do to rapidly migrate the DNS hosting service?",
    "options_en": {
      "A": "Create an Amazon Route 53 public hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.",
      "B": "Create an Amazon Route 53 private hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.",
      "C": "Create a Simple AD directory in AWS. Enable zone transfer between the DNS provider and AWS Directory Service for Microsoft Active Directory for the domain records.",
      "D": "Create an Amazon Route 53 Resolver inbound endpoint in the VPC. Specify the IP addresses that the provider's DNS will forward DNS queries to. Configure the provider's DNS to forward DNS queries for the domain to the IP addresses that are specified in the inbound endpoint."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "托管公司域名记录的 DNS 提供商正经历中断，导致在 AWS 上运行的网站服务中断。该公司需要迁移到更具弹性的托管 DNS 服务，并且希望该服务在 AWS 上运行。解决方案架构师应该怎么做才能快速迁移 DNS 托管服务？",
    "options_cn": {
      "A": "为域名创建一个 Amazon Route 53 公共托管区域。导入包含先前提供商托管的域记录的区域文件。",
      "B": "为域名创建一个 Amazon Route 53 私有托管区域。导入包含先前提供商托管的域记录的区域文件。",
      "C": "在 AWS 中创建一个 Simple AD 目录。在 DNS 提供商和 AWS Directory Service for Microsoft Active Directory 之间为域记录启用区域传输。",
      "D": "在 VPC 中创建一个 Amazon Route 53 Resolver 入站端点。指定提供商的 DNS 将 DNS 查询转发到的 IP 地址。配置提供商的 DNS，以将域的 DNS 查询转发到入站端点中指定的 IP 地址。"
    }
  },
  {
    "id": 742,
    "topic": "1",
    "question_en": "A company is building an application on AWS that connects to an Amazon RDS database. The company wants to manage the application configuration and to securely store and retrieve credentials for the database and other services. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Use AWS AppConfig to store and manage the application configuration. Use AWS Secrets Manager to store and retrieve the credentials.",
      "B": "Use AWS Lambda to store and manage the application configuration. Use AWS Systems Manager Parameter Store to store and retrieve the credentials.",
      "C": "Use an encrypted application configuration file. Store the file in Amazon S3 for the application configuration. Create another S3 file to store and retrieve the credentials.",
      "D": "Use AWS AppConfig to store and manage the application configuration. Use Amazon RDS to store and retrieve the credentials."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 上构建一个应用程序，该应用程序连接到 Amazon RDS 数据库。该公司希望管理应用程序配置，并安全地存储和检索数据库和其他服务的凭据。哪种解决方案以最小的管理开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS AppConfig 存储和管理应用程序配置。使用 AWS Secrets Manager 存储和检索凭据。",
      "B": "使用 AWS Lambda 存储和管理应用程序配置。使用 AWS Systems Manager Parameter Store 存储和检索凭据。",
      "C": "使用加密的应用程序配置文件。将文件存储在 Amazon S3 中用于应用程序配置。创建另一个 S3 文件来存储和检索凭据。",
      "D": "使用 AWS AppConfig 存储和管理应用程序配置。使用 Amazon RDS 存储和检索凭据。"
    }
  },
  {
    "id": 743,
    "topic": "1",
    "question_en": "To meet security requirements, a company needs to encrypt all of its application data in transit while communicating with an Amazon RDS MySQL DB instance. A recent security audit revealed that encryption at rest is enabled using AWS Key Management Service (AWS KMS), but data in transit is not enabled. What should a solutions architect do to satisfy the security requirements?",
    "options_en": {
      "A": "Enable IAM database authentication on the database.",
      "B": "Provide self-signed certificates. Use the certificates in all connections to the RDS instance.",
      "C": "Take a snapshot of the RDS instance. Restore the snapshot to a new instance with encryption enabled.",
      "D": "Download AWS-provided root certificates. Provide the certificates in all connections to the RDS instance."
    },
    "correct_answer": "A",
    "vote_percentage": "81%",
    "question_cn": "为了满足安全要求，一家公司需要对所有应用程序在与 Amazon RDS MySQL 数据库实例通信时传输的数据进行加密。最近的安全审计显示，静态加密已使用 AWS Key Management Service (AWS KMS) 启用，但传输中的数据未启用。解决方案架构师应该怎么做才能满足安全要求？",
    "options_cn": {
      "A": "在数据库上启用 IAM 数据库身份验证。",
      "B": "提供自签名证书。在与 RDS 实例的所有连接中使用这些证书。",
      "C": "拍摄 RDS 实例的快照。将快照恢复到启用了加密的新实例。",
      "D": "下载 AWS 提供的根证书。在与 RDS 实例的所有连接中使用这些证书。"
    }
  },
  {
    "id": 744,
    "topic": "1",
    "question_en": "A company is designing a new web service that will run on Amazon EC2 instances behind an Elastic Load Balancing (ELB) load balancer. However, many of the web service clients can only reach IP addresses authorized on their firewalls. What should a solutions architect recommend to meet the clients’ needs?",
    "options_en": {
      "A": "A Network Load Balancer with an associated Elastic IP address.",
      "B": "An Application Load Balancer with an associated Elastic IP address.",
      "C": "An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address.",
      "D": "An EC2 instance with a public IP address running as a proxy in front of the load balancer."
    },
    "correct_answer": "D",
    "vote_percentage": "92%",
    "question_cn": "一家公司正在设计一个新的 Web 服务，该服务将在弹性负载均衡（ELB）负载均衡器后面的 Amazon EC2 实例上运行。但是，许多 Web 服务客户端只能访问其防火墙上授权的 IP 地址。 解决方案架构师应该推荐什么来满足客户的需求？",
    "options_cn": {
      "A": "带有相关弹性 IP 地址的网络负载均衡器。",
      "B": "带有相关弹性 IP 地址的 Application Load Balancer。",
      "C": "在 Amazon Route 53 托管区域中指向弹性 IP 地址的 A 记录。",
      "D": "一个 EC2 实例，带有公共 IP 地址，作为负载均衡器之前的代理运行。"
    }
  },
  {
    "id": 745,
    "topic": "1",
    "question_en": "A company has established a new AWS account. The account is newly provisioned and no changes have been made to the default settings. The company is concerned about the security of the AWS account root user. What should be done to secure the root user?",
    "options_en": {
      "A": "Create IAM users for daily administrative tasks. Disable the root user.",
      "B": "Create IAM users for daily administrative tasks. Enable multi-factor authentication on the root user.",
      "C": "Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console.",
      "D": "Provide the root user credentials to the most senior solutions architect. Have the solutions architect use the root user for daily administration tasks."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司建立了一个新的 AWS 账户。该账户是新配置的，并且没有对默认设置进行任何更改。该公司担心 AWS 账户根用户的安全性。应该怎么做来保护根用户？",
    "options_cn": {
      "A": "为日常管理任务创建 IAM 用户。禁用根用户。",
      "B": "为日常管理任务创建 IAM 用户。在根用户上启用多因素身份验证。",
      "C": "为根用户生成访问密钥。使用访问密钥进行日常管理任务，而不是 AWS 管理控制台。",
      "D": "将根用户凭据提供给最资深解决方案架构师。让解决方案架构师使用根用户进行日常管理任务。"
    }
  },
  {
    "id": 746,
    "topic": "1",
    "question_en": "A company is deploying an application that processes streaming data in near-real time. The company plans to use Amazon EC2 instances for the workload. The network architecture must be configurable to provide the lowest possible latency between nodes. Which combination of network solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Enable and configure enhanced networking on each EC2 instance.",
      "B": "Group the EC2 instances in separate accounts.",
      "C": "Run the EC2 instances in a cluster placement group.",
      "D": "Attach multiple elastic network interfaces to each EC2 instanc",
      "E": "E. Use Amazon Elastic Block Store (Amazon EBS) optimized instance types."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在部署一个应用程序，该应用程序近乎实时地处理流数据。该公司计划使用 Amazon EC2 实例来处理工作负载。网络架构必须可配置，以在节点之间提供尽可能低的延迟。哪种网络解决方案组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在每个 EC2 实例上启用并配置增强型网络。",
      "B": "将 EC2 实例分组到不同的账户中。",
      "C": "在集群放置组中运行 EC2 实例。",
      "D": "将多个弹性网络接口附加到每个 EC2 实例。",
      "E": "使用 Amazon Elastic Block Store (Amazon EBS) 优化实例类型。"
    }
  },
  {
    "id": 747,
    "topic": "1",
    "question_en": "A financial services company wants to shut down two data centers and migrate more than 100 TB of data to AWS. The data has an intricate directory structure with millions of small files stored in deep hierarchies of subfolders. Most of the data is unstructured, and the company’s file storage consists of SMB-based storage types from multiple vendors. The company does not want to change its applications to access the data after migration. What should a solutions architect do to meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Direct Connect to migrate the data to Amazon S3.",
      "B": "Use AWS DataSync to migrate the data to Amazon FSx for Lustre.",
      "C": "Use AWS DataSync to migrate the data to Amazon FSx for Windows File Server.",
      "D": "Use AWS Direct Connect to migrate the data on-premises file storage to an AWS Storage Gateway volume gateway."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家金融服务公司希望关闭两个数据中心，并将超过 100 TB 的数据迁移到 AWS。这些数据具有复杂的目录结构，其中数百万个小文件存储在深层次的子文件夹层次结构中。大多数数据是非结构化的，并且该公司的文件存储由来自多个供应商的基于 SMB 的存储类型组成。该公司不想在迁移后更改其应用程序以访问数据。解决方案架构师应该怎么做才能以最少的运营开销来满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Direct Connect 将数据迁移到 Amazon S3。",
      "B": "使用 AWS DataSync 将数据迁移到 Amazon FSx for Lustre。",
      "C": "使用 AWS DataSync 将数据迁移到 Amazon FSx for Windows File Server。",
      "D": "使用 AWS Direct Connect 将本地文件存储中的数据迁移到 AWS Storage Gateway 卷网关。"
    }
  },
  {
    "id": 748,
    "topic": "1",
    "question_en": "A company uses an organization in AWS Organizations to manage AWS accounts that contain applications. The company sets up a dedicated monitoring member account in the organization. The company wants to query and visualize observability data across the accounts by using Amazon CloudWatch. Which solution will meet these requirements?",
    "options_en": {
      "A": "Enable CloudWatch cross-account observability for the monitoring account. Deploy an AWS CloudFormation template provided by the monitoring account in each AWS account to share the data with the monitoring account.",
      "B": "Set up service control policies (SCPs) to provide access to CloudWatch in the monitoring account under the Organizations root organizational unit (OU).",
      "C": "Configure a new IAM user in the monitoring account. In each AWS account, configure an IAM policy to have access to query and visualize the CloudWatch data in the account. Attach the new IAM policy to the new IAM user.",
      "D": "Create a new IAM user in the monitoring account. Create cross-account IAM policies in each AWS account. Attach the IAM policies to the new IAM user."
    },
    "correct_answer": "C",
    "vote_percentage": "86%",
    "question_cn": "一家公司使用 AWS Organizations 中的一个组织来管理包含应用程序的 AWS 账户。该公司在组织中设置了一个专门的监控成员账户。该公司希望使用 Amazon CloudWatch 查询和可视化跨账户的可观察性数据。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为监控账户打开 CloudWatch 跨账户可观察性。在每个 AWS 账户中部署监控账户提供的 AWS CloudFormation 模板，以便与监控账户共享数据。",
      "B": "设置服务控制策略 (SCP)，以在 Organizations 根组织单元 (OU) 下为监控账户提供对 CloudWatch 的访问权限。",
      "C": "在监控账户中配置一个新的 IAM 用户。在每个 AWS 账户中，配置一个 IAM 策略，以便有权查询和可视化该账户中的 CloudWatch 数据。将新的 IAM 策略附加到新的 IAM 用户。",
      "D": "在监控账户中创建一个新的 IAM 用户。在每个 AWS 账户中创建跨账户 IAM 策略。将 IAM 策略附加到新的 IAM 用户。"
    }
  },
  {
    "id": 749,
    "topic": "1",
    "question_en": "A company’s website is used to sell products to the public. The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). There is also an Amazon CloudFront distribution, and AWS WAF is being used to protect against SQL injection attacks. The ALB is the origin for the CloudFront distribution. A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website. What should a solutions architect do to protect the application?",
    "options_en": {
      "A": "Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address.",
      "B": "Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address.",
      "C": "Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address.",
      "D": "Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address."
    },
    "correct_answer": "A",
    "vote_percentage": "81%",
    "question_cn": "一家公司的网站用于向公众销售产品。该网站在 Application Load Balancer (ALB) 之后，在 Auto Scaling 组中的 Amazon EC2 实例上运行。 还有一个 Amazon CloudFront 分发，并且正在使用 AWS WAF 来防御 SQL 注入攻击。 ALB 是 CloudFront 分发的源。 最近对安全日志的审查显示了一个需要阻止访问该网站的外部恶意 IP。 解决方案架构师应该怎么做来保护应用程序？",
    "options_cn": {
      "A": "修改 CloudFront 分发上的网络 ACL，以添加拒绝恶意 IP 地址的规则。",
      "B": "修改 AWS WAF 的配置，以添加 IP 匹配条件来阻止恶意 IP 地址。",
      "C": "修改 ALB 之后的目标组中 EC2 实例的网络 ACL，以拒绝恶意 IP 地址。",
      "D": "修改 ALB 之后的目标组中 EC2 实例的安全组，以拒绝恶意 IP 地址。"
    }
  },
  {
    "id": 750,
    "topic": "1",
    "question_en": "A company sets up an organization in AWS Organizations that contains 10 AWS accounts. A solutions architect must design a solution to provide access to the accounts for several thousand employees. The company has an existing identity provider (IdP). The company wants to use the existing IdP for authentication to AWS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create IAM users for the employees in the required AWS accounts. Connect IAM users to the existing IdP. Configure federated authentication for the IAM users.",
      "B": "Set up AWS account root users with user email addresses and passwords that are synchronized from the existing IdP.",
      "C": "Configure AWS IAM Identity Center (AWS Single Sign-On). Connect IAM Identity Center to the existing IdP. Provision users and groups from the existing IdP.",
      "D": "Use AWS Resource Access Manager (AWS RAM) to share access to the AWS accounts with the users in the existing IdP."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS Organizations 中设置了一个组织，其中包含 10 个 AWS 账户。 一位解决方案架构师必须设计一个解决方案，为数千名员工提供对这些账户的访问权限。该公司有一个现有的身份提供商 (IdP)。该公司希望使用现有的 IdP 进行 AWS 身份验证。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在所需的 AWS 账户中为员工创建 IAM 用户。将 IAM 用户连接到现有的 IdP。为 IAM 用户配置联合身份验证。",
      "B": "使用从现有的 IdP 同步的用户电子邮件地址和密码设置 AWS 账户根用户。",
      "C": "配置 AWS IAM Identity Center (AWS Single Sign-On)。将 IAM Identity Center 连接到现有的 IdP。从现有的 IdP 预置用户和组。",
      "D": "使用 AWS Resource Access Manager (AWS RAM) 与现有的 IdP 中的用户共享对 AWS 账户的访问权限。"
    }
  },
  {
    "id": 751,
    "topic": "1",
    "question_en": "A solutions architect is designing an AWS Identity and Access Management (IAM) authorization model for a company's AWS account. The company has designated five specific employees to have full access to AWS services and resources in the AWS account. The solutions architect has created an IAM user for each of the five designated employees and has created an IAM user group. Which solution will meet these requirements?",
    "options_en": {
      "A": "Attach the AdministratorAccess resource-based policy to the IAM user group. Place each of the five designated employee IAM users in the IAM user group.",
      "B": "Attach the SystemAdministrator identity-based policy to the IAM user group. Place each of the five designated employee IAM users in the IAM user group.",
      "C": "Attach the AdministratorAccess identity-based policy to the IAM user group. Place each of the five designated employee IAM users in the IAM user group.",
      "D": "Attach the SystemAdministrator resource-based policy to the IAM user group. Place each of the five designated employee IAM users in the IAM user group."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在为公司 AWS 账户设计 AWS Identity and Access Management (IAM) 授权模型。该公司已指定五名特定员工完全访问 AWS 账户中的 AWS 服务和资源。解决方案架构师为这五名指定员工中的每位创建了一个 IAM 用户，并创建了一个 IAM 用户组。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 AdministratorAccess 基于资源的策略附加到 IAM 用户组。将五名指定员工的每个 IAM 用户放入 IAM 用户组。",
      "B": "将 SystemAdministrator 基于身份的策略附加到 IAM 用户组。将五名指定员工的每个 IAM 用户放入 IAM 用户组。",
      "C": "将 AdministratorAccess 基于身份的策略附加到 IAM 用户组。将五名指定员工的每个 IAM 用户放入 IAM 用户组。",
      "D": "将 SystemAdministrator 基于资源的策略附加到 IAM 用户组。将五名指定员工的每个 IAM 用户放入 IAM 用户组。"
    }
  },
  {
    "id": 752,
    "topic": "1",
    "question_en": "A company has a multi-tier payment processing application that is based on virtual machines (VMs). The communication between the tiers occurs asynchronously through a third-party middleware solution that guarantees exactly-once delivery. The company needs a solution that requires the least amount of infrastructure management. The solution must guarantee exactly-once delivery for application messaging. Which combination of actions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Lambda for the compute layers in the architecture.",
      "B": "Use Amazon EC2 instances for the compute layers in the architecture.",
      "C": "Use Amazon Simple Notification Service (Amazon SNS) as the messaging component between the compute layers.",
      "D": "Use Amazon Simple Queue Service (Amazon SQS) FIFO queues as the messaging component between the compute layers",
      "E": "Use containers that are based on Amazon Elastic Kubernetes Service (Amazon EKS) for the compute layers in the architecture."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个基于虚拟机 (VM) 的多层支付处理应用程序。各层之间的通信通过第三方中间件解决方案异步进行，该解决方案保证了仅一次交付。该公司需要一个基础设施管理需求最少的解决方案。该解决方案必须保证应用程序消息传递的仅一次交付。哪两种操作的组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在架构中使用 AWS Lambda 作为计算层。",
      "B": "在架构中使用 Amazon EC2 实例作为计算层。",
      "C": "使用 Amazon Simple Notification Service (Amazon SNS) 作为计算层之间的消息传递组件。",
      "D": "使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列作为计算层之间的消息传递组件。",
      "E": "在架构中使用基于 Amazon Elastic Kubernetes Service (Amazon EKS) 的容器作为计算层。"
    }
  },
  {
    "id": 753,
    "topic": "1",
    "question_en": "A company has a nightly batch processing routine that analyzes report files that an on-premises file system receives daily through SFTP. The company wants to move the solution to the AWS Cloud. The solution must be highly available and resilient. The solution also must minimize operational effort. Which solution meets these requirements?",
    "options_en": {
      "A": "Deploy AWS Transfer for SFTP and an Amazon Elastic File System (Amazon EFS) file system for storage. Use an Amazon EC2 instance in an Auto Scaling group with a scheduled scaling policy to run the batch operation.",
      "B": "Deploy an Amazon EC2 instance that runs Linux and an SFTP service. Use an Amazon Elastic Block Store (Amazon EBS) volume for storage. Use an Auto Scaling group with the minimum number of instances and desired number of instances set to 1.",
      "C": "Deploy an Amazon EC2 instance that runs Linux and an SFTP service. Use an Amazon Elastic File System (Amazon EFS) file system for storage. Use an Auto Scaling group with the minimum number of instances and desired number of instances set to 1.",
      "D": "Deploy AWS Transfer for SFTP and an Amazon S3 bucket for storage. Modify the application to pull the batch files from Amazon S3 to an Amazon EC2 instance for processing. Use an EC2 instance in an Auto Scaling group with a scheduled scaling policy to run the batch operation."
    },
    "correct_answer": "B",
    "vote_percentage": "63%",
    "question_cn": "题目 14\n题干: 一家公司有一个夜间批处理例程，该例程分析本地文件系统每天通过 SFTP 接收的报告文件。该公司希望将解决方案转移到 AWS Cloud。该解决方案必须具有高可用性和弹性。该解决方案还必须最大限度地减少运营工作量。哪个解决方案满足这些要求？\n选项:\n   A. 部署 AWS Transfer for SFTP 和一个 Amazon Elastic File System (Amazon EFS) 文件系统进行存储。使用 Auto Scaling 组中的 Amazon EC2 实例（具有计划的扩展策略）来运行批处理操作。\n   B. 部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例。使用 Amazon Elastic Block Store (Amazon EBS) 卷进行存储。使用 Auto Scaling 组，并将实例的最小数量和所需实例数量设置为 1。\n   C. 部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例。使用 Amazon Elastic File System (Amazon EFS) 文件系统进行存储。使用 Auto Scaling 组，并将实例的最小数量和所需实例数量设置为 1。\n   D. 部署 AWS Transfer for SFTP 和一个 Amazon S3 存储桶进行存储。修改应用程序，从 Amazon S3 将批处理文件拉取到 Amazon EC2 实例进行处理。使用 Auto Scaling 组中的 EC2 实例（具有计划的扩展策略）来运行批处理操作。",
    "options_cn": {
      "A": "部署 AWS Transfer for SFTP 和一个 Amazon Elastic File System (Amazon EFS) 文件系统进行存储。使用 Auto Scaling 组中的 Amazon EC2 实例（具有计划的扩展策略）来运行批处理操作。",
      "B": "部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例。使用 Amazon Elastic Block Store (Amazon EBS) 卷进行存储。使用 Auto Scaling 组，并将实例的最小数量和所需实例数量设置为 1。",
      "C": "部署一个运行 Linux 和 SFTP 服务的 Amazon EC2 实例。使用 Amazon Elastic File System (Amazon EFS) 文件系统进行存储。使用 Auto Scaling 组，并将实例的最小数量和所需实例数量设置为 1。",
      "D": "部署 AWS Transfer for SFTP 和一个 Amazon S3 存储桶进行存储。修改应用程序，从 Amazon S3 将批处理文件拉取到 Amazon EC2 实例进行处理。使用 Auto Scaling 组中的 EC2 实例（具有计划的扩展策略）来运行批处理操作。"
    }
  },
  {
    "id": 754,
    "topic": "1",
    "question_en": "A company has users all around the world accessing its HTTP-based application deployed on Amazon EC2 instances in multiple AWS Regions. The company wants to improve the availability and performance of the application. The company also wants to protect the application against common web exploits that may affect availability, compromise security, or consume excessive resources. Static IP addresses are required. What should a solutions architect recommend to accomplish this?",
    "options_en": {
      "A": "Put the EC2 instances behind Network Load Balancers (NLBs) in each Region. Deploy AWS WAF on the NLBs. Create an accelerator using AWS Global Accelerator and register the NLBs as endpoints.",
      "B": "Put the EC2 instances behind Application Load Balancers (ALBs) in each Region. Deploy AWS WAF on the ALBs. Create an accelerator using AWS Global Accelerator and register the ALBs as endpoints.",
      "C": "Put the EC2 instances behind Network Load Balancers (NLBs) in each Region. Deploy AWS WAF on the NLBs. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the NLBs.",
      "D": "Put the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the ALBs. Deploy AWS WAF on the CloudFront distribution."
    },
    "correct_answer": "C",
    "vote_percentage": "83%",
    "question_cn": "题目 15\n题干: 一家公司拥有遍布全球的用户，他们通过 HTTP 访问部署在多个 AWS 区域中的 Amazon EC2 实例上的基于 HTTP 的应用程序。该公司希望提高应用程序的可用性和性能。该公司还希望保护应用程序免受可能影响可用性、损害安全性或消耗过多资源的常见 Web 漏洞的侵害。需要静态 IP 地址。解决方案架构师应建议采取什么措施来实现此目的？\n选项:\n   A. 将 EC2 实例置于每个区域中的 Network Load Balancer (NLB) 后面。在 NLB 上部署 AWS WAF。使用 AWS Global Accelerator 创建一个加速器，并将 NLB 注册为终端节点。\n   B. 将 EC2 实例置于每个区域中的 Application Load Balancer (ALB) 后面。在 ALB 上部署 AWS WAF。使用 AWS Global Accelerator 创建一个加速器，并将 ALB 注册为终端节点。\n   C. 将 EC2 实例置于每个区域中的 Network Load Balancer (NLB) 后面。在 NLB 上部署 AWS WAF。创建一个 Amazon CloudFront 分配，其源使用 Amazon Route 53 基于延迟的路由将请求路由到 NLB。\n   D. 将 EC2 实例置于每个区域中的 Application Load Balancer (ALB) 后面。创建一个 Amazon CloudFront 分配，其源使用 Amazon Route 53 基于延迟的路由将请求路由到 ALB。在 CloudFront 分配上部署 AWS WAF。",
    "options_cn": {
      "A": "将 EC2 实例置于每个区域中的 Network Load Balancer (NLB) 后面。在 NLB 上部署 AWS WAF。使用 AWS Global Accelerator 创建一个加速器，并将 NLB 注册为终端节点。",
      "B": "将 EC2 实例置于每个区域中的 Application Load Balancer (ALB) 后面。在 ALB 上部署 AWS WAF。使用 AWS Global Accelerator 创建一个加速器，并将 ALB 注册为终端节点。",
      "C": "将 EC2 实例置于每个区域中的 Network Load Balancer (NLB) 后面。在 NLB 上部署 AWS WAF。创建一个 Amazon CloudFront 分配，其源使用 Amazon Route 53 基于延迟的路由将请求路由到 NLB。",
      "D": "将 EC2 实例置于每个区域中的 Application Load Balancer (ALB) 后面。创建一个 Amazon CloudFront 分配，其源使用 Amazon Route 53 基于延迟的路由将请求路由到 ALB。在 CloudFront 分配上部署 AWS WAF。"
    }
  },
  {
    "id": 755,
    "topic": "1",
    "question_en": "A company’s data platform uses an Amazon Aurora MySQL database. The database has multiple read replicas and multiple DB instances across different Availability Zones. Users have recently reported errors from the database that indicate that there are too many connections. The company wants to reduce the failover time by 20% when a read replica is promoted to primary writer. Which solution will meet this requirement?",
    "options_en": {
      "A": "Switch from Aurora to Amazon RDS with Multi-AZ cluster deployment.",
      "B": "Use Amazon RDS Proxy in front of the Aurora database.",
      "C": "Switch to Amazon DynamoDB with DynamoDB Accelerator (DAX) for read connections.",
      "D": "Switch to Amazon Redshift with relocation capability."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司的数据平台使用 Amazon Aurora MySQL 数据库。该数据库在不同的可用区中拥有多个只读副本和多个数据库实例。用户最近报告了来自数据库的错误，表明连接过多。该公司希望在将只读副本提升为主写库时，将故障转移时间缩短 20%。哪种解决方案将满足此要求？",
    "options_cn": {
      "A": "从 Aurora 切换到具有 Multi-AZ 集群部署的 Amazon RDS。",
      "B": "在 Aurora 数据库前面使用 Amazon RDS Proxy。",
      "C": "切换到 Amazon DynamoDB，并使用 DynamoDB Accelerator (DAX) 进行读取连接。",
      "D": "切换到具有重新定位功能的 Amazon Redshift。"
    }
  },
  {
    "id": 756,
    "topic": "1",
    "question_en": "A company stores text files in Amazon S3. The text files include customer chat messages, date and time information, and customer personally identifiable information (PII). The company needs a solution to provide samples of the conversations to an external service provider for quality control. The external service provider needs to randomly pick sample conversations up to the most recent conversation. The company must not share the customer PII with the external service provider. The solution must scale when the number of customer conversations increases. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Object Lambda Access Point. Create an AWS Lambda function that redacts the PII when the function reads the file. Instruct the external service provider to access the Object Lambda Access Point.",
      "B": "Create a web application on an Amazon EC2 instance that presents a list of the files, redacts the PII from the files, and allows the external service provider to download new versions of the files that have the PII redacted.",
      "D": "Create an Amazon DynamoDB table. Create an AWS Lambda function that reads only the data in the files that does not contain PII. Configure the Lambda function to store the non-PII data in the DynamoDB table when a new file is written to Amazon S3. Grant the external service provider access to the DynamoDB table."
    },
    "correct_answer": "D",
    "vote_percentage": "91%",
    "question_cn": "一家公司将文本文件存储在 Amazon S3 中。文本文件包含客户聊天消息、日期和时间信息以及客户个人身份信息 (PII)。该公司需要一个解决方案，向外部服务提供商提供对话样本以进行质量控制。外部服务提供商需要随机选取最新的对话样本。该公司不得与外部服务提供商共享客户 PII。当客户对话数量增加时，该解决方案必须能够扩展。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Object Lambda Access Point。创建一个 AWS Lambda 函数，该函数在读取文件时会编辑掉 PII。指示外部服务提供商访问 Object Lambda Access Point。",
      "B": "在 Amazon EC2 实例上创建一个 Web 应用程序，该应用程序会显示文件列表，从文件中编辑掉 PII，并允许外部服务提供商下载已编辑掉 PII 的文件的新版本。",
      "D": "创建一个 Amazon DynamoDB 表。创建一个 AWS Lambda 函数，该函数仅读取文件中不包含 PII 的数据。将 Lambda 函数配置为在将新文件写入 Amazon S3 时将非 PII 数据存储在 DynamoDB 表中。授予外部服务提供商访问 DynamoDB 表的权限。"
    }
  },
  {
    "id": 757,
    "topic": "1",
    "question_en": "A company is running a legacy system on an Amazon EC2 instance. The application code cannot be modified, and the system cannot run on more than one instance. A solutions architect must design a resilient solution that can improve the recovery time for the system. What should the solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Enable termination protection for the EC2 instance.",
      "B": "Configure the EC2 instance for Multi-AZ deployment.",
      "C": "Create an Amazon CloudWatch alarm to recover the EC2 instance in case of failure.",
      "D": "Launch the EC2 instance with two Amazon Elastic Block Store (Amazon EBS) volumes that use RAID configurations for storage redundancy."
    },
    "correct_answer": "A",
    "vote_percentage": "68%",
    "question_cn": "一家公司正在 Amazon EC2 实例上运行一个旧系统。应用程序代码无法修改，并且系统无法在多个实例上运行。解决方案架构师必须设计一个弹性解决方案，以改善系统的恢复时间。解决方案架构师应推荐什么来满足这些要求？",
    "options_cn": {
      "A": "为 EC2 实例启用终止保护。",
      "B": "为多可用区 (Multi-AZ) 部署配置 EC2 实例。",
      "C": "创建一个 Amazon CloudWatch 警报，以在发生故障时恢复 EC2 实例。",
      "D": "启动具有两个 Amazon Elastic Block Store (Amazon EBS) 卷的 EC2 实例，这些卷使用 RAID 配置来实现存储冗余。"
    }
  },
  {
    "id": 758,
    "topic": "1",
    "question_en": "A company wants to deploy its containerized application workloads to a VPC across three Availability Zones. The company needs a solution that is highly available across Availability Zones. The solution must require minimal changes to the application. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon Elastic Container Service (Amazon ECS). Configure Amazon ECS Service Auto Scaling to use target tracking scaling. Set the minimum capacity to 3. Set the task placement strategy type to spread with an Availability Zone attribute.",
      "B": "Use Amazon Elastic Kubernetes Service (Amazon EKS) self-managed nodes. Configure Application Auto Scaling to use target tracking scaling. Set the minimum capacity to 3.",
      "C": "Use Amazon EC2 Reserved Instances. Launch three EC2 instances in a spread placement group. Configure an Auto Scaling group to use target tracking scaling. Set the minimum capacity to 3.",
      "D": "Use an AWS Lambda function. Configure the Lambda function to connect to a VPC. Configure Application Auto Scaling to use Lambda as a scalable target. Set the minimum capacity to 3."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将其容器化应用程序工作负载部署到跨越三个可用区的 VPC 中。该公司需要一个在可用区之间具有高可用性的解决方案。该解决方案必须对应用程序进行最少的更改。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Service (Amazon ECS)。配置 Amazon ECS 服务自动伸缩以使用目标跟踪伸缩。将最小容量设置为 3。将任务放置策略类型设置为按可用区属性进行分散。",
      "B": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 自管理节点。配置 Application Auto Scaling 以使用目标跟踪伸缩。将最小容量设置为 3。",
      "C": "使用 Amazon EC2 预留实例。在分散放置组中启动三个 EC2 实例。配置一个 Auto Scaling 组以使用目标跟踪伸缩。将最小容量设置为 3。",
      "D": "使用 AWS Lambda 函数。配置 Lambda 函数以连接到 VPC。配置 Application Auto Scaling 以使用 Lambda 作为可伸缩目标。将最小容量设置为 3。"
    }
  },
  {
    "id": 759,
    "topic": "1",
    "question_en": "A media company stores movies in Amazon S3. Each movie is stored in a single video file that ranges from 1 GB to 10 GB in size. The company must be able to provide the streaming content of a movie within 5 minutes of a user purchase. There is higher demand for movies that are less than 20 years old than for movies that are more than 20 years old. The company wants to minimize hosting service costs based on demand. Which solution will meet these requirements?",
    "options_en": {
      "A": "Store all media content in Amazon S3. Use S3 Lifecycle policies to move media data into the Infrequent Access tier when the demand for a movie decreases.",
      "B": "Store newer movie video files in S3 Standard. Store older movie video files in S3 Standard-infrequent Access (S3 Standard-IA). When a user orders an older movie, retrieve the video file by using standard retrieval.",
      "C": "Store newer movie video files in S3 Intelligent-Tiering. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using expedited retrieval.",
      "D": "Store newer movie video files in S3 Standard. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using bulk retrieval."
    },
    "correct_answer": "A",
    "vote_percentage": "50%",
    "question_cn": "一家媒体公司将电影存储在 Amazon S3 中。每部电影存储在一个单独的视频文件中，大小从 1 GB 到 10 GB 不等。该公司必须能够在用户购买后 5 分钟内提供电影的流媒体内容。对 20 年以下的电影的需求高于对 20 年以上的电影的需求。该公司希望根据需求最大限度地降低托管服务成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将所有媒体内容存储在 Amazon S3 中。使用 S3 生命周期策略将媒体数据移动到不频繁访问层，当对电影的需求下降时。",
      "B": "将较新的电影视频文件存储在 S3 Standard 中。将较旧的电影视频文件存储在 S3 Standard-infrequent Access (S3 Standard-IA) 中。当用户订购一部较旧的电影时，使用标准检索方式检索视频文件。",
      "C": "将较新的电影视频文件存储在 S3 Intelligent-Tiering 中。将较旧的电影视频文件存储在 S3 Glacier Flexible Retrieval 中。当用户订购一部较旧的电影时，使用加速检索方式检索视频文件。",
      "D": "将较新的电影视频文件存储在 S3 Standard 中。将较旧的电影视频文件存储在 S3 Glacier Flexible Retrieval 中。当用户订购一部较旧的电影时，使用批量检索方式检索视频文件。"
    }
  },
  {
    "id": 760,
    "topic": "1",
    "question_en": "A solutions architect needs to design the architecture for an application that a vendor provides as a Docker container image. The container needs 50 GB of storage available for temporary files. The infrastructure must be serverless. Which solution meets these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Lambda function that uses the Docker container image with an Amazon S3 mounted volume that has more than 50 GB of space.",
      "B": "Create an AWS Lambda function that uses the Docker container image with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space.",
      "C": "Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the AWS Fargate launch type. Create a task definition for the container image with an Amazon Elastic File System (Amazon EFS) volume. Create a service with that task definition.",
      "D": "Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the Amazon EC2 launch type with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space. Create a task definition for the container image. Create a service with that task definition."
    },
    "correct_answer": "B",
    "vote_percentage": "91%",
    "question_cn": "解决方案架构师需要为供应商以 Docker 容器镜像形式提供的应用程序设计架构。容器需要 50 GB 的可用存储空间用于临时文件。基础设施必须是无服务器的。哪个解决方案能以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，该函数使用 Docker 容器镜像，并挂载一个具有超过 50 GB 空间的 Amazon S3 卷。",
      "B": "创建一个 AWS Lambda 函数，该函数使用 Docker 容器镜像，并挂载一个具有超过 50 GB 空间的 Amazon Elastic Block Store (Amazon EBS) 卷。",
      "C": "创建一个 Amazon Elastic Container Service (Amazon ECS) 集群，该集群使用 AWS Fargate 启动类型。为容器镜像创建一个任务定义，其中包含一个 Amazon Elastic File System (Amazon EFS) 卷。创建一个使用该任务定义的服务。",
      "D": "创建一个 Amazon Elastic Container Service (Amazon ECS) 集群，该集群使用 Amazon EC2 启动类型，其中包含一个 Amazon Elastic Block Store (Amazon EBS) 卷，该卷具有超过 50 GB 的空间。为容器镜像创建一个任务定义。创建一个使用该任务定义的服务。"
    }
  },
  {
    "id": 761,
    "topic": "1",
    "question_en": "A company needs to use its on-premises LDAP directory service to authenticate its users to the AWS Management Console. The directory service is not compatible with Security Assertion Markup Language (SAML). Which solution meets these requirements?",
    "options_en": {
      "A": "Enable AWS IAM Identity Center (AWS Single Sign-On) between AWS and the on-premises LDAP.",
      "B": "Create an IAM policy that uses AWS credentials, and integrate the policy into LDAP.",
      "C": "Set up a process that rotates the IAM credentials whenever LDAP credentials are updated.",
      "D": "Develop an on-premises custom identity broker application or process that uses AWS Security Token Service (AWS STS) to get short- lived credentials."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要使用其本地 LDAP 目录服务对用户进行 AWS Management Console 的身份验证。 该目录服务与 Security Assertion Markup Language (SAML) 不兼容。哪种解决方案符合这些要求？",
    "options_cn": {
      "A": "在 AWS 和本地 LDAP 之间启用 AWS IAM Identity Center (AWS Single Sign-On)。",
      "B": "创建一个使用 AWS 凭证的 IAM policy，并将该 policy 集成到 LDAP 中。",
      "C": "设置一个流程，以便在 LDAP 凭证更新时轮换 IAM 凭证。",
      "D": "开发一个本地自定义身份代理应用程序或流程，该应用程序或流程使用 AWS Security Token Service (AWS STS) 获取短期凭证。"
    }
  },
  {
    "id": 762,
    "topic": "1",
    "question_en": "A company stores multiple Amazon Machine Images (AMIs) in an AWS account to launch its Amazon EC2 instances. The AMIs contain critical data and configurations that are necessary for the company’s operations. The company wants to implement a solution that will recover accidentally deleted AMIs quickly and eficiently. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create Amazon Elastic Block Store (Amazon EBS) snapshots of the AMIs. Store the snapshots in a separate AWS account.",
      "B": "Copy all AMIs to another AWS account periodically.",
      "C": "Create a retention rule in Recycle Bin.",
      "D": "Upload the AMIs to an Amazon S3 bucket that has Cross-Region Replication."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 账户中存储多个 Amazon Machine Images (AMI) 以启动其 Amazon EC2 实例。 AMI 包含对公司运营至关重要的关键数据和配置。该公司希望实施一个解决方案，以便快速有效地恢复意外删除的 AMI。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "为 AMI 创建 Amazon Elastic Block Store (Amazon EBS) 快照。将快照存储在单独的 AWS 账户中。",
      "B": "定期将所有 AMI 复制到另一个 AWS 账户。",
      "C": "在回收站中创建保留规则。",
      "D": "将 AMI 上传到已启用 S3 跨区域复制的 Amazon S3 存储桶。"
    }
  },
  {
    "id": 763,
    "topic": "1",
    "question_en": "A company has 150 TB of archived image data stored on-premises that needs to be moved to the AWS Cloud within the next month. The company’s current network connection allows up to 100 Mbps uploads for this purpose during the night only. What is the MOST cost-effective mechanism to move this data and meet the migration deadline?",
    "options_en": {
      "A": "Use AWS Snowmobile to ship the data to AWS.",
      "B": "Order multiple AWS Snowball devices to ship the data to AWS.",
      "C": "Enable Amazon S3 Transfer Acceleration and securely upload the data.",
      "D": "Create an Amazon S3 VPC endpoint and establish a VPN to upload the data."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有 150 TB 的存档图像数据存储在本地，需要在下个月内将其移动到 AWS 云。该公司当前的网路连接仅允许夜间上传，速度高达 100 Mbps。哪种机制最经济高效，可以将这些数据移动并满足迁移截止日期？",
    "options_cn": {
      "A": "使用 AWS Snowmobile 将数据运送到 AWS。",
      "B": "订购多个 AWS Snowball 设备以将数据运送到 AWS。",
      "C": "打开 Amazon S3 Transfer Acceleration 并安全地上传数据。",
      "D": "创建 Amazon S3 VPC endpoint 并建立 VPN 以上传数据。"
    }
  },
  {
    "id": 764,
    "topic": "1",
    "question_en": "A company wants to migrate its three-tier application from on premises to AWS. The web tier and the application tier are running on third- party virtual machines (VMs). The database tier is running on MySQL. The company needs to migrate the application by making the fewest possible changes to the architecture. The company also needs a database solution that can restore data to a specific point in time. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Migrate the web tier and the application tier to Amazon EC2 instances in private subnets. Migrate the database tier to Amazon RDS for MySQL in private subnets.",
      "B": "Migrate the web tier to Amazon EC2 instances in public subnets. Migrate the application tier to EC2 instances in private subnets. Migrate the database tier to Amazon Aurora MySQL in private subnets.",
      "C": "Migrate the web tier to Amazon EC2 instances in public subnets. Migrate the application tier to EC2 instances in private subnets. Migrate the database tier to Amazon RDS for MySQL in private subnets.",
      "D": "Migrate the web tier and the application tier to Amazon EC2 instances in public subnets. Migrate the database tier to Amazon Aurora MySQL in public subnets."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司希望将其三层应用程序从本地环境迁移到 AWS。Web 层和应用程序层运行在第三方虚拟机 (VM) 上。数据库层运行在 MySQL 上。该公司需要通过对架构进行最少的更改来迁移应用程序。该公司还需要一个数据库解决方案，该解决方案可以将数据恢复到特定的时间点。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将 Web 层和应用程序层迁移到私有子网中的 Amazon EC2 实例。将数据库层迁移到私有子网中的 Amazon RDS for MySQL。",
      "B": "将 Web 层迁移到公共子网中的 Amazon EC2 实例。将应用程序层迁移到私有子网中的 EC2 实例。将数据库层迁移到私有子网中的 Amazon Aurora MySQL。",
      "C": "将 Web 层迁移到公共子网中的 Amazon EC2 实例。将应用程序层迁移到私有子网中的 EC2 实例。将数据库层迁移到私有子网中的 Amazon RDS for MySQL。",
      "D": "将 Web 层和应用程序层迁移到公共子网中的 Amazon EC2 实例。将数据库层迁移到公共子网中的 Amazon Aurora MySQL。"
    }
  },
  {
    "id": 765,
    "topic": "1",
    "question_en": "A development team is collaborating with another company to create an integrated product. The other company needs to access an Amazon Simple Queue Service (Amazon SQS) queue that is contained in the development team's account. The other company wants to poll the queue without giving up its own account permissions to do so. How should a solutions architect provide access to the SQS queue?",
    "options_en": {
      "A": "Create an instance profile that provides the other company access to the SQS queue.",
      "B": "Create an IAM policy that provides the other company access to the SQS queue.",
      "C": "Create an SQS access policy that provides the other company access to the SQS queue.",
      "D": "Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一个开发团队正与另一家公司合作创建一个集成产品。另一家公司需要访问开发团队账户中包含的 Amazon Simple Queue Service (Amazon SQS) 队列。另一家公司希望轮询该队列，而不放弃其自身的账户权限。解决方案架构师应该如何提供对 SQS 队列的访问权限？",
    "options_cn": {
      "A": "创建一个实例配置文件，为另一家公司提供对 SQS 队列的访问权限。",
      "B": "创建一个 IAM 策略，为另一家公司提供对 SQS 队列的访问权限。",
      "C": "创建一个 SQS 访问策略，为另一家公司提供对 SQS 队列的访问权限。",
      "D": "创建一个 Amazon Simple Notification Service (Amazon SNS) 访问策略，为另一家公司提供对 SQS 队列的访问权限。"
    }
  },
  {
    "id": 766,
    "topic": "1",
    "question_en": "A company’s developers want a secure way to gain SSH access on the company's Amazon EC2 instances that run the latest version of Amazon Linux. The developers work remotely and in the corporate ofice. The company wants to use AWS services as a part of the solution. The EC2 instances are hosted in a VPC private subnet and access the internet through a NAT gateway that is deployed in a public subnet. What should a solutions architect do to meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a bastion host in the same subnet as the EC2 instances. Grant the ec2:CreateVpnConnection IAM permission to the developers. Install EC2 Instance Connect so that the developers can connect to the EC2 instances.",
      "B": "Create an AWS Site-to-Site VPN connection between the corporate network and the VPC. Instruct the developers to use the Site-to-Site VPN connection to access the EC2 instances when the developers are on the corporate network. Instruct the developers to set up another VPN connection for access when they work remotely.",
      "C": "Create a bastion host in the public subnet of the VPConfigure the security groups and SSH keys of the bastion host to only allow connections and SSH authentication from the developers’ corporate and remote networks. Instruct the developers to connect through the bastion host by using SSH to reach the EC2 instances.",
      "D": "Attach the AmazonSSMManagedInstanceCore IAM policy to an IAM role that is associated with the EC2 instances. Instruct the developers to use AWS Systems Manager Session Manager to access the EC2 instances."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司的开发人员希望通过安全的方式访问在其运行最新版 Amazon Linux 的公司 Amazon EC2 实例上的 SSH。开发人员可以在远程和公司办公室工作。该公司希望将 AWS 服务用作解决方案的一部分。EC2 实例托管在 VPC 私有子网中，并通过部署在公共子网中的 NAT 网关访问互联网。解决方案架构师应如何以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "在与 EC2 实例相同的子网中创建一个堡垒主机。授予开发人员 ec2:CreateVpnConnection IAM 权限。安装 EC2 Instance Connect，以便开发人员可以连接到 EC2 实例。",
      "B": "在公司网络和 VPC 之间创建 AWS Site-to-Site VPN 连接。指示开发人员使用 Site-to-Site VPN 连接来访问 EC2 实例（当开发人员在公司网络上时）。指示开发人员设置另一个 VPN 连接以供他们在远程工作时访问。",
      "C": "在 VPC 的公共子网中创建一个堡垒主机。配置堡垒主机的安全组和 SSH 密钥，仅允许来自开发人员的公司和远程网络的连接和 SSH 身份验证。指示开发人员通过堡垒主机使用 SSH 连接到 EC2 实例。",
      "D": "将 AmazonSSMManagedInstanceCore IAM 策略附加到与 EC2 实例关联的 IAM 角色。指示开发人员使用 AWS Systems Manager Session Manager 访问 EC2 实例。"
    }
  },
  {
    "id": 767,
    "topic": "1",
    "question_en": "A pharmaceutical company is developing a new drug. The volume of data that the company generates has grown exponentially over the past few months. The company's researchers regularly require a subset of the entire dataset to be immediately available with minimal lag. However, the entire dataset does not need to be accessed on a daily basis. All the data currently resides in on-premises storage arrays, and the company wants to reduce ongoing capital expenses. Which storage solution should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Run AWS DataSync as a scheduled cron job to migrate the data to an Amazon S3 bucket on an ongoing basis.",
      "B": "Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
      "C": "Deploy an AWS Storage Gateway volume gateway with cached volumes with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
      "D": "Configure an AWS Site-to-Site VPN connection from the on-premises environment to AWS. Migrate data to an Amazon Elastic File System (Amazon EFS) file system."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家制药公司正在开发一种新药。在过去几个月中，该公司生成的数据量呈指数级增长。该公司的研究人员需要定期获得整个数据集的子集，并立即可用，且延迟最小。但是，无需每天访问整个数据集。所有数据目前都驻留在本地存储阵列中，并且该公司希望减少持续的资本支出。解决方案架构师应该推荐哪种存储解决方案来满足这些要求？",
    "options_cn": {
      "A": "将 AWS DataSync 作为计划好的 cron 作业运行，以持续将数据迁移到 Amazon S3 存储桶。",
      "B": "部署一个 AWS Storage Gateway 文件网关，并将 Amazon S3 存储桶作为目标存储。将数据迁移到 Storage Gateway 设备。",
      "C": "部署一个带有缓存卷的 AWS Storage Gateway 卷网关，并将 Amazon S3 存储桶作为目标存储。将数据迁移到 Storage Gateway 设备。",
      "D": "配置从本地环境到 AWS 的 AWS Site-to-Site VPN 连接。将数据迁移到 Amazon Elastic File System (Amazon EFS) 文件系统。"
    }
  },
  {
    "id": 768,
    "topic": "1",
    "question_en": "A company has a business-critical application that runs on Amazon EC2 instances. The application stores data in an Amazon DynamoDB table. The company must be able to revert the table to any point within the last 24 hours. Which solution meets these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure point-in-time recovery for the table.",
      "B": "Use AWS Backup for the table.",
      "C": "Use an AWS Lambda function to make an on-demand backup of the table every hour.",
      "D": "Turn on streams on the table to capture a log of all changes to the table in the last 24 hours. Store a copy of the stream in an Amazon S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个在 Amazon EC2 实例上运行的关键业务应用程序。该应用程序将数据存储在 Amazon DynamoDB 表中。该公司必须能够将表恢复到过去 24 小时内的任何时间点。哪个解决方案能以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "为表配置时间点恢复。",
      "B": "将 AWS Backup 用于该表。",
      "C": "使用 AWS Lambda 函数每小时对该表进行按需备份。",
      "D": "打开表的流，以捕获过去 24 小时内对表的所有更改的日志。在 Amazon S3 存储桶中存储流的副本。"
    }
  },
  {
    "id": 769,
    "topic": "1",
    "question_en": "A company hosts an application used to upload files to an Amazon S3 bucket. Once uploaded, the files are processed to extract metadata, which takes less than 5 seconds. The volume and frequency of the uploads varies from a few files each hour to hundreds of concurrent uploads. The company has asked a solutions architect to design a cost-effective architecture that will meet these requirements. What should the solutions architect recommend?",
    "options_en": {
      "A": "Configure AWS CloudTrail trails to log S3 API calls. Use AWS AppSync to process the files.",
      "B": "Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.",
      "C": "Configure Amazon Kinesis Data Streams to process and send data to Amazon S3. Invoke an AWS Lambda function to process the files.",
      "D": "Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司托管一个用于将文件上传到 Amazon S3 存储桶的应用程序。上传后，将处理文件以提取元数据，这需要不到 5 秒的时间。上传量和频率从每小时几个文件到数百个并发上传不等。该公司已要求解决方案架构师设计一个具有成本效益的架构，以满足这些要求。解决方案架构师应推荐什么？",
    "options_cn": {
      "A": "配置 AWS CloudTrail 追踪以记录 S3 API 调用。使用 AWS AppSync 处理文件。",
      "B": "在 S3 存储桶中配置对象创建事件通知，以调用 AWS Lambda 函数来处理文件。",
      "C": "配置 Amazon Kinesis Data Streams 来处理数据并将其发送到 Amazon S3。调用 AWS Lambda 函数来处理文件。",
      "D": "配置一个 Amazon Simple Notification Service (Amazon SNS) 主题来处理上传到 Amazon S3 的文件。调用 AWS Lambda 函数来处理文件。"
    }
  },
  {
    "id": 770,
    "topic": "1",
    "question_en": "A company’s application is deployed on Amazon EC2 instances and uses AWS Lambda functions for an event-driven architecture. The company uses nonproduction development environments in a different AWS account to test new features before the company deploys the features to production. The production instances show constant usage because of customers in different time zones. The company uses nonproduction instances only during business hours on weekdays. The company does not use the nonproduction instances on the weekends. The company wants to optimize the costs to run its application on AWS. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use On-Demand Instances for the production instances. Use Dedicated Hosts for the nonproduction instances on weekends only.",
      "B": "Use Reserved Instances for the production instances and the nonproduction instances. Shut down the nonproduction instances when not in use.",
      "C": "Use Compute Savings Plans for the production instances. Use On-Demand Instances for the nonproduction instances. Shut down the nonproduction instances when not in use.",
      "D": "Use Dedicated Hosts for the production instances. Use EC2 Instance Savings Plans for the nonproduction instances."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司的应用程序部署在 Amazon EC2 实例上，并使用 AWS Lambda 函数来实现事件驱动架构。该公司使用位于不同 AWS 账户中的非生产开发环境来测试新功能，然后再将这些功能部署到生产环境。由于来自不同时区的客户，生产实例显示持续使用。该公司仅在工作日的工作时间使用非生产实例。该公司在周末不使用非生产实例。该公司希望优化在 AWS 上运行其应用程序的成本。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "为生产实例使用按需实例。仅在周末为非生产实例使用专用主机。",
      "B": "为生产实例和非生产实例使用预留实例。在不使用时关闭非生产实例。",
      "C": "为生产实例使用计算节省计划。为非生产实例使用按需实例。在不使用时关闭非生产实例。",
      "D": "为生产实例使用专用主机。为非生产实例使用 EC2 实例节省计划。"
    }
  },
  {
    "id": 771,
    "topic": "1",
    "question_en": "A company stores data in an on-premises Oracle relational database. The company needs to make the data available in Amazon Aurora PostgreSQL for analysis. The company uses an AWS Site-to-Site VPN connection to connect its on-premises network to AWS. The company must capture the changes that occur to the source database during the migration to Aurora PostgreSQL. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use the AWS Database Migration Service (AWS DMS) full-load migration task to migrate the data.",
      "B": "Use AWS DataSync to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension.",
      "C": "Use the AWS Schema Conversion Tool (AWS SCT) to convert the Oracle schema to Aurora PostgreSQL schema. Use AWS Database Migration Service (AWS DMS) to migrate the existing data and replicate the ongoing changes.",
      "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Import the S3 data to Aurora PostgreSQL by using the Aurora PostgreSQL aws_s3 extension."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司将其数据存储在本地 Oracle 关系数据库中。该公司需要将数据提供给 Amazon Aurora PostgreSQL 以进行分析。该公司使用 AWS Site-to-Site VPN 连接将其本地网络连接到 AWS。该公司必须捕获在迁移到 Aurora PostgreSQL 期间对 源 数据库发生的更改。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Schema Conversion Tool (AWS SCT) 将 Oracle 模式转换为 Aurora PostgreSQL 模式。使用 AWS Database Migration Service (AWS DMS) 的完全加载迁移任务来迁移数据。",
      "B": "使用 AWS DataSync 将数据迁移到 Amazon S3 存储桶。使用 Aurora PostgreSQL aws_s3 扩展将 S3 数据导入到 Aurora PostgreSQL。",
      "C": "使用 AWS Schema Conversion Tool (AWS SCT) 将 Oracle 模式转换为 Aurora PostgreSQL 模式。使用 AWS Database Migration Service (AWS DMS) 迁移现有数据并复制正在进行的更改。",
      "D": "使用 AWS Snowball 设备将数据迁移到 Amazon S3 存储桶。使用 Aurora PostgreSQL aws_s3 扩展将 S3 数据导入到 Aurora PostgreSQL。"
    }
  },
  {
    "id": 772,
    "topic": "1",
    "question_en": "A company built an application with Docker containers and needs to run the application in the AWS Cloud. The company wants to use a managed service to host the application. The solution must scale in and out appropriately according to demand on the individual container services. The solution also must not result in additional operational overhead or infrastructure to manage. Which solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.",
      "B": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate.",
      "C": "Provision an Amazon API Gateway API. Connect the API to AWS Lambda to run the containers.",
      "D": "Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 worker nodes",
      "E": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes."
    },
    "correct_answer": "A",
    "vote_percentage": "67%",
    "question_cn": "一家公司使用 Docker 容器构建了一个应用程序，需要在 AWS 云中运行该应用程序。该公司希望使用托管服务来托管该应用程序。该解决方案必须根据各个容器服务的需求进行适当的横向扩展和缩减。该解决方案还不能导致额外的运营开销或需要管理的架构。哪种解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate。",
      "B": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 AWS Fargate。",
      "C": "配置 Amazon API Gateway API。将 API 连接到 AWS Lambda 以运行容器。",
      "D": "使用 Amazon Elastic Container Service (Amazon ECS) 和 Amazon EC2 工作节点。",
      "E": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 Amazon EC2 工作节点。"
    }
  },
  {
    "id": 773,
    "topic": "1",
    "question_en": "An ecommerce company is running a seasonal online sale. The company hosts its website on Amazon EC2 instances spanning multiple Availability Zones. The company wants its website to manage sudden trafic increases during the sale. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an Auto Scaling group that is large enough to handle peak trafic load. Stop half of the Amazon EC2 instances. Configure the Auto Scaling group to use the stopped instances to scale out when trafic increases.",
      "B": "Create an Auto Scaling group for the website. Set the minimum size of the Auto Scaling group so that it can handle high trafic volumes without the need to scale out.",
      "C": "Use Amazon CloudFront and Amazon ElastiCache to cache dynamic content with an Auto Scaling group set as the origin. Configure the Auto Scaling group with the instances necessary to populate CloudFront and ElastiCache. Scale in after the cache is fully populated.",
      "D": "Configure an Auto Scaling group to scale out as trafic increases. Create a launch template to start new instances from a preconfigured Amazon Machine Image (AMI)."
    },
    "correct_answer": "A",
    "vote_percentage": "80%",
    "question_cn": "一家电子商务公司正在进行季节性在线促销活动。该公司将其网站托管在跨多个可用区的 Amazon EC2 实例上。该公司希望其网站能够管理促销期间突然增加的流量。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "创建一个足够大的 Auto Scaling 组以处理峰值流量负载。停止一半的 Amazon EC2 实例。将 Auto Scaling 组配置为使用已停止的实例在流量增加时进行扩展。",
      "B": "为网站创建一个 Auto Scaling 组。将 Auto Scaling 组的最小大小设置为可以处理高流量，而无需横向扩展。",
      "C": "使用 Amazon CloudFront 和 Amazon ElastiCache 来缓存动态内容，并将 Auto Scaling 组设置为源。配置 Auto Scaling 组，其中包含填充 CloudFront 和 ElastiCache 所需的实例。在缓存完全填充后进行缩减。",
      "D": "配置一个 Auto Scaling 组，以便在流量增加时横向扩展。创建一个启动模板，从预配置的 Amazon Machine Image (AMI) 启动新实例。"
    }
  },
  {
    "id": 774,
    "topic": "1",
    "question_en": "A solutions architect must provide an automated solution for a company's compliance policy that states security groups cannot include a rule that allows SSH from 0.0.0.0/0. The company needs to be notified if there is any breach in the policy. A solution is needed as soon as possible. What should the solutions architect do to meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Write an AWS Lambda script that monitors security groups for SSH being open to 0.0.0.0/0 addresses and creates a notification every time it finds one.",
      "B": "Enable the restricted-ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created.",
      "C": "Create an IAM role with permissions to globally open security groups and network ACLs. Create an Amazon Simple Notification Service (Amazon SNS) topic to generate a notification every time the role is assumed by a user.",
      "D": "Configure a service control policy (SCP) that prevents non-administrative users from creating or editing security groups. Create a notification in the ticketing system when a user requests a rule that needs administrator permissions."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师必须为一家公司的合规策略提供一个自动化解决方案，该策略规定安全组不能包含允许来自 0.0.0.0/0 的 SSH 的规则。如果该策略有任何违规行为，公司需要收到通知。需要尽快提供一个解决方案。 解决方案架构师应该怎么做才能以最少的运营开销来满足这些要求？",
    "options_cn": {
      "A": "编写一个 AWS Lambda 脚本，该脚本监视安全组，以查找允许 SSH 到 0.0.0.0/0 地址的情况，并在每次发现此类情况时创建一个通知。",
      "B": "启用 restricted-ssh AWS Config 托管规则，并在创建不合规规则时生成一个 Amazon Simple Notification Service (Amazon SNS) 通知。",
      "C": "创建一个 IAM 角色，该角色具有全局打开安全组和网络 ACL 的权限。创建一个 Amazon Simple Notification Service (Amazon SNS) 主题，以便在用户每次承担该角色时生成通知。",
      "D": "配置一个服务控制策略 (SCP)，阻止非管理用户创建或编辑安全组。当用户请求需要管理员权限的规则时，在工单系统中创建一个通知。"
    }
  },
  {
    "id": 775,
    "topic": "1",
    "question_en": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes. A company has deployed an application in an AWS account. The application consists of microservices that run on AWS Lambda and Amazon Elastic Kubernetes Service (Amazon EKS). A separate team supports each microservice. The company has multiple AWS accounts and wants to give each team its own account for its microservices. A solutions architect needs to design a solution that will provide service-to-service communication over HTTPS (port 443). The solution also must provide a service registry for service discovery. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Create an inspection VPC. Deploy an AWS Network Firewall firewall to the inspection VPC. Attach the inspection VPC to a new transit gateway. Route VPC-to-VPC trafic to the inspection VPC. Apply firewall rules to allow only HTTPS communication.",
      "B": "Create a VPC Lattice service network. Associate the microservices with the service network. Define HTTPS listeners for each service. Register microservice compute resources as targets. Identify VPCs that need to communicate with the services. Associate those VPCs with the service network.",
      "C": "Create a Network Load Balancer (NLB) with an HTTPS listener and target groups for each microservice. Create an AWS PrivateLink endpoint service for each microservice. Create an interface VPC endpoint in each VPC that needs to consume that microservice.",
      "D": "Create peering connections between VPCs that contain microservices. Create a prefix list for each service that requires a connection to a client. Create route tables to route trafic to the appropriate VPC. Create security groups to allow only HTTPS communication."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和 Amazon EC2 工作节点。一家公司已在一个 AWS 账户中部署了一个应用程序。该应用程序由在 AWS Lambda 和 Amazon Elastic Kubernetes Service (Amazon EKS) 上运行的微服务组成。每个微服务由一个单独的团队支持。该公司有多个 AWS 账户，并希望为每个团队提供自己的账户来运行其微服务。解决方案架构师需要设计一个解决方案，该方案将通过 HTTPS (443 端口) 提供服务到服务的通信。该解决方案还必须为服务发现提供服务注册表。哪种解决方案将以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "创建一个检查 VPC。将 AWS Network Firewall 防火墙部署到检查 VPC。将检查 VPC 附加到新的 transit gateway。将 VPC 到 VPC 的流量路由到检查 VPC。应用防火墙规则，仅允许 HTTPS 通信。",
      "B": "创建 VPC Lattice 服务网络。将微服务与服务网络关联。为每个服务定义 HTTPS 监听器。将微服务计算资源注册为目标。确定需要与服务通信的 VPC。将这些 VPC 与服务网络关联。",
      "C": "创建一个 Network Load Balancer (NLB)，其中包含 HTTPS 监听器和每个微服务的目标组。为每个微服务创建一个 AWS PrivateLink 终端节点服务。在每个需要使用该微服务的 VPC 中创建一个接口 VPC 终端节点。",
      "D": "在包含微服务的 VPC 之间创建对等连接。为每个需要与客户端建立连接的服务创建一个前缀列表。创建路由表以将流量路由到相应的 VPC。创建安全组以仅允许 HTTPS 通信。"
    }
  },
  {
    "id": 776,
    "topic": "1",
    "question_en": "A company has a mobile game that reads most of its metadata from an Amazon RDS DB instance. As the game increased in popularity, developers noticed slowdowns related to the game's metadata load times. Performance metrics indicate that simply scaling the database will not help. A solutions architect must explore all options that include capabilities for snapshots, replication, and sub-millisecond response times. What should the solutions architect recommend to solve these issues?",
    "options_en": {
      "A": "Migrate the database to Amazon Aurora with Aurora Replicas.",
      "B": "Migrate the database to Amazon DynamoDB with global tables.",
      "C": "Add an Amazon ElastiCache for Redis layer in front of the database.",
      "D": "Add an Amazon ElastiCache for Memcached layer in front of the database."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一款手机游戏，该游戏的大部分元数据从 Amazon RDS 数据库实例中读取。随着游戏的普及，开发人员注意到与游戏元数据加载时间相关的速度变慢。性能指标表明，简单地扩展数据库将无济于事。一位解决方案架构师必须探索所有选项，包括快照、复制和亚毫秒级响应时间的功能。 解决方案架构师应该推荐什么来解决这些问题？",
    "options_cn": {
      "A": "将数据库迁移到带有 Aurora Replicas 的 Amazon Aurora。",
      "B": "将数据库迁移到带有全局表的 Amazon DynamoDB。",
      "C": "在数据库前面添加一个 Amazon ElastiCache for Redis 层。",
      "D": "在数据库前面添加一个 Amazon ElastiCache for Memcached 层。"
    }
  },
  {
    "id": 777,
    "topic": "1",
    "question_en": "A company uses AWS Organizations for its multi-account AWS setup. The security organizational unit (OU) of the company needs to share approved Amazon Machine Images (AMIs) with the development OU. The AMIs are created by using AWS Key Management Service (AWS KMS) encrypted snapshots. Which solution will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Add the development team's OU Amazon Resource Name (ARN) to the launch permission list for the AMIs.",
      "B": "Add the Organizations root Amazon Resource Name (ARN) to the launch permission list for the AMIs.",
      "C": "Update the key policy to allow the development team's OU to use the AWS KMS keys that are used to decrypt the snapshots.",
      "D": "Add the development team’s account Amazon Resource Name (ARN) to the launch permission list for the AMIs",
      "E": "Recreate the AWS KMS key. Add a key policy to allow the Organizations root Amazon Resource Name (ARN) to use the AWS KMS key."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS Organizations 设置其多账户 AWS。 该公司的安全组织单元 (OU) 需要与开发 OU 共享已批准的 Amazon Machine Images (AMI)。 AMI 是使用 AWS Key Management Service (AWS KMS) 加密快照创建的。 哪种解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将开发团队的 OU Amazon Resource Name (ARN) 添加到 AMI 的启动权限列表中。",
      "B": "将 Organizations 根 Amazon Resource Name (ARN) 添加到 AMI 的启动权限列表中。",
      "C": "更新密钥策略，允许开发团队的 OU 使用用于解密快照的 AWS KMS 密钥。",
      "D": "将开发团队的账户 Amazon Resource Name (ARN) 添加到 AMI 的启动权限列表中。",
      "E": "重新创建 AWS KMS 密钥。 添加一个密钥策略，允许 Organizations 根 Amazon Resource Name (ARN) 使用 AWS KMS 密钥。"
    }
  },
  {
    "id": 778,
    "topic": "1",
    "question_en": "A data analytics company has 80 ofices that are distributed globally. Each ofice hosts 1 PB of data and has between 1 and 2 Gbps of internet bandwidth. The company needs to perform a one-time migration of a large amount of data from its ofices to Amazon S3. The company must complete the migration within 4 weeks. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Establish a new 10 Gbps AWS Direct Connect connection to each ofice. Transfer the data to Amazon S3.",
      "B": "Use multiple AWS Snowball Edge storage-optimized devices to store and transfer the data to Amazon S3.",
      "C": "Use an AWS Snowmobile to store and transfer the data to Amazon S3.",
      "D": "Set up an AWS Storage Gateway Volume Gateway to transfer the data to Amazon S3."
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家数据分析公司在全球分布着 80 个办事处。每个办事处托管 1 PB 的数据，并拥有 1 到 2 Gbps 的互联网带宽。该公司需要一次性将大量数据从其办事处迁移到 Amazon S3。该公司必须在 4 周内完成迁移。哪种解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "为每个办事处建立一个新的 10 Gbps AWS Direct Connect 连接。将数据传输到 Amazon S3。",
      "B": "使用多个 AWS Snowball Edge 存储优化设备来存储数据并将数据传输到 Amazon S3。",
      "C": "使用 AWS Snowmobile 来存储数据并将数据传输到 Amazon S3。",
      "D": "设置 AWS Storage Gateway Volume Gateway 以将数据传输到 Amazon S3。"
    }
  },
  {
    "id": 779,
    "topic": "1",
    "question_en": "A company has an Amazon Elastic File System (Amazon EFS) file system that contains a reference dataset. The company has applications on Amazon EC2 instances that need to read the dataset. However, the applications must not be able to change the dataset. The company wants to use IAM access control to prevent the applications from being able to modify or delete the dataset. Which solution will meet these requirements?",
    "options_en": {
      "A": "Mount the EFS file system in read-only mode from within the EC2 instances.",
      "B": "Create a resource policy for the EFS file system that denies the elasticfilesystem:ClientWrite action to the IAM roles that are attached to the EC2 instances.",
      "C": "Create an identity policy for the EFS file system that denies the elasticfilesystem:ClientWrite action on the EFS file system.",
      "D": "Create an EFS access point for each application. Use Portable Operating System Interface (POSIX) file permissions to allow read-only access to files in the root directory."
    },
    "correct_answer": "A",
    "vote_percentage": "60%",
    "question_cn": "一家公司有一个包含参考数据集的 Amazon Elastic File System (Amazon EFS) 文件系统。该公司在 Amazon EC2 实例上有需要读取数据集的应用程序。但是，这些应用程序不能更改数据集。该公司希望使用 IAM 访问控制来阻止应用程序修改或删除数据集。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "从 EC2 实例中以只读模式挂载 EFS 文件系统。",
      "B": "为 EFS 文件系统创建一个资源策略，该策略拒绝 elasticfilesystem:ClientWrite 操作给附加到 EC2 实例的 IAM 角色。",
      "C": "为 EFS 文件系统创建一个身份策略，该策略拒绝在 EFS 文件系统上执行 elasticfilesystem:ClientWrite 操作。",
      "D": "为每个应用程序创建一个 EFS 访问点。使用 Portable Operating System Interface (POSIX) 文件权限来允许对根目录中的文件进行只读访问。"
    }
  },
  {
    "id": 780,
    "topic": "1",
    "question_en": "A company has hired an external vendor to perform work in the company’s AWS account. The vendor uses an automated tool that is hosted in an AWS account that the vendor owns. The vendor does not have IAM access to the company’s AWS account. The company needs to grant the vendor access to the company’s AWS account. Which solution will meet these requirements MOST securely?",
    "options_en": {
      "A": "Create an IAM role in the company’s account to delegate access to the vendor’s IAM role. Attach the appropriate IAM policies to the role for the permissions that the vendor requires.",
      "B": "Create an IAM user in the company’s account with a password that meets the password complexity requirements. Attach the appropriate IAM policies to the user for the permissions that the vendor requires.",
      "C": "Create an IAM group in the company’s account. Add the automated tool’s IAM user from the vendor account to the group. Attach the appropriate IAM policies to the group for the permissions that the vendor requires.",
      "D": "Create an IAM user in the company’s account that has a permission boundary that allows the vendor’s account. Attach the appropriate IAM policies to the user for the permissions that the vendor requires."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司聘请了一家外部供应商在其公司的 AWS 账户中执行工作。该供应商使用托管在其拥有的 AWS 账户中的自动化工具。该供应商无法访问该公司 AWS 账户的 IAM。该公司需要授予供应商对其公司 AWS 账户的访问权限。哪种解决方案最安全地满足这些要求？",
    "options_cn": {
      "A": "在公司的账户中创建一个 IAM 角色，以将访问权限委托给供应商的 IAM 角色。将适当的 IAM 策略附加到该角色，以获取供应商所需的权限。",
      "B": "在公司的账户中创建一个 IAM 用户，该用户的密码符合密码复杂性要求。将适当的 IAM 策略附加到该用户，以获取供应商所需的权限。",
      "C": "在公司的账户中创建一个 IAM 组。将供应商账户中的自动化工具的 IAM 用户添加到该组。将适当的 IAM 策略附加到该组，以获取供应商所需的权限。",
      "D": "在公司的账户中创建一个 IAM 用户，该用户具有一个允许供应商账户的权限边界。将适当的 IAM 策略附加到该用户，以获取供应商所需的权限。"
    }
  },
  {
    "id": 781,
    "topic": "1",
    "question_en": "A company wants to run its experimental workloads in the AWS Cloud. The company has a budget for cloud spending. The company's CFO is concerned about cloud spending accountability for each department. The CFO wants to receive notification when the spending threshold reaches 60% of the budget. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use cost allocation tags on AWS resources to label owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget.",
      "B": "Use AWS Cost Explorer forecasts to determine resource owners. Use AWS Cost Anomaly Detection to create alert threshold notifications when spending exceeds 60% of the budget.",
      "C": "Use cost allocation tags on AWS resources to label owners. Use AWS Support API on AWS Trusted Advisor to create alert threshold notifications when spending exceeds 60% of the budget.",
      "D": "Use AWS Cost Explorer forecasts to determine resource owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在 AWS 云中运行其实验性工作负载。该公司有一个用于云支出的预算。该公司的首席财务官担心每个部门的云支出问责制。首席财务官希望在支出阈值达到预算的 60% 时收到通知。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS 资源上使用成本分配标签来标记所有者。在 AWS Budgets 中创建使用预算。添加一个警报阈值，以便在支出超过预算的 60% 时收到通知。",
      "B": "使用 AWS Cost Explorer 预测来确定资源所有者。使用 AWS Cost Anomaly Detection 在支出超过预算的 60% 时创建警报阈值通知。",
      "C": "在 AWS 资源上使用成本分配标签来标记所有者。使用 AWS Trusted Advisor 上的 AWS Support API 在支出超过预算的 60% 时创建警报阈值通知。",
      "D": "使用 AWS Cost Explorer 预测来确定资源所有者。在 AWS Budgets 中创建使用预算。添加一个警报阈值，以便在支出超过预算的 60% 时收到通知。"
    }
  },
  {
    "id": 782,
    "topic": "1",
    "question_en": "A company wants to deploy an internal web application on AWS. The web application must be accessible only from the company's ofice. The company needs to download security patches for the web application from the internet. The company has created a VPC and has configured an AWS Site-to-Site VPN connection to the company's ofice. A solutions architect must design a secure architecture for the web application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy the web application on Amazon EC2 instances in public subnets behind a public Application Load Balancer (ALB). Attach an internet gateway to the VPC. Set the inbound source of the ALB's security group to 0.0.0.0/0.",
      "B": "Deploy the web application on Amazon EC2 instances in private subnets behind an internal Application Load Balancer (ALB). Deploy NAT gateways in public subnets. Attach an internet gateway to the VPC. Set the inbound source of the ALB's security group to the company's ofice network CIDR block.",
      "C": "Deploy the web application on Amazon EC2 instances in public subnets behind an internal Application Load Balancer (ALB). Deploy NAT gateways in private subnets. Attach an internet gateway to the VPSet the outbound destination of the ALB’s security group to the company's ofice network CIDR block.",
      "D": "Deploy the web application on Amazon EC2 instances in private subnets behind a public Application Load Balancer (ALB). Attach an internet gateway to the VPC. Set the outbound destination of the ALB’s security group to 0.0.0.0/0."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在 AWS 上部署一个内部 Web 应用程序。该 Web 应用程序必须仅从公司的办公室访问。该公司需要从互联网下载 Web 应用程序的安全补丁。该公司已创建了 VPC，并配置了到公司办公室的 AWS Site-to-Site VPN 连接。解决方案架构师必须为 Web 应用程序设计一个安全的架构。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 Web 应用程序部署在公有子网中的 Amazon EC2 实例上，位于公有 Application Load Balancer (ALB) 之后。将互联网网关附加到 VPC。将 ALB 的安全组的入站源设置为 0.0.0.0/0。",
      "B": "将 Web 应用程序部署在私有子网中的 Amazon EC2 实例上，位于内部 Application Load Balancer (ALB) 之后。在公有子网中部署 NAT 网关。将互联网网关附加到 VPC。将 ALB 的安全组的入站源设置为公司办公室网络 CIDR 块。",
      "C": "将 Web 应用程序部署在公有子网中的 Amazon EC2 实例上，位于内部 Application Load Balancer (ALB) 之后。在私有子网中部署 NAT 网关。将互联网网关附加到 VPC。将 ALB 的安全组的出站目标设置为公司办公室网络 CIDR 块。",
      "D": "将 Web 应用程序部署在私有子网中的 Amazon EC2 实例上，位于公有 Application Load Balancer (ALB) 之后。将互联网网关附加到 VPC。将 ALB 的安全组的出站目标设置为 0.0.0.0/0。"
    }
  },
  {
    "id": 783,
    "topic": "1",
    "question_en": "A company maintains its accounting records in a custom application that runs on Amazon EC2 instances. The company needs to migrate the data to an AWS managed service for development and maintenance of the application data. The solution must require minimal operational support and provide immutable, cryptographically verifiable logs of data changes. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Copy the records from the application into an Amazon Redshift cluster.",
      "B": "Copy the records from the application into an Amazon Neptune cluster.",
      "C": "Copy the records from the application into an Amazon Timestream database.",
      "D": "Copy the records from the application into an Amazon Quantum Ledger Database (Amazon QLDB) ledger."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Amazon EC2 实例上运行的自定义应用程序中维护其会计记录。该公司需要将数据迁移到 AWS 托管服务，用于应用程序数据的开发和维护。该解决方案必须需要最少的运营支持，并提供对数据更改的不可变、经过密码学验证的日志。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将记录从应用程序复制到 Amazon Redshift 集群。",
      "B": "将记录从应用程序复制到 Amazon Neptune 集群。",
      "C": "将记录从应用程序复制到 Amazon Timestream 数据库。",
      "D": "将记录从应用程序复制到 Amazon Quantum Ledger Database (Amazon QLDB) 账本。"
    }
  },
  {
    "id": 784,
    "topic": "1",
    "question_en": "A company's marketing data is uploaded from multiple sources to an Amazon S3 bucket. A series of data preparation jobs aggregate the data for reporting. The data preparation jobs need to run at regular intervals in parallel. A few jobs need to run in a specific order later. The company wants to remove the operational overhead of job error handling, retry logic, and state management. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an AWS Lambda function to process the data as soon as the data is uploaded to the S3 bucket. Invoke other Lambda functions at regularly scheduled intervals.",
      "B": "Use Amazon Athena to process the data. Use Amazon EventBridge Scheduler to invoke Athena on a regular internal.",
      "C": "Use AWS Glue DataBrew to process the data. Use an AWS Step Functions state machine to run the DataBrew data preparation jobs.",
      "D": "Use AWS Data Pipeline to process the data. Schedule Data Pipeline to process the data once at midnight."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司的营销数据从多个源上传到 Amazon S3 存储桶。一系列数据准备作业聚合数据用于报告。数据准备作业需要定期间隔并行运行。少数作业需要在稍后以特定顺序运行。该公司希望移除作业错误处理、重试逻辑和状态管理的操作开销。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Lambda 函数在数据上传到 S3 存储桶后立即处理数据。以定期间隔调用其他 Lambda 函数。",
      "B": "使用 Amazon Athena 处理数据。使用 Amazon EventBridge Scheduler 定期间隔调用 Athena。",
      "C": "使用 AWS Glue DataBrew 处理数据。使用 AWS Step Functions 状态机运行 DataBrew 数据准备作业。",
      "D": "使用 AWS Data Pipeline 处理数据。将 Data Pipeline 调度为在午夜处理数据一次。"
    }
  },
  {
    "id": 785,
    "topic": "1",
    "question_en": "A solutions architect is designing a payment processing application that runs on AWS Lambda in private subnets across multiple Availability Zones. The application uses multiple Lambda functions and processes millions of transactions each day. The architecture must ensure that the application does not process duplicate payments. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Lambda to retrieve all due payments. Publish the due payments to an Amazon S3 bucket. Configure the S3 bucket with an event notification to invoke another Lambda function to process the due payments.",
      "B": "Use Lambda to retrieve all due payments. Publish the due payments to an Amazon Simple Queue Service (Amazon SQS) queue. Configure another Lambda function to poll the SQS queue and to process the due payments.",
      "C": "Use Lambda to retrieve all due payments. Publish the due payments to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Configure another Lambda function to poll the FIFO queue and to process the due payments.",
      "D": "Use Lambda to retrieve all due payments. Store the due payments in an Amazon DynamoDB table. Configure streams on the DynamoDB table to invoke another Lambda function to process the due payments."
    },
    "correct_answer": "C",
    "vote_percentage": "73%",
    "question_cn": "一位解决方案架构师正在设计一个支付处理应用程序，该应用程序在跨多个可用区的私有子网中的 AWS Lambda 上运行。该应用程序使用多个 Lambda 函数，并且每天处理数百万笔交易。该架构必须确保应用程序不会处理重复的付款。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Lambda 检索所有到期付款。将到期付款发布到 Amazon S3 存储桶。使用事件通知配置 S3 存储桶，以调用另一个 Lambda 函数来处理到期付款。",
      "B": "使用 Lambda 检索所有到期付款。将到期付款发布到 Amazon Simple Queue Service (Amazon SQS) 队列。配置另一个 Lambda 函数来轮询 SQS 队列并处理到期付款。",
      "C": "使用 Lambda 检索所有到期付款。将到期付款发布到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列。配置另一个 Lambda 函数来轮询 FIFO 队列并处理到期付款。",
      "D": "使用 Lambda 检索所有到期付款。将到期付款存储在 Amazon DynamoDB 表中。在 DynamoDB 表上配置流以调用另一个 Lambda 函数来处理到期付款。"
    }
  },
  {
    "id": 786,
    "topic": "1",
    "question_en": "A company runs multiple workloads in its on-premises data center. The company's data center cannot scale fast enough to meet the company's expanding business needs. The company wants to collect usage and configuration data about the on-premises servers and workloads to plan a migration to AWS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set the home AWS Region in AWS Migration Hub. Use AWS Systems Manager to collect data about the on-premises servers.",
      "B": "Set the home AWS Region in AWS Migration Hub. Use AWS Application Discovery Service to collect data about the on-premises servers.",
      "C": "Use the AWS Schema Conversion Tool (AWS SCT) to create the relevant templates. Use AWS Trusted Advisor to collect data about the on-premises servers.",
      "D": "Use the AWS Schema Conversion Tool (AWS SCT) to create the relevant templates. Use AWS Database Migration Service (AWS DMS) to collect data about the on-premises servers."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其本地数据中心运行多个工作负载。该公司的的数据中心无法快速扩展以满足公司不断增长的业务需求。该公司希望收集有关本地服务器和工作负载的用量和配置数据，以便规划向 AWS 的迁移。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Migration Hub 中设置 home AWS 区域。 使用 AWS Systems Manager 收集有关本地服务器的数据。",
      "B": "在 AWS Migration Hub 中设置 home AWS 区域。使用 AWS Application Discovery Service 收集有关本地服务器的数据。",
      "C": "使用 AWS Schema Conversion Tool (AWS SCT) 创建相关模板。 使用 AWS Trusted Advisor 收集有关本地服务器的数据。",
      "D": "使用 AWS Schema Conversion Tool (AWS SCT) 创建相关模板。使用 AWS Database Migration Service (AWS DMS) 收集有关本地服务器的数据。"
    }
  },
  {
    "id": 787,
    "topic": "1",
    "question_en": "A company has an organization in AWS Organizations that has all features enabled. The company requires that all API calls and logins in any existing or new AWS account must be audited. The company needs a managed solution to prevent additional work and to minimize costs. The company also needs to know when any AWS account is not compliant with the AWS Foundational Security Best Practices (FSBP) standard. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Deploy an AWS Control Tower environment in the Organizations management account. Enable AWS Security Hub and AWS Control Tower Account Factory in the environment.",
      "B": "Deploy an AWS Control Tower environment in a dedicated Organizations member account. Enable AWS Security Hub and AWS Control Tower Account Factory in the environment.",
      "C": "Use AWS Managed Services (AMS) Accelerate to build a multi-account landing zone (MALZ). Submit an RFC to self-service provision Amazon GuardDuty in the MALZ.",
      "D": "Use AWS Managed Services (AMS) Accelerate to build a multi-account landing zone (MALZ). Submit an RFC to self-service provision AWS Security Hub in the MALZ."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS Organizations 中拥有已启用所有功能的组织。该公司要求必须审核任何现有或新 AWS 账户中的所有 API 调用和登录。该公司需要一个托管解决方案，以防止额外的工作并最大限度地降低成本。该公司还需要知道何时任何 AWS 账户不符合 AWS 基础安全最佳实践 (FSBP) 标准。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 Organizations 管理账户中部署 AWS Control Tower 环境。在该环境中启用 AWS Security Hub 和 AWS Control Tower Account Factory。",
      "B": "在专用的 Organizations 成员账户中部署 AWS Control Tower 环境。在该环境中启用 AWS Security Hub 和 AWS Control Tower Account Factory。",
      "C": "使用 AWS Managed Services (AMS) Accelerate 构建一个多账户登陆区 (MALZ)。提交一个 RFC 以自助服务方式在 MALZ 中配置 Amazon GuardDuty。",
      "D": "使用 AWS Managed Services (AMS) Accelerate 构建一个多账户登陆区 (MALZ)。提交一个 RFC 以自助服务方式在 MALZ 中配置 AWS Security Hub。"
    }
  },
  {
    "id": 788,
    "topic": "1",
    "question_en": "A company has stored 10 TB of log files in Apache Parquet format in an Amazon S3 bucket. The company occasionally needs to use SQL to analyze the log files. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an Amazon Aurora MySQL database. Migrate the data from the S3 bucket into Aurora by using AWS Database Migration Service (AWS DMS). Issue SQL statements to the Aurora database.",
      "B": "Create an Amazon Redshift cluster. Use Redshift Spectrum to run SQL statements directly on the data in the S3 bucket.",
      "C": "Create an AWS Glue crawler to store and retrieve table metadata from the S3 bucket. Use Amazon Athena to run SQL statements directly on the data in the S3 bucket.",
      "D": "Create an Amazon EMR cluster. Use Apache Spark SQL to run SQL statements directly on the data in the S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司将 10 TB 的日志文件以 Apache Parquet 格式存储在 Amazon S3 存储桶中。该公司偶尔需要使用 SQL 分析日志文件。哪种解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Aurora MySQL 数据库。使用 AWS Database Migration Service (AWS DMS) 将数据从 S3 存储桶迁移到 Aurora。向 Aurora 数据库发出 SQL 语句。",
      "B": "创建一个 Amazon Redshift 集群。使用 Redshift Spectrum 直接在 S3 存储桶中的数据上运行 SQL 语句。",
      "C": "创建一个 AWS Glue 爬虫程序，以存储和检索 S3 存储桶中的表元数据。使用 Amazon Athena 直接在 S3 存储桶中的数据上运行 SQL 语句。",
      "D": "创建一个 Amazon EMR 集群。使用 Apache Spark SQL 直接在 S3 存储桶中的数据上运行 SQL 语句。"
    }
  },
  {
    "id": 789,
    "topic": "1",
    "question_en": "A company needs a solution to prevent AWS CloudFormation stacks from deploying AWS Identity and Access Management (IAM) resources that include an inline policy or “*” in the statement. The solution must also prohibit deployment of Amazon EC2 instances with public IP addresses. The company has AWS Control Tower enabled in its organization in AWS Organizations. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Control Tower proactive controls to block deployment of EC2 instances with public IP addresses and inline policies with elevated access or “*”.",
      "B": "Use AWS Control Tower detective controls to block deployment of EC2 instances with public IP addresses and inline policies with elevated access or “*”.",
      "C": "Use AWS Config to create rules for EC2 and IAM compliance. Configure the rules to run an AWS Systems Manager Session Manager automation to delete a resource when it is not compliant.",
      "D": "Use a service control policy (SCP) to block actions for the EC2 instances and IAM resources if the actions lead to noncompliance."
    },
    "correct_answer": "D",
    "vote_percentage": "64%",
    "question_cn": "一家公司需要一个解决方案，以防止 AWS CloudFormation 堆栈部署包含内联策略或语句中包含“*”的 AWS Identity and Access Management (IAM) 资源。该解决方案还必须禁止部署具有公共 IP 地址的 Amazon EC2 实例。该公司在其 AWS Organizations 组织中启用了 AWS Control Tower。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Control Tower 主动控制来阻止部署具有公共 IP 地址的 EC2 实例以及具有提升访问权限或“*”的内联策略。",
      "B": "使用 AWS Control Tower 侦探控制来阻止部署具有公共 IP 地址的 EC2 实例以及具有提升访问权限或“*”的内联策略。",
      "C": "使用 AWS Config 为 EC2 和 IAM 合规性创建规则。配置规则以运行 AWS Systems Manager Session Manager 自动化，以便在资源不合规时删除资源。",
      "D": "使用服务控制策略 (SCP) 来阻止 EC2 实例和 IAM 资源的动作，如果这些动作导致不合规。"
    }
  },
  {
    "id": 790,
    "topic": "1",
    "question_en": "A company's web application that is hosted in the AWS Cloud recently increased in popularity. The web application currently exists on a single Amazon EC2 instance in a single public subnet. The web application has not been able to meet the demand of the increased web trafic. The company needs a solution that will provide high availability and scalability to meet the increased user demand without rewriting the web application. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Replace the EC2 instance with a larger compute optimized instance.",
      "B": "Configure Amazon EC2 Auto Scaling with multiple Availability Zones in private subnets.",
      "C": "Configure a NAT gateway in a public subnet to handle web requests.",
      "D": "Replace the EC2 instance with a larger memory optimized instanc",
      "E": "E. Configure an Application Load Balancer in a public subnet to distribute web trafic."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司托管在 AWS 云中的 Web 应用程序最近越来越受欢迎。该 Web 应用程序目前存在于单个公有子网中的单个 Amazon EC2 实例上。该 Web 应用程序一直无法满足不断增长的 Web 流量的需求。该公司需要一个解决方案，该方案将提供高可用性和可扩展性，以满足不断增长的用户需求，而无需重写 Web 应用程序。哪两种步骤的组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "用更大的计算优化实例替换 EC2 实例。",
      "B": "配置 Amazon EC2 Auto Scaling，在私有子网中使用多个可用区。",
      "C": "在公有子网中配置一个 NAT Gateway 来处理 Web 请求。",
      "D": "用更大的内存优化实例替换 EC2 实例。",
      "E": "在公有子网中配置一个 Application Load Balancer 来分发 Web 流量。"
    }
  },
  {
    "id": 791,
    "topic": "1",
    "question_en": "A company has AWS Lambda functions that use environment variables. The company does not want its developers to see environment variables in plaintext. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy code to Amazon EC2 instances instead of using Lambda functions.",
      "B": "Configure SSL encryption on the Lambda functions to use AWS CloudHSM to store and encrypt the environment variables.",
      "C": "Create a certificate in AWS Certificate Manager (ACM). Configure the Lambda functions to use the certificate to encrypt the environment variables.",
      "D": "Create an AWS Key Management Service (AWS KMS) key. Enable encryption helpers on the Lambda functions to use the KMS key to store and encrypt the environment variables."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有使用环境变量的 AWS Lambda 函数。该公司不希望其开发人员以纯文本形式查看环境变量。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将代码部署到 Amazon EC2 实例而不是使用 Lambda 函数。",
      "B": "在 Lambda 函数上配置 SSL 加密，以使用 AWS CloudHSM 存储和加密环境变量。",
      "C": "在 AWS Certificate Manager (ACM) 中创建证书。配置 Lambda 函数使用该证书加密环境变量。",
      "D": "创建 AWS Key Management Service (AWS KMS) 密钥。在 Lambda 函数上启用加密助手，以使用 KMS 密钥存储和加密环境变量。"
    }
  },
  {
    "id": 792,
    "topic": "1",
    "question_en": "An analytics company uses Amazon VPC to run its multi-tier services. The company wants to use RESTful APIs to offer a web analytics service to millions of users. Users must be verified by using an authentication service to access the APIs. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Configure an Amazon Cognito user pool for user authentication. Implement Amazon API Gateway REST APIs with a Cognito authorizer.",
      "B": "Configure an Amazon Cognito identity pool for user authentication. Implement Amazon API Gateway HTTP APIs with a Cognito authorizer.",
      "C": "Configure an AWS Lambda function to handle user authentication. Implement Amazon API Gateway REST APIs with a Lambda authorizer.",
      "D": "Configure an IAM user to handle user authentication. Implement Amazon API Gateway HTTP APIs with an IAM authorizer."
    },
    "correct_answer": "D",
    "vote_percentage": "85%",
    "question_cn": "一家分析公司使用 Amazon VPC 运行其多层服务。该公司希望使用 RESTful APIs 向数百万用户提供 Web 分析服务。用户必须通过身份验证服务进行验证才能访问这些 APIs。哪个解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "配置一个 Amazon Cognito 用户池用于用户身份验证。使用 Cognito 授权器实现 Amazon API Gateway REST APIs。",
      "B": "配置一个 Amazon Cognito 身份池用于用户身份验证。使用 Cognito 授权器实现 Amazon API Gateway HTTP APIs。",
      "C": "配置一个 AWS Lambda 函数来处理用户身份验证。使用 Lambda 授权器实现 Amazon API Gateway REST APIs。",
      "D": "配置一个 IAM 用户来处理用户身份验证。使用 IAM 授权器实现 Amazon API Gateway HTTP APIs。"
    }
  },
  {
    "id": 793,
    "topic": "1",
    "question_en": "A company has a mobile app for customers. The app’s data is sensitive and must be encrypted at rest. The company uses AWS Key Management Service (AWS KMS). The company needs a solution that prevents the accidental deletion of KMS keys. The solution must use Amazon Simple Notification Service (Amazon SNS) to send an email notification to administrators when a user attempts to delete a KMS key. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon EventBridge rule that reacts when a user tries to delete a KMS key. Configure an AWS Config rule that cancels any deletion of a KMS key. Add the AWS Config rule as a target of the EventBridge rule. Create an SNS topic that notifies the administrators.",
      "B": "Create an AWS Lambda function that has custom logic to prevent KMS key deletion. Create an Amazon CloudWatch alarm that is activated when a user tries to delete a KMS key. Create an Amazon EventBridge rule that invokes the Lambda function when the DeleteKey operation is performed. Create an SNS topic. Configure the EventBridge rule to publish an SNS message that notifies the administrators.",
      "C": "Create an Amazon EventBridge rule that reacts when the KMS DeleteKey operation is performed. Configure the rule to initiate an AWS Systems Manager Automation runbook. Configure the runbook to cancel the deletion of the KMS key. Create an SNS topic. Configure the EventBridge rule to publish an SNS message that notifies the administrators.",
      "D": "Create an AWS CloudTrail trail. Configure the trail to deliver logs to a new Amazon CloudWatch log group. Create a CloudWatch alarm based on the metric filter for the CloudWatch log group. Configure the alarm to use Amazon SNS to notify the administrators when the KMS DeleteKey operation is performed."
    },
    "correct_answer": "D",
    "vote_percentage": "80%",
    "question_cn": "一家公司为客户提供移动应用程序。该应用程序的数据很敏感，必须在静态时进行加密。该公司使用 AWS Key Management Service (AWS KMS)。该公司需要一个解决方案来防止意外删除 KMS 密钥。该解决方案必须使用 Amazon Simple Notification Service (Amazon SNS) 向管理员发送电子邮件通知，当用户尝试删除 KMS 密钥时。哪个解决方案能以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon EventBridge 规则，该规则在用户尝试删除 KMS 密钥时做出反应。配置一个 AWS Config 规则，取消任何 KMS 密钥的删除。将 AWS Config 规则添加为 EventBridge 规则的目标。创建一个 SNS 主题，通知管理员。",
      "B": "创建一个 AWS Lambda 函数，该函数具有自定义逻辑以防止 KMS 密钥被删除。创建一个 Amazon CloudWatch 警报，当用户尝试删除 KMS 密钥时激活。创建一个 Amazon EventBridge 规则，该规则在执行 DeleteKey 操作时调用 Lambda 函数。创建一个 SNS 主题。配置 EventBridge 规则以发布 SNS 消息，通知管理员。",
      "C": "创建一个 Amazon EventBridge 规则，该规则在 KMS DeleteKey 操作执行时做出反应。配置该规则以启动一个 AWS Systems Manager Automation runbook。配置 runbook 以取消 KMS 密钥的删除。创建一个 SNS 主题。配置 EventBridge 规则以发布 SNS 消息，通知管理员。",
      "D": "创建一个 AWS CloudTrail 追踪。配置追踪以将日志发送到一个新的 Amazon CloudWatch 日志组。基于 CloudWatch 日志组的指标过滤器创建一个 CloudWatch 警报。配置警报以使用 Amazon SNS 在执行 KMS DeleteKey 操作时通知管理员。"
    }
  },
  {
    "id": 794,
    "topic": "1",
    "question_en": "A company wants to analyze and generate reports to track the usage of its mobile app. The app is popular and has a global user base. The company uses a custom report building program to analyze application usage. The program generates multiple reports during the last week of each month. The program takes less than 10 minutes to produce each report. The company rarely uses the program to generate reports outside of the last week of each month The company wants to generate reports in the least amount of time when the reports are requested. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Run the program by using Amazon EC2 On-Demand Instances. Create an Amazon EventBridge rule to start the EC2 instances when reports are requested. Run the EC2 instances continuously during the last week of each month.",
      "B": "Run the program in AWS Lambda. Create an Amazon EventBridge rule to run a Lambda function when reports are requested.",
      "C": "Run the program in Amazon Elastic Container Service (Amazon ECS). Schedule Amazon ECS to run the program when reports are requested.",
      "D": "Run the program by using Amazon EC2 Spot Instances. Create an Amazon EventBndge rule to start the EC2 instances when reports are requested. Run the EC2 instances continuously during the last week of each month."
    },
    "correct_answer": "B",
    "vote_percentage": "60%",
    "question_cn": "一家公司希望分析并生成报告，以跟踪其移动应用程序的使用情况。该应用程序很受欢迎，并且拥有全球用户群。该公司使用自定义报告构建程序来分析应用程序的使用情况。该程序在每个月的最后一周生成多个报告。该程序生成每个报告需要不到 10 分钟的时间。该公司很少在每个月最后一周之外使用该程序生成报告。该公司希望在报告被请求时，以最少的时间生成报告。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EC2 按需实例运行该程序。创建 Amazon EventBridge 规则以在请求报告时启动 EC2 实例。在每个月的最后一周持续运行 EC2 实例。",
      "B": "在 AWS Lambda 中运行该程序。创建 Amazon EventBridge 规则以在请求报告时运行 Lambda 函数。",
      "C": "在 Amazon Elastic Container Service (Amazon ECS) 中运行该程序。调度 Amazon ECS 在请求报告时运行该程序。",
      "D": "使用 Amazon EC2 Spot 实例运行该程序。创建 Amazon EventBridge 规则以在请求报告时启动 EC2 实例。在每个月的最后一周持续运行 EC2 实例。"
    }
  },
  {
    "id": 795,
    "topic": "1",
    "question_en": "A company is designing a tightly coupled high performance computing (HPC) environment in the AWS Cloud. The company needs to include features that will optimize the HPC environment for networking and storage. Which combination of solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an accelerator in AWS Global Accelerator. Configure custom routing for the accelerator.",
      "B": "Create an Amazon FSx for Lustre file system. Configure the file system with scratch storage.",
      "C": "Create an Amazon CloudFront distribution. Configure the viewer protocol policy to be HTTP and HTTPS.",
      "D": "Launch Amazon EC2 instances. Attach an Elastic Fabric Adapter (EFA) to the instances",
      "E": "Create an AWS Elastic Beanstalk deployment to manage the environment."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 AWS 云中设计一个紧密耦合的高性能计算 (HPC) 环境。公司需要包含可以优化 HPC 环境网络和存储的功能。哪种解决方案组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 AWS Global Accelerator 中创建一个加速器。为加速器配置自定义路由。",
      "B": "创建一个 Amazon FSx for Lustre 文件系统。使用临时存储配置文件系统。",
      "C": "创建一个 Amazon CloudFront 分发。将查看器协议策略配置为 HTTP 和 HTTPS。",
      "D": "启动 Amazon EC2 实例。将 Elastic Fabric Adapter (EFA) 附加到实例。",
      "E": "创建一个 AWS Elastic Beanstalk 部署来管理环境。"
    }
  },
  {
    "id": 796,
    "topic": "1",
    "question_en": "A company needs a solution to prevent photos with unwanted content from being uploaded to the company's web application. The solution must not involve training a machine learning (ML) model. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create and deploy a model by using Amazon SageMaker Autopilot. Create a real-time endpoint that the web application invokes when new photos are uploaded.",
      "B": "Create an AWS Lambda function that uses Amazon Rekognition to detect unwanted content. Create a Lambda function URL that the web application invokes when new photos are uploaded.",
      "C": "Create an Amazon CloudFront function that uses Amazon Comprehend to detect unwanted content. Associate the function with the web application.",
      "D": "Create an AWS Lambda function that uses Amazon Rekognition Video to detect unwanted content. Create a Lambda function URL that the web application invokes when new photos are uploaded."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要一个解决方案，以防止包含不必要内容的照片上传到公司的 Web 应用程序。该解决方案不得涉及训练机器学习 (ML) 模型。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon SageMaker Autopilot 创建并部署一个模型。创建一个实时终端节点，当上传新照片时，Web 应用程序会调用该节点。",
      "B": "创建一个 AWS Lambda 函数，该函数使用 Amazon Rekognition 检测不需要的内容。创建一个 Lambda 函数 URL，当上传新照片时，Web 应用程序会调用该 URL。",
      "C": "创建一个 Amazon CloudFront 函数，该函数使用 Amazon Comprehend 检测不需要的内容。将该函数与 Web 应用程序关联。",
      "D": "创建一个 AWS Lambda 函数，该函数使用 Amazon Rekognition Video 检测不需要的内容。创建一个 Lambda 函数 URL，当上传新照片时，Web 应用程序会调用该 URL。"
    }
  },
  {
    "id": 797,
    "topic": "1",
    "question_en": "A company uses AWS to run its ecommerce platform. The platform is critical to the company's operations and has a high volume of trafic and transactions. The company configures a multi-factor authentication (MFA) device to secure its AWS account root user credentials. The company wants to ensure that it will not lose access to the root user account if the MFA device is lost. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up a backup administrator account that the company can use to log in if the company loses the MFA device.",
      "B": "Add multiple MFA devices for the root user account to handle the disaster scenario.",
      "C": "Create a new administrator account when the company cannot access the root account.",
      "D": "Attach the administrator policy to another IAM user when the company cannot access the root account."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 AWS 运行其电子商务平台。该平台对公司的运营至关重要，并且拥有大量的流量和交易。该公司配置了多因素身份验证 (MFA) 设备来保护其 AWS 账户的根用户凭证。该公司希望确保如果 MFA 设备丢失，它将不会失去对根用户账户的访问权限。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置一个备用管理员账户，以便在公司丢失 MFA 设备时登录。",
      "B": "为根用户账户添加多个 MFA 设备以处理灾难场景。",
      "C": "当公司无法访问根账户时，创建一个新的管理员账户。",
      "D": "当公司无法访问根账户时，将管理员策略附加到另一个 IAM 用户。"
    }
  },
  {
    "id": 798,
    "topic": "1",
    "question_en": "A social media company is creating a rewards program website for its users. The company gives users points when users create and upload videos to the website. Users redeem their points for gifts or discounts from the company's afiliated partners. A unique ID identifies users. The partners refer to this ID to verify user eligibility for rewards. The partners want to receive notification of user IDs through an HTTP endpoint when the company gives users points. Hundreds of vendors are interested in becoming afiliated partners every day. The company wants to design an architecture that gives the website the ability to add partners rapidly in a scalable way. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Create an Amazon Timestream database to keep a list of afiliated partners. Implement an AWS Lambda function to read the list. Configure the Lambda function to send user IDs to each partner when the company gives users points.",
      "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Choose an endpoint protocol. Subscribe the partners to the topic. Publish user IDs to the topic when the company gives users points.",
      "C": "Create an AWS Step Functions state machine. Create a task for every afiliated partner. Invoke the state machine with user IDs as input when the company gives users points.",
      "D": "Create a data stream in Amazon Kinesis Data Streams. Implement producer and consumer applications. Store a list of afiliated partners in the data stream. Send user IDs when the company gives users points."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家社交媒体公司正在为其用户创建一个奖励计划网站。当用户创建并将视频上传到网站时，该公司会向用户提供积分。用户可以用他们的积分兑换公司附属合作伙伴提供的礼物或折扣。唯一的 ID 标识用户。合作伙伴参考此 ID 来验证用户的奖励资格。合作伙伴希望在公司向用户提供积分时，通过 HTTP 端点接收用户 ID 的通知。每天都有数百家供应商有兴趣成为附属合作伙伴。该公司希望设计一个架构，使网站能够以可扩展的方式快速添加合作伙伴。哪种解决方案将以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Timestream 数据库来保存附属合作伙伴的列表。实施一个 AWS Lambda 函数来读取该列表。配置 Lambda 函数，在公司向用户提供积分时，将用户 ID 发送到每个合作伙伴。",
      "B": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。选择一个端点协议。让合作伙伴订阅该主题。在公司向用户提供积分时，将用户 ID 发布到该主题。",
      "C": "创建一个 AWS Step Functions 状态机。为每个附属合作伙伴创建一个任务。在公司向用户提供积分时，使用用户 ID 作为输入来调用该状态机。",
      "D": "在 Amazon Kinesis Data Streams 中创建一个数据流。实施生产者和消费者应用程序。在数据流中存储附属合作伙伴的列表。在公司向用户提供积分时，发送用户 ID。"
    }
  },
  {
    "id": 799,
    "topic": "1",
    "question_en": "A company needs to extract the names of ingredients from recipe records that are stored as text files in an Amazon S3 bucket. A web application will use the ingredient names to query an Amazon DynamoDB table and determine a nutrition score. The application can handle non-food records and errors. The company does not have any employees who have machine learning knowledge to develop this solution. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use S3 Event Notifications to invoke an AWS Lambda function when PutObject requests occur. Program the Lambda function to analyze the object and extract the ingredient names by using Amazon Comprehend. Store the Amazon Comprehend output in the DynamoDB table.",
      "B": "Use an Amazon EventBridge rule to invoke an AWS Lambda function when PutObject requests occur. Program the Lambda function to analyze the object by using Amazon Forecast to extract the ingredient names. Store the Forecast output in the DynamoDB table.",
      "C": "Use S3 Event Notifications to invoke an AWS Lambda function when PutObject requests occur. Use Amazon Polly to create audio recordings of the recipe records. Save the audio files in the S3 bucket. Use Amazon Simple Notification Service (Amazon SNS) to send a URL as a message to employees. Instruct the employees to listen to the audio files and calculate the nutrition score. Store the ingredient names in the DynamoDB table.",
      "D": "Use an Amazon EventBridge rule to invoke an AWS Lambda function when a PutObject request occurs. Program the Lambda function to analyze the object and extract the ingredient names by using Amazon SageMaker. Store the inference output from the SageMaker endpoint in the DynamoDB table."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要从存储为文本文件的、位于 Amazon S3 存储桶中的食谱记录中提取配料名称。一个 Web 应用程序将使用配料名称来查询 Amazon DynamoDB 表并确定营养评分。该应用程序可以处理非食品记录和错误。该公司没有任何具备机器学习知识的员工来开发此解决方案。哪个解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 S3 事件通知在 PutObject 请求发生时调用 AWS Lambda 函数。对 Lambda 函数进行编程，以使用 Amazon Comprehend 分析对象并提取配料名称。将 Amazon Comprehend 输出存储在 DynamoDB 表中。",
      "B": "使用 Amazon EventBridge 规则在 PutObject 请求发生时调用 AWS Lambda 函数。对 Lambda 函数进行编程，以使用 Amazon Forecast 分析对象来提取配料名称。将 Forecast 输出存储在 DynamoDB 表中。",
      "C": "使用 S3 事件通知在 PutObject 请求发生时调用 AWS Lambda 函数。使用 Amazon Polly 创建食谱记录的录音。将音频文件保存在 S3 存储桶中。使用 Amazon Simple Notification Service (Amazon SNS) 将 URL 作为消息发送给员工。指示员工收听音频文件并计算营养评分。将配料名称存储在 DynamoDB 表中。",
      "D": "使用 Amazon EventBridge 规则在 PutObject 请求发生时调用 AWS Lambda 函数。对 Lambda 函数进行编程，以使用 Amazon SageMaker 分析对象并提取配料名称。将 SageMaker 终端节点的推理输出存储在 DynamoDB 表中。"
    }
  },
  {
    "id": 800,
    "topic": "1",
    "question_en": "A company needs to create an AWS Lambda function that will run in a VPC in the company's primary AWS account. The Lambda function needs to access files that the company stores in an Amazon Elastic File System (Amazon EFS) file system. The EFS file system is located in a secondary AWS account. As the company adds files to the file system, the solution must scale to meet the demand. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a new EFS file system in the primary account. Use AWS DataSync to copy the contents of the original EFS file system to the new EFS file system.",
      "B": "Create a VPC peering connection between the VPCs that are in the primary account and the secondary account.",
      "C": "Create a second Lambda function in the secondary account that has a mount that is configured for the file system. Use the primary account's Lambda function to invoke the secondary account's Lambda function.",
      "D": "Move the contents of the file system to a Lambda layer. Configure the Lambda layer's permissions to allow the company's secondary account to use the Lambda layer."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要创建一个 AWS Lambda 函数，该函数将在公司主 AWS 账户的 VPC 中运行。 Lambda 函数需要访问公司存储在 Amazon EFS 文件系统中的文件。 EFS 文件系统位于辅助 AWS 账户中。 随着公司将文件添加到文件系统，解决方案必须扩展以满足需求。 哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "在主账户中创建一个新的 EFS 文件系统。 使用 AWS DataSync 将原始 EFS 文件系统的内容复制到新的 EFS 文件系统。",
      "B": "在主账户和辅助账户中的 VPC 之间创建 VPC 对等连接。",
      "C": "在辅助账户中创建第二个 Lambda 函数，该函数具有为文件系统配置的挂载。 使用主账户的 Lambda 函数来调用辅助账户的 Lambda 函数。",
      "D": "将文件系统的内容移动到 Lambda 层。 将 Lambda 层的权限配置为允许公司的辅助账户使用 Lambda 层。"
    }
  },
  {
    "id": 801,
    "topic": "1",
    "question_en": "A financial company needs to handle highly sensitive data. The company will store the data in an Amazon S3 bucket. The company needs to ensure that the data is encrypted in transit and at rest. The company must manage the encryption keys outside the AWS Cloud. Which solution will meet these requirements?",
    "options_en": {
      "A": "Encrypt the data in the S3 bucket with server-side encryption (SSE) that uses an AWS Key Management Service (AWS KMS) customer managed key.",
      "B": "Encrypt the data in the S3 bucket with server-side encryption (SSE) that uses an AWS Key Management Service (AWS KMS) AWS managed key.",
      "C": "Encrypt the data in the S3 bucket with the default server-side encryption (SSE).",
      "D": "Encrypt the data at the company's data center before storing the data in the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家金融公司需要处理高度敏感的数据。该公司将数据存储在 Amazon S3 存储桶中。该公司需要确保数据在传输中和静态时都已加密。该公司必须在 AWS 云之外管理加密密钥。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用服务器端加密 (SSE) 对 S3 存储桶中的数据进行加密，该加密使用 AWS Key Management Service (AWS KMS) 客户托管密钥。",
      "B": "使用服务器端加密 (SSE) 对 S3 存储桶中的数据进行加密，该加密使用 AWS Key Management Service (AWS KMS) AWS 托管密钥。",
      "C": "使用默认的服务器端加密 (SSE) 对 S3 存储桶中的数据进行加密。",
      "D": "在将数据存储在 S3 存储桶中之前，在公司的数据中心对数据进行加密。"
    }
  },
  {
    "id": 802,
    "topic": "1",
    "question_en": "A company wants to run its payment application on AWS. The application receives payment notifications from mobile devices. Payment notifications require a basic validation before they are sent for further processing. The backend processing application is long running and requires compute and memory to be adjusted. The company does not want to manage the infrastructure. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Integrate the queue with an Amazon EventBridge rule to receive payment notifications from mobile devices. Configure the rule to validate payment notifications and send the notifications to the backend application. Deploy the backend application on Amazon Elastic Kubernetes Service (Amazon EKS) Anywhere. Create a standalone cluster.",
      "B": "Create an Amazon API Gateway API. Integrate the API with an AWS Step Functions state machine to receive payment notifications from mobile devices. Invoke the state machine to validate payment notifications and send the notifications to the backend application. Deploy the backend application on Amazon Elastic Kubernetes Service (Amazon EKS). Configure an EKS cluster with self-managed nodes.",
      "C": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Integrate the queue with an Amazon EventBridge rule to receive payment notifications from mobile devices. Configure the rule to validate payment notifications and send the notifications to the backend application. Deploy the backend application on Amazon EC2 Spot Instances. Configure a Spot Fleet with a default allocation strategy.",
      "D": "Create an Amazon API Gateway API. Integrate the API with AWS Lambda to receive payment notifications from mobile devices. Invoke a Lambda function to validate payment notifications and send the notifications to the backend application. Deploy the backend application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon ECS with an AWS Fargate launch type."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望在 AWS 上运行其支付应用程序。该应用程序接收来自移动设备的支付通知。支付通知在发送进行进一步处理之前需要进行基本的验证。后端处理应用程序是长时间运行的，需要调整计算和内存。该公司不希望管理基础设施。哪个解决方案能以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将队列与 Amazon EventBridge 规则集成，以接收来自移动设备的支付通知。将该规则配置为验证支付通知并将通知发送到后端应用程序。将后端应用程序部署在 Amazon Elastic Kubernetes Service (Amazon EKS) Anywhere 上。创建一个独立的集群。",
      "B": "创建一个 Amazon API Gateway API。将 API 与 AWS Step Functions 状态机集成，以接收来自移动设备的支付通知。调用状态机来验证支付通知并将通知发送到后端应用程序。将后端应用程序部署在 Amazon Elastic Kubernetes Service (Amazon EKS) 上。配置一个具有自管理节点的 EKS 集群。",
      "C": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。将队列与 Amazon EventBridge 规则集成，以接收来自移动设备的支付通知。将该规则配置为验证支付通知并将通知发送到后端应用程序。将后端应用程序部署在 Amazon EC2 Spot Instances 上。使用默认分配策略配置一个 Spot Fleet。",
      "D": "创建一个 Amazon API Gateway API。将 API 与 AWS Lambda 集成，以接收来自移动设备的支付通知。调用 Lambda 函数来验证支付通知并将通知发送到后端应用程序。将后端应用程序部署在 Amazon Elastic Container Service (Amazon ECS) 上。使用 AWS Fargate 启动类型配置 Amazon ECS。"
    }
  },
  {
    "id": 803,
    "topic": "1",
    "question_en": "A solutions architect is designing a user authentication solution for a company. The solution must invoke two-factor authentication for users that log in from inconsistent geographical locations, IP addresses, or devices. The solution must also be able to scale up to accommodate millions of users. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure Amazon Cognito user pools for user authentication. Enable the risk-based adaptive authentication feature with multifactor authentication (MFA).",
      "B": "Configure Amazon Cognito identity pools for user authentication. Enable multi-factor authentication (MFA).",
      "C": "Configure AWS Identity and Access Management (IAM) users for user authentication. Attach an IAM policy that allows the AllowManageOwnUserMFA action.",
      "D": "Configure AWS IAM Identity Center (AWS Single Sign-On) authentication for user authentication. Configure the permission sets to require multi-factor authentication (MFA)."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在为一家公司设计用户身份验证解决方案。该解决方案必须为从不一致的地理位置、IP 地址或设备登录的用户调用双因素身份验证。该解决方案还必须能够扩展以容纳数百万用户。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Cognito 用户池进行用户身份验证。启用具有多因素身份验证 (MFA) 的基于风险的自适应身份验证功能。",
      "B": "配置 Amazon Cognito 身份池进行用户身份验证。启用多因素身份验证 (MFA)。",
      "C": "配置 AWS Identity and Access Management (IAM) 用户进行用户身份验证。附加一个允许 AllowManageOwnUserMFA 操作的 IAM 策略。",
      "D": "配置 AWS IAM Identity Center (AWS Single Sign-On) 身份验证进行用户身份验证。配置权限集以要求多因素身份验证 (MFA)。"
    }
  },
  {
    "id": 804,
    "topic": "1",
    "question_en": "A company has an Amazon S3 data lake. The company needs a solution that transforms the data from the data lake and loads the data into a data warehouse every day. The data warehouse must have massively parallel processing (MPP) capabilities. Data analysts then need to create and train machine learning (ML) models by using SQL commands on the data. The solution must use serverless AWS services wherever possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Run a daily Amazon EMR job to transform the data and load the data into Amazon Redshift. Use Amazon Redshift ML to create and train the ML models.",
      "B": "Run a daily Amazon EMR job to transform the data and load the data into Amazon Aurora Serverless. Use Amazon Aurora ML to create and train the ML models.",
      "C": "Run a daily AWS Glue job to transform the data and load the data into Amazon Redshift Serverless. Use Amazon Redshift ML to create and train the ML models.",
      "D": "Run a daily AWS Glue job to transform the data and load the data into Amazon Athena tables. Use Amazon Athena ML to create and train the ML models."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个 Amazon S3 数据湖。该公司需要一个解决方案，每天转换来自数据湖的数据，并将数据加载到数据仓库中。数据仓库必须具有大规模并行处理 (MPP) 功能。然后，数据分析师需要使用 SQL 命令在数据上创建和训练机器学习 (ML) 模型。该解决方案必须尽可能使用无服务器 AWS 服务。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "运行每日 Amazon EMR 作业，以转换数据并将数据加载到 Amazon Redshift 中。使用 Amazon Redshift ML 创建和训练 ML 模型。",
      "B": "运行每日 Amazon EMR 作业，以转换数据并将数据加载到 Amazon Aurora Serverless 中。使用 Amazon Aurora ML 创建和训练 ML 模型。",
      "C": "运行每日 AWS Glue 作业，以转换数据并将数据加载到 Amazon Redshift Serverless 中。使用 Amazon Redshift ML 创建和训练 ML 模型。",
      "D": "运行每日 AWS Glue 作业，以转换数据并将数据加载到 Amazon Athena 表中。使用 Amazon Athena ML 创建和训练 ML 模型。"
    }
  },
  {
    "id": 805,
    "topic": "1",
    "question_en": "A company runs containers in a Kubernetes environment in the company's local data center. The company wants to use Amazon Elastic Kubernetes Service (Amazon EKS) and other AWS managed services. Data must remain locally in the company's data center and cannot be stored in any remote site or cloud to maintain compliance. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy AWS Local Zones in the company's data center.",
      "B": "Use an AWS Snowmobile in the company's data center.",
      "C": "Install an AWS Outposts rack in the company's data center.",
      "D": "Install an AWS Snowball Edge Storage Optimized node in the data center."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其本地数据中心内的 Kubernetes 环境中运行容器。该公司希望使用 Amazon Elastic Kubernetes Service (Amazon EKS) 和其他 AWS 托管服务。为了保持合规性，数据必须保留在该公司的数据中心内，并且不能存储在任何远程站点或云中。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在该公司的数据中心部署 AWS Local Zones。",
      "B": "在该公司的数据中心使用 AWS Snowmobile。",
      "C": "在该公司的数据中心安装 AWS Outposts 机架。",
      "D": "在该数据中心安装 AWS Snowball Edge 存储优化设备。"
    }
  },
  {
    "id": 806,
    "topic": "1",
    "question_en": "A social media company has workloads that collect and process data. The workloads store the data in on-premises NFS storage. The data store cannot scale fast enough to meet the company’s expanding business needs. The company wants to migrate the current data store to AWS. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Set up an AWS Storage Gateway Volume Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.",
      "B": "Set up an AWS Storage Gateway Amazon S3 File Gateway. Use an Amazon S3 Lifecycle policy to transition the data to the appropriate storage class.",
      "C": "Use the Amazon Elastic File System (Amazon EFS) Standard-Infrequent Access (Standard-IA) storage class. Activate the infrequent access lifecycle policy.",
      "D": "Use the Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA) storage class. Activate the infrequent access lifecycle policy."
    },
    "correct_answer": "D",
    "vote_percentage": "90%",
    "question_cn": "一家社交媒体公司有收集和处理数据的业务。这些业务将数据存储在本地 NFS 存储中。数据存储无法快速扩展以满足公司不断增长的业务需求。该公司希望将当前数据存储迁移到 AWS。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "设置 AWS Storage Gateway Volume Gateway。 使用 Amazon S3 生命周期策略将数据转换为适当的存储类别。",
      "B": "设置 AWS Storage Gateway Amazon S3 File Gateway。 使用 Amazon S3 生命周期策略将数据转换为适当的存储类别。",
      "C": "使用 Amazon EFS 标准-不频繁访问（标准-IA）存储类别。 激活不频繁访问生命周期策略。",
      "D": "使用 Amazon EFS 单区-不频繁访问（单区-IA）存储类别。 激活不频繁访问生命周期策略。"
    }
  },
  {
    "id": 807,
    "topic": "1",
    "question_en": "A company uses high concurrency AWS Lambda functions to process a constantly increasing number of messages in a message queue during marketing events. The Lambda functions use CPU intensive code to process the messages. The company wants to reduce the compute costs and to maintain service latency for its customers. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure reserved concurrency for the Lambda functions. Decrease the memory allocated to the Lambda functions.",
      "B": "Configure reserved concurrency for the Lambda functions. Increase the memory according to AWS Compute Optimizer recommendations.",
      "C": "Configure provisioned concurrency for the Lambda functions. Decrease the memory allocated to the Lambda functions.",
      "D": "Configure provisioned concurrency for the Lambda functions. Increase the memory according to AWS Compute Optimizer recommendations."
    },
    "correct_answer": "C",
    "vote_percentage": "69%",
    "question_cn": "一家公司使用高并发的 AWS Lambda 函数来处理营销活动期间消息队列中不断增加的消息数量。Lambda 函数使用 CPU 密集型代码来处理消息。该公司希望降低计算成本并保持其客户的服务延迟。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Lambda 函数配置预留并发。减少分配给 Lambda 函数的内存。",
      "B": "为 Lambda 函数配置预留并发。根据 AWS Compute Optimizer 的建议增加内存。",
      "C": "为 Lambda 函数配置预置并发。减少分配给 Lambda 函数的内存。",
      "D": "为 Lambda 函数配置预置并发。根据 AWS Compute Optimizer 的建议增加内存。"
    }
  },
  {
    "id": 808,
    "topic": "1",
    "question_en": "A company runs its workloads on Amazon Elastic Container Service (Amazon ECS). The container images that the ECS task definition uses need to be scanned for Common Vulnerabilities and Exposures (CVEs). New container images that are created also need to be scanned. Which solution will meet these requirements with the FEWEST changes to the workloads?",
    "options_en": {
      "A": "Use Amazon Elastic Container Registry (Amazon ECR) as a private image repository to store the container images. Specify scan on push filters for the ECR basic scan.",
      "B": "Store the container images in an Amazon S3 bucket. Use Amazon Macie to scan the images. Use an S3 Event Notification to initiate a Macie scan for every event with an s3:ObjectCreated:Put event type.",
      "C": "Deploy the workloads to Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Container Registry (Amazon ECR) as a private image repository. Specify scan on push filters for the ECR enhanced scan.",
      "D": "Store the container images in an Amazon S3 bucket that has versioning enabled. Configure an S3 Event Notification for s3:ObjectCreated:* events to invoke an AWS Lambda function. Configure the Lambda function to initiate an Amazon Inspector scan."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Amazon Elastic Container Service (Amazon ECS) 上运行其工作负载。 ECS 任务定义使用的容器镜像需要扫描 Common Vulnerabilities and Exposures (CVE)。还需要扫描创建的新容器镜像。哪种解决方案能够以对工作负载影响最小的方式满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Registry (Amazon ECR) 作为私有镜像仓库来存储容器镜像。为 ECR 基本扫描指定推送扫描过滤器。",
      "B": "将容器镜像存储在 Amazon S3 存储桶中。使用 Amazon Macie 扫描镜像。使用 S3 事件通知为每个具有 s3:ObjectCreated:Put 事件类型的事件启动 Macie 扫描。",
      "C": "将工作负载部署到 Amazon Elastic Kubernetes Service (Amazon EKS)。 使用 Amazon Elastic Container Registry (Amazon ECR) 作为私有镜像仓库。 为 ECR 增强扫描指定推送扫描过滤器。",
      "D": "将容器镜像存储在已启用版本控制的 Amazon S3 存储桶中。 配置 S3 事件通知，用于 s3:ObjectCreated:* 事件以调用 AWS Lambda 函数。 配置 Lambda 函数以启动 Amazon Inspector 扫描。"
    }
  },
  {
    "id": 809,
    "topic": "1",
    "question_en": "A company uses an AWS Batch job to run its end-of-day sales process. The company needs a serverless solution that will invoke a third-party reporting application when the AWS Batch job is successful. The reporting application has an HTTP API interface that uses username and password authentication. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an Amazon EventBridge rule to match incoming AWS Batch job SUCCEEDED events. Configure the third-party API as an EventBridge API destination with a username and password. Set the API destination as the EventBridge rule target.",
      "B": "Configure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events. Configure an AWS Lambda function to invoke the third-party API by using a username and password. Set the Lambda function as the EventBridge rule target.",
      "C": "Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure an HTTP proxy integration on the API Gateway REST API to invoke the third-party API by using a username and password.",
      "D": "Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure a proxy integration on the API Gateway REST API to an AWS Lambda function. Configure the Lambda function to invoke the third-party API by using a username and password."
    },
    "correct_answer": "D",
    "vote_percentage": "61%",
    "question_cn": "一家公司使用 AWS Batch 作业来运行其每日销售流程。该公司需要一个无服务器解决方案，以便在 AWS Batch 作业成功时调用第三方报告应用程序。该报告应用程序具有使用用户名和密码身份验证的 HTTP API 接口。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon EventBridge 规则以匹配传入的 AWS Batch 作业 SUCCEEDED 事件。将第三方 API 配置为带有用户名和密码的 EventBridge API 目标。将 API 目标设置为 EventBridge 规则目标。",
      "B": "配置 Amazon EventBridge Scheduler 以匹配传入的 AWS Batch 作业 SUCCEEDED 事件。配置一个 AWS Lambda 函数，使用用户名和密码调用第三方 API。将 Lambda 函数设置为 EventBridge 规则目标。",
      "C": "配置 AWS Batch 作业以将作业 SUCCEEDED 事件发布到 Amazon API Gateway REST API。在 API Gateway REST API 上配置 HTTP 代理集成，以便使用用户名和密码调用第三方 API。",
      "D": "配置 AWS Batch 作业以将作业 SUCCEEDED 事件发布到 Amazon API Gateway REST API。在 API Gateway REST API 上配置代理集成到 AWS Lambda 函数。配置 Lambda 函数以使用用户名和密码调用第三方 API。"
    }
  },
  {
    "id": 810,
    "topic": "1",
    "question_en": "A company collects and processes data from a vendor. The vendor stores its data in an Amazon RDS for MySQL database in the vendor's own AWS account. The company’s VPC does not have an internet gateway, an AWS Direct Connect connection, or an AWS Site-to-Site VPN connection. The company needs to access the data that is in the vendor database. Which solution will meet this requirement?",
    "options_en": {
      "A": "Instruct the vendor to sign up for the AWS Hosted Connection Direct Connect Program. Use VPC peering to connect the company's VPC and the vendor's VPC.",
      "B": "Configure a client VPN connection between the company's VPC and the vendor's VPC. Use VPC peering to connect the company's VPC and the vendor's VPC.",
      "C": "Instruct the vendor to create a Network Load Balancer (NLB). Place the NLB in front of the Amazon RDS for MySQL database. Use AWS PrivateLink to integrate the company's VPC and the vendor's VPC.",
      "D": "Use AWS Transit Gateway to integrate the company's VPC and the vendor's VPC. Use VPC peering to connect the company’s VPC and the vendor's VPC."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司从供应商处收集和处理数据。供应商将其数据存储在供应商自己的 AWS 账户中的 Amazon RDS for MySQL 数据库中。该公司的 VPC 没有互联网网关、AWS Direct Connect 连接或 AWS Site-to-Site VPN 连接。该公司需要访问供应商数据库中的数据。哪种解决方案将满足此要求？",
    "options_cn": {
      "A": "指示供应商注册 AWS Hosted Connection Direct Connect Program。使用 VPC 对等互连来连接公司的 VPC 和供应商的 VPC。",
      "B": "在公司的 VPC 和供应商的 VPC 之间配置客户端 VPN 连接。使用 VPC 对等互连来连接公司的 VPC 和供应商的 VPC。",
      "C": "指示供应商创建一个 Network Load Balancer (NLB)。将 NLB 放置在 Amazon RDS for MySQL 数据库的前面。使用 AWS PrivateLink 来集成公司的 VPC 和供应商的 VPC。",
      "D": "使用 AWS Transit Gateway 来集成公司的 VPC 和供应商的 VPC。使用 VPC 对等互连来连接公司的 VPC 和供应商的 VPC。"
    }
  },
  {
    "id": 811,
    "topic": "1",
    "question_en": "A company wants to set up Amazon Managed Grafana as its visualization tool. The company wants to visualize data from its Amazon RDS database as one data source. The company needs a secure solution that will not expose the data over the internet. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon Managed Grafana workspace without a VPC. Create a public endpoint for the RDS database. Configure the public endpoint as a data source in Amazon Managed Grafana.",
      "B": "Create an Amazon Managed Grafana workspace in a VPC. Create a private endpoint for the RDS database. Configure the private endpoint as a data source in Amazon Managed Grafana.",
      "C": "Create an Amazon Managed Grafana workspace without a VPCreate an AWS PrivateLink endpoint to establish a connection between Amazon Managed Grafana and Amazon RDS. Set up Amazon RDS as a data source in Amazon Managed Grafana.",
      "D": "Create an Amazon Managed Grafana workspace in a VPC. Create a public endpoint for the RDS database. Configure the public endpoint as a data source in Amazon Managed Grafana."
    },
    "correct_answer": "B",
    "vote_percentage": "67%",
    "question_cn": "一家公司希望将 Amazon Managed Grafana 设置为其可视化工具。该公司希望将来自 Amazon RDS 数据库的数据可视化为一个数据源。该公司需要一个安全的解决方案，该解决方案不会通过互联网公开数据。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在没有 VPC 的情况下创建 Amazon Managed Grafana 工作区。为 RDS 数据库创建一个公共端点。在 Amazon Managed Grafana 中将公共端点配置为数据源。",
      "B": "在 VPC 中创建 Amazon Managed Grafana 工作区。为 RDS 数据库创建一个私有端点。在 Amazon Managed Grafana 中将私有端点配置为数据源。",
      "C": "在没有 VPC 的情况下创建 Amazon Managed Grafana 工作区。创建一个 AWS PrivateLink 端点以在 Amazon Managed Grafana 和 Amazon RDS 之间建立连接。在 Amazon Managed Grafana 中将 Amazon RDS 设置为数据源。",
      "D": "在 VPC 中创建 Amazon Managed Grafana 工作区。为 RDS 数据库创建一个公共端点。在 Amazon Managed Grafana 中将公共端点配置为数据源。"
    }
  },
  {
    "id": 812,
    "topic": "1",
    "question_en": "A company hosts a data lake on Amazon S3. The data lake ingests data in Apache Parquet format from various data sources. The company uses multiple transformation steps to prepare the ingested data. The steps include filtering of anomalies, normalizing of data to standard date and time values, and generation of aggregates for analyses. The company must store the transformed data in S3 buckets that data analysts access. The company needs a prebuilt solution for data transformation that does not require code. The solution must provide data lineage and data profiling. The company needs to share the data transformation steps with employees throughout the company. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure an AWS Glue Studio visual canvas to transform the data. Share the transformation steps with employees by using AWS Glue jobs.",
      "B": "Configure Amazon EMR Serverless to transform the data. Share the transformation steps with employees by using EMR Serverless jobs.",
      "C": "Configure AWS Glue DataBrew to transform the data. Share the transformation steps with employees by using DataBrew recipes.",
      "D": "Create Amazon Athena tables for the data. Write Athena SQL queries to transform the data. Share the Athena SQL queries with employees."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 Amazon S3 上托管数据湖。数据湖以 Apache Parquet 格式从各种数据 源 摄取数据。该公司使用多个转换步骤来准备摄取的数据。这些步骤包括过滤异常值、将数据标准化为标准日期和时间值，以及生成用于分析的聚合。该公司必须将转换后的数据存储在数据分析师访问的 S3 存储桶中。该公司需要一个无需代码即可进行数据转换的预构建解决方案。该解决方案必须提供数据沿袭和数据分析。该公司需要与整个公司的员工共享数据转换步骤。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 AWS Glue Studio 可视画布来转换数据。通过使用 AWS Glue 作业与员工共享转换步骤。",
      "B": "配置 Amazon EMR Serverless 来转换数据。通过使用 EMR Serverless 作业与员工共享转换步骤。",
      "C": "配置 AWS Glue DataBrew 来转换数据。通过使用 DataBrew 配方与员工共享转换步骤。",
      "D": "为数据创建 Amazon Athena 表。编写 Athena SQL 查询来转换数据。与员工共享 Athena SQL 查询。"
    }
  },
  {
    "id": 813,
    "topic": "1",
    "question_en": "A solutions architect runs a web application on multiple Amazon EC2 instances that are in individual target groups behind an Application Load Balancer (ALB). Users can reach the application through a public website. The solutions architect wants to allow engineers to use a development version of the website to access one specific development EC2 instance to test new features for the application. The solutions architect wants to use an Amazon Route 53 hosted zone to give the engineers access to the development instance. The solution must automatically route to the development instance even if the development instance is replaced. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an A Record for the development website that has the value set to the ALB. Create a listener rule on the ALB that forwards requests for the development website to the target group that contains the development instance.",
      "B": "Recreate the development instance with a public IP address. Create an A Record for the development website that has the value set to the public IP address of the development instance.",
      "C": "Create an A Record for the development website that has the value set to the ALB. Create a listener rule on the ALB to redirect requests for the development website to the public IP address of the development instance.",
      "D": "Place all the instances in the same target group. Create an A Record for the development website. Set the value to the ALB. Create a listener rule on the ALB that forwards requests for the development website to the target group."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师在多个 Amazon EC2 实例上运行一个 Web 应用程序，这些实例位于 Application Load Balancer (ALB) 之后的单独目标组中。用户可以通过公共网站访问该应用程序。解决方案架构师希望允许工程师使用网站的开发版本来访问一个特定的开发 EC2 实例，以测试该应用程序的新功能。解决方案架构师希望使用 Amazon Route 53 托管区域为工程师提供对开发实例的访问权限。该解决方案必须自动路由到开发实例，即使开发实例被替换。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为开发网站创建一个 A 记录，其值设置为 ALB。在 ALB 上创建一个侦听器规则，将开发网站的请求转发到包含开发实例的目标组。",
      "B": "使用公共 IP 地址重新创建开发实例。为开发网站创建一个 A 记录，其值设置为开发实例的公共 IP 地址。",
      "C": "为开发网站创建一个 A 记录，其值设置为 ALB。在 ALB 上创建一个侦听器规则，将开发网站的请求重定向到开发实例的公共 IP 地址。",
      "D": "将所有实例放在同一个目标组中。为开发网站创建一个 A 记录。将值设置为 ALB。在 ALB 上创建一个侦听器规则，将开发网站的请求转发到目标组。"
    }
  },
  {
    "id": 814,
    "topic": "1",
    "question_en": "A company runs a container application on a Kubernetes cluster in the company's data center. The application uses Advanced Message Queuing Protocol (AMQP) to communicate with a message queue. The data center cannot scale fast enough to meet the company’s expanding business needs. The company wants to migrate the workloads to AWS. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Migrate the container application to Amazon Elastic Container Service (Amazon ECS). Use Amazon Simple Queue Service (Amazon SQS) to retrieve the messages.",
      "B": "Migrate the container application to Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon MQ to retrieve the messages.",
      "C": "Use highly available Amazon EC2 instances to run the application. Use Amazon MQ to retrieve the messages.",
      "D": "Use AWS Lambda functions to run the application. Use Amazon Simple Queue Service (Amazon SQS) to retrieve the messages."
    },
    "correct_answer": "A",
    "vote_percentage": "93%",
    "question_cn": "一家公司在其数据中心的 Kubernetes 集群上运行一个容器应用程序。该应用程序使用高级消息队列协议 (AMQP) 与消息队列通信。数据中心无法快速扩展以满足公司不断增长的业务需求。该公司希望将工作负载迁移到 AWS。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "将容器应用程序迁移到 Amazon Elastic Container Service (Amazon ECS)。使用 Amazon Simple Queue Service (Amazon SQS) 检索消息。",
      "B": "将容器应用程序迁移到 Amazon Elastic Kubernetes Service (Amazon EKS)。使用 Amazon MQ 检索消息。",
      "C": "使用高可用 Amazon EC2 实例来运行应用程序。使用 Amazon MQ 检索消息。",
      "D": "使用 AWS Lambda 函数来运行应用程序。使用 Amazon Simple Queue Service (Amazon SQS) 检索消息。"
    }
  },
  {
    "id": 815,
    "topic": "1",
    "question_en": "An online gaming company hosts its platform on Amazon EC2 instances behind Network Load Balancers (NLBs) across multiple AWS Regions. The NLBs can route requests to targets over the internet. The company wants to improve the customer playing experience by reducing end-to- end load time for its global customer base. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create Application Load Balancers (ALBs) in each Region to replace the existing NLBs. Register the existing EC2 instances as targets for the ALBs in each Region.",
      "B": "Configure Amazon Route 53 to route equally weighted trafic to the NLBs in each Region.",
      "C": "Create additional NLBs and EC2 instances in other Regions where the company has large customer bases.",
      "D": "Create a standard accelerator in AWS Global Accelerator. Configure the existing NLBs as target endpoints."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家在线游戏公司在其平台上的 Amazon EC2 实例上托管平台，这些实例位于多个 AWS 区域内的网络负载均衡器 (NLB) 之后。 NLB 可以通过互联网将请求路由到目标。该公司希望通过减少其全球客户群的端到端加载时间来改善客户的游戏体验。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在每个区域创建 Application Load Balancer (ALB) 以替换现有的 NLB。将现有的 EC2 实例注册为每个区域中 ALB 的目标。",
      "B": "配置 Amazon Route 53 以将流量平均路由到每个区域中的 NLB。",
      "C": "在公司拥有大量客户群的其他区域中创建额外的 NLB 和 EC2 实例。",
      "D": "在 AWS Global Accelerator 中创建一个标准加速器。将现有的 NLB 配置为目标端点。"
    }
  },
  {
    "id": 816,
    "topic": "1",
    "question_en": "A company has an on-premises application that uses SFTP to collect financial data from multiple vendors. The company is migrating to the AWS Cloud. The company has created an application that uses Amazon S3 APIs to upload files from vendors. Some vendors run their systems on legacy applications that do not support S3 APIs. The vendors want to continue to use SFTP-based applications to upload data. The company wants to use managed services for the needs of the vendors that use legacy applications. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an AWS Database Migration Service (AWS DMS) instance to replicate data from the storage of the vendors that use legacy applications to Amazon S3. Provide the vendors with the credentials to access the AWS DMS instance.",
      "B": "Create an AWS Transfer Family endpoint for vendors that use legacy applications.",
      "C": "Configure an Amazon EC2 instance to run an SFTP server. Instruct the vendors that use legacy applications to use the SFTP server to upload data.",
      "D": "Configure an Amazon S3 File Gateway for vendors that use legacy applications to upload files to an SMB file share."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个本地应用程序，该应用程序使用 SFTP 从多个供应商处收集财务数据。该公司正在迁移到 AWS 云。该公司创建了一个使用 Amazon S3 API 从供应商处上传文件的应用程序。一些供应商在其不支持 S3 API 的旧版应用程序上运行其系统。供应商希望继续使用基于 SFTP 的应用程序来上传数据。该公司希望使用托管服务来满足使用旧版应用程序的供应商的需求。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Database Migration Service (AWS DMS) 实例，以将数据从使用旧版应用程序的供应商的存储复制到 Amazon S3。向供应商提供访问 AWS DMS 实例的凭证。",
      "B": "为使用旧版应用程序的供应商创建一个 AWS Transfer Family 端点。",
      "C": "配置一个 Amazon EC2 实例来运行 SFTP 服务器。指示使用旧版应用程序的供应商使用 SFTP 服务器上传数据。",
      "D": "为使用旧版应用程序的供应商配置一个 Amazon S3 File Gateway，以便将文件上传到 SMB 文件共享。"
    }
  },
  {
    "id": 817,
    "topic": "1",
    "question_en": "A marketing team wants to build a campaign for an upcoming multi-sport event. The team has news reports from the past five years in PDF format. The team needs a solution to extract insights about the content and the sentiment of the news reports. The solution must use Amazon Textract to process the news reports. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Provide the extracted insights to Amazon Athena for analysis. Store the extracted insights and analysis in an Amazon S3 bucket.",
      "B": "Store the extracted insights in an Amazon DynamoDB table. Use Amazon SageMaker to build a sentiment model.",
      "C": "Provide the extracted insights to Amazon Comprehend for analysis. Save the analysis to an Amazon S3 bucket.",
      "D": "Store the extracted insights in an Amazon S3 bucket. Use Amazon QuickSight to visualize and analyze the data."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一个市场营销团队想要为即将到来的多项体育赛事建立一个宣传活动。该团队有过去五年的新闻报道，格式为 PDF。该团队需要一个解决方案来提取关于新闻报道内容和情感的见解。该解决方案必须使用 Amazon Textract 来处理新闻报道。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将提取的见解提供给 Amazon Athena 进行分析。将提取的见解和分析存储在 Amazon S3 存储桶中。",
      "B": "将提取的见解存储在 Amazon DynamoDB 表中。使用 Amazon SageMaker 构建情感模型。",
      "C": "将提取的见解提供给 Amazon Comprehend 进行分析。将分析结果保存到 Amazon S3 存储桶。",
      "D": "将提取的见解存储在 Amazon S3 存储桶中。使用 Amazon QuickSight 可视化和分析数据。"
    }
  },
  {
    "id": 818,
    "topic": "1",
    "question_en": "A company's application runs on Amazon EC2 instances that are in multiple Availability Zones. The application needs to ingest real-time data from third-party applications. The company needs a data ingestion solution that places the ingested raw data in an Amazon S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create Amazon Kinesis data streams for data ingestion. Create Amazon Kinesis Data Firehose delivery streams to consume the Kinesis data streams. Specify the S3 bucket as the destination of the delivery streams.",
      "B": "Create database migration tasks in AWS Database Migration Service (AWS DMS). Specify replication instances of the EC2 instances as the source endpoints. Specify the S3 bucket as the target endpoint. Set the migration type to migrate existing data and replicate ongoing changes.",
      "C": "Create and configure AWS DataSync agents on the EC2 instances. Configure DataSync tasks to transfer data from the EC2 instances to the S3 bucket.",
      "D": "Create an AWS Direct Connect connection to the application for data ingestion. Create Amazon Kinesis Data Firehose delivery streams to consume direct PUT operations from the application. Specify the S3 bucket as the destination of the delivery streams."
    },
    "correct_answer": "A",
    "vote_percentage": "60%",
    "question_cn": "一家公司的应用程序运行在多个可用区中的 Amazon EC2 实例上。该应用程序需要从第三方应用程序提取实时数据。该公司需要一个数据提取解决方案，该解决方案将提取的原始数据放置在 Amazon S3 存储桶中。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为数据提取创建 Amazon Kinesis 数据流。创建 Amazon Kinesis Data Firehose 交付流以使用 Kinesis 数据流。将 S3 存储桶指定为交付流的目标。",
      "B": "在 AWS Database Migration Service (AWS DMS) 中创建数据库迁移任务。将 EC2 实例的复制实例指定为源终端节点。将 S3 存储桶指定为目标终端节点。将迁移类型设置为迁移现有数据并复制正在进行的更改。",
      "C": "在 EC2 实例上创建并配置 AWS DataSync 代理。配置 DataSync 任务，以将数据从 EC2 实例传输到 S3 存储桶。",
      "D": "创建与应用程序的 AWS Direct Connect 连接以进行数据提取。创建 Amazon Kinesis Data Firehose 交付流以使用来自应用程序的直接 PUT 操作。将 S3 存储桶指定为交付流的目标。"
    }
  },
  {
    "id": 819,
    "topic": "1",
    "question_en": "A company’s application is receiving data from multiple data sources. The size of the data varies and is expected to increase over time. The current maximum size is 700 KB. The data volume and data size continue to grow as more data sources are added. The company decides to use Amazon DynamoDB as the primary database for the application. A solutions architect needs to identify a solution that handles the large data sizes. Which solution will meet these requirements in the MOST operationally eficient way?",
    "options_en": {
      "A": "Create an AWS Lambda function to filter the data that exceeds DynamoDB item size limits. Store the larger data in an Amazon DocumentDB (with MongoDB compatibility) database.",
      "B": "Store the large data as objects in an Amazon S3 bucket. In a DynamoDB table, create an item that has an attribute that points to the S3 URL of the data.",
      "C": "Split all incoming large data into a collection of items that have the same partition key. Write the data to a DynamoDB table in a single operation by using the BatchWriteItem API operation.",
      "D": "Create an AWS Lambda function that uses gzip compression to compress the large objects as they are written to a DynamoDB table."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司的应用程序正在接收来自多个数据源的数据。数据大小各不相同，预计会随着时间的推移而增加。当前最大大小为 700 KB。随着添加更多数据源，数据量和数据大小会持续增长。该公司决定使用 Amazon DynamoDB 作为应用程序的主要数据库。解决方案架构师需要确定一个可以处理大型数据大小的解决方案。哪个解决方案能以最具运营效率的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数来筛选超出 DynamoDB 项目大小限制的数据。将较大的数据存储在 Amazon DocumentDB（与 MongoDB 兼容）数据库中。",
      "B": "将大型数据作为对象存储在 Amazon S3 存储桶中。在 DynamoDB 表中，创建一个具有指向数据 S3 URL 的属性的项目。",
      "C": "将所有传入的大型数据拆分为具有相同分区键的项目集合。使用 BatchWriteItem API 操作将数据写入 DynamoDB 表中的单个操作。",
      "D": "创建一个 AWS Lambda 函数，该函数使用 gzip 压缩来压缩写入 DynamoDB 表时的大型对象。"
    }
  },
  {
    "id": 820,
    "topic": "1",
    "question_en": "A company is migrating a legacy application from an on-premises data center to AWS. The application relies on hundreds of cron jobs that run between 1 and 20 minutes on different recurring schedules throughout the day. The company wants a solution to schedule and run the cron jobs on AWS with minimal refactoring. The solution must support running the cron jobs in response to an event in the future. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a container image for the cron jobs. Use Amazon EventBridge Scheduler to create a recurring schedule. Run the cron job tasks as AWS Lambda functions.",
      "B": "Create a container image for the cron jobs. Use AWS Batch on Amazon Elastic Container Service (Amazon ECS) with a scheduling policy to run the cron jobs.",
      "C": "Create a container image for the cron jobs. Use Amazon EventBridge Scheduler to create a recurring schedule. Run the cron job tasks on AWS Fargate.",
      "D": "Create a container image for the cron jobs. Create a workfiow in AWS Step Functions that uses a Wait state to run the cron jobs at a specified time. Use the RunTask action to run the cron job tasks on AWS Fargate."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其遗留应用程序从本地数据中心迁移到 AWS。该应用程序依赖于数百个 cron 作业，这些作业每天在不同的重复时间表上运行 1 到 20 分钟。该公司希望在 AWS 上安排和运行 cron 作业的解决方案，并尽量减少重构。该解决方案必须支持响应未来发生的事件来运行 cron 作业。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 cron 作业创建容器镜像。使用 Amazon EventBridge Scheduler 创建重复计划。将 cron 作业任务作为 AWS Lambda 函数运行。",
      "B": "为 cron 作业创建容器镜像。在 Amazon Elastic Container Service (Amazon ECS) 上使用 AWS Batch 和调度策略来运行 cron 作业。",
      "C": "为 cron 作业创建容器镜像。使用 Amazon EventBridge Scheduler 创建重复计划。在 AWS Fargate 上运行 cron 作业任务。",
      "D": "为 cron 作业创建容器镜像。在 AWS Step Functions 中创建一个工作流，该工作流使用 Wait 状态在指定时间运行 cron 作业。使用 RunTask 操作在 AWS Fargate 上运行 cron 作业任务。"
    }
  },
  {
    "id": 821,
    "topic": "1",
    "question_en": "A company uses Salesforce. The company needs to load existing data and ongoing data changes from Salesforce to Amazon Redshift for analysis. The company does not want the data to travel over the public internet. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Establish a VPN connection from the VPC to Salesforce. Use AWS Glue DataBrew to transfer data.",
      "B": "Establish an AWS Direct Connect connection from the VPC to Salesforce. Use AWS Glue DataBrew to transfer data.",
      "C": "Create an AWS PrivateLink connection in the VPC to Salesforce. Use Amazon AppFlow to transfer data.",
      "D": "Create a VPC peering connection to Salesforce. Use Amazon AppFlow to transfer data."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Salesforce。该公司需要将现有数据和持续的数据更改从 Salesforce 加载到 Amazon Redshift 中进行分析。该公司不希望数据通过公共互联网传输。哪个解决方案将以最少的开发工作量满足这些要求？",
    "options_cn": {
      "A": "建立从 VPC 到 Salesforce 的 VPN 连接。使用 AWS Glue DataBrew 传输数据。",
      "B": "建立从 VPC 到 Salesforce 的 AWS Direct Connect 连接。使用 AWS Glue DataBrew 传输数据。",
      "C": "在 VPC 中创建到 Salesforce 的 AWS PrivateLink 连接。使用 Amazon AppFlow 传输数据。",
      "D": "创建到 Salesforce 的 VPC 对等连接。使用 Amazon AppFlow 传输数据。"
    }
  },
  {
    "id": 822,
    "topic": "1",
    "question_en": "A company recently migrated its application to AWS. The application runs on Amazon EC2 Linux instances in an Auto Scaling group across multiple Availability Zones. The application stores data in an Amazon Elastic File System (Amazon EFS) file system that uses EFS Standard- Infrequent Access storage. The application indexes the company's files. The index is stored in an Amazon RDS database. The company needs to optimize storage costs with some application and services changes. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an Amazon S3 bucket that uses an Intelligent-Tiering lifecycle policy. Copy all files to the S3 bucket. Update the application to use Amazon S3 API to store and retrieve files.",
      "B": "Deploy Amazon FSx for Windows File Server file shares. Update the application to use CIFS protocol to store and retrieve files.",
      "C": "Deploy Amazon FSx for OpenZFS file system shares. Update the application to use the new mount point to store and retrieve files.",
      "D": "Create an Amazon S3 bucket that uses S3 Glacier Flexible Retrieval. Copy all files to the S3 bucket. Update the application to use Amazon S3 API to store and retrieve files as standard retrievals."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司最近将其应用程序迁移到了 AWS。该应用程序在跨多个可用区的 Auto Scaling 组中的 Amazon EC2 Linux 实例上运行。该应用程序将数据存储在 Amazon Elastic File System (Amazon EFS) 文件系统中，该文件系统使用 EFS 标准-不频繁访问存储。该应用程序为公司的文件建立索引。索引存储在 Amazon RDS 数据库中。公司需要通过一些应用程序和服务更改来优化存储成本。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个使用智能分层生命周期策略的 Amazon S3 存储桶。将所有文件复制到 S3 存储桶。更新应用程序以使用 Amazon S3 API 存储和检索文件。",
      "B": "部署 Amazon FSx for Windows 文件服务器文件共享。更新应用程序以使用 CIFS 协议存储和检索文件。",
      "C": "部署 Amazon FSx for OpenZFS 文件系统共享。更新应用程序以使用新的挂载点来存储和检索文件。",
      "D": "创建一个使用 S3 Glacier Flexible Retrieval 的 Amazon S3 存储桶。将所有文件复制到 S3 存储桶。更新应用程序以使用 Amazon S3 API 将文件作为标准检索方式检索。"
    }
  },
  {
    "id": 823,
    "topic": "1",
    "question_en": "A robotics company is designing a solution for medical surgery. The robots will use advanced sensors, cameras, and AI algorithms to perceive their environment and to complete surgeries. The company needs a public load balancer in the AWS Cloud that will ensure seamless communication with backend services. The load balancer must be capable of routing trafic based on the query strings to different target groups. The trafic must also be encrypted. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use a Network Load Balancer with a certificate attached from AWS Certificate Manager (ACM). Use query parameter-based routing.",
      "B": "Use a Gateway Load Balancer. Import a generated certificate in AWS Identity and Access Management (IAM). Attach the certificate to the load balancer. Use HTTP path-based routing.",
      "C": "Use an Application Load Balancer with a certificate attached from AWS Certificate Manager (ACM). Use query parameter-based routing.",
      "D": "Use a Network Load Balancer. Import a generated certificate in AWS Identity and Access Management (IAM). Attach the certificate to the load balancer. Use query parameter-based routing."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家机器人公司正在为医疗手术设计一个解决方案。机器人将使用先进的传感器、摄像头和 AI 算法来感知其环境并完成手术。该公司需要在 AWS Cloud 中使用一个公共负载均衡器，以确保与后端服务的无缝通信。该负载均衡器必须能够根据查询字符串将流量路由到不同的目标组。流量也必须被加密。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Network Load Balancer，并附带来自 AWS Certificate Manager (ACM) 的证书。使用基于查询参数的路由。",
      "B": "使用 Gateway Load Balancer。在 AWS Identity and Access Management (IAM) 中导入一个生成的证书。将该证书附加到负载均衡器。使用基于 HTTP 路径的路由。",
      "C": "使用 Application Load Balancer，并附带来自 AWS Certificate Manager (ACM) 的证书。使用基于查询参数的路由。",
      "D": "使用 Network Load Balancer。在 AWS Identity and Access Management (IAM) 中导入一个生成的证书。将该证书附加到负载均衡器。使用基于查询参数的路由。"
    }
  },
  {
    "id": 824,
    "topic": "1",
    "question_en": "A company has an application that runs on a single Amazon EC2 instance. The application uses a MySQL database that runs on the same EC2 instance. The company needs a highly available and automatically scalable solution to handle increased trafic. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy the application to EC2 instances that run in an Auto Scaling group behind an Application Load Balancer. Create an Amazon Redshift cluster that has multiple MySQL-compatible nodes.",
      "B": "Deploy the application to EC2 instances that are configured as a target group behind an Application Load Balancer. Create an Amazon RDS for MySQL cluster that has multiple instances.",
      "C": "Deploy the application to EC2 instances that run in an Auto Scaling group behind an Application Load Balancer. Create an Amazon Aurora Serverless MySQL cluster for the database layer.",
      "D": "Deploy the application to EC2 instances that are configured as a target group behind an Application Load Balancer. Create an Amazon ElastiCache for Redis cluster that uses the MySQL connector."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个在单个 Amazon EC2 实例上运行的应用程序。该应用程序使用一个在同一 EC2 实例上运行的 MySQL 数据库。该公司需要一个高可用性且自动可扩展的解决方案来处理增加的流量。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将应用程序部署到在 Application Load Balancer 后运行在 Auto Scaling 组中的 EC2 实例。创建一个具有多个 MySQL 兼容节点的 Amazon Redshift 集群。",
      "B": "将应用程序部署到配置为 Application Load Balancer 后面的目标组的 EC2 实例。创建一个具有多个实例的 Amazon RDS for MySQL 集群。",
      "C": "将应用程序部署到在 Application Load Balancer 后运行在 Auto Scaling 组中的 EC2 实例。为数据库层创建一个 Amazon Aurora Serverless MySQL 集群。",
      "D": "将应用程序部署到配置为 Application Load Balancer 后面的目标组的 EC2 实例。创建一个使用 MySQL 连接器的 Amazon ElastiCache for Redis 集群。"
    }
  },
  {
    "id": 825,
    "topic": "1",
    "question_en": "A company is planning to migrate data to an Amazon S3 bucket. The data must be encrypted at rest within the S3 bucket. The encryption key must be rotated automatically every year. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Migrate the data to the S3 bucket. Use server-side encryption with Amazon S3 managed keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys.",
      "B": "Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket's default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket.",
      "C": "Create an AWS Key Management Service (AWS KMS) customer managed key. Set the S3 bucket's default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket. Manually rotate the KMS key every year.",
      "D": "Use customer key material to encrypt the data. Migrate the data to the S3 bucket. Create an AWS Key Management Service (AWS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation."
    },
    "correct_answer": "A",
    "vote_percentage": "60%",
    "question_cn": "一家公司计划将数据迁移到 Amazon S3 存储桶。 数据必须在 S3 存储桶内静态加密。 加密密钥必须每年自动轮换。 哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将数据迁移到 S3 存储桶。 使用具有 Amazon S3 托管密钥 (SSE-S3) 的服务器端加密。 使用 SSE-S3 加密密钥的内置密钥轮换行为。",
      "B": "创建一个 AWS Key Management Service (AWS KMS) 客户托管密钥。 启用自动密钥轮换。 将 S3 存储桶的默认加密行为设置为使用客户托管 KMS 密钥。 将数据迁移到 S3 存储桶。",
      "C": "创建一个 AWS Key Management Service (AWS KMS) 客户托管密钥。 将 S3 存储桶的默认加密行为设置为使用客户托管 KMS 密钥。 将数据迁移到 S3 存储桶。 每年手动轮换 KMS 密钥。",
      "D": "使用客户密钥材料对数据进行加密。 将数据迁移到 S3 存储桶。 创建一个 AWS Key Management Service (AWS KMS) 密钥，不带密钥材料。 将客户密钥材料导入 KMS 密钥。 启用自动密钥轮换。"
    }
  },
  {
    "id": 826,
    "topic": "1",
    "question_en": "A company is migrating applications from an on-premises Microsoft Active Directory that the company manages to AWS. The company deploys the applications in multiple AWS accounts. The company uses AWS Organizations to manage the accounts centrally. The company's security team needs a single sign-on solution across all the company's AWS accounts. The company must continue to manage users and groups that are in the on-premises Active Directory. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Enterprise Edition Active Directory in AWS Directory Service for Microsoft Active Directory. Configure the Active Directory to be the identity source for AWS IAM Identity Center.",
      "B": "Enable AWS IAM Identity Center. Configure a two-way forest trust relationship to connect the company's self-managed Active Directory with IAM Identity Center by using AWS Directory Service for Microsoft Active Directory.",
      "C": "Use AWS Directory Service and create a two-way trust relationship with the company's self-managed Active Directory.",
      "D": "Deploy an identity provider (IdP) on Amazon EC2. Link the IdP as an identity source within AWS IAM Identity Center."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其应用程序从公司管理的本地 Microsoft Active Directory 迁移到 AWS。该公司在多个 AWS 账户中部署了这些应用程序。该公司使用 AWS Organizations 集中管理这些账户。该公司的安全团队需要一个跨所有公司 AWS 账户的单点登录解决方案。该公司必须继续管理位于本地 Active Directory 中的用户和组。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 AWS Directory Service for Microsoft Active Directory 中创建一个 Enterprise Edition Active Directory。将 Active Directory 配置为 AWS IAM Identity Center 的身份源。",
      "B": "打开 AWS IAM Identity Center。使用 AWS Directory Service for Microsoft Active Directory 配置双向林信任关系，以将公司的自管理 Active Directory 与 IAM Identity Center 连接起来。",
      "C": "使用 AWS Directory Service，并与公司的自管理 Active Directory 创建双向信任关系。",
      "D": "在 Amazon EC2 上部署一个身份提供商 (IdP)。将 IdP 链接为 AWS IAM Identity Center 中的身份源。"
    }
  },
  {
    "id": 827,
    "topic": "1",
    "question_en": "A company is planning to deploy its application on an Amazon Aurora PostgreSQL Serverless v2 cluster. The application will receive large amounts of trafic. The company wants to optimize the storage performance of the cluster as the load on the application increases. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure the cluster to use the Aurora Standard storage configuration.",
      "B": "Configure the cluster storage type as Provisioned IOPS.",
      "C": "Configure the cluster storage type as General Purpose.",
      "D": "Configure the cluster to use the Aurora I/O-Optimized storage configuration."
    },
    "correct_answer": "C",
    "vote_percentage": "85%",
    "question_cn": "一家公司计划在其 Amazon Aurora PostgreSQL Serverless v2 集群上部署其应用程序。该应用程序将收到大量流量。该公司希望在应用程序的负载增加时优化集群的存储性能。哪个解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "将集群配置为使用 Aurora Standard 存储配置。",
      "B": "将集群存储类型配置为 Provisioned IOPS。",
      "C": "将集群存储类型配置为 General Purpose。",
      "D": "将集群配置为使用 Aurora I/O-Optimized 存储配置。"
    }
  },
  {
    "id": 828,
    "topic": "1",
    "question_en": "A financial services company that runs on AWS has designed its security controls to meet industry standards. The industry standards include the National Institute of Standards and Technology (NIST) and the Payment Card Industry Data Security Standard (PCI DSS). The company's third-party auditors need proof that the designed controls have been implemented and are functioning correctly. The company has hundreds of AWS accounts in a single organization in AWS Organizations. The company needs to monitor the current state of the controls across accounts. Which solution will meet these requirements?",
    "options_en": {
      "A": "Designate one account as the Amazon Inspector delegated administrator account from the Organizations management account. Integrate Inspector with Organizations to discover and scan resources across all AWS accounts. Enable Inspector industry standards for NIST and PCI DSS.",
      "B": "Designate one account as the Amazon GuardDuty delegated administrator account from the Organizations management account. In the designated GuardDuty administrator account, enable GuardDuty to protect all member accounts. Enable GuardDuty industry standards for NIST and PCI DSS.",
      "C": "Configure an AWS CloudTrail organization trail in the Organizations management account. Designate one account as the compliance account. Enable CloudTrail security standards for NIST and PCI DSS in the compliance account.",
      "D": "Designate one account as the AWS Security Hub delegated administrator account from the Organizations management account. In the designated Security Hub administrator account, enable Security Hub for all member accounts. Enable Security Hub standards for NIST and PCI DSS."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家在 AWS 上运营的金融服务公司已设计其安全控制措施以满足行业标准。行业标准包括国家标准与技术研究院 (NIST) 和支付卡行业数据安全标准 (PCI DSS)。该公司的第三方审计员需要证明已实施所设计的控制措施并正常运行。该公司在 AWS Organizations 的单个组织中拥有数百个 AWS 账户。该公司需要监控所有账户的当前控制状态。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "从 Organizations 管理账户中指定一个账户作为 Amazon Inspector 委托管理员账户。将 Inspector 与 Organizations 集成，以发现和扫描所有 AWS 账户中的资源。为 NIST 和 PCI DSS 启用 Inspector 行业标准。",
      "B": "从 Organizations 管理账户中指定一个账户作为 Amazon GuardDuty 委托管理员账户。在指定的 GuardDuty 管理员账户中，启用 GuardDuty 以保护所有成员账户。为 NIST 和 PCI DSS 启用 GuardDuty 行业标准。",
      "C": "在 Organizations 管理账户中配置一个 AWS CloudTrail 组织追踪。将一个账户指定为合规账户。在合规账户中为 NIST 和 PCI DSS 启用 CloudTrail 安全标准。",
      "D": "从 Organizations 管理账户中指定一个账户作为 AWS Security Hub 委托管理员账户。在指定的 Security Hub 管理员账户中，为所有成员账户启用 Security Hub。为 NIST 和 PCI DSS 启用 Security Hub 标准。"
    }
  },
  {
    "id": 829,
    "topic": "1",
    "question_en": "A company uses an Amazon S3 bucket as its data lake storage platform. The S3 bucket contains a massive amount of data that is accessed randomly by multiple teams and hundreds of applications. The company wants to reduce the S3 storage costs and provide immediate availability for frequently accessed objects. What is the MOST operationally eficient solution that meets these requirements?",
    "options_en": {
      "A": "Create an S3 Lifecycle rule to transition objects to the S3 Intelligent-Tiering storage class.",
      "B": "Store objects in Amazon S3 Glacier. Use S3 Select to provide applications with access to the data.",
      "C": "Use data from S3 storage class analysis to create S3 Lifecycle rules to automatically transition objects to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class.",
      "D": "Transition objects to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an AWS Lambda function to transition objects to the S3 Standard storage class when they are accessed by an application."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon S3 存储桶作为其数据湖存储平台。 S3 存储桶包含大量数据，这些数据由多个团队和数百个应用程序随机访问。该公司希望降低 S3 存储成本，并为经常访问的对象提供即时可用性。哪种解决方案在运营上最有效，可以满足这些要求？",
    "options_cn": {
      "A": "创建 S3 生命周期规则，将对象转换为 S3 Intelligent-Tiering 存储类。",
      "B": "将对象存储在 Amazon S3 Glacier 中。使用 S3 Select 为应用程序提供对数据的访问。",
      "C": "使用来自 S3 存储类分析的数据，创建 S3 生命周期规则，以自动将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA) 存储类。",
      "D": "将对象转换为 S3 Standard-Infrequent Access (S3 Standard-IA) 存储类。创建一个 AWS Lambda 函数，以便在应用程序访问对象时将对象转换为 S3 Standard 存储类。"
    }
  },
  {
    "id": 830,
    "topic": "1",
    "question_en": "A company has 5 TB of datasets. The datasets consist of 1 million user profiles and 10 million connections. The user profiles have connections as many-to-many relationships. The company needs a performance eficient way to find mutual connections up to five levels. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an Amazon S3 bucket to store the datasets. Use Amazon Athena to perform SQL JOIN queries to find connections.",
      "B": "Use Amazon Neptune to store the datasets with edges and vertices. Query the data to find connections.",
      "C": "Use an Amazon S3 bucket to store the datasets. Use Amazon QuickSight to visualize connections.",
      "D": "Use Amazon RDS to store the datasets with multiple tables. Perform SQL JOIN queries to find connections."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司有 5 TB 的数据集。数据集由 100 万个用户配置文件和 1000 万个连接组成。用户配置文件具有多对多的连接关系。该公司需要一种高性能的方式来查找多达五个级别的共同连接。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 存储桶存储数据集。使用 Amazon Athena 执行 SQL JOIN 查询来查找连接。",
      "B": "使用 Amazon Neptune 存储带有边和顶点的的数据集。查询数据以查找连接。",
      "C": "使用 Amazon S3 存储桶存储数据集。使用 Amazon QuickSight 可视化连接。",
      "D": "使用 Amazon RDS 存储带有多个表的数据集。执行 SQL JOIN 查询来查找连接。"
    }
  },
  {
    "id": 831,
    "topic": "1",
    "question_en": "A company needs a secure connection between its on-premises environment and AWS. This connection does not need high bandwidth and will handle a small amount of trafic. The connection should be set up quickly. What is the MOST cost-effective method to establish this type of connection?",
    "options_en": {
      "A": "Implement a client VPN.",
      "B": "Implement AWS Direct Connect.",
      "C": "Implement a bastion host on Amazon EC2.",
      "D": "Implement an AWS Site-to-Site VPN connection."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司需要在其本地环境和 AWS 之间建立安全连接。此连接不需要高带宽，并且将处理少量流量。该连接应快速建立。建立此类连接的最具成本效益的方法是什么？",
    "options_cn": {
      "A": "实施客户端 VPN。",
      "B": "实施 AWS Direct Connect。",
      "C": "在 Amazon EC2 上实施堡垒主机。",
      "D": "实施 AWS 站点到站点 VPN 连接。"
    }
  },
  {
    "id": 832,
    "topic": "1",
    "question_en": "A company has an on-premises SFTP file transfer solution. The company is migrating to the AWS Cloud to scale the file transfer solution and to optimize costs by using Amazon S3. The company's employees will use their credentials for the on-premises Microsoft Active Directory (AD) to access the new solution. The company wants to keep the current authentication and file access mechanisms. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure an S3 File Gateway. Create SMB file shares on the file gateway that use the existing Active Directory to authenticate.",
      "B": "Configure an Auto Scaling group with Amazon EC2 instances to run an SFTP solution. Configure the group to scale up at 60% CPU utilization.",
      "C": "Create an AWS Transfer Family server with SFTP endpoints. Choose the AWS Directory Service option as the identity provider. Use AD Connector to connect the on-premises Active Directory.",
      "D": "Create an AWS Transfer Family SFTP endpoint. Configure the endpoint to use the AWS Directory Service option as the identity provider to connect to the existing Active Directory."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个本地 SFTP 文件传输解决方案。该公司正在迁移到 AWS 云，以扩展文件传输解决方案，并通过使用 Amazon S3 来优化成本。该公司的员工将使用其本地 Microsoft Active Directory (AD) 的凭证来访问新解决方案。该公司希望保留当前的身份验证和文件访问机制。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "配置 S3 File Gateway。在 File Gateway 上创建 SMB 文件共享，使用现有的 Active Directory 进行身份验证。",
      "B": "配置一个包含 Amazon EC2 实例的 Auto Scaling 组以运行 SFTP 解决方案。将该组配置为在 60% CPU 利用率时进行扩展。",
      "C": "使用 SFTP 端点创建一个 AWS Transfer Family 服务器。选择 AWS Directory Service 选项作为身份提供商。使用 AD Connector 连接本地 Active Directory。",
      "D": "创建一个 AWS Transfer Family SFTP 端点。将端点配置为使用 AWS Directory Service 选项作为身份提供商以连接到现有的 Active Directory。"
    }
  },
  {
    "id": 833,
    "topic": "1",
    "question_en": "A company is designing an event-driven order processing system. Each order requires multiple validation steps after the order is created. An idempotent AWS Lambda function performs each validation step. Each validation step is independent from the other validation steps. Individual validation steps need only a subset of the order event information. The company wants to ensure that each validation step Lambda function has access to only the information from the order event that the function requires. The components of the order processing system should be loosely coupled to accommodate future business changes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue for each validation step. Create a new Lambda function to transform the order data to the format that each validation step requires and to publish the messages to the appropriate SQS queues. Subscribe each validation step Lambda function to its corresponding SQS queue.",
      "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the validation step Lambda functions to the SNS topic. Use message body filtering to send only the required data to each subscribed Lambda function.",
      "C": "Create an Amazon EventBridge event bus. Create an event rule for each validation step. Configure the input transformer to send only the required data to each target validation step Lambda function.",
      "D": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Create a new Lambda function to subscribe to the SQS queue and to transform the order data to the format that each validation step requires. Use the new Lambda function to perform synchronous invocations of the validation step Lambda functions in parallel on separate threads."
    },
    "correct_answer": "C",
    "vote_percentage": "89%",
    "question_cn": "一家公司正在设计一个事件驱动的订单处理系统。每个订单在创建后都需要多个验证步骤。一个幂等 AWS Lambda 函数执行每个验证步骤。每个验证步骤与其他验证步骤无关。各个验证步骤只需要订单事件信息的一个子集。该公司希望确保每个验证步骤 Lambda 函数只能访问该函数所需的订单事件中的信息。订单处理系统的组件应松散耦合，以适应未来的业务变更。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为每个验证步骤创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。创建一个新的 Lambda 函数来转换订单数据以满足每个验证步骤的要求，并将消息发布到相应的 SQS 队列。将每个验证步骤 Lambda 函数订阅到其相应的 SQS 队列。",
      "B": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题。将验证步骤 Lambda 函数订阅到 SNS 主题。使用消息正文过滤仅将所需数据发送到每个已订阅的 Lambda 函数。",
      "C": "创建一个 Amazon EventBridge 事件总线。为每个验证步骤创建一个事件规则。配置输入转换器以仅将所需数据发送到每个目标验证步骤 Lambda 函数。",
      "D": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列。创建一个新的 Lambda 函数来订阅 SQS 队列，并将订单数据转换为每个验证步骤所需的格式。使用新的 Lambda 函数在单独的线程上并行执行验证步骤 Lambda 函数的同步调用。"
    }
  },
  {
    "id": 834,
    "topic": "1",
    "question_en": "A company is migrating a three-tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real- time reports from the application during working hours. Which solution will improve the performance of the application when it is moved to AWS?",
    "options_en": {
      "A": "Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports.",
      "B": "Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database.",
      "C": "Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint for reports.",
      "D": "Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将三层应用程序迁移到 AWS。该应用程序需要一个 MySQL 数据库。过去，当创建新条目时，应用程序用户报告了较差的应用程序性能。这些性能问题是由用户在工作时间从应用程序生成不同的实时报告引起的。将应用程序移动到 AWS 时，哪种解决方案将提高应用程序的性能？",
    "options_cn": {
      "A": "将数据导入具有预置容量的 Amazon DynamoDB 表。重构应用程序以使用 DynamoDB 进行报告。",
      "B": "在计算优化的 Amazon EC2 实例上创建数据库。确保计算资源超过本地数据库。",
      "C": "使用多个只读副本创建 Amazon Aurora MySQL 多可用区数据库集群。配置应用程序以将读取器端点用于报告。",
      "D": "创建 Amazon Aurora MySQL 多可用区数据库集群。配置应用程序以使用集群的备份实例作为报告的端点。"
    }
  },
  {
    "id": 835,
    "topic": "1",
    "question_en": "A company is expanding a secure on-premises network to the AWS Cloud by using an AWS Direct Connect connection. The on-premises network has no direct internet access. An application that runs on the on-premises network needs to use an Amazon S3 bucket. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a public virtual interface (VIF). Route the AWS trafic over the public VIF.",
      "B": "Create a VPC and a NAT gateway. Route the AWS trafic from the on-premises network to the NAT gateway.",
      "C": "Create a VPC and an Amazon S3 interface endpoint. Route the AWS trafic from the on-premises network to the S3 interface endpoint.",
      "D": "Create a VPC peering connection between the on-premises network and Direct Connect. Route the AWS trafic over the peering connection."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在使用 AWS Direct Connect 连接将其安全的本地网络扩展到 AWS Cloud。本地网络没有直接的互联网访问。一个在本地网络上运行的应用程序需要使用 Amazon S3 存储桶。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个公共虚拟接口（VIF）。通过公共 VIF 路由 AWS 流量。",
      "B": "创建一个 VPC 和一个 NAT 网关。将来自本地网络的 AWS 流量路由到 NAT 网关。",
      "C": "创建一个 VPC 和一个 Amazon S3 接口终端节点。将来自本地网络的 AWS 流量路由到 S3 接口终端节点。",
      "D": "在本地网络和 Direct Connect 之间创建一个 VPC 对等连接。通过对等连接路由 AWS 流量。"
    }
  },
  {
    "id": 836,
    "topic": "1",
    "question_en": "A company serves its website by using an Auto Scaling group of Amazon EC2 instances in a single AWS Region. The website does not require a database. The company is expanding, and the company's engineering team deploys the website to a second Region. The company wants to distribute trafic across both Regions to accommodate growth and for disaster recovery purposes. The solution should not serve trafic from a Region in which the website is unhealthy. Which policy or resource should the company use to meet these requirements?",
    "options_en": {
      "A": "An Amazon Route 53 simple routing policy",
      "B": "An Amazon Route 53 multivalue answer routing policy",
      "C": "An Application Load Balancer in one Region with a target group that specifies the EC2 instance IDs from both Regions",
      "D": "An Application Load Balancer in one Region with a target group that specifies the IP addresses of the EC2 instances from both Regions"
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用单个 AWS 区域中的 Amazon EC2 实例的 Auto Scaling 组来提供其网站服务。该网站不需要数据库。该公司正在扩展，并且该公司的工程团队将该网站部署到第二个区域。该公司希望跨两个区域分配流量以适应增长和灾难恢复。该解决方案不应从网站运行状况不佳的区域提供流量。该公司应使用哪种策略或资源来满足这些要求？",
    "options_cn": {
      "A": "Amazon Route 53 简单路由策略",
      "B": "Amazon Route 53 多值应答路由策略",
      "C": "一个区域中的 Application Load Balancer，其目标组指定来自两个区域的 EC2 实例 ID",
      "D": "一个区域中的 Application Load Balancer，其目标组指定来自两个区域的 EC2 实例的 IP 地址"
    }
  },
  {
    "id": 837,
    "topic": "1",
    "question_en": "A company runs its applications on Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS). The EC2 instances run the most recent Amazon Linux release. The applications are experiencing availability issues when the company's employees store and retrieve files that are 25 GB or larger. The company needs a solution that does not require the company to transfer files between EC2 instances. The files must be available across many EC2 instances and across multiple Availability Zones. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate all the files to an Amazon S3 bucket. Instruct the employees to access the files from the S3 bucket.",
      "B": "Take a snapshot of the existing EBS volume. Mount the snapshot as an EBS volume across the EC2 instances. Instruct the employees to access the files from the EC2 instances.",
      "C": "Mount an Amazon Elastic File System (Amazon EFS) file system across all the EC2 instances. Instruct the employees to access the files from the EC2 instances.",
      "D": "Create an Amazon Machine Image (AMI) from the EC2 instances. Configure new EC2 instances from the AMI that use an instance store volume. Instruct the employees to access the files from the EC2 instances."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其由 Amazon Elastic Block Store (Amazon EBS) 支持的 Amazon EC2 实例上运行其应用程序。 EC2 实例运行最新的 Amazon Linux 版本。 当公司的员工存储和检索 25 GB 或更大的文件时，应用程序遇到了可用性问题。 公司需要一个不需要公司在 EC2 实例之间传输文件的解决方案。 文件必须在多个 EC2 实例和多个可用区中可用。 哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将所有文件迁移到 Amazon S3 存储桶。 指示员工从 S3 存储桶访问文件。",
      "B": "拍摄现有 EBS 卷的快照。 将快照作为 EBS 卷挂载在 EC2 实例中。 指示员工从 EC2 实例访问文件。",
      "C": "在所有 EC2 实例中挂载一个 Amazon Elastic File System (Amazon EFS) 文件系统。 指示员工从 EC2 实例访问文件。",
      "D": "从 EC2 实例创建 Amazon Machine Image (AMI)。 从使用实例存储卷的 AMI 配置新的 EC2 实例。 指示员工从 EC2 实例访问文件。"
    }
  },
  {
    "id": 838,
    "topic": "1",
    "question_en": "A company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database. Compliance regulations mandate that all personally identifiable information (PII) be encrypted at rest. Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure?",
    "options_en": {
      "A": "Deploy AWS Certificate Manager to generate certificates. Use the certificates to encrypt the database volume.",
      "B": "Deploy AWS CloudHSM, generate encryption keys, and use the keys to encrypt database volumes.",
      "C": "Configure SSL encryption using AWS Key Management Service (AWS KMS) keys to encrypt database volumes.",
      "D": "Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在 Amazon EC2 上运行一个高度敏感的应用程序，该应用程序由 Amazon RDS 数据库支持。合规性法规要求所有个人身份信息 (PII) 都必须进行静态加密。解决方案架构师应该推荐哪个解决方案以最少的对基础设施的更改来满足此要求？",
    "options_cn": {
      "A": "部署 AWS Certificate Manager 以生成证书。使用这些证书对数据库卷进行加密。",
      "B": "部署 AWS CloudHSM，生成加密密钥，并使用这些密钥对数据库卷进行加密。",
      "C": "使用 AWS Key Management Service (AWS KMS) 密钥配置 SSL 加密以对数据库卷进行加密。",
      "D": "配置 Amazon Elastic Block Store (Amazon EBS) 加密和 Amazon RDS 加密，使用 AWS Key Management Service (AWS KMS) 密钥对实例和数据库卷进行加密。"
    }
  },
  {
    "id": 839,
    "topic": "1",
    "question_en": "A company runs an AWS Lambda function in private subnets in a VPC. The subnets have a default route to the internet through an Amazon EC2 NAT instance. The Lambda function processes input data and saves its output as an object to Amazon S3. Intermittently, the Lambda function times out while trying to upload the object because of saturated trafic on the NAT instance's network. The company wants to access Amazon S3 without traversing the internet. Which solution will meet these requirements?",
    "options_en": {
      "A": "Replace the EC2 NAT instance with an AWS managed NAT gateway.",
      "B": "Increase the size of the EC2 NAT instance in the VPC to a network optimized instance type.",
      "C": "Provision a gateway endpoint for Amazon S3 in the VPUpdate the route tables of the subnets accordingly.",
      "D": "Provision a transit gateway. Place transit gateway attachments in the private subnets where the Lambda function is running."
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家公司在 VPC 的私有子网中运行 AWS Lambda 函数。这些子网通过 Amazon EC2 NAT 实例具有通往互联网的默认路由。Lambda 函数处理输入数据，并将其输出保存为 Amazon S3 中的一个对象。间歇性地，Lambda 函数在尝试上传对象时超时，原因是 NAT 实例的网络流量饱和。该公司希望访问 Amazon S3 而无需遍历互联网。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 EC2 NAT 实例替换为 AWS 托管的 NAT 网关。",
      "B": "将 VPC 中 EC2 NAT 实例的大小增加到网络优化实例类型。",
      "C": "在 VPC 中配置 Amazon S3 的网关 VPC endpoint，并相应地更新子网的路由表。",
      "D": "配置一个 Transit Gateway。将 Transit Gateway 附件放置在 Lambda 函数运行的私有子网中。"
    }
  },
  {
    "id": 840,
    "topic": "1",
    "question_en": "A news company that has reporters all over the world is hosting its broadcast system on AWS. The reporters send live broadcasts to the broadcast system. The reporters use software on their phones to send live streams through the Real Time Messaging Protocol (RTMP). A solutions architect must design a solution that gives the reporters the ability to send the highest quality streams. The solution must provide accelerated TCP connections back to the broadcast system. What should the solutions architect use to meet these requirements?",
    "options_en": {
      "A": "Amazon CloudFront",
      "B": "AWS Global Accelerator",
      "C": "AWS Client VPN",
      "D": "Amazon EC2 instances and AWS Elastic IP addresses"
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家新闻公司在全球各地都设有记者，该公司正在 AWS 上托管其广播系统。记者将实时广播发送到广播系统。记者使用手机上的软件通过实时消息传递协议 (RTMP) 发送实时流。解决方案架构师必须设计一个解决方案，使记者能够发送最高质量的流。该解决方案必须提供加速的 TCP 连接以返回到广播系统。解决方案架构师应该使用什么来满足这些要求？",
    "options_cn": {
      "A": "Amazon CloudFront",
      "B": "AWS Global Accelerator",
      "C": "AWS Client VPN",
      "D": "Amazon EC2 实例和 AWS Elastic IP 地址"
    }
  },
  {
    "id": 841,
    "topic": "1",
    "question_en": "A company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) to run its self-managed database. The company has 350 TB of data spread across all EBS volumes. The company takes daily EBS snapshots and keeps the snapshots for 1 month. The daily change rate is 5% of the EBS volumes. Because of new regulations, the company needs to keep the monthly snapshots for 7 years. The company needs to change its backup strategy to comply with the new regulations and to ensure that data is available with minimal administrative effort. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Keep the daily snapshot in the EBS snapshot standard tier for 1 month. Copy the monthly snapshot to Amazon S3 Glacier Deep Archive with a 7-year retention period.",
      "B": "Continue with the current EBS snapshot policy. Add a new policy to move the monthly snapshot to Amazon EBS Snapshots Archive with a 7-year retention period.",
      "C": "Keep the daily snapshot in the EBS snapshot standard tier for 1 month. Keep the monthly snapshot in the standard tier for 7 years. Use incremental snapshots.",
      "D": "Keep the daily snapshot in the EBS snapshot standard tier. Use EBS direct APIs to take snapshots of all the EBS volumes every month. Store the snapshots in an Amazon S3 bucket in the Infrequent Access tier for 7 years."
    },
    "correct_answer": "A",
    "vote_percentage": "45%",
    "question_cn": "一家公司使用 Amazon EC2 实例和 Amazon Elastic Block Store (Amazon EBS) 来运行其自管理的数据库。该公司有 350 TB 的数据分布在所有 EBS 卷中。该公司每天拍摄 EBS 快照，并将快照保留 1 个月。每日变化率为 EBS 卷的 5%。由于新的法规，该公司需要将每月快照保留 7 年。该公司需要更改其备份策略以符合新法规，并确保数据可用且管理工作量最少。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "将每日快照保留在 EBS 快照标准层中 1 个月。将每月快照复制到 Amazon S3 Glacier Deep Archive，保留期为 7 年。",
      "B": "继续执行当前的 EBS 快照策略。添加一项新策略，将每月快照移动到 Amazon EBS Snapshots Archive，保留期为 7 年。",
      "C": "将每日快照保留在 EBS 快照标准层中 1 个月。将每月快照保留在标准层中 7 年。使用增量快照。",
      "D": "将每日快照保留在 EBS 快照标准层中。使用 EBS 直接 API 每月对所有 EBS 卷进行快照。将快照存储在 Amazon S3 存储桶的非频繁访问层中 7 年。"
    }
  },
  {
    "id": 842,
    "topic": "1",
    "question_en": "A company runs an application on several Amazon EC2 instances that store persistent data on an Amazon Elastic File System (Amazon EFS) file system. The company needs to replicate the data to another AWS Region by using an AWS managed service solution. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use the EFS-to-EFS backup solution to replicate the data to an EFS file system in another Region.",
      "B": "Run a nightly script to copy data from the EFS file system to an Amazon S3 bucket. Enable S3 Cross-Region Replication on the S3 bucket.",
      "C": "Create a VPC in another Region. Establish a cross-Region VPC peer. Run a nightly rsync to copy data from the original Region to the new Region.",
      "D": "Use AWS Backup to create a backup plan with a rule that takes a daily backup and replicates it to another Region. Assign the EFS file system resource to the backup plan."
    },
    "correct_answer": "D",
    "vote_percentage": "71%",
    "question_cn": "一家公司在其几个 Amazon EC2 实例上运行一个应用程序，这些实例将持久性数据存储在 Amazon Elastic File System (Amazon EFS) 文件系统中。该公司需要使用 AWS 托管服务解决方案将数据复制到另一个 AWS 区域。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 EFS 到 EFS 备份解决方案将数据复制到另一个区域中的 EFS 文件系统。",
      "B": "运行一个夜间脚本，将数据从 EFS 文件系统复制到 Amazon S3 存储桶。在 S3 存储桶上打开目标 S3 存储桶的S3 跨区域复制。",
      "C": "在另一个区域中创建一个 VPC。建立跨区域 VPC 对等。运行一个夜间 rsync 以将数据从原始区域复制到新区域。",
      "D": "使用 AWS Backup 创建一个备份计划，其中包含一个规则，该规则会进行每日备份并将其复制到另一个区域。将 EFS 文件系统资源分配给备份计划。"
    }
  },
  {
    "id": 843,
    "topic": "1",
    "question_en": "An ecommerce company is migrating its on-premises workload to the AWS Cloud. The workload currently consists of a web application and a backend Microsoft SQL database for storage. The company expects a high volume of customers during a promotional event. The new infrastructure in the AWS Cloud must be highly available and scalable. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Migrate the web application to two Amazon EC2 instances across two Availability Zones behind an Application Load Balancer. Migrate the database to Amazon RDS for Microsoft SQL Server with read replicas in both Availability Zones.",
      "B": "Migrate the web application to an Amazon EC2 instance that runs in an Auto Scaling group across two Availability Zones behind an Application Load Balancer. Migrate the database to two EC2 instances across separate AWS Regions with database replication.",
      "C": "Migrate the web application to Amazon EC2 instances that run in an Auto Scaling group across two Availability Zones behind an Application Load Balancer. Migrate the database to Amazon RDS with Multi-AZ deployment.",
      "D": "Migrate the web application to three Amazon EC2 instances across three Availability Zones behind an Application Load Balancer. Migrate the database to three EC2 instances across three Availability Zones."
    },
    "correct_answer": "C",
    "vote_percentage": "88%",
    "question_cn": "一家电子商务公司正在将其本地工作负载迁移到 AWS 云。该工作负载目前包含一个 Web 应用程序和一个用于存储的后端 Microsoft SQL 数据库。该公司预计在促销活动期间将有大量的客户。AWS 云中的新基础设施必须具有高可用性和可扩展性。哪种解决方案将以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "将 Web 应用程序迁移到两个 Amazon EC2 实例，这些实例跨越两个可用区，位于 Application Load Balancer 之后。将数据库迁移到 Amazon RDS for Microsoft SQL Server，并在两个可用区中设置读取副本。",
      "B": "将 Web 应用程序迁移到在跨越两个可用区的 Auto Scaling 组中运行的 Amazon EC2 实例，位于 Application Load Balancer 之后。将数据库迁移到跨越不同 AWS 区域的两个 EC2 实例，并进行数据库复制。",
      "C": "将 Web 应用程序迁移到在跨越两个可用区的 Auto Scaling 组中运行的 Amazon EC2 实例，位于 Application Load Balancer 之后。将数据库迁移到具有 Multi-AZ 部署的 Amazon RDS。",
      "D": "将 Web 应用程序迁移到三个 Amazon EC2 实例，这些实例跨越三个可用区，位于 Application Load Balancer 之后。将数据库迁移到跨越三个可用区的三个 EC2 实例。"
    }
  },
  {
    "id": 844,
    "topic": "1",
    "question_en": "A company has an on-premises business application that generates hundreds of files each day. These files are stored on an SMB file share and require a low-latency connection to the application servers. A new company policy states all application-generated files must be copied to AWS. There is already a VPN connection to AWS. The application development team does not have time to make the necessary code modifications to move the application to AWS. Which service should a solutions architect recommend to allow the application to copy files to AWS?",
    "options_en": {
      "A": "Amazon Elastic File System (Amazon EFS)",
      "B": "Amazon FSx for Windows File Server",
      "C": "AWS Snowball",
      "D": "AWS Storage Gateway"
    },
    "correct_answer": "D",
    "vote_percentage": "50%",
    "question_cn": "一家公司有一个本地业务应用程序，该应用程序每天生成数百个文件。这些文件存储在 SMB 文件共享上，并且需要与应用程序服务器建立低延迟连接。一项新的公司策略规定，所有应用程序生成的文件都必须复制到 AWS。已经有一个到 AWS 的 VPN 连接。应用程序开发团队没有时间对代码进行必要的修改以将应用程序移至 AWS。解决方案架构师应该推荐哪种服务来允许应用程序将文件复制到 AWS？",
    "options_cn": {
      "A": "Amazon Elastic File System (Amazon EFS)",
      "B": "Amazon FSx for Windows File Server",
      "C": "AWS Snowball",
      "D": "AWS Storage Gateway"
    }
  },
  {
    "id": 845,
    "topic": "1",
    "question_en": "A company has 15 employees. The company stores employee start dates in an Amazon DynamoDB table. The company wants to send an email message to each employee on the day of the employee's work anniversary. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create a script that scans the DynamoDB table and uses Amazon Simple Notification Service (Amazon SNS) to send email messages to employees when necessary. Use a cron job to run this script every day on an Amazon EC2 instance.",
      "B": "Create a script that scans the DynamoDB table and uses Amazon Simple Queue Service (Amazon SQS) to send email messages to employees when necessary. Use a cron job to run this script every day on an Amazon EC2 instance.",
      "C": "Create an AWS Lambda function that scans the DynamoDB table and uses Amazon Simple Notification Service (Amazon SNS) to send email messages to employees when necessary. Schedule this Lambda function to run every day.",
      "D": "Create an AWS Lambda function that scans the DynamoDB table and uses Amazon Simple Queue Service (Amazon SQS) to send email messages to employees when necessary. Schedule this Lambda function to run every day."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司有 15 名员工。该公司将员工开始日期存储在 Amazon DynamoDB 表中。该公司希望在员工的周年纪念日向每位员工发送一封电子邮件。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "创建一个脚本，扫描 DynamoDB 表，并在必要时使用 Amazon Simple Notification Service (Amazon SNS) 向员工发送电子邮件。使用 cron 作业每天在 Amazon EC2 实例上运行此脚本。",
      "B": "创建一个脚本，扫描 DynamoDB 表，并在必要时使用 Amazon Simple Queue Service (Amazon SQS) 向员工发送电子邮件。使用 cron 作业每天在 Amazon EC2 实例上运行此脚本。",
      "C": "创建一个 AWS Lambda 函数，扫描 DynamoDB 表，并在必要时使用 Amazon Simple Notification Service (Amazon SNS) 向员工发送电子邮件。将此 Lambda 函数安排为每天运行。",
      "D": "创建一个 AWS Lambda 函数，扫描 DynamoDB 表，并在必要时使用 Amazon Simple Queue Service (Amazon SQS) 向员工发送电子邮件。将此 Lambda 函数安排为每天运行。"
    }
  },
  {
    "id": 846,
    "topic": "1",
    "question_en": "A company’s application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancing (ELB) load balancer. Based on the application's history, the company anticipates a spike in trafic during a holiday each year. A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%.",
      "B": "Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand.",
      "C": "Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period.",
      "D": "Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are autoscaling:EC2_INSTANCE_LAUNCH events."
    },
    "correct_answer": "B",
    "vote_percentage": "91%",
    "question_cn": "一家公司的应用程序在弹性负载平衡 (ELB) 负载均衡器后面的 Auto Scaling 组中的 Amazon EC2 实例上运行。根据应用程序的历史记录，该公司预计每年假期期间流量会激增。解决方案架构师必须设计一种策略，以确保 Auto Scaling 组主动增加容量，以最大限度地减少对应用程序用户的任何性能影响。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon CloudWatch 警报，当 CPU 利用率超过 90% 时，扩大 EC2 实例的规模。",
      "B": "创建一个定期计划的操作，在预计的峰值需求时段之前扩大 Auto Scaling 组的规模。",
      "C": "在峰值需求期间增加 Auto Scaling 组中 EC2 实例的最小和最大数量。",
      "D": "配置一个 Amazon Simple Notification Service (Amazon SNS) 通知，以在发生 autoscaling:EC2_INSTANCE_LAUNCH 事件时发送警报。"
    }
  },
  {
    "id": 847,
    "topic": "1",
    "question_en": "A company uses Amazon RDS for PostgreSQL databases for its data tier. The company must implement password rotation for the databases. Which solution meets this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the password in AWS Secrets Manager. Enable automatic rotation on the secret.",
      "B": "Store the password in AWS Systems Manager Parameter Store. Enable automatic rotation on the parameter.",
      "C": "Store the password in AWS Systems Manager Parameter Store. Write an AWS Lambda function that rotates the password.",
      "D": "Store the password in AWS Key Management Service (AWS KMS). Enable automatic rotation on the AWS KMS key."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon RDS for PostgreSQL 数据库作为其数据层。该公司必须为数据库实施密码轮换。哪个解决方案以最少的运营开销满足此要求？",
    "options_cn": {
      "A": "将密码存储在 AWS Secrets Manager 中。在密钥上启用自动轮换。",
      "B": "将密码存储在 AWS Systems Manager Parameter Store 中。在参数上启用自动轮换。",
      "C": "将密码存储在 AWS Systems Manager Parameter Store 中。编写一个 AWS Lambda 函数来轮换密码。",
      "D": "将密码存储在 AWS Key Management Service (AWS KMS) 中。在 AWS KMS 密钥上启用自动轮换。"
    }
  },
  {
    "id": 848,
    "topic": "1",
    "question_en": "A company runs its application on Oracle Database Enterprise Edition. The company needs to migrate the application and the database to AWS. The company can use the Bring Your Own License (BYOL) model while migrating to AWS. The application uses third-party database features that require privileged access. A solutions architect must design a solution for the database migration. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Migrate the database to Amazon RDS for Oracle by using native tools. Replace the third-party features with AWS Lambda.",
      "B": "Migrate the database to Amazon RDS Custom for Oracle by using native tools. Customize the new database settings to support the third-party features.",
      "C": "Migrate the database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS). Customize the new database settings to support the third-party features.",
      "D": "Migrate the database to Amazon RDS for PostgreSQL by using AWS Database Migration Service (AWS DMS). Rewrite the application code to remove the dependency on third-party features."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在其 Oracle Database Enterprise Edition 上运行其应用程序。该公司需要将应用程序和数据库迁移到 AWS。该公司可以在迁移到 AWS 时使用自带许可证 (BYOL) 模型。该应用程序使用需要特权访问的第三方数据库功能。解决方案架构师必须为数据库迁移设计一个解决方案。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用原生工具将数据库迁移到 Amazon RDS for Oracle。用 AWS Lambda 替换第三方功能。",
      "B": "使用原生工具将数据库迁移到 Amazon RDS Custom for Oracle。自定义新的数据库设置以支持第三方功能。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 将数据库迁移到 Amazon DynamoDB。自定义新的数据库设置以支持第三方功能。",
      "D": "使用 AWS Database Migration Service (AWS DMS) 将数据库迁移到 Amazon RDS for PostgreSQL。重写应用程序代码以移除对第三方功能的依赖。"
    }
  },
  {
    "id": 849,
    "topic": "1",
    "question_en": "A large international university has deployed all of its compute services in the AWS Cloud. These services include Amazon EC2, Amazon RDS, and Amazon DynamoDB. The university currently relies on many custom scripts to back up its infrastructure. However, the university wants to centralize management and automate data backups as much as possible by using AWS native options. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use third-party backup software with an AWS Storage Gateway tape gateway virtual tape library.",
      "B": "Use AWS Backup to configure and monitor all backups for the services in use.",
      "C": "Use AWS Config to set lifecycle management to take snapshots of all data sources on a schedule.",
      "D": "Use AWS Systems Manager State Manager to manage the configuration and monitoring of backup tasks."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一所大型国际大学已在 AWS 云中部署了其所有计算服务。这些服务包括 Amazon EC2、Amazon RDS 和 Amazon DynamoDB。该大学目前依赖许多自定义脚本来备份其基础设施。但是，该大学希望通过使用 AWS 原生选项来集中管理并尽可能多地自动化数据备份。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用第三方备份软件与 AWS Storage Gateway 磁带网关虚拟磁带库。",
      "B": "使用 AWS Backup 为正在使用的服务配置和监控所有备份。",
      "C": "使用 AWS Config 设置生命周期管理，以按计划拍摄所有数据源的快照。",
      "D": "使用 AWS Systems Manager State Manager 来管理备份任务的配置和监控。"
    }
  },
  {
    "id": 850,
    "topic": "1",
    "question_en": "A company wants to build a map of its IT infrastructure to identify and enforce policies on resources that pose security risks. The company's security team must be able to query data in the IT infrastructure map and quickly identify security risks. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon RDS to store the data. Use SQL to query the data to identify security risks.",
      "B": "Use Amazon Neptune to store the data. Use SPARQL to query the data to identify security risks.",
      "C": "Use Amazon Redshift to store the data. Use SQL to query the data to identify security risks.",
      "D": "Use Amazon DynamoDB to store the data. Use PartiQL to query the data to identify security risks."
    },
    "correct_answer": "B",
    "vote_percentage": "86%",
    "question_cn": "一家公司希望构建其 IT 基础设施的地图，以识别和执行对构成安全风险的资源的策略。该公司的安全团队必须能够查询 IT 基础设施地图中的数据并快速识别安全风险。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon RDS 存储数据。使用 SQL 查询数据以识别安全风险。",
      "B": "使用 Amazon Neptune 存储数据。使用 SPARQL 查询数据以识别安全风险。",
      "C": "使用 Amazon Redshift 存储数据。使用 SQL 查询数据以识别安全风险。",
      "D": "使用 Amazon DynamoDB 存储数据。使用 PartiQL 查询数据以识别安全风险。"
    }
  },
  {
    "id": 851,
    "topic": "1",
    "question_en": "A large company wants to provide its globally located developers separate, limited size, managed PostgreSQL databases for development purposes. The databases will be low volume. The developers need the databases only when they are actively working. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Give the developers the ability to launch separate Amazon Aurora instances. Set up a process to shut down Aurora instances at the end of the workday and to start Aurora instances at the beginning of the next workday.",
      "B": "Develop an AWS Service Catalog product that enforces size restrictions for launching Amazon Aurora instances. Give the developers access to launch the product when they need a development database.",
      "C": "Create an Amazon Aurora Serverless cluster. Develop an AWS Service Catalog product to launch databases in the cluster with the default capacity settings. Grant the developers access to the product.",
      "D": "Monitor AWS Trusted Advisor checks for idle Amazon RDS databases. Create a process to terminate identified idle RDS databases."
    },
    "correct_answer": "C",
    "vote_percentage": "75%",
    "question_cn": "一家大型公司希望为其全球的开发人员提供独立的、大小受限的、托管的 PostgreSQL 数据库，用于开发目的。这些数据库的用量很低。开发人员仅在他们积极工作时才需要这些数据库。哪种解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "让开发人员能够启动独立的 Amazon Aurora 实例。设置一个流程，在工作日结束时关闭 Aurora 实例，并在下一个工作日开始时启动 Aurora 实例。",
      "B": "开发一个 AWS Service Catalog 产品，该产品强制执行启动 Amazon Aurora 实例的大小限制。让开发人员在需要开发数据库时访问启动该产品。",
      "C": "创建一个 Amazon Aurora Serverless 集群。开发一个 AWS Service Catalog 产品，以默认容量设置在集群中启动数据库。授予开发人员访问该产品的权限。",
      "D": "监控 AWS Trusted Advisor 检查，检查闲置的 Amazon RDS 数据库。创建一个流程来终止已识别的闲置 RDS 数据库。"
    }
  },
  {
    "id": 852,
    "topic": "1",
    "question_en": "A company is building a web application that serves a content management system. The content management system runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones. Users are constantly adding and updating files, blogs, and other website assets in the content management system. A solutions architect must implement a solution in which all the EC2 instances share up-to-date website content with the least possible lag time. Which solution meets these requirements?",
    "options_en": {
      "A": "Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the website assets only in the newest EC2 instance.",
      "B": "Copy the website assets to an Amazon Elastic File System (Amazon EFS) file system. Configure each EC2 instance to mount the EFS file system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.",
      "C": "Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Elastic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.",
      "D": "Restore an Amazon Elastic Block Store (Amazon EBS) snapshot with the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在构建一个为内容管理系统提供服务的 Web 应用程序。内容管理系统在应用程序负载均衡器 (ALB) 后的 Amazon EC2 实例上运行。EC2 实例在多个可用区中的 Auto Scaling 组中运行。用户不断在内容管理系统中添加和更新文件、博客和其他网站资产。解决方案架构师必须实施一种解决方案，其中所有 EC2 实例共享最新的网站内容，且滞后时间最短。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "更新 Auto Scaling 组生命周期策略中的 EC2 用户数据，以从最近启动的 EC2 实例复制网站资产。配置 ALB 仅在新 EC2 实例中更改网站资产。",
      "B": "将网站资产复制到 Amazon Elastic File System (Amazon EFS) 文件系统。将每个 EC2 实例配置为在本地挂载 EFS 文件系统。配置网站托管应用程序以引用存储在 EFS 文件系统中的网站资产。",
      "C": "将网站资产复制到 Amazon S3 存储桶。确保每个 EC2 实例从 S3 存储桶下载网站资产到连接的 Amazon Elastic Block Store (Amazon EBS) 卷。定期间隔运行 S3 同步命令以保持文件最新。",
      "D": "使用网站资产还原 Amazon Elastic Block Store (Amazon EBS) 快照。在启动新 EC2 实例时，将 EBS 快照作为辅助 EBS 卷连接。配置网站托管应用程序以引用存储在辅助 EBS 卷中的网站资产。"
    }
  },
  {
    "id": 853,
    "topic": "1",
    "question_en": "A company's web application consists of multiple Amazon EC2 instances that run behind an Application Load Balancer in a VPC. An Amazon RDS for MySQL DB instance contains the data. The company needs the ability to automatically detect and respond to suspicious or unexpected behavior in its AWS environment. The company already has added AWS WAF to its architecture. What should a solutions architect do next to protect against threats?",
    "options_en": {
      "A": "Use Amazon GuardDuty to perform threat detection. Configure Amazon EventBridge to filter for GuardDuty findings and to invoke an AWS Lambda function to adjust the AWS WAF rules.",
      "B": "Use AWS Firewall Manager to perform threat detection. Configure Amazon EventBridge to filter for Firewall Manager findings and to invoke an AWS Lambda function to adjust the AWS WAF web ACL.",
      "C": "Use Amazon Inspector to perform threat detection and to update the AWS WAF rules. Create a VPC network ACL to limit access to the web application.",
      "D": "Use Amazon Macie to perform threat detection and to update the AWS WAF rules. Create a VPC network ACL to limit access to the web application."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司的 Web 应用程序由多个在 VPC 中的 Application Load Balancer 后面运行的 Amazon EC2 实例组成。Amazon RDS for MySQL 数据库实例包含数据。该公司需要能够自动检测和响应其 AWS 环境中可疑或意外行为的能力。该公司已在其架构中添加了 AWS WAF。解决方案架构师接下来应该做什么来防范威胁？",
    "options_cn": {
      "A": "使用 Amazon GuardDuty 执行威胁检测。配置 Amazon EventBridge 以筛选 GuardDuty 结果并调用 AWS Lambda 函数以调整 AWS WAF 规则。",
      "B": "使用 AWS Firewall Manager 执行威胁检测。配置 Amazon EventBridge 以筛选 Firewall Manager 结果并调用 AWS Lambda 函数以调整 AWS WAF Web ACL。",
      "C": "使用 Amazon Inspector 执行威胁检测并更新 AWS WAF 规则。创建 VPC 网络 ACL 以限制对 Web 应用程序的访问。",
      "D": "使用 Amazon Macie 执行威胁检测并更新 AWS WAF 规则。创建 VPC 网络 ACL 以限制对 Web 应用程序的访问。"
    }
  },
  {
    "id": 854,
    "topic": "1",
    "question_en": "A company is planning to run a group of Amazon EC2 instances that connect to an Amazon Aurora database. The company has built an AWS CloudFormation template to deploy the EC2 instances and the Aurora DB cluster. The company wants to allow the instances to authenticate to the database in a secure way. The company does not want to maintain static database credentials. Which solution meets these requirements with the LEAST operational effort?",
    "options_en": {
      "A": "Create a database user with a user name and password. Add parameters for the database user name and password to the CloudFormation template. Pass the parameters to the EC2 instances when the instances are launched.",
      "B": "Create a database user with a user name and password. Store the user name and password in AWS Systems Manager Parameter Store. Configure the EC2 instances to retrieve the database credentials from Parameter Store.",
      "C": "Configure the DB cluster to use IAM database authentication. Create a database user to use with IAM authentication. Associate a role with the EC2 instances to allow applications on the instances to access the database.",
      "D": "Configure the DB cluster to use IAM database authentication with an IAM user. Create a database user that has a name that matches the IAM user. Associate the IAM user with the EC2 instances to allow applications on the instances to access the database."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划运行一组连接到 Amazon Aurora 数据库的 Amazon EC2 实例。该公司构建了一个 AWS CloudFormation 模板来部署 EC2 实例和 Aurora 数据库集群。该公司希望允许实例以安全的方式向数据库进行身份验证。该公司不想维护静态数据库凭证。哪种解决方案以最少的运营工作量满足这些要求？",
    "options_cn": {
      "A": "使用用户名和密码创建数据库用户。将数据库用户名和密码的参数添加到 CloudFormation 模板。在启动实例时将参数传递给 EC2 实例。",
      "B": "使用用户名和密码创建数据库用户。将用户名和密码存储在 AWS Systems Manager Parameter Store 中。配置 EC2 实例从 Parameter Store 检索数据库凭证。",
      "C": "配置数据库集群以使用 IAM 数据库身份验证。创建一个数据库用户以与 IAM 身份验证一起使用。将一个角色与 EC2 实例关联，以允许实例上的应用程序访问数据库。",
      "D": "配置数据库集群以使用 IAM 数据库身份验证以及 IAM 用户。创建一个与 IAM 用户名匹配的数据库用户。将 IAM 用户与 EC2 实例关联，以允许实例上的应用程序访问数据库。"
    }
  },
  {
    "id": 855,
    "topic": "1",
    "question_en": "A company wants to configure its Amazon CloudFront distribution to use SSL/TLS certificates. The company does not want to use the default domain name for the distribution. Instead, the company wants to use a different domain name for the distribution. Which solution will deploy the certificate without incurring any additional costs?",
    "options_en": {
      "A": "Request an Amazon issued private certificate from AWS Certificate Manager (ACM) in the us-east-1 Region.",
      "B": "Request an Amazon issued private certificate from AWS Certificate Manager (ACM) in the us-west-1 Region.",
      "C": "Request an Amazon issued public certificate from AWS Certificate Manager (ACM) in the us-east-1 Region.",
      "D": "Request an Amazon issued public certificate from AWS Certificate Manager (ACM) in the us-west-1 Region."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望配置其 Amazon CloudFront 分配以使用 SSL/TLS 证书。该公司不想使用该分配的默认域名。相反，该公司希望使用该分配的不同域名。哪种解决方案将部署证书而不会产生任何额外费用？",
    "options_cn": {
      "A": "从 us-east-1 区域的 AWS Certificate Manager (ACM) 请求 Amazon 颁发的私有证书。",
      "B": "从 us-west-1 区域的 AWS Certificate Manager (ACM) 请求 Amazon 颁发的私有证书。",
      "C": "从 us-east-1 区域的 AWS Certificate Manager (ACM) 请求 Amazon 颁发的公共证书。",
      "D": "从 us-west-1 区域的 AWS Certificate Manager (ACM) 请求 Amazon 颁发的公共证书。"
    }
  },
  {
    "id": 856,
    "topic": "1",
    "question_en": "A company creates operations data and stores the data in an Amazon S3 bucket. For the company's annual audit, an external consultant needs to access an annual report that is stored in the S3 bucket. The external consultant needs to access the report for 7 days. The company must implement a solution to allow the external consultant access to only the report. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create a new S3 bucket that is configured to host a public static website. Migrate the operations data to the new S3 bucket. Share the S3 website URL with the external consultant.",
      "B": "Enable public access to the S3 bucket for 7 days. Remove access to the S3 bucket when the external consultant completes the audit.",
      "C": "Create a new IAM user that has access to the report in the S3 bucket. Provide the access keys to the external consultant. Revoke the access keys after 7 days.",
      "D": "Generate a presigned URL that has the required access to the location of the report on the S3 bucket. Share the presigned URL with the external consultant."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司创建运营数据并将数据存储在 Amazon S3 存储桶中。对于公司的年度审计，外部顾问需要访问存储在 S3 存储桶中的年度报告。外部顾问需要访问该报告 7 天。该公司必须实施一个解决方案，以允许外部顾问仅访问该报告。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 S3 存储桶，该存储桶配置为托管公共静态网站。将运营数据迁移到新的 S3 存储桶。与外部顾问共享 S3 网站 URL。",
      "B": "打开对 S3 存储桶的公共访问权限 7 天。当外部顾问完成审计时，移除对 S3 存储桶的访问权限。",
      "C": "创建一个新的 IAM 用户，该用户有权访问 S3 存储桶中的报告。向外部顾问提供访问密钥。7 天后撤销访问密钥。",
      "D": "生成一个预签名 URL，该 URL 具有对 S3 存储桶中报告位置的必要访问权限。与外部顾问共享预签名 URL。"
    }
  },
  {
    "id": 857,
    "topic": "1",
    "question_en": "A company plans to run a high performance computing (HPC) workload on Amazon EC2 Instances. The workload requires low-latency network performance and high network throughput with tightly coupled node-to-node communication. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the EC2 instances to be part of a cluster placement group.",
      "B": "Launch the EC2 instances with Dedicated Instance tenancy.",
      "C": "Launch the EC2 instances as Spot Instances.",
      "D": "Configure an On-Demand Capacity Reservation when the EC2 instances are launched."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司计划在 Amazon EC2 实例上运行高性能计算 (HPC) 工作负载。该工作负载需要低延迟的网络性能和高网络吞吐量，并具有紧密耦合的节点间通信。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 EC2 实例配置为集群放置组的一部分。",
      "B": "使用 Dedicated Instance 租赁启动 EC2 实例。",
      "C": "将 EC2 实例作为 Spot Instances 启动。",
      "D": "在启动 EC2 实例时配置按需容量预留。"
    }
  },
  {
    "id": 858,
    "topic": "1",
    "question_en": "A company has primary and secondary data centers that are 500 miles (804.7 km) apart and interconnected with high-speed fiber-optic cable. The company needs a highly available and secure network connection between its data centers and a VPC on AWS for a mission-critical workload. A solutions architect must choose a connection solution that provides maximum resiliency. Which solution meets these requirements?",
    "options_en": {
      "A": "Two AWS Direct Connect connections from the primary data center terminating at two Direct Connect locations on two separate devices",
      "B": "A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on the same device",
      "C": "Two AWS Direct Connect connections from each of the primary and secondary data centers terminating at two Direct Connect locations on two separate devices",
      "D": "A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on two separate devices"
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有主数据中心和辅助数据中心，这两个数据中心相距 500 英里（804.7 公里），并通过高速光纤电缆互连。该公司需要在其数据中心和 AWS 上的 VPC 之间建立一个高可用性和安全的网络连接，以用于关键任务工作负载。解决方案架构师必须选择一个能提供最大弹性的连接解决方案。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "从主数据中心到两个 Direct Connect 位置的两个 AWS Direct Connect 连接，终止于两个独立设备",
      "B": "从主数据中心和辅助数据中心各自到同一个 Direct Connect 位置的一个 AWS Direct Connect 连接，终止于同一设备",
      "C": "从主数据中心和辅助数据中心各自到两个 Direct Connect 位置的两个 AWS Direct Connect 连接，终止于两个独立设备",
      "D": "从主数据中心和辅助数据中心各自到同一个 Direct Connect 位置的一个 AWS Direct Connect 连接，终止于两个独立设备"
    }
  },
  {
    "id": 859,
    "topic": "1",
    "question_en": "A company runs several Amazon RDS for Oracle On-Demand DB instances that have high utilization. The RDS DB instances run in member accounts that are in an organization in AWS Organizations. The company's finance team has access to the organization's management account and member accounts. The finance team wants to find ways to optimize costs by using AWS Trusted Advisor. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use the Trusted Advisor recommendations in the management account.",
      "B": "Use the Trusted Advisor recommendations in the member accounts where the RDS DB instances are running.",
      "C": "Review the Trusted Advisor checks for Amazon RDS Reserved Instance Optimization.",
      "D": "Review the Trusted Advisor checks for Amazon RDS Idle DB Instances",
      "E": "Review the Trusted Advisor checks for compute optimization. Crosscheck the results by using AWS Compute Optimizer."
    },
    "correct_answer": "B",
    "vote_percentage": "62%",
    "question_cn": "一家公司运行几个 Amazon RDS for Oracle 按需数据库实例，这些实例具有高利用率。RDS 数据库实例在 AWS Organizations 中的组织中的成员账户中运行。该公司的财务团队有权访问该组织的管理账户和成员账户。财务团队希望通过使用 AWS Trusted Advisor 找到优化成本的方法。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用管理账户中的 Trusted Advisor 建议。",
      "B": "使用 RDS 数据库实例运行所在的成员账户中的 Trusted Advisor 建议。",
      "C": "查看 Amazon RDS 保留实例优化方面的 Trusted Advisor 检查。",
      "D": "查看 Amazon RDS 空闲数据库实例的 Trusted Advisor 检查。",
      "E": "查看计算优化方面的 Trusted Advisor 检查。使用 AWS Compute Optimizer 交叉检查结果。"
    }
  },
  {
    "id": 860,
    "topic": "1",
    "question_en": "A solutions architect is creating an application. The application will run on Amazon EC2 instances in private subnets across multiple Availability Zones in a VPC. The EC2 instances will frequently access large files that contain confidential information. These files are stored in Amazon S3 buckets for processing. The solutions architect must optimize the network architecture to minimize data transfer costs. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create a gateway endpoint for Amazon S3 in the VPC. In the route tables for the private subnets, add an entry for the gateway endpoint.",
      "B": "Create a single NAT gateway in a public subnet. In the route tables for the private subnets, add a default route that points to the NAT gateway.",
      "C": "Create an AWS PrivateLink interface endpoint for Amazon S3 in the VPIn the route tables for the private subnets, add an entry for the interface endpoint.",
      "D": "Create one NAT gateway for each Availability Zone in public subnets. In each of the route tables for the private subnets, add a default route that points to the NAT gateway in the same Availability Zone."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在创建一个应用程序。该应用程序将在VPC中跨多个可用区内的私有子网中的Amazon EC2实例上运行。EC2实例将频繁访问包含机密信息的大型文件。这些文件存储在Amazon S3存储桶中进行处理。解决方案架构师必须优化网络架构以最大限度地降低数据传输成本。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "在VPC中为Amazon S3创建一个网关endpoint。在私有子网的路由表中，为网关endpoint添加一个条目。",
      "B": "在公共子网中创建一个NAT gateway。在私有子网的路由表中，添加一个指向NAT gateway的默认路由。",
      "C": "在VPC中为Amazon S3创建一个AWS PrivateLink interface endpoint。在私有子网的路由表中，为interface endpoint添加一个条目。",
      "D": "在公共子网中为每个可用区创建一个NAT gateway。在每个私有子网的路由表中，添加一个指向同一可用区中NAT gateway的默认路由。"
    }
  },
  {
    "id": 861,
    "topic": "1",
    "question_en": "A company wants to relocate its on-premises MySQL database to AWS. The database accepts regular imports from a client-facing application, which causes a high volume of write operations. The company is concerned that the amount of trafic might be causing performance issues within the application. How should a solutions architect design the architecture on AWS?",
    "options_en": {
      "A": "Provision an Amazon RDS for MySQL DB instance with Provisioned IOPS SSD storage. Monitor write operation metrics by using Amazon CloudWatch. Adjust the provisioned IOPS if necessary.",
      "B": "Provision an Amazon RDS for MySQL DB instance with General Purpose SSD storage. Place an Amazon ElastiCache cluster in front of the DB instance. Configure the application to query ElastiCache instead.",
      "C": "Provision an Amazon DocumentDB (with MongoDB compatibility) instance with a memory optimized instance type. Monitor Amazon CloudWatch for performance-related issues. Change the instance class if necessary.",
      "D": "Provision an Amazon Elastic File System (Amazon EFS) file system in General Purpose performance mode. Monitor Amazon CloudWatch for IOPS bottlenecks. Change to Provisioned Throughput performance mode if necessary."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司希望将其本地 MySQL 数据库迁移到 AWS。该数据库接受来自面向客户端应用程序的定期导入，这导致了大量的写操作。该公司担心流量的增加可能会导致应用程序内的性能问题。解决方案架构师应该如何在 AWS 上设计架构？",
    "options_cn": {
      "A": "预置一个带有 Provisioned IOPS SSD 存储的 Amazon RDS for MySQL 数据库实例。使用 Amazon CloudWatch 监控写操作指标。如有必要，调整已预置的 IOPS。",
      "B": "预置一个带有 General Purpose SSD 存储的 Amazon RDS for MySQL 数据库实例。在数据库实例前面放置一个 Amazon ElastiCache 集群。配置应用程序查询 ElastiCache。",
      "C": "预置一个带有内存优化实例类型的 Amazon DocumentDB（兼容 MongoDB）实例。监控 Amazon CloudWatch 以查找与性能相关的问题。如有必要，更改实例类。",
      "D": "在 General Purpose 性能模式下预置一个 Amazon Elastic File System (Amazon EFS) 文件系统。监控 Amazon CloudWatch 以查找 IOPS 瓶颈。如有必要，更改为 Provisioned Throughput 性能模式。"
    }
  },
  {
    "id": 862,
    "topic": "1",
    "question_en": "A company runs an application in the AWS Cloud that generates sensitive archival data files. The company wants to rearchitect the application's data storage. The company wants to encrypt the data files and to ensure that third parties do not have access to the data before the data is encrypted and sent to AWS. The company has already created an Amazon S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the S3 bucket to use client-side encryption with an Amazon S3 managed encryption key. Configure the application to use the S3 bucket to store the archival files.",
      "B": "Configure the S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Configure the application to use the S3 bucket to store the archival files.",
      "C": "Configure the S3 bucket to use dual-layer server-side encryption with AWS KMS keys (SSE-KMS). Configure the application to use the S3 bucket to store the archival files.",
      "D": "Configure the application to use client-side encryption with a key stored in AWS Key Management Service (AWS KMS). Configure the application to store the archival files in the S3 bucket."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 云中运行一个应用程序，该应用程序生成敏感的归档数据文件。该公司希望重新设计应用程序的数据存储。该公司希望对数据文件进行加密，并确保第三方在数据加密并发送到 AWS 之前无法访问这些数据。该公司已经创建了一个 Amazon S3 存储桶。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 S3 存储桶配置为使用客户端加密和 Amazon S3 托管加密密钥。将应用程序配置为使用 S3 存储桶存储归档文件。",
      "B": "将 S3 存储桶配置为使用具有 AWS KMS 密钥的服务器端加密 (SSE-KMS)。将应用程序配置为使用 S3 存储桶存储归档文件。",
      "C": "将 S3 存储桶配置为使用具有 AWS KMS 密钥的双层服务器端加密 (SSE-KMS)。将应用程序配置为使用 S3 存储桶存储归档文件。",
      "D": "将应用程序配置为使用客户端加密，使用存储在 AWS Key Management Service (AWS KMS) 中的密钥。将应用程序配置为将归档文件存储在 S3 存储桶中。"
    }
  },
  {
    "id": 863,
    "topic": "1",
    "question_en": "A company uses Amazon RDS with default backup settings for its database tier. The company needs to make a daily backup of the database to meet regulatory requirements. The company must retain the backups for 30 days. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Write an AWS Lambda function to create an RDS snapshot every day.",
      "B": "Modify the RDS database to have a retention period of 30 days for automated backups.",
      "C": "Use AWS Systems Manager Maintenance Windows to modify the RDS backup retention period.",
      "D": "Create a manual snapshot every day by using the AWS CLI. Modify the RDS backup retention period."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon RDS 及其数据库层的默认备份设置。该公司需要每天备份数据库以满足监管要求。该公司必须将备份保留 30 天。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "编写一个 AWS Lambda 函数，每天创建 RDS 快照。",
      "B": "修改 RDS 数据库，使其自动备份的保留期为 30 天。",
      "C": "使用 AWS Systems Manager Maintenance Windows 修改 RDS 备份保留期。",
      "D": "每天使用 AWS CLI 创建手动快照。修改 RDS 备份保留期。"
    }
  },
  {
    "id": 864,
    "topic": "1",
    "question_en": "A company that runs its application on AWS uses an Amazon Aurora DB cluster as its database. During peak usage hours when multiple users access and read the data, the monitoring system shows degradation of database performance for the write queries. The company wants to increase the scalability of the application to meet peak usage demands. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a second Aurora DB cluster. Configure a copy job to replicate the users’ data to the new database. Update the application to use the second database to read the data.",
      "B": "Create an Amazon DynamoDB Accelerator (DAX) cluster in front of the existing Aurora DB cluster. Update the application to use the DAX cluster for read-only queries. Write data directly to the Aurora DB cluster.",
      "C": "Create an Aurora read replica in the existing Aurora DB cluster. Update the application to use the replica endpoint for read-only queries and to use the cluster endpoint for write queries.",
      "D": "Create an Amazon Redshift cluster. Copy the users' data to the Redshift cluster. Update the application to connect to the Redshift cluster and to perform read-only queries on the Redshift cluster."
    },
    "correct_answer": "C",
    "vote_percentage": "80%",
    "question_cn": "一家在 AWS 上运行其应用程序的公司使用 Amazon Aurora 数据库集群作为其数据库。 在多个用户访问和读取数据的峰值使用时段，监控系统显示写入查询的数据库性能下降。该公司希望提高应用程序的可扩展性以满足峰值使用需求。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建第二个 Aurora 数据库集群。 配置一个复制作业以将用户的数据复制到新数据库。 更新应用程序以使用第二个数据库读取数据。",
      "B": "在现有的 Aurora 数据库集群前面创建一个 Amazon DynamoDB Accelerator (DAX) 集群。更新应用程序以使用 DAX 集群进行只读查询。 直接将数据写入 Aurora 数据库集群。",
      "C": "在现有的 Aurora 数据库集群中创建一个 Aurora 只读副本。更新应用程序以使用副本终端节点进行只读查询，并使用集群终端节点进行写入查询。",
      "D": "创建一个 Amazon Redshift 集群。将用户的数据复制到 Redshift 集群。更新应用程序以连接到 Redshift 集群，并在 Redshift 集群上执行只读查询。"
    }
  },
  {
    "id": 865,
    "topic": "1",
    "question_en": "A company's near-real-time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance. Which combination of steps should the solutions architect take? (Choose two.)",
    "options_en": {
      "A": "Use Amazon Kinesis Data Firehose to ingest the data.",
      "B": "Use AWS Lambda with AWS Step Functions to process the data.",
      "C": "Use AWS Database Migration Service (AWS DMS) to ingest the data.",
      "D": "Use Amazon EC2 instances in an Auto Scaling group to process the data",
      "E": "Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司的近实时流应用程序正在 AWS 上运行。当数据被摄取时，一个作业在数据上运行，需要 30 分钟才能完成。由于大量传入数据，工作负载经常遇到高延迟。一位解决方案架构师需要设计一个可扩展的、无服务器的解决方案来提高性能。解决方案架构师应该采取哪些组合步骤？（选择两个。）",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Firehose 摄取数据。",
      "B": "使用 AWS Lambda 和 AWS Step Functions 处理数据。",
      "C": "使用 AWS Database Migration Service (AWS DMS) 摄取数据。",
      "D": "使用 Auto Scaling 组中的 Amazon EC2 实例来处理数据。",
      "E": "使用 AWS Fargate 和 Amazon Elastic Container Service (Amazon ECS) 来处理数据。"
    }
  },
  {
    "id": 866,
    "topic": "1",
    "question_en": "A company runs a web application on multiple Amazon EC2 instances in a VPC. The application needs to write sensitive data to an Amazon S3 bucket. The data cannot be sent over the public internet. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a gateway VPC endpoint for Amazon S3. Create a route in the VPC route table to the endpoint.",
      "B": "Create an internal Network Load Balancer that has the S3 bucket as the target.",
      "C": "Deploy the S3 bucket inside the VPCreate a route in the VPC route table to the bucket.",
      "D": "Create an AWS Direct Connect connection between the VPC and an S3 regional endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 VPC 中的多个 Amazon EC2 实例上运行一个 Web 应用程序。该应用程序需要将敏感数据写入 Amazon S3 存储桶。数据不能通过公共互联网发送。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Amazon S3 创建一个网关 VPC endpoint。在 VPC 路由表中创建指向该 endpoint 的路由。",
      "B": "创建一个内部 Network Load Balancer，该负载均衡器将 S3 存储桶作为目标。",
      "C": "在 VPC 内部部署 S3 存储桶。在 VPC 路由表中创建指向该存储桶的路由。",
      "D": "在 VPC 和 S3 区域 endpoint 之间创建 AWS Direct Connect 连接。"
    }
  },
  {
    "id": 867,
    "topic": "1",
    "question_en": "A company runs its production workload on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) volumes. A solutions architect needs to analyze the current EBS volume cost and to recommend optimizations. The recommendations need to include estimated monthly saving opportunities. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon Inspector reporting to generate EBS volume recommendations for optimization.",
      "B": "Use AWS Systems Manager reporting to determine EBS volume recommendations for optimization.",
      "C": "Use Amazon CloudWatch metrics reporting to determine EBS volume recommendations for optimization.",
      "D": "Use AWS Compute Optimizer to generate EBS volume recommendations for optimization."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在其 Amazon EC2 实例上运行生产工作负载，这些实例使用 Amazon Elastic Block Store (Amazon EBS) 卷。一个解决方案架构师需要分析当前的 EBS 卷成本并推荐优化措施。这些建议需要包括估计的月度节省机会。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Inspector 报告生成 EBS 卷优化建议。",
      "B": "使用 AWS Systems Manager 报告来确定 EBS 卷优化建议。",
      "C": "使用 Amazon CloudWatch 指标报告来确定 EBS 卷优化建议。",
      "D": "使用 AWS Compute Optimizer 生成 EBS 卷优化建议。"
    }
  },
  {
    "id": 868,
    "topic": "1",
    "question_en": "A global company runs its workloads on AWS. The company's application uses Amazon S3 buckets across AWS Regions for sensitive data storage and analysis. The company stores millions of objects in multiple S3 buckets daily. The company wants to identify all S3 buckets that are not versioning-enabled. Which solution will meet these requirements?",
    "options_en": {
      "B": "Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.",
      "C": "Enable IAM Access Analyzer for S3 to identify all S3 buckets that are not versioning-enabled across Regions.",
      "D": "Create an S3 Multi-Region Access Point to identify all S3 buckets that are not versioning-enabled across Regions."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家全球公司在 AWS 上运行其工作负载。 公司的应用程序使用跨 AWS 区域的 Amazon S3 存储桶来存储和分析敏感数据。该公司每天在多个 S3 存储桶中存储数百万个对象。该公司希望识别所有未启用版本控制的 S3 存储桶。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 AWS Lambda 函数，该函数定期检查所有 S3 存储桶，以确定哪些存储桶未启用版本控制。",
      "B": "使用 Amazon S3 Storage Lens 识别跨区域所有未启用版本控制的 S3 存储桶。",
      "C": "为 S3 启用 IAM Access Analyzer 以识别跨区域所有未启用版本控制的 S3 存储桶。",
      "D": "创建一个 S3 多区域访问点来识别跨区域所有未启用版本控制的 S3 存储桶。"
    }
  },
  {
    "id": 889,
    "topic": "",
    "question_en": "On the other hand S3 Storage Lens: You can use the Versioning-enabled bucket count metric to see which buckets use S3 Versioning. Then, you can take action in the S3 console to enable S3 Versioning for other buckets. So",
    "options_en": {},
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "另一方面，S3 Storage Lens：您可以使用已启用版本控制的存储桶计数指标来查看哪些存储桶使用 S3 版本控制。然后，您可以在 S3 控制台中采取措施，为其他存储桶打开 S3 版本控制。所以",
    "options_cn": {
      "A": "S3 存储桶现在启用了版本控制。",
      "B": "版本控制已在所有 S3 存储桶中启用。",
      "C": "您可以识别当前未启用版本控制的 S3 存储桶。",
      "D": "您正在创建 S3 跨区域复制。"
    }
  },
  {
    "id": 869,
    "topic": "1",
    "question_en": "A company wants to enhance its ecommerce order-processing application that is deployed on AWS. The application must process each order exactly once without affecting the customer experience during unpredictable trafic surges. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Put all the orders in the SQS queue. Configure an AWS Lambda function as the target to process the orders.",
      "B": "Create an Amazon Simple Notification Service (Amazon SNS) standard topic. Publish all the orders to the SNS standard topic. Configure the application as a notification target.",
      "C": "Create a fiow by using Amazon AppFlow. Send the orders to the fiow. Configure an AWS Lambda function as the target to process the orders.",
      "D": "Configure AWS X-Ray in the application to track the order requests. Configure the application to process the orders by pulling the orders from Amazon CloudWatch."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望增强其部署在 AWS 上的电子商务订单处理应用程序。该应用程序必须准确地处理每个订单一次，且在不可预测的流量激增期间不影响客户体验。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建 Amazon Simple Queue Service (Amazon SQS) FIFO 队列。将所有订单放入 SQS 队列中。将 AWS Lambda 函数配置为目标以处理订单。",
      "B": "创建一个 Amazon Simple Notification Service (Amazon SNS) 标准主题。将所有订单发布到 SNS 标准主题。将应用程序配置为通知目标。",
      "C": "使用 Amazon AppFlow 创建一个流程。将订单发送到该流程。将 AWS Lambda 函数配置为目标以处理订单。",
      "D": "在应用程序中配置 AWS X-Ray 以跟踪订单请求。配置应用程序，通过从 Amazon CloudWatch 中提取订单来处理这些订单。"
    }
  },
  {
    "id": 870,
    "topic": "1",
    "question_en": "A company has two AWS accounts: Production and Development. The company needs to push code changes in the Development account to the Production account. In the alpha phase, only two senior developers on the development team need access to the Production account. In the beta phase, more developers will need access to perform testing. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create two policy documents by using the AWS Management Console in each account. Assign the policy to developers who need access.",
      "B": "Create an IAM role in the Development account. Grant the IAM role access to the Production account. Allow developers to assume the role.",
      "C": "Create an IAM role in the Production account. Define a trust policy that specifies the Development account. Allow developers to assume the role.",
      "D": "Create an IAM group in the Production account. Add the group as a principal in a trust policy that specifies the Production account. Add developers to the group."
    },
    "correct_answer": "C",
    "vote_percentage": "55%",
    "question_cn": "一家公司有两个 AWS 账户：生产环境和开发环境。该公司需要在开发账户中推送代码更改到生产环境账户。在 alpha 阶段，只有开发团队中的两名高级开发人员需要访问生产环境账户。在 beta 阶段，将有更多开发人员需要访问以执行测试。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用每个账户中的 AWS 管理控制台创建两个策略文档。将策略分配给需要访问的开发人员。",
      "B": "在开发账户中创建一个 IAM 角色。授予 IAM 角色访问生产环境账户的权限。允许开发人员担任该角色。",
      "C": "在生产环境账户中创建一个 IAM 角色。定义一个信任策略，指定开发环境账户。允许开发人员担任该角色。",
      "D": "在生产环境账户中创建一个 IAM 组。将该组添加为指定生产环境账户的信任策略中的委托人。将开发人员添加到该组。"
    }
  },
  {
    "id": 871,
    "topic": "1",
    "question_en": "A company wants to restrict access to the content of its web application. The company needs to protect the content by using authorization techniques that are available on AWS. The company also wants to implement a serverless architecture for authorization and authentication that has low login latency. The solution must integrate with the web application and serve web content globally. The application currently has a small user base, but the company expects the application's user base to increase. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure Amazon Cognito for authentication. Implement Lambda@Edge for authorization. Configure Amazon CloudFront to serve the web application globally.",
      "B": "Configure AWS Directory Service for Microsoft Active Directory for authentication. Implement AWS Lambda for authorization. Use an Application Load Balancer to serve the web application globally.",
      "C": "Configure Amazon Cognito for authentication. Implement AWS Lambda for authorization. Use Amazon S3 Transfer Acceleration to serve the web application globally.",
      "D": "Configure AWS Directory Service for Microsoft Active Directory for authentication. Implement Lambda@Edge for authorization. Use AWS Elastic Beanstalk to serve the web application globally."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望限制对其 Web 应用程序内容的访问。该公司需要使用 AWS 上可用的授权技术来保护内容。该公司还希望为授权和身份验证实施一个无服务器架构，该架构具有低登录延迟。该解决方案必须与 Web 应用程序集成并全球范围地提供 Web 内容。该应用程序目前的用户群很小，但该公司预计该应用程序的用户群会增加。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Cognito 用于身份验证。实施 Lambda@Edge 用于授权。配置 Amazon CloudFront 以在全球范围内提供 Web 应用程序。",
      "B": "配置 AWS Directory Service for Microsoft Active Directory 用于身份验证。实施 AWS Lambda 用于授权。使用 Application Load Balancer 以在全球范围内提供 Web 应用程序。",
      "C": "配置 Amazon Cognito 用于身份验证。实施 AWS Lambda 用于授权。使用 Amazon S3 Transfer Acceleration 以在全球范围内提供 Web 应用程序。",
      "D": "配置 AWS Directory Service for Microsoft Active Directory 用于身份验证。实施 Lambda@Edge 用于授权。使用 AWS Elastic Beanstalk 以在全球范围内提供 Web 应用程序。"
    }
  },
  {
    "id": 872,
    "topic": "1",
    "question_en": "A development team uses multiple AWS accounts for its development, staging, and production environments. Team members have been launching large Amazon EC2 instances that are underutilized. A solutions architect must prevent large instances from being launched in all accounts. How can the solutions architect meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Update the IAM policies to deny the launch of large EC2 instances. Apply the policies to all users.",
      "B": "Define a resource in AWS Resource Access Manager that prevents the launch of large EC2 instances.",
      "C": "Create an IAM role in each account that denies the launch of large EC2 instances. Grant the developers IAM group access to the role.",
      "D": "Create an organization in AWS Organizations in the management account with the default policy. Create a service control policy (SCP) that denies the launch of large EC2 instances, and apply it to the AWS accounts."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "开发团队为其开发、预发布和生产环境使用多个 AWS 账户。团队成员一直在启动未充分利用的大型 Amazon EC2 实例。解决方案架构师必须阻止在所有账户中启动大型实例。解决方案架构师如何以最小的运营开销满足此要求？",
    "options_cn": {
      "A": "更新 IAM 策略以拒绝启动大型 EC2 实例。将策略应用于所有用户。",
      "B": "在 AWS Resource Access Manager 中定义一个资源，以阻止启动大型 EC2 实例。",
      "C": "在每个账户中创建一个 IAM 角色，以拒绝启动大型 EC2 实例。授予开发人员 IAM 组访问该角色的权限。",
      "D": "在管理账户的 AWS Organizations 中使用默认策略创建一个组织。创建一个服务控制策略 (SCP) 以拒绝启动大型 EC2 实例，并将其应用于 AWS 账户。"
    }
  },
  {
    "id": 873,
    "topic": "1",
    "question_en": "A company has migrated a fieet of hundreds of on-premises virtual machines (VMs) to Amazon EC2 instances. The instances run a diverse fieet of Windows Server versions along with several Linux distributions. The company wants a solution that will automate inventory and updates of the operating systems. The company also needs a summary of common vulnerabilities of each instance for regular monthly reviews. What should a solutions architect recommend to meet these requirements?",
    "options_en": {
      "A": "Set up AWS Systems Manager Patch Manager to manage all the EC2 instances. Configure AWS Security Hub to produce monthly reports.",
      "B": "Set up AWS Systems Manager Patch Manager to manage all the EC2 instances. Deploy Amazon Inspector, and configure monthly reports.",
      "C": "Set up AWS Shield Advanced, and configure monthly reports. Deploy AWS Config to automate patch installations on the EC2 instances.",
      "D": "Set up Amazon GuardDuty in the account to monitor all EC2 instances. Deploy AWS Config to automate patch installations on the EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家公司已将其数百台本地虚拟机 (VM) 迁移到 Amazon EC2 实例。 这些实例运行各种 Windows Server 版本以及多个 Linux 发行版。该公司希望一个可以自动进行操作系统清点和更新的解决方案。该公司还需要每个实例的常见漏洞摘要，以供定期的月度审查。解决方案架构师应该推荐什么来满足这些要求？",
    "options_cn": {
      "A": "设置 AWS Systems Manager Patch Manager 以管理所有 EC2 实例。配置 AWS Security Hub 以生成月度报告。",
      "B": "设置 AWS Systems Manager Patch Manager 以管理所有 EC2 实例。部署 Amazon Inspector，并配置月度报告。",
      "C": "设置 AWS Shield Advanced，并配置月度报告。部署 AWS Config 以自动在 EC2 实例上安装补丁程序。",
      "D": "在账户中设置 Amazon GuardDuty 以监控所有 EC2 实例。部署 AWS Config 以自动在 EC2 实例上安装补丁程序。"
    }
  },
  {
    "id": 874,
    "topic": "1",
    "question_en": "A company hosts its application in the AWS Cloud. The application runs on Amazon EC2 instances in an Auto Scaling group behind an Elastic Load Balancing (ELB) load balancer. The application connects to an Amazon DynamoDB table. For disaster recovery (DR) purposes, the company wants to ensure that the application is available from another AWS Region with minimal downtime. Which solution will meet these requirements with the LEAST downtime?",
    "options_en": {
      "A": "Create an Auto Scaling group and an ELB in the DR Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new DR Region's ELB.",
      "B": "Create an AWS CloudFormation template to create EC2 instances, ELBs, and DynamoDB tables to be launched when necessary. Configure DNS failover to point to the new DR Region's ELB.",
      "C": "Create an AWS CloudFormation template to create EC2 instances and an ELB to be launched when necessary. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new DR Region's ELB.",
      "D": "Create an Auto Scaling group and an ELB in the DR Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm with an evaluation period of 10 minutes to invoke an AWS Lambda function that updates Amazon Route 53 to point to the DR Region's ELB."
    },
    "correct_answer": "A",
    "vote_percentage": "85%",
    "question_cn": "一家公司在 AWS 云中托管其应用程序。该应用程序在 Elastic Load Balancing (ELB) 负载均衡器后面的 Auto Scaling 组中的 Amazon EC2 实例上运行。该应用程序连接到 Amazon DynamoDB 表。为了灾难恢复 (DR) 的目的，该公司希望确保该应用程序可以从另一个 AWS 区域使用，并且停机时间最短。哪种解决方案能以最少的停机时间满足这些要求？",
    "options_cn": {
      "A": "在 DR 区域创建 Auto Scaling 组和 ELB。将 DynamoDB 表配置为全局表。配置 DNS 故障转移以指向新的 DR 区域的 ELB。",
      "B": "创建 AWS CloudFormation 模板以创建 EC2 实例、ELB 和 DynamoDB 表，以便在必要时启动。配置 DNS 故障转移以指向新的 DR 区域的 ELB。",
      "C": "创建 AWS CloudFormation 模板以创建 EC2 实例和 ELB，以便在必要时启动。将 DynamoDB 表配置为全局表。配置 DNS 故障转移以指向新的 DR 区域的 ELB。",
      "D": "在 DR 区域创建 Auto Scaling 组和 ELB。将 DynamoDB 表配置为全局表。创建一个 Amazon CloudWatch 警报，评估周期为 10 分钟，以调用一个 AWS Lambda 函数，该函数更新 Amazon Route 53 以指向 DR 区域的 ELB。"
    }
  },
  {
    "id": 875,
    "topic": "1",
    "question_en": "A company runs an application on Amazon EC2 instances in a private subnet. The application needs to store and retrieve data in Amazon S3 buckets. According to regulatory requirements, the data must not travel across the public internet. What should a solutions architect do to meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Deploy a NAT gateway to access the S3 buckets.",
      "B": "Deploy AWS Storage Gateway to access the S3 buckets.",
      "C": "Deploy an S3 interface endpoint to access the S3 buckets.",
      "D": "Deploy an S3 gateway endpoint to access the S3 buckets."
    },
    "correct_answer": "D",
    "vote_percentage": "85%",
    "question_cn": "一家公司在私有子网中的 Amazon EC2 实例上运行应用程序。 该应用程序需要在 Amazon S3 存储桶中存储和检索数据。 根据法规要求，数据不得通过公共互联网传输。 解决方案架构师应该怎么做才能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "部署 NAT Gateway 以访问 S3 存储桶。",
      "B": "部署 AWS Storage Gateway 以访问 S3 存储桶。",
      "C": "部署 S3 接口 endpoint 以访问 S3 存储桶。",
      "D": "部署 S3 网关 endpoint 以访问 S3 存储桶。"
    }
  },
  {
    "id": 876,
    "topic": "1",
    "question_en": "A company hosts an application on Amazon EC2 instances that run in a single Availability Zone. The application is accessible by using the transport layer of the Open Systems Interconnection (OSI) model. The company needs the application architecture to have high availability. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Configure new EC2 instances in a different Availability Zone. Use Amazon Route 53 to route trafic to all instances.",
      "B": "Configure a Network Load Balancer in front of the EC2 instances.",
      "C": "Configure a Network Load Balancer for TCP trafic to the instances. Configure an Application Load Balancer for HTTP and HTTPS trafic to the instances.",
      "D": "Create an Auto Scaling group for the EC2 instances. Configure the Auto Scaling group to use multiple Availability Zones. Configure the Auto Scaling group to run application health checks on the instances",
      "E": "Create an Amazon CloudWatch alarm. Configure the alarm to restart EC2 instances that transition to a stopped state."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在单个可用区中运行的 Amazon EC2 实例上托管应用程序。该应用程序可以通过使用开放系统互连 (OSI) 模型的传输层进行访问。该公司需要应用程序架构具有高可用性。哪种步骤组合将以最具成本效益的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在不同的可用区中配置新的 EC2 实例。使用 Amazon Route 53 将流量路由到所有实例。",
      "B": "在 EC2 实例前面配置一个 Network Load Balancer。",
      "C": "为 TCP 流量配置一个 Network Load Balancer。为 HTTP 和 HTTPS 流量配置一个 Application Load Balancer。",
      "D": "为 EC2 实例创建一个 Auto Scaling 组。将 Auto Scaling 组配置为使用多个可用区。将 Auto Scaling 组配置为在实例上运行应用程序运行状况检查。",
      "E": "创建一个 Amazon CloudWatch 告警。将告警配置为重新启动转换为停止状态的 EC2 实例。"
    }
  },
  {
    "id": 877,
    "topic": "1",
    "question_en": "A company uses Amazon S3 to host its static website. The company wants to add a contact form to the webpage. The contact form will have dynamic server-side components for users to input their name, email address, phone number, and user message. The company expects fewer than 100 site visits each month. The contact form must notify the company by email when a customer fills out the form. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Host the dynamic contact form in Amazon Elastic Container Service (Amazon ECS). Set up Amazon Simple Email Service (Amazon SES) to connect to a third-party email provider.",
      "B": "Create an Amazon API Gateway endpoint that returns the contact form from an AWS Lambda function. Configure another Lambda function on the API Gateway to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.",
      "C": "Host the website by using AWS Amplify Hosting for static content and dynamic content. Use server-side scripting to build the contact form. Configure Amazon Simple Queue Service (Amazon SQS) to deliver the message to the company.",
      "D": "Migrate the website from Amazon S3 to Amazon EC2 instances that run Windows Server. Use Internet Information Services (IIS) for Windows Server to host the webpage. Use client-side scripting to build the contact form. Integrate the form with Amazon WorkMail."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Amazon S3 托管其静态网站。该公司希望向网页添加一个联系表单。联系表单将具有动态服务器端组件，供用户输入他们的姓名、电子邮件地址、电话号码和用户消息。该公司预计每月访问量少于 100 次。当客户填写表单时，联系表单必须通过电子邮件通知该公司。哪种解决方案最经济高效地满足这些要求？",
    "options_cn": {
      "A": "在 Amazon Elastic Container Service (Amazon ECS) 中托管动态联系表单。设置 Amazon Simple Email Service (Amazon SES) 以连接到第三方电子邮件提供商。",
      "B": "创建一个 Amazon API Gateway 端点，该端点从 AWS Lambda 函数返回联系表单。在 API Gateway 上配置另一个 Lambda 函数，以将消息发布到 Amazon Simple Notification Service (Amazon SNS) 主题。",
      "C": "使用 AWS Amplify Hosting 托管静态内容和动态内容的网站。使用服务器端脚本构建联系表单。配置 Amazon Simple Queue Service (Amazon SQS) 将消息传递给公司。",
      "D": "将网站从 Amazon S3 迁移到运行 Windows Server 的 Amazon EC2 实例。使用 Internet Information Services (IIS) for Windows Server 托管网页。使用客户端脚本构建联系表单。将表单与 Amazon WorkMail 集成。"
    }
  },
  {
    "id": 878,
    "topic": "1",
    "question_en": "A company creates dedicated AWS accounts in AWS Organizations for its business units. Recently, an important notification was sent to the root user email address of a business unit account instead of the assigned account owner. The company wants to ensure that all future notifications can be sent to different employees based on the notification categories of billing, operations, or security. Which solution will meet these requirements MOST securely?",
    "options_en": {
      "A": "Configure each AWS account to use a single email address that the company manages. Ensure that all account owners can access the email account to receive notifications. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
      "B": "Configure each AWS account to use a different email distribution list for each business unit that the company manages. Configure each distribution list with administrator email addresses that can respond to alerts. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
      "C": "Configure each AWS account root user email address to be the individual company managed email address of one person from each business unit. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.",
      "D": "Configure each AWS account root user to use email aliases that go to a centralized mailbox. Configure alternate contacts for each account by using a single business managed email distribution list each for the billing team, the security team, and the operations team."
    },
    "correct_answer": "B",
    "vote_percentage": "54%",
    "question_cn": "一家公司在 AWS Organizations 中为其业务部门创建了专用的 AWS 账户。最近，一条重要通知被发送到了某个业务部门账户的根用户电子邮件地址，而不是指定的账户所有者。该公司希望确保所有未来的通知可以根据账单、运营或安全通知类别发送给不同的员工。哪种解决方案将最安全地满足这些要求？",
    "options_cn": {
      "A": "将每个 AWS 账户配置为使用公司管理的单个电子邮件地址。确保所有账户所有者都可以访问该电子邮件账户以接收通知。为每个 AWS 账户配置备用联系人，并为每个业务部门配置相应的账单团队、安全团队和运营团队的通讯组列表。",
      "B": "将每个 AWS 账户配置为使用公司管理的每个业务部门的不同电子邮件通讯组列表。为每个通讯组列表配置可以响应警报的管理员电子邮件地址。为每个 AWS 账户配置备用联系人，并为每个业务部门配置相应的账单团队、安全团队和运营团队的通讯组列表。",
      "C": "将每个 AWS 账户的根用户电子邮件地址配置为来自每个业务部门的一个人的个人公司管理的电子邮件地址。为每个 AWS 账户配置备用联系人，并为每个业务部门配置相应的账单团队、安全团队和运营团队的通讯组列表。",
      "D": "配置每个 AWS 账户根用户使用指向集中邮箱的电子邮件别名。通过为每个账户使用一个业务管理的电子邮件通讯组列表（分别用于账单团队、安全团队和运营团队）来配置备用联系人。"
    }
  },
  {
    "id": 879,
    "topic": "1",
    "question_en": "A company runs an ecommerce application on AWS. Amazon EC2 instances process purchases and store the purchase details in an Amazon Aurora PostgreSQL DB cluster. Customers are experiencing application timeouts during times of peak usage. A solutions architect needs to rearchitect the application so that the application can scale to meet peak usage demands. Which combination of actions will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Configure an Auto Scaling group of new EC2 instances to retry the purchases until the processing is complete. Update the applications to connect to the DB cluster by using Amazon RDS Proxy.",
      "B": "Configure the application to use an Amazon ElastiCache cluster in front of the Aurora PostgreSQL DB cluster.",
      "C": "Update the application to send the purchase requests to an Amazon Simple Queue Service (Amazon SQS) queue. Configure an Auto Scaling group of new EC2 instances that read from the SQS queue.",
      "D": "Configure an AWS Lambda function to retry the ticket purchases until the processing is complet",
      "E": "E. Configure an Amazon AP! Gateway REST API with a usage plan."
    },
    "correct_answer": "A",
    "vote_percentage": "80%",
    "question_cn": "一家公司在 AWS 上运行电子商务应用程序。Amazon EC2 实例处理购买并将其详细信息存储在 Amazon Aurora PostgreSQL 数据库集群中。客户在高峰使用期间遇到应用程序超时问题。解决方案架构师需要重新设计应用程序，以便应用程序可以扩展以满足高峰使用需求。哪两种操作的组合将以最具成本效益的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "配置新的 EC2 实例的 Auto Scaling 组，以重试购买，直到处理完成。更新应用程序以使用 Amazon RDS Proxy 连接到数据库集群。",
      "B": "配置应用程序以在 Aurora PostgreSQL 数据库集群前面使用 Amazon ElastiCache 集群。",
      "C": "更新应用程序以将购买请求发送到 Amazon Simple Queue Service (Amazon SQS) 队列。配置从 SQS 队列读取的新 EC2 实例的 Auto Scaling 组。",
      "D": "配置一个 AWS Lambda 函数以重试门票购买，直到处理完成。",
      "E": "配置带有使用计划的 Amazon API 网关 REST API。"
    }
  },
  {
    "id": 880,
    "topic": "1",
    "question_en": "A company that uses AWS Organizations runs 150 applications across 30 different AWS accounts. The company used AWS Cost and Usage Report to create a new report in the management account. The report is delivered to an Amazon S3 bucket that is replicated to a bucket in the data collection account. The company’s senior leadership wants to view a custom dashboard that provides NAT gateway costs each day starting at the beginning of the current month. Which solution will meet these requirements?",
    "options_en": {
      "A": "Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use AWS DataSync to query the new report.",
      "B": "Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use Amazon Athena to query the new report.",
      "C": "Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use AWS DataSync to query the new report.",
      "D": "Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use Amazon Athena to query the new report."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家使用 AWS Organizations 的公司在 30 个不同的 AWS 账户上运行 150 个应用程序。该公司使用 AWS Cost and Usage Report 在管理账户中创建了一个新报告。该报告被交付到一个 Amazon S3 存储桶，该存储桶被复制到数据收集账户中的一个存储桶。公司的高级管理层希望查看一个自定义仪表板，该仪表板每天提供 NAT gateway 的成本，从当月月初开始。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "共享一个包含所需表格视图的 Amazon QuickSight 仪表板。配置 QuickSight 使用 AWS DataSync 来查询新报告。",
      "B": "共享一个包含所需表格视图的 Amazon QuickSight 仪表板。配置 QuickSight 使用 Amazon Athena 来查询新报告。",
      "C": "共享一个包含所需表格视图的 Amazon CloudWatch 仪表板。配置 CloudWatch 使用 AWS DataSync 来查询新报告。",
      "D": "共享一个包含所需表格视图的 Amazon CloudWatch 仪表板。配置 CloudWatch 使用 Amazon Athena 来查询新报告。"
    }
  },
  {
    "id": 881,
    "topic": "1",
    "question_en": "A company is hosting a high-trafic static website on Amazon S3 with an Amazon CloudFront distribution that has a default TTL of 0 seconds. The company wants to implement caching to improve performance for the website. However, the company also wants to ensure that stale content is not served for more than a few minutes after a deployment. Which combination of caching methods should a solutions architect implement to meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Set the CloudFront default TTL to 2 minutes.",
      "B": "Set a default TTL of 2 minutes on the S3 bucket.",
      "C": "Add a Cache-Control private directive to the objects in Amazon S3.",
      "D": "Create an AWS Lambda@Edge function to add an Expires header to HTTP responses. Configure the function to run on viewer respons",
      "E": "E. Add a Cache-Control max-age directive of 24 hours to the objects in Amazon S3. On deployment, create a CloudFront invalidation to clear any changed files from edge caches."
    },
    "correct_answer": "A",
    "vote_percentage": "47%",
    "question_cn": "一家公司正在 Amazon S3 上托管一个高流量静态网站，该网站使用 Amazon CloudFront 分发，其默认 TTL 为 0 秒。该公司希望实现缓存以提高网站的性能。但是，该公司还希望确保在部署后几分钟内不会提供过时内容。解决方案架构师应该实施哪种缓存方法的组合来满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "将 CloudFront 默认 TTL 设置为 2 分钟。",
      "B": "在 S3 存储桶上设置 2 分钟的默认 TTL。",
      "C": "将 Cache-Control private 指令添加到 Amazon S3 中的对象。",
      "D": "创建一个 AWS Lambda@Edge 函数，以将 Expires 标头添加到 HTTP 响应中。将该函数配置为在查看器响应时运行。",
      "E": "将 Cache-Control max-age 指令设置为 Amazon S3 中对象的 24 小时。在部署时，创建一个 CloudFront 无效化，以从边缘缓存中清除任何已更改的文件。"
    }
  },
  {
    "id": 882,
    "topic": "1",
    "question_en": "A company runs its application by using Amazon EC2 instances and AWS Lambda functions. The EC2 instances run in private subnets of a VPC. The Lambda functions need direct network access to the EC2 instances for the application to work. The application will run for 1 year. The number of Lambda functions that the application uses will increase during the 1-year period. The company must minimize costs on all application resources. Which solution will meet these requirements?",
    "options_en": {
      "A": "Purchase an EC2 Instance Savings Plan. Connect the Lambda functions to the private subnets that contain the EC2 instances.",
      "B": "Purchase an EC2 Instance Savings Plan. Connect the Lambda functions to new public subnets in the same VPC where the EC2 instances run.",
      "C": "Purchase a Compute Savings Plan. Connect the Lambda functions to the private subnets that contain the EC2 instances.",
      "D": "Purchase a Compute Savings Plan. Keep the Lambda functions in the Lambda service VPC."
    },
    "correct_answer": "C",
    "vote_percentage": "63%",
    "question_cn": "一家公司使用 Amazon EC2 实例和 AWS Lambda 函数运行其应用程序。EC2 实例在 VPC 的私有子网中运行。Lambda 函数需要直接网络访问 EC2 实例才能使应用程序工作。该应用程序将运行 1 年。应用程序使用的 Lambda 函数数量将在 1 年期间增加。公司必须最大限度地减少所有应用程序资源的成本。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "购买 EC2 实例储蓄计划。将 Lambda 函数连接到包含 EC2 实例的私有子网。",
      "B": "购买 EC2 实例储蓄计划。将 Lambda 函数连接到与 EC2 实例运行在同一 VPC 中的新公共子网。",
      "C": "购买计算储蓄计划。将 Lambda 函数连接到包含 EC2 实例的私有子网。",
      "D": "购买计算储蓄计划。将 Lambda 函数保留在 Lambda 服务 VPC 中。"
    }
  },
  {
    "id": 883,
    "topic": "1",
    "question_en": "A company has deployed a multi-account strategy on AWS by using AWS Control Tower. The company has provided individual AWS accounts to each of its developers. The company wants to implement controls to limit AWS resource costs that the developers incur. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Instruct each developer to tag all their resources with a tag that has a key of CostCenter and a value of the developer's name. Use the required-tags AWS Config managed rule to check for the tag. Create an AWS Lambda function to terminate resources that do not have the tag. Configure AWS Cost Explorer to send a daily report to each developer to monitor their spending.",
      "B": "Use AWS Budgets to establish budgets for each developer account. Set up budget alerts for actual and forecast values to notify developers when they exceed or expect to exceed their assigned budget. Use AWS Budgets actions to apply a DenyAll policy to the developer's IAM role to prevent additional resources from being launched when the assigned budget is reached.",
      "C": "Use AWS Cost Explorer to monitor and report on costs for each developer account. Configure Cost Explorer to send a daily report to each developer to monitor their spending. Use AWS Cost Anomaly Detection to detect anomalous spending and provide alerts.",
      "D": "Use AWS Service Catalog to allow developers to launch resources within a limited cost range. Create AWS Lambda functions in each AWS account to stop running resources at the end of each work day. Configure the Lambda functions to resume the resources at the start of each work day."
    },
    "correct_answer": "B",
    "vote_percentage": "75%",
    "question_cn": "一家公司通过使用 AWS Control Tower 在 AWS 上部署了多账户策略。该公司已为其每个开发人员提供了单独的 AWS 账户。该公司希望实施控制措施来限制开发人员产生的 AWS 资源成本。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "指示每个开发人员使用一个名为 CostCenter 的标签标记其所有资源，其值为开发人员的姓名。使用 required-tags AWS Config 托管规则来检查该标签。创建一个 AWS Lambda 函数以终止没有该标签的资源。配置 AWS Cost Explorer 每天向每个开发人员发送一份报告，以监控他们的支出。",
      "B": "使用 AWS Budgets 为每个开发人员账户建立预算。设置预算警报，用于实际值和预测值，以便在开发人员超出或预计超出其分配的预算时通知他们。使用 AWS Budgets 操作将 DenyAll 策略应用于开发人员的 IAM 角色，以防止在达到分配的预算时启动其他资源。",
      "C": "使用 AWS Cost Explorer 监控和报告每个开发人员账户的成本。配置 Cost Explorer 每天向每个开发人员发送一份报告，以监控他们的支出。使用 AWS Cost Anomaly Detection 检测异常支出并提供警报。",
      "D": "使用 AWS Service Catalog 允许开发人员在有限的成本范围内启动资源。在每个 AWS 账户中创建 AWS Lambda 函数，以在每个工作日结束时停止运行的资源。配置 Lambda 函数以在每个工作日开始时恢复资源。"
    }
  },
  {
    "id": 884,
    "topic": "1",
    "question_en": "A solutions architect is designing a three-tier web application. The architecture consists of an internet-facing Application Load Balancer (ALB) and a web tier that is hosted on Amazon EC2 instances in private subnets. The application tier with the business logic runs on EC2 instances in private subnets. The database tier consists of Microsoft SQL Server that runs on EC2 instances in private subnets. Security is a high priority for the company. Which combination of security group configurations should the solutions architect use? (Choose three.)",
    "options_en": {
      "A": "Configure the security group for the web tier to allow inbound HTTPS trafic from the security group for the ALB.",
      "B": "Configure the security group for the web tier to allow outbound HTTPS trafic to 0.0.0.0/0.",
      "C": "Configure the security group for the database tier to allow inbound Microsoft SQL Server trafic from the security group for the application tier.",
      "D": "Configure the security group for the database tier to allow outbound HTTPS trafic and Microsoft SQL Server trafic to the security group for the web tier",
      "E": "Configure the security group for the application tier to allow inbound HTTPS trafic from the security group for the web tier",
      "F": "Configure the security group for the application tier to allow outbound HTTPS trafic and Microsoft SQL Server trafic to the security group for the web tier."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一个解决方案架构师正在设计一个三层 Web 应用程序。该架构由一个面向互联网的 Application Load Balancer (ALB) 和一个托管在私有子网中的 Amazon EC2 实例上的 Web 层组成。带有业务逻辑的应用程序层在私有子网中的 EC2 实例上运行。数据库层由在私有子网中的 EC2 实例上运行的 Microsoft SQL Server 组成。安全性是该公司的高度优先事项。解决方案架构师应该使用哪种安全组配置组合？（选择三个。）",
    "options_cn": {
      "A": "将 Web 层的安全组配置为允许来自 ALB 安全组的入站 HTTPS 流量。",
      "B": "将 Web 层的安全组配置为允许到 0.0.0.0/0 的出站 HTTPS 流量。",
      "C": "将数据库层的安全组配置为允许来自应用程序层安全组的入站 Microsoft SQL Server 流量。",
      "D": "将数据库层的安全组配置为允许到 Web 层安全组的出站 HTTPS 流量和 Microsoft SQL Server 流量。",
      "E": "将应用程序层的安全组配置为允许来自 Web 层安全组的入站 HTTPS 流量。",
      "F": "将应用程序层的安全组配置为允许到 Web 层安全组的出站 HTTPS 流量和 Microsoft SQL Server 流量。"
    }
  },
  {
    "id": 885,
    "topic": "1",
    "question_en": "A company has released a new version of its production application. The company's workload uses Amazon EC2, AWS Lambda, AWS Fargate, and Amazon SageMaker. The company wants to cost optimize the workload now that usage is at a steady state. The company wants to cover the most services with the fewest savings plans. Which combination of savings plans will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Purchase an EC2 Instance Savings Plan for Amazon EC2 and SageMaker.",
      "B": "Purchase a Compute Savings Plan for Amazon EC2, Lambda, and SageMaker.",
      "C": "Purchase a SageMaker Savings Plan.",
      "D": "Purchase a Compute Savings Plan for Lambda, Fargate, and Amazon EC2",
      "E": "Purchase an EC2 Instance Savings Plan for Amazon EC2 and Fargate."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司发布了其生产应用程序的新版本。该公司的负载使用 Amazon EC2、AWS Lambda、AWS Fargate 和 Amazon SageMaker。该公司希望在用量达到稳定状态后对工作负载进行成本优化。该公司希望用最少的节省计划涵盖最多的服务。哪种节省计划组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "为 Amazon EC2 和 SageMaker 购买 EC2 实例节省计划。",
      "B": "为 Amazon EC2、Lambda 和 SageMaker 购买计算节省计划。",
      "C": "购买 SageMaker 节省计划。",
      "D": "为 Lambda、Fargate 和 Amazon EC2 购买计算节省计划。",
      "E": "为 Amazon EC2 和 Fargate 购买 EC2 实例节省计划。"
    }
  },
  {
    "id": 886,
    "topic": "1",
    "question_en": "A company uses a Microsoft SQL Server database. The company's applications are connected to the database. The company wants to migrate to an Amazon Aurora PostgreSQL database with minimal changes to the application code. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications.",
      "B": "Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications.",
      "C": "Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS).",
      "D": "Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL",
      "E": "Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司使用 Microsoft SQL Server 数据库。该公司的应用程序连接到该数据库。该公司希望以最少的应用程序代码更改迁移到 Amazon Aurora PostgreSQL 数据库。哪些步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Schema Conversion Tool (AWS SCT) 重写应用程序中的 SQL 查询。",
      "B": "在 Aurora PostgreSQL 上启用 Babelfish 以运行来自应用程序的 SQL 查询。",
      "C": "使用 AWS Schema Conversion Tool (AWS SCT) 和 AWS Database Migration Service (AWS DMS) 迁移数据库模式和数据。",
      "D": "使用 Amazon RDS Proxy 将应用程序连接到 Aurora PostgreSQL。",
      "E": "使用 AWS Database Migration Service (AWS DMS) 重写应用程序中的 SQL 查询。"
    }
  },
  {
    "id": 887,
    "topic": "1",
    "question_en": "A company plans to rehost an application to Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) as the attached storage. A solutions architect must design a solution to ensure that all newly created Amazon EBS volumes are encrypted by default. The solution must also prevent the creation of unencrypted EBS volumes. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the EC2 account attributes to always encrypt new EBS volumes.",
      "B": "Use AWS Config. Configure the encrypted-volumes identifier. Apply the default AWS Key Management Service (AWS KMS) key.",
      "C": "Configure AWS Systems Manager to create encrypted copies of the EBS volumes. Reconfigure the EC2 instances to use the encrypted volumes.",
      "D": "Create a customer managed key in AWS Key Management Service (AWS KMS). Configure AWS Migration Hub to use the key when the company migrates workloads."
    },
    "correct_answer": "A",
    "vote_percentage": "67%",
    "question_cn": "一家公司计划将应用程序重新托管到使用 Amazon Elastic Block Store (Amazon EBS) 作为附加存储的 Amazon EC2 实例。一位解决方案架构师必须设计一个解决方案，以确保所有新创建的 Amazon EBS 卷都默认加密。该解决方案还必须防止创建未加密的 EBS 卷。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 EC2 账户属性以始终加密新的 EBS 卷。",
      "B": "使用 AWS Config。配置 encrypted-volumes 标识符。应用默认的 AWS Key Management Service (AWS KMS) 密钥。",
      "C": "配置 AWS Systems Manager 以创建 EBS 卷的加密副本。重新配置 EC2 实例以使用加密卷。",
      "D": "在 AWS Key Management Service (AWS KMS) 中创建客户托管密钥。配置 AWS Migration Hub 在公司迁移工作负载时使用该密钥。"
    }
  },
  {
    "id": 888,
    "topic": "1",
    "question_en": "An ecommerce company wants to collect user clickstream data from the company's website for real-time analysis. The website experiences fiuctuating trafic patterns throughout the day. The company needs a scalable solution that can adapt to varying levels of trafic. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use a data stream in Amazon Kinesis Data Streams in on-demand mode to capture the clickstream data. Use AWS Lambda to process the data in real time.",
      "B": "Use Amazon Kinesis Data Firehose to capture the clickstream data. Use AWS Glue to process the data in real time.",
      "C": "Use Amazon Kinesis Video Streams to capture the clickstream data. Use AWS Glue to process the data in real time.",
      "D": "Use Amazon Managed Service for Apache Flink (previously known as Amazon Kinesis Data Analytics) to capture the clickstream data. Use AWS Lambda to process the data in real time."
    },
    "correct_answer": "A",
    "vote_percentage": "88%",
    "question_cn": "一家电子商务公司希望从该公司的网站收集用户点击流数据，以进行实时分析。该网站在一天中会经历波动的流量模式。该公司需要一个可扩展的解决方案，该解决方案可以适应不同级别的流量。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Kinesis Data Streams 中的数据流以按需模式捕获点击流数据。使用 AWS Lambda 实时处理数据。",
      "B": "使用 Amazon Kinesis Data Firehose 捕获点击流数据。使用 AWS Glue 实时处理数据。",
      "C": "使用 Amazon Kinesis Video Streams 捕获点击流数据。使用 AWS Glue 实时处理数据。",
      "D": "使用 Amazon Managed Service for Apache Flink（以前称为 Amazon Kinesis Data Analytics）来捕获点击流数据。使用 AWS Lambda 实时处理数据。"
    }
  },
  {
    "id": 889,
    "topic": "1",
    "question_en": "A global company runs its workloads on AWS. The company's application uses Amazon S3 buckets across AWS Regions for sensitive data storage and analysis. The company stores millions of objects in multiple S3 buckets daily. The company wants to identify all S3 buckets that are not versioning-enabled. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up an AWS CloudTrail event that has a rule to identify all S3 buckets that are not versioning-enabled across Regions.",
      "B": "Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.",
      "C": "Enable IAM Access Analyzer for S3 to identify all S3 buckets that are not versioning-enabled across Regions.",
      "D": "Create an S3 Multi-Region Access Point to identify all S3 buckets that are not versioning-enabled across Regions."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家全球性公司在 AWS 上运行其工作负载。该公司的应用程序使用 Amazon S3 存储桶在不同的 AWS 区域中存储和分析敏感数据。该公司每天在多个 S3 存储桶中存储数百万个对象。该公司希望识别所有未启用版本控制的 S3 存储桶。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置一个 AWS CloudTrail 事件，该事件有一个规则来识别跨区域的所有未启用版本控制的 S3 存储桶。",
      "B": "使用 Amazon S3 Storage Lens 来识别跨区域的所有未启用版本控制的 S3 存储桶。",
      "C": "为 S3 启用 IAM Access Analyzer 以识别跨区域的所有未启用版本控制的 S3 存储桶。",
      "D": "创建一个 S3 多区域访问点来识别所有未启用版本控制的 S3 存储桶。"
    }
  },
  {
    "id": 890,
    "topic": "1",
    "question_en": "A company needs to optimize its Amazon S3 storage costs for an application that generates many files that cannot be recreated. Each file is approximately 5 MB and is stored in Amazon S3 Standard storage. The company must store the files for 4 years before the files can be deleted. The files must be immediately accessible. The files are frequently accessed in the first 30 days of object creation, but they are rarely accessed after the first 30 days. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an S3 Lifecycle policy to move the files to S3 Glacier Instant Retrieval 30 days after object creation. Delete the files 4 years after object creation.",
      "B": "Create an S3 Lifecycle policy to move the files to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days after object creation. Delete the files 4 years after object creation.",
      "C": "Create an S3 Lifecycle policy to move the files to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days after object creation. Delete the files 4 years after object creation.",
      "D": "Create an S3 Lifecycle policy to move the files to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days after object creation. Move the files to S3 Glacier Flexible Retrieval 4 years after object creation."
    },
    "correct_answer": "D",
    "vote_percentage": "50%",
    "question_cn": "一家公司需要优化其 Amazon S3 存储成本，该应用程序生成大量无法重新创建的文件。每个文件大约为 5 MB，存储在 Amazon S3 Standard 存储中。该公司必须将文件存储 4 年才能删除这些文件。必须立即访问这些文件。这些文件在对象创建后的前 30 天内经常被访问，但在前 30 天后很少被访问。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "创建一个 S3 生命周期策略，在对象创建 30 天后将文件移动到 S3 Glacier Instant Retrieval。在对象创建 4 年后删除这些文件。",
      "B": "创建一个 S3 生命周期策略，在对象创建 30 天后将文件移动到 S3 One Zone-Infrequent Access (S3 One Zone-IA)。在对象创建 4 年后删除这些文件。",
      "C": "创建一个 S3 生命周期策略，在对象创建 30 天后将文件移动到 S3 Standard-Infrequent Access (S3 Standard-IA)。在对象创建 4 年后删除这些文件。",
      "D": "创建一个 S3 生命周期策略，在对象创建 30 天后将文件移动到 S3 Standard-Infrequent Access (S3 Standard-IA)。在对象创建 4 年后将文件移动到 S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 891,
    "topic": "1",
    "question_en": "A company runs its critical storage application in the AWS Cloud. The application uses Amazon S3 in two AWS Regions. The company wants the application to send remote user data to the nearest S3 bucket with no public network congestion. The company also wants the application to fail over with the least amount of management of Amazon S3. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement an active-active design between the two Regions. Configure the application to use the regional S3 endpoints closest to the user.",
      "B": "Use an active-passive configuration with S3 Multi-Region Access Points. Create a global endpoint for each of the Regions.",
      "C": "Send user data to the regional S3 endpoints closest to the user. Configure an S3 cross-account replication rule to keep the S3 buckets synchronized.",
      "D": "Set up Amazon S3 to use Multi-Region Access Points in an active-active configuration with a single global endpoint. Configure S3 Cross- Region Replication."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 云中运行其关键存储应用程序。该应用程序在两个 AWS 区域中使用 Amazon S3。公司希望应用程序将远程用户数据发送到最近的 S3 存储桶，而不会出现公共网络拥塞。公司还希望该应用程序以最少的 Amazon S3 管理方式进行故障转移。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在两个区域之间实施主动-主动设计。配置应用程序以使用最靠近用户的区域 S3 终端节点。",
      "B": "使用带有 S3 多区域访问点的活动-被动配置。为每个区域创建一个全局终端节点。",
      "C": "将用户数据发送到最靠近用户的区域 S3 终端节点。配置 S3 跨区域复制规则以保持 S3 存储桶同步。",
      "D": "设置 Amazon S3 以使用多区域访问点，采用主动-主动配置，使用单个全局终端节点。配置 S3 跨区域复制。"
    }
  },
  {
    "id": 892,
    "topic": "1",
    "question_en": "A company is migrating a data center from its on-premises location to AWS. The company has several legacy applications that are hosted on individual virtual servers. Changes to the application designs cannot be made. Each individual virtual server currently runs as its own EC2 instance. A solutions architect needs to ensure that the applications are reliable and fault tolerant after migration to AWS. The applications will run on Amazon EC2 instances. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Auto Scaling group that has a minimum of one and a maximum of one. Create an Amazon Machine Image (AMI) of each application instance. Use the AMI to create EC2 instances in the Auto Scaling group Configure an Application Load Balancer in front of the Auto Scaling group.",
      "B": "Use AWS Backup to create an hourly backup of the EC2 instance that hosts each application. Store the backup in Amazon S3 in a separate Availability Zone. Configure a disaster recovery process to restore the EC2 instance for each application from its most recent backup.",
      "C": "Create an Amazon Machine Image (AMI) of each application instance. Launch two new EC2 instances from the AMI. Place each EC2 instance in a separate Availability Zone. Configure a Network Load Balancer that has the EC2 instances as targets.",
      "D": "Use AWS Mitigation Hub Refactor Spaces to migrate each application off the EC2 instance. Break down functionality from each application into individual components. Host each application on Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type."
    },
    "correct_answer": "C",
    "vote_percentage": "50%",
    "question_cn": "一家公司正在将其数据中心从本地位置迁移到 AWS。该公司有几个托管在独立虚拟服务器上的旧版应用程序。无法对应用程序设计进行更改。每个独立的虚拟服务器当前都作为其自己的 EC2 实例运行。解决方案架构师需要确保在迁移到 AWS 后，应用程序具有可靠性和容错性。应用程序将在 Amazon EC2 实例上运行。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Auto Scaling 组，该组的最小值为 1，最大值为 1。创建每个应用程序实例的 Amazon Machine Image (AMI)。使用 AMI 在 Auto Scaling 组中创建 EC2 实例。在 Auto Scaling 组的前面配置一个 Application Load Balancer。",
      "B": "使用 AWS Backup 为托管每个应用程序的 EC2 实例创建每小时备份。将备份存储在不同可用区的 Amazon S3 中。配置灾难恢复流程，以从其最近的备份中恢复每个应用程序的 EC2 实例。",
      "C": "创建每个应用程序实例的 Amazon Machine Image (AMI)。从 AMI 启动两个新的 EC2 实例。将每个 EC2 实例放置在不同的可用区中。配置一个 Network Load Balancer，该负载均衡器将 EC2 实例作为目标。",
      "D": "使用 AWS Mitigation Hub Refactor Spaces 从 EC2 实例中迁移每个应用程序。将每个应用程序的功能分解为各个组件。将每个应用程序托管在 Amazon Elastic Container Service (Amazon ECS) 上，并使用 AWS Fargate 启动类型。"
    }
  },
  {
    "id": 893,
    "topic": "1",
    "question_en": "A company wants to isolate its workloads by creating an AWS account for each workload. The company needs a solution that centrally manages networking components for the workloads. The solution also must create accounts with automatic security controls (guardrails). Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS Control Tower to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts.",
      "B": "Use AWS Organizations to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts.",
      "C": "Use AWS Control Tower to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment.",
      "D": "Use AWS Organizations to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment."
    },
    "correct_answer": "A",
    "vote_percentage": "67%",
    "question_cn": "一家公司希望通过为每个工作负载创建 AWS 账户来隔离其工作负载。该公司需要一个解决方案来集中管理工作负载的网络组件。该解决方案还必须创建具有自动安全控制（护栏）的账户。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Control Tower 部署账户。创建一个网络账户，该账户有一个带有私有子网和公有子网的 VPC。使用 AWS Resource Access Manager (AWS RAM) 与工作负载账户共享子网。",
      "B": "使用 AWS Organizations 部署账户。创建一个网络账户，该账户有一个带有私有子网和公有子网的 VPC。使用 AWS Resource Access Manager (AWS RAM) 与工作负载账户共享子网。",
      "C": "使用 AWS Control Tower 部署账户。在每个工作负载账户中部署一个 VPC。配置每个 VPC，通过使用转接网关附件路由到检查 VPC。",
      "D": "使用 AWS Organizations 部署账户。在每个工作负载账户中部署一个 VPC。配置每个 VPC，通过使用转接网关附件路由到检查 VPC。"
    }
  },
  {
    "id": 894,
    "topic": "1",
    "question_en": "A company hosts a website on Amazon EC2 instances behind an Application Load Balancer (ALB). The website serves static content. Website trafic is increasing. The company wants to minimize the website hosting costs. Which solution will meet these requirements?",
    "options_en": {
      "A": "Move the website to an Amazon S3 bucket. Configure an Amazon CloudFront distribution for the S3 bucket.",
      "B": "Move the website to an Amazon S3 bucket. Configure an Amazon ElastiCache cluster for the S3 bucket.",
      "C": "Move the website to AWS Amplify. Configure an ALB to resolve to the Amplify website.",
      "D": "Move the website to AWS Amplify. Configure EC2 instances to cache the website."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司在其Application Load Balancer (ALB) 之后，在Amazon EC2实例上托管一个网站。该网站提供静态内容。网站流量正在增加。该公司希望最大限度地减少网站托管成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将网站迁移到Amazon S3 存储桶。为S3 存储桶配置Amazon CloudFront 分发。",
      "B": "将网站迁移到Amazon S3 存储桶。为S3 存储桶配置Amazon ElastiCache 集群。",
      "C": "将网站迁移到AWS Amplify。配置ALB以解析到Amplify网站。",
      "D": "将网站迁移到AWS Amplify。配置EC2实例来缓存网站。"
    }
  },
  {
    "id": 895,
    "topic": "1",
    "question_en": "A company is implementing a shared storage solution for a media application that the company hosts on AWS. The company needs the ability to use SMB clients to access stored data. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Create an AWS Storage Gateway Volume Gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.",
      "B": "Create an AWS Storage Gateway Tape Gateway. Configure tapes to use Amazon S3. Connect the application server to the Tape Gateway.",
      "C": "Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.",
      "D": "Create an Amazon FSx for Windows File Server file system. Connect the application server to the file system."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为其在 AWS 上托管的媒体应用程序实施共享存储解决方案。该公司需要使用 SMB 客户端访问存储数据的能力。哪种解决方案以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "创建 AWS Storage Gateway Volume Gateway。创建一个使用所需客户端协议的文件共享。将应用程序服务器连接到文件共享。",
      "B": "创建 AWS Storage Gateway Tape Gateway。配置磁带以使用 Amazon S3。将应用程序服务器连接到 Tape Gateway。",
      "C": "创建 Amazon EC2 Windows 实例。在该实例上安装并配置 Windows 文件共享角色。将应用程序服务器连接到文件共享。",
      "D": "创建 Amazon FSx for Windows File Server 文件系统。将应用程序服务器连接到文件系统。"
    }
  },
  {
    "id": 896,
    "topic": "1",
    "question_en": "A company is designing its production application's disaster recovery (DR) strategy. The application is backed by a MySQL database on an Amazon Aurora cluster in the us-east-1 Region. The company has chosen the us-west-1 Region as its DR Region. The company's target recovery point objective (RPO) is 5 minutes and the target recovery time objective (RTO) is 20 minutes. The company wants to minimize configuration changes. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create an Aurora read replica in us-west-1 similar in size to the production application's Aurora MySQL cluster writer instance.",
      "B": "Convert the Aurora cluster to an Aurora global database. Configure managed failover.",
      "C": "Create a new Aurora cluster in us-west-1 that has Cross-Region Replication.",
      "D": "Create a new Aurora cluster in us-west-1. Use AWS Database Migration Service (AWS DMS) to sync both clusters."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在为其生产应用程序设计灾难恢复 (DR) 策略。该应用程序由 us-east-1 区域中 Amazon Aurora 集群上的 MySQL 数据库提供支持。该公司已选择 us-west-1 区域作为其 DR 区域。该公司的目标恢复点目标 (RPO) 为 5 分钟，目标恢复时间目标 (RTO) 为 20 分钟。该公司希望尽量减少配置更改。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "在 us-west-1 中创建一个 Aurora 只读副本，其大小与生产应用程序的 Aurora MySQL 集群写入器实例相似。",
      "B": "将 Aurora 集群转换为 Aurora 全局数据库。配置托管故障转移。",
      "C": "在 us-west-1 中创建一个新的 Aurora 集群，该集群具有跨区域复制。",
      "D": "在 us-west-1 中创建一个新的 Aurora 集群。使用 AWS Database Migration Service (AWS DMS) 同步这两个集群。"
    }
  },
  {
    "id": 897,
    "topic": "1",
    "question_en": "A company runs a critical data analysis job each week before the first day of the work week. The job requires at least 1 hour to complete the analysis. The job is stateful and cannot tolerate interruptions. The company needs a solution to run the job on AWS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a container for the job. Schedule the job to run as an AWS Fargate task on an Amazon Elastic Container Service (Amazon ECS) cluster by using Amazon EventBridge Scheduler.",
      "B": "Configure the job to run in an AWS Lambda function. Create a scheduled rule in Amazon EventBridge to invoke the Lambda function.",
      "C": "Configure an Auto Scaling group of Amazon EC2 Spot Instances that run Amazon Linux. Configure a crontab entry on the instances to run the analysis.",
      "D": "Configure an AWS DataSync task to run the job. Configure a cron expression to run the task on a schedule."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司在每周工作日开始前运行一项关键的数据分析工作。该工作需要至少 1 小时才能完成分析。该工作是有状态的，并且不能容忍中断。该公司需要在 AWS 上运行该工作的解决方案。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为该工作创建一个容器。使用 Amazon EventBridge Scheduler，将该工作安排为在 Amazon Elastic Container Service (Amazon ECS) 集群上的 AWS Fargate 任务运行。",
      "B": "配置该工作在 AWS Lambda 函数中运行。在 Amazon EventBridge 中创建一个计划规则来调用 Lambda 函数。",
      "C": "配置一个运行 Amazon Linux 的 Amazon EC2 Spot 实例的 Auto Scaling 组。在实例上配置一个 crontab 条目以运行分析。",
      "D": "配置一个 AWS DataSync 任务来运行该工作。配置一个 cron 表达式以按计划运行该任务。"
    }
  },
  {
    "id": 898,
    "topic": "1",
    "question_en": "A company runs workloads in the AWS Cloud. The company wants to centrally collect security data to assess security across the entire company and to improve workload protection. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Configure a data lake in AWS Lake Formation. Use AWS Glue crawlers to ingest the security data into the data lake.",
      "B": "Configure an AWS Lambda function to collect the security data in .csv format. Upload the data to an Amazon S3 bucket.",
      "C": "Configure a data lake in Amazon Security Lake to collect the security data. Upload the data to an Amazon S3 bucket.",
      "D": "Configure an AWS Database Migration Service (AWS DMS) replication instance to load the security data into an Amazon RDS cluster."
    },
    "correct_answer": "C",
    "vote_percentage": "100%",
    "question_cn": "一家公司在 AWS 云中运行工作负载。该公司希望集中收集安全数据，以评估整个公司的安全性并提高工作负载保护。哪种解决方案将以最小的开发工作量满足这些要求？",
    "options_cn": {
      "A": "在 AWS Lake Formation 中配置一个数据湖。使用 AWS Glue 爬虫将安全数据提取到数据湖中。",
      "B": "配置一个 AWS Lambda 函数以 .csv 格式收集安全数据。将数据上传到 Amazon S3 存储桶。",
      "C": "配置 Amazon Security Lake 中的一个数据湖以收集安全数据。将数据上传到 Amazon S3 存储桶。",
      "D": "配置 AWS Database Migration Service (AWS DMS) 复制实例，以将安全数据加载到 Amazon RDS 集群中。"
    }
  },
  {
    "id": 899,
    "topic": "1",
    "question_en": "A company is migrating five on-premises applications to VPCs in the AWS Cloud. Each application is currently deployed in isolated virtual networks on premises and should be deployed similarly in the AWS Cloud. The applications need to reach a shared services VPC. All the applications must be able to communicate with each other. If the migration is successful, the company will repeat the migration process for more than 100 applications. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Deploy software VPN tunnels between the application VPCs and the shared services VPC. Add routes between the application VPCs in their subnets to the shared services VPC.",
      "B": "Deploy VPC peering connections between the application VPCs and the shared services VPC. Add routes between the application VPCs in their subnets to the shared services VPC through the peering connection.",
      "C": "Deploy an AWS Direct Connect connection between the application VPCs and the shared services VPAdd routes from the application VPCs in their subnets to the shared services VPC and the applications VPCs. Add routes from the shared services VPC subnets to the applications VPCs.",
      "D": "Deploy a transit gateway with associations between the transit gateway and the application VPCs and the shared services VPC. Add routes between the application VPCs in their subnets and the application VPCs to the shared services VPC through the transit gateway."
    },
    "correct_answer": "D",
    "vote_percentage": "88%",
    "question_cn": "一家公司正在将五个本地应用程序迁移到 AWS 云中的 VPC。每个应用程序目前都部署在本地的独立虚拟网络中，并且应在 AWS 云中进行类似的部署。应用程序需要连接到共享服务 VPC。所有应用程序都必须能够相互通信。如果迁移成功，公司将为 100 多个应用程序重复迁移过程。哪种解决方案以最小的管理开销满足这些要求？",
    "options_cn": {
      "A": "在应用程序 VPC 和共享服务 VPC 之间部署软件 VPN 隧道。在应用程序 VPC 的子网中添加路由到共享服务 VPC。",
      "B": "在应用程序 VPC 和共享服务 VPC 之间部署 VPC 对等连接。通过对等连接，在应用程序 VPC 的子网中添加路由到共享服务 VPC。",
      "C": "在应用程序 VPC 和共享服务 VPC 之间部署 AWS Direct Connect 连接。从应用程序 VPC 的子网到共享服务 VPC 和应用程序 VPC 添加路由。从共享服务 VPC 子网到应用程序 VPC 添加路由。",
      "D": "部署一个过渡网关，并在过渡网关与应用程序 VPC 和共享服务 VPC 之间建立关联。通过过渡网关，在应用程序 VPC 的子网中添加路由到应用程序 VPC 到共享服务 VPC 的路由。"
    }
  },
  {
    "id": 900,
    "topic": "1",
    "question_en": "A company wants to use Amazon Elastic Container Service (Amazon ECS) to run its on-premises application in a hybrid environment. The application currently runs on containers on premises. The company needs a single container solution that can scale in an on-premises, hybrid, or cloud environment. The company must run new application containers in the AWS Cloud and must use a load balancer for HTTP trafic. Which combination of actions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Set up an ECS cluster that uses the AWS Fargate launch type for the cloud application containers. Use an Amazon ECS Anywhere external launch type for the on-premises application containers.",
      "B": "Set up an Application Load Balancer for cloud ECS services.",
      "C": "Set up a Network Load Balancer for cloud ECS services.",
      "D": "Set up an ECS cluster that uses the AWS Fargate launch typ",
      "E": "Use Fargate for the cloud application containers and the on-premises application containers. E. Set up an ECS cluster that uses the Amazon EC2 launch type for the cloud application containers. Use Amazon ECS Anywhere with an AWS Fargate launch type for the on-premises application containers."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望使用 Amazon Elastic Container Service (Amazon ECS) 在混合环境中运行其本地应用程序。该应用程序目前在本地容器上运行。该公司需要一个单一的容器解决方案，该解决方案可以在本地、混合或云环境中扩展。该公司必须在 AWS 云中运行新的应用程序容器，并且必须使用负载均衡器进行 HTTP 流量。哪种组合的操作将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "设置一个 ECS 集群，该集群使用 AWS Fargate 启动类型来实现云应用程序容器。使用 Amazon ECS Anywhere 外部启动类型来实现本地应用程序容器。",
      "B": "为云 ECS 服务设置一个 Application Load Balancer。",
      "C": "为云 ECS 服务设置一个 Network Load Balancer。",
      "D": "设置一个 ECS 集群，该集群使用 AWS Fargate 启动类型。将 Fargate 用于云应用程序容器和本地应用程序容器。",
      "E": "设置一个 ECS 集群，该集群使用 Amazon EC2 启动类型来实现云应用程序容器。使用 Amazon ECS Anywhere 并使用 AWS Fargate 启动类型来实现本地应用程序容器。"
    }
  },
  {
    "id": 901,
    "topic": "1",
    "question_en": "A company is migrating its workloads to AWS. The company has sensitive and critical data in on-premises relational databases that run on SQL Server instances. The company wants to use the AWS Cloud to increase security and reduce operational overhead for the databases. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the databases to Amazon EC2 instances. Use an AWS Key Management Service (AWS KMS) AWS managed key for encryption.",
      "B": "Migrate the databases to a Multi-AZ Amazon RDS for SQL Server DB instance. Use an AWS Key Management Service (AWS KMS) AWS managed key for encryption.",
      "C": "Migrate the data to an Amazon S3 bucket. Use Amazon Macie to ensure data security.",
      "D": "Migrate the databases to an Amazon DynamoDB table. Use Amazon CloudWatch Logs to ensure data security."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其工作负载迁移到 AWS。该公司在本地关系数据库（在 SQL Server 实例上运行）中拥有敏感和关键数据。该公司希望使用 AWS Cloud 来提高数据库的安全性并减少运营开销。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将数据库迁移到 Amazon EC2 实例。使用 AWS Key Management Service (AWS KMS) AWS 托管密钥进行加密。",
      "B": "将数据库迁移到 Multi-AZ Amazon RDS for SQL Server 数据库实例。使用 AWS Key Management Service (AWS KMS) AWS 托管密钥进行加密。",
      "C": "将数据迁移到 Amazon S3 存储桶。使用 Amazon Macie 确保数据安全。",
      "D": "将数据库迁移到 Amazon DynamoDB 表。使用 Amazon CloudWatch Logs 确保数据安全。"
    }
  },
  {
    "id": 902,
    "topic": "1",
    "question_en": "A company wants to migrate an application to AWS. The company wants to increase the application's current availability. The company wants to use AWS WAF in the application's architecture. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Auto Scaling group that contains multiple Amazon EC2 instances that host the application across two Availability Zones. Configure an Application Load Balancer (ALB) and set the Auto Scaling group as the target. Connect a WAF to the ALB.",
      "B": "Create a cluster placement group that contains multiple Amazon EC2 instances that hosts the application. Configure an Application Load Balancer and set the EC2 instances as the targets. Connect a WAF to the placement group.",
      "C": "Create two Amazon EC2 instances that host the application across two Availability Zones. Configure the EC2 instances as the targets of an Application Load Balancer (ALB). Connect a WAF to the ALB.",
      "D": "Create an Auto Scaling group that contains multiple Amazon EC2 instances that host the application across two Availability Zones. Configure an Application Load Balancer (ALB) and set the Auto Scaling group as the target. Connect a WAF to the Auto Scaling group."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将应用程序迁移到 AWS。该公司希望提高应用程序当前的可用性。该公司希望在应用程序的架构中使用 AWS WAF。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个包含多个 Amazon EC2 实例的 Auto Scaling 组，这些实例在两个可用区中托管应用程序。配置一个 Application Load Balancer (ALB) 并将 Auto Scaling 组设置为目标。将 WAF 连接到 ALB。",
      "B": "创建一个包含多个托管应用程序的 Amazon EC2 实例的集群放置组。配置一个 Application Load Balancer 并将 EC2 实例设置为目标。将 WAF 连接到放置组。",
      "C": "创建两个 Amazon EC2 实例，这些实例在两个可用区中托管应用程序。将 EC2 实例配置为 Application Load Balancer (ALB) 的目标。将 WAF 连接到 ALB。",
      "D": "创建一个包含多个 Amazon EC2 实例的 Auto Scaling 组，这些实例在两个可用区中托管应用程序。配置一个 Application Load Balancer (ALB) 并将 Auto Scaling 组设置为目标。将 WAF 连接到 Auto Scaling 组。"
    }
  },
  {
    "id": 903,
    "topic": "1",
    "question_en": "A company manages a data lake in an Amazon S3 bucket that numerous applications access. The S3 bucket contains a unique prefix for each application. The company wants to restrict each application to its specific prefix and to have granular control of the objects under each prefix. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create dedicated S3 access points and access point policies for each application.",
      "B": "Create an S3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.",
      "C": "Replicate the objects in the S3 bucket to new S3 buckets for each application. Create replication rules by prefix.",
      "D": "Replicate the objects in the S3 bucket to new S3 buckets for each application. Create dedicated S3 access points for each application."
    },
    "correct_answer": "A",
    "vote_percentage": "78%",
    "question_cn": "一家公司在其 Amazon S3 存储桶中管理一个数据湖，多个应用程序都可以访问该数据湖。S3 存储桶包含每个应用程序的唯一前缀。该公司希望将每个应用程序限制为其特定的前缀，并对每个前缀下的对象进行精细控制。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "为每个应用程序创建专用的 S3 访问点和访问点策略。",
      "B": "创建一个 S3 批量操作作业来设置 S3 存储桶中每个对象的 ACL 权限。",
      "C": "将 S3 存储桶中的对象复制到每个应用程序的新 S3 存储桶。按前缀创建复制规则。",
      "D": "将 S3 存储桶中的对象复制到每个应用程序的新 S3 存储桶。为每个应用程序创建专用的 S3 访问点。"
    }
  },
  {
    "id": 904,
    "topic": "1",
    "question_en": "A company has an application that customers use to upload images to an Amazon S3 bucket. Each night, the company launches an Amazon EC2 Spot Fleet that processes all the images that the company received that day. The processing for each image takes 2 minutes and requires 512 MB of memory. A solutions architect needs to change the application to process the images when the images are uploaded. Which change will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use S3 Event Notifications to write a message with image details to an Amazon Simple Queue Service (Amazon SQS) queue. Configure an AWS Lambda function to read the messages from the queue and to process the images.",
      "B": "Use S3 Event Notifications to write a message with image details to an Amazon Simple Queue Service (Amazon SQS) queue. Configure an EC2 Reserved Instance to read the messages from the queue and to process the images.",
      "C": "Use S3 Event Notifications to publish a message with image details to an Amazon Simple Notification Service (Amazon SNS) topic. Configure a container instance in Amazon Elastic Container Service (Amazon ECS) to subscribe to the topic and to process the images.",
      "D": "Use S3 Event Notifications to publish a message with image details to an Amazon Simple Notification Service (Amazon SNS) topic. Configure an AWS Elastic Beanstalk application to subscribe to the topic and to process the images."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司有一个应用程序，客户可以使用该应用程序将图像上传到 Amazon S3 存储桶。每天晚上，该公司都会启动一个 Amazon EC2 Spot Fleet，该车队会处理该公司当天收到的所有图像。每个图像的处理需要 2 分钟，并且需要 512 MB 的内存。一个解决方案架构师需要更改该应用程序以在上传图像时处理图像。哪种更改将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 S3 事件通知将包含图像详细信息的邮件写入 Amazon Simple Queue Service (Amazon SQS) 队列。配置一个 AWS Lambda 函数以从队列中读取邮件并处理图像。",
      "B": "使用 S3 事件通知将包含图像详细信息的邮件写入 Amazon Simple Queue Service (Amazon SQS) 队列。配置一个 EC2 Reserved Instance 以从队列中读取邮件并处理图像。",
      "C": "使用 S3 事件通知将包含图像详细信息的邮件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置 Amazon Elastic Container Service (Amazon ECS) 中的容器实例以订阅该主题并处理图像。",
      "D": "使用 S3 事件通知将包含图像详细信息的邮件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置一个 AWS Elastic Beanstalk 应用程序以订阅该主题并处理图像。"
    }
  },
  {
    "id": 905,
    "topic": "1",
    "question_en": "A company wants to improve the availability and performance of its hybrid application. The application consists of a stateful TCP-based workload hosted on Amazon EC2 instances in different AWS Regions and a stateless UDP-based workload hosted on premises. Which combination of actions should a solutions architect take to improve availability and performance? (Choose two.)",
    "options_en": {
      "A": "Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.",
      "B": "Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the load balancers.",
      "C": "Configure two Application Load Balancers in each Region. The first will route to the EC2 endpoints, and the second will route to the on- premises endpoints.",
      "D": "Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on-premises endpoints",
      "E": "Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure an Application Load Balancer in each Region that routes to the on-premises endpoints."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司希望提高其混合应用程序的可用性和性能。该应用程序包含一个基于状态的、基于 TCP 的工作负载，该工作负载托管在不同 AWS 区域的 Amazon EC2 实例上，以及一个基于无状态的 UDP 的工作负载，该工作负载托管在本地。解决方案架构师应该采取哪些行动组合来提高可用性和性能？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Global Accelerator 创建一个加速器。将负载均衡器添加为端点。",
      "B": "创建一个 Amazon CloudFront 分发，其源使用 Amazon Route 53 基于延迟的路由将请求路由到负载均衡器。",
      "C": "在每个区域配置两个 Application Load Balancer。第一个将路由到 EC2 端点，第二个将路由到本地端点。",
      "D": "在每个区域配置一个 Network Load Balancer 以寻址 EC2 端点。在每个区域配置一个 Network Load Balancer，该负载均衡器路由到本地端点。",
      "E": "在每个区域配置一个 Network Load Balancer 以寻址 EC2 端点。在每个区域配置一个 Application Load Balancer，该负载均衡器路由到本地端点。"
    }
  },
  {
    "id": 906,
    "topic": "1",
    "question_en": "A company runs a self-managed Microsoft SQL Server on Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS). Daily snapshots are taken of the EBS volumes. Recently, all the company’s EBS snapshots were accidentally deleted while running a snapshot cleaning script that deletes all expired EBS snapshots. A solutions architect needs to update the architecture to prevent data loss without retaining EBS snapshots indefinitely. Which solution will meet these requirements with the LEAST development effort?",
    "options_en": {
      "A": "Change the IAM policy of the user to deny EBS snapshot deletion.",
      "B": "Copy the EBS snapshots to another AWS Region after completing the snapshots daily.",
      "C": "Create a 7-day EBS snapshot retention rule in Recycle Bin and apply the rule for all snapshots.",
      "D": "Copy EBS snapshots to Amazon S3 Standard-Infrequent Access (S3 Standard-IA)."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在 Amazon EC2 实例和 Amazon Elastic Block Store (Amazon EBS) 上运行一个自管理的 Microsoft SQL Server。每天都会对 EBS 卷进行快照。最近，在运行一个快照清理脚本时，该公司所有的 EBS 快照都被意外删除，该脚本会删除所有过期的 EBS 快照。一个解决方案架构师需要更新该架构，以防止数据丢失，而无需无限期地保留 EBS 快照。哪个解决方案将以最少的开发工作满足这些要求？",
    "options_cn": {
      "A": "更改用户的 IAM 策略以拒绝 EBS 快照删除。",
      "B": "每天完成快照后，将 EBS 快照复制到另一个 AWS 区域。",
      "C": "在回收站中创建 7 天的 EBS 快照保留规则，并将该规则应用于所有快照。",
      "D": "将 EBS 快照复制到 Amazon S3 标准 - 较少访问 (S3 标准 - IA)。"
    }
  },
  {
    "id": 907,
    "topic": "1",
    "question_en": "A company wants to use an AWS CloudFormation stack for its application in a test environment. The company stores the CloudFormation template in an Amazon S3 bucket that blocks public access. The company wants to grant CloudFormation access to the template in the S3 bucket based on specific user requests to create the test environment. The solution must follow security best practices. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a gateway VPC endpoint for Amazon S3. Configure the CloudFormation stack to use the S3 object URL.",
      "B": "Create an Amazon API Gateway REST API that has the S3 bucket as the target. Configure the CloudFormation stack to use the API Gateway URL.",
      "C": "Create a presigned URL for the template object. Configure the CloudFormation stack to use the presigned URL.",
      "D": "Allow public access to the template object in the S3 bucket. Block the public access after the test environment is created."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司希望使用 AWS CloudFormation 堆栈来在其测试环境中运行其应用程序。该公司将 CloudFormation 模板存储在一个阻止公共访问的 Amazon S3 存储桶中。该公司希望根据特定用户请求向 CloudFormation 授予对 S3 存储桶中模板的访问权限，以创建测试环境。该解决方案必须遵循安全最佳实践。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 Amazon S3 创建一个网关 VPC endpoint。将 CloudFormation 堆栈配置为使用 S3 对象 URL。",
      "B": "创建一个 Amazon API Gateway REST API，该 API 将 S3 存储桶作为目标。将 CloudFormation 堆栈配置为使用 API Gateway URL。",
      "C": "为模板对象创建一个预签名 URL。将 CloudFormation 堆栈配置为使用预签名 URL。",
      "D": "允许公共访问 S3 存储桶中的模板对象。在创建测试环境后阻止公共访问。"
    }
  },
  {
    "id": 908,
    "topic": "1",
    "question_en": "A company has applications that run in an organization in AWS Organizations. The company outsources operational support of the applications. The company needs to provide access for the external support engineers without compromising security. The external support engineers need access to the AWS Management Console. The external support engineers also need operating system access to the company’s fieet ofAmazon EC2 instances that run Amazon Linux in private subnets. Which solution will meet these requirements MOST securely?",
    "options_en": {
      "A": "Confirm that AWS Systems Manager Agent (SSM Agent) is installed on all instances. Assign an instance profile with the necessary policy to connect to Systems Manager. Use AWS IAM Identity Center to provide the external support engineers console access. Use Systems Manager Session Manager to assign the required permissions.",
      "B": "Confirm that AWS Systems Manager Agent (SSM Agent) is installed on all instances. Assign an instance profile with the necessary policy to connect to Systems Manager. Use Systems Manager Session Manager to provide local IAM user credentials in each AWS account to the external support engineers for console access.",
      "C": "Confirm that all instances have a security group that allows SSH access only from the external support engineers’ source IP address ranges. Provide local IAM user credentials in each AWS account to the external support engineers for console access. Provide each external support engineer an SSH key pair to log in to the application instances.",
      "D": "Create a bastion host in a public subnet. Set up the bastion host security group to allow access from only the external engineers’ IP address ranges. Ensure that all instances have a security group that allows SSH access from the bastion host. Provide each external support engineer an SSH key pair to log in to the application instances. Provide local account IAM user credentials to the engineers for console access."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS Organizations 中运行应用程序。该公司外包了应用程序的运营支持。该公司需要为外部支持工程师提供访问权限，而不会影响安全性。外部支持工程师需要访问 AWS 管理控制台。外部支持工程师还需要操作系统访问权限，才能访问该公司在私有子网中运行 Amazon Linux 的 Amazon EC2 实例集群。哪个解决方案将以最安全的方式满足这些要求？",
    "options_cn": {
      "A": "确认所有实例上都安装了 AWS Systems Manager Agent (SSM Agent)。分配一个具有连接到 Systems Manager 所需策略的实例配置文件。使用 AWS IAM Identity Center 为外部支持工程师提供控制台访问权限。使用 Systems Manager Session Manager 分配所需的权限。",
      "B": "确认所有实例上都安装了 AWS Systems Manager Agent (SSM Agent)。分配一个具有连接到 Systems Manager 所需策略的实例配置文件。使用 Systems Manager Session Manager 为每个 AWS 账户中的外部支持工程师提供本地 IAM 用户凭证，以进行控制台访问。",
      "C": "确认所有实例都具有一个安全组，该安全组仅允许来自外部支持工程师源 IP 地址范围的 SSH 访问。为每个 AWS 账户中的外部支持工程师提供本地 IAM 用户凭证，以进行控制台访问。为每个外部支持工程师提供 SSH 密钥对，以登录到应用程序实例。",
      "D": "在公共子网中创建一个堡垒主机。将堡垒主机安全组设置为仅允许来自外部工程师 IP 地址范围的访问。确保所有实例都具有一个安全组，该安全组允许从堡垒主机进行 SSH 访问。为每个外部支持工程师提供 SSH 密钥对，以登录到应用程序实例。为工程师提供本地账户 IAM 用户凭证，以进行控制台访问。"
    }
  },
  {
    "id": 909,
    "topic": "1",
    "question_en": "A company uses Amazon RDS for PostgreSQL to run its applications in the us-east-1 Region. The company also uses machine learning (ML) models to forecast annual revenue based on near real-time reports. The reports are generated by using the same RDS for PostgreSQL database. The database performance slows during business hours. The company needs to improve database performance. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create a cross-Region read replica. Configure the reports to be generated from the read replica.",
      "B": "Activate Multi-AZ DB instance deployment for RDS for PostgreSQL. Configure the reports to be generated from the standby database.",
      "C": "Use AWS Data Migration Service (AWS DMS) to logically replicate data to a new database. Configure the reports to be generated from the new database.",
      "D": "Create a read replica in us-east-1. Configure the reports to be generated from the read replica."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司使用 Amazon RDS for PostgreSQL 在 us-east-1 区域中运行其应用程序。该公司还使用机器学习 (ML) 模型，根据近乎实时的报告预测年度收入。这些报告是使用相同的 RDS for PostgreSQL 数据库生成的。数据库性能在工作时间内会变慢。该公司需要提高数据库性能。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建一个跨区域读取副本。配置报告以从读取副本生成。",
      "B": "为 RDS for PostgreSQL 激活 Multi-AZ 数据库实例部署。配置报告以从备用数据库生成。",
      "C": "使用 AWS Data Migration Service (AWS DMS) 将数据逻辑复制到新数据库。配置报告以从新数据库生成。",
      "D": "在 us-east-1 中创建一个读取副本。配置报告以从读取副本生成。"
    }
  },
  {
    "id": 910,
    "topic": "1",
    "question_en": "A company hosts its multi-tier, public web application in the AWS Cloud. The web application runs on Amazon EC2 instances, and its database runs on Amazon RDS. The company is anticipating a large increase in sales during an upcoming holiday weekend. A solutions architect needs to build a solution to analyze the performance of the web application with a granularity of no more than 2 minutes. What should the solutions architect do to meet this requirement?",
    "options_en": {
      "A": "Send Amazon CloudWatch logs to Amazon Redshift. Use Amazon QuickS ght to perform further analysis.",
      "B": "Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.",
      "C": "Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs. Use Amazon CloudWatch metrics to perform further analysis.",
      "D": "Send EC2 logs to Amazon S3. Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS Cloud 中托管其多层公共 Web 应用程序。Web 应用程序在 Amazon EC2 实例上运行，其数据库在 Amazon RDS 上运行。该公司预计在即将到来的假期周末销售额将大幅增加。一个解决方案架构师需要构建一个解决方案，以不超过 2 分钟的粒度分析 Web 应用程序的性能。解决方案架构师应该怎么做才能满足此要求？",
    "options_cn": {
      "A": "将 Amazon CloudWatch 日志发送到 Amazon Redshift。使用 Amazon QuickSight 执行进一步的分析。",
      "B": "在所有 EC2 实例上启用详细监控。使用 Amazon CloudWatch 指标执行进一步的分析。",
      "C": "创建一个 AWS Lambda 函数，用于从 Amazon CloudWatch Logs 中提取 EC2 日志。使用 Amazon CloudWatch 指标执行进一步的分析。",
      "D": "将 EC2 日志发送到 Amazon S3。使用 Amazon Redshift 从 S3 存储桶中提取日志，以处理原始数据，以便使用 Amazon QuickSight 进行进一步分析。"
    }
  },
  {
    "id": 911,
    "topic": "1",
    "question_en": "A company runs an application that stores and shares photos. Users upload the photos to an Amazon S3 bucket. Every day, users upload approximately 150 photos. The company wants to design a solution that creates a thumbnail of each new photo and stores the thumbnail in a second S3 bucket. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an Amazon EventBridge scheduled rule to invoke a script every minute on a long-running Amazon EMR cluster. Configure the script to generate thumbnails for the photos that do not have thumbnails. Configure the script to upload the thumbnails to the second S3 bucket.",
      "B": "Configure an Amazon EventBridge scheduled rule to invoke a script every minute on a memory-optimized Amazon EC2 instance that is always on. Configure the script to generate thumbnails for the photos that do not have thumbnails. Configure the script to upload the thumbnails to the second S3 bucket.",
      "C": "Configure an S3 event notification to invoke an AWS Lambda function each time a user uploads a new photo to the application. Configure the Lambda function to generate a thumbnail and to upload the thumbnail to the second S3 bucket.",
      "D": "Configure S3 Storage Lens to invoke an AWS Lambda function each time a user uploads a new photo to the application. Configure the Lambda function to generate a thumbnail and to upload the thumbnail to a second S3 bucket."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司运行一个应用程序，该应用程序存储和共享照片。用户将照片上传到 Amazon S3 存储桶。每天，用户大约上传 150 张照片。该公司希望设计一个解决方案，该解决方案可以为每张新照片创建缩略图，并将缩略图存储在第二个 S3 存储桶中。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon EventBridge 定时规则，以在长时间运行的 Amazon EMR 集群上每分钟调用一个脚本。配置脚本以生成没有缩略图的照片的缩略图。配置脚本以将缩略图上传到第二个 S3 存储桶。",
      "B": "配置 Amazon EventBridge 定时规则，以在始终处于运行状态的内存优化 Amazon EC2 实例上每分钟调用一个脚本。配置脚本以生成没有缩略图的照片的缩略图。配置脚本以将缩略图上传到第二个 S3 存储桶。",
      "C": "配置 S3 事件通知，以便在用户每次将新照片上传到应用程序时调用一个 AWS Lambda 函数。配置 Lambda 函数以生成缩略图并将缩略图上传到第二个 S3 存储桶。",
      "D": "配置 S3 Storage Lens，以便在用户每次将新照片上传到应用程序时调用一个 AWS Lambda 函数。配置 Lambda 函数以生成缩略图并将缩略图上传到第二个 S3 存储桶。"
    }
  },
  {
    "id": 912,
    "topic": "1",
    "question_en": "A company has stored millions of objects across multiple prefixes in an Amazon S3 bucket by using the Amazon S3 Glacier Deep Archive storage class. The company needs to delete all data older than 3 years except for a subset of data that must be retained. The company has identified the data that must be retained and wants to implement a serverless solution. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use S3 Inventory to list all objects. Use the AWS CLI to create a script that runs on an Amazon EC2 instance that deletes objects from the inventory list.",
      "B": "Use AWS Batch to delete objects older than 3 years except for the data that must be retained.",
      "C": "Provision an AWS Glue crawler to query objects older than 3 years. Save the manifest file of old objects. Create a script to delete objects in the manifest.",
      "D": "Enable S3 Inventory. Create an AWS Lambda function to filter and delete objects. Invoke the Lambda function with S3 Batch Operations to delete objects by using the inventory reports."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司使用 Amazon S3 Glacier Deep Archive 存储类将数百万个对象存储在 Amazon S3 存储桶中的多个前缀中。该公司需要删除所有超过 3 年的数据，但必须保留一部分数据。该公司已确定了必须保留的数据，并希望实施一个无服务器解决方案。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 S3 Inventory 列出所有对象。使用 AWS CLI 创建一个脚本，该脚本在 Amazon EC2 实例上运行，用于删除清单列表中的对象。",
      "B": "使用 AWS Batch 删除超过 3 年的对象，但必须保留的数据除外。",
      "C": "配置一个 AWS Glue 爬虫程序以查询超过 3 年的对象。保存旧对象的清单文件。创建一个脚本以删除清单中的对象。",
      "D": "启用 S3 Inventory。创建一个 AWS Lambda 函数以筛选和删除对象。使用 S3 批量操作调用 Lambda 函数，以使用库存报告删除对象。"
    }
  },
  {
    "id": 913,
    "topic": "1",
    "question_en": "A company is building an application on AWS. The application uses multiple AWS Lambda functions to retrieve sensitive data from a single Amazon S3 bucket for processing. The company must ensure that only authorized Lambda functions can access the data. The solution must comply with the principle of least privilege. Which solution will meet these requirements?",
    "options_en": {
      "A": "Grant full S3 bucket access to all Lambda functions through a shared IAM role.",
      "B": "Configure the Lambda functions to run within a VPC. Configure a bucket policy to grant access based on the Lambda functions' VPC endpoint IP addresses.",
      "C": "Create individual IAM roles for each Lambda function. Grant the IAM roles access to the S3 bucket. Assign each IAM role as the Lambda execution role for its corresponding Lambda function.",
      "D": "Configure a bucket policy granting access to the Lambda functions based on their function ARNs."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上构建一个应用程序。该应用程序使用多个 AWS Lambda 函数从单个 Amazon S3 存储桶中检索敏感数据进行处理。该公司必须确保只有授权的 Lambda 函数才能访问数据。该解决方案必须符合最小权限原则。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "通过共享 IAM 角色向所有 Lambda 函数授予对 S3 存储桶的完全访问权限。",
      "B": "将 Lambda 函数配置为在 VPC 中运行。配置存储桶策略以根据 Lambda 函数的 VPC endpoint IP 地址授予访问权限。",
      "C": "为每个 Lambda 函数创建单独的 IAM 角色。授予 IAM 角色对 S3 存储桶的访问权限。将每个 IAM 角色分配为其相应 Lambda 函数的 Lambda 执行角色。",
      "D": "配置一个存储桶策略，根据 Lambda 函数的函数 ARN 授予对 Lambda 函数的访问权限。"
    }
  },
  {
    "id": 914,
    "topic": "1",
    "question_en": "A company has developed a non-production application that is composed of multiple microservices for each of the company's business units. A single development team maintains all the microservices. The current architecture uses a static web frontend and a Java-based backend that contains the application logic. The architecture also uses a MySQL database that the company hosts on an Amazon EC2 instance. The company needs to ensure that the application is secure and available globally. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon CloudFront and AWS Amplify to host the static web frontend. Refactor the microservices to use AWS Lambda functions that the microservices access by using Amazon API Gateway. Migrate the MySQL database to an Amazon EC2 Reserved Instance.",
      "B": "Use Amazon CloudFront and Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that the microservices access by using Amazon API Gateway. Migrate the MySQL database to Amazon RDS for MySQL.",
      "C": "Use Amazon CloudFront and Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that are in a target group behind a Network Load Balancer. Migrate the MySQL database to Amazon RDS for MySQL.",
      "D": "Use Amazon S3 to host the static web frontend. Refactor the microservices to use AWS Lambda functions that are in a target group behind an Application Load Balancer. Migrate the MySQL database to an Amazon EC2 Reserved Instance."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司开发了一个非生产应用程序，该应用程序由该公司每个业务部门的多个微服务组成。单个开发团队维护所有微服务。当前的架构使用静态 Web 前端和基于 Java 的后端，该后端包含应用程序逻辑。该架构还使用公司在 Amazon EC2 实例上托管的 MySQL 数据库。该公司需要确保该应用程序在全球范围内安全且可用。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudFront 和 AWS Amplify 托管静态 Web 前端。重构微服务，以使用 AWS Lambda 函数，微服务通过 Amazon API Gateway 访问这些函数。将 MySQL 数据库迁移到 Amazon EC2 Reserved Instance。",
      "B": "使用 Amazon CloudFront 和 Amazon S3 托管静态 Web 前端。重构微服务，以使用 AWS Lambda 函数，微服务通过 Amazon API Gateway 访问这些函数。将 MySQL 数据库迁移到 Amazon RDS for MySQL。",
      "C": "使用 Amazon CloudFront 和 Amazon S3 托管静态 Web 前端。重构微服务，以使用位于 Network Load Balancer 后面的 AWS Lambda 函数。将 MySQL 数据库迁移到 Amazon RDS for MySQL。",
      "D": "使用 Amazon S3 托管静态 Web 前端。重构微服务，以使用位于 Application Load Balancer 后面的 AWS Lambda 函数。将 MySQL 数据库迁移到 Amazon EC2 Reserved Instance。"
    }
  },
  {
    "id": 915,
    "topic": "1",
    "question_en": "A video game company is deploying a new gaming application to its global users. The company requires a solution that will provide near real- time reviews and rankings of the players. A solutions architect must design a solution to provide fast access to the data. The solution must also ensure the data persists on disks in the event that the company restarts the application. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin. Store the player data in the S3 bucket.",
      "B": "Create Amazon EC2 instances in multiple AWS Regions. Store the player data on the EC2 instances. Configure Amazon Route 53 with geolocation records to direct users to the closest EC2 instance.",
      "C": "Deploy an Amazon ElastiCache for Redis duster. Store the player data in the ElastiCache cluster.",
      "D": "Deploy an Amazon ElastiCache for Memcached duster. Store the player data in the ElastiCache cluster."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家视频游戏公司正在为其全球用户部署一个新的游戏应用程序。该公司需要一个解决方案，以提供近实时的玩家评论和排名。解决方案架构师必须设计一个解决方案，以提供对数据的快速访问。该解决方案还必须确保在公司重新启动应用程序时，数据保存在磁盘上。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "配置一个以 Amazon S3 存储桶为源的 Amazon CloudFront 分发。将玩家数据存储在 S3 存储桶中。",
      "B": "在多个 AWS 区域中创建 Amazon EC2 实例。将玩家数据存储在 EC2 实例上。使用地理位置记录配置 Amazon Route 53，以将用户定向到最近的 EC2 实例。",
      "C": "部署一个 Amazon ElastiCache for Redis 集群。将玩家数据存储在 ElastiCache 集群中。",
      "D": "部署一个 Amazon ElastiCache for Memcached 集群。将玩家数据存储在 ElastiCache 集群中。"
    }
  },
  {
    "id": 916,
    "topic": "1",
    "question_en": "A company is designing an application on AWS that processes sensitive data. The application stores and processes financial data for multiple customers. To meet compliance requirements, the data for each customer must be encrypted separately at rest by using a secure, centralized key management solution. The company wants to use AWS Key Management Service (AWS KMS) to implement encryption. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Generate a unique encryption key for each customer. Store the keys in an Amazon S3 bucket. Enable server-side encryption.",
      "B": "Deploy a hardware security appliance in the AWS environment that securely stores customer-provided encryption keys. Integrate the security appliance with AWS KMS to encrypt the sensitive data in the application.",
      "C": "Create a single AWS KMS key to encrypt all sensitive data across the application.",
      "D": "Create separate AWS KMS keys for each customer's data that have granular access control and logging enabled."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上设计一个应用程序，该应用程序处理敏感数据。该应用程序存储和处理多个客户的财务数据。为了满足合规性要求，每个客户的数据都必须使用安全的集中式密钥管理解决方案单独静态加密。该公司希望使用 AWS Key Management Service (AWS KMS) 来实现加密。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "为每个客户生成唯一的加密密钥。将密钥存储在 Amazon S3 存储桶中。启用服务器端加密。",
      "B": "在 AWS 环境中部署一个硬件安全设备，该设备安全地存储客户提供的加密密钥。将安全设备与 AWS KMS 集成，以加密应用程序中的敏感数据。",
      "C": "创建一个 AWS KMS 密钥来加密应用程序中的所有敏感数据。",
      "D": "为每个客户的数据创建单独的 AWS KMS 密钥，并启用细粒度的访问控制和日志记录。"
    }
  },
  {
    "id": 917,
    "topic": "1",
    "question_en": "A company needs to design a resilient web application to process customer orders. The web application must automatically handle increases in web trafic and application usage without affecting the customer experience or losing customer orders. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use a NAT gateway to manage web trafic. Use Amazon EC2 Auto Scaling groups to receive, process, and store processed customer orders. Use an AWS Lambda function to capture and store unprocessed orders.",
      "B": "Use a Network Load Balancer (NLB) to manage web trafic. Use an Application Load Balancer to receive customer orders from the NLUse Amazon Redshift with a Multi-AZ deployment to store unprocessed and processed customer orders.",
      "C": "Use a Gateway Load Balancer (GWLB) to manage web trafic. Use Amazon Elastic Container Service (Amazon ECS) to receive and process customer orders. Use the GWLB to capture and store unprocessed orders. Use Amazon DynamoDB to store processed customer orders.",
      "D": "Use an Application Load Balancer to manage web trafic. Use Amazon EC2 Auto Scaling groups to receive and process customer orders. Use Amazon Simple Queue Service (Amazon SQS) to store unprocessed orders. Use Amazon RDS with a Multi-AZ deployment to store processed customer orders."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司需要设计一个具有弹性的 Web 应用程序来处理客户订单。该 Web 应用程序必须自动处理 Web 流量和应用程序使用量的增加，而不会影响客户体验或丢失客户订单。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 NAT Gateway 管理 Web 流量。使用 Amazon EC2 Auto Scaling 组接收、处理和存储已处理的客户订单。使用 AWS Lambda 函数捕获并存储未处理的订单。",
      "B": "使用 Network Load Balancer (NLB) 管理 Web 流量。使用 Application Load Balancer (ALB) 接收来自客户的订单。使用具有多可用区部署的 Amazon Redshift 存储未处理和已处理的客户订单。",
      "C": "使用 Gateway Load Balancer (GWLB) 管理 Web 流量。使用 Amazon Elastic Container Service (Amazon ECS) 接收和处理客户订单。使用 GWLB 捕获并存储未处理的订单。使用 Amazon DynamoDB 存储已处理的客户订单。",
      "D": "使用 Application Load Balancer 管理 Web 流量。使用 Amazon EC2 Auto Scaling 组接收和处理客户订单。使用 Amazon Simple Queue Service (Amazon SQS) 存储未处理的订单。使用具有多可用区部署的 Amazon RDS 存储已处理的客户订单。"
    }
  },
  {
    "id": 918,
    "topic": "1",
    "question_en": "A company is using AWS DataSync to migrate millions of files from an on-premises system to AWS. The files are 10 KB in size on average. The company wants to use Amazon S3 for file storage. For the first year after the migration, the files will be accessed once or twice and must be immediately available. After 1 year, the files must be archived for at least 7 years. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use an archive tool to group the files into large objects. Use DataSync to migrate the objects. Store the objects in S3 Glacier Instant Retrieval for the first year. Use a lifecycle configuration to transition the files to S3 Glacier Deep Archive after 1 year with a retention period of 7 years.",
      "B": "Use an archive tool to group the files into large objects. Use DataSync to copy the objects to S3 Standard-Infrequent Access (S3 Standard-IA). Use a lifecycle configuration to transition the files to S3 Glacier Instant Retrieval after 1 year with a retention period of 7 years.",
      "C": "Configure the destination storage class for the files as S3 Glacier Instant Retrieval. Use a lifecycle policy to transition the files to S3 Glacier Flexible Retrieval after 1 year with a retention period of 7 years.",
      "D": "Configure a DataSync task to transfer the files to S3 Standard-Infrequent Access (S3 Standard-IA). Use a lifecycle configuration to transition the files to S3 Deep Archive after 1 year with a retention period of 7 years."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在使用 AWS DataSync 将数百万个文件从本地系统迁移到 AWS。这些文件平均大小为 10 KB。该公司希望使用 Amazon S3 进行文件存储。迁移后的第一年，将访问这些文件一两次，并且必须立即可用。1 年后，这些文件必须归档至少 7 年。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用归档工具将文件分组为大对象。使用 DataSync 迁移这些对象。将这些对象存储在 S3 Glacier Instant Retrieval 中一年。使用生命周期配置将文件在 1 年后过渡到 S3 Glacier Deep Archive，保留期为 7 年。",
      "B": "使用归档工具将文件分组为大对象。使用 DataSync 将对象复制到 S3 Standard-Infrequent Access (S3 Standard-IA)。使用生命周期配置将文件在 1 年后过渡到 S3 Glacier Instant Retrieval，保留期为 7 年。",
      "C": "将文件的目标存储类配置为 S3 Glacier Instant Retrieval。使用生命周期策略将文件在 1 年后过渡到 S3 Glacier Flexible Retrieval，保留期为 7 年。",
      "D": "配置 DataSync 任务以将文件传输到 S3 Standard-Infrequent Access (S3 Standard-IA)。使用生命周期配置将文件在 1 年后过渡到 S3 Deep Archive，保留期为 7 年。"
    }
  },
  {
    "id": 919,
    "topic": "1",
    "question_en": "A company recently performed a lift and shift migration of its on-premises Oracle database workload to run on an Amazon EC2 memory optimized Linux instance. The EC2 Linux instance uses a 1 TB Provisioned IOPS SSD (io1) EBS volume with 64,000 IOPS. The database storage performance after the migration is slower than the performance of the on-premises database. Which solution will improve storage performance?",
    "options_en": {
      "A": "Add more Provisioned IOPS SSD (io1) EBS volumes. Use OS commands to create a Logical Volume Management (LVM) stripe.",
      "B": "Increase the Provisioned IOPS SSD (io1) EBS volume to more than 64,000 IOPS.",
      "C": "Increase the size of the Provisioned IOPS SSD (io1) EBS volume to 2 TB.",
      "D": "Change the EC2 Linux instance to a storage optimized instance type. Do not change the Provisioned IOPS SSD (io1) EBS volume."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司最近将其本地 Oracle 数据库工作负载进行了迁移，以便在 Amazon EC2 内存优化 Linux 实例上运行。 EC2 Linux 实例使用 1 TB 预置 IOPS SSD (io1) EBS 卷，具有 64,000 IOPS。 迁移后，数据库存储性能比本地数据库的性能慢。 哪个解决方案将提高存储性能？",
    "options_cn": {
      "A": "添加更多预置 IOPS SSD (io1) EBS 卷。 使用操作系统命令创建逻辑卷管理 (LVM) 条带。",
      "B": "将预置 IOPS SSD (io1) EBS 卷增加到超过 64,000 IOPS。",
      "C": "将预置 IOPS SSD (io1) EBS 卷的大小增加到 2 TB。",
      "D": "将 EC2 Linux 实例更改为存储优化实例类型。 不更改预置 IOPS SSD (io1) EBS 卷。"
    }
  },
  {
    "id": 920,
    "topic": "1",
    "question_en": "A company is migrating from a monolithic architecture for a web application that is hosted on Amazon EC2 to a serverless microservices architecture. The company wants to use AWS services that support an event-driven, loosely coupled architecture. The company wants to use the publish/subscribe (pub/sub) pattern. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an Amazon API Gateway REST API to invoke an AWS Lambda function that publishes events to an Amazon Simple Queue Service (Amazon SQS) queue. Configure one or more subscribers to read events from the SQS queue.",
      "B": "Configure an Amazon API Gateway REST API to invoke an AWS Lambda function that publishes events to an Amazon Simple Notification Service (Amazon SNS) topic. Configure one or more subscribers to receive events from the SNS topic.",
      "C": "Configure an Amazon API Gateway WebSocket API to write to a data stream in Amazon Kinesis Data Streams with enhanced fan-out. Configure one or more subscribers to receive events from the data stream.",
      "D": "Configure an Amazon API Gateway HTTP API to invoke an AWS Lambda function that publishes events to an Amazon Simple Notification Service (Amazon SNS) topic. Configure one or more subscribers to receive events from the topic."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其托管在 Amazon EC2 上的 Web 应用程序从单体架构迁移到无服务器微服务架构。该公司希望使用支持事件驱动、松耦合架构的 AWS 服务。该公司希望使用发布/订阅 (pub/sub) 模式。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon API Gateway REST API 以调用一个 AWS Lambda 函数，该函数将事件发布到 Amazon Simple Queue Service (Amazon SQS) 队列。配置一个或多个订阅者以从 SQS 队列中读取事件。",
      "B": "配置 Amazon API Gateway REST API 以调用一个 AWS Lambda 函数，该函数将事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置一个或多个订阅者以从 SNS 主题接收事件。",
      "C": "配置 Amazon API Gateway WebSocket API 以写入 Amazon Kinesis Data Streams 中的数据流，并使用增强的扇出功能。配置一个或多个订阅者以从数据流接收事件。",
      "D": "配置 Amazon API Gateway HTTP API 以调用一个 AWS Lambda 函数，该函数将事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置一个或多个订阅者以从该主题接收事件。"
    }
  },
  {
    "id": 921,
    "topic": "1",
    "question_en": "A company recently migrated a monolithic application to an Amazon EC2 instance and Amazon RDS. The application has tightly coupled modules. The existing design of the application gives the application the ability to run on only a single EC2 instance. The company has noticed high CPU utilization on the EC2 instance during peak usage times. The high CPU utilization corresponds to degraded performance on Amazon RDS for read requests. The company wants to reduce the high CPU utilization and improve read request performance. Which solution will meet these requirements?",
    "options_en": {
      "A": "Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Configure an RDS read replica for read requests.",
      "B": "Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Add an RDS read replica and redirect all read/write trafic to the replica.",
      "C": "Configure an Auto Scaling group with a minimum size of 1 and maximum size of 2. Resize the RDS DB instance to an instance type that has more CPU capacity.",
      "D": "Resize the EC2 instance to an EC2 instance type that has more CPU capacity. Configure an Auto Scaling group with a minimum and maximum size of 1. Resize the RDS DB instance to an instance type that has more CPU capacity."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司最近将其单体应用程序迁移到 Amazon EC2 实例和 Amazon RDS。该应用程序具有紧密耦合的模块。该应用程序的现有设计使其只能在一个 EC2 实例上运行。该公司注意到在高峰使用时段，EC2 实例上的 CPU 利用率很高。高 CPU 利用率对应于 Amazon RDS 上读取请求的性能下降。该公司希望降低高 CPU 利用率并提高读取请求的性能。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 EC2 实例调整为具有更多 CPU 容量的 EC2 实例类型。配置一个 Auto Scaling 组，其最小和最大大小为 1。为读取请求配置 RDS 读取副本。",
      "B": "将 EC2 实例调整为具有更多 CPU 容量的 EC2 实例类型。配置一个 Auto Scaling 组，其最小和最大大小为 1。添加一个 RDS 读取副本，并将所有读取/写入流量重定向到该副本。",
      "C": "配置一个 Auto Scaling 组，其最小大小为 1，最大大小为 2。将 RDS 数据库实例调整为具有更多 CPU 容量的实例类型。",
      "D": "将 EC2 实例调整为具有更多 CPU 容量的 EC2 实例类型。配置一个 Auto Scaling 组，其最小和最大大小为 1。将 RDS 数据库实例调整为具有更多 CPU 容量的实例类型。"
    }
  },
  {
    "id": 922,
    "topic": "1",
    "question_en": "A company needs to grant a team of developers access to the company's AWS resources. The company must maintain a high level of security for the resources. The company requires an access control solution that will prevent unauthorized access to the sensitive data. Which solution will meet these requirements?",
    "options_en": {
      "A": "Share the IAM user credentials for each development team member with the rest of the team to simplify access management and to streamline development workfiows.",
      "B": "Define IAM roles that have fine-grained permissions based on the principle of least privilege. Assign an IAM role to each developer.",
      "C": "Create IAM access keys to grant programmatic access to AWS resources. Allow only developers to interact with AWS resources through API calls by using the access keys.",
      "D": "Create an AWS Cognito user pool. Grant developers access to AWS resources by using the user pool."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司需要授予一个开发团队访问公司 AWS 资源的权限。该公司必须为其资源维护高水平的安全性。该公司需要一个访问控制解决方案，以防止未经授权访问敏感数据。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "与团队的其他成员共享每个开发团队成员的 IAM 用户凭证，以简化访问管理并简化开发工作流程。",
      "B": "定义基于最小权限原则的细粒度权限的 IAM 角色。为每个开发人员分配一个 IAM 角色。",
      "C": "创建 IAM 访问密钥以授予对 AWS 资源的编程访问权限。仅允许开发人员通过使用访问密钥的 API 调用与 AWS 资源交互。",
      "D": "创建一个 AWS Cognito 用户池。通过使用用户池授予开发人员对 AWS 资源的访问权限。"
    }
  },
  {
    "id": 923,
    "topic": "1",
    "question_en": "A company hosts a monolithic web application on an Amazon EC2 instance. Application users have recently reported poor performance at specific times. Analysis of Amazon CloudWatch metrics shows that CPU utilization is 100% during the periods of poor performance. The company wants to resolve this performance issue and improve application availability. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Use AWS Compute Optimizer to obtain a recommendation for an instance type to scale vertically.",
      "B": "Create an Amazon Machine Image (AMI) from the web server. Reference the AMI in a new launch template.",
      "C": "Create an Auto Scaling group and an Application Load Balancer to scale vertically.",
      "D": "Use AWS Compute Optimizer to obtain a recommendation for an instance type to scale horizontally",
      "E": "Create an Auto Scaling group and an Application Load Balancer to scale horizontally."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在其 Amazon EC2 实例上托管一个单体 Web 应用程序。 应用程序用户最近报告说在特定时间性能很差。对 Amazon CloudWatch 指标的分析表明，在性能不佳的时段，CPU 利用率为 100%。该公司希望解决此性能问题并提高应用程序的可用性。哪两种步骤的组合将最具成本效益地满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Compute Optimizer 获取有关纵向扩展实例类型的建议。",
      "B": "从 Web 服务器创建一个 Amazon Machine Image (AMI)。在新启动模板中引用该 AMI。",
      "C": "创建一个 Auto Scaling 组和一个 Application Load Balancer 进行纵向扩展。",
      "D": "使用 AWS Compute Optimizer 获取有关横向扩展实例类型的建议。",
      "E": "创建一个 Auto Scaling 组和一个 Application Load Balancer 进行横向扩展。"
    }
  },
  {
    "id": 924,
    "topic": "1",
    "question_en": "A company runs all its business applications in the AWS Cloud. The company uses AWS Organizations to manage multiple AWS accounts. A solutions architect needs to review all permissions that are granted to IAM users to determine which IAM users have more permissions than required. Which solution will meet these requirements with the LEAST administrative overhead?",
    "options_en": {
      "A": "Use Network Access Analyzer to review all access permissions in the company's AWS accounts.",
      "B": "Create an AWS CloudWatch alarm that activates when an IAM user creates or modifies resources in an AWS account.",
      "C": "Use AWS Identity and Access Management (IAM) Access Analyzer to review all the company’s resources and accounts.",
      "D": "Use Amazon Inspector to find vulnerabilities in existing IAM policies."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 云中运行其所有业务应用程序。该公司使用 AWS Organizations 管理多个 AWS 账户。一个解决方案架构师需要审查授予 IAM 用户的所有权限，以确定哪些 IAM 用户拥有超过所需权限的权限。哪种解决方案以最少的管理开销满足这些要求？",
    "options_cn": {
      "A": "使用 Network Access Analyzer 审查公司 AWS 账户中的所有访问权限。",
      "B": "创建一个 AWS CloudWatch 警报，该警报在 IAM 用户在 AWS 账户中创建或修改资源时激活。",
      "C": "使用 AWS Identity and Access Management (IAM) Access Analyzer 审查公司所有资源和账户。",
      "D": "使用 Amazon Inspector 查找现有 IAM 策略中的漏洞。"
    }
  },
  {
    "id": 925,
    "topic": "1",
    "question_en": "A company needs to implement a new data retention policy for regulatory compliance. As part of this policy, sensitive documents that are stored in an Amazon S3 bucket must be protected from deletion or modification for a fixed period of time. Which solution will meet these requirements?",
    "options_en": {
      "A": "Activate S3 Object Lock on the required objects and enable governance mode.",
      "B": "Activate S3 Object Lock on the required objects and enable compliance mode.",
      "C": "Enable versioning on the S3 bucket. Set a lifecycle policy to delete the objects after a specified period.",
      "D": "Configure an S3 Lifecycle policy to transition objects to S3 Glacier Flexible Retrieval for the retention duration."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司需要实施一项新的数据保留策略以符合法规要求。作为此策略的一部分，存储在 Amazon S3 存储桶中的敏感文档必须在固定时间内受到保护，以防止被删除或修改。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "在所需对象上激活 S3 Object Lock 并启用管理模式。",
      "B": "在所需对象上激活 S3 Object Lock 并启用合规模式。",
      "C": "在 S3 存储桶上启用版本控制。设置一个生命周期策略，在指定的时间段后删除对象。",
      "D": "配置 S3 生命周期策略，以便在保留期限内将对象转移到 S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 926,
    "topic": "1",
    "question_en": "A company runs its customer-facing web application on containers. The workload uses Amazon Elastic Container Service (Amazon ECS) on AWS Fargate. The web application is resource intensive. The web application needs to be available 24 hours a day, 7 days a week for customers. The company expects the application to experience short bursts of high trafic. The workload must be highly available. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an ECS capacity provider with Fargate. Conduct load testing by using a third-party tool. Rightsize the Fargate tasks in Amazon CloudWatch.",
      "B": "Configure an ECS capacity provider with Fargate for steady state and Fargate Spot for burst trafic.",
      "C": "Configure an ECS capacity provider with Fargate Spot for steady state and Fargate for burst trafic.",
      "D": "Configure an ECS capacity provider with Fargate. Use AWS Compute Optimizer to rightsize the Fargate task."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在其容器上运行面向客户的 Web 应用程序。工作负载在 AWS Fargate 上使用 Amazon Elastic Container Service (Amazon ECS)。Web 应用程序资源密集。Web 应用程序需要每周 7 天、每天 24 小时为客户提供服务。该公司预计应用程序将经历短时高峰流量。工作负载必须具有高可用性。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 Fargate 配置 ECS 容量提供程序。使用第三方工具进行负载测试。在 Amazon CloudWatch 中调整 Fargate 任务的大小。",
      "B": "为稳定状态配置具有 Fargate 的 ECS 容量提供程序，并为突发流量配置 Fargate Spot。",
      "C": "为稳定状态配置具有 Fargate Spot 的 ECS 容量提供程序，并为突发流量配置 Fargate。",
      "D": "使用 Fargate 配置 ECS 容量提供程序。使用 AWS Compute Optimizer 调整 Fargate 任务的大小。"
    }
  },
  {
    "id": 927,
    "topic": "1",
    "question_en": "A company is building an application in the AWS Cloud. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses Amazon Route 53 for the DNS. The company needs a managed solution with proactive engagement to detect against DDoS attacks. Which solution will meet these requirements?",
    "options_en": {
      "A": "Enable AWS Config. Configure an AWS Config managed rule that detects DDoS attacks.",
      "B": "Enable AWS WAF on the ALCreate an AWS WAF web ACL with rules to detect and prevent DDoS attacks. Associate the web ACL with the ALB.",
      "C": "Store the ALB access logs in an Amazon S3 bucket. Configure Amazon GuardDuty to detect and take automated preventative actions for DDoS attacks.",
      "D": "Subscribe to AWS Shield Advanced. Configure hosted zones in Route 53. Add ALB resources as protected resources."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 云中构建一个应用程序。 该应用程序托管在 Application Load Balancer (ALB) 后的 Amazon EC2 实例上。 公司使用 Amazon Route 53 进行 DNS。 该公司需要一个具有主动参与的托管解决方案来检测 DDoS 攻击。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "启用 AWS Config。 配置一个 AWS Config 托管规则来检测 DDoS 攻击。",
      "B": "在 ALB 上启用 AWS WAF。 创建一个带有规则的 AWS WAF Web ACL 来检测和阻止 DDoS 攻击。 将 Web ACL 与 ALB 关联。",
      "C": "将 ALB 访问日志存储在 Amazon S3 存储桶中。 配置 Amazon GuardDuty 以检测 DDoS 攻击并采取自动预防措施。",
      "D": "订阅 AWS Shield Advanced。 在 Route 53 中配置托管区域。 将 ALB 资源添加为受保护资源。"
    }
  },
  {
    "id": 928,
    "topic": "1",
    "question_en": "A company hosts a video streaming web application in a VPC. The company uses a Network Load Balancer (NLB) to handle TCP trafic for real-time data processing. There have been unauthorized attempts to access the application. The company wants to improve application security with minimal architectural change to prevent unauthorized attempts to access the application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement a series of AWS WAF rules directly on the NLB to filter out unauthorized trafic.",
      "B": "Recreate the NLB with a security group to allow only trusted IP addresses.",
      "C": "Deploy a second NLB in parallel with the existing NLB configured with a strict IP address allow list.",
      "D": "Use AWS Shield Advanced to provide enhanced DDoS protection and prevent unauthorized access attempts."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在 VPC 中托管视频流 Web 应用程序。该公司使用 Network Load Balancer (NLB) 来处理实时数据处理的 TCP 流量。 出现过未经授权访问该应用程序的尝试。该公司希望通过对架构进行最少的更改来提高应用程序安全性，以防止未经授权的访问尝试。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "直接在 NLB 上实施一系列 AWS WAF 规则以过滤掉未经授权的流量。",
      "B": "使用安全组重新创建 NLB，仅允许受信任的 IP 地址。",
      "C": "部署与现有 NLB 并行运行的第二个 NLB，配置严格的 IP 地址允许列表。",
      "D": "使用 AWS Shield Advanced 提供增强的 DDoS 保护并防止未经授权的访问尝试。"
    }
  },
  {
    "id": 929,
    "topic": "1",
    "question_en": "A healthcare company is developing an AWS Lambda function that publishes notifications to an encrypted Amazon Simple Notification Service (Amazon SNS) topic. The notifications contain protected health information (PHI). The SNS topic uses AWS Key Management Service (AWS KMS) customer managed keys for encryption. The company must ensure that the application has the necessary permissions to publish messages securely to the SNS topic. Which combination of steps will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Create a resource policy for the SNS topic that allows the Lambda function to publish messages to the topic.",
      "B": "Use server-side encryption with AWS KMS keys (SSE-KMS) for the SNS topic instead of customer managed keys.",
      "C": "Create a resource policy for the encryption key that the SNS topic uses that has the necessary AWS KMS permissions.",
      "D": "Specify the Lambda function's Amazon Resource Name (ARN) in the SNS topic's resource policy",
      "E": "Associate an Amazon API Gateway HTTP API with the SNS topic to control access to the topic by using API Gateway resource policies",
      "F": "Configure a Lambda execution role that has the necessary IAM permissions to use a customer managed key in AWS KMS."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家医疗保健公司正在开发一个 AWS Lambda 函数，该函数将通知发布到加密的 Amazon Simple Notification Service (Amazon SNS) 主题。通知包含受保护的健康信息 (PHI)。SNS 主题使用 AWS Key Management Service (AWS KMS) 客户托管密钥进行加密。该公司必须确保该应用程序具有将消息安全地发布到 SNS 主题的必要权限。哪种组合步骤将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "为 SNS 主题创建资源策略，允许 Lambda 函数将消息发布到该主题。",
      "B": "使用带有 AWS KMS 密钥的服务器端加密 (SSE-KMS) 来代替客户托管密钥加密 SNS 主题。",
      "C": "为 SNS 主题使用的加密密钥创建资源策略，该策略具有必要的 AWS KMS 权限。",
      "D": "在 SNS 主题的资源策略中指定 Lambda 函数的 Amazon 资源名称 (ARN)。",
      "E": "将 Amazon API Gateway HTTP API 与 SNS 主题关联，以使用 API Gateway 资源策略控制对该主题的访问。",
      "F": "配置 Lambda 执行角色，该角色具有使用 AWS KMS 中的客户托管密钥的必要 IAM 权限。"
    }
  },
  {
    "id": 930,
    "topic": "1",
    "question_en": "A company has an employee web portal. Employees log in to the portal to view payroll details. The company is developing a new system to give employees the ability to upload scanned documents for reimbursement. The company runs a program to extract text-based data from the documents and attach the extracted information to each employee’s reimbursement IDs for processing. The employee web portal requires 100% uptime. The document extract program runs infrequently throughout the day on an on-demand basis. The company wants to build a scalable and cost-effective new system that will require minimal changes to the existing web portal. The company does not want to make any code changes. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Run Amazon EC2 On-Demand Instances in an Auto Scaling group for the web portal. Use an AWS Lambda function to run the document extract program. Invoke the Lambda function when an employee uploads a new reimbursement document.",
      "B": "Run Amazon EC2 Spot Instances in an Auto Scaling group for the web portal. Run the document extract program on EC2 Spot Instances. Start document extract program instances when an employee uploads a new reimbursement document.",
      "C": "Purchase a Savings Plan to run the web portal and the document extract program. Run the web portal and the document extract program in an Auto Scaling group.",
      "D": "Create an Amazon S3 bucket to host the web portal. Use Amazon API Gateway and an AWS Lambda function for the existing functionalities. Use the Lambda function to run the document extract program. Invoke the Lambda function when the API that is associated with a new document upload is called."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司有一个员工 Web 门户。员工登录门户网站以查看工资单详细信息。该公司正在开发一个新系统，使员工能够上传扫描的文档以进行报销。该公司运行一个程序，从文档中提取基于文本的数据，并将提取的信息附加到每个员工的报销 ID，以便进行处理。员工 Web 门户需要 100% 的正常运行时间。文档提取程序在一天中不频繁地按需运行。该公司希望构建一个可扩展且具有成本效益的新系统，该系统需要对现有 Web 门户进行最少的更改。该公司不想进行任何代码更改。哪个解决方案将以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "在 Auto Scaling 组中运行 Amazon EC2 按需实例来运行 Web 门户。使用 AWS Lambda 函数运行文档提取程序。当员工上传新的报销文档时调用 Lambda 函数。",
      "B": "在 Auto Scaling 组中运行 Amazon EC2 Spot 实例来运行 Web 门户。在 EC2 Spot 实例上运行文档提取程序。当员工上传新的报销文档时，启动文档提取程序实例。",
      "C": "购买 Savings Plan 以运行 Web 门户和文档提取程序。在 Auto Scaling 组中运行 Web 门户和文档提取程序。",
      "D": "创建一个 Amazon S3 存储桶来托管 Web 门户。使用 Amazon API Gateway 和 AWS Lambda 函数来实现现有功能。使用 Lambda 函数运行文档提取程序。当调用与新文档上传关联的 API 时，调用 Lambda 函数。"
    }
  },
  {
    "id": 931,
    "topic": "1",
    "question_en": "A media company has a multi-account AWS environment in the us-east-1 Region. The company has an Amazon Simple Notification Service (Amazon SNS) topic in a production account that publishes performance metrics. The company has an AWS Lambda function in an administrator account to process and analyze log data. The Lambda function that is in the administrator account must be invoked by messages from the SNS topic that is in the production account when significant metrics are reported. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function.",
      "B": "Implement an Amazon Simple Queue Service (Amazon SQS) queue in the administrator account to buffer messages from the SNS topic that is in the production account. Configure the SQS queue to invoke the Lambda function.",
      "C": "Create an IAM policy for the SNS topic that allows the Lambda function to subscribe to the topic.",
      "D": "Use an Amazon EventBridge rule in the production account to capture the SNS topic notifications. Configure the EventBridge rule to forward notifications to the Lambda function that is in the administrator account",
      "E": "Store performance metrics in an Amazon S3 bucket in the production account. Use Amazon Athena to analyze the metrics from the administrator account."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家媒体公司在 us-east-1 区域有一个多账户 AWS 环境。该公司在生产账户中有一个 Amazon Simple Notification Service (Amazon SNS) 主题，用于发布性能指标。该公司在管理员账户中有一个 AWS Lambda 函数，用于处理和分析日志数据。当报告重要指标时，必须通过来自生产账户中的 SNS 主题的消息来调用管理员账户中的 Lambda 函数。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "为 Lambda 函数创建 IAM 资源策略，允许 Amazon SNS 调用该函数。",
      "B": "在管理员账户中实施一个 Amazon Simple Queue Service (Amazon SQS) 队列，以缓冲来自生产账户中 SNS 主题的消息。配置 SQS 队列以调用 Lambda 函数。",
      "C": "为 SNS 主题创建 IAM 策略，允许 Lambda 函数订阅该主题。",
      "D": "在生产账户中使用 Amazon EventBridge 规则来捕获 SNS 主题通知。配置 EventBridge 规则，将通知转发到管理员账户中的 Lambda 函数。",
      "E": "将性能指标存储在生产账户中的 Amazon S3 存储桶中。使用 Amazon Athena 从管理员账户分析这些指标。"
    }
  },
  {
    "id": 932,
    "topic": "1",
    "question_en": "A company is migrating an application from an on-premises location to Amazon Elastic Kubernetes Service (Amazon EKS). The company must use a custom subnet for pods that are in the company's VPC to comply with requirements. The company also needs to ensure that the pods can communicate securely within the pods' VPC. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure AWS Transit Gateway to directly manage custom subnet configurations for the pods in Amazon EKS.",
      "B": "Create an AWS Direct Connect connection from the company's on-premises IP address ranges to the EKS pods.",
      "C": "Use the Amazon VPC CNI plugin for Kubernetes. Define custom subnets in the VPC cluster for the pods to use.",
      "D": "Implement a Kubernetes network policy that has pod anti-afinity rules to restrict pod placement to specific nodes that are within custom subnets."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其应用程序从本地位置迁移到 Amazon Elastic Kubernetes Service (Amazon EKS)。该公司必须使用自定义子网，以便符合要求的 pod 位于公司的 VPC 中。该公司还需要确保 pod 可以在 pod 的 VPC 中安全地通信。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "配置 AWS Transit Gateway 以直接管理 Amazon EKS 中 pod 的自定义子网配置。",
      "B": "从公司的本地 IP 地址范围创建到 EKS pod 的 AWS Direct Connect 连接。",
      "C": "使用 Kubernetes 的 Amazon VPC CNI 插件。在 VPC 集群中为 pod 定义自定义子网以供使用。",
      "D": "实施 Kubernetes 网络策略，该策略具有 pod 反亲和性规则，以将 pod 放置限制为位于自定义子网内的特定节点。"
    }
  },
  {
    "id": 933,
    "topic": "1",
    "question_en": "A company hosts an ecommerce application that stores all data in a single Amazon RDS for MySQL DB instance that is fully managed by AWS. The company needs to mitigate the risk of a single point of failure. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Modify the RDS DB instance to use a Multi-AZ deployment. Apply the changes during the next maintenance window.",
      "B": "Migrate the current database to a new Amazon DynamoDB Multi-AZ deployment. Use AWS Database Migration Service (AWS DMS) with a heterogeneous migration strategy to migrate the current RDS DB instance to DynamoDB tables.",
      "C": "Create a new RDS DB instance in a Multi-AZ deployment. Manually restore the data from the existing RDS DB instance from the"
    },
    "correct_answer": "",
    "vote_percentage": "",
    "question_cn": "一家公司托管一个电子商务应用程序，该应用程序将所有数据存储在由 AWS 完全托管的单个 Amazon RDS for MySQL 数据库实例中。该公司需要减轻单点故障的风险。哪种解决方案以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "修改 RDS 数据库实例以使用多可用区部署。在下一次维护窗口期间应用更改。",
      "B": "将当前数据库迁移到新的 Amazon DynamoDB 多可用区部署。使用 AWS Database Migration Service (AWS DMS) 以及异构迁移策略将当前 RDS 数据库实例迁移到 DynamoDB 表。",
      "C": "在多可用区部署中创建一个新的 RDS 数据库实例。手动从现有 RDS 数据库实例还原数据。"
    }
  },
  {
    "id": 934,
    "topic": "1",
    "question_en": "A company has multiple Microsoft Windows SMB file servers and Linux NFS file servers for file sharing in an on-premises environment. As part of the company's AWS migration plan, the company wants to consolidate the file servers in the AWS Cloud. The company needs a managed AWS storage service that supports both NFS and SMB access. The solution must be able to share between protocols. The solution must have redundancy at the Availability Zone level. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon FSx for NetApp ONTAP for storage. Configure multi-protocol access.",
      "B": "Create two Amazon EC2 instances. Use one EC2 instance for Windows SMB file server access and one EC2 instance for Linux NFS file server access.",
      "C": "Use Amazon FSx for NetApp ONTAP for SMB access. Use Amazon FSx for Lustre for NFS access.",
      "D": "Use Amazon S3 storage. Access Amazon S3 through an Amazon S3 File Gateway."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在本地环境中拥有多个 Microsoft Windows SMB 文件服务器和 Linux NFS 文件服务器，用于文件共享。作为公司 AWS 迁移计划的一部分，该公司希望在 AWS 云中整合文件服务器。该公司需要一个托管的 AWS 存储服务，该服务支持 NFS 和 SMB 访问。该解决方案必须能够在协议之间共享。该解决方案必须在可用区级别具有冗余。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon FSx for NetApp ONTAP 进行存储。配置多协议访问。",
      "B": "创建两个 Amazon EC2 实例。使用一个 EC2 实例进行 Windows SMB 文件服务器访问，使用一个 EC2 实例进行 Linux NFS 文件服务器访问。",
      "C": "使用 Amazon FSx for NetApp ONTAP 进行 SMB 访问。使用 Amazon FSx for Lustre 进行 NFS 访问。",
      "D": "使用 Amazon S3 存储。通过 Amazon S3 File Gateway 访问 Amazon S3。"
    }
  },
  {
    "id": 935,
    "topic": "1",
    "question_en": "A software company needs to upgrade a critical web application. The application currently runs on a single Amazon EC2 instance that the company hosts in a public subnet. The EC2 instance runs a MySQL database. The application's DNS records are published in an Amazon Route 53 zone. A solutions architect must reconfigure the application to be scalable and highly available. The solutions architect must also reduce MySQL read latency. Which combination of solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Launch a second EC2 instance in a second AWS Region. Use a Route 53 failover routing policy to redirect the trafic to the second EC2 instance.",
      "B": "Create and configure an Auto Scaling group to launch private EC2 instances in multiple Availability Zones. Add the instances to a target group behind a new Application Load Balancer.",
      "C": "Migrate the database to an Amazon Aurora MySQL cluster. Create the primary DB instance and reader DB instance in separate Availability Zones.",
      "D": "Create and configure an Auto Scaling group to launch private EC2 instances in multiple AWS Regions. Add the instances to a target group behind a new Application Load Balancer",
      "E": "Migrate the database to an Amazon Aurora MySQL cluster with cross-Region read replicas."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家软件公司需要升级一个关键的 Web 应用程序。该应用程序目前在公司托管于一个公有子网中的单个 Amazon EC2 实例上运行。EC2 实例运行一个 MySQL 数据库。应用程序的 DNS 记录发布在 Amazon Route 53 区域中。解决方案架构师必须重新配置应用程序以实现可扩展性和高可用性。解决方案架构师还必须减少 MySQL 读取延迟。哪种解决方案组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在第二个 AWS 区域启动第二个 EC2 实例。使用 Route 53 故障转移路由策略将流量重定向到第二个 EC2 实例。",
      "B": "创建并配置一个 Auto Scaling 组，以在多个可用区启动私有 EC2 实例。将这些实例添加到新 Application Load Balancer 后面的目标组。",
      "C": "将数据库迁移到 Amazon Aurora MySQL 集群。在不同的可用区创建主数据库实例和读取数据库实例。",
      "D": "创建并配置一个 Auto Scaling 组，以在多个 AWS 区域启动私有 EC2 实例。将这些实例添加到新 Application Load Balancer 后面的目标组。",
      "E": "将数据库迁移到具有跨区域读取副本的 Amazon Aurora MySQL 集群。"
    }
  },
  {
    "id": 936,
    "topic": "1",
    "question_en": "A company runs thousands of AWS Lambda functions. The company needs a solution to securely store sensitive information that all the Lambda functions use. The solution must also manage the automatic rotation of the sensitive information. Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)",
    "options_en": {
      "A": "Create HTTP security headers by using Lambda@Edge to retrieve and create sensitive information",
      "B": "Create a Lambda layer that retrieves sensitive information",
      "C": "Store sensitive information in AWS Secrets Manager",
      "D": "Store sensitive information in AWS Systems Manager Parameter Store",
      "E": "Create a Lambda consumer with dedicated throughput to retrieve sensitive information and create environmental variables"
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司运行数千个 AWS Lambda 函数。该公司需要一个解决方案来安全地存储所有 Lambda 函数使用的敏感信息。该解决方案还必须管理敏感信息的自动轮换。哪两种步骤的组合将以最低的运营开销满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 Lambda@Edge 创建 HTTP 安全标头，以检索和创建敏感信息",
      "B": "创建一个 Lambda 层来检索敏感信息",
      "C": "将敏感信息存储在 AWS Secrets Manager 中",
      "D": "将敏感信息存储在 AWS Systems Manager Parameter Store 中",
      "E": "创建一个具有专用吞吐量的 Lambda consumer 来检索敏感信息并创建环境变量"
    }
  },
  {
    "id": 937,
    "topic": "1",
    "question_en": "A company has an internal application that runs on Amazon EC2 instances in an Auto Scaling group. The EC2 instances are compute optimized and use Amazon Elastic Block Store (Amazon EBS) volumes. The company wants to identify cost optimizations across the EC2 instances, the Auto Scaling group, and the EBS volumes. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Create a new AWS Cost and Usage Report. Search the report for cost recommendations for the EC2 instances the Auto Scaling group, and the EBS volumes.",
      "B": "Create new Amazon CloudWatch billing alerts. Check the alert statuses for cost recommendations for the EC2 instances, the Auto Scaling group, and the EBS volumes.",
      "C": "Configure AWS Compute Optimizer for cost recommendations for the EC2 instances, the Auto Scaling group and the EBS volumes.",
      "D": "Configure AWS Compute Optimizer for cost recommendations for the EC2 instances. Create a new AWS Cost and Usage Report. Search the report for cost recommendations for the Auto Scaling group and the EBS volumes."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司有一个内部应用程序，该应用程序在 Auto Scaling 组中的 Amazon EC2 实例上运行。EC2 实例是计算优化实例，并使用 Amazon Elastic Block Store (Amazon EBS) 卷。该公司希望确定 EC2 实例、Auto Scaling 组和 EBS 卷的成本优化。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 AWS 成本和使用情况报告。在报告中搜索 EC2 实例、Auto Scaling 组和 EBS 卷的成本建议。",
      "B": "创建新的 Amazon CloudWatch 账单警报。检查警报状态，以获取 EC2 实例、Auto Scaling 组和 EBS 卷的成本建议。",
      "C": "为 EC2 实例、Auto Scaling 组和 EBS 卷配置 AWS Compute Optimizer 以获取成本建议。",
      "D": "为 EC2 实例配置 AWS Compute Optimizer 以获取成本建议。创建一个新的 AWS 成本和使用情况报告。在报告中搜索 Auto Scaling 组和 EBS 卷的成本建议。"
    }
  },
  {
    "id": 938,
    "topic": "1",
    "question_en": "A company is running a media store across multiple Amazon EC2 instances distributed across multiple Availability Zones in a single VPC. The company wants a high-performing solution to share data between all the EC2 instances, and prefers to keep the data within the VPC only. What should a solutions architect recommend?",
    "options_en": {
      "A": "Create an Amazon S3 bucket and call the service APIs from each instance's application",
      "B": "Create an Amazon S3 bucket and configure all instances to access it as a mounted volume",
      "C": "Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances",
      "D": "Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances"
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在运营一个媒体商店，该商店分布在单个 VPC 中多个可用区中的多个 Amazon EC2 实例上。该公司希望有一个高性能的解决方案，以便在所有 EC2 实例之间共享数据，并且希望仅将数据保留在 VPC 内。解决方案架构师应该推荐什么？",
    "options_cn": {
      "A": "创建一个 Amazon S3 存储桶，并从每个实例的应用程序调用服务 API",
      "B": "创建一个 Amazon S3 存储桶，并将所有实例配置为将其作为已挂载的卷进行访问",
      "C": "配置一个 Amazon Elastic Block Store (Amazon EBS) 卷并在所有实例之间挂载它",
      "D": "配置一个 Amazon Elastic File System (Amazon EFS) 文件系统并在所有实例之间挂载它"
    }
  },
  {
    "id": 939,
    "topic": "1",
    "question_en": "A company uses an Amazon RDS for MySQL instance. To prepare for end-of-year processing, the company added a read replica to accommodate extra read-only queries from the company's reporting tool. The read replica CPU usage was 60% and the primary instance CPU usage was 60%. After end-of-year activities are complete, the read replica has a constant 25% CPU usage. The primary instance still has a constant 60% CPU usage. The company wants to rightsize the database and still provide enough performance for future growth. Which solution will meet these requirements?",
    "options_en": {
      "A": "Delete the read replica Do not make changes to the primary instance",
      "B": "Resize the read replica to a smaller instance size Do not make changes to the primary instance",
      "C": "Resize the read replica to a larger instance size Resize the primary instance to a smaller instance size",
      "D": "Delete the read replica Resize the primary instance to a larger instance"
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司使用 Amazon RDS for MySQL 实例。为了准备年终处理，该公司添加了一个只读副本以适应来自公司报告工具的额外只读查询。只读副本的 CPU 使用率为 60%，主实例的 CPU 使用率为 60%。年终活动完成后，只读副本的 CPU 使用率恒定为 25%。主实例的 CPU 使用率仍然恒定为 60%。公司希望调整数据库大小，同时仍然为未来的增长提供足够的性能。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "删除只读副本。不对主实例进行更改。",
      "B": "将只读副本调整为较小的实例大小。不对主实例进行更改。",
      "C": "将只读副本调整为更大的实例大小。将主实例调整为较小的实例大小。",
      "D": "删除只读副本。将主实例调整为更大的实例大小。"
    }
  },
  {
    "id": 940,
    "topic": "1",
    "question_en": "A company is migrating its databases to Amazon RDS for PostgreSQL. The company is migrating its applications to Amazon EC2 instances. The company wants to optimize costs for long-running workloads. Which solution will meet this requirement MOST cost-effectively?",
    "options_en": {
      "A": "Use On-Demand Instances for the Amazon RDS for PostgreSQL workloads. Purchase a 1 year Compute Savings Plan with the No Upfront option for the EC2 instances.",
      "B": "Purchase Reserved Instances for a 1 year term with the No Upfront option for the Amazon RDS for PostgreSQL workloads. Purchase a 1 year EC2 Instance Savings Plan with the No Upfront option for the EC2 instances.",
      "C": "Purchase Reserved Instances for a 1 year term with the Partial Upfront option for the Amazon RDS for PostgreSQL workloads. Purchase a 1 year EC2 Instance Savings Plan with the Partial Upfront option for the EC2 instances.",
      "D": "Purchase Reserved Instances for a 3 year term with the All Upfront option for the Amazon RDS for PostgreSQL workloads. Purchase a 3 year EC2 Instance Savings Plan with the All Upfront option for the EC2 instances."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其数据库迁移到 Amazon RDS for PostgreSQL。该公司正在将其应用程序迁移到 Amazon EC2 实例。该公司希望优化长期运行的工作负载的成本。哪个解决方案将以最具成本效益的方式满足此要求？",
    "options_cn": {
      "A": "将按需实例用于 Amazon RDS for PostgreSQL 工作负载。为 EC2 实例购买 1 年期计算节省计划，且无预付选项。",
      "B": "为 Amazon RDS for PostgreSQL 工作负载购买 1 年期预留实例，且无预付选项。为 EC2 实例购买 1 年期 EC2 实例节省计划，且无预付选项。",
      "C": "为 Amazon RDS for PostgreSQL 工作负载购买 1 年期预留实例，且部分预付选项。为 EC2 实例购买 1 年期 EC2 实例节省计划，且部分预付选项。",
      "D": "为 Amazon RDS for PostgreSQL 工作负载购买 3 年期预留实例，且全部预付选项。为 EC2 实例购买 3 年期 EC2 实例节省计划，且全部预付选项。"
    }
  },
  {
    "id": 941,
    "topic": "1",
    "question_en": "A company is using an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The company must ensure that Kubernetes service accounts in the EKS cluster have secure and granular access to specific AWS resources by using IAM roles for service accounts (IRSA). Which combination of solutions will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Create an IAM policy that defines the required permissions Attach the policy directly to the IAM role of the EKS nodes.",
      "B": "Implement network policies within the EKS cluster to prevent Kubernetes service accounts from accessing specific AWS services.",
      "C": "Modify the EKS cluster's IAM role to include permissions for each Kubernetes service account. Ensure a one-to-one mapping between IAM roles and Kubernetes roles.",
      "D": "Define an IAM role that includes the necessary permissions. Annotate the Kubernetes service accounts with the Amazon ResourceName (ARN) of the IAM rol",
      "E": "E. Set up a trust relationship between the IAM roles for the service accounts and an OpenID Connect (OIDC) identity provider."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在使用 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。该公司必须确保 EKS 集群中的 Kubernetes 服务账户通过使用 IAM 角色进行服务账户 (IRSA) 对特定的 AWS 资源具有安全且细粒度的访问权限。哪种解决方案组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "创建一个定义所需权限的 IAM 策略。将该策略直接附加到 EKS 节点的 IAM 角色。",
      "B": "在 EKS 集群内实施网络策略，以防止 Kubernetes 服务账户访问特定的 AWS 服务。",
      "C": "修改 EKS 集群的 IAM 角色，以包括每个 Kubernetes 服务账户的权限。确保 IAM 角色和 Kubernetes 角色之间存在一对一的映射。",
      "D": "定义一个包含必要权限的 IAM 角色。使用 IAM 角色的 Amazon 资源名称 (ARN) 注释 Kubernetes 服务账户。",
      "E": "在服务账户的 IAM 角色和 OpenID Connect (OIDC) 身份提供商之间建立信任关系。"
    }
  },
  {
    "id": 942,
    "topic": "1",
    "question_en": "A company regularly uploads confidential data to Amazon S3 buckets for analysis. The company's security policies mandate that the objects must be encrypted at rest. The company must automatically rotate the encryption key every year. The company must be able to track key rotation by using AWS CloudTrail. The company also must minimize costs for the encryption key. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use server-side encryption with customer-provided keys (SSE-C)",
      "B": "Use server-side encryption with Amazon S3 managed keys (SSE-S3)",
      "C": "Use server-side encryption with AWS KMS keys (SSE-KMS)",
      "D": "Use server-side encryption with customer managed AWS KMS keys"
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司定期将机密数据上传到 Amazon S3 存储桶以进行分析。该公司的安全策略规定，对象必须静态加密。公司必须每年自动轮换加密密钥。公司还必须能够通过使用 AWS CloudTrail 来跟踪密钥轮换。该公司还必须最大限度地降低加密密钥的成本。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用客户提供的密钥 (SSE-C) 进行服务器端加密",
      "B": "使用 Amazon S3 托管密钥 (SSE-S3) 进行服务器端加密",
      "C": "使用 AWS KMS 密钥 (SSE-KMS) 进行服务器端加密",
      "D": "使用客户管理的 AWS KMS 密钥进行服务器端加密"
    }
  },
  {
    "id": 943,
    "topic": "1",
    "question_en": "A company has migrated several applications to AWS in the past 3 months. The company wants to know the breakdown of costs for each of these applications. The company wants to receive a regular report that includes this information. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Use AWS Budgets to download data for the past 3 months into a .csv file. Look up the desired information.",
      "B": "Load AWS Cost and Usage Reports into an Amazon RDS DB instance. Run SQL queries to get the desired information.",
      "C": "Tag all the AWS resources with a key for cost and a value of the application's name. Activate cost allocation tags. Use Cost Explorerto get the desired information.",
      "D": "Tag all the AWS resources with a key for cost and a value of the application's name. Use the AWS Billing and Cost Management console todownload bills for the past 3 months. Look up the desired information."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在过去 3 个月内将几个应用程序迁移到了 AWS。该公司想了解每个应用程序的成本细分。该公司希望定期收到一份包含此信息的报告。哪种解决方案可以最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Budgets 将过去 3 个月的数据下载到 .csv 文件中。查找所需信息。",
      "B": "将 AWS 成本和使用情况报告加载到 Amazon RDS 数据库实例中。运行 SQL 查询以获取所需信息。",
      "C": "使用成本键和应用程序名称值标记所有 AWS 资源。激活成本分配标签。使用 Cost Explorer 获取所需信息。",
      "D": "使用成本键和应用程序名称值标记所有 AWS 资源。使用 AWS 账单和成本管理控制台下载过去 3 个月的账单。查找所需信息。"
    }
  },
  {
    "id": 944,
    "topic": "1",
    "question_en": "An ecommerce company is preparing to deploy a web application on AWS to ensure continuous service for customers. The architecture includes a web application that the company hosts on Amazon EC2 instances, a relational database in Amazon RDS, and static assets that the company stores in Amazon S3. The company wants to design a robust and resilient architecture for the application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy Amazon EC2 instances in a single Availability Zone. Deploy an RDS DB instance in the same Availability Zone. Use Amazon S3 with versioning enabled to store static assets.",
      "B": "Deploy Amazon EC2 instances in an Auto Scaling group across multiple Availability Zones. Deploy a Multi-AZ RDS DB instance. Use Amazon CloudFront to distribute static assets.",
      "C": "Deploy Amazon EC2 instances in a single Availability Zone. Deploy an RDS DB instance in a second Availability Zone for cross-AZ redundancy. Serve static assets directly from the EC2 instances.",
      "D": "Use AWS Lambda functions to serve the web application. Use Amazon Aurora Serverless v2 for the database. Store static assets in Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA)."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家电子商务公司正准备在 AWS 上部署一个 Web 应用程序，以确保为客户提供持续服务。该架构包括该公司托管在 Amazon EC2 实例上的 Web 应用程序，Amazon RDS 中的关系数据库，以及该公司存储在 Amazon S3 中的静态资产。该公司希望为该应用程序设计一个强大且有弹性的架构。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在单个可用区中部署 Amazon EC2 实例。 在同一可用区中部署 RDS 数据库实例。 使用启用版本控制的 Amazon S3 存储静态资产。",
      "B": "将 Amazon EC2 实例部署在跨多个可用区的 Auto Scaling 组中。 部署 Multi-AZ RDS 数据库实例。 使用 Amazon CloudFront 分发静态资产。",
      "C": "在单个可用区中部署 Amazon EC2 实例。 将 RDS 数据库实例部署在第二个可用区中，以实现跨可用区冗余。 直接从 EC2 实例提供静态资产。",
      "D": "使用 AWS Lambda 函数来提供 Web 应用程序。 将 Amazon Aurora Serverless v2 用于数据库。 将静态资产存储在 Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA) 中。"
    }
  },
  {
    "id": 945,
    "topic": "1",
    "question_en": "An ecommerce company runs several internal applications in multiple AWS accounts. The company uses AWS Organizations to manage its AWS accounts. A security appliance in the company's networking account must inspect interactions between applications across AWS accounts. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy a Network Load Balancer (NLB) in the networking account to send trafic to the security appliance. Configure the application accounts to send trafic to the NLB by using an interface VPC endpoint in the application accounts.",
      "B": "Deploy an Application Load Balancer (ALB) in the application accounts to send trafic directly to the security appliance.",
      "C": "Deploy a Gateway Load Balancer (GWLB) in the networking account to send trafic to the security appliance. Configure the application accounts to send trafic to the GWLB by using an interface GWLB endpoint in the application accounts.",
      "D": "Deploy an interface VPC endpoint in the application accounts to send trafic directly to the security appliance."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家电子商务公司在多个 AWS 账户中运行几个内部应用程序。该公司使用 AWS Organizations 来管理其 AWS 账户。该公司网络账户中的一个安全设备必须检查跨 AWS 账户的应用程序之间的交互。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在网络账户中部署一个 Network Load Balancer (NLB) 以将流量发送到安全设备。 配置应用程序账户，通过在应用程序账户中使用接口 VPC endpoint 将流量发送到 NLB。",
      "B": "在应用程序账户中部署一个 Application Load Balancer (ALB) 以将流量直接发送到安全设备。",
      "C": "在网络账户中部署一个 Gateway Load Balancer (GWLB) 以将流量发送到安全设备。配置应用程序账户，通过在应用程序账户中使用接口 GWLB endpoint 将流量发送到 GWLB。",
      "D": "在应用程序账户中部署一个接口 VPC endpoint 以将流量直接发送到安全设备。"
    }
  },
  {
    "id": 946,
    "topic": "1",
    "question_en": "A company runs its production workload on an Amazon Aurora MySQL DB cluster that includes six Aurora Replicas. The company wants near- real-time reporting queries from one of its departments to be automatically distributed across three of the Aurora Replicas. Those three replicas have a different compute and memory specification from the rest of the DB cluster. Which solution meets these requirements?",
    "options_en": {
      "A": "Create and use a custom endpoint for the workload",
      "B": "Create a three-node cluster clone and use the reader endpoint",
      "C": "Use any of the instance endpoints for the selected three nodes",
      "D": "Use the reader endpoint to automatically distribute the read-only workload"
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在其 Amazon Aurora MySQL 数据库集群上运行其生产工作负载，该集群包括六个 Aurora 副本。该公司希望其中一个部门的近实时报告查询自动分布在其中三个 Aurora 副本上。这三个副本与数据库集群的其余部分具有不同的计算和内存规格。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "为工作负载创建并使用自定义端点",
      "B": "创建三节点集群克隆并使用读取器端点",
      "C": "使用所选三个节点的任何实例端点",
      "D": "使用读取器端点自动分配只读工作负载"
    }
  },
  {
    "id": 947,
    "topic": "1",
    "question_en": "A company runs a Node js function on a server in its on-premises data center. The data center stores data in a PostgreSQL database. The company stores the credentials in a connection string in an environment variable on the server. The company wants to migrate its application to AWS and to replace the Node.js application server with AWS Lambda. The company also wants to migrate to Amazon RDS for PostgreSQL and to ensure that the database credentials are securely managed. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the database credentials as a parameter in AWS Systems Manager Parameter Store Configure Parameter Store to automatically rotate the secrets every 30 days. Update the Lambda function to retrieve the credentials from the parameter.",
      "B": "Store the database credentials as a secret in AWS Secrets Manager. Configure Secrets Manager to automatically rotate the credentials every 30 days. Update the Lambda function to retrieve the credentials from the secret.",
      "C": "Store the database credentials as an encrypted Lambda environment variable. Write a custom Lambda function to rotate the credentials. Schedule the Lambda function to run every 30 days.",
      "D": "Store the database credentials as a key in AWS Key Management Service (AWS KMS). Configure automatic rotation for the key. Update the Lambda function to retneve the credentials from the KMS key."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在其本地数据中心的一台服务器上运行 Node.js 函数。 数据中心将数据存储在 PostgreSQL 数据库中。该公司将凭证存储在服务器上环境变量中的连接字符串中。该公司希望将其应用程序迁移到 AWS，并将 Node.js 应用程序服务器替换为 AWS Lambda。该公司还希望迁移到 Amazon RDS for PostgreSQL，并确保安全地管理数据库凭证。哪种解决方案能够以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "将数据库凭证存储为 AWS Systems Manager Parameter Store 中的一个参数。 配置 Parameter Store，以便每 30 天自动轮换密钥。更新 Lambda 函数以从参数中检索凭证。",
      "B": "将数据库凭证存储为 AWS Secrets Manager 中的一个密钥。 配置 Secrets Manager 以每 30 天自动轮换凭证。更新 Lambda 函数以从密钥中检索凭证。",
      "C": "将数据库凭证存储为加密的 Lambda 环境变量。编写一个自定义 Lambda 函数来轮换凭证。计划 Lambda 函数每 30 天运行一次。",
      "D": "将数据库凭证存储为 AWS Key Management Service (AWS KMS) 中的一个密钥。 配置密钥的自动轮换。更新 Lambda 函数以从 KMS 密钥中检索凭证。"
    }
  },
  {
    "id": 948,
    "topic": "1",
    "question_en": "A company wants to replicate existing and ongoing data changes from an on-premises Oracle database to Amazon RDS for Oracle. The amount of data to replicate varies throughout each day. The company wants to use AWS Database Migration Service (AWS DMS) for data replication. The solution must allocate only the capacity that the replication instance requires. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the AWS DMS replication instance with a Multi-AZ deployment to provision instances across multiple Availability Zones.",
      "B": "Create an AWS DMS Serverless replication task to analyze and replicate the data while provisioning the required capacity.",
      "C": "Use Amazon EC2 Auto Scaling to scale the size of the AWS DMS replication instance up or down based on the amount of data toreplicate.",
      "D": "Provision AWS DMS replication capacity by using Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type to analyze and replicate the data while provisioning the required capacity."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将现有数据和正在进行的更改从本地 Oracle 数据库复制到 Amazon RDS for Oracle。 每天需要复制的数据量有所不同。 公司希望使用 AWS Database Migration Service (AWS DMS) 进行数据复制。 该解决方案必须仅分配复制实例所需的容量。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将 AWS DMS 复制实例配置为 Multi-AZ 部署，以便跨多个可用区预置实例。",
      "B": "创建 AWS DMS Serverless 复制任务以分析和复制数据，同时预置所需的容量。",
      "C": "使用 Amazon EC2 Auto Scaling 根据要复制的数据量来扩展或缩减 AWS DMS 复制实例的大小。",
      "D": "通过使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate 启动类型来预置 AWS DMS 复制容量，以分析和复制数据，同时预置所需的容量。"
    }
  },
  {
    "id": 949,
    "topic": "1",
    "question_en": "A company has a multi-tier web application. The application's internal service components are deployed on Amazon EC2 instances. The internal service components need to access third-party software as a service (SaaS) APIs that are hosted on AWS. The company needs to provide secure and private connectivity from the application's internal services to the third-party SaaS application. The company needs to ensure that there is minimal public internet exposure. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement an AWS Site-to-Site VPN to establish a secure connection with the third-party SaaS provider.",
      "B": "Deploy AWS Transit Gateway to manage and route trafic between the application's VPC and the third-party SaaS provider.",
      "C": "Configure AWS PrivateLink to allow only outbound trafic from the VPC without enabling the third-party SaaS provider to establish.",
      "D": "Use AWS PrivateLink to create a private connection between the application's VPC and the third-party SaaS provider."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一家公司拥有一个多层 Web 应用程序。 应用程序的内部服务组件部署在 Amazon EC2 实例上。 内部服务组件需要访问托管在 AWS 上的第三方软件即服务 (SaaS) API。该公司需要为应用程序的内部服务到第三方 SaaS 应用程序提供安全且私密的连接。该公司需要确保将公共 Internet 暴露降到最低。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "实施 AWS Site-to-Site VPN 以建立与第三方 SaaS 提供商的安全连接。",
      "B": "部署 AWS Transit Gateway 来管理和路由应用程序的 VPC 和第三方 SaaS 提供商之间的流量。",
      "C": "配置 AWS PrivateLink 以仅允许从 VPC 传出的流量，而无需第三方 SaaS 提供商建立连接。",
      "D": "使用 AWS PrivateLink 在应用程序的 VPC 和第三方 SaaS 提供商之间创建私有连接。"
    }
  },
  {
    "id": 950,
    "topic": "1",
    "question_en": "A solutions architect needs to connect a company's corporate network to its VPC to allow on-premises access to its AWS resources. The solution must provide encryption of all trafic between the corporate network and the VPC at the network layer and the session layer. The solution also must provide security controls to prevent unrestricted access between AWS and the on-premises systems. Which solution meets these requirements?",
    "options_en": {
      "A": "Configure AWS Direct Connect to connect to the VPC. Configure the VPC route tables to allow and deny trafic between AWS and on premises as required.",
      "B": "Create an IAM policy to allow access to the AWS Management Console only from a defined set of corporate IP addresses. Restrict user access based on job responsibility by using an IAM policy and roles.",
      "C": "Configure AWS Site-to-Site VPN to connect to the VPConfigure route table entries to direct trafic from on premises to the VPConfigure instance security groups and network ACLs to allow only required trafic from on premises.",
      "D": "Configure AWS Transit Gateway to connect to the VPC. Configure route table entries to direct trafic from on premises to the VPC. Configure instance security groups and network ACLs to allow only required trafic from on premises."
    },
    "correct_answer": "D",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师需要将公司的企业网络连接到其 VPC，以允许本地访问其 AWS 资源。该解决方案必须在网络层和会话层对企业网络和 VPC 之间的所有流量进行加密。该解决方案还必须提供安全控制，以防止 AWS 和本地系统之间不受限制的访问。哪个解决方案满足这些要求？",
    "options_cn": {
      "A": "配置 AWS Direct Connect 以连接到 VPC。配置 VPC 路由表以根据需要允许和拒绝 AWS 和本地之间的流量。",
      "B": "创建一个 IAM 策略，仅允许从一组已定义的 corporate IP 地址访问 AWS 管理控制台。使用 IAM 策略和角色根据工作职责限制用户访问。",
      "C": "配置 AWS Site-to-Site VPN 以连接到 VPC。配置路由表条目以将流量从本地定向到 VPC。配置实例安全组和网络 ACL，仅允许来自本地的所需流量。",
      "D": "配置 AWS Transit Gateway 以连接到 VPC。配置路由表条目以将流量从本地定向到 VPC。配置实例安全组和网络 ACL，仅允许来自本地的所需流量。"
    }
  },
  {
    "id": 951,
    "topic": "1",
    "question_en": "A company has a custom application with embedded credentials that retrieves information from a database in an Amazon RDS for MySQL DB cluster. The company needs to make the application more secure with minimal programming effort. The company has created credentials on the RDS for MySQL database for the application user. Which solution will meet these requirements?",
    "options_en": {
      "A": "Store the credentials in AWS Key Management Service (AWS KMS). Create keys in AWS KMS. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation",
      "B": "Store the credentials in encrypted local storage. Configure the application to load the database credentials from the local storage. Set up a credentials rotation schedule by creating a cron job.",
      "C": "Store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule by creating an AWS Lambda function for Secrets Manager.",
      "D": "Store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule in the RDS for MySQL database by using Parameter Store."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司有一个自定义应用程序，其中嵌入了凭证，用于从 Amazon RDS for MySQL DB 集群中的数据库检索信息。该公司需要通过最少的编程工作来提高应用程序的安全性。该公司已为应用程序用户在 RDS for MySQL 数据库上创建了凭证。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将凭证存储在 AWS Key Management Service (AWS KMS) 中。在 AWS KMS 中创建密钥。将应用程序配置为从 AWS KMS 加载数据库凭证。启用自动密钥轮换",
      "B": "将凭证存储在加密的本地存储中。将应用程序配置为从本地存储加载数据库凭证。通过创建 cron 作业来设置凭证轮换计划。",
      "C": "将凭证存储在 AWS Secrets Manager 中。将应用程序配置为从 Secrets Manager 加载数据库凭证。通过为 Secrets Manager 创建一个 AWS Lambda 函数来设置凭证轮换计划。",
      "D": "将凭证存储在 AWS Systems Manager Parameter Store 中。将应用程序配置为从 Parameter Store 加载数据库凭证。通过使用 Parameter Store 在 RDS for MySQL 数据库中设置凭证轮换计划。"
    }
  },
  {
    "id": 952,
    "topic": "1",
    "question_en": "A company wants to move its application to a serverless solution. The serverless solution needs to analyze existing data and new data by using SQL. The company stores the data in an Amazon S3 bucket. The data must be encrypted at rest and replicated to a different AWS Region. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a new S3 bucket that uses server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Configure Cross-Region Replication (CRR). Load the data into the new S3 bucket. Use Amazon Athena to query the data.",
      "B": "Create a new S3 bucket that uses server-side encryption with Amazon S3 managed keys (SSE-S3). Configure Cross-Region Replication (CRR). Load the data into the new S3 bucket. Use Amazon RDS to query the data.",
      "C": "Configure Cross-Region Replication (CRR) on the existing S3 bucket. Use server-side encryption with Amazon S3 managed keys (SSE-S3). Use Amazon Athena to query the data.",
      "D": "Configure S3 Cross-Region Replication (CRR) on the existing S3 bucket. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一家公司希望将其应用程序迁移到无服务器解决方案。该无服务器解决方案需要使用 SQL 分析现有数据和新数据。该公司将数据存储在 Amazon S3 存储桶中。数据必须静态加密并复制到不同的 AWS 区域。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个新的 S3 存储桶，该存储桶使用带有 AWS KMS 多区域密钥（SSE-KMS）的服务器端加密。配置 跨区域复制 (CRR)。将数据加载到新的 S3 存储桶中。使用 Amazon Athena 查询数据。",
      "B": "创建一个新的 S3 存储桶，该存储桶使用带有 Amazon S3 托管密钥（SSE-S3）的服务器端加密。配置 跨区域复制 (CRR)。将数据加载到新的 S3 存储桶中。使用 Amazon RDS 查询数据。",
      "C": "在现有的 S3 存储桶上配置 跨区域复制 (CRR)。使用带有 Amazon S3 托管密钥（SSE-S3）的服务器端加密。使用 Amazon Athena 查询数据。",
      "D": "在现有的 S3 存储桶上配置 S3 跨区域复制 (CRR)。使用带有 AWS KMS 多区域密钥（SSE-KMS）的服务器端加密。使用 Amazon RDS 查询数据。"
    }
  },
  {
    "id": 953,
    "topic": "1",
    "question_en": "A company has a web application that has thousands of users. The application uses 8-10 user-uploaded images to generate AI images. Users can download the generated AI images once every 6 hours. The company also has a premium user option that gives users the ability to download the generated AI images anytime. The company uses the user-uploaded images to run AI model training twice a year. The company needs a storage solution to store the images. Which storage solution meets these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Move uploaded images to Amazon S3 Glacier Deep Archive. Move premium user-generated AI images to S3 Standard. Move non- premium user-generated AI images to S3 Standard-Infrequent Access (S3 Standard-IA).",
      "B": "Move uploaded images to Amazon S3 Glacier Deep Archive Move all generated AI images to S3 Glacier Flexible Retrieval.",
      "C": "Move uploaded images to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). Move premium user-generated AI images to S3 Standard. Move non-premium user-generated AI images to S3 Standard-Infrequent Access (S3 Standard-IA).",
      "D": "Move uploaded images to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). Move all generated AI images to S3 Glacier Flexible Retrieval."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司有一个拥有数千用户的 Web 应用程序。 该应用程序使用 8-10 个用户上传的图像来生成 AI 图像。 用户每 6 小时可以下载一次生成的 AI 图像。该公司还有一个高级用户选项，该选项允许用户随时下载生成的 AI 图像。该公司使用用户上传的图像每年运行两次 AI 模型训练。该公司需要一个存储解决方案来存储这些图像。哪个存储解决方案能最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "将上传的图像移动到 Amazon S3 Glacier Deep Archive。将高级用户生成的 AI 图像移动到 S3 Standard。将非高级用户生成的 AI 图像移动到 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "B": "将上传的图像移动到 Amazon S3 Glacier Deep Archive。将所有生成的 AI 图像移动到 S3 Glacier Flexible Retrieval。",
      "C": "将上传的图像移动到 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)。将高级用户生成的 AI 图像移动到 S3 Standard。将非高级用户生成的 AI 图像移动到 S3 Standard-Infrequent Access (S3 Standard-IA)。",
      "D": "将上传的图像移动到 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)。将所有生成的 AI 图像移动到 S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 954,
    "topic": "1",
    "question_en": "A company is developing machine learning (ML) models on AWS. The company is developing the ML models as independent microservices. The microservices fetch approximately 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the ML models through an asynchronous API. Users can send a request or a batch of requests. The company provides the ML models to hundreds of users. The usage patterns for the models are irregular. Some models are not used for days or weeks. Other models receive batches of thousands of requests at a time. Which solution will meet these requirements?",
    "options_en": {
      "A": "Direct the requests from the API to a Network Load Balancer (NLB). Deploy the ML models as AWS Lambda functions that the NLB will invoke. Use auto scaling to scale the Lambda functions based on the trafic that the NLB receives.",
      "B": "Direct the requests from the API to an Application Load Balancer (ALB). Deploy the ML models as Amazon Elastic Container Service (Amazon ECS) services that the ALB will invoke. Use auto scaling to scale the ECS cluster instances based on the trafic that the ALB receives.",
      "C": "Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the ML models as AWS Lambda functions that SQS events will invoke. Use auto scaling to increase the number of vCPUs for the Lambda functions based on the size of the SQS queue.",
      "D": "Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the ML models as Amazon Elastic Container Service (Amazon ECS) services that read from the queue. Use auto scaling for Amazon ECS to scale both the cluster capacity and number of the services based on the size of the SQS queue."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上开发机器学习 (ML) 模型。该公司将 ML 模型开发为独立的微服务。这些微服务在启动时从 Amazon S3 获取大约 1 GB 的模型数据，并将数据加载到内存中。用户通过异步 API 访问 ML 模型。用户可以发送一个请求或一批请求。该公司向数百个用户提供 ML 模型。这些模型的使用模式是不规则的。有些模型几天或几周未使用。其他模型一次接收数千个请求的批处理。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "将来自 API 的请求定向到 Network Load Balancer (NLB)。将 ML 模型部署为 AWS Lambda 函数，NLB 将调用这些函数。根据 NLB 接收的流量使用自动伸缩来扩展 Lambda 函数。",
      "B": "将来自 API 的请求定向到 Application Load Balancer (ALB)。将 ML 模型部署为 Amazon Elastic Container Service (Amazon ECS) 服务，ALB 将调用这些服务。根据 ALB 接收的流量使用自动伸缩来扩展 ECS 集群实例。",
      "C": "将来自 API 的请求定向到 Amazon Simple Queue Service (Amazon SQS) 队列。将 ML 模型部署为 AWS Lambda 函数，SQS 事件将调用这些函数。使用自动伸缩根据 SQS 队列的大小来增加 Lambda 函数的 vCPU 数量。",
      "D": "将来自 API 的请求定向到 Amazon Simple Queue Service (Amazon SQS) 队列。将 ML 模型部署为 Amazon Elastic Container Service (Amazon ECS) 服务，这些服务从队列中读取数据。对 Amazon ECS 使用自动伸缩，以根据 SQS 队列的大小来扩展集群容量和服务的数量。"
    }
  },
  {
    "id": 955,
    "topic": "1",
    "question_en": "A company runs a web application on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). The application stores data in an Amazon Aurora MySQL DB cluster. The company needs to create a disaster recovery (DR) solution. The acceptable recovery time for the DR solution is up to 30 minutes. The DR solution does not need to support customer usage when the primary infrastructure is healthy. Which solution will meet these requirements?",
    "options_en": {
      "A": "Deploy the DR infrastructure in a second AWS Region with an ALB and an Auto Scaling group. Set the desired capacity and maximum capacity of the Auto Scaling group to a minimum value. Convert the Aurora MySQL DB cluster to an Aurora global database. Configure Amazon Route 53 for an active-passive failover with ALB endpoints.",
      "B": "Deploy the DR infrastructure in a second AWS Region with an ALUpdate the Auto Scaling group to include EC2 instances from the second Region. Use Amazon Route 53 to configure active-active failover. Convert the Aurora MySQL DB cluster to an Aurora global database.",
      "C": "Back up the Aurora MySQL DB cluster data by using AWS Backup. Deploy the DR infrastructure in a second AWS Region with an ALB. Update the Auto Scaling group to include EC2 instances from the second Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora MySQL DB cluster in the second Region Restore the data from the backup.",
      "D": "Back up the infrastructure configuration by using AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Set the Auto Scaling group desired capacity to zero. Use Amazon Route 53 to configure active-passive failover. Convert the Aurora MySQL DB cluster to an Aurora global database."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在其Application Load Balancer (ALB) 之后，在Auto Scaling组中的Amazon EC2实例上运行Web应用程序。该应用程序将数据存储在Amazon Aurora MySQL数据库集群中。该公司需要创建一个灾难恢复（DR）解决方案。DR解决方案的可接受恢复时间最长为30分钟。当主基础设施运行正常时，DR解决方案不需要支持客户使用。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在第二个AWS区域中部署DR基础设施，其中包含一个ALB和一个Auto Scaling组。将Auto Scaling组的所需容量和最大容量设置为最小值。将Aurora MySQL数据库集群转换为Aurora全局数据库。配置Amazon Route 53以进行主动-被动故障转移，使用ALB端点。",
      "B": "在第二个AWS区域中部署DR基础设施，其中包含一个ALB。更新Auto Scaling组以包含来自第二个区域的EC2实例。使用Amazon Route 53配置主动-主动故障转移。将Aurora MySQL数据库集群转换为Aurora全局数据库。",
      "C": "使用AWS Backup备份Aurora MySQL数据库集群数据。在第二个AWS区域中部署DR基础设施，其中包含一个ALB。更新Auto Scaling组以包含来自第二个区域的EC2实例。使用Amazon Route 53配置主动-主动故障转移。在第二个区域中创建Aurora MySQL数据库集群。从备份中恢复数据。",
      "D": "使用AWS Backup备份基础设施配置。使用备份在第二个AWS区域中创建所需的基础设施。将Auto Scaling组的所需容量设置为零。使用Amazon Route 53配置主动-被动故障转移。将Aurora MySQL数据库集群转换为Aurora全局数据库。"
    }
  },
  {
    "id": 956,
    "topic": "1",
    "question_en": "A company is migrating its data processing application to the AWS Cloud. The application processes several short-lived batch jobs that cannot be disrupted. Data is generated after each batch job is completed. The data is accessed for 30 days and retained for 2 years. The company wants to keep the cost of running the application in the AWS Cloud as low as possible. Which solution will meet these requirements?",
    "options_en": {
      "A": "Migrate the data processing application to Amazon EC2 Spot Instances. Store the data in Amazon S3 Standard. Move the data to Amazon S3 Glacier Instant. Retrieval after 30 days. Set an expiration to delete the data after 2 years.",
      "B": "Migrate the data processing application to Amazon EC2 On-Demand Instances. Store the data in Amazon S3 Glacier Instant Retrieval. Move the data to S3 Glacier Deep Archive after 30 days. Set an expiration to delete the data after 2 years.",
      "C": "Deploy Amazon EC2 Spot Instances to run the batch jobs. Store the data in Amazon S3 Standard. Move the data to Amazon S3 Glacier Flexible Retrieval after 30 days. Set an expiration to delete the data after 2 years.",
      "D": "Deploy Amazon EC2 On-Demand Instances to run the batch jobs. Store the data in Amazon S3 Standard. Move the data to Amazon S3 Glacier Deep Archive after 30 days. Set an expiration to delete the data after 2 years."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其数据处理应用程序迁移到 AWS 云。该应用程序处理几个短期的批处理作业，这些作业不能中断。在每个批处理作业完成后，都会生成数据。数据可访问 30 天，并保留 2 年。该公司希望尽可能降低在 AWS 云中运行应用程序的成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "将数据处理应用程序迁移到 Amazon EC2 Spot Instances。将数据存储在 Amazon S3 Standard 中。将数据移动到 Amazon S3 Glacier Instant。30 天后检索。设置到期时间，在 2 年后删除数据。",
      "B": "将数据处理应用程序迁移到 Amazon EC2 On-Demand Instances。将数据存储在 Amazon S3 Glacier Instant Retrieval 中。30 天后将数据移动到 S3 Glacier Deep Archive。设置到期时间，在 2 年后删除数据。",
      "C": "部署 Amazon EC2 Spot Instances 以运行批处理作业。将数据存储在 Amazon S3 Standard 中。30 天后将数据移动到 Amazon S3 Glacier Flexible Retrieval。设置到期时间，在 2 年后删除数据。",
      "D": "部署 Amazon EC2 On-Demand Instances 以运行批处理作业。将数据存储在 Amazon S3 Standard 中。30 天后将数据移动到 Amazon S3 Glacier Deep Archive。设置到期时间，在 2 年后删除数据。"
    }
  },
  {
    "id": 957,
    "topic": "1",
    "question_en": "A company needs to design a hybrid network architecture. The company's workloads are currently stored in the AWS Cloud and in on-premises data centers. The workloads require single-digit latencies to communicate. The company uses an AWS Transit Gateway transit gateway to connect multiple VPCs. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Establish an AWS Site-to-Site VPN connection to each VPC.",
      "B": "Associate an AWS Direct Connect gateway with the transit gateway that is attached to the VPCs.",
      "C": "Establish an AWS Site-to-Site VPN connection to an AWS Direct Connect gateway.",
      "D": "Establish an AWS Direct Connect connection. Create a transit virtual interface (VIF) to a Direct Connect gateway",
      "E": "Associate AWS Site-to-Site VPN connections with the transit gateway that is attached to the VPCs."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司需要设计混合网络架构。该公司的负载目前存储在 AWS 云和本地数据中心中。这些负载需要个位数的延迟才能进行通信。该公司使用 AWS Transit Gateway 传输网关连接多个 VPC。哪两种步骤的组合将以最具成本效益的方式满足这些要求？（选择两项。）",
    "options_cn": {
      "A": "建立到每个 VPC 的 AWS Site-to-Site VPN 连接。",
      "B": "将 AWS Direct Connect 网关与附加到 VPC 的传输网关关联。",
      "C": "建立到 AWS Direct Connect 网关的 AWS Site-to-Site VPN 连接。",
      "D": "建立 AWS Direct Connect 连接。创建一个到 Direct Connect 网关的传输虚拟接口 (VIF)。",
      "E": "将 AWS Site-to-Site VPN 连接与附加到 VPC 的传输网关关联。"
    }
  },
  {
    "id": 958,
    "topic": "1",
    "question_en": "A global ecommerce company runs its critical workloads on AWS. The workloads use an Amazon RDS for PostgreSQL DB instance that is configured for a Multi-AZ deployment. Customers have reported application timeouts when the company undergoes database failovers. The company needs a resilient solution to reduce failover time. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon RDS Proxy. Assign the proxy to the DB instance.",
      "B": "Create a read replica for the DB instance. Move the read trafic to the read replica.",
      "C": "Enable Performance Insights. Monitor the CPU load to identify the timeouts.",
      "D": "Take regular automatic snapshots. Copy the automatic snapshots to multiple AWS Regions."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家全球电商公司在 AWS 上运行其关键工作负载。这些工作负载使用配置为多可用区部署的 Amazon RDS for PostgreSQL 数据库实例。当公司进行数据库故障转移时，客户报告了应用程序超时。该公司需要一个弹性解决方案来减少故障转移时间。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建 Amazon RDS Proxy。将代理分配给数据库实例。",
      "B": "为数据库实例创建只读副本。将读取流量移动到只读副本。",
      "C": "打开 Performance Insights。监控 CPU 负载以识别超时。",
      "D": "定期拍摄自动快照。将自动快照复制到多个 AWS 区域。"
    }
  },
  {
    "id": 959,
    "topic": "1",
    "question_en": "A company has multiple Amazon RDS DB instances that run in a development AWS account. All the instances have tags to identify them as development resources. The company needs the development DB instances to run on a schedule only during business hours. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon CloudWatch alarm to identify RDS instances that need to be stopped. Create an AWS Lambda function to start and stop the RDS instances.",
      "B": "Create an AWS Trusted Advisor report to identify RDS instances to be started and stopped. Create an AWS Lambda function to start and stop the RDS instances.",
      "C": "Create AWS Systems Manager State Manager associations to start and stop the RDS instances.",
      "D": "Create an Amazon EventBridge rule that invokes AWS Lambda functions to start and stop the RDS instances."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在开发 AWS 账户中运行多个 Amazon RDS 数据库实例。所有实例都有标签来标识它们为开发资源。该公司需要开发数据库实例仅在工作时间内按计划运行。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon CloudWatch 警报来识别需要停止的 RDS 实例。创建一个 AWS Lambda 函数来启动和停止 RDS 实例。",
      "B": "创建一个 AWS Trusted Advisor 报告来识别需要启动和停止的 RDS 实例。创建一个 AWS Lambda 函数来启动和停止 RDS 实例。",
      "C": "创建 AWS Systems Manager 状态管理器关联以启动和停止 RDS 实例。",
      "D": "创建一个 Amazon EventBridge 规则，该规则调用 AWS Lambda 函数来启动和停止 RDS 实例。"
    }
  },
  {
    "id": 960,
    "topic": "1",
    "question_en": "A consumer survey company has gathered data for several years from a specific geographic region. The company stores this data in an Amazon S3 bucket in an AWS Region. The company has started to share this data with a marketing firm in a new geographic region. The company has granted the firm's AWS account access to the S3 bucket. The company wants to minimize the data transfer costs when the marketing firm requests data from the S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure the Requester Pays feature on the company’s S3 bucket.",
      "B": "Configure S3 Cross-Region Replication (CRR) from the company’s S3 bucket to one of the marketing firm’s S3 buckets.",
      "C": "Configure AWS Resource Access Manager to share the S3 bucket with the marketing firm AWS account.",
      "D": "Configure the company’s S3 bucket to use S3 Intelligent-Tiering Sync the S3 bucket to one of the marketing firm’s S3 buckets."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家消费者调查公司从特定地理区域收集了多年数据。该公司将这些数据存储在 AWS 区域的 Amazon S3 存储桶中。该公司已开始与新地理区域的一家营销公司共享此数据。该公司已授予该公司的 AWS 账户访问 S3 存储桶的权限。该公司希望在营销公司从 S3 存储桶请求数据时最大限度地减少数据传输成本。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在公司的 S3 存储桶上配置 Requester Pays 功能。",
      "B": "配置 S3 跨区域复制 (CRR)，将数据从公司的 S3 存储桶复制到营销公司的一个 S3 存储桶。",
      "C": "配置 AWS Resource Access Manager 以与营销公司的 AWS 账户共享 S3 存储桶。",
      "D": "配置公司的 S3 存储桶以使用 S3 Intelligent-Tiering 并将 S3 存储桶同步到营销公司的一个 S3 存储桶。"
    }
  },
  {
    "id": 961,
    "topic": "1",
    "question_en": "A company uses AWS to host its public ecommerce website. The website uses an AWS Global Accelerator accelerator for trafic from the internet. The Global Accelerator accelerator forwards the trafic to an Application Load Balancer (ALB) that is the entry point for an Auto Scaling group. The company recently identified a DDoS attack on the website. The company needs a solution to mitigate future attacks. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Configure an AWS WAF web ACL for the Global Accelerator accelerator to block trafic by using rate-based rules",
      "B": "Configure an AWS Lambda function to read the ALB metrics to block attacks by updating a VPC network ACL",
      "C": "Configure an AWS WAF web ACL on the ALB to block trafic by using rate-based rules",
      "D": "Configure an Amazon CloudFront distribution in front of the Global Accelerator accelerator"
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司使用 AWS 托管其公共电子商务网站。该网站使用 AWS Global Accelerator 加速器来处理来自互联网的流量。Global Accelerator 加速器将流量转发到作为 Auto Scaling 组入口点的 Application Load Balancer (ALB)。该公司最近在其网站上发现了一次 DDoS 攻击。该公司需要一个解决方案来缓解未来的攻击。哪个解决方案将以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "为 Global Accelerator 加速器配置 AWS WAF web ACL，通过使用基于速率的规则来阻止流量",
      "B": "配置一个 AWS Lambda 函数来读取 ALB 指标，通过更新 VPC 网络 ACL 来阻止攻击",
      "C": "在 ALB 上配置 AWS WAF web ACL，通过使用基于速率的规则来阻止流量",
      "D": "在 Global Accelerator 加速器前面配置 Amazon CloudFront 分发"
    }
  },
  {
    "id": 962,
    "topic": "1",
    "question_en": "A company uses an Amazon DynamoDB table to store data that the company receives from devices. The DynamoDB table supports a customer-facing website to display recent activity on customer devices. The company configured the table with provisioned throughput for writes and reads. The company wants to calculate performance metrics for customer device data on a daily basis. The solution must have minimal effect on the table's provisioned read and write capacity. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an Amazon Athena SQL query with the Amazon Athena DynamoDB connector to calculate performance metrics on a recurring schedule.",
      "B": "Use an AWS Glue job with the AWS Glue DynamoDB export connector to calculate performance metrics on a recurring schedule.",
      "C": "Use an Amazon Redshift COPY command to calculate performance metrics on a recurring schedule.",
      "D": "Use an Amazon EMR job with an Apache Hive external table to calculate performance metrics on a recurring schedule."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司使用 Amazon DynamoDB 表来存储从设备接收的数据。DynamoDB 表支持面向客户的网站，以显示客户设备的近期活动。该公司为表配置了写入和读取的预置吞吐量。该公司希望每天计算客户设备数据的性能指标。该解决方案必须对表的预置读取和写入容量的影响最小。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Athena SQL 查询和 Amazon Athena DynamoDB 连接器，以定期安排计算性能指标。",
      "B": "使用 AWS Glue 作业和 AWS Glue DynamoDB 导出连接器，以定期安排计算性能指标。",
      "C": "使用 Amazon Redshift COPY 命令，以定期安排计算性能指标。",
      "D": "使用 Amazon EMR 作业和 Apache Hive 外部表，以定期安排计算性能指标。"
    }
  },
  {
    "id": 963,
    "topic": "1",
    "question_en": "A solutions architect is designing the cloud architecture for a new stateless application that will be deployed on AWS. The solutions architect created an Amazon Machine Image (AMI) and launch template for the application. Based on the number of jobs that need to be processed, the processing must run in parallel while adding and removing application Amazon EC2 instances as needed. The application must be loosely coupled. The job items must be durably stored. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon Simple Notification Service (Amazon SNS) topic to send the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on CPU usage.",
      "B": "Create an Amazon Simple Queue Service (Amazon SQS) queue to hold the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on network usage.",
      "C": "Create an Amazon Simple Queue Service (Amazon SQS) queue to hold the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on the number of items in the SQS queue.",
      "D": "Create an Amazon Simple Notification Service (Amazon SNS) topic to send the jobs that need to be processed. Create an Auto Scaling group by using the launch template with the scaling policy set to add and remove EC2 instances based on the number of messages published to the SNS topic."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一位解决方案架构师正在为将在 AWS 上部署的新无状态应用程序设计云架构。该解决方案架构师为该应用程序创建了 Amazon Machine Image (AMI) 和启动模板。基于需要处理的作业数量，处理必须并行运行，同时根据需要添加和删除应用程序 Amazon EC2 实例。应用程序必须松散耦合。作业项必须持久存储。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题来发送需要处理的作业。使用启动模板创建一个 Auto Scaling 组，其伸缩策略设置为根据 CPU 使用率添加和删除 EC2 实例。",
      "B": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列来保存需要处理的作业。使用启动模板创建一个 Auto Scaling 组，其伸缩策略设置为根据网络使用率添加和删除 EC2 实例。",
      "C": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列来保存需要处理的作业。使用启动模板创建一个 Auto Scaling 组，其伸缩策略设置为根据 SQS 队列中的项目数量添加和删除 EC2 实例。",
      "D": "创建一个 Amazon Simple Notification Service (Amazon SNS) 主题来发送需要处理的作业。使用启动模板创建一个 Auto Scaling 组，其伸缩策略设置为根据发布到 SNS 主题的消息数量添加和删除 EC2 实例。"
    }
  },
  {
    "id": 964,
    "topic": "1",
    "question_en": "A global ecommerce company uses a monolithic architecture. The company needs a solution to manage the increasing volume of product data. The solution must be scalable and have a modular service architecture. The company needs to maintain its structured database schemas. The company also needs a storage solution to store product data and product images. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use an Amazon EC2 instance in an Auto Scaling group to deploy a containerized application. Use an Application Load Balancer to distribute web trafic. Use an Amazon RDS DB instance to store product data and product images.",
      "B": "Use AWS Lambda functions to manage the existing monolithic application. Use Amazon DynamoDB to store product data and product images. Use Amazon Simple Notification Service (Amazon SNS) for event-driven communication between the Lambda functions.",
      "C": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with an Amazon EC2 deployment to deploy a containerized application. Use an Amazon Aurora cluster to store the product data. Use AWS Step Functions to manage workfiows. Store the product images in Amazon S3 Glacier Deep Archive.",
      "D": "Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate to deploy a containerized application. Use Amazon RDS with a Multi-AZ deployment to store the product data. Store the product images in an Amazon S3 bucket."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家全球电子商务公司使用单体架构。该公司需要一个解决方案来管理不断增长的产品数据量。该解决方案必须具有可扩展性并具有模块化服务架构。该公司需要维护其结构化的数据库模式。该公司还需要一个存储解决方案来存储产品数据和产品图像。哪种解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "在 Auto Scaling 组中使用 Amazon EC2 实例来部署容器化应用程序。使用 Application Load Balancer 分发 Web 流量。使用 Amazon RDS DB 实例存储产品数据和产品图像。",
      "B": "使用 AWS Lambda 函数管理现有的单体应用程序。使用 Amazon DynamoDB 存储产品数据和产品图像。使用 Amazon Simple Notification Service (Amazon SNS) 在 Lambda 函数之间进行事件驱动的通信。",
      "C": "将 Amazon Elastic Kubernetes Service (Amazon EKS) 与 Amazon EC2 部署结合使用，以部署容器化应用程序。使用 Amazon Aurora 集群存储产品数据。使用 AWS Step Functions 管理工作流程。将产品图像存储在 Amazon S3 Glacier Deep Archive 中。",
      "D": "使用 Amazon Elastic Container Service (Amazon ECS) 与 AWS Fargate 部署容器化应用程序。使用具有 Multi-AZ 部署的 Amazon RDS 存储产品数据。将产品图像存储在 Amazon S3 存储桶中。"
    }
  },
  {
    "id": 965,
    "topic": "1",
    "question_en": "A company is migrating an application from an on-premises environment to AWS. The application will store sensitive data in Amazon S3. The company must encrypt the data before storing the data in Amazon S3. Which solution will meet these requirements?",
    "options_en": {
      "A": "Encrypt the data by using client-side encryption with customer managed keys.",
      "B": "Encrypt the data by using server-side encryption with AWS KMS keys (SSE-KMS).",
      "C": "Encrypt the data by using server-side encryption with customer-provided keys (SSE-C).",
      "D": "Encrypt the data by using client-side encryption with Amazon S3 managed keys."
    },
    "correct_answer": "B",
    "vote_percentage": "100%",
    "question_cn": "一家公司正在将其应用程序从本地环境迁移到 AWS。 该应用程序将敏感数据存储在 Amazon S3 中。该公司必须在将数据存储在 Amazon S3 之前对数据进行加密。 哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用由客户管理的密钥通过客户端加密对数据进行加密。",
      "B": "使用由 AWS KMS 密钥 (SSE-KMS) 进行服务器端加密对数据进行加密。",
      "C": "使用由客户提供的密钥 (SSE-C) 进行服务器端加密对数据进行加密。",
      "D": "使用由 Amazon S3 托管密钥进行客户端加密对数据进行加密。"
    }
  },
  {
    "id": 966,
    "topic": "1",
    "question_en": "A company wants to create an Amazon EMR cluster that multiple teams will use. The company wants to ensure that each team’s big data workloads can access only the AWS services that each team needs to interact with. The company does not want the workloads to have access to Instance Metadata Service Version 2 (IMDSv2) on the cluster’s underlying EC2 instances. Which solution will meet these requirements?",
    "options_en": {
      "A": "Configure interface VPC endpoints for each AWS service that the teams need. Use the required interface VPC endpoints to submit the big data workloads.",
      "B": "Create EMR runtime roles. Configure the cluster to use the runtime roles. Use the runtime roles to submit the big data workloads.",
      "C": "Create an EC2 IAM instance profile that has the required permissions for each team. Use the instance profile to submit the big data workloads.",
      "D": "Create an EMR security configuration that has the EnableApplicationScopedIAMRole option set to false. Use the security configuration to submit the big data workloads."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司希望创建多个团队将使用的 Amazon EMR 集群。该公司希望确保每个团队的大数据工作负载只能访问每个团队需要交互的 AWS 服务。该公司不希望工作负载能够访问集群底层 EC2 实例上的 Instance Metadata Service Version 2 (IMDSv2)。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "为团队需要的每个 AWS 服务配置接口 VPC endpoint。使用所需的接口 VPC endpoint 提交大数据工作负载。",
      "B": "创建 EMR 运行时角色。配置集群使用运行时角色。使用运行时角色提交大数据工作负载。",
      "C": "创建具有每个团队所需权限的 EC2 IAM 实例配置文件。使用实例配置文件提交大数据工作负载。",
      "D": "创建 EMR 安全配置，将 EnableApplicationScopedIAMRole 选项设置为 false。使用安全配置提交大数据工作负载。"
    }
  },
  {
    "id": 967,
    "topic": "1",
    "question_en": "A solutions architect is designing an application that helps users fill out and submit registration forms. The solutions architect plans to use a two-tier architecture that includes a web application server tier and a worker tier. The application needs to process submitted forms quickly. The application needs to process each form exactly once. The solution must ensure that no data is lost. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use an Amazon Simple Queue Service (Amazon SQS) FIFO queue between the web application server tier and the worker tier to store and forward form data.",
      "B": "Use an Amazon API Gateway HTTP API between the web application server tier and the worker tier to store and forward form data.",
      "C": "Use an Amazon Simple Queue Service (Amazon SQS) standard queue between the web application server tier and the worker tier to store and forward form data.",
      "D": "Use an AWS Step Functions workfiow. Create a synchronous workfiow between the web application server tier and the worker tier that stores and forwards form data."
    },
    "correct_answer": "A",
    "vote_percentage": "100%",
    "question_cn": "一位解决方案架构师正在设计一个应用程序，该应用程序帮助用户填写并提交注册表单。该解决方案架构师计划使用两层架构，其中包括 Web 应用程序服务器层和工作者层。该应用程序需要快速处理提交的表单。该应用程序需要仅处理每个表单一次。该解决方案必须确保不会丢失任何数据。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "在 Web 应用程序服务器层和工作者层之间使用 Amazon Simple Queue Service (Amazon SQS) FIFO 队列来存储和转发表单数据。",
      "B": "在 Web 应用程序服务器层和工作者层之间使用 Amazon API Gateway HTTP API 来存储和转发表单数据。",
      "C": "在 Web 应用程序服务器层和工作者层之间使用 Amazon Simple Queue Service (Amazon SQS) 标准队列来存储和转发表单数据。",
      "D": "使用 AWS Step Functions 工作流程。在 Web 应用程序服务器层和工作者层之间创建一个同步工作流程，用于存储和转发表单数据。"
    }
  },
  {
    "id": 968,
    "topic": "1",
    "question_en": "A finance company uses an on-premises search application to collect streaming data from various producers. The application provides real- time updates to search and visualization features. The company is planning to migrate to AWS and wants to use an AWS native solution. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon EC2 instances to ingest and process the data streams to Amazon S3 buckets tor storage. Use Amazon Athena to search the data. Use Amazon Managed Grafana to create visualizations.",
      "B": "Use Amazon EMR to ingest and process the data streams to Amazon Redshift for storage. Use Amazon Redshift Spectrum to search the data. Use Amazon QuickSight to create visualizations.",
      "C": "Use Amazon Elastic Kubernetes Service (Amazon EKS) to ingest and process the data streams to Amazon DynamoDB for storage. Use Amazon CloudWatch to create graphical dashboards to search and visualize the data.",
      "D": "Use Amazon Kinesis Data Streams to ingest and process the data streams to Amazon OpenSearch Service. Use OpenSearch Service to search the data. Use Amazon QuickSight to create visualizations."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家金融公司使用本地搜索应用程序从各种生产者那里收集流数据。该应用程序为搜索和可视化功能提供实时更新。该公司计划迁移到 AWS，并希望使用 AWS 原生解决方案。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon EC2 实例将数据流提取和处理到 Amazon S3 存储桶进行存储。使用 Amazon Athena 搜索数据。使用 Amazon Managed Grafana 创建可视化。",
      "B": "使用 Amazon EMR 将数据流提取和处理到 Amazon Redshift 进行存储。使用 Amazon Redshift Spectrum 搜索数据。使用 Amazon QuickSight 创建可视化。",
      "C": "使用 Amazon Elastic Kubernetes Service (Amazon EKS) 将数据流提取和处理到 Amazon DynamoDB 进行存储。使用 Amazon CloudWatch 创建图形仪表板来搜索和可视化数据。",
      "D": "使用 Amazon Kinesis Data Streams 将数据流提取和处理到 Amazon OpenSearch Service。使用 OpenSearch Service 搜索数据。使用 Amazon QuickSight 创建可视化。"
    }
  },
  {
    "id": 969,
    "topic": "1",
    "question_en": "A company currently runs an on-premises application that usesASP.NET on Linux machines. The application is resource-intensive and serves customers directly. The company wants to modernize the application to .NET. The company wants to run the application on containers and to scale based on Amazon CloudWatch metrics. The company also wants to reduce the time spent on operational maintenance activities. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use AWS App2Container to containerize the application. Use an AWS CloudFormation template to deploy the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.",
      "B": "Use AWS App2Container to containerize the application. Use an AWS CloudFormation template to deploy the application to Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 instances.",
      "C": "Use AWS App Runner to containerize the application. Use App Runner to deploy the application to Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.",
      "D": "Use AWS App Runner to containerize the application. Use App Runner to deploy the application to Amazon Elastic Kubernetes Service (Amazon EKS) on Amazon EC2 instances."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司目前运行一个在本地部署的应用程序，该应用程序在 Linux 机器上使用 ASP.NET。该应用程序资源密集，并直接为客户提供服务。公司希望将应用程序现代化为 .NET。公司希望在容器上运行应用程序，并根据 Amazon CloudWatch 指标进行扩展。公司还希望减少在运营维护活动上花费的时间。哪个解决方案将以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 AWS App2Container 将应用程序容器化。使用 AWS CloudFormation 模板将应用程序部署到 AWS Fargate 上的 Amazon Elastic Container Service (Amazon ECS)。",
      "B": "使用 AWS App2Container 将应用程序容器化。使用 AWS CloudFormation 模板将应用程序部署到 Amazon EC2 实例上的 Amazon Elastic Container Service (Amazon ECS)。",
      "C": "使用 AWS App Runner 将应用程序容器化。使用 App Runner 将应用程序部署到 AWS Fargate 上的 Amazon Elastic Container Service (Amazon ECS)。",
      "D": "使用 AWS App Runner 将应用程序容器化。使用 App Runner 将应用程序部署到 Amazon EC2 实例上的 Amazon Elastic Kubernetes Service (Amazon EKS)。"
    }
  },
  {
    "id": 970,
    "topic": "1",
    "question_en": "A company is designing a new internal web application in the AWS Cloud. The new application must securely retrieve and store multiple employee usernames and passwords from an AWS managed service. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Store the employee credentials in AWS Systems Manager Parameter Store. Use AWS CloudFormation and the BatchGetSecretValue API to retrieve usernames and passwords from Parameter Store.",
      "B": "Store the employee credentials in AWS Secrets Manager. Use AWS CloudFormation and AWS Batch with the BatchGetSecretValue API to retrieve the usernames and passwords from Secrets Manager.",
      "C": "Store the employee credentials in AWS Systems Manager Parameter Store. Use AWS CloudFormation and AWS Batch with the BatchGetSecretValue API to retrieve the usernames and passwords from Parameter Store.",
      "D": "Store the employee credentials in AWS Secrets Manager. Use AWS CloudFormation and the BatchGetSecretValue API to retrieve the usernames and passwords from Secrets Manager."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 云中设计一个新的内部 Web 应用程序。新应用程序必须安全地从 AWS 托管服务中检索和存储多个员工的用户名和密码。哪种解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "将员工凭据存储在 AWS Systems Manager Parameter Store 中。使用 AWS CloudFormation 和 BatchGetSecretValue API 从 Parameter Store 检索用户名和密码。",
      "B": "将员工凭据存储在 AWS Secrets Manager 中。使用 AWS CloudFormation 和 AWS Batch 以及 BatchGetSecretValue API 从 Secrets Manager 检索用户名和密码。",
      "C": "将员工凭据存储在 AWS Systems Manager Parameter Store 中。使用 AWS CloudFormation 和 AWS Batch 以及 BatchGetSecretValue API 从 Parameter Store 检索用户名和密码。",
      "D": "将员工凭据存储在 AWS Secrets Manager 中。使用 AWS CloudFormation 和 BatchGetSecretValue API 从 Secrets Manager 检索用户名和密码。"
    }
  },
  {
    "id": 971,
    "topic": "1",
    "question_en": "A company that is in the ap-northeast-1 Region has a fieet of thousands of AWS Outposts servers. The company has deployed the servers at remote locations around the world. All the servers regularly download new software versions that consist of 100 files. There is significant latency before all servers run the new software versions. The company must reduce the deployment latency for new software versions. Which solution will meet this requirement with the LEAST operational overhead?",
    "options_en": {
      "A": "Create an Amazon S3 bucket in ap-northeast-1. Set up an Amazon CloudFront distribution in ap-northeast-1 that includes a CachingDisabled cache policy. Configure the S3 bucket as the origin. Download the software by using signed URLs.",
      "B": "Create an Amazon S3 bucket in ap-northeast-1. Create a second S3 bucket in the us-east-1 Region. Configure replication between the buckets. Set up an Amazon CloudFront distribution that uses ap-northeast-1 as the primary origin and us-east-1 as the secondary origin. Download the software by using signed URLs.",
      "C": "Create an Amazon S3 bucket in ap-northeast-1. Configure Amazon S3 Transfer Acceleration. Download the software by using the S3 Transfer Acceleration endpoint.",
      "D": "Create an Amazon S3 bucket in ap-northeast-1. Set up an Amazon CloudFront distribution. Configure the S3 bucket as the origin. Download the software by using signed URLs."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家位于 ap-northeast-1 区域的公司拥有数千台 AWS Outposts 服务器。该公司已将服务器部署在全球各地的远程位置。所有服务器会定期下载由 100 个文件组成的新软件版本。在所有服务器运行新软件版本之前存在显着的延迟。该公司必须减少新软件版本的部署延迟。哪种解决方案能够以最少的运营开销满足此要求？",
    "options_cn": {
      "A": "在 ap-northeast-1 区域创建一个 Amazon S3 存储桶。在 ap-northeast-1 区域设置一个 Amazon CloudFront 分发，其中包括 CachingDisabled 缓存策略。将 S3 存储桶配置为源。使用签名 URL 下载软件。",
      "B": "在 ap-northeast-1 区域创建一个 Amazon S3 存储桶。在 us-east-1 区域创建第二个 S3 存储桶。配置存储桶之间的复制。设置一个 Amazon CloudFront 分发，该分发使用 ap-northeast-1 作为主要源，us-east-1 作为辅助源。使用签名 URL 下载软件。",
      "C": "在 ap-northeast-1 区域创建一个 Amazon S3 存储桶。配置 Amazon S3 Transfer Acceleration。使用 S3 Transfer Acceleration 端点下载软件。",
      "D": "在 ap-northeast-1 区域创建一个 Amazon S3 存储桶。设置一个 Amazon CloudFront 分发。将 S3 存储桶配置为源。使用签名 URL 下载软件。"
    }
  },
  {
    "id": 972,
    "topic": "1",
    "question_en": "A company currently runs an on-premises stock trading application by using Microsoft Windows Server. The company wants to migrate the application to the AWS Cloud. The company needs to design a highly available solution that provides low-latency access to block storage across multiple Availability Zones. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Configure a Windows Server cluster that spans two Availability Zones on Amazon EC2 instances. Install the application on both cluster nodes. Use Amazon FSx for Windows File Server as shared storage between the two cluster nodes.",
      "B": "Configure a Windows Server cluster that spans two Availability Zones on Amazon EC2 instances. Install the application on both cluster nodes. Use Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp3) volumes as storage attached to the EC2 instances. Set up application-level replication to sync data from one EBS volume in one Availability Zone to another EBS volume in the second Availability Zone.",
      "C": "Deploy the application on Amazon EC2 instances in two Availability Zones. Configure one EC2 instance as active and the second EC2 instance in standby mode. Use an Amazon FSx for NetApp ONTAP Multi-AZ file system to access the data by using Internet Small Computer Systems Interface (iSCSI) protocol.",
      "D": "Deploy the application on Amazon EC2 instances in two Availability Zones. Configure one EC2 instance as active and the second EC2 instance in standby mode. Use Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io2) volumes as storage attached to the EC2 instances. Set up Amazon EBS level replication to sync data from one io2 volume in one Availability Zone to another io2 volume in the second Availability Zone."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司目前通过使用 Microsoft Windows Server 运行本地股票交易应用程序。该公司希望将该应用程序迁移到 AWS Cloud。该公司需要设计一个高可用性解决方案，该解决方案可在多个可用区内提供对块存储的低延迟访问。哪种解决方案将以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "在 Amazon EC2 实例上配置一个跨越两个可用区的 Windows Server 集群。在两个集群节点上安装该应用程序。使用 Amazon FSx for Windows File Server 作为两个集群节点之间的共享存储。",
      "B": "在 Amazon EC2 实例上配置一个跨越两个可用区的 Windows Server 集群。在两个集群节点上安装该应用程序。使用 Amazon Elastic Block Store (Amazon EBS) 通用型 SSD (gp3) 卷作为连接到 EC2 实例的存储。设置应用程序级复制，以将数据从一个可用区中的一个 EBS 卷同步到第二个可用区中的另一个 EBS 卷。",
      "C": "在两个可用区的 Amazon EC2 实例上部署该应用程序。将一个 EC2 实例配置为活动状态，并将第二个 EC2 实例配置为备用模式。使用 Amazon FSx for NetApp ONTAP 多可用区文件系统，通过 Internet Small Computer Systems Interface (iSCSI) 协议访问数据。",
      "D": "在两个可用区的 Amazon EC2 实例上部署该应用程序。将一个 EC2 实例配置为活动状态，并将第二个 EC2 实例配置为备用模式。使用 Amazon Elastic Block Store (Amazon EBS) 预置 IOPS SSD (io2) 卷作为连接到 EC2 实例的存储。设置 Amazon EBS 级别的复制，以将数据从一个可用区中的一个 io2 卷同步到第二个可用区中的另一个 io2 卷。"
    }
  },
  {
    "id": 973,
    "topic": "1",
    "question_en": "A company is designing a web application with an internet-facing Application Load Balancer (ALB). The company needs the ALB to receive HTTPS web trafic from the public internet. The ALB must send only HTTPS trafic to the web application servers hosted on the Amazon EC2 instances on port 443. The ALB must perform a health check of the web application servers over HTTPS on port 8443. Which combination of configurations of the security group that is associated with the ALB will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Allow HTTPS inbound trafic from 0.0.0.0/0 for port 443.",
      "B": "Allow all outbound trafic to 0.0.0.0/0 for port 443.",
      "C": "Allow HTTPS outbound trafic to the web application instances for port 443.",
      "D": "Allow HTTPS inbound trafic from the web application instances for port 443",
      "E": "Allow HTTPS outbound trafic to the web application instances for the health check on port 8443",
      "F": "Allow HTTPS inbound trafic from the web application instances for the health check on port 8443."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司正在设计一个面向互联网的 Application Load Balancer (ALB) 的 Web 应用程序。该公司需要 ALB 从公共互联网接收 HTTPS Web 流量。ALB 必须仅将 HTTPS 流量发送到托管在 Amazon EC2 实例上且端口为 443 的 Web 应用程序服务器。 ALB 必须通过 HTTPS 在端口 8443 上对 Web 应用程序服务器执行运行状况检查。安全组的哪些配置组合与 ALB 关联，将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "允许来自 0.0.0.0/0 的 HTTPS 入站流量通过端口 443。",
      "B": "允许所有出站流量到 0.0.0.0/0 端口 443。",
      "C": "允许到 Web 应用程序实例的 HTTPS 出站流量通过端口 443。",
      "D": "允许来自 Web 应用程序实例的 HTTPS 入站流量通过端口 443。",
      "E": "允许到 Web 应用程序实例的 HTTPS 出站流量通过端口 8443 上的运行状况检查。",
      "F": "允许来自 Web 应用程序实例的 HTTPS 入站流量通过端口 8443 上的运行状况检查。"
    }
  },
  {
    "id": 974,
    "topic": "1",
    "question_en": "A company hosts an application on AWS. The application gives users the ability to upload photos and store the photos in an Amazon S3 bucket. The company wants to use Amazon CloudFront and a custom domain name to upload the photo files to the S3 bucket in the eu-west-1 Region. Which solution will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "Use AWS Certificate Manager (ACM) to create a public certificate in the us-east-1 Region. Use the certificate in CloudFront.",
      "B": "Use AWS Certificate Manager (ACM) to create a public certificate in eu-west-1. Use the certificate in CloudFront.",
      "C": "Configure Amazon S3 to allow uploads from CloudFront. Configure S3 Transfer Acceleration.",
      "D": "Configure Amazon S3 to allow uploads from CloudFront origin access control (OAC)",
      "E": "Configure Amazon S3 to allow uploads from CloudFront. Configure an Amazon S3 website endpoint."
    },
    "correct_answer": "A",
    "vote_percentage": "50%",
    "question_cn": "一家公司在 AWS 上托管一个应用程序。该应用程序允许用户上传照片并将照片存储在 Amazon S3 存储桶中。该公司希望使用 Amazon CloudFront 和自定义域名将照片文件上传到 eu-west-1 区域中的 S3 存储桶。哪种解决方案将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "使用 AWS Certificate Manager (ACM) 在 us-east-1 区域中创建公共证书。在 CloudFront 中使用该证书。",
      "B": "使用 AWS Certificate Manager (ACM) 在 eu-west-1 区域中创建公共证书。在 CloudFront 中使用该证书。",
      "C": "配置 Amazon S3 允许从 CloudFront 上传。配置 S3 Transfer Acceleration。",
      "D": "配置 Amazon S3 以允许从 CloudFront 源访问控制 (OAC) 上传。",
      "E": "配置 Amazon S3 允许从 CloudFront 上传。配置 Amazon S3 网站终端节点。"
    }
  },
  {
    "id": 975,
    "topic": "1",
    "question_en": "A weather forecasting company collects temperature readings from various sensors on a continuous basis. An existing data ingestion process collects the readings and aggregates the readings into larger Apache Parquet files. Then the process encrypts the files by using client-side encryption with KMS managed keys (CSE-KMS). Finally, the process writes the files to an Amazon S3 bucket with separate prefixes for each calendar day. The company wants to run occasional SQL queries on the data to take sample moving averages for a specific calendar day. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure Amazon Athena to read the encrypted files. Run SQL queries on the data directly in Amazon S3.",
      "B": "Use Amazon S3 Select to run SQL queries on the data directly in Amazon S3.",
      "C": "Configure Amazon Redshift to read the encrypted files. Use Redshift Spectrum and Redshift query editor v2 to run SQL queries on the data directly in Amazon S3.",
      "D": "Configure Amazon EMR Serverless to read the encrypted files. Use Apache SparkSQL to run SQL queries on the data directly in Amazon S3."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家天气预报公司持续不断地从各种传感器收集温度读数。现有的数据摄取流程收集读数并将这些读数聚合到更大的 Apache Parquet 文件中。然后，该流程使用客户端加密和 KMS 托管密钥 (CSE-KMS) 对文件进行加密。最后，该流程将文件写入 Amazon S3 存储桶，每个日历日使用单独的前缀。该公司希望对数据运行偶尔的 SQL 查询，以获取特定日历日的移动平均样本。哪个解决方案能最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "配置 Amazon Athena 以读取加密的文件。直接在 Amazon S3 中对数据运行 SQL 查询。",
      "B": "使用 Amazon S3 Select 直接在 Amazon S3 中对数据运行 SQL 查询。",
      "C": "配置 Amazon Redshift 以读取加密的文件。使用 Redshift Spectrum 和 Redshift 查询编辑器 v2 直接在 Amazon S3 中对数据运行 SQL 查询。",
      "D": "配置 Amazon EMR Serverless 以读取加密的文件。使用 Apache SparkSQL 直接在 Amazon S3 中对数据运行 SQL 查询。"
    }
  },
  {
    "id": 976,
    "topic": "1",
    "question_en": "A company is implementing a new application on AWS. The company will run the application on multiple Amazon EC2 instances across multiple Availability Zones within multiple AWS Regions. The application will be available through the internet. Users will access the application from around the world. The company wants to ensure that each user who accesses the application is sent to the EC2 instances that are closest to the user’s location. Which solution will meet these requirements?",
    "options_en": {
      "A": "Implement an Amazon Route 53 geolocation routing policy. Use an internet-facing Application Load Balancer to distribute the trafic across all Availability Zones within the same Region.",
      "B": "Implement an Amazon Route 53 geoproximity routing policy. Use an internet-facing Network Load Balancer to distribute the trafic across all Availability Zones within the same Region.",
      "C": "Implement an Amazon Route 53 multivalue answer routing policy. Use an internet-facing Application Load Balancer to distribute the trafic across all Availability Zones within the same Region.",
      "D": "Implement an Amazon Route 53 weighted routing policy. Use an internet-facing Network Load Balancer to distribute the trafic across all Availability Zones within the same Region."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上实施新的应用程序。该公司将在多个 AWS 区域内的多个可用区中，在多个 Amazon EC2 实例上运行该应用程序。该应用程序将通过互联网提供。用户将从世界各地访问该应用程序。该公司希望确保将访问该应用程序的每个用户发送到离用户位置最近的 EC2 实例。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "实施 Amazon Route 53 地理位置路由策略。使用面向互联网的 Application Load Balancer 在同一区域内的所有可用区之间分配流量。",
      "B": "实施 Amazon Route 53 地理邻近路由策略。使用面向互联网的 Network Load Balancer 在同一区域内的所有可用区之间分配流量。",
      "C": "实施 Amazon Route 53 多值应答路由策略。使用面向互联网的 Application Load Balancer 在同一区域内的所有可用区之间分配流量。",
      "D": "实施 Amazon Route 53 加权路由策略。使用面向互联网的 Network Load Balancer 在同一区域内的所有可用区之间分配流量。"
    }
  },
  {
    "id": 977,
    "topic": "1",
    "question_en": "A financial services company plans to launch a new application on AWS to handle sensitive financial transactions. The company will deploy the application on Amazon EC2 instances. The company will use Amazon RDS for MySQL as the database. The company’s security policies mandate that data must be encrypted at rest and in transit. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Configure encryption at rest for Amazon RDS for MySQL by using AWS KMS managed keys. Configure AWS Certificate Manager (ACM) SSL/TLS certificates for encryption in transit.",
      "B": "Configure encryption at rest for Amazon RDS for MySQL by using AWS KMS managed keys. Configure IPsec tunnels for encryption in transit.",
      "C": "Implement third-party application-level data encryption before storing data in Amazon RDS for MySQL. Configure AWS Certificate Manager (ACM) SSL/TLS certificates for encryption in transit.",
      "D": "Configure encryption at rest for Amazon RDS for MySQL by using AWS KMS managed keys. Configure a VPN connection to enable private connectivity to encrypt data in transit."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家金融服务公司计划在 AWS 上启动一个新应用程序来处理敏感的金融交易。该公司将在 Amazon EC2 实例上部署该应用程序。该公司将使用 Amazon RDS for MySQL 作为数据库。该公司的安全策略要求静态数据和传输中的数据都必须加密。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "通过使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。为传输中的加密配置 AWS Certificate Manager (ACM) SSL/TLS 证书。",
      "B": "通过使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。为传输中的加密配置 IPsec 隧道。",
      "C": "在将数据存储在 Amazon RDS for MySQL 之前，实现第三方应用程序级数据加密。为传输中的加密配置 AWS Certificate Manager (ACM) SSL/TLS 证书。",
      "D": "通过使用 AWS KMS 托管密钥为 Amazon RDS for MySQL 配置静态加密。配置 VPN 连接以实现私有连接来加密传输中的数据。"
    }
  },
  {
    "id": 978,
    "topic": "1",
    "question_en": "A company is migrating its on-premises Oracle database to an Amazon RDS for Oracle database. The company needs to retain data for 90 days to meet regulatory requirements. The company must also be able to restore the database to a specific point in time for up to 14 days. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create Amazon RDS automated backups. Set the retention period to 90 days.",
      "B": "Create an Amazon RDS manual snapshot every day. Delete manual snapshots that are older than 90 days.",
      "C": "Use the Amazon Aurora Clone feature for Oracle to create a point-in-time restore. Delete clones that are older than 90 days.",
      "D": "Create a backup plan that has a retention period of 90 days by using AWS Backup for Amazon RDS."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司正在将其本地 Oracle 数据库迁移到 Amazon RDS for Oracle 数据库。该公司需要保留 90 天的数据以满足监管要求。该公司还必须能够将数据库恢复到长达 14 天的特定时间点。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "创建 Amazon RDS 自动备份。将保留期设置为 90 天。",
      "B": "每天创建 Amazon RDS 手动快照。删除 90 天以上的手动快照。",
      "C": "使用 Amazon Aurora Clone 功能创建 Oracle 的时间点还原。删除 90 天以上的克隆。",
      "D": "使用 AWS Backup for Amazon RDS 创建一个备份计划，该计划的保留期为 90 天。"
    }
  },
  {
    "id": 979,
    "topic": "1",
    "question_en": "A company is developing a new application that uses a relational database to store user data and application configurations. The company expects the application to have steady user growth. The company expects the database usage to be variable and read-heavy, with occasional writes. The company wants to cost-optimize the database solution. The company wants to use an AWS managed database solution that will provide the necessary performance. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Deploy the database on Amazon RDS. Use Provisioned IOPS SSD storage to ensure consistent performance for read and write operations.",
      "B": "Deploy the database on Amazon Aurora Serverless to automatically scale the database capacity based on actual usage to accommodate the workload.",
      "C": "Deploy the database on Amazon DynamoDB. Use on-demand capacity mode to automatically scale throughput to accommodate the workload.",
      "D": "Deploy the database on Amazon RDS. Use magnetic storage and use read replicas to accommodate the workload."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在开发一个新应用程序，该应用程序使用关系数据库来存储用户数据和应用程序配置。该公司预计该应用程序将实现稳定的用户增长。该公司预计数据库使用量将是可变的，并且以读取为主，偶尔会进行写入。该公司希望对数据库解决方案进行成本优化。该公司希望使用 AWS 托管数据库解决方案，以提供所需的性能。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在 Amazon RDS 上部署数据库。使用预置 IOPS SSD 存储，以确保读取和写入操作的持续性能。",
      "B": "在 Amazon Aurora Serverless 上部署数据库，以根据实际使用情况自动扩展数据库容量，从而适应工作负载。",
      "C": "在 Amazon DynamoDB 上部署数据库。使用按需容量模式来自动扩展吞吐量，以适应工作负载。",
      "D": "在 Amazon RDS 上部署数据库。使用磁性存储并使用只读副本以适应工作负载。"
    }
  },
  {
    "id": 980,
    "topic": "1",
    "question_en": "A company hosts its application on several Amazon EC2 instances inside a VPC. The company creates a dedicated Amazon S3 bucket for each customer to store their relevant information in Amazon S3. The company wants to ensure that the application running on EC2 instances can securely access only the S3 buckets that belong to the company’s AWS account. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Create a gateway endpoint for Amazon S3 that is attached to the VPC. Update the IAM instance profile policy to provide access to only the specific buckets that the application needs.",
      "B": "Create a NAT gateway in a public subnet with a security group that allows access to only Amazon S3. Update the route tables to use the NAT Gateway.",
      "C": "Create a gateway endpoint for Amazon S3 that is attached to the VPUpdate the IAM instance profile policy with a Deny action and the following condition key:",
      "D": "Create a NAT Gateway in a public subnet. Update route tables to use the NAT Gateway. Assign bucket policies for all buckets with a Deny action and the following condition key:"
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在其 VPC 内部的多个 Amazon EC2 实例上托管其应用程序。该公司为每个客户创建一个专用的 Amazon S3 存储桶，以在 Amazon S3 中存储其相关信息。该公司希望确保在 EC2 实例上运行的应用程序只能安全地访问属于该公司 AWS 账户的 S3 存储桶。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "为 Amazon S3 创建一个附加到 VPC 的网关 endpoint。更新 IAM 实例配置文件策略，仅提供对应用程序所需的特定存储桶的访问权限。",
      "B": "在公共子网中创建一个 NAT Gateway，其安全组仅允许访问 Amazon S3。更新路由表以使用 NAT Gateway。",
      "C": "为 Amazon S3 创建一个附加到 VPC 的网关 endpoint。使用 Deny 操作和以下条件密钥更新 IAM 实例配置文件策略：",
      "D": "在公共子网中创建一个 NAT Gateway。更新路由表以使用 NAT Gateway。为所有存储桶分配具有 Deny 操作和以下条件密钥的存储桶策略："
    }
  },
  {
    "id": 981,
    "topic": "1",
    "question_en": "A company is building a cloud-based application on AWS that will handle sensitive customer data. The application uses Amazon RDS for the database, Amazon S3 for object storage, and S3 Event Notifications that invoke AWS Lambda for serverless processing. The company uses AWS IAM Identity Center to manage user credentials. The development, testing, and operations teams need secure access to Amazon RDS and Amazon S3 while ensuring the confidentiality of sensitive customer data. The solution must comply with the principle of least privilege. Which solution meets these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use IAM roles with least privilege to grant all the teams access. Assign IAM roles to each team with customized IAM policies defining specific permission for Amazon RDS and S3 object access based on team responsibilities.",
      "B": "Enable IAM Identity Center with an Identity Center directory. Create and configure permission sets with granular access to Amazon RDS and Amazon S3. Assign all the teams to groups that have specific access with the permission sets.",
      "C": "Create individual IAM users for each member in all the teams with role-based permissions. Assign the IAM roles with predefined policies for RDS and S3 access to each user based on user needs. Implement IAM Access Analyzer for periodic credential evaluation.",
      "D": "Use AWS Organizations to create separate accounts for each team. Implement cross-account IAM roles with least privilege. Grant specific permission for RDS and S3 access based on team roles and responsibilities."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上构建一个基于云的应用程序，该应用程序将处理敏感的客户数据。该应用程序使用 Amazon RDS 作为数据库，Amazon S3 作为对象存储，并使用 S3 事件通知来调用 AWS Lambda 进行无服务器处理。该公司使用 AWS IAM Identity Center 来管理用户凭证。开发、测试和运维团队需要安全地访问 Amazon RDS 和 Amazon S3，同时确保敏感客户数据的机密性。该解决方案必须遵循最小权限原则。哪个解决方案以最少的运维开销满足这些要求？",
    "options_cn": {
      "A": "使用具有最小权限的 IAM 角色授予所有团队访问权限。为每个团队分配 IAM 角色，并使用自定义的 IAM 策略根据团队的职责定义对 Amazon RDS 和 S3 对象访问的特定权限。",
      "B": "使用 Identity Center 目录启用 IAM Identity Center。创建和配置具有对 Amazon RDS 和 Amazon S3 细粒度访问权限的权限集。将所有团队分配给具有权限集的特定访问权限的组。",
      "C": "为所有团队中的每个成员创建单独的 IAM 用户，并使用基于角色的权限。根据用户的需求，将具有预定义 RDS 和 S3 访问策略的 IAM 角色分配给每个用户。实施 IAM Access Analyzer 用于定期凭证评估。",
      "D": "使用 AWS Organizations 为每个团队创建单独的账户。实施跨账户 IAM 角色，并使用最小权限。根据团队的角色和职责，授予 RDS 和 S3 访问的特定权限。"
    }
  },
  {
    "id": 982,
    "topic": "1",
    "question_en": "A company has an Amazon S3 bucket that contains sensitive data files. The company has an application that runs on virtual machines in an on-premises data center. The company currently uses AWS IAM Identity Center. The application requires temporary access to files in the S3 bucket. The company wants to grant the application secure access to the files in the S3 bucket. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an S3 bucket policy that permits access to the bucket from the public IP address range of the company’s on-premises data center.",
      "B": "Use IAM Roles Anywhere to obtain security credentials in IAM Identity Center that grant access to the S3 bucket. Configure the virtual machines to assume the role by using the AWS CLI.",
      "C": "Install the AWS CLI on the virtual machine. Configure the AWS CLI with access keys from an IAM user that has access to the bucket.",
      "D": "Create an IAM user and policy that grants access to the bucket. Store the access key and secret key for the IAM user in AWS Secrets Manager. Configure the application to retrieve the access key and secret key at startup."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司有一个 Amazon S3 存储桶，其中包含敏感数据文件。该公司有一个应用程序，该应用程序在本地数据中心的虚拟机上运行。该公司目前正在使用 AWS IAM Identity Center。该应用程序需要临时访问 S3 存储桶中的文件。该公司希望授予该应用程序安全访问 S3 存储桶中文件的权限。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 S3 存储桶策略，允许从该公司本地数据中心的公共 IP 地址范围访问该存储桶。",
      "B": "使用 IAM Roles Anywhere 在 IAM Identity Center 中获取安全凭证，这些凭证授予对 S3 存储桶的访问权限。配置虚拟机使用 AWS CLI 担任该角色。",
      "C": "在虚拟机上安装 AWS CLI。使用有权访问该存储桶的 IAM 用户的访问密钥配置 AWS CLI。",
      "D": "创建一个 IAM 用户和策略，授予对该存储桶的访问权限。将该 IAM 用户的访问密钥和私有密钥存储在 AWS Secrets Manager 中。配置应用程序在启动时检索访问密钥和私有密钥。"
    }
  },
  {
    "id": 983,
    "topic": "1",
    "question_en": "A company hosts its core network services, including directory services and DNS, in its on-premises data center. The data center is connected to the AWS Cloud using AWS Direct Connect (DX). Additional AWS accounts are planned that will require quick, cost-effective, and consistent access to these network services. What should a solutions architect implement to meet these requirements with the LEAST amount of operational overhead?",
    "options_en": {
      "A": "Create a DX connection in each new account. Route the network trafic to the on-premises servers.",
      "B": "Configure VPC endpoints in the DX VPC for all required services. Route the network trafic to the on-premises servers.",
      "C": "Create a VPN connection between each new account and the DX VPRoute the network trafic to the on-premises servers.",
      "D": "Configure AWS Transit Gateway between the accounts. Assign DX to the transit gateway and route network trafic to the on-premises servers."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在其本地数据中心托管其核心网络服务，包括目录服务和 DNS。该数据中心使用 AWS Direct Connect (DX) 连接到 AWS 云。计划添加额外的 AWS 账户，这些账户将需要快速、经济高效且一致地访问这些网络服务。解决方案架构师应该实施什么来满足这些要求，同时运营开销最少？",
    "options_cn": {
      "A": "在新账户中创建 DX 连接。将网络流量路由到本地服务器。",
      "B": "在 DX VPC 中为所有所需服务配置 VPC endpoint。将网络流量路由到本地服务器。",
      "C": "在新账户和 DX VPC 之间创建 VPN 连接。将网络流量路由到本地服务器。",
      "D": "在账户之间配置 AWS Transit Gateway。将 DX 分配给 Transit Gateway，并将网络流量路由到本地服务器。"
    }
  },
  {
    "id": 984,
    "topic": "1",
    "question_en": "A company hosts its main public web application in one AWS Region across multiple Availability Zones. The application uses an Amazon EC2 Auto Scaling group and an Application Load Balancer (ALB). A web development team needs a cost-optimized compute solution to improve the company’s ability to serve dynamic content globally to millions of customers. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create an Amazon CloudFront distribution. Configure the existing ALB as the origin.",
      "B": "Use Amazon Route 53 to serve trafic to the ALB and EC2 instances based on the geographic location of each customer.",
      "C": "Create an Amazon S3 bucket with public read access enabled. Migrate the web application to the S3 bucket. Configure the S3 bucket for website hosting.",
      "D": "Use AWS Direct Connect to directly serve content from the web application to the location of each customer."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司将其主要的公共 Web 应用程序托管在多个可用区的一个 AWS 区域中。该应用程序使用 Amazon EC2 Auto Scaling 组和 Application Load Balancer (ALB)。一个 Web 开发团队需要一个成本优化的计算解决方案，以提高公司向全球数百万客户提供动态内容的能力。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon CloudFront 分发。将现有的 ALB 配置为源。",
      "B": "使用 Amazon Route 53 根据每个客户的地理位置向 ALB 和 EC2 实例提供流量。",
      "C": "创建一个具有公共读取访问权限的 Amazon S3 存储桶。将 Web 应用程序迁移到 S3 存储桶。将 S3 存储桶配置为网站托管。",
      "D": "使用 AWS Direct Connect 直接将内容从 Web 应用程序提供给每个客户的所在位置。"
    }
  },
  {
    "id": 985,
    "topic": "1",
    "question_en": "A company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used for months at a time. A solutions architect must choose a cost-effective solution that maintains the highest level of durability while maintaining high availability. Which storage solution meets these requirements?",
    "options_en": {
      "A": "Amazon S3 Standard",
      "B": "Amazon S3 Intelligent-Tiering",
      "C": "Amazon S3 Glacier Deep Archive",
      "D": "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)"
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 中存储用户数据。这些数据被持续使用，并在工作时间内达到峰值使用量。访问模式各不相同，有些数据几个月都不会被使用。一位解决方案架构师必须选择一个具有成本效益的解决方案，该方案在保持最高级别的耐用性的同时，还要保持高可用性。哪种存储解决方案符合这些要求？",
    "options_cn": {
      "A": "Amazon S3 标准",
      "B": "Amazon S3 智能分层",
      "C": "Amazon S3 Glacier Deep Archive",
      "D": "Amazon S3 单区-不频繁访问 (S3 One Zone-IA)"
    }
  },
  {
    "id": 986,
    "topic": "1",
    "question_en": "A company is testing an application that runs on an Amazon EC2 Linux instance. A single 500 GB Amazon Elastic Block Store (Amazon EBS) General Purpose SSO (gp2) volume is attached to the EC2 instance. The company will deploy the application on multiple EC2 instances in an Auto Scaling group. All instances require access to the data that is stored in the EBS volume. The company needs a highly available and resilient solution that does not introduce significant changes to the application's code. Which solution will meet these requirements?",
    "options_en": {
      "A": "Provision an EC2 instance that uses NFS server software. Attach a single 500 GB gp2 EBS volume to the instance.",
      "B": "Provision an Amazon FSx for Windows File Server file system. Configure the file system as an SMB file store within a single Availability Zone.",
      "C": "Provision an EC2 instance with two 250 GB Provisioned IOPS SSD EBS volumes.",
      "D": "Provision an Amazon Elastic File System (Amazon EFS) file system. Configure the file system to use General Purpose performance mode."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司正在测试一个在 Amazon EC2 Linux 实例上运行的应用程序。一个 500 GB Amazon Elastic Block Store (Amazon EBS) 通用型 SSD (gp2) 卷已附加到 EC2 实例。该公司将在 Auto Scaling 组中的多个 EC2 实例上部署该应用程序。所有实例都需要访问存储在 EBS 卷中的数据。该公司需要一个高可用性和弹性的解决方案，该方案不会对应用程序的代码进行重大更改。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "预置一个使用 NFS 服务器软件的 EC2 实例。将一个 500 GB gp2 EBS 卷附加到该实例。",
      "B": "预置一个 Amazon FSx for Windows File Server 文件系统。将该文件系统配置为单个可用区内的 SMB 文件存储。",
      "C": "预置一个带有两个 250 GB 预置 IOPS SSD EBS 卷的 EC2 实例。",
      "D": "预置一个 Amazon Elastic File System (Amazon EFS) 文件系统。将该文件系统配置为使用通用性能模式。"
    }
  },
  {
    "id": 987,
    "topic": "1",
    "question_en": "A company recently launched a new application for its customers. The application runs on multiple Amazon EC2 instances across two Availability Zones. End users use TCP to communicate with the application. The application must be highly available and must automatically scale as the number of users increases. Which combination of steps will meet these requirements MOST cost-effectively? (Choose two.)",
    "options_en": {
      "A": "Add a Network Load Balancer in front of the EC2 instances.",
      "B": "Configure an Auto Scaling group for the EC2 instances.",
      "C": "Add an Application Load Balancer in front of the EC2 instances.",
      "D": "Manually add more EC2 instances for the application",
      "E": "Add a Gateway Load Balancer in front of the EC2 instances."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司最近为其客户推出了一个新应用程序。该应用程序在两个可用区中的多个 Amazon EC2 实例上运行。最终用户使用 TCP 与该应用程序通信。该应用程序必须具有高可用性，并且必须随着用户数量的增加而自动扩展。哪种步骤组合将以最具成本效益的方式满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 EC2 实例前面添加 Network Load Balancer。",
      "B": "为 EC2 实例配置 Auto Scaling 组。",
      "C": "在 EC2 实例前面添加 Application Load Balancer (ALB)。",
      "D": "手动为应用程序添加更多 EC2 实例。",
      "E": "在 EC2 实例前面添加 Gateway Load Balancer。"
    }
  },
  {
    "id": 988,
    "topic": "1",
    "question_en": "A company is designing the architecture for a new mobile app that uses the AWS Cloud. The company uses organizational units (OUs) in AWS Organizations to manage its accounts. The company wants to tag Amazon EC2 instances with data sensitivity by using values of sensitive and nonsensitive. IAM identities must not be able to delete a tag or create instances without a tag. Which combination of steps will meet these requirements? (Choose two.)",
    "options_en": {
      "A": "In Organizations, create a new tag policy that specifies the data sensitivity tag key and the required values. Enforce the tag values for the EC2 instances. Attach the tag policy to the appropriate OU.",
      "B": "In Organizations, create a new service control policy (SCP) that specifies the data sensitivity tag key and the required tag values. Enforce the tag values for the EC2 instances. Attach the SCP to the appropriate OU.",
      "C": "Create a tag policy to deny running instances when a tag key is not specified. Create another tag policy that prevents identities from deleting tags. Attach the tag policies to the appropriate OU.",
      "D": "Create a service control policy (SCP) to deny creating instances when a tag key is not specified. Create another SCP that prevents identities from deleting tags. Attach the SCPs to the appropriate OU",
      "E": "Create an AWS Config rule to check if EC2 instances use the data sensitivity tag and the specified values. Configure an AWS Lambda function to delete the resource if a noncompliant resource is found."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司正在为其使用 AWS 云的新移动应用程序设计架构。该公司在 AWS Organizations 中使用组织单元 (OU) 来管理其账户。该公司希望通过使用敏感和非敏感值对 Amazon EC2 实例进行数据敏感度标记。IAM 身份不能删除标签或在没有标签的情况下创建实例。哪种步骤组合将满足这些要求？（选择两个。）",
    "options_cn": {
      "A": "在 Organizations 中，创建一个新的标签策略，该策略指定数据敏感度标签键和所需的值。对 EC2 实例强制执行标签值。将标签策略附加到相应的 OU。",
      "B": "在 Organizations 中，创建一个新的服务控制策略 (SCP)，该策略指定数据敏感度标签键和所需的标签值。对 EC2 实例强制执行标签值。将 SCP 附加到相应的 OU。",
      "C": "创建标签策略以拒绝在未指定标签键时运行实例。创建另一个标签策略以防止身份删除标签。将标签策略附加到相应的 OU。",
      "D": "创建服务控制策略 (SCP) 以拒绝在未指定标签键时创建实例。创建另一个 SCP 以防止身份删除标签。将 SCP 附加到相应的 OU。",
      "E": "创建 AWS Config 规则以检查 EC2 实例是否使用数据敏感度标签和指定的值。配置 AWS Lambda 函数以在找到不合规的资源时删除该资源。"
    }
  },
  {
    "id": 989,
    "topic": "1",
    "question_en": "A company runs database workloads on AWS that are the backend for the company's customer portals. The company runs a Multi-AZ database cluster on Amazon RDS for PostgreSQL. The company needs to implement a 30-day backup retention policy. The company currently has both automated RDS backups and manual RDS backups. The company wants to maintain both types of existing RDS backups that are less than 30 days old. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure the RDS backup retention policy to 30 days for automated backups by using AWS Backup. Manually delete manual backups that are older than 30 days.",
      "B": "Disable RDS automated backups. Delete automated backups and manual backups that are older than 30 days. Configure the RDS backup retention policy to 30 days for automated backups.",
      "C": "Configure the RDS backup retention policy to 30 days for automated backups. Manually delete manual backups that are older than 30 days.",
      "D": "Disable RDS automated backups. Delete automated backups and manual backups that are older than 30 days automatically by using AWS CloudFormation. Configure the RDS backup retention policy to 30 days for automated backups."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 上运行数据库工作负载，这些工作负载是该公司客户门户网站的后端。该公司在 Amazon RDS for PostgreSQL 上运行 Multi-AZ 数据库集群。该公司需要实施 30 天的备份保留策略。该公司目前同时拥有自动 RDS 备份和手动 RDS 备份。该公司希望保留现有类型的、不到 30 天的 RDS 备份。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Backup 将 RDS 备份保留策略配置为自动备份 30 天。手动删除超过 30 天的手动备份。",
      "B": "禁用 RDS 自动备份。删除超过 30 天的自动备份和手动备份。将 RDS 备份保留策略配置为自动备份 30 天。",
      "C": "将 RDS 备份保留策略配置为自动备份 30 天。手动删除超过 30 天的手动备份。",
      "D": "禁用 RDS 自动备份。使用 AWS CloudFormation 自动删除超过 30 天的自动备份和手动备份。将 RDS 备份保留策略配置为自动备份 30 天。"
    }
  },
  {
    "id": 990,
    "topic": "1",
    "question_en": "A company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on-premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose. Which storage solution should a solutions architect recommend for use after the migration?",
    "options_en": {
      "A": "AWS DataSync",
      "B": "Amazon Elastic Block Store (Amazon EBS)",
      "C": "Amazon Elastic File System (Amazon EFS)",
      "D": "Amazon EMR File System (Amazon EMRFS)"
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司计划将传统应用程序迁移到 AWS。该应用程序当前使用 NFS 与本地存储解决方案通信以存储应用程序数据。 为了此目的，该应用程序无法修改为使用 NFS 以外的任何其他通信协议。 解决方案架构师应该为迁移后使用推荐哪种存储解决方案？",
    "options_cn": {
      "A": "AWS DataSync",
      "B": "Amazon Elastic Block Store (Amazon EBS)",
      "C": "Amazon Elastic File System (Amazon EFS)",
      "D": "Amazon EMR File System (Amazon EMRFS)"
    }
  },
  {
    "id": 991,
    "topic": "1",
    "question_en": "A company uses GPS trackers to document the migration patterns of thousands of sea turtles. The trackers check every 5 minutes to see if a turtle has moved more than 100 yards (91.4 meters). If a turtle has moved, its tracker sends the new coordinates to a web application running on three Amazon EC2 instances that are in multiple Availability Zones in one AWS Region. Recently, the web application was overwhelmed while processing an unexpected volume of tracker data. Data was lost with no way to replay the events. A solutions architect must prevent this problem from happening again and needs a solution with the least operational overhead. What should the solutions architect do to meet these requirements?",
    "options_en": {
      "A": "Create an Amazon S3 bucket to store the data. Configure the application to scan for new data in the bucket for processing.",
      "B": "Create an Amazon API Gateway endpoint to handle transmitted location coordinates. Use an AWS Lambda function to process each item concurrently.",
      "C": "Create an Amazon Simple Queue Service (Amazon SQS) queue to store the incoming data. Configure the application to poll for new messages for processing.",
      "D": "Create an Amazon DynamoDB table to store transmitted location coordinates. Configure the application to query the table for new data for processing. Use TTL to remove data that has been processed."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司使用 GPS 跟踪器记录数千只海龟的迁徙模式。 跟踪器每 5 分钟检查一次，看看海龟是否移动了超过 100 码（91.4 米）。 如果海龟移动了，它的跟踪器会将新的坐标发送到在位于一个 AWS 区域中的多个可用区内的三个 Amazon EC2 实例上运行的 Web 应用程序。 最近，Web 应用程序在处理意外的大量跟踪器数据时不堪重负。 数据丢失且无法重放事件。 解决方案架构师必须防止此问题再次发生，并需要一个运营开销最少的解决方案。 解决方案架构师应该怎么做才能满足这些要求？",
    "options_cn": {
      "A": "创建一个 Amazon S3 存储桶来存储数据。 配置应用程序以扫描存储桶中的新数据进行处理。",
      "B": "创建一个 Amazon API Gateway 端点来处理传输的位置坐标。 使用一个 AWS Lambda 函数来并行处理每个项目。",
      "C": "创建一个 Amazon Simple Queue Service (Amazon SQS) 队列来存储传入数据。 配置应用程序以轮询新消息以进行处理。",
      "D": "创建一个 Amazon DynamoDB 表来存储传输的位置坐标。 配置应用程序以查询该表以获取要处理的新数据。 使用 TTL 删除已处理的数据。"
    }
  },
  {
    "id": 992,
    "topic": "1",
    "question_en": "A company's software development team needs an Amazon RDS Multi-AZ cluster. The RDS cluster will serve as a backend for a desktop client that is deployed on premises. The desktop client requires direct connectivity to the RDS cluster. The company must give the development team the ability to connect to the cluster by using the client when the team is in the ofice. Which solution provides the required connectivity MOST securely?",
    "options_en": {
      "A": "Create a VPC and two public subnets. Create the RDS cluster in the public subnets. Use AWS Site-to-Site VPN with a customer gateway in the company's ofice.",
      "B": "Create a VPC and two private subnets. Create the RDS cluster in the private subnets. Use AWS Site-to-Site VPN with a customer gateway in the company's ofice.",
      "C": "Create a VPC and two private subnets. Create the RDS cluster in the private subnets. Use RDS security groups to allow the company's ofice IP ranges to access the cluster.",
      "D": "Create a VPC and two public subnets. Create the RDS cluster in the public subnets. Create a cluster user for each developer. Use RDS security groups to allow the users to access the cluster."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司的软件开发团队需要一个 Amazon RDS Multi-AZ 集群。 RDS 集群将作为部署在本地的桌面客户端的后端。 桌面客户端需要直接连接到 RDS 集群。 公司必须让开发团队能够在团队在办公室时使用客户端连接到集群。 哪种解决方案以最安全的方式提供所需的连接？",
    "options_cn": {
      "A": "创建一个 VPC 和两个公有子网。 在公有子网中创建 RDS 集群。 使用 AWS Site-to-Site VPN，并在公司的办公室中使用一个客户网关。",
      "B": "创建一个 VPC 和两个私有子网。 在私有子网中创建 RDS 集群。 使用 AWS Site-to-Site VPN，并在公司的办公室中使用一个客户网关。",
      "C": "创建一个 VPC 和两个私有子网。 在私有子网中创建 RDS 集群。 使用 RDS 安全组允许公司的办公室 IP 范围访问集群。",
      "D": "创建一个 VPC 和两个公有子网。 在公有子网中创建 RDS 集群。 为每个开发人员创建一个集群用户。 使用 RDS 安全组允许用户访问集群。"
    }
  },
  {
    "id": 993,
    "topic": "1",
    "question_en": "A solutions architect is creating an application that will handle batch processing of large amounts of data. The input data will be held in Amazon S3 and the output data will be stored in a different S3 bucket. For processing, the application will transfer the data over the network between multiple Amazon EC2 instances. What should the solutions architect do to reduce the overall data transfer costs?",
    "options_en": {
      "A": "Place all the EC2 instances in an Auto Scaling group.",
      "B": "Place all the EC2 instances in the same AWS Region.",
      "C": "Place all the EC2 instances in the same Availability Zone.",
      "D": "Place all the EC2 instances in private subnets in multiple Availability Zones."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一位解决方案架构师正在创建一个应用程序，该应用程序将处理大量数据的批处理。 输入数据将保存在 Amazon S3 中，输出数据将存储在另一个 S3 存储桶中。 为了进行处理，应用程序将在多个 Amazon EC2 实例之间通过网络传输数据。 解决方案架构师应该怎么做才能减少总体数据传输成本？",
    "options_cn": {
      "A": "将所有 EC2 实例放置在 Auto Scaling 组中。",
      "B": "将所有 EC2 实例放置在相同的 AWS 区域中。",
      "C": "将所有 EC2 实例放置在相同的可用区中。",
      "D": "将所有 EC2 实例放置在多个可用区的私有子网中。"
    }
  },
  {
    "id": 994,
    "topic": "1",
    "question_en": "A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company's IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days. What should a solutions architect do to meet this requirement with the LEAST operational effort?",
    "options_en": {
      "A": "Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.",
      "B": "Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.",
      "C": "Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.",
      "D": "Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司托管了一个多层 Web 应用程序，该应用程序使用 Amazon Aurora MySQL 数据库集群进行存储。应用程序层托管在 Amazon EC2 实例上。该公司的 IT 安全指南规定数据库凭证必须加密并每 14 天轮换一次。解决方案架构师应该怎么做才能以最少的运营工作量满足此要求？",
    "options_cn": {
      "A": "创建一个新的 AWS Key Management Service (AWS KMS) 加密密钥。使用 AWS Secrets Manager 创建一个使用 KMS 密钥和适当凭证的新密钥。将该密钥与 Aurora 数据库集群关联。配置 14 天的自定义轮换周期。",
      "B": "在 AWS Systems Manager Parameter Store 中创建两个参数：一个用于用户名的字符串参数，另一个使用 SecureString 类型用于密码。为密码参数选择 AWS Key Management Service (AWS KMS) 加密，并在应用程序层加载这些参数。实现一个 AWS Lambda 函数，每 14 天轮换一次密码。",
      "C": "将包含凭证的文件存储在 AWS Key Management Service (AWS KMS) 加密的 Amazon Elastic File System (Amazon EFS) 文件系统中。在应用程序层的所有 EC2 实例中挂载 EFS 文件系统。限制对文件系统的访问权限，以便应用程序可以读取该文件，并且只有超级用户才能修改该文件。实现一个 AWS Lambda 函数，每 14 天轮换一次 Aurora 中的密钥，并将新凭证写入该文件。",
      "D": "将包含凭证的文件存储在 AWS Key Management Service (AWS KMS) 加密的 Amazon S3 存储桶中，应用程序使用该存储桶加载凭证。定期将文件下载到应用程序以确保使用正确的凭证。实现一个 AWS Lambda 函数，每 14 天轮换一次 Aurora 凭证，并将这些凭证上传到 S3 存储桶中的文件中。"
    }
  },
  {
    "id": 995,
    "topic": "1",
    "question_en": "A streaming media company is rebuilding its infrastructure to accommodate increasing demand for video content that users consume daily. The company needs to process terabyte-sized videos to block some content in the videos. Video processing can take up to 20 minutes. The company needs a solution that will scale with demand and remain cost-effective. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use AWS Lambda functions to process videos. Store video metadata in Amazon DynamoDB. Store video content in Amazon S3 Intelligent-Tiering.",
      "B": "Use Amazon Elastic Container Service (Amazon ECS) and AWS Fargate to implement microservices to process videos. Store video metadata in Amazon Aurora. Store video content in Amazon S3 Intelligent-Tiering.",
      "C": "Use Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) to process videos. Store video content in Amazon S3 Standard. Use Amazon Simple Queue Service (Amazon SQS) for queuing and to decouple processing tasks.",
      "D": "Deploy a containerized video processing application on Amazon Elastic Kubernetes Service (Amazon EKS) on Amazon EC2. Store video metadata in Amazon RDS in a single Availability Zone. Store video content in Amazon S3 Glacier Deep Archive."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家流媒体公司正在重建其基础设施，以满足用户每天对视频内容日益增长的需求。该公司需要处理 TB 级视频以屏蔽视频中的某些内容。视频处理可能需要长达 20 分钟。该公司需要一个能够随需求扩展且具有成本效益的解决方案。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 AWS Lambda 函数处理视频。将视频元数据存储在 Amazon DynamoDB 中。将视频内容存储在 Amazon S3 Intelligent-Tiering 中。",
      "B": "使用 Amazon Elastic Container Service (Amazon ECS) 和 AWS Fargate 来实现微服务以处理视频。将视频元数据存储在 Amazon Aurora 中。将视频内容存储在 Amazon S3 Intelligent-Tiering 中。",
      "C": "在 Application Load Balancer (ALB) 之后，使用 Auto Scaling 组中的 Amazon EC2 实例处理视频。将视频内容存储在 Amazon S3 Standard 中。使用 Amazon Simple Queue Service (Amazon SQS) 进行排队，并将处理任务解耦。",
      "D": "在 Amazon EC2 上部署基于容器的视频处理应用程序，该应用程序位于 Amazon Elastic Kubernetes Service (Amazon EKS) 上。将视频元数据存储在单个可用区的 Amazon RDS 中。将视频内容存储在 Amazon S3 Glacier Deep Archive 中。"
    }
  },
  {
    "id": 996,
    "topic": "1",
    "question_en": "A company runs an on-premises application on a Kubernetes cluster. The company recently added millions of new customers. The company's existing on-premises infrastructure is unable to handle the large number of new customers. The company needs to migrate the on-premises application to the AWS Cloud. The company will migrate to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The company does not want to manage the underlying compute infrastructure for the new architecture on AWS. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use a self-managed node to supply compute capacity. Deploy the application to the new EKS cluster.",
      "B": "Use managed node groups to supply compute capacity. Deploy the application to the new EKS cluster.",
      "C": "Use AWS Fargate to supply compute capacity. Create a Fargate profile. Use the Fargate profile to deploy the application.",
      "D": "Use managed node groups with Karpenter to supply compute capacity. Deploy the application to the new EKS cluster."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司在其 Kubernetes 集群上运行一个本地应用程序。该公司最近增加了数百万新客户。该公司现有的本地基础设施无法处理大量新客户。该公司需要将本地应用程序迁移到 AWS 云。该公司将迁移到 Amazon Elastic Kubernetes Service (Amazon EKS) 集群。该公司不想管理 AWS 上新架构的基础计算基础设施。哪种解决方案以最小的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用自管理节点提供计算能力。将应用程序部署到新的 EKS 集群。",
      "B": "使用托管节点组提供计算能力。将应用程序部署到新的 EKS 集群。",
      "C": "使用 AWS Fargate 提供计算能力。创建一个 Fargate 配置文件。使用 Fargate 配置文件部署应用程序。",
      "D": "使用带有 Karpenter 的托管节点组提供计算能力。将应用程序部署到新的 EKS 集群。"
    }
  },
  {
    "id": 997,
    "topic": "1",
    "question_en": "A company is launching a new application that requires a structured database to store user profiles, application settings, and transactional data. The database must be scalable with application trafic and must offer backups. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Deploy a self-managed database on Amazon EC2 instances by using open source software. Use Spot Instances for cost optimization. Configure automated backups to Amazon S3.",
      "B": "Use Amazon RDS. Use on-demand capacity mode for the database with General Purpose SSD storage. Configure automatic backups with a retention period of 7 days.",
      "C": "Use Amazon Aurora Serverless for the database. Use serverless capacity scaling. Configure automated backups to Amazon S3.",
      "D": "Deploy a self-managed NoSQL database on Amazon EC2 instances. Use Reserved Instances for cost optimization. Configure automated backups directly to Amazon S3 Glacier Flexible Retrieval."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司正在推出一个新应用程序，该应用程序需要一个结构化数据库来存储用户配置文件、应用程序设置和事务数据。 该数据库必须能够随应用程序流量进行扩展，并且必须提供备份。 哪个解决方案能以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "在 Amazon EC2 实例上使用开源软件部署一个自管理的数据库。使用 Spot Instances 进行成本优化。配置自动备份到 Amazon S3。",
      "B": "使用 Amazon RDS。将按需容量模式用于数据库，并使用 General Purpose SSD 存储。配置自动备份，保留期为 7 天。",
      "C": "使用 Amazon Aurora Serverless 作为数据库。使用无服务器容量扩展。配置自动备份到 Amazon S3。",
      "D": "在 Amazon EC2 实例上部署一个自管理的 NoSQL 数据库。使用 Reserved Instances 进行成本优化。配置自动备份到 Amazon S3 Glacier Flexible Retrieval。"
    }
  },
  {
    "id": 998,
    "topic": "1",
    "question_en": "A company runs its legacy web application on AWS. The web application server runs on an Amazon EC2 instance in the public subnet of a VPC. The web application server collects images from customers and stores the image files in a locally attached Amazon Elastic Block Store (Amazon EBS) volume. The image files are uploaded every night to an Amazon S3 bucket for backup. A solutions architect discovers that the image files are being uploaded to Amazon S3 through the public endpoint. The solutions architect needs to ensure that trafic to Amazon S3 does not use the public endpoint. Which solution will meet these requirements?",
    "options_en": {
      "A": "Create a gateway VPC endpoint for the S3 bucket that has the necessary permissions for the VPC. Configure the subnet route table to use the gateway VPC endpoint.",
      "B": "Move the S3 bucket inside the VPC. Configure the subnet route table to access the S3 bucket through private IP addresses.",
      "C": "Create an Amazon S3 access point for the Amazon EC2 instance inside the VPConfigure the web application to upload by using the Amazon S3 access point.",
      "D": "Configure an AWS Direct Connect connection between the VPC that has the Amazon EC2 instance and Amazon S3 to provide a dedicated network path."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在 AWS 上运行其旧版 Web 应用程序。Web 应用程序服务器在 VPC 的公有子网中的 Amazon EC2 实例上运行。Web 应用程序服务器从客户那里收集图像，并将图像文件存储在本地连接的 Amazon Elastic Block Store (Amazon EBS) 卷中。图像文件每天晚上都会上传到 Amazon S3 存储桶进行备份。一位解决方案架构师发现图像文件是通过公有端点上传到 Amazon S3 的。解决方案架构师需要确保到 Amazon S3 的流量不使用公有端点。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "为 S3 存储桶创建网关 VPC 端点，该端点具有 VPC 的必要权限。配置子网路由表以使用网关 VPC 端点。",
      "B": "将 S3 存储桶移入 VPC 内部。配置子网路由表以通过私有 IP 地址访问 S3 存储桶。",
      "C": "为 VPC 内部的 Amazon EC2 实例创建 Amazon S3 访问点。配置 Web 应用程序以使用 Amazon S3 访问点上传。",
      "D": "在具有 Amazon EC2 实例的 VPC 和 Amazon S3 之间配置 AWS Direct Connect 连接，以提供专用网络路径。"
    }
  },
  {
    "id": 999,
    "topic": "1",
    "question_en": "A company is creating a prototype of an ecommerce website on AWS. The website consists of an Application Load Balancer, an Auto Scaling group of Amazon EC2 instances for web servers, and an Amazon RDS for MySQL DB instance that runs with the Single-AZ configuration. The website is slow to respond during searches of the product catalog. The product catalog is a group of tables in the MySQL database that the company does not update frequently. A solutions architect has determined that the CPU utilization on the DB instance is high when product catalog searches occur. What should the solutions architect recommend to improve the performance of the website during searches of the product catalog?",
    "options_en": {
      "A": "Migrate the product catalog to an Amazon Redshift database. Use the COPY command to load the product catalog tables.",
      "B": "Implement an Amazon ElastiCache for Redis cluster to cache the product catalog. Use lazy loading to populate the cache.",
      "C": "Add an additional scaling policy to the Auto Scaling group to launch additional EC2 instances when database response is slow.",
      "D": "Turn on the Multi-AZ configuration for the DB instance. Configure the EC2 instances to throttle the product catalog queries that are sent to the database."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 上创建一个电子商务网站原型。该网站由一个 Application Load Balancer、一个用于 Web 服务器的 Amazon EC2 实例的 Auto Scaling 组以及一个使用 Single-AZ 配置运行的 Amazon RDS for MySQL 数据库实例组成。在搜索产品目录时，网站响应缓慢。产品目录是 MySQL 数据库中的一组表，该公司不经常更新这些表。解决方案架构师确定，在进行产品目录搜索时，数据库实例上的 CPU 利用率很高。解决方案架构师应该建议采取什么措施来提高网站在搜索产品目录期间的性能？",
    "options_cn": {
      "A": "将产品目录迁移到 Amazon Redshift 数据库。使用 COPY 命令加载产品目录表。",
      "B": "实施一个 Amazon ElastiCache for Redis 集群来缓存产品目录。使用延迟加载来填充缓存。",
      "C": "向 Auto Scaling 组添加额外的伸缩策略，以便在数据库响应缓慢时启动额外的 EC2 实例。",
      "D": "为数据库实例打开 Multi-AZ 配置。配置 EC2 实例以限制发送到数据库的产品目录查询。"
    }
  },
  {
    "id": 1000,
    "topic": "1",
    "question_en": "A company currently stores 5 TB of data in on-premises block storage systems. The company's current storage solution provides limited space for additional data. The company runs applications on premises that must be able to retrieve frequently accessed data with low latency. The company requires a cloud-based storage solution. Which solution will meet these requirements with the MOST operational eficiency?",
    "options_en": {
      "A": "Use Amazon S3 File Gateway. Integrate S3 File Gateway with the on-premises applications to store and directly retrieve files by using the SMB file system.",
      "B": "Use an AWS Storage Gateway Volume Gateway with cached volumes as iSCSI targets.",
      "C": "Use an AWS Storage Gateway Volume Gateway with stored volumes as iSCSI targets.",
      "D": "Use an AWS Storage Gateway Tape Gateway. Integrate Tape Gateway with the on-premises applications to store virtual tapes in Amazon S3."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司目前将 5 TB 的数据存储在本地块存储系统中。该公司当前的存储解决方案为额外数据提供了有限的空间。该公司在本地运行应用程序，这些应用程序必须能够以低延迟检索经常访问的数据。该公司需要基于云的存储解决方案。哪种解决方案将以最高的运营效率满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon S3 File Gateway。将 S3 File Gateway 与本地应用程序集成，以使用 SMB 文件系统存储和直接检索文件。",
      "B": "使用 AWS Storage Gateway Volume Gateway，使用缓存卷作为 iSCSI 目标。",
      "C": "使用 AWS Storage Gateway Volume Gateway，使用存储卷作为 iSCSI 目标。",
      "D": "使用 AWS Storage Gateway Tape Gateway。将 Tape Gateway 与本地应用程序集成，以将虚拟磁带存储在 Amazon S3 中。"
    }
  },
  {
    "id": 1001,
    "topic": "1",
    "question_en": "A company operates a food delivery service. Because of recent growth, the company's order processing system is experiencing scaling problems during peak trafic hours. The current architecture includes Amazon EC2 instances in an Auto Scaling group that collect orders from an application. A second group of EC2 instances in an Auto Scaling group fulfills the orders. The order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event. A solutions architect must ensure that the order collection process and the order fulfillment process can both scale adequately during peak trafic hours. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure each Auto Scaling group's minimum capacity to meet its peak workload value.",
      "B": "Use Amazon CloudWatch to monitor the CPUUtilization metric for each instance in both Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic to create additional Auto Scaling groups on demand.",
      "C": "Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on notifications that the queues send.",
      "D": "Provision two Amazon Simple Queue Service (Amazon SQS) queues. Use one SQS queue for order collection. Use the second SQS queue for order fulfillment. Configure the EC2 instances to poll their respective queues. Scale the Auto Scaling groups based on the number of messages in each queue."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司运营一家食品配送服务。由于最近的增长，该公司的订单处理系统在高峰时段遇到了扩展问题。当前的架构包括一个 Auto Scaling 组中的 Amazon EC2 实例，这些实例从应用程序收集订单。第二个 Auto Scaling 组中的 EC2 实例履行订单。订单收集过程很快，但订单履行过程可能需要更长时间。由于扩展事件，数据不能丢失。解决方案架构师必须确保订单收集流程和订单履行流程在高峰时段都能充分扩展。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon CloudWatch 监控两个 Auto Scaling 组中每个实例的 CPUUtilization 指标。将每个 Auto Scaling 组的最小容量配置为满足其峰值工作负载值。",
      "B": "使用 Amazon CloudWatch 监控两个 Auto Scaling 组中每个实例的 CPUUtilization 指标。配置一个 CloudWatch 警报以调用 Amazon Simple Notification Service (Amazon SNS) 主题，以按需创建额外的 Auto Scaling 组。",
      "C": "配置两个 Amazon Simple Queue Service (Amazon SQS) 队列。将一个 SQS 队列用于订单收集。将第二个 SQS 队列用于订单履行。配置 EC2 实例以轮询它们各自的队列。根据队列发送的通知来扩展 Auto Scaling 组。",
      "D": "配置两个 Amazon Simple Queue Service (Amazon SQS) 队列。将一个 SQS 队列用于订单收集。将第二个 SQS 队列用于订单履行。配置 EC2 实例以轮询它们各自的队列。根据每个队列中的消息数量来扩展 Auto Scaling 组。"
    }
  },
  {
    "id": 1002,
    "topic": "1",
    "question_en": "An online gaming company is transitioning user data storage to Amazon DynamoDB to support the company's growing user base. The current architecture includes DynamoDB tables that contain user profiles, achievements, and in-game transactions. The company needs to design a robust, continuously available, and resilient DynamoDB architecture to maintain a seamless gaming experience for users. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create DynamoDB tables in a single AWS Region. Use on-demand capacity mode. Use global tables to replicate data across multiple Regions.",
      "B": "Use DynamoDB Accelerator (DAX) to cache frequently accessed data. Deploy tables in a single AWS Region and enable auto scaling. Configure Cross-Region Replication manually to additional Regions.",
      "C": "Create DynamoDB tables in multiple AWS Regions. Use on-demand capacity mode. Use DynamoDB Streams for Cross-Region Replication between Regions.",
      "D": "Use DynamoDB global tables for automatic multi-Region replication. Deploy tables in multiple AWS Regions. Use provisioned capacity mode. Enable auto scaling."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家在线游戏公司正在将用户数据存储迁移到 Amazon DynamoDB，以支持公司不断增长的用户群。目前的架构包括包含用户个人资料、成就和游戏内交易的 DynamoDB 表。该公司需要设计一个强大、持续可用且有弹性的 DynamoDB 架构，以保持为用户提供无缝的游戏体验。哪种解决方案能够最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "在单个 AWS 区域中创建 DynamoDB 表。使用按需容量模式。使用全局表将数据复制到多个区域。",
      "B": "使用 DynamoDB Accelerator (DAX) 缓存经常访问的数据。在单个 AWS 区域中部署表并启用自动伸缩。手动配置 跨区域复制 到其他区域。",
      "C": "在多个 AWS 区域中创建 DynamoDB 表。使用按需容量模式。使用 DynamoDB Streams 在区域之间进行 跨区域复制。",
      "D": "使用 DynamoDB 全局表进行自动多区域复制。在多个 AWS 区域中部署表。使用预置容量模式。启用自动伸缩。"
    }
  },
  {
    "id": 1003,
    "topic": "1",
    "question_en": "A company runs its media rendering application on premises. The company wants to reduce storage costs and has moved all data to Amazon S3. The on-premises rendering application needs low-latency access to storage. The company needs to design a storage solution for the application. The storage solution must maintain the desired application performance. Which storage solution will meet these requirements in the MOST cost-effective way?",
    "options_en": {
      "A": "Use Mountpoint for Amazon S3 to access the data in Amazon S3 for the on-premises application.",
      "B": "Configure an Amazon S3 File Gateway to provide storage for the on-premises application.",
      "C": "Copy the data from Amazon S3 to Amazon FSx for Windows File Server. Configure an Amazon FSx File Gateway to provide storage for the on-premises application.",
      "D": "Configure an on-premises file server. Use the Amazon S3 API to connect to S3 storage. Configure the application to access the storage from the on-premises file server."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在其本地运行媒体渲染应用程序。该公司希望降低存储成本，并将所有数据移动到 Amazon S3。本地渲染应用程序需要低延迟访问存储。该公司需要为应用程序设计一个存储解决方案。该存储解决方案必须保持所需的应用程序性能。哪种存储解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "使用 Mountpoint for Amazon S3 访问 Amazon S3 中的数据，以供本地应用程序使用。",
      "B": "配置一个 Amazon S3 File Gateway 来为本地应用程序提供存储。",
      "C": "将数据从 Amazon S3 复制到 Amazon FSx for Windows File Server。配置一个 Amazon FSx File Gateway 来为本地应用程序提供存储。",
      "D": "配置一个本地文件服务器。使用 Amazon S3 API 连接到 S3 存储。配置应用程序从本地文件服务器访问存储。"
    }
  },
  {
    "id": 1004,
    "topic": "1",
    "question_en": "A company hosts its enterprise resource planning (ERP) system in the us-east-1 Region. The system runs on Amazon EC2 instances. Customers use a public API that is hosted on the EC2 instances to exchange information with the ERP system. International customers report slow API response times from their data centers. Which solution will improve response times for the international customers MOST cost-effectively?",
    "options_en": {
      "A": "Create an AWS Direct Connect connection that has a public virtual interface (VIF) to provide connectivity from each customer's data center to us-east-1. Route customer API requests by using a Direct Connect gateway to the ERP system API.",
      "B": "Set up an Amazon CloudFront distribution in front of the API. Configure the CachingOptimized managed cache policy to provide improved cache eficiency.",
      "C": "Set up AWS Global Accelerator. Configure listeners for the necessary ports. Configure endpoint groups for the appropriate Regions to distribute trafic. Create an endpoint in the group for the API.",
      "D": "Use AWS Site-to-Site VPN to establish dedicated VPN tunnels between Regions and customer networks. Route trafic to the API over the VPN connections."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在其 us-east-1 区域托管其企业资源规划 (ERP) 系统。该系统在 Amazon EC2 实例上运行。客户使用托管在 EC2 实例上的公共 API 与 ERP 系统交换信息。国际客户报告来自其数据中心的 API 响应时间较慢。哪种解决方案将以最具成本效益的方式改善国际客户的响应时间？",
    "options_cn": {
      "A": "创建具有公共虚拟接口 (VIF) 的 AWS Direct Connect 连接，以提供从每个客户的数据中心到 us-east-1 的连接。使用 Direct Connect 网关将客户 API 请求路由到 ERP 系统 API。",
      "B": "在 API 前设置 Amazon CloudFront 分发。配置 CachingOptimized 托管缓存策略以提供改进的缓存效率。",
      "C": "设置 AWS Global Accelerator。为必要的端口配置侦听器。配置相应区域的端点组以分配流量。在组中为 API 创建一个端点。",
      "D": "使用 AWS Site-to-Site VPN 在区域和客户网络之间建立专用 VPN 隧道。通过 VPN 连接将流量路由到 API。"
    }
  },
  {
    "id": 1005,
    "topic": "1",
    "question_en": "A company tracks customer satisfaction by using surveys that the company hosts on its website. The surveys sometimes reach thousands of customers every hour. Survey results are currently sent in email messages to the company so company employees can manually review results and assess customer sentiment. The company wants to automate the customer survey process. Survey results must be available for the previous 12 months. Which solution will meet these requirements in the MOST scalable way?",
    "options_en": {
      "A": "Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Create an AWS Lambda function to poll the SQS queue, call Amazon Comprehend for sentiment analysis, and save the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future.",
      "B": "Send the survey results data to an API that is running on an Amazon EC2 instance. Configure the API to store the survey results as a new record in an Amazon DynamoDB table, call Amazon Comprehend for sentiment analysis, and save the results in a second DynamoDB table. Set the TTL for all records to 365 days in the future.",
      "C": "Write the survey results data to an Amazon S3 bucket. Use S3 Event Notifications to invoke an AWS Lambda function to read the data and call Amazon Rekognition for sentiment analysis. Store the sentiment analysis results in a second S3 bucket. Use S3 lifecycle policies on each bucket to expire objects after 365 days.",
      "D": "Send the survey results data to an Amazon API Gateway endpoint that is connected to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the SQS queue to invoke an AWS Lambda function that calls Amazon Lex for sentiment analysis and saves the results to an Amazon DynamoDB table. Set the TTL for all records to 365 days in the future."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司通过使用其网站上托管的调查来跟踪客户满意度。 这些调查有时每小时都会接触到数千名客户。 调查结果目前通过电子邮件消息发送给公司，以便公司员工可以手动审查结果并评估客户情绪。 公司希望自动化客户调查流程。 调查结果必须提供过去 12 个月的数据。 哪种解决方案将以最具可扩展性的方式满足这些要求？",
    "options_cn": {
      "A": "将调查结果数据发送到连接到 Amazon Simple Queue Service (Amazon SQS) 队列的 Amazon API Gateway 终端节点。 创建一个 AWS Lambda 函数来轮询 SQS 队列，调用 Amazon Comprehend 进行情感分析，并将结果保存到 Amazon DynamoDB 表中。 将所有记录的 TTL 设置为 365 天后的未来。",
      "B": "将调查结果数据发送到在 Amazon EC2 实例上运行的 API。 配置 API 将调查结果存储为 Amazon DynamoDB 表中的新记录，调用 Amazon Comprehend 进行情感分析，并将结果保存在第二个 DynamoDB 表中。 将所有记录的 TTL 设置为 365 天后的未来。",
      "C": "将调查结果数据写入 Amazon S3 存储桶。 使用 S3 事件通知来调用 AWS Lambda 函数以读取数据并调用 Amazon Rekognition 进行情感分析。 将情感分析结果存储在第二个 S3 存储桶中。 在每个存储桶上使用 S3 生命周期策略在 365 天后使对象过期。",
      "D": "将调查结果数据发送到连接到 Amazon Simple Queue Service (Amazon SQS) 队列的 Amazon API Gateway 终端节点。 配置 SQS 队列以调用 AWS Lambda 函数，该函数调用 Amazon Lex 进行情感分析并将结果保存到 Amazon DynamoDB 表中。 将所有记录的 TTL 设置为 365 天后的未来。"
    }
  },
  {
    "id": 1006,
    "topic": "1",
    "question_en": "A company uses AWS Systems Manager for routine management and patching of Amazon EC2 instances. The EC2 instances are in an IP address type target group behind an Application Load Balancer (ALB). New security protocols require the company to remove EC2 instances from service during a patch. When the company attempts to follow the security protocol during the next patch, the company receives errors during the patching window. Which combination of solutions will resolve the errors? (Choose two.)",
    "options_en": {
      "A": "Change the target type of the target group from IP address type to instance type.",
      "B": "Continue to use the existing Systems Manager document without changes because it is already optimized to handle instances that are in an IP address type target group behind an ALB.",
      "C": "Implement the AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation document to manage the patching process.",
      "D": "Use Systems Manager Maintenance Windows to automatically remove the instances from service to patch the instances",
      "E": "Configure Systems Manager State Manager to remove the instances from service and manage the patching schedule. Use ALB health checks to re-route trafic."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司使用 AWS Systems Manager 进行 Amazon EC2 实例的例行管理和修补。 EC2 实例位于 Application Load Balancer (ALB) 之后的一个 IP 地址类型目标组中。新的安全协议要求公司在修补期间将 EC2 实例从服务中移除。当公司尝试在下一次修补期间遵循安全协议时，公司在修补窗口期间收到错误。哪种解决方案组合将解决这些错误？（选择两个。）",
    "options_cn": {
      "A": "将目标组的目标类型从 IP 地址类型更改为实例类型。",
      "B": "继续使用现有的 Systems Manager 文档，无需更改，因为它已经过优化，可以处理位于 ALB 之后 IP 地址类型目标组中的实例。",
      "C": "实施 AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation 文档来管理修补过程。",
      "D": "使用 Systems Manager 维护时段自动将实例从服务中移除以修补实例。",
      "E": "配置 Systems Manager State Manager 以将实例从服务中移除并管理修补计划。 使用 ALB 健康检查来重新路由流量。"
    }
  },
  {
    "id": 1007,
    "topic": "1",
    "question_en": "A medical company wants to perform transformations on a large amount of clinical trial data that comes from several customers. The company must extract the data from a relational database that contains the customer data. Then the company will transform the data by using a series of complex rules. The company will load the data to Amazon S3 when the transformations are complete. All data must be encrypted where it is processed before the company stores the data in Amazon S3. All data must be encrypted by using customer-specific keys. Which solution will meet these requirements with the LEAST amount of operational effort?",
    "options_en": {
      "A": "Create one AWS Glue job for each customer. Attach a security configuration to each job that uses server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data.",
      "B": "Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses client-side encryption with a custom client-side root key (CSE-Custom) to encrypt the data.",
      "C": "Create one AWS Glue job for each customer. Attach a security configuration to each job that uses client-side encryption with AWS KMS managed keys (CSE-KMS) to encrypt the data.",
      "D": "Create one Amazon EMR cluster for each customer. Attach a security configuration to each cluster that uses server-side encryption with AWS KMS keys (SSE-KMS) to encrypt the data."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家医疗公司希望对来自多个客户的大量临床试验数据进行转换。该公司必须从包含客户数据的关系数据库中提取数据。然后，该公司将使用一系列复杂的规则转换数据。转换完成后，该公司会将数据加载到 Amazon S3。在公司将数据存储在 Amazon S3 之前，所有数据都必须在处理时进行加密。所有数据都必须使用客户特定的密钥进行加密。哪种解决方案将以最少的运营工作量满足这些要求？",
    "options_cn": {
      "A": "为每个客户创建一个 AWS Glue 作业。将安全配置附加到每个作业，该配置使用带有 Amazon S3 托管密钥 (SSE-S3) 的服务器端加密来加密数据。",
      "B": "为每个客户创建一个 Amazon EMR 集群。将安全配置附加到每个集群，该配置使用带有自定义客户端根密钥 (CSE-Custom) 的客户端加密来加密数据。",
      "C": "为每个客户创建一个 AWS Glue 作业。将安全配置附加到每个作业，该配置使用带有 AWS KMS 托管密钥 (CSE-KMS) 的客户端加密来加密数据。",
      "D": "为每个客户创建一个 Amazon EMR 集群。将安全配置附加到每个集群，该配置使用带有 AWS KMS 密钥 (SSE-KMS) 的服务器端加密来加密数据。"
    }
  },
  {
    "id": 1008,
    "topic": "1",
    "question_en": "A company hosts a website analytics application on a single Amazon EC2 On-Demand Instance. The analytics application is highly resilient and is designed to run in stateless mode. The company notices that the application is showing signs of performance degradation during busy times and is presenting 5xx errors. The company needs to make the application scale seamlessly. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load across the two EC2 instances.",
      "B": "Create an Amazon Machine Image (AMI) of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances.",
      "C": "Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization is more than 75%.",
      "D": "Create an Amazon Machine Image (AMI) of the web application. Apply the AMI to a launch template. Create an Auto Scaling group that includes the launch template. Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司在单个 Amazon EC2 按需实例上托管一个网站分析应用程序。该分析应用程序具有高度的弹性，并且设计为以无状态模式运行。该公司注意到该应用程序在繁忙时段显示出性能下降的迹象，并出现 5xx 错误。该公司需要使应用程序无缝扩展。哪种解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "创建该 Web 应用程序的 Amazon Machine Image (AMI)。使用 AMI 启动第二个 EC2 按需实例。使用 Application Load Balancer 将负载分配到两个 EC2 实例。",
      "B": "创建该 Web 应用程序的 Amazon Machine Image (AMI)。使用 AMI 启动第二个 EC2 按需实例。使用 Amazon Route 53 加权路由将负载分配到两个 EC2 实例。",
      "C": "创建 AWS Lambda 函数以停止 EC2 实例并更改实例类型。创建 Amazon CloudWatch 警报，以便在 CPU 利用率超过 75% 时调用 Lambda 函数。",
      "D": "创建该 Web 应用程序的 Amazon Machine Image (AMI)。将 AMI 应用于启动模板。创建一个包含启动模板的 Auto Scaling 组。配置启动模板以使用 Spot Fleet。将 Application Load Balancer 附加到 Auto Scaling 组。"
    }
  },
  {
    "id": 1009,
    "topic": "1",
    "question_en": "A company runs an environment where data is stored in an Amazon S3 bucket. The objects are accessed frequently throughout the day. The company has strict da ta encryption requirements for data that is stored in the S3 bucket. The company currently uses AWS Key Management Service (AWS KMS) for encryption. The company wants to optimize costs associated with encrypting S3 objects without making additional calls to AWS KMS. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use server-side encryption with Amazon S3 managed keys (SSE-S3).",
      "B": "Use an S3 Bucket Key for server-side encryption with AWS KMS keys (SSE-KMS) on the new objects.",
      "C": "Use client-side encryption with AWS KMS customer managed keys.",
      "D": "Use server-side encryption with customer-provided keys (SSE-C) stored in AWS KMS."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司运营一个环境，数据存储在 Amazon S3 存储桶中。这些对象在一天中经常被访问。该公司对存储在 S3 存储桶中的数据有严格的数据加密要求。该公司目前使用 AWS Key Management Service (AWS KMS) 进行加密。该公司希望优化与加密 S3 对象相关的成本，而无需对 AWS KMS 进行额外的调用。哪个解决方案将满足这些要求？",
    "options_cn": {
      "A": "使用由 Amazon S3 托管的密钥（SSE-S3）进行服务器端加密。",
      "B": "在新对象上使用 S3 存储桶密钥进行服务器端加密，密钥由 AWS KMS 管理（SSE-KMS）。",
      "C": "使用由 AWS KMS 客户管理的密钥进行客户端加密。",
      "D": "使用客户提供的密钥（SSE-C）进行服务器端加密，这些密钥存储在 AWS KMS 中。"
    }
  },
  {
    "id": 1010,
    "topic": "1",
    "question_en": "A company runs multiple workloads on virtual machines (VMs) in an on-premises data center. The company is expanding rapidly. The on- premises data center is not able to scale fast enough to meet business needs. The company wants to migrate the workloads to AWS. The migration is time sensitive. The company wants to use a lift-and-shift strategy for non-critical workloads. Which combination of steps will meet these requirements? (Choose three.)",
    "options_en": {
      "A": "Use the AWS Schema Conversion Tool (AWS SCT) to collect data about the VMs.",
      "B": "Use AWS Application Migration Service. Install the AWS Replication Agent on the VMs.",
      "C": "Complete the initial replication of the VMs. Launch test instances to perform acceptance tests on the VMs.",
      "D": "Stop all operations on the VMs. Launch a cutover instanc",
      "E": "E. Use AWS App2Container (A2C) to collect data about the VMs",
      "F": "Use AWS Database Migration Service (AWS DMS) to migrate the VMs."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在其本地数据中心内的虚拟机 (VM) 上运行多个工作负载。该公司正在迅速扩张。本地数据中心无法快速扩展以满足业务需求。该公司希望将工作负载迁移到 AWS。迁移具有时间敏感性。该公司希望对非关键工作负载使用迁移策略。哪三个步骤的组合将满足这些要求？（选择三个。）",
    "options_cn": {
      "A": "使用 AWS 架构转换工具 (AWS SCT) 收集有关 VM 的数据。",
      "B": "使用 AWS Application Migration Service。在 VM 上安装 AWS 复制代理。",
      "C": "完成 VM 的初始复制。启动测试实例以对 VM 执行验收测试。",
      "D": "停止 VM 上的所有操作。启动一个切换实例。",
      "E": "使用 AWS App2Container (A2C) 收集有关 VM 的数据。",
      "F": "使用 AWS 数据库迁移服务 (AWS DMS) 迁移 VM。"
    }
  },
  {
    "id": 1011,
    "topic": "1",
    "question_en": "A company hosts an application in a private subnet. The company has already integrated the application with Amazon Cognito. The company uses an Amazon Cognito user pool to authenticate users. The company needs to modify the application so the application can securely store user documents in an Amazon S3 bucket. Which combination of steps will securely integrate Amazon S3 with the application? (Choose two.)",
    "options_en": {
      "A": "Create an Amazon Cognito identity pool to generate secure Amazon S3 access tokens for users when they successfully log in.",
      "B": "Use the existing Amazon Cognito user pool to generate Amazon S3 access tokens for users when they successfully log in.",
      "C": "Create an Amazon S3 VPC endpoint in the same VPC where the company hosts the application.",
      "D": "Create a NAT gateway in the VPC where the company hosts the application. Assign a policy to the S3 bucket to deny any request that is not initiated from Amazon Cognito",
      "E": "Attach a policy to the S3 bucket that allows access only from the users' IP addresses."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司在私有子网中托管一个应用程序。该公司已经将该应用程序与 Amazon Cognito 集成。该公司使用 Amazon Cognito 用户池来验证用户身份。该公司需要修改该应用程序，以便该应用程序可以安全地将用户文档存储在 Amazon S3 存储桶中。哪些步骤组合将安全地将 Amazon S3 与应用程序集成？（选择两个。）",
    "options_cn": {
      "A": "创建一个 Amazon Cognito 身份池，以便在用户成功登录时为用户生成安全的 Amazon S3 访问令牌。",
      "B": "使用现有的 Amazon Cognito 用户池，在用户成功登录时为用户生成 Amazon S3 访问令牌。",
      "C": "在托管该应用程序的同一 VPC 中创建 Amazon S3 VPC endpoint。",
      "D": "在托管该应用程序的 VPC 中创建 NAT Gateway。为 S3 存储桶分配一个策略，以拒绝任何未从 Amazon Cognito 启动的请求。",
      "E": "为 S3 存储桶附加一个策略，该策略仅允许来自用户 IP 地址的访问。"
    }
  },
  {
    "id": 1012,
    "topic": "1",
    "question_en": "A company has a three-tier web application that processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer. The processing tier consists of EC2 instances. The company decoupled the web tier and processing tier by using Amazon Simple Queue Service (Amazon SQS). The storage layer uses Amazon DynamoDB. At peak times, some users report order processing delays and halls. The company has noticed that during these delays, the EC2 instances are running at 100% CPU usage, and the SQS queue fills up. The peak times are variable and unpredictable. The company needs to improve the performance of the application. Which solution will meet these requirements?",
    "options_en": {
      "A": "Use scheduled scaling for Amazon EC2 Auto Scaling to scale out the processing tier instances for the duration of peak usage times. Use the CPU Utilization metric to determine when to scale.",
      "B": "Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier. Use target utilization as a metric to determine when to scale.",
      "C": "Add an Amazon CloudFront distribution to cache the responses for the web tier. Use HTTP latency as a metric to determine when to scale.",
      "D": "Use an Amazon EC2 Auto Scaling target tracking policy to scale out the processing tier instances. Use the ApproximateNumberOfMessages attribute to determine when to scale."
    },
    "correct_answer": "D",
    "vote_percentage": "",
    "question_cn": "一家公司有一个三层 Web 应用程序，用于处理客户订单。Web 层由 Application Load Balancer 后面的 Amazon EC2 实例组成。处理层由 EC2 实例组成。该公司使用 Amazon Simple Queue Service (Amazon SQS) 将 Web 层和处理层解耦。存储层使用 Amazon DynamoDB。在高峰时段，一些用户报告订单处理延迟和暂停。该公司注意到，在这些延迟期间，EC2 实例的 CPU 使用率达到 100%，并且 SQS 队列已满。高峰时段是可变的且不可预测的。该公司需要提高应用程序的性能。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "对 Amazon EC2 Auto Scaling 使用预定扩展，以在高峰使用时段内扩展处理层实例。使用 CPU 利用率指标来确定何时进行扩展。",
      "B": "在 DynamoDB 后端层之前使用 Amazon ElastiCache for Redis。使用目标利用率作为指标来确定何时进行扩展。",
      "C": "添加 Amazon CloudFront 分发以缓存 Web 层的响应。使用 HTTP 延迟作为指标来确定何时进行扩展。",
      "D": "使用 Amazon EC2 Auto Scaling 目标跟踪策略来扩展处理层实例。使用 ApproximateNumberOfMessages 属性来确定何时进行扩展。"
    }
  },
  {
    "id": 1013,
    "topic": "1",
    "question_en": "A company's production environment consists of Amazon EC2 On-Demand Instances that run constantly between Monday and Saturday. The instances must run for only 12 hours on Sunday and cannot tolerate interruptions. The company wants to cost-optimize the production environment. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Purchase Scheduled Reserved Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.",
      "B": "Purchase Convertible Reserved Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.",
      "C": "Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.",
      "D": "Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday. Purchase Convertible Reserved Instances for the EC2 instances that run constantly between Monday and Saturday."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司的生产环境包括在周一到周六之间持续运行的 Amazon EC2 按需实例。这些实例必须仅在周日运行 12 小时，并且不能容忍中断。该公司希望对生产环境进行成本优化。哪种解决方案将最具成本效益地满足这些要求？",
    "options_cn": {
      "A": "为仅在周日运行 12 小时的 EC2 实例购买预留实例（计划）。为周一到周六之间持续运行的 EC2 实例购买预留实例（标准）。",
      "B": "为仅在周日运行 12 小时的 EC2 实例购买可转换预留实例。为周一到周六之间持续运行的 EC2 实例购买预留实例（标准）。",
      "C": "对仅在周日运行 12 小时的 EC2 实例使用 Spot 实例。为周一到周六之间持续运行的 EC2 实例购买预留实例（标准）。",
      "D": "对仅在周日运行 12 小时的 EC2 实例使用 Spot 实例。为周一到周六之间持续运行的 EC2 实例购买可转换预留实例。"
    }
  },
  {
    "id": 1014,
    "topic": "1",
    "question_en": "A digital image processing company wants to migrate its on-premises monolithic application to the AWS Cloud. The company processes thousands of images and generates large files as part of the processing workfiow. The company needs a solution to manage the growing number of image processing jobs. The solution must also reduce the manual tasks in the image processing workfiow. The company does not want to manage the underlying infrastructure of the solution. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 Spot Instances to process the images. Configure Amazon Simple Queue Service (Amazon SQS) to orchestrate the workfiow. Store the processed files in Amazon Elastic File System (Amazon EFS).",
      "B": "Use AWS Batch jobs to process the images. Use AWS Step Functions to orchestrate the workfiow. Store the processed files in an Amazon S3 bucket.",
      "C": "Use AWS Lambda functions and Amazon EC2 Spot Instances to process the images. Store the processed files in Amazon FSx.",
      "D": "Deploy a group of Amazon EC2 instances to process the images. Use AWS Step Functions to orchestrate the workfiow. Store the processed files in an Amazon Elastic Block Store (Amazon EBS) volume."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家数字图像处理公司希望将其本地整体应用程序迁移到 AWS 云。该公司处理数千张图像，并在处理工作流程中生成大型文件。该公司需要一个解决方案来管理不断增长的图像处理作业数量。该解决方案还必须减少图像处理工作流程中的手动任务。该公司不想管理该解决方案的底层基础设施。哪个解决方案将以最低的运营开销满足这些要求？",
    "options_cn": {
      "A": "使用 Amazon Elastic Container Service (Amazon ECS) 和 Amazon EC2 Spot 实例来处理图像。配置 Amazon Simple Queue Service (Amazon SQS) 来编排工作流程。将处理后的文件存储在 Amazon Elastic File System (Amazon EFS) 中。",
      "B": "使用 AWS Batch 作业来处理图像。使用 AWS Step Functions 来编排工作流程。将处理后的文件存储在 Amazon S3 存储桶中。",
      "C": "使用 AWS Lambda 函数和 Amazon EC2 Spot 实例来处理图像。将处理后的文件存储在 Amazon FSx 中。",
      "D": "部署一组 Amazon EC2 实例来处理图像。使用 AWS Step Functions 来编排工作流程。将处理后的文件存储在 Amazon Elastic Block Store (Amazon EBS) 卷中。"
    }
  },
  {
    "id": 1015,
    "topic": "1",
    "question_en": "A company's image-hosting website gives users around the world the ability to up load, view, and download images from their mobile devices. The company currently hosts the static website in an Amazon S3 bucket. Because of the website's growing popularity, the website's performance has decreased. Users have reported latency issues when they upload and download images. The company must improve the performance of the website. Which solution will meet these requirements with the LEAST implementation effort?",
    "options_en": {
      "A": "Configure an Amazon CloudFront distribution for the S3 bucket to improve the download performance. Enable S3 Transfer Acceleration to improve the upload performance.",
      "B": "Configure Amazon EC2 instances of the right sizes in multiple AWS Regions. Migrate the application to the EC2 instances. Use an Application Load Balancer to distribute the website trafic equally among the EC2 instances. Configure AWS Global Accelerator to address global demand with low latency.",
      "C": "Configure an Amazon CloudFront distribution that uses the S3 bucket as an origin to improve the download performance. Configure the application to use CloudFront to upload images to improve the upload performance. Create S3 buckets in multiple AWS Regions. Configure replication rules for the buckets to replicate users' data based on the users' location. Redirect downloads to the S3 bucket that is closest to each user's location.",
      "D": "Configure AWS Global Accelerator for the S3 bucket to improve network performance. Create an endpoint for the application to use Global Accelerator instead of the S3 bucket."
    },
    "correct_answer": "A",
    "vote_percentage": "",
    "question_cn": "一家公司的图片托管网站为世界各地的用户提供了从其移动设备上传、查看和下载图片的功能。该公司目前将静态网站托管在 Amazon S3 存储桶中。由于网站越来越受欢迎，网站的性能有所下降。用户报告在上传和下载图片时遇到延迟问题。该公司必须提高网站的性能。哪种解决方案将以最少的实施工作量满足这些要求？",
    "options_cn": {
      "A": "为 S3 存储桶配置 Amazon CloudFront 分发，以提高下载性能。打开 S3 Transfer Acceleration 以提高上传性能。",
      "B": "在多个 AWS 区域中配置适当大小的 Amazon EC2 实例。将应用程序迁移到 EC2 实例。使用 Application Load Balancer 在 EC2 实例之间平均分配网站流量。配置 AWS Global Accelerator 以低延迟处理全球需求。",
      "C": "配置使用 S3 存储桶作为源的 Amazon CloudFront 分发，以提高下载性能。配置应用程序以使用 CloudFront 上传图片以提高上传性能。在多个 AWS 区域中创建 S3 存储桶。配置存储桶的复制规则，以根据用户的位置复制用户的数据。将下载重定向到最靠近每个用户位置的 S3 存储桶。",
      "D": "为 S3 存储桶配置 AWS Global Accelerator 以提高网络性能。为应用程序创建一个端点以使用 Global Accelerator 而不是 S3 存储桶。"
    }
  },
  {
    "id": 1016,
    "topic": "1",
    "question_en": "A company runs an application in a private subnet behind an Application Load Balancer (ALB) in a VPC. The VPC has a NAT gateway and an internet gateway. The application calls the Amazon S3 API to store objects. According to the company's security policy, trafic from the application must not travel across the internet. Which solution will meet these requirements MOST cost-effectively?",
    "options_en": {
      "A": "Configure an S3 interface endpoint. Create a security group that allows outbound trafic to Amazon S3.",
      "B": "Configure an S3 gateway endpoint. Update the VPC route table to use the endpoint.",
      "C": "Configure an S3 bucket policy to allow trafic from the Elastic IP address that is assigned to the NAT gateway.",
      "D": "Create a second NAT gateway in the same subnet where the legacy application is deployed. Update the VPC route table to use the second NAT gateway."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司在 VPC 的 Application Load Balancer (ALB) 后面的私有子网中运行应用程序。VPC 具有 NAT 网关和 Internet 网关。应用程序调用 Amazon S3 API 来存储对象。根据公司的安全策略，来自应用程序的流量不得通过 Internet 传输。哪个解决方案将以最具成本效益的方式满足这些要求？",
    "options_cn": {
      "A": "配置一个 S3 接口终端节点。创建一个安全组，允许向 Amazon S3 发出流量。",
      "B": "配置一个 S3 网关终端节点。更新 VPC 路由表以使用该终端节点。",
      "C": "配置 S3 存储桶策略以允许来自分配给 NAT 网关的弹性 IP 地址的流量。",
      "D": "在部署旧应用程序的同一子网中创建第二个 NAT 网关。更新 VPC 路由表以使用第二个 NAT 网关。"
    }
  },
  {
    "id": 1017,
    "topic": "1",
    "question_en": "A company has an application that runs on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster on Amazon EC2 instances. The application has a UI that uses Amazon DynamoDB and data services that use Amazon S3 as part of the application deployment. The company must ensure that the EKS Pods for the UI can access only Amazon DynamoDB and that the EKS Pods for the data services can access only Amazon S3. The company uses AWS Identity and Access Management (IAM). Which solution meals these requirements?",
    "options_en": {
      "A": "Create separate IAM policies for Amazon S3 and DynamoDB access with the required permissions. Attach both IAM policies to the EC2 instance profile. Use role-based access control (RBAC) to control access to Amazon S3 or DynamoDB for the respective EKS Pods.",
      "B": "Create separate IAM policies for Amazon S3 and DynamoDB access with the required permissions. Attach the Amazon S3 IAM policy directly to the EKS Pods for the data services and the DynamoDB policy to the EKS Pods for the UI.",
      "C": "Create separate Kubernetes service accounts for the UI and data services to assume an IAM role. Attach the AmazonS3FullAccess policy to the data services account and the AmazonDynamoDBFullAccess policy to the UI service account.",
      "D": "Create separate Kubernetes service accounts for the UI and data services to assume an IAM role. Use IAM Role for Service Accounts (IRSA) to provide access to the EKS Pods for the UI to Amazon S3 and the EKS Pods for the data services to DynamoDB."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司有一个应用程序，该应用程序在 Amazon EC2 实例上的 Amazon Elastic Kubernetes Service (Amazon EKS) 集群上运行。该应用程序有一个使用 Amazon DynamoDB 的 UI 和使用 Amazon S3 的数据服务，这些都是应用程序部署的一部分。该公司必须确保 UI 的 EKS Pod 只能访问 Amazon DynamoDB，并且数据服务的 EKS Pod 只能访问 Amazon S3。该公司使用 AWS Identity and Access Management (IAM)。哪种解决方案满足这些要求？",
    "options_cn": {
      "A": "为 Amazon S3 和 DynamoDB 访问创建具有所需权限的单独 IAM 策略。将这两个 IAM 策略附加到 EC2 实例配置文件。使用基于角色的访问控制 (RBAC) 来控制相应 EKS Pod 对 Amazon S3 或 DynamoDB 的访问。",
      "B": "为 Amazon S3 和 DynamoDB 访问创建具有所需权限的单独 IAM 策略。将 Amazon S3 IAM 策略直接附加到数据服务的 EKS Pod，并将 DynamoDB 策略附加到 UI 的 EKS Pod。",
      "C": "为 UI 和数据服务创建单独的 Kubernetes 服务帐户以承担 IAM 角色。将 AmazonS3FullAccess 策略附加到数据服务帐户，并将 AmazonDynamoDBFullAccess 策略附加到 UI 服务帐户。",
      "D": "为 UI 和数据服务创建单独的 Kubernetes 服务帐户以承担 IAM 角色。使用 IAM Role for Service Accounts (IRSA) 为 UI 的 EKS Pod 提供对 Amazon S3 的访问权限，并为数据服务的 EKS Pod 提供对 DynamoDB 的访问权限。"
    }
  },
  {
    "id": 1018,
    "topic": "1",
    "question_en": "A company needs to give a globally distributed development team secure access to the company's AWS resources in a way that complies with security policies. The company currently uses an on-premises Active Directory for internal authentication. The company uses AWS Organizations to manage multiple AWS accounts that support multiple projects. The company needs a solution to integrate with the existing infrastructure to provide centralized identity management and access control. Which solution will meet these requirements with the LEAST operational overhead?",
    "options_en": {
      "A": "Set up AWS Directory Service to create an AWS managed Microsoft Active Directory on AWS. Establish a trust relationship with the on- premises Active Directory. Use IAM rotes that are assigned to Active Directory groups to access AWS resources within the company's AWS accounts.",
      "B": "Create an IAM user for each developer. Manually manage permissions for each IAM user based on each user's involvement with each project. Enforce multi-factor authentication (MFA) as an additional layer of security.",
      "C": "Use AD Connector in AWS Directory Service to connect to the on-premises Active Directory. Integrate AD Connector with AWS IAM Identity Center. Configure permissions sets to give each AD group access to specific AWS accounts and resources.",
      "D": "Use Amazon Cognito to deploy an identity federation solution. Integrate the identity federation solution with the on-premises Active Directory. Use Amazon Cognito to provide access tokens for developers to access AWS accounts and resources."
    },
    "correct_answer": "C",
    "vote_percentage": "",
    "question_cn": "一家公司需要为其全球分布的开发团队提供对公司 AWS 资源的访问权限，并确保其安全性符合安全策略。该公司目前使用本地 Active Directory 进行内部身份验证。该公司使用 AWS Organizations 管理支持多个项目的多个 AWS 账户。该公司需要一个解决方案来与现有基础设施集成，以提供集中式身份管理和访问控制。哪种解决方案以最少的运营开销满足这些要求？",
    "options_cn": {
      "A": "设置 AWS Directory Service 以在 AWS 上创建 AWS 托管的 Microsoft Active Directory。与本地 Active Directory 建立信任关系。使用分配给 Active Directory 组的 IAM 角色来访问公司 AWS 账户中的 AWS 资源。",
      "B": "为每个开发人员创建 IAM 用户。根据每个用户参与每个项目的情况手动管理每个 IAM 用户的权限。强制使用多因素身份验证 (MFA) 作为额外的安全层。",
      "C": "在 AWS Directory Service 中使用 AD Connector 连接到本地 Active Directory。将 AD Connector 与 AWS IAM Identity Center 集成。配置权限集以授予每个 AD 组对特定 AWS 账户和资源的访问权限。",
      "D": "使用 Amazon Cognito 部署身份联合解决方案。将身份联合解决方案与本地 Active Directory 集成。使用 Amazon Cognito 为开发人员提供访问令牌以访问 AWS 账户和资源。"
    }
  },
  {
    "id": 1019,
    "topic": "1",
    "question_en": "A company is developing an application in the AWS Cloud. The application's HTTP API contains critical information that is published in Amazon API Gateway. The critical information must be accessible from only a limited set of trusted IP addresses that belong to the company's internal network. Which solution will meet these requirements?",
    "options_en": {
      "A": "Set up an API Gateway private integration to restrict access to a predefined set of IP addresses.",
      "B": "Create a resource policy for the API that denies access to any IP address that is not specifically allowed.",
      "C": "Directly deploy the API in a private subnet. Create a network ACL. Set up rules to allow the trafic from specific IP addresses.",
      "D": "Modify the security group that is attached to API Gateway to allow inbound trafic from only the trusted IP addresses."
    },
    "correct_answer": "B",
    "vote_percentage": "",
    "question_cn": "一家公司正在 AWS 云中开发一个应用程序。该应用程序的 HTTP API 包含发布在 Amazon API Gateway 中的关键信息。关键信息只能从属于公司内部网络的有限的一组可信 IP 地址访问。哪种解决方案将满足这些要求？",
    "options_cn": {
      "A": "设置 API Gateway 私有集成以限制对预定义 IP 地址集的访问。",
      "B": "为 API 创建一个资源策略，该策略拒绝任何未明确允许的 IP 地址的访问。",
      "C": "直接在私有子网中部署 API。创建网络 ACL。设置规则以允许来自特定 IP 地址的流量。",
      "D": "修改附加到 API Gateway 的安全组，以仅允许来自可信 IP 地址的入站流量。"
    }
  }
]